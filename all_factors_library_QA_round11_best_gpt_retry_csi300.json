{
  "metadata": {
    "created_at": "2026-01-21T17:29:28.748983",
    "last_updated": "2026-01-22T09:06:56.822523",
    "total_factors": 83,
    "version": "1.0"
  },
  "factors": {
    "641ddb2db6374ff6": {
      "factor_id": "641ddb2db6374ff6",
      "factor_name": "Capitulation_Exhaustion_Score_60_20_10",
      "factor_expression": "MAX(TS_ZSCORE((TS_MAX($close,60)-$close)/(TS_MAX($close,60)+1e-8),252),0)*MAX(-TS_CORR($return,TS_PCTCHANGE($volume,1),20),0)*MAX(-TS_ZSCORE($open/(DELAY($close,1)+1e-8)-1,10),0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MAX(TS_ZSCORE((TS_MAX($close,60)-$close)/(TS_MAX($close,60)+1e-8),252),0)*MAX(-TS_CORR(TS_PCTCHANGE($close,1),TS_PCTCHANGE($volume,1),20),0)*MAX(-TS_ZSCORE($open/(DELAY($close,1)+1e-8)-1,10),0)\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Exhaustion_Score_60_20_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Capitulation/exhaustion proxy: combines 60D drawdown severity (standardized over 252D), negative 20D return–volume-change correlation, and negative 10D overnight gap z-score. High values aim to identify stress-driven selling exhaustion that can precede short-horizon reversals.",
      "factor_formulation": "CES=\\max\\left(Z_{252}\\left(\\frac{\\max_{60}(C)-C}{\\max_{60}(C)}\\right),0\\right)\\cdot\\max\\left(-\\rho_{20}(r,\\Delta\\%V),0\\right)\\cdot\\max\\left(-Z_{10}(\\frac{O}{C_{-1}}-1),0\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1bbd3e6bfef2",
        "parent_trajectory_ids": [
          "cf0bd0b282c0",
          "0db36aa1a67c"
        ],
        "hypothesis": "Hypothesis: A state-transition, regime-conditioned factor that predicts next-horizon returns by detecting a two-stage pipeline—(1) capitulation/exhaustion under stress (deep 60D drawdown + strongly negative 20D return–volume-change correlation + negative overnight-dominant moves) and (2) subsequent volatility-compression-to-breakout continuation (20D range/volatility squeeze + 55D Donchian breakout + 20D volume surprise)—where the factor adaptively shifts weight from reversal to breakout as post-capitulation compression and breakout confirmation emerge, thereby capturing the handoff from mean-reversion to trend continuation while filtering false breakouts and falling-knife rebounds.\n                Concise Observation: With only daily OHLCV available, both ‘capitulation’ and ‘breakout’ can be proxied robustly using (i) 60D drawdown severity, (ii) 20D corr(log-return, log-volume-change), (iii) 10D overnight return dominance from open vs prior close, (iv) 20D Donchian width/return-vol compression, (v) 55D Donchian breakout distance, and (vi) 20D log-volume z-score, enabling an explicit state controller rather than a single always-on continuation or reversal signal.\n                Concise Justification: The crossover aims to avoid parent weaknesses by (a) preventing trend-following false breakouts during stress via a stress gate and requiring post-capitulation squeeze improvement, and (b) preventing pure mean-reversion traps by demanding either emerging compression improvement or early breakout/volume confirmation before shifting weight toward continuation; economically, this aligns with liquidity-shock exhaustion followed by re-accumulation and eventual price discovery through breakout.\n                Concise Knowledge: If forced-selling creates temporary price dislocation, then deep medium-term drawdowns accompanied by negative return–volume-change correlation and negative overnight-dominant returns can indicate exhaustion and short-term rebound; when that rebound is followed by measurable volatility/range compression and then a price-level breakout with abnormal volume, continuation probability increases, so a regime-conditioned mixture that transitions from reversal-weighted to breakout-weighted signals should outperform an unconditional blend in daily OHLCV-only settings.\n                concise Specification: Define daily r_t=log(close_t/close_{t-1}), ovn_t=log(open_t/close_{t-1}), dv_t=log(volume_t/volume_{t-1}); Stress components: DD60_t=close_t/max(close_{t-59:t})-1 and DDZ_t=zscore_ts(DD60,252), CorrRV20_t=corr_ts(r,dv,20), OvnZ10_t=zscore_ts(ovn,10); Breakout components: Width20_t=(max(high_{t-19:t})-min(low_{t-19:t}))/close_t and Squeeze20_t=-zscore_ts(Width20,252) (or equivalently -zscore_ts(std_ts(r,20),252)), Break55_t=close_t/max(high_{t-54:t})-1, VolZ20_t=zscore_ts(log(volume),20); StressScore_t = (-DDZ_t)*max(0,-CorrRV20_t), StressWeight_t = sigmoid((StressScore_t-1.0)/0.5) (fixed center=1.0, scale=0.5); CapitExh_t = (-DDZ_t)*max(0,-CorrRV20_t)*max(0,-OvnZ10_t); BC_t = 0.4*Squeeze20_t + 0.4*Break55_t + 0.2*VolZ20_t; PostCapBC_t = BC_t*max(0, Squeeze20_t - Squeeze20_{t-5}); FinalFactor_t = (1-StressWeight_t)*BC_t + StressWeight_t*(0.7*CapitExh_t + 0.3*PostCapBC_t); all windows (5,10,20,55,60,252) and weights (0.4/0.4/0.2, 0.7/0.3) are fixed to create one static factor output from daily_pv OHLCV.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T17:29:28.748545"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1150757447201481,
        "ICIR": 0.0172302398982419,
        "1day.excess_return_without_cost.std": 0.0043855868817998,
        "1day.excess_return_with_cost.annualized_return": 0.0474453794374161,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003980702559682,
        "1day.excess_return_without_cost.annualized_return": 0.0947407209204337,
        "1day.excess_return_with_cost.std": 0.0043869180380865,
        "Rank IC": 0.0177967059639598,
        "IC": 0.0023988699481808,
        "1day.excess_return_without_cost.max_drawdown": -0.1053434467940478,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4002980610758913,
        "1day.pa": 0.0,
        "l2.valid": 0.9967469082458336,
        "Rank ICIR": 0.1315465153050344,
        "l2.train": 0.9937278935806476,
        "1day.excess_return_with_cost.information_ratio": 0.70104504687972,
        "1day.excess_return_with_cost.mean": 0.0001993503337706
      },
      "feedback": {
        "observations": "This run only tests the two implemented legs (Capitulation_Exhaustion_Score_60_20_10 and Compression_Breakout_Confirm_20_55_20_60). The combined strategy improves portfolio-level performance vs SOTA on return and risk-adjusted return, but deteriorates on signal-quality (IC) and tail risk (max drawdown).\n\nMetric read:\n- Annualized return: 0.0947 vs 0.0520 (better)\n- Information ratio: 1.4003 vs 0.9726 (better)\n- Max drawdown: -0.1053 vs -0.0726 (worse; deeper drawdown)\n- IC: 0.00240 vs 0.00580 (worse; weaker cross-sectional linear relation)\n\nInterpretation: the factor mix is producing better realized PnL/IR despite a weaker average linear IC—this often happens when payoffs are nonlinear/conditional (e.g., only works in specific regimes) or when the signal is “spiky” (captures occasional big moves) but is not consistently rank-correlated day to day. The drawdown worsening suggests regime-mistiming (false rebounds / false breakouts) is still material, which is exactly what the unimplemented regime-transition gate was supposed to mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis but does not fully validate it.\n\nSupported elements:\n- The two-stage concept (stress/exhaustion + compression/breakout confirmation) appears to translate into better portfolio outcomes (higher annualized return and IR), consistent with the idea that conditioning on post-stress dynamics can improve tradability.\n\nNot supported / unverified elements:\n- The hypothesis specifically emphasizes an adaptive state-transition that shifts weight from reversal to breakout as confirmation emerges. The key mechanism for that (Regime_Transition_Mix_60_20_5_55) was not implemented, so the core “handoff” claim cannot be directly verified.\n- The worse IC indicates the current implemented signals are not reliably ranking next-day returns across the universe, which weakens the claim that the constructed factor robustly predicts next-horizon returns in a generalizable cross-sectional sense.\n- The worse max drawdown indicates the current construction is not yet filtering falling knives / false breakouts adequately—again pointing to missing or insufficient regime conditioning and/or inadequate confirmation filters.",
        "decision": true,
        "reason": "Concrete iteration directions (keeping the same theoretical framework):\n\n1) Implement the regime-transition factor (critical to test the hypothesis)\n- Current limitation: you are effectively testing two independent legs without the state machine.\n- Implement Regime_Transition_Mix_60_20_5_55, but prefer a smooth gate over a hard threshold:\n  - Replace the indicator [stress > 2] with a logistic weight w in [0,1].\n  - Output = w * (reversal leg) + (1-w) * (breakout/continuation leg).\n  - This typically reduces instability and drawdowns caused by threshold jitter.\n- Hyperparameters to expose as separate factor variants (each variant is a new factor):\n  - Stress threshold (if kept): 1.5, 2.0, 2.5\n  - Logistic temperature: 0.5, 1.0, 2.0\n  - Reversal window: 3D, 5D, 10D (don’t mix; separate factors)\n\n2) Fix breakout definition to avoid look-ahead / same-bar bias and reduce false breakouts\n- In CBC and RTM you use max_55(H). For a proper Donchian breakout signal, use the previous 55-day high excluding today:\n  - max_55(DELAY(high,1))\n- Also consider using close-based channel (max_55(DELAY(close,1))) as a separate factor variant; it often aligns better with how breakouts are traded.\n- Add minimal confirmation (still simple): require close above prior channel by a small buffer, e.g. +0.5% or +1% (again: each buffer value is a separate factor definition).\n\n3) Reduce drawdown by adding a “falling-knife filter” inside the capitulation leg\n- Your CES multiplies three rectified components; products can become very spiky and can fire during ongoing downtrends.\n- Variants to test (separate factors):\n  - Use sum of clipped components instead of product (more robust):\n    CES_sum = clip(Z252(DD60),0,cap) + clip(-corr20,0,cap) + clip(-Z10(gap),0,cap)\n  - Add a stabilization condition: require 3–5 day realized volatility to stop expanding (e.g., -Δσ short-term), or require that the last 3-day return is not extremely negative.\n\n4) Improve IC (cross-sectional ranking) via normalization choices\n- For each leg, test these as separate factor versions:\n  - Cross-sectional rank (per day) after computing the raw signal.\n  - Winsorize then z-score (to reduce domination by microcaps/illiquids).\n  - Volatility scaling: divide the final signal by σ20 to reduce extreme risk concentration.\n\n5) Parameter sensitivity (must be explored within the same framework)\n- CES windows to vary as separate factors:\n  - Drawdown window: 40D / 60D / 80D\n  - Corr window: 10D / 20D / 30D\n  - Overnight z window: 5D / 10D / 20D\n- CBC windows to vary as separate factors:\n  - Compression vol window: σ10 / σ20 / σ30\n  - Breakout window: 40D / 55D / 80D\n  - Volume surprise: V/mean20 vs V/mean10; z-score over 60 vs 120\n\n6) Why the metric pattern matters\n- Higher annualized + IR but lower IC suggests the signal may be conditional/nonlinear. That is consistent with regime logic, but it also means you should explicitly encode the regime transition (the missing RTM) to stabilize drawdowns and improve generalization.\n\nComplexity control note:\n- No explicit complexity warning was provided. Still, prefer simpler constructions (sum + clipping + smooth gate) over multiplicative chains, because products tend to create extreme, regime-fragile outliers that often worsen drawdowns out of sample."
      }
    },
    "72c6933d20dc803c": {
      "factor_id": "72c6933d20dc803c",
      "factor_name": "Compression_Breakout_Confirm_20_55_20_60",
      "factor_expression": "0.4*TS_ZSCORE(INV(TS_STD($return,20)+1e-8),252)+0.4*($close-TS_MAX($high,55))/(TS_MAX($high,55)+1e-8)+0.2*TS_ZSCORE($volume/(TS_MEAN($volume,20)+1e-8),60)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"0.4*TS_ZSCORE(INV(TS_STD(TS_PCTCHANGE($close,1),20)+1e-8),252)+0.4*($close-DELAY(TS_MAX($high,55),1))/(DELAY(TS_MAX($high,55),1)+1e-8)+0.2*TS_ZSCORE($volume/(TS_MEAN($volume,20)+1e-8),60)\" # Your output factor expression will be filled in here\n    name = \"Compression_Breakout_Confirm_20_55_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Compression-to-breakout confirmation: rewards volatility compression (inverse 20D return volatility z-scored over 252D), proximity/strength of a 55D breakout, and a 20D volume surprise (volume vs 20D mean) standardized over 60D. Intended to capture continuation after post-stress compression resolves.",
      "factor_formulation": "CBC=0.4\\,Z_{252}\\left(\\frac{1}{\\sigma_{20}(r)}\\right)+0.4\\left(\\frac{C-\\max_{55}(H)}{\\max_{55}(H)}\\right)+0.2\\,Z_{60}\\left(\\frac{V}{\\mu_{20}(V)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1bbd3e6bfef2",
        "parent_trajectory_ids": [
          "cf0bd0b282c0",
          "0db36aa1a67c"
        ],
        "hypothesis": "Hypothesis: A state-transition, regime-conditioned factor that predicts next-horizon returns by detecting a two-stage pipeline—(1) capitulation/exhaustion under stress (deep 60D drawdown + strongly negative 20D return–volume-change correlation + negative overnight-dominant moves) and (2) subsequent volatility-compression-to-breakout continuation (20D range/volatility squeeze + 55D Donchian breakout + 20D volume surprise)—where the factor adaptively shifts weight from reversal to breakout as post-capitulation compression and breakout confirmation emerge, thereby capturing the handoff from mean-reversion to trend continuation while filtering false breakouts and falling-knife rebounds.\n                Concise Observation: With only daily OHLCV available, both ‘capitulation’ and ‘breakout’ can be proxied robustly using (i) 60D drawdown severity, (ii) 20D corr(log-return, log-volume-change), (iii) 10D overnight return dominance from open vs prior close, (iv) 20D Donchian width/return-vol compression, (v) 55D Donchian breakout distance, and (vi) 20D log-volume z-score, enabling an explicit state controller rather than a single always-on continuation or reversal signal.\n                Concise Justification: The crossover aims to avoid parent weaknesses by (a) preventing trend-following false breakouts during stress via a stress gate and requiring post-capitulation squeeze improvement, and (b) preventing pure mean-reversion traps by demanding either emerging compression improvement or early breakout/volume confirmation before shifting weight toward continuation; economically, this aligns with liquidity-shock exhaustion followed by re-accumulation and eventual price discovery through breakout.\n                Concise Knowledge: If forced-selling creates temporary price dislocation, then deep medium-term drawdowns accompanied by negative return–volume-change correlation and negative overnight-dominant returns can indicate exhaustion and short-term rebound; when that rebound is followed by measurable volatility/range compression and then a price-level breakout with abnormal volume, continuation probability increases, so a regime-conditioned mixture that transitions from reversal-weighted to breakout-weighted signals should outperform an unconditional blend in daily OHLCV-only settings.\n                concise Specification: Define daily r_t=log(close_t/close_{t-1}), ovn_t=log(open_t/close_{t-1}), dv_t=log(volume_t/volume_{t-1}); Stress components: DD60_t=close_t/max(close_{t-59:t})-1 and DDZ_t=zscore_ts(DD60,252), CorrRV20_t=corr_ts(r,dv,20), OvnZ10_t=zscore_ts(ovn,10); Breakout components: Width20_t=(max(high_{t-19:t})-min(low_{t-19:t}))/close_t and Squeeze20_t=-zscore_ts(Width20,252) (or equivalently -zscore_ts(std_ts(r,20),252)), Break55_t=close_t/max(high_{t-54:t})-1, VolZ20_t=zscore_ts(log(volume),20); StressScore_t = (-DDZ_t)*max(0,-CorrRV20_t), StressWeight_t = sigmoid((StressScore_t-1.0)/0.5) (fixed center=1.0, scale=0.5); CapitExh_t = (-DDZ_t)*max(0,-CorrRV20_t)*max(0,-OvnZ10_t); BC_t = 0.4*Squeeze20_t + 0.4*Break55_t + 0.2*VolZ20_t; PostCapBC_t = BC_t*max(0, Squeeze20_t - Squeeze20_{t-5}); FinalFactor_t = (1-StressWeight_t)*BC_t + StressWeight_t*(0.7*CapitExh_t + 0.3*PostCapBC_t); all windows (5,10,20,55,60,252) and weights (0.4/0.4/0.2, 0.7/0.3) are fixed to create one static factor output from daily_pv OHLCV.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T17:29:28.748545"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1150757447201481,
        "ICIR": 0.0172302398982419,
        "1day.excess_return_without_cost.std": 0.0043855868817998,
        "1day.excess_return_with_cost.annualized_return": 0.0474453794374161,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003980702559682,
        "1day.excess_return_without_cost.annualized_return": 0.0947407209204337,
        "1day.excess_return_with_cost.std": 0.0043869180380865,
        "Rank IC": 0.0177967059639598,
        "IC": 0.0023988699481808,
        "1day.excess_return_without_cost.max_drawdown": -0.1053434467940478,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4002980610758913,
        "1day.pa": 0.0,
        "l2.valid": 0.9967469082458336,
        "Rank ICIR": 0.1315465153050344,
        "l2.train": 0.9937278935806476,
        "1day.excess_return_with_cost.information_ratio": 0.70104504687972,
        "1day.excess_return_with_cost.mean": 0.0001993503337706
      },
      "feedback": {
        "observations": "This run only tests the two implemented legs (Capitulation_Exhaustion_Score_60_20_10 and Compression_Breakout_Confirm_20_55_20_60). The combined strategy improves portfolio-level performance vs SOTA on return and risk-adjusted return, but deteriorates on signal-quality (IC) and tail risk (max drawdown).\n\nMetric read:\n- Annualized return: 0.0947 vs 0.0520 (better)\n- Information ratio: 1.4003 vs 0.9726 (better)\n- Max drawdown: -0.1053 vs -0.0726 (worse; deeper drawdown)\n- IC: 0.00240 vs 0.00580 (worse; weaker cross-sectional linear relation)\n\nInterpretation: the factor mix is producing better realized PnL/IR despite a weaker average linear IC—this often happens when payoffs are nonlinear/conditional (e.g., only works in specific regimes) or when the signal is “spiky” (captures occasional big moves) but is not consistently rank-correlated day to day. The drawdown worsening suggests regime-mistiming (false rebounds / false breakouts) is still material, which is exactly what the unimplemented regime-transition gate was supposed to mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis but does not fully validate it.\n\nSupported elements:\n- The two-stage concept (stress/exhaustion + compression/breakout confirmation) appears to translate into better portfolio outcomes (higher annualized return and IR), consistent with the idea that conditioning on post-stress dynamics can improve tradability.\n\nNot supported / unverified elements:\n- The hypothesis specifically emphasizes an adaptive state-transition that shifts weight from reversal to breakout as confirmation emerges. The key mechanism for that (Regime_Transition_Mix_60_20_5_55) was not implemented, so the core “handoff” claim cannot be directly verified.\n- The worse IC indicates the current implemented signals are not reliably ranking next-day returns across the universe, which weakens the claim that the constructed factor robustly predicts next-horizon returns in a generalizable cross-sectional sense.\n- The worse max drawdown indicates the current construction is not yet filtering falling knives / false breakouts adequately—again pointing to missing or insufficient regime conditioning and/or inadequate confirmation filters.",
        "decision": true,
        "reason": "Concrete iteration directions (keeping the same theoretical framework):\n\n1) Implement the regime-transition factor (critical to test the hypothesis)\n- Current limitation: you are effectively testing two independent legs without the state machine.\n- Implement Regime_Transition_Mix_60_20_5_55, but prefer a smooth gate over a hard threshold:\n  - Replace the indicator [stress > 2] with a logistic weight w in [0,1].\n  - Output = w * (reversal leg) + (1-w) * (breakout/continuation leg).\n  - This typically reduces instability and drawdowns caused by threshold jitter.\n- Hyperparameters to expose as separate factor variants (each variant is a new factor):\n  - Stress threshold (if kept): 1.5, 2.0, 2.5\n  - Logistic temperature: 0.5, 1.0, 2.0\n  - Reversal window: 3D, 5D, 10D (don’t mix; separate factors)\n\n2) Fix breakout definition to avoid look-ahead / same-bar bias and reduce false breakouts\n- In CBC and RTM you use max_55(H). For a proper Donchian breakout signal, use the previous 55-day high excluding today:\n  - max_55(DELAY(high,1))\n- Also consider using close-based channel (max_55(DELAY(close,1))) as a separate factor variant; it often aligns better with how breakouts are traded.\n- Add minimal confirmation (still simple): require close above prior channel by a small buffer, e.g. +0.5% or +1% (again: each buffer value is a separate factor definition).\n\n3) Reduce drawdown by adding a “falling-knife filter” inside the capitulation leg\n- Your CES multiplies three rectified components; products can become very spiky and can fire during ongoing downtrends.\n- Variants to test (separate factors):\n  - Use sum of clipped components instead of product (more robust):\n    CES_sum = clip(Z252(DD60),0,cap) + clip(-corr20,0,cap) + clip(-Z10(gap),0,cap)\n  - Add a stabilization condition: require 3–5 day realized volatility to stop expanding (e.g., -Δσ short-term), or require that the last 3-day return is not extremely negative.\n\n4) Improve IC (cross-sectional ranking) via normalization choices\n- For each leg, test these as separate factor versions:\n  - Cross-sectional rank (per day) after computing the raw signal.\n  - Winsorize then z-score (to reduce domination by microcaps/illiquids).\n  - Volatility scaling: divide the final signal by σ20 to reduce extreme risk concentration.\n\n5) Parameter sensitivity (must be explored within the same framework)\n- CES windows to vary as separate factors:\n  - Drawdown window: 40D / 60D / 80D\n  - Corr window: 10D / 20D / 30D\n  - Overnight z window: 5D / 10D / 20D\n- CBC windows to vary as separate factors:\n  - Compression vol window: σ10 / σ20 / σ30\n  - Breakout window: 40D / 55D / 80D\n  - Volume surprise: V/mean20 vs V/mean10; z-score over 60 vs 120\n\n6) Why the metric pattern matters\n- Higher annualized + IR but lower IC suggests the signal may be conditional/nonlinear. That is consistent with regime logic, but it also means you should explicitly encode the regime transition (the missing RTM) to stabilize drawdowns and improve generalization.\n\nComplexity control note:\n- No explicit complexity warning was provided. Still, prefer simpler constructions (sum + clipping + smooth gate) over multiplicative chains, because products tend to create extreme, regime-fragile outliers that often worsen drawdowns out of sample."
      }
    },
    "763c3a102b027963": {
      "factor_id": "763c3a102b027963",
      "factor_name": "Regime_Transition_Mix_60_20_5_55",
      "factor_expression": "(TS_ZSCORE((TS_MAX($close,60)-$close)/(TS_MAX($close,60)+1e-8),252)+MAX(-TS_CORR($return,TS_PCTCHANGE($volume,1),20),0)>2)?(-TS_MEAN($return,5)):(($close-TS_MAX($high,55))/(TS_MAX($high,55)+1e-8)+TS_ZSCORE(INV(TS_STD($return,20)+1e-8),252))",
      "factor_implementation_code": "",
      "factor_description": "State-transition mixture (simple gate): if stress is high (drawdown z-score plus negative return–volume-change correlation exceeds a fixed threshold), it outputs a short-term reversal signal (-5D mean return). Otherwise it outputs a breakout/continuation composite (55D breakout distance plus volatility-compression term).",
      "factor_formulation": "RTM=\\begin{cases}-\\mu_{5}(r),& Z_{252}(DD_{60})+\\max(-\\rho_{20}(r,\\Delta\\%V),0)>2\\\\ \\left(\\frac{C-\\max_{55}(H)}{\\max_{55}(H)}\\right)+Z_{252}\\left(\\frac{1}{\\sigma_{20}(r)}\\right),& \\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1bbd3e6bfef2",
        "parent_trajectory_ids": [
          "cf0bd0b282c0",
          "0db36aa1a67c"
        ],
        "hypothesis": "Hypothesis: A state-transition, regime-conditioned factor that predicts next-horizon returns by detecting a two-stage pipeline—(1) capitulation/exhaustion under stress (deep 60D drawdown + strongly negative 20D return–volume-change correlation + negative overnight-dominant moves) and (2) subsequent volatility-compression-to-breakout continuation (20D range/volatility squeeze + 55D Donchian breakout + 20D volume surprise)—where the factor adaptively shifts weight from reversal to breakout as post-capitulation compression and breakout confirmation emerge, thereby capturing the handoff from mean-reversion to trend continuation while filtering false breakouts and falling-knife rebounds.\n                Concise Observation: With only daily OHLCV available, both ‘capitulation’ and ‘breakout’ can be proxied robustly using (i) 60D drawdown severity, (ii) 20D corr(log-return, log-volume-change), (iii) 10D overnight return dominance from open vs prior close, (iv) 20D Donchian width/return-vol compression, (v) 55D Donchian breakout distance, and (vi) 20D log-volume z-score, enabling an explicit state controller rather than a single always-on continuation or reversal signal.\n                Concise Justification: The crossover aims to avoid parent weaknesses by (a) preventing trend-following false breakouts during stress via a stress gate and requiring post-capitulation squeeze improvement, and (b) preventing pure mean-reversion traps by demanding either emerging compression improvement or early breakout/volume confirmation before shifting weight toward continuation; economically, this aligns with liquidity-shock exhaustion followed by re-accumulation and eventual price discovery through breakout.\n                Concise Knowledge: If forced-selling creates temporary price dislocation, then deep medium-term drawdowns accompanied by negative return–volume-change correlation and negative overnight-dominant returns can indicate exhaustion and short-term rebound; when that rebound is followed by measurable volatility/range compression and then a price-level breakout with abnormal volume, continuation probability increases, so a regime-conditioned mixture that transitions from reversal-weighted to breakout-weighted signals should outperform an unconditional blend in daily OHLCV-only settings.\n                concise Specification: Define daily r_t=log(close_t/close_{t-1}), ovn_t=log(open_t/close_{t-1}), dv_t=log(volume_t/volume_{t-1}); Stress components: DD60_t=close_t/max(close_{t-59:t})-1 and DDZ_t=zscore_ts(DD60,252), CorrRV20_t=corr_ts(r,dv,20), OvnZ10_t=zscore_ts(ovn,10); Breakout components: Width20_t=(max(high_{t-19:t})-min(low_{t-19:t}))/close_t and Squeeze20_t=-zscore_ts(Width20,252) (or equivalently -zscore_ts(std_ts(r,20),252)), Break55_t=close_t/max(high_{t-54:t})-1, VolZ20_t=zscore_ts(log(volume),20); StressScore_t = (-DDZ_t)*max(0,-CorrRV20_t), StressWeight_t = sigmoid((StressScore_t-1.0)/0.5) (fixed center=1.0, scale=0.5); CapitExh_t = (-DDZ_t)*max(0,-CorrRV20_t)*max(0,-OvnZ10_t); BC_t = 0.4*Squeeze20_t + 0.4*Break55_t + 0.2*VolZ20_t; PostCapBC_t = BC_t*max(0, Squeeze20_t - Squeeze20_{t-5}); FinalFactor_t = (1-StressWeight_t)*BC_t + StressWeight_t*(0.7*CapitExh_t + 0.3*PostCapBC_t); all windows (5,10,20,55,60,252) and weights (0.4/0.4/0.2, 0.7/0.3) are fixed to create one static factor output from daily_pv OHLCV.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T17:29:28.748545"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1150757447201481,
        "ICIR": 0.0172302398982419,
        "1day.excess_return_without_cost.std": 0.0043855868817998,
        "1day.excess_return_with_cost.annualized_return": 0.0474453794374161,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003980702559682,
        "1day.excess_return_without_cost.annualized_return": 0.0947407209204337,
        "1day.excess_return_with_cost.std": 0.0043869180380865,
        "Rank IC": 0.0177967059639598,
        "IC": 0.0023988699481808,
        "1day.excess_return_without_cost.max_drawdown": -0.1053434467940478,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4002980610758913,
        "1day.pa": 0.0,
        "l2.valid": 0.9967469082458336,
        "Rank ICIR": 0.1315465153050344,
        "l2.train": 0.9937278935806476,
        "1day.excess_return_with_cost.information_ratio": 0.70104504687972,
        "1day.excess_return_with_cost.mean": 0.0001993503337706
      },
      "feedback": {
        "observations": "This run only tests the two implemented legs (Capitulation_Exhaustion_Score_60_20_10 and Compression_Breakout_Confirm_20_55_20_60). The combined strategy improves portfolio-level performance vs SOTA on return and risk-adjusted return, but deteriorates on signal-quality (IC) and tail risk (max drawdown).\n\nMetric read:\n- Annualized return: 0.0947 vs 0.0520 (better)\n- Information ratio: 1.4003 vs 0.9726 (better)\n- Max drawdown: -0.1053 vs -0.0726 (worse; deeper drawdown)\n- IC: 0.00240 vs 0.00580 (worse; weaker cross-sectional linear relation)\n\nInterpretation: the factor mix is producing better realized PnL/IR despite a weaker average linear IC—this often happens when payoffs are nonlinear/conditional (e.g., only works in specific regimes) or when the signal is “spiky” (captures occasional big moves) but is not consistently rank-correlated day to day. The drawdown worsening suggests regime-mistiming (false rebounds / false breakouts) is still material, which is exactly what the unimplemented regime-transition gate was supposed to mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis but does not fully validate it.\n\nSupported elements:\n- The two-stage concept (stress/exhaustion + compression/breakout confirmation) appears to translate into better portfolio outcomes (higher annualized return and IR), consistent with the idea that conditioning on post-stress dynamics can improve tradability.\n\nNot supported / unverified elements:\n- The hypothesis specifically emphasizes an adaptive state-transition that shifts weight from reversal to breakout as confirmation emerges. The key mechanism for that (Regime_Transition_Mix_60_20_5_55) was not implemented, so the core “handoff” claim cannot be directly verified.\n- The worse IC indicates the current implemented signals are not reliably ranking next-day returns across the universe, which weakens the claim that the constructed factor robustly predicts next-horizon returns in a generalizable cross-sectional sense.\n- The worse max drawdown indicates the current construction is not yet filtering falling knives / false breakouts adequately—again pointing to missing or insufficient regime conditioning and/or inadequate confirmation filters.",
        "decision": true,
        "reason": "Concrete iteration directions (keeping the same theoretical framework):\n\n1) Implement the regime-transition factor (critical to test the hypothesis)\n- Current limitation: you are effectively testing two independent legs without the state machine.\n- Implement Regime_Transition_Mix_60_20_5_55, but prefer a smooth gate over a hard threshold:\n  - Replace the indicator [stress > 2] with a logistic weight w in [0,1].\n  - Output = w * (reversal leg) + (1-w) * (breakout/continuation leg).\n  - This typically reduces instability and drawdowns caused by threshold jitter.\n- Hyperparameters to expose as separate factor variants (each variant is a new factor):\n  - Stress threshold (if kept): 1.5, 2.0, 2.5\n  - Logistic temperature: 0.5, 1.0, 2.0\n  - Reversal window: 3D, 5D, 10D (don’t mix; separate factors)\n\n2) Fix breakout definition to avoid look-ahead / same-bar bias and reduce false breakouts\n- In CBC and RTM you use max_55(H). For a proper Donchian breakout signal, use the previous 55-day high excluding today:\n  - max_55(DELAY(high,1))\n- Also consider using close-based channel (max_55(DELAY(close,1))) as a separate factor variant; it often aligns better with how breakouts are traded.\n- Add minimal confirmation (still simple): require close above prior channel by a small buffer, e.g. +0.5% or +1% (again: each buffer value is a separate factor definition).\n\n3) Reduce drawdown by adding a “falling-knife filter” inside the capitulation leg\n- Your CES multiplies three rectified components; products can become very spiky and can fire during ongoing downtrends.\n- Variants to test (separate factors):\n  - Use sum of clipped components instead of product (more robust):\n    CES_sum = clip(Z252(DD60),0,cap) + clip(-corr20,0,cap) + clip(-Z10(gap),0,cap)\n  - Add a stabilization condition: require 3–5 day realized volatility to stop expanding (e.g., -Δσ short-term), or require that the last 3-day return is not extremely negative.\n\n4) Improve IC (cross-sectional ranking) via normalization choices\n- For each leg, test these as separate factor versions:\n  - Cross-sectional rank (per day) after computing the raw signal.\n  - Winsorize then z-score (to reduce domination by microcaps/illiquids).\n  - Volatility scaling: divide the final signal by σ20 to reduce extreme risk concentration.\n\n5) Parameter sensitivity (must be explored within the same framework)\n- CES windows to vary as separate factors:\n  - Drawdown window: 40D / 60D / 80D\n  - Corr window: 10D / 20D / 30D\n  - Overnight z window: 5D / 10D / 20D\n- CBC windows to vary as separate factors:\n  - Compression vol window: σ10 / σ20 / σ30\n  - Breakout window: 40D / 55D / 80D\n  - Volume surprise: V/mean20 vs V/mean10; z-score over 60 vs 120\n\n6) Why the metric pattern matters\n- Higher annualized + IR but lower IC suggests the signal may be conditional/nonlinear. That is consistent with regime logic, but it also means you should explicitly encode the regime transition (the missing RTM) to stabilize drawdowns and improve generalization.\n\nComplexity control note:\n- No explicit complexity warning was provided. Still, prefer simpler constructions (sum + clipping + smooth gate) over multiplicative chains, because products tend to create extreme, regime-fragile outliers that often worsen drawdowns out of sample."
      }
    },
    "e710a84afaf4ad2e": {
      "factor_id": "e710a84afaf4ad2e",
      "factor_name": "VolCompression_Depth_TSRank_20v60",
      "factor_expression": "1 - TS_RANK(TS_STD($return, 20), 60) / 60",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"1 - TS_RANK(TS_STD(TS_PCTCHANGE($close, 1), 20), 60) / 60\" # Your output factor expression will be filled in here\n    name = \"VolCompression_Depth_TSRank_20v60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures how deeply the stock is in a recent low-volatility regime by ranking the current 20D realized volatility (std of daily returns) within the past 60D; higher values indicate stronger compression.",
      "factor_formulation": "CD_{20/60}=1-\\frac{\\mathrm{TS\\_RANK}(\\sigma_{20}(r),60)}{60}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "66a07d67dd3d",
        "parent_trajectory_ids": [
          "d8d61e5e8145",
          "ca115a2f9009"
        ],
        "hypothesis": "Hypothesis: Quiet-to-gap-led trend ignition continuation: Next-1~5D returns are higher when (i) a stock is in a deep 60D volatility/range compression regime, (ii) a non-extreme 1D expansion ‘breakout’ occurs with strong close-location/body direction, and (iii) the subsequent ~10D price path exhibits a statistically clean linear up/down trend whose cumulative return is dominated by overnight gaps (prev close→open) rather than intraday mean-reversion, with the forecast direction set by breakout-day CLV/body sign and reinforced by the sign of cumulative overnight return; the prediction strength scales multiplicatively with compression depth × expansion strength × trend-fit quality × overnight-dominance while explicitly capping extreme expansion tails to reduce drawdown clustering.\n                Concise Observation: The available OHLCV daily data enables (a) compression depth via rolling realized volatility/range ranks, (b) breakout expansion via 1D true-range/ATR z-scores with tail caps, (c) trend cleanliness via 10D log-price regression R²/residual volatility, and (d) overnight dominance via the ratio of cumulative close-to-open gaps to total close-to-close move—making the proposed multi-stage regime-change + quality filter directly testable as a single multiplicative factor.\n                Concise Justification: Combining a regime precondition (compression) with a trigger (controlled expansion breakout) and a post-trigger quality confirmation (clean trend + overnight-dominant drift) targets situations where price discovery transitions from equilibrium to informed repricing, while the tail-cap on expansion reduces the common breakout-strategy weakness of chasing exhausted gaps that increase drawdowns.\n                Concise Knowledge: If volatility/range compresses for a long window, latent order-imbalance can accumulate; when the first expansion breakout is confirmed by strong close-location (close near high/low) and the following short-window path has high linear-trend fit with returns coming primarily from overnight gaps (proxy for informed repricing), then continuation is more likely than reversal; when expansion is extremely large (tail event), continuation becomes less stable so capping/excluding the most extreme expansion improves robustness.\n                concise Specification: Use only daily_pv.h5 OHLCV: define compression_depth as rank(low) of 20D realized vol (std of log returns) or 20D avg true range versus a 60D history (e.g., bottom 20%); define expansion_strength as 1D true-range z-score vs past 60D, but exclude/cap top 1% to avoid tails; define breakout_direction via CLV=(2*close-high-low)/(high-low) and/or (close-open)/open; define trend_quality on last 10D as R² of linear regression of log(close) on time and residual volatility penalty; define overnight_dominance as |sum(log(open_t/close_{t-1}))| / (|sum(log(close_t/close_{t-1}))|+eps) over 10D; final factor = sign(breakout_direction)*sign(sum_overnight_10D) * compression_depth * clipped(expansion_strength) * trend_quality * overnight_dominance, computed cross-sectionally per day with fixed windows (20,60,10) and explicit eps/clipping thresholds for stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T18:04:49.192846"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0855530955018066,
        "ICIR": 0.0347834624845055,
        "1day.excess_return_without_cost.std": 0.0041367365392047,
        "1day.excess_return_with_cost.annualized_return": 0.031898853727355,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302037186339,
        "1day.excess_return_without_cost.annualized_return": 0.0785884850348917,
        "1day.excess_return_with_cost.std": 0.0041369368828074,
        "Rank IC": 0.0200703153301638,
        "IC": 0.0046179876754496,
        "1day.excess_return_without_cost.max_drawdown": -0.0783059190366319,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.231438070690706,
        "1day.pa": 0.0,
        "l2.valid": 0.9967316431147404,
        "Rank ICIR": 0.1513647968944023,
        "l2.train": 0.9932070117727992,
        "1day.excess_return_with_cost.information_ratio": 0.499813179385166,
        "1day.excess_return_with_cost.mean": 0.0001340287971737
      },
      "feedback": {
        "observations": "Compared with SOTA, the combined factor set improved portfolio-level performance but weakened linear predictiveness. Annualized return increased from 0.0520 to 0.0786 (better) and information ratio increased from 0.9726 to 1.2314 (better). However, max drawdown deteriorated (from -0.0726 to -0.0783; worse), and IC declined (0.00580 → 0.00462; worse). This pattern suggests the signal may be exploiting non-linear payoffs / conditional regimes (good realized returns/IR) but with weaker unconditional linear correlation to next-day returns (lower IC).",
        "hypothesis_evaluation": "Overall the results are directionally supportive of the hypothesis’ core idea (compression + breakout direction + continuation-quality improves forward returns), because the strategy-level outcomes (annualized return and IR) improved meaningfully. However, the hypothesis is only partially validated because:\n1) The drop in IC indicates the effect may be episodic/conditional rather than broadly monotonic day-to-day.\n2) The worse max drawdown suggests the “cap extreme expansion tails to reduce drawdown clustering” is not fully achieved by the current cap (clip at 3, floor at 0) and/or the breakout trigger still admits adverse regimes.\n3) The ‘post-breakout subsequent ~10D path’ part is tricky: your current OvernightDominant_TrendCleanliness_10D is only valid if it is computed strictly from information available up to the prediction time. If the intended design is ‘after breakout, wait ~10D to assess cleanliness’, then using it to predict next 1–5D returns creates a timing mismatch unless you explicitly delay the trading decision (or re-index the event so that the 10D window is in the past relative to the prediction date).",
        "decision": true,
        "reason": "To stay within the same theoretical framework while addressing observed issues:\n- **Why IC fell but returns rose**: the current construction likely produces a sparse/conditional signal (works strongly in select regimes) that boosts realized PnL/IR, but the average linear correlation across all days is weaker. Making the continuation-quality component more tightly aligned to the 1–5D forecast window should increase IC.\n- **Timing alignment (critical check)**: If ODTQ_10 is meant to measure ‘subsequent’ behavior after a breakout, you must implement it as an event-driven feature available at time t (e.g., breakout at t-6, measure follow-through from t-5..t-1, predict t..t+4), or shorten it to be fully backward-looking relative to the prediction date.\n- **Concrete within-framework iterations (explicit hyperparameters):**\n  1) Vol compression depth variants:\n     - Keep definition but test (lookback_vol, rank_window): (10,60), (20,120), (30,120) instead of only (20,60).\n     - Alternative compression measure within same concept: use range-based vol (e.g., std of log(high/low)) with the same TS_RANK window.\n  2) Breakout expansion cap sensitivity:\n     - Current: Z_60(high-low) clipped to [0,3]. Test z-window {40, 60, 120}, cap {2, 2.5, 3, 4}, and also a *soft cap* (e.g., cap via tanh) to reduce tail leverage without hard truncation.\n     - Direction component: replace SIGN(CLV) with SIGN(close-open) or SIGN((close-open)/(high-low)) to better match “body direction”; or combine CLV and body with a single sign: SIGN(0.5*CLV + 0.5*(close-open)/(high-low+eps)).\n  3) Overnight dominance / trend cleanliness made forecast-horizon consistent:\n     - Current ODTQ uses 10D. Test n={3,5,7,10}. For next-1~5D prediction, n=3–7 is more aligned.\n     - Decompose overnight vs intraday explicitly (same data, clearer):\n       * overnight_sum_n = SUM(log(open/DELAY(close,1)), n)\n       * intraday_sum_n = SUM(log(close/open), n)\n       * dominance = |overnight_sum_n| / (|overnight_sum_n| + |intraday_sum_n| + eps)\n       Then apply SIGN(overnight_sum_n) * dominance.\n     - Trend cleanliness: use R^2-like metric instead of 1 - std(resid)/std(logC) to stabilize scaling; still keep n small (3–10).\n  4) Drawdown control within the same hypothesis (no new data):\n     - Add a volatility-scaled position size proxy (e.g., divide breakout score by TS_STD(return,20)+eps) to reduce exposure when volatility spikes right after breakout.\n     - Add a “no-chase” filter: require expansion z-score to be in a mid-band (e.g., between 0.5 and cap), not just >0, to avoid weak/noisy breakouts and reduce tail-risk clustering.\n- **Complexity control**: current factors are relatively simple (few base features: open/close/high/low; no obvious parameter explosion). Keep the next iteration focused on 1–2 parameter changes at a time (window/cap/sign) rather than combining many new transforms into one long expression."
      }
    },
    "f5636cb12cc7a409": {
      "factor_id": "f5636cb12cc7a409",
      "factor_name": "Capped_RangeBreakout_Direction_CLV_60D",
      "factor_expression": "SIGN((2*$close-$high-$low)/($high-$low+1e-8)) * MAX(MIN(TS_ZSCORE($high-$low, 60), 3), 0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN((2*$close-$high-$low)/($high-$low+1e-8)) * MAX(MIN(TS_ZSCORE($high-$low, 60), 3), 0)\" # Your output factor expression will be filled in here\n    name = \"Capped_RangeBreakout_Direction_CLV_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Directional breakout trigger combining (i) capped 1D range expansion strength via 60D z-score of (high-low), clipped at 3 and floored at 0, and (ii) breakout direction via the sign of CLV (close-location value). Designed to avoid extreme expansion tails.",
      "factor_formulation": "F=\\mathrm{SIGN}(CLV)\\cdot \\max\\left(0,\\min\\left(Z_{60}(H-L),3\\right)\\right),\\quad CLV=\\frac{2C-H-L}{H-L+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "66a07d67dd3d",
        "parent_trajectory_ids": [
          "d8d61e5e8145",
          "ca115a2f9009"
        ],
        "hypothesis": "Hypothesis: Quiet-to-gap-led trend ignition continuation: Next-1~5D returns are higher when (i) a stock is in a deep 60D volatility/range compression regime, (ii) a non-extreme 1D expansion ‘breakout’ occurs with strong close-location/body direction, and (iii) the subsequent ~10D price path exhibits a statistically clean linear up/down trend whose cumulative return is dominated by overnight gaps (prev close→open) rather than intraday mean-reversion, with the forecast direction set by breakout-day CLV/body sign and reinforced by the sign of cumulative overnight return; the prediction strength scales multiplicatively with compression depth × expansion strength × trend-fit quality × overnight-dominance while explicitly capping extreme expansion tails to reduce drawdown clustering.\n                Concise Observation: The available OHLCV daily data enables (a) compression depth via rolling realized volatility/range ranks, (b) breakout expansion via 1D true-range/ATR z-scores with tail caps, (c) trend cleanliness via 10D log-price regression R²/residual volatility, and (d) overnight dominance via the ratio of cumulative close-to-open gaps to total close-to-close move—making the proposed multi-stage regime-change + quality filter directly testable as a single multiplicative factor.\n                Concise Justification: Combining a regime precondition (compression) with a trigger (controlled expansion breakout) and a post-trigger quality confirmation (clean trend + overnight-dominant drift) targets situations where price discovery transitions from equilibrium to informed repricing, while the tail-cap on expansion reduces the common breakout-strategy weakness of chasing exhausted gaps that increase drawdowns.\n                Concise Knowledge: If volatility/range compresses for a long window, latent order-imbalance can accumulate; when the first expansion breakout is confirmed by strong close-location (close near high/low) and the following short-window path has high linear-trend fit with returns coming primarily from overnight gaps (proxy for informed repricing), then continuation is more likely than reversal; when expansion is extremely large (tail event), continuation becomes less stable so capping/excluding the most extreme expansion improves robustness.\n                concise Specification: Use only daily_pv.h5 OHLCV: define compression_depth as rank(low) of 20D realized vol (std of log returns) or 20D avg true range versus a 60D history (e.g., bottom 20%); define expansion_strength as 1D true-range z-score vs past 60D, but exclude/cap top 1% to avoid tails; define breakout_direction via CLV=(2*close-high-low)/(high-low) and/or (close-open)/open; define trend_quality on last 10D as R² of linear regression of log(close) on time and residual volatility penalty; define overnight_dominance as |sum(log(open_t/close_{t-1}))| / (|sum(log(close_t/close_{t-1}))|+eps) over 10D; final factor = sign(breakout_direction)*sign(sum_overnight_10D) * compression_depth * clipped(expansion_strength) * trend_quality * overnight_dominance, computed cross-sectionally per day with fixed windows (20,60,10) and explicit eps/clipping thresholds for stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T18:04:49.192846"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0855530955018066,
        "ICIR": 0.0347834624845055,
        "1day.excess_return_without_cost.std": 0.0041367365392047,
        "1day.excess_return_with_cost.annualized_return": 0.031898853727355,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302037186339,
        "1day.excess_return_without_cost.annualized_return": 0.0785884850348917,
        "1day.excess_return_with_cost.std": 0.0041369368828074,
        "Rank IC": 0.0200703153301638,
        "IC": 0.0046179876754496,
        "1day.excess_return_without_cost.max_drawdown": -0.0783059190366319,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.231438070690706,
        "1day.pa": 0.0,
        "l2.valid": 0.9967316431147404,
        "Rank ICIR": 0.1513647968944023,
        "l2.train": 0.9932070117727992,
        "1day.excess_return_with_cost.information_ratio": 0.499813179385166,
        "1day.excess_return_with_cost.mean": 0.0001340287971737
      },
      "feedback": {
        "observations": "Compared with SOTA, the combined factor set improved portfolio-level performance but weakened linear predictiveness. Annualized return increased from 0.0520 to 0.0786 (better) and information ratio increased from 0.9726 to 1.2314 (better). However, max drawdown deteriorated (from -0.0726 to -0.0783; worse), and IC declined (0.00580 → 0.00462; worse). This pattern suggests the signal may be exploiting non-linear payoffs / conditional regimes (good realized returns/IR) but with weaker unconditional linear correlation to next-day returns (lower IC).",
        "hypothesis_evaluation": "Overall the results are directionally supportive of the hypothesis’ core idea (compression + breakout direction + continuation-quality improves forward returns), because the strategy-level outcomes (annualized return and IR) improved meaningfully. However, the hypothesis is only partially validated because:\n1) The drop in IC indicates the effect may be episodic/conditional rather than broadly monotonic day-to-day.\n2) The worse max drawdown suggests the “cap extreme expansion tails to reduce drawdown clustering” is not fully achieved by the current cap (clip at 3, floor at 0) and/or the breakout trigger still admits adverse regimes.\n3) The ‘post-breakout subsequent ~10D path’ part is tricky: your current OvernightDominant_TrendCleanliness_10D is only valid if it is computed strictly from information available up to the prediction time. If the intended design is ‘after breakout, wait ~10D to assess cleanliness’, then using it to predict next 1–5D returns creates a timing mismatch unless you explicitly delay the trading decision (or re-index the event so that the 10D window is in the past relative to the prediction date).",
        "decision": true,
        "reason": "To stay within the same theoretical framework while addressing observed issues:\n- **Why IC fell but returns rose**: the current construction likely produces a sparse/conditional signal (works strongly in select regimes) that boosts realized PnL/IR, but the average linear correlation across all days is weaker. Making the continuation-quality component more tightly aligned to the 1–5D forecast window should increase IC.\n- **Timing alignment (critical check)**: If ODTQ_10 is meant to measure ‘subsequent’ behavior after a breakout, you must implement it as an event-driven feature available at time t (e.g., breakout at t-6, measure follow-through from t-5..t-1, predict t..t+4), or shorten it to be fully backward-looking relative to the prediction date.\n- **Concrete within-framework iterations (explicit hyperparameters):**\n  1) Vol compression depth variants:\n     - Keep definition but test (lookback_vol, rank_window): (10,60), (20,120), (30,120) instead of only (20,60).\n     - Alternative compression measure within same concept: use range-based vol (e.g., std of log(high/low)) with the same TS_RANK window.\n  2) Breakout expansion cap sensitivity:\n     - Current: Z_60(high-low) clipped to [0,3]. Test z-window {40, 60, 120}, cap {2, 2.5, 3, 4}, and also a *soft cap* (e.g., cap via tanh) to reduce tail leverage without hard truncation.\n     - Direction component: replace SIGN(CLV) with SIGN(close-open) or SIGN((close-open)/(high-low)) to better match “body direction”; or combine CLV and body with a single sign: SIGN(0.5*CLV + 0.5*(close-open)/(high-low+eps)).\n  3) Overnight dominance / trend cleanliness made forecast-horizon consistent:\n     - Current ODTQ uses 10D. Test n={3,5,7,10}. For next-1~5D prediction, n=3–7 is more aligned.\n     - Decompose overnight vs intraday explicitly (same data, clearer):\n       * overnight_sum_n = SUM(log(open/DELAY(close,1)), n)\n       * intraday_sum_n = SUM(log(close/open), n)\n       * dominance = |overnight_sum_n| / (|overnight_sum_n| + |intraday_sum_n| + eps)\n       Then apply SIGN(overnight_sum_n) * dominance.\n     - Trend cleanliness: use R^2-like metric instead of 1 - std(resid)/std(logC) to stabilize scaling; still keep n small (3–10).\n  4) Drawdown control within the same hypothesis (no new data):\n     - Add a volatility-scaled position size proxy (e.g., divide breakout score by TS_STD(return,20)+eps) to reduce exposure when volatility spikes right after breakout.\n     - Add a “no-chase” filter: require expansion z-score to be in a mid-band (e.g., between 0.5 and cap), not just >0, to avoid weak/noisy breakouts and reduce tail-risk clustering.\n- **Complexity control**: current factors are relatively simple (few base features: open/close/high/low; no obvious parameter explosion). Keep the next iteration focused on 1–2 parameter changes at a time (window/cap/sign) rather than combining many new transforms into one long expression."
      }
    },
    "783cf4aabb58d0fb": {
      "factor_id": "783cf4aabb58d0fb",
      "factor_name": "OvernightDominant_TrendCleanliness_10D",
      "factor_expression": "SIGN(TS_SUM(LOG($open/(DELAY($close,1)+1e-8)),10))*(ABS(TS_SUM(LOG($open/(DELAY($close,1)+1e-8)),10))/(ABS(TS_SUM(LOG($close/(DELAY($close,1)+1e-8)),10))+1e-8))*(1-TS_STD(REGRESI(LOG($close),SEQUENCE(10),10),10)/(TS_STD(LOG($close),10)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_SUM(LOG($open/(DELAY($close,1)+1e-8)),10))*(ABS(TS_SUM(LOG($open/(DELAY($close,1)+1e-8)),10))/(ABS(TS_SUM(LOG($close/(DELAY($close,1)+1e-8)),10))+1e-8))*(1-TS_STD(REGRESI(LOG($close),SEQUENCE(10),10),10)/(TS_STD(LOG($close),10)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"OvernightDominant_TrendCleanliness_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Post-breakout continuation quality proxy: multiplies (i) the sign and dominance of cumulative overnight gaps (prev close→open) relative to total close→close log move over 10D, by (ii) a trend-cleanliness score based on low regression residual volatility of log(close) vs time over 10D.",
      "factor_formulation": "\\mathrm{ODTQ}_{10}=\\mathrm{SIGN}(S_o)\\cdot\\frac{|S_o|}{|S_c|+\\epsilon}\\cdot\\left(1-\\frac{\\sigma_{10}(\\varepsilon)}{\\sigma_{10}(\\log C)+\\epsilon}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "66a07d67dd3d",
        "parent_trajectory_ids": [
          "d8d61e5e8145",
          "ca115a2f9009"
        ],
        "hypothesis": "Hypothesis: Quiet-to-gap-led trend ignition continuation: Next-1~5D returns are higher when (i) a stock is in a deep 60D volatility/range compression regime, (ii) a non-extreme 1D expansion ‘breakout’ occurs with strong close-location/body direction, and (iii) the subsequent ~10D price path exhibits a statistically clean linear up/down trend whose cumulative return is dominated by overnight gaps (prev close→open) rather than intraday mean-reversion, with the forecast direction set by breakout-day CLV/body sign and reinforced by the sign of cumulative overnight return; the prediction strength scales multiplicatively with compression depth × expansion strength × trend-fit quality × overnight-dominance while explicitly capping extreme expansion tails to reduce drawdown clustering.\n                Concise Observation: The available OHLCV daily data enables (a) compression depth via rolling realized volatility/range ranks, (b) breakout expansion via 1D true-range/ATR z-scores with tail caps, (c) trend cleanliness via 10D log-price regression R²/residual volatility, and (d) overnight dominance via the ratio of cumulative close-to-open gaps to total close-to-close move—making the proposed multi-stage regime-change + quality filter directly testable as a single multiplicative factor.\n                Concise Justification: Combining a regime precondition (compression) with a trigger (controlled expansion breakout) and a post-trigger quality confirmation (clean trend + overnight-dominant drift) targets situations where price discovery transitions from equilibrium to informed repricing, while the tail-cap on expansion reduces the common breakout-strategy weakness of chasing exhausted gaps that increase drawdowns.\n                Concise Knowledge: If volatility/range compresses for a long window, latent order-imbalance can accumulate; when the first expansion breakout is confirmed by strong close-location (close near high/low) and the following short-window path has high linear-trend fit with returns coming primarily from overnight gaps (proxy for informed repricing), then continuation is more likely than reversal; when expansion is extremely large (tail event), continuation becomes less stable so capping/excluding the most extreme expansion improves robustness.\n                concise Specification: Use only daily_pv.h5 OHLCV: define compression_depth as rank(low) of 20D realized vol (std of log returns) or 20D avg true range versus a 60D history (e.g., bottom 20%); define expansion_strength as 1D true-range z-score vs past 60D, but exclude/cap top 1% to avoid tails; define breakout_direction via CLV=(2*close-high-low)/(high-low) and/or (close-open)/open; define trend_quality on last 10D as R² of linear regression of log(close) on time and residual volatility penalty; define overnight_dominance as |sum(log(open_t/close_{t-1}))| / (|sum(log(close_t/close_{t-1}))|+eps) over 10D; final factor = sign(breakout_direction)*sign(sum_overnight_10D) * compression_depth * clipped(expansion_strength) * trend_quality * overnight_dominance, computed cross-sectionally per day with fixed windows (20,60,10) and explicit eps/clipping thresholds for stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T18:04:49.192846"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0855530955018066,
        "ICIR": 0.0347834624845055,
        "1day.excess_return_without_cost.std": 0.0041367365392047,
        "1day.excess_return_with_cost.annualized_return": 0.031898853727355,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302037186339,
        "1day.excess_return_without_cost.annualized_return": 0.0785884850348917,
        "1day.excess_return_with_cost.std": 0.0041369368828074,
        "Rank IC": 0.0200703153301638,
        "IC": 0.0046179876754496,
        "1day.excess_return_without_cost.max_drawdown": -0.0783059190366319,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.231438070690706,
        "1day.pa": 0.0,
        "l2.valid": 0.9967316431147404,
        "Rank ICIR": 0.1513647968944023,
        "l2.train": 0.9932070117727992,
        "1day.excess_return_with_cost.information_ratio": 0.499813179385166,
        "1day.excess_return_with_cost.mean": 0.0001340287971737
      },
      "feedback": {
        "observations": "Compared with SOTA, the combined factor set improved portfolio-level performance but weakened linear predictiveness. Annualized return increased from 0.0520 to 0.0786 (better) and information ratio increased from 0.9726 to 1.2314 (better). However, max drawdown deteriorated (from -0.0726 to -0.0783; worse), and IC declined (0.00580 → 0.00462; worse). This pattern suggests the signal may be exploiting non-linear payoffs / conditional regimes (good realized returns/IR) but with weaker unconditional linear correlation to next-day returns (lower IC).",
        "hypothesis_evaluation": "Overall the results are directionally supportive of the hypothesis’ core idea (compression + breakout direction + continuation-quality improves forward returns), because the strategy-level outcomes (annualized return and IR) improved meaningfully. However, the hypothesis is only partially validated because:\n1) The drop in IC indicates the effect may be episodic/conditional rather than broadly monotonic day-to-day.\n2) The worse max drawdown suggests the “cap extreme expansion tails to reduce drawdown clustering” is not fully achieved by the current cap (clip at 3, floor at 0) and/or the breakout trigger still admits adverse regimes.\n3) The ‘post-breakout subsequent ~10D path’ part is tricky: your current OvernightDominant_TrendCleanliness_10D is only valid if it is computed strictly from information available up to the prediction time. If the intended design is ‘after breakout, wait ~10D to assess cleanliness’, then using it to predict next 1–5D returns creates a timing mismatch unless you explicitly delay the trading decision (or re-index the event so that the 10D window is in the past relative to the prediction date).",
        "decision": true,
        "reason": "To stay within the same theoretical framework while addressing observed issues:\n- **Why IC fell but returns rose**: the current construction likely produces a sparse/conditional signal (works strongly in select regimes) that boosts realized PnL/IR, but the average linear correlation across all days is weaker. Making the continuation-quality component more tightly aligned to the 1–5D forecast window should increase IC.\n- **Timing alignment (critical check)**: If ODTQ_10 is meant to measure ‘subsequent’ behavior after a breakout, you must implement it as an event-driven feature available at time t (e.g., breakout at t-6, measure follow-through from t-5..t-1, predict t..t+4), or shorten it to be fully backward-looking relative to the prediction date.\n- **Concrete within-framework iterations (explicit hyperparameters):**\n  1) Vol compression depth variants:\n     - Keep definition but test (lookback_vol, rank_window): (10,60), (20,120), (30,120) instead of only (20,60).\n     - Alternative compression measure within same concept: use range-based vol (e.g., std of log(high/low)) with the same TS_RANK window.\n  2) Breakout expansion cap sensitivity:\n     - Current: Z_60(high-low) clipped to [0,3]. Test z-window {40, 60, 120}, cap {2, 2.5, 3, 4}, and also a *soft cap* (e.g., cap via tanh) to reduce tail leverage without hard truncation.\n     - Direction component: replace SIGN(CLV) with SIGN(close-open) or SIGN((close-open)/(high-low)) to better match “body direction”; or combine CLV and body with a single sign: SIGN(0.5*CLV + 0.5*(close-open)/(high-low+eps)).\n  3) Overnight dominance / trend cleanliness made forecast-horizon consistent:\n     - Current ODTQ uses 10D. Test n={3,5,7,10}. For next-1~5D prediction, n=3–7 is more aligned.\n     - Decompose overnight vs intraday explicitly (same data, clearer):\n       * overnight_sum_n = SUM(log(open/DELAY(close,1)), n)\n       * intraday_sum_n = SUM(log(close/open), n)\n       * dominance = |overnight_sum_n| / (|overnight_sum_n| + |intraday_sum_n| + eps)\n       Then apply SIGN(overnight_sum_n) * dominance.\n     - Trend cleanliness: use R^2-like metric instead of 1 - std(resid)/std(logC) to stabilize scaling; still keep n small (3–10).\n  4) Drawdown control within the same hypothesis (no new data):\n     - Add a volatility-scaled position size proxy (e.g., divide breakout score by TS_STD(return,20)+eps) to reduce exposure when volatility spikes right after breakout.\n     - Add a “no-chase” filter: require expansion z-score to be in a mid-band (e.g., between 0.5 and cap), not just >0, to avoid weak/noisy breakouts and reduce tail-risk clustering.\n- **Complexity control**: current factors are relatively simple (few base features: open/close/high/low; no obvious parameter explosion). Keep the next iteration focused on 1–2 parameter changes at a time (window/cap/sign) rather than combining many new transforms into one long expression."
      }
    },
    "b0304298c39b4aad": {
      "factor_id": "b0304298c39b4aad",
      "factor_name": "LiquidityVacuum_Contrarian_20D",
      "factor_expression": "-SIGN($return) * RANK(TS_ZSCORE(ABS($return),20) + TS_ZSCORE(LOG($high/$low),20)) * RANK(-TS_ZSCORE(LOG($volume+1),20)) * RANK(TS_ZSCORE(ABS($return)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1)) * RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1)),20) + TS_ZSCORE(LOG($high/$low),20)) * RANK(-TS_ZSCORE(LOG($volume+1),20)) * RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($close*$volume+1),20))\" # Your output factor expression will be filled in here\n    name = \"LiquidityVacuum_Contrarian_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian liquidity-vacuum mean reversion signal: a large daily move (return and range) occurring with low participation (low volume) and a spike in Amihud-style illiquidity is more likely to reverse over the next 1–5 days.",
      "factor_formulation": "F_t=-\\operatorname{sign}(r_t)\\cdot \\operatorname{rank}\\Big(Z_{20}(|r_t|)+Z_{20}(\\ln(\\tfrac{H_t}{L_t}))\\Big)\\cdot \\operatorname{rank}\\Big(-Z_{20}(\\ln(V_t+1))\\Big)\\cdot \\operatorname{rank}\\Big(Z_{20}(\\tfrac{|r_t|}{C_tV_t+\\varepsilon})\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ebb8d0d5ab65",
        "parent_trajectory_ids": [
          "2e54befa5567"
        ],
        "hypothesis": "Hypothesis: Liquidity-vacuum mean reversion: when an instrument experiences an abnormally large daily move (|close-to-close return| and/or high-low range) while contemporaneous participation is abnormally low (low volume and low dollar-volume), causing a spike in estimated price impact (Amihud-style illiquidity), the move is more likely transitory and will partially reverse over the next 1–5 trading days; therefore a contrarian signal proportional to (large-move intensity × illiquidity spike × low-participation) and signed opposite to today’s return should predict next-1/3/5D returns.\n                Concise Observation: The available data is daily OHLCV only, so price-impact/participation proxies (|r|, log(high/low), volume, close·volume) and their rolling z-scores/ranks are directly computable, and this liquidity-scarcity contrarian mechanism is orthogonal to the parent strategy’s high-volume shock + clean-trend continuation + wick/rejection anatomy.\n                Concise Justification: In thin-liquidity sessions, order-book depth is lower and mechanical flow imbalance can move prices disproportionately (high estimated impact per unit volume); because such moves are less likely to reflect broad-information repricing, subsequent days with normalized participation should exhibit partial retracement, creating a testable short-horizon mean-reversion edge.\n                Concise Knowledge: If a large price change occurs under low participation, then marginal trades have higher price impact and the move is more likely driven by temporary liquidity scarcity than durable information; when liquidity normalizes, prices tend to revert toward the pre-move level, so a contrarian predictor should strengthen with higher |r_t|, higher range, higher |r_t|/(close_t·volume_t), and lower volume/dollar-volume relative to their 20–60D baselines.\n                concise Specification: Construct a daily factor using only daily_pv.h5 OHLCV with fixed hyperparameters: large-move component = Z20(|log(close_t/close_{t-1})|) and/or Z20(log(high_t/low_t)); participation component = −Z20(log(volume_t+1)) and −Z20(log(close_t·volume_t+1)); illiquidity component = Z20(|log(close_t/close_{t-1})|/(close_t·volume_t+1e-8)) (optionally also range-impact = Z20(log(high_t/low_t)/(close_t·volume_t+1e-8))); combine multiplicatively or additively then apply contrarian sign = −sign(log(close_t/close_{t-1}))·Rank(large_move+range)·Rank(low_participation)·Rank(illiquidity), with the intended tested target being next-1/3/5D return reversal strongest when participation z-scores < −1 and move z-scores > +1.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-21T18:15:43.960994"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739729433149265,
        "ICIR": 0.0563013355127636,
        "1day.excess_return_without_cost.std": 0.0042677682868853,
        "1day.excess_return_with_cost.annualized_return": 0.0391481721273005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003626491188995,
        "1day.excess_return_without_cost.annualized_return": 0.0863104902981027,
        "1day.excess_return_with_cost.std": 0.0042697635230861,
        "Rank IC": 0.0225197548973739,
        "IC": 0.007798313907826,
        "1day.excess_return_without_cost.max_drawdown": -0.0607287911837116,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3109142163309362,
        "1day.pa": 0.0,
        "l2.valid": 0.996546277707308,
        "Rank ICIR": 0.1662510337361869,
        "l2.train": 0.9938212943848126,
        "1day.excess_return_with_cost.information_ratio": 0.5943184161364468,
        "1day.excess_return_with_cost.mean": 0.0001644881181819
      },
      "feedback": {
        "observations": "The combined Liquidity-Vacuum contrarian factor set shows consistent improvements versus SOTA across all reported metrics: (i) max drawdown improves from -0.0726 to -0.0607 (smaller drawdown is better), (ii) information ratio rises from 0.9726 to 1.3109, (iii) annualized return rises from 0.0520 to 0.0863, and (iv) IC rises from 0.0058 to 0.0078. The improvements are directionally aligned (better return, better risk-adjusted return, better IC, and smaller drawdown), suggesting the signal is not a metric-specific artifact.\n\nFactor-design-wise, the three implementations appear to be coherent variants of the same mechanism: large move intensity (|return| and/or range), low participation (volume or dollar volume), and illiquidity/price impact spike (Amihud-style |r|/(dollar volume)). Using cross-sectional ranks after time-series normalization is a reasonable way to stabilize heavy tails and regime shifts. No explicit complexity warnings were provided; symbol length and feature count look moderate (mainly close/high/low/volume).",
        "hypothesis_evaluation": "Supported. The hypothesis predicts short-horizon mean reversion after large moves that occur with thin liquidity/participation. The observed improvements in IC and 1-day excess performance metrics are consistent with that contrarian reversal mechanism working in aggregate. Importantly, the drawdown improvement alongside higher annualized return suggests the signal is not merely increasing exposure/variance; it is improving the return/risk profile.\n\nCompared to SOTA, this experiment is a clear step forward. Since annualized return improves (0.0863 vs 0.0520) and at least one other metric also improves (in fact all do), this satisfies the replacement rule.\n\nHyperparameters explicitly present in the tested factors (for further sensitivity sweeps):\n- Lookback / baseline windows: 20D (LiquidityVacuum_Contrarian_20D), 40D (DollarVolumeSparse_Impact_Contrarian_40D), 60D (RangeImpact_LowVol_Contrarian_60D)\n- Transform/normalization choices: TS_ZSCORE window n ∈ {20,40,60}; TS_RANK window n = 40; cross-sectional RANK applied daily; LOG with LOG(x+1)\n- Illiquidity epsilon: ε in |r|/(C*V + ε) and range/(C*V + ε) (value not specified; should be fixed and documented)\n- Move definition choices: |r_t| vs log(H/L) vs combination (|r| + range term)\n\nKey refinement need (next iteration): quantify turnover and cost sensitivity. “Without cost” metrics can look strong for contrarian signals that trade frequently; if turnover is high, live performance may degrade. Add explicit controls that reduce churn while keeping the same liquidity-vacuum concept.",
        "decision": true,
        "reason": "Your current framework mixes (large move) × (low participation) × (price impact) with ranks/z-scores, which is directionally correct. Two common failure modes remain within the same theoretical framework:\n1) False positives during high-volatility regimes: |r| can be large simply because volatility is high; reversal is weaker when the move is not an outlier relative to recent realized vol.\n2) Participation measures can be noisy across names and regimes: volume or dollar volume should be judged relative to its own history (e.g., ADV) and/or matched to volatility regimes.\n\nConcrete within-hypothesis improvements to explore (keep factors simple; create separate factors for each parameter choice):\n- Volatility-adjusted move outlier (new hyperparameters: vol window m): use |r_t| / (TS_STD(r, m) + 1e-12) then TS_ZSCORE over n. Try m ∈ {10,20} with n ∈ {20,40}.\n- Participation squeeze relative to ADV (new hyperparameters: ADV window k): use log(V_t+1) - log(TS_MEAN(V, k)+1) or Z_k(log(V+1)); try k ∈ {20,60}. This keeps the same “low participation” concept but makes it instrument-regime aware.\n- Replace multiplicative ranks with a clipped additive score to reduce extreme-product instability (same concept, simpler behavior): Score = -sign(r_t) * (w1*rank(move) + w2*rank(illiquidity) + w3*rank(low_participation)), with fixed weights (e.g., equal weights). This often improves generalization vs triple-products.\n- Event-gating (reduces turnover): only activate when move intensity is in the top q percentile cross-sectionally AND participation is in bottom q percentile (hyperparameter q ∈ {5%,10%,20%}). Outside the gate, factor=0.\n- Window sweep around your current best: keep structure identical and test n ∈ {15,20,30,40,60}; do not mix windows inside a single factor to avoid overfitting.\n\nAlso recommended reporting in the next run: turnover, performance with simple cost assumptions, and stability by market-cap/ADV buckets (the hypothesis implies stronger effects in less liquid names)."
      }
    },
    "21bee40a40b6e29b": {
      "factor_id": "21bee40a40b6e29b",
      "factor_name": "DollarVolumeSparse_Impact_Contrarian_40D",
      "factor_expression": "-SIGN($return) * RANK(TS_RANK(ABS($return),40)) * RANK(-TS_ZSCORE(LOG($close*$volume+1),40)) * RANK(TS_ZSCORE(ABS($return)/($close*$volume+1e-8),40))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1)) * RANK(TS_RANK(ABS(TS_PCTCHANGE($close,1)),40)) * RANK(-TS_ZSCORE(LOG($close*$volume+1),40)) * RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($close*$volume+0.00000001),40))\" # Your output factor expression will be filled in here\n    name = \"DollarVolumeSparse_Impact_Contrarian_40D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian signal emphasizing low dollar-volume participation: large-move intensity (time-series rank) combined with abnormally low dollar volume and elevated Amihud illiquidity over a 40-day baseline.",
      "factor_formulation": "F_t=-\\operatorname{sign}(r_t)\\cdot \\operatorname{rank}(\\operatorname{TS\\_RANK}_{40}(|r_t|))\\cdot \\operatorname{rank}\\Big(-Z_{40}(\\ln(C_tV_t+1))\\Big)\\cdot \\operatorname{rank}\\Big(Z_{40}(\\tfrac{|r_t|}{C_tV_t+\\varepsilon})\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ebb8d0d5ab65",
        "parent_trajectory_ids": [
          "2e54befa5567"
        ],
        "hypothesis": "Hypothesis: Liquidity-vacuum mean reversion: when an instrument experiences an abnormally large daily move (|close-to-close return| and/or high-low range) while contemporaneous participation is abnormally low (low volume and low dollar-volume), causing a spike in estimated price impact (Amihud-style illiquidity), the move is more likely transitory and will partially reverse over the next 1–5 trading days; therefore a contrarian signal proportional to (large-move intensity × illiquidity spike × low-participation) and signed opposite to today’s return should predict next-1/3/5D returns.\n                Concise Observation: The available data is daily OHLCV only, so price-impact/participation proxies (|r|, log(high/low), volume, close·volume) and their rolling z-scores/ranks are directly computable, and this liquidity-scarcity contrarian mechanism is orthogonal to the parent strategy’s high-volume shock + clean-trend continuation + wick/rejection anatomy.\n                Concise Justification: In thin-liquidity sessions, order-book depth is lower and mechanical flow imbalance can move prices disproportionately (high estimated impact per unit volume); because such moves are less likely to reflect broad-information repricing, subsequent days with normalized participation should exhibit partial retracement, creating a testable short-horizon mean-reversion edge.\n                Concise Knowledge: If a large price change occurs under low participation, then marginal trades have higher price impact and the move is more likely driven by temporary liquidity scarcity than durable information; when liquidity normalizes, prices tend to revert toward the pre-move level, so a contrarian predictor should strengthen with higher |r_t|, higher range, higher |r_t|/(close_t·volume_t), and lower volume/dollar-volume relative to their 20–60D baselines.\n                concise Specification: Construct a daily factor using only daily_pv.h5 OHLCV with fixed hyperparameters: large-move component = Z20(|log(close_t/close_{t-1})|) and/or Z20(log(high_t/low_t)); participation component = −Z20(log(volume_t+1)) and −Z20(log(close_t·volume_t+1)); illiquidity component = Z20(|log(close_t/close_{t-1})|/(close_t·volume_t+1e-8)) (optionally also range-impact = Z20(log(high_t/low_t)/(close_t·volume_t+1e-8))); combine multiplicatively or additively then apply contrarian sign = −sign(log(close_t/close_{t-1}))·Rank(large_move+range)·Rank(low_participation)·Rank(illiquidity), with the intended tested target being next-1/3/5D return reversal strongest when participation z-scores < −1 and move z-scores > +1.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-21T18:15:43.960994"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739729433149265,
        "ICIR": 0.0563013355127636,
        "1day.excess_return_without_cost.std": 0.0042677682868853,
        "1day.excess_return_with_cost.annualized_return": 0.0391481721273005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003626491188995,
        "1day.excess_return_without_cost.annualized_return": 0.0863104902981027,
        "1day.excess_return_with_cost.std": 0.0042697635230861,
        "Rank IC": 0.0225197548973739,
        "IC": 0.007798313907826,
        "1day.excess_return_without_cost.max_drawdown": -0.0607287911837116,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3109142163309362,
        "1day.pa": 0.0,
        "l2.valid": 0.996546277707308,
        "Rank ICIR": 0.1662510337361869,
        "l2.train": 0.9938212943848126,
        "1day.excess_return_with_cost.information_ratio": 0.5943184161364468,
        "1day.excess_return_with_cost.mean": 0.0001644881181819
      },
      "feedback": {
        "observations": "The combined Liquidity-Vacuum contrarian factor set shows consistent improvements versus SOTA across all reported metrics: (i) max drawdown improves from -0.0726 to -0.0607 (smaller drawdown is better), (ii) information ratio rises from 0.9726 to 1.3109, (iii) annualized return rises from 0.0520 to 0.0863, and (iv) IC rises from 0.0058 to 0.0078. The improvements are directionally aligned (better return, better risk-adjusted return, better IC, and smaller drawdown), suggesting the signal is not a metric-specific artifact.\n\nFactor-design-wise, the three implementations appear to be coherent variants of the same mechanism: large move intensity (|return| and/or range), low participation (volume or dollar volume), and illiquidity/price impact spike (Amihud-style |r|/(dollar volume)). Using cross-sectional ranks after time-series normalization is a reasonable way to stabilize heavy tails and regime shifts. No explicit complexity warnings were provided; symbol length and feature count look moderate (mainly close/high/low/volume).",
        "hypothesis_evaluation": "Supported. The hypothesis predicts short-horizon mean reversion after large moves that occur with thin liquidity/participation. The observed improvements in IC and 1-day excess performance metrics are consistent with that contrarian reversal mechanism working in aggregate. Importantly, the drawdown improvement alongside higher annualized return suggests the signal is not merely increasing exposure/variance; it is improving the return/risk profile.\n\nCompared to SOTA, this experiment is a clear step forward. Since annualized return improves (0.0863 vs 0.0520) and at least one other metric also improves (in fact all do), this satisfies the replacement rule.\n\nHyperparameters explicitly present in the tested factors (for further sensitivity sweeps):\n- Lookback / baseline windows: 20D (LiquidityVacuum_Contrarian_20D), 40D (DollarVolumeSparse_Impact_Contrarian_40D), 60D (RangeImpact_LowVol_Contrarian_60D)\n- Transform/normalization choices: TS_ZSCORE window n ∈ {20,40,60}; TS_RANK window n = 40; cross-sectional RANK applied daily; LOG with LOG(x+1)\n- Illiquidity epsilon: ε in |r|/(C*V + ε) and range/(C*V + ε) (value not specified; should be fixed and documented)\n- Move definition choices: |r_t| vs log(H/L) vs combination (|r| + range term)\n\nKey refinement need (next iteration): quantify turnover and cost sensitivity. “Without cost” metrics can look strong for contrarian signals that trade frequently; if turnover is high, live performance may degrade. Add explicit controls that reduce churn while keeping the same liquidity-vacuum concept.",
        "decision": true,
        "reason": "Your current framework mixes (large move) × (low participation) × (price impact) with ranks/z-scores, which is directionally correct. Two common failure modes remain within the same theoretical framework:\n1) False positives during high-volatility regimes: |r| can be large simply because volatility is high; reversal is weaker when the move is not an outlier relative to recent realized vol.\n2) Participation measures can be noisy across names and regimes: volume or dollar volume should be judged relative to its own history (e.g., ADV) and/or matched to volatility regimes.\n\nConcrete within-hypothesis improvements to explore (keep factors simple; create separate factors for each parameter choice):\n- Volatility-adjusted move outlier (new hyperparameters: vol window m): use |r_t| / (TS_STD(r, m) + 1e-12) then TS_ZSCORE over n. Try m ∈ {10,20} with n ∈ {20,40}.\n- Participation squeeze relative to ADV (new hyperparameters: ADV window k): use log(V_t+1) - log(TS_MEAN(V, k)+1) or Z_k(log(V+1)); try k ∈ {20,60}. This keeps the same “low participation” concept but makes it instrument-regime aware.\n- Replace multiplicative ranks with a clipped additive score to reduce extreme-product instability (same concept, simpler behavior): Score = -sign(r_t) * (w1*rank(move) + w2*rank(illiquidity) + w3*rank(low_participation)), with fixed weights (e.g., equal weights). This often improves generalization vs triple-products.\n- Event-gating (reduces turnover): only activate when move intensity is in the top q percentile cross-sectionally AND participation is in bottom q percentile (hyperparameter q ∈ {5%,10%,20%}). Outside the gate, factor=0.\n- Window sweep around your current best: keep structure identical and test n ∈ {15,20,30,40,60}; do not mix windows inside a single factor to avoid overfitting.\n\nAlso recommended reporting in the next run: turnover, performance with simple cost assumptions, and stability by market-cap/ADV buckets (the hypothesis implies stronger effects in less liquid names)."
      }
    },
    "f44a74dfac86592d": {
      "factor_id": "f44a74dfac86592d",
      "factor_name": "RangeImpact_LowVol_Contrarian_60D",
      "factor_expression": "-SIGN($return) * RANK(TS_ZSCORE(LOG($high/$low),60)) * RANK(-TS_ZSCORE(LOG($volume+1),60)) * RANK(TS_ZSCORE(LOG($high/$low)/($close*$volume+1e-8),60))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1)) * RANK(TS_ZSCORE(LOG($high/$low),60)) * RANK(-TS_ZSCORE(LOG($volume+1),60)) * RANK(TS_ZSCORE(LOG($high/$low)/($close*$volume+0.00000001),60))\" # Your output factor expression will be filled in here\n    name = \"RangeImpact_LowVol_Contrarian_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity-vacuum contrarian using range-based price impact: abnormally wide intraday range together with low volume and high range-per-dollar-volume impact (proxying thin liquidity) tends to mean revert over the next several days.",
      "factor_formulation": "F_t=-\\operatorname{sign}(r_t)\\cdot \\operatorname{rank}\\Big(Z_{60}(\\ln(\\tfrac{H_t}{L_t}))\\Big)\\cdot \\operatorname{rank}\\Big(-Z_{60}(\\ln(V_t+1))\\Big)\\cdot \\operatorname{rank}\\Big(Z_{60}(\\tfrac{\\ln(H_t/L_t)}{C_tV_t+\\varepsilon})\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ebb8d0d5ab65",
        "parent_trajectory_ids": [
          "2e54befa5567"
        ],
        "hypothesis": "Hypothesis: Liquidity-vacuum mean reversion: when an instrument experiences an abnormally large daily move (|close-to-close return| and/or high-low range) while contemporaneous participation is abnormally low (low volume and low dollar-volume), causing a spike in estimated price impact (Amihud-style illiquidity), the move is more likely transitory and will partially reverse over the next 1–5 trading days; therefore a contrarian signal proportional to (large-move intensity × illiquidity spike × low-participation) and signed opposite to today’s return should predict next-1/3/5D returns.\n                Concise Observation: The available data is daily OHLCV only, so price-impact/participation proxies (|r|, log(high/low), volume, close·volume) and their rolling z-scores/ranks are directly computable, and this liquidity-scarcity contrarian mechanism is orthogonal to the parent strategy’s high-volume shock + clean-trend continuation + wick/rejection anatomy.\n                Concise Justification: In thin-liquidity sessions, order-book depth is lower and mechanical flow imbalance can move prices disproportionately (high estimated impact per unit volume); because such moves are less likely to reflect broad-information repricing, subsequent days with normalized participation should exhibit partial retracement, creating a testable short-horizon mean-reversion edge.\n                Concise Knowledge: If a large price change occurs under low participation, then marginal trades have higher price impact and the move is more likely driven by temporary liquidity scarcity than durable information; when liquidity normalizes, prices tend to revert toward the pre-move level, so a contrarian predictor should strengthen with higher |r_t|, higher range, higher |r_t|/(close_t·volume_t), and lower volume/dollar-volume relative to their 20–60D baselines.\n                concise Specification: Construct a daily factor using only daily_pv.h5 OHLCV with fixed hyperparameters: large-move component = Z20(|log(close_t/close_{t-1})|) and/or Z20(log(high_t/low_t)); participation component = −Z20(log(volume_t+1)) and −Z20(log(close_t·volume_t+1)); illiquidity component = Z20(|log(close_t/close_{t-1})|/(close_t·volume_t+1e-8)) (optionally also range-impact = Z20(log(high_t/low_t)/(close_t·volume_t+1e-8))); combine multiplicatively or additively then apply contrarian sign = −sign(log(close_t/close_{t-1}))·Rank(large_move+range)·Rank(low_participation)·Rank(illiquidity), with the intended tested target being next-1/3/5D return reversal strongest when participation z-scores < −1 and move z-scores > +1.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-21T18:15:43.960994"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739729433149265,
        "ICIR": 0.0563013355127636,
        "1day.excess_return_without_cost.std": 0.0042677682868853,
        "1day.excess_return_with_cost.annualized_return": 0.0391481721273005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003626491188995,
        "1day.excess_return_without_cost.annualized_return": 0.0863104902981027,
        "1day.excess_return_with_cost.std": 0.0042697635230861,
        "Rank IC": 0.0225197548973739,
        "IC": 0.007798313907826,
        "1day.excess_return_without_cost.max_drawdown": -0.0607287911837116,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3109142163309362,
        "1day.pa": 0.0,
        "l2.valid": 0.996546277707308,
        "Rank ICIR": 0.1662510337361869,
        "l2.train": 0.9938212943848126,
        "1day.excess_return_with_cost.information_ratio": 0.5943184161364468,
        "1day.excess_return_with_cost.mean": 0.0001644881181819
      },
      "feedback": {
        "observations": "The combined Liquidity-Vacuum contrarian factor set shows consistent improvements versus SOTA across all reported metrics: (i) max drawdown improves from -0.0726 to -0.0607 (smaller drawdown is better), (ii) information ratio rises from 0.9726 to 1.3109, (iii) annualized return rises from 0.0520 to 0.0863, and (iv) IC rises from 0.0058 to 0.0078. The improvements are directionally aligned (better return, better risk-adjusted return, better IC, and smaller drawdown), suggesting the signal is not a metric-specific artifact.\n\nFactor-design-wise, the three implementations appear to be coherent variants of the same mechanism: large move intensity (|return| and/or range), low participation (volume or dollar volume), and illiquidity/price impact spike (Amihud-style |r|/(dollar volume)). Using cross-sectional ranks after time-series normalization is a reasonable way to stabilize heavy tails and regime shifts. No explicit complexity warnings were provided; symbol length and feature count look moderate (mainly close/high/low/volume).",
        "hypothesis_evaluation": "Supported. The hypothesis predicts short-horizon mean reversion after large moves that occur with thin liquidity/participation. The observed improvements in IC and 1-day excess performance metrics are consistent with that contrarian reversal mechanism working in aggregate. Importantly, the drawdown improvement alongside higher annualized return suggests the signal is not merely increasing exposure/variance; it is improving the return/risk profile.\n\nCompared to SOTA, this experiment is a clear step forward. Since annualized return improves (0.0863 vs 0.0520) and at least one other metric also improves (in fact all do), this satisfies the replacement rule.\n\nHyperparameters explicitly present in the tested factors (for further sensitivity sweeps):\n- Lookback / baseline windows: 20D (LiquidityVacuum_Contrarian_20D), 40D (DollarVolumeSparse_Impact_Contrarian_40D), 60D (RangeImpact_LowVol_Contrarian_60D)\n- Transform/normalization choices: TS_ZSCORE window n ∈ {20,40,60}; TS_RANK window n = 40; cross-sectional RANK applied daily; LOG with LOG(x+1)\n- Illiquidity epsilon: ε in |r|/(C*V + ε) and range/(C*V + ε) (value not specified; should be fixed and documented)\n- Move definition choices: |r_t| vs log(H/L) vs combination (|r| + range term)\n\nKey refinement need (next iteration): quantify turnover and cost sensitivity. “Without cost” metrics can look strong for contrarian signals that trade frequently; if turnover is high, live performance may degrade. Add explicit controls that reduce churn while keeping the same liquidity-vacuum concept.",
        "decision": true,
        "reason": "Your current framework mixes (large move) × (low participation) × (price impact) with ranks/z-scores, which is directionally correct. Two common failure modes remain within the same theoretical framework:\n1) False positives during high-volatility regimes: |r| can be large simply because volatility is high; reversal is weaker when the move is not an outlier relative to recent realized vol.\n2) Participation measures can be noisy across names and regimes: volume or dollar volume should be judged relative to its own history (e.g., ADV) and/or matched to volatility regimes.\n\nConcrete within-hypothesis improvements to explore (keep factors simple; create separate factors for each parameter choice):\n- Volatility-adjusted move outlier (new hyperparameters: vol window m): use |r_t| / (TS_STD(r, m) + 1e-12) then TS_ZSCORE over n. Try m ∈ {10,20} with n ∈ {20,40}.\n- Participation squeeze relative to ADV (new hyperparameters: ADV window k): use log(V_t+1) - log(TS_MEAN(V, k)+1) or Z_k(log(V+1)); try k ∈ {20,60}. This keeps the same “low participation” concept but makes it instrument-regime aware.\n- Replace multiplicative ranks with a clipped additive score to reduce extreme-product instability (same concept, simpler behavior): Score = -sign(r_t) * (w1*rank(move) + w2*rank(illiquidity) + w3*rank(low_participation)), with fixed weights (e.g., equal weights). This often improves generalization vs triple-products.\n- Event-gating (reduces turnover): only activate when move intensity is in the top q percentile cross-sectionally AND participation is in bottom q percentile (hyperparameter q ∈ {5%,10%,20%}). Outside the gate, factor=0.\n- Window sweep around your current best: keep structure identical and test n ∈ {15,20,30,40,60}; do not mix windows inside a single factor to avoid overfitting.\n\nAlso recommended reporting in the next run: turnover, performance with simple cost assumptions, and stability by market-cap/ADV buckets (the hypothesis implies stronger effects in less liquid names)."
      }
    },
    "715dd889fae18bfc": {
      "factor_id": "715dd889fae18bfc",
      "factor_name": "GapZ40_WickRejection_VolExpRange_5v20",
      "factor_expression": "-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),40))*((SIGN(LOG($open/(DELAY($close,1)+1e-8)))>0)?(($high-MAX($open,$close))/($high-$low+1e-8)):((MIN($open,$close)-$low)/($high-$low+1e-8)))*(TS_MEAN($high-$low,5)/(TS_MEAN($high-$low,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),40))*((SIGN(LOG($open/(DELAY($close,1)+1e-8)))>0)?(($high-MAX($open,$close))/($high-$low+1e-8)):((MIN($open,$close)-$low)/($high-$low+1e-8)))*(TS_MEAN($high-$low,5)/(TS_MEAN($high-$low,20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"GapZ40_WickRejection_VolExpRange_5v20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian overnight-gap factor: fades up-gaps and buys down-gaps, scaled by (i) 40D z-scored log gap magnitude, (ii) same-day wick rejection on the gap side, and (iii) short-term vs long-term volatility expansion measured by (high-low) range ratio (5D/20D).",
      "factor_formulation": "F = -\\operatorname{sign}(g)\\,|Z_{40}(g)|\\,\\text{WickRej}(g)\\,\\frac{\\text{MA}_5(H-L)}{\\text{MA}_{20}(H-L)},\\quad g=\\ln\\left(\\frac{O}{C_{-1}}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "0cb59f628636",
        "parent_trajectory_ids": [
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Overnight gap shocks that are intraday-rejected in a short-term volatility-expansion and overextension regime represent transient liquidity/positioning dislocations rather than durable information; therefore a contrarian factor that is negative for up-gaps and positive for down-gaps, scaled by (i) the rolling z-score magnitude of log(open/prev_close), (ii) same-day candle rejection strength (close back into the prior day’s range with large wick on the gap side), and (iii) a vol-expansion filter (ATR5/ATR20 high) will predict 1–5 day mean-reversion returns (fade up-gaps; buy down-gaps), with strongest effect on high |gap_z| and high rejection_strength days and weaker/absent effect when volume is unusually high (information days).\n                Concise Observation: The available data (daily OHLCV) supports constructing gap magnitude (log(open/prev_close)), candle anatomy-based rejection (wicks/body normalized by range), volatility-regime ratios (ATR5 vs ATR20), overextension (close/MA10-1), and volume surprise (volume z-score), enabling a factor that targets volatility expansion + intraday rejection—mechanistically distinct from the parent’s volatility compression + breakout continuation and thus expected to have low/negative correlation.\n                Concise Justification: Large overnight gaps create immediate mark-to-market pressure and forced liquidity demand; if the gap is not supported by sustained intraday buying/selling, market makers and mean-reversion traders absorb the flow, producing a close that retraces the gap and subsequent short-horizon continuation of reversion, especially when recent volatility is expanding and price is overextended, which increases the probability of overshoot rather than trend formation.\n                Concise Knowledge: If an overnight gap is primarily driven by temporary liquidity/positioning imbalance, then the same-day close tends to revert toward the prior close and the next few days continue that reversion; when intraday trading rejects the gap (close returns inside the prior day range and wick is large on the gap side) under volatility expansion (ATR5/ATR20 elevated), the gap is more likely non-informational and mean-reversion should dominate; when the gap occurs with unusually high relative volume, the move is more likely informational and the contrarian edge should decay or flip.\n                concise Specification: Define Gap = ln(open/DELAY(close,1)); compute GapZ_40 = (Gap-TS_MEAN(Gap,40))/(TS_STD(Gap,40)+1e-8) and gate on |GapZ_40|>=1.5; define Rejection as: for Gap>0 use UpRej=(high-max(open,close))/(high-low+1e-8) and Require close<=DELAY(high,1) (close back below prior-day high), for Gap<0 use DownRej=(min(open,close)-low)/(high-low+1e-8) and Require close>=DELAY(low,1) (close back above prior-day low); define VolExp=ATR5/ (ATR20+1e-8) where ATRn=TS_MEAN(max(high-low, abs(high-DELAY(close,1)), abs(low-DELAY(close,1))), n) and gate on VolExp>=1.2; define OverExt=abs(close/(TS_MEAN(close,10)+1e-8)-1) and optionally weight by min(OverExt/0.03,1); define VolZ_20=(volume-TS_MEAN(volume,20))/(TS_STD(volume,20)+1e-8) and downweight informational days by weight_vol=exp(-max(VolZ_20,0)); final factor (one output) = -sign(Gap)*clip(|GapZ_40|/3,0,1)*clip(Rejection,0,1)*clip(VolExp/2,0,1)*clip(OverExt/0.03,0,1)*weight_vol, evaluated cross-sectionally per day to predict next 1–5D returns.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-21T18:22:48.233437"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0952568727900517,
        "ICIR": 0.0378956610002847,
        "1day.excess_return_without_cost.std": 0.0042207982685915,
        "1day.excess_return_with_cost.annualized_return": 0.0069287540779068,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002282718283015,
        "1day.excess_return_without_cost.annualized_return": 0.0543286951357664,
        "1day.excess_return_with_cost.std": 0.0042210125343763,
        "Rank IC": 0.0191110800301698,
        "IC": 0.0049976277700027,
        "1day.excess_return_without_cost.max_drawdown": -0.0694278964923048,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8343460227604177,
        "1day.pa": 0.0,
        "l2.valid": 0.9964305885203252,
        "Rank ICIR": 0.1485168046356516,
        "l2.train": 0.9934204700029544,
        "1day.excess_return_with_cost.information_ratio": 0.1064020577124402,
        "1day.excess_return_with_cost.mean": 2.911241209204542e-05
      },
      "feedback": {
        "observations": "Overall performance is mixed but slightly improved vs SOTA on portfolio-level outcomes. Annualized return without cost improved (0.054329 vs 0.052010), and max drawdown is less severe (-0.069428 vs -0.072585, smaller drawdown is better). However, predictive quality metrics deteriorated: Information Ratio decreased (0.834346 vs 0.972561) and IC decreased (0.004998 vs 0.005798). This pattern suggests the signal may still monetize, but is noisier/less stable cross-sectionally than the current SOTA factor set.",
        "hypothesis_evaluation": "The results weakly support (but do not strongly confirm) the hypothesis. The contrarian gap + rejection + volatility-expansion idea appears to retain economic edge (higher annualized return and improved drawdown), consistent with mean-reversion behavior after dislocation-like gaps. However, the lower IC and IR indicate the implementation likely lacks precise conditioning for “transient dislocation vs information” days. In other words, the core effect may exist, but current gating/measurement of (i) rejection strength and (ii) volume/information filter is not sharp enough, reducing consistency.\n\nWhat this run implies about the hypothesis components:\n- Gap magnitude scaling works directionally (still monetizes), but the chosen z-score lookbacks may not be optimal.\n- Rejection logic likely needs to be more selective (e.g., true ‘close back into prior range’ vs wick proxy; avoid ambiguous candles).\n- Vol-expansion filter helps risk (better drawdown) but may be overly broad, hurting IC/IR.\n- The “volume unusually high => informational day” clause is plausible but likely under-specified (simple exp(-max(z,0)) may over-penalize or misclassify).",
        "decision": true,
        "reason": "Your current metrics suggest monetization but weaker forecasting consistency. That typically happens when the signal is correct in some regimes but diluted elsewhere. The hypothesis already points to regime specificity (high |gap_z|, strong rejection, vol-expansion, low abnormal volume). The next iterations should tighten these gates and normalize magnitudes to reduce heteroskedasticity:\n\n1) Tighten “rejection” definition (reduce noisy positives):\n- Use a strict BackIntoPriorRange condition with margin: for up-gap require Close <= PriorHigh - k*ATR_n; for down-gap require Close >= PriorLow + k*ATR_n (k small like 0.05–0.2). This reduces ambiguous cases where price barely tags back inside.\n- Consider a ‘gap-side wick dominance’ ratio rather than raw wick: (gap-side wick) / (true range) and require it exceed a threshold.\n\n2) Replace/augment z-scored gap with ATR-scaled gap:\n- Instead of (or in addition to) TS_ZSCORE(log(O/C-1), L), use: gap_atr = log(O/C-1) / ATR_n. This often improves cross-sectional comparability and stability.\n\n3) Re-think the “information day” filter:\n- Volume penalty should be conditional: zVol - beta*zAbsRet (or zVol / (1+zAbsRet)) so that high volume on high-vol days is not automatically treated as informational.\n- Alternatively gate on both: high volume AND small intraday rejection (i.e., if there is strong rejection, allow some volume).\n\n4) Vol-expansion filter sensitivity:\n- Current ratios: RangeMA(5)/RangeMA(20) and StdRet(5)/StdRet(20). These may be too reactive/noisy. Test smoother alternatives (e.g., 10/60) or rank-transform the ratio cross-sectionally per day.\n\nParameter/hyperparameter inventory (explicit) and recommended sweeps:\n- Gap z-score lookback: currently 40 (GapZ40_*), 30 (GapZ30_*). Sweep: 20, 30, 40, 60.\n- Overextension lookback: currently 10 (OverExt10). Sweep: 5, 10, 20.\n- Vol-expansion windows: currently 5/20 (both range ratio and return-vol ratio). Sweep: 3/15, 5/30, 10/60.\n- Volume z-score lookback: currently 20 (VolumeDamp_20). Sweep: 10, 20, 60.\n- Penalty function: exp(-max(z,0)) is asymmetric; try logistic/(1+exp(z)) or clipped linear; also test two-sided penalty (penalize both extreme high and extreme low volume if microstructure effects exist).\n\nImplementation-level improvements still within the same theoretical framework:\n- Use True Range (ATR) rather than (H-L) to capture gap contributions to volatility.\n- Add a “gap fill distance” term: distance from close to prior close (or to prior range boundary) normalized by ATR, to quantify actual recapture.\n- Winsorize or clip extreme z-scores (e.g., clip |gap_z| to 3–5) to improve robustness and potentially raise IC/IR.\n\nNet: The hypothesis direction remains viable; the next iteration should focus on stricter event definitions and better normalization/conditioning to recover IC/IR while keeping the improved return/drawdown."
      }
    },
    "0c092909e00893e0": {
      "factor_id": "0c092909e00893e0",
      "factor_name": "GapZ40_BackIntoPriorRange_VolumeDamp_20",
      "factor_expression": "-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),40))*((SIGN(LOG($open/(DELAY($close,1)+1e-8)))>0)?(($close<DELAY($high,1))?1:0):(($close>DELAY($low,1))?1:0))*EXP(-MAX(TS_ZSCORE($volume,20),0))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),40))*((SIGN(LOG($open/(DELAY($close,1)+1e-8)))>0)?(($close<DELAY($high,1))?1:0):(($close>DELAY($low,1))?1:0))*EXP(-MAX(TS_ZSCORE($volume,20),0))\" # Your output factor expression will be filled in here\n    name = \"GapZ40_BackIntoPriorRange_VolumeDamp_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian gap-reversal signal that only activates when the close returns back inside the prior day's range boundary (below prior high for up-gaps, above prior low for down-gaps), with downweighting on high relative-volume (potentially informational) days via an exponential penalty of 20D volume z-score.",
      "factor_formulation": "F = -\\operatorname{sign}(g)\\,|Z_{40}(g)|\\,\\mathbf{1}[\\text{BackIn}]\\,\\exp(-\\max(Z_{20}(V),0)),\\quad g=\\ln\\left(\\frac{O}{C_{-1}}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "0cb59f628636",
        "parent_trajectory_ids": [
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Overnight gap shocks that are intraday-rejected in a short-term volatility-expansion and overextension regime represent transient liquidity/positioning dislocations rather than durable information; therefore a contrarian factor that is negative for up-gaps and positive for down-gaps, scaled by (i) the rolling z-score magnitude of log(open/prev_close), (ii) same-day candle rejection strength (close back into the prior day’s range with large wick on the gap side), and (iii) a vol-expansion filter (ATR5/ATR20 high) will predict 1–5 day mean-reversion returns (fade up-gaps; buy down-gaps), with strongest effect on high |gap_z| and high rejection_strength days and weaker/absent effect when volume is unusually high (information days).\n                Concise Observation: The available data (daily OHLCV) supports constructing gap magnitude (log(open/prev_close)), candle anatomy-based rejection (wicks/body normalized by range), volatility-regime ratios (ATR5 vs ATR20), overextension (close/MA10-1), and volume surprise (volume z-score), enabling a factor that targets volatility expansion + intraday rejection—mechanistically distinct from the parent’s volatility compression + breakout continuation and thus expected to have low/negative correlation.\n                Concise Justification: Large overnight gaps create immediate mark-to-market pressure and forced liquidity demand; if the gap is not supported by sustained intraday buying/selling, market makers and mean-reversion traders absorb the flow, producing a close that retraces the gap and subsequent short-horizon continuation of reversion, especially when recent volatility is expanding and price is overextended, which increases the probability of overshoot rather than trend formation.\n                Concise Knowledge: If an overnight gap is primarily driven by temporary liquidity/positioning imbalance, then the same-day close tends to revert toward the prior close and the next few days continue that reversion; when intraday trading rejects the gap (close returns inside the prior day range and wick is large on the gap side) under volatility expansion (ATR5/ATR20 elevated), the gap is more likely non-informational and mean-reversion should dominate; when the gap occurs with unusually high relative volume, the move is more likely informational and the contrarian edge should decay or flip.\n                concise Specification: Define Gap = ln(open/DELAY(close,1)); compute GapZ_40 = (Gap-TS_MEAN(Gap,40))/(TS_STD(Gap,40)+1e-8) and gate on |GapZ_40|>=1.5; define Rejection as: for Gap>0 use UpRej=(high-max(open,close))/(high-low+1e-8) and Require close<=DELAY(high,1) (close back below prior-day high), for Gap<0 use DownRej=(min(open,close)-low)/(high-low+1e-8) and Require close>=DELAY(low,1) (close back above prior-day low); define VolExp=ATR5/ (ATR20+1e-8) where ATRn=TS_MEAN(max(high-low, abs(high-DELAY(close,1)), abs(low-DELAY(close,1))), n) and gate on VolExp>=1.2; define OverExt=abs(close/(TS_MEAN(close,10)+1e-8)-1) and optionally weight by min(OverExt/0.03,1); define VolZ_20=(volume-TS_MEAN(volume,20))/(TS_STD(volume,20)+1e-8) and downweight informational days by weight_vol=exp(-max(VolZ_20,0)); final factor (one output) = -sign(Gap)*clip(|GapZ_40|/3,0,1)*clip(Rejection,0,1)*clip(VolExp/2,0,1)*clip(OverExt/0.03,0,1)*weight_vol, evaluated cross-sectionally per day to predict next 1–5D returns.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-21T18:22:48.233437"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0952568727900517,
        "ICIR": 0.0378956610002847,
        "1day.excess_return_without_cost.std": 0.0042207982685915,
        "1day.excess_return_with_cost.annualized_return": 0.0069287540779068,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002282718283015,
        "1day.excess_return_without_cost.annualized_return": 0.0543286951357664,
        "1day.excess_return_with_cost.std": 0.0042210125343763,
        "Rank IC": 0.0191110800301698,
        "IC": 0.0049976277700027,
        "1day.excess_return_without_cost.max_drawdown": -0.0694278964923048,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8343460227604177,
        "1day.pa": 0.0,
        "l2.valid": 0.9964305885203252,
        "Rank ICIR": 0.1485168046356516,
        "l2.train": 0.9934204700029544,
        "1day.excess_return_with_cost.information_ratio": 0.1064020577124402,
        "1day.excess_return_with_cost.mean": 2.911241209204542e-05
      },
      "feedback": {
        "observations": "Overall performance is mixed but slightly improved vs SOTA on portfolio-level outcomes. Annualized return without cost improved (0.054329 vs 0.052010), and max drawdown is less severe (-0.069428 vs -0.072585, smaller drawdown is better). However, predictive quality metrics deteriorated: Information Ratio decreased (0.834346 vs 0.972561) and IC decreased (0.004998 vs 0.005798). This pattern suggests the signal may still monetize, but is noisier/less stable cross-sectionally than the current SOTA factor set.",
        "hypothesis_evaluation": "The results weakly support (but do not strongly confirm) the hypothesis. The contrarian gap + rejection + volatility-expansion idea appears to retain economic edge (higher annualized return and improved drawdown), consistent with mean-reversion behavior after dislocation-like gaps. However, the lower IC and IR indicate the implementation likely lacks precise conditioning for “transient dislocation vs information” days. In other words, the core effect may exist, but current gating/measurement of (i) rejection strength and (ii) volume/information filter is not sharp enough, reducing consistency.\n\nWhat this run implies about the hypothesis components:\n- Gap magnitude scaling works directionally (still monetizes), but the chosen z-score lookbacks may not be optimal.\n- Rejection logic likely needs to be more selective (e.g., true ‘close back into prior range’ vs wick proxy; avoid ambiguous candles).\n- Vol-expansion filter helps risk (better drawdown) but may be overly broad, hurting IC/IR.\n- The “volume unusually high => informational day” clause is plausible but likely under-specified (simple exp(-max(z,0)) may over-penalize or misclassify).",
        "decision": true,
        "reason": "Your current metrics suggest monetization but weaker forecasting consistency. That typically happens when the signal is correct in some regimes but diluted elsewhere. The hypothesis already points to regime specificity (high |gap_z|, strong rejection, vol-expansion, low abnormal volume). The next iterations should tighten these gates and normalize magnitudes to reduce heteroskedasticity:\n\n1) Tighten “rejection” definition (reduce noisy positives):\n- Use a strict BackIntoPriorRange condition with margin: for up-gap require Close <= PriorHigh - k*ATR_n; for down-gap require Close >= PriorLow + k*ATR_n (k small like 0.05–0.2). This reduces ambiguous cases where price barely tags back inside.\n- Consider a ‘gap-side wick dominance’ ratio rather than raw wick: (gap-side wick) / (true range) and require it exceed a threshold.\n\n2) Replace/augment z-scored gap with ATR-scaled gap:\n- Instead of (or in addition to) TS_ZSCORE(log(O/C-1), L), use: gap_atr = log(O/C-1) / ATR_n. This often improves cross-sectional comparability and stability.\n\n3) Re-think the “information day” filter:\n- Volume penalty should be conditional: zVol - beta*zAbsRet (or zVol / (1+zAbsRet)) so that high volume on high-vol days is not automatically treated as informational.\n- Alternatively gate on both: high volume AND small intraday rejection (i.e., if there is strong rejection, allow some volume).\n\n4) Vol-expansion filter sensitivity:\n- Current ratios: RangeMA(5)/RangeMA(20) and StdRet(5)/StdRet(20). These may be too reactive/noisy. Test smoother alternatives (e.g., 10/60) or rank-transform the ratio cross-sectionally per day.\n\nParameter/hyperparameter inventory (explicit) and recommended sweeps:\n- Gap z-score lookback: currently 40 (GapZ40_*), 30 (GapZ30_*). Sweep: 20, 30, 40, 60.\n- Overextension lookback: currently 10 (OverExt10). Sweep: 5, 10, 20.\n- Vol-expansion windows: currently 5/20 (both range ratio and return-vol ratio). Sweep: 3/15, 5/30, 10/60.\n- Volume z-score lookback: currently 20 (VolumeDamp_20). Sweep: 10, 20, 60.\n- Penalty function: exp(-max(z,0)) is asymmetric; try logistic/(1+exp(z)) or clipped linear; also test two-sided penalty (penalize both extreme high and extreme low volume if microstructure effects exist).\n\nImplementation-level improvements still within the same theoretical framework:\n- Use True Range (ATR) rather than (H-L) to capture gap contributions to volatility.\n- Add a “gap fill distance” term: distance from close to prior close (or to prior range boundary) normalized by ATR, to quantify actual recapture.\n- Winsorize or clip extreme z-scores (e.g., clip |gap_z| to 3–5) to improve robustness and potentially raise IC/IR.\n\nNet: The hypothesis direction remains viable; the next iteration should focus on stricter event definitions and better normalization/conditioning to recover IC/IR while keeping the improved return/drawdown."
      }
    },
    "2a6d3faf3327fd4d": {
      "factor_id": "2a6d3faf3327fd4d",
      "factor_name": "GapZ30_OverExt10_VolExpStdRet_5v20",
      "factor_expression": "-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),30))*ABS($close/(TS_MEAN($close,10)+1e-8)-1)*(TS_STD($return,5)/(TS_STD($return,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(LOG($open/(DELAY($close,1)+1e-8)))*ABS(TS_ZSCORE(LOG($open/(DELAY($close,1)+1e-8)),30))*ABS($close/(TS_MEAN($close,10)+1e-8)-1)*(TS_STD(LOG($close/(DELAY($close,1)+1e-8)),5)/(TS_STD(LOG($close/(DELAY($close,1)+1e-8)),20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"GapZ30_OverExt10_VolExpStdRet_5v20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Mean-reversion gap factor emphasizing overextension and volatility expansion: contrarian to the overnight gap direction, scaled by 30D gap z-score magnitude, 10D price overextension from its mean, and a volatility-expansion filter using 5D/20D rolling return volatility ratio.",
      "factor_formulation": "F=-\\operatorname{sign}(g)\\,|Z_{30}(g)|\\,\\left|\\frac{C}{\\text{MA}_{10}(C)}-1\\right|\\,\\frac{\\sigma_5(r)}{\\sigma_{20}(r)},\\quad g=\\ln\\left(\\frac{O}{C_{-1}}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "0cb59f628636",
        "parent_trajectory_ids": [
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Overnight gap shocks that are intraday-rejected in a short-term volatility-expansion and overextension regime represent transient liquidity/positioning dislocations rather than durable information; therefore a contrarian factor that is negative for up-gaps and positive for down-gaps, scaled by (i) the rolling z-score magnitude of log(open/prev_close), (ii) same-day candle rejection strength (close back into the prior day’s range with large wick on the gap side), and (iii) a vol-expansion filter (ATR5/ATR20 high) will predict 1–5 day mean-reversion returns (fade up-gaps; buy down-gaps), with strongest effect on high |gap_z| and high rejection_strength days and weaker/absent effect when volume is unusually high (information days).\n                Concise Observation: The available data (daily OHLCV) supports constructing gap magnitude (log(open/prev_close)), candle anatomy-based rejection (wicks/body normalized by range), volatility-regime ratios (ATR5 vs ATR20), overextension (close/MA10-1), and volume surprise (volume z-score), enabling a factor that targets volatility expansion + intraday rejection—mechanistically distinct from the parent’s volatility compression + breakout continuation and thus expected to have low/negative correlation.\n                Concise Justification: Large overnight gaps create immediate mark-to-market pressure and forced liquidity demand; if the gap is not supported by sustained intraday buying/selling, market makers and mean-reversion traders absorb the flow, producing a close that retraces the gap and subsequent short-horizon continuation of reversion, especially when recent volatility is expanding and price is overextended, which increases the probability of overshoot rather than trend formation.\n                Concise Knowledge: If an overnight gap is primarily driven by temporary liquidity/positioning imbalance, then the same-day close tends to revert toward the prior close and the next few days continue that reversion; when intraday trading rejects the gap (close returns inside the prior day range and wick is large on the gap side) under volatility expansion (ATR5/ATR20 elevated), the gap is more likely non-informational and mean-reversion should dominate; when the gap occurs with unusually high relative volume, the move is more likely informational and the contrarian edge should decay or flip.\n                concise Specification: Define Gap = ln(open/DELAY(close,1)); compute GapZ_40 = (Gap-TS_MEAN(Gap,40))/(TS_STD(Gap,40)+1e-8) and gate on |GapZ_40|>=1.5; define Rejection as: for Gap>0 use UpRej=(high-max(open,close))/(high-low+1e-8) and Require close<=DELAY(high,1) (close back below prior-day high), for Gap<0 use DownRej=(min(open,close)-low)/(high-low+1e-8) and Require close>=DELAY(low,1) (close back above prior-day low); define VolExp=ATR5/ (ATR20+1e-8) where ATRn=TS_MEAN(max(high-low, abs(high-DELAY(close,1)), abs(low-DELAY(close,1))), n) and gate on VolExp>=1.2; define OverExt=abs(close/(TS_MEAN(close,10)+1e-8)-1) and optionally weight by min(OverExt/0.03,1); define VolZ_20=(volume-TS_MEAN(volume,20))/(TS_STD(volume,20)+1e-8) and downweight informational days by weight_vol=exp(-max(VolZ_20,0)); final factor (one output) = -sign(Gap)*clip(|GapZ_40|/3,0,1)*clip(Rejection,0,1)*clip(VolExp/2,0,1)*clip(OverExt/0.03,0,1)*weight_vol, evaluated cross-sectionally per day to predict next 1–5D returns.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-21T18:22:48.233437"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0952568727900517,
        "ICIR": 0.0378956610002847,
        "1day.excess_return_without_cost.std": 0.0042207982685915,
        "1day.excess_return_with_cost.annualized_return": 0.0069287540779068,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002282718283015,
        "1day.excess_return_without_cost.annualized_return": 0.0543286951357664,
        "1day.excess_return_with_cost.std": 0.0042210125343763,
        "Rank IC": 0.0191110800301698,
        "IC": 0.0049976277700027,
        "1day.excess_return_without_cost.max_drawdown": -0.0694278964923048,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8343460227604177,
        "1day.pa": 0.0,
        "l2.valid": 0.9964305885203252,
        "Rank ICIR": 0.1485168046356516,
        "l2.train": 0.9934204700029544,
        "1day.excess_return_with_cost.information_ratio": 0.1064020577124402,
        "1day.excess_return_with_cost.mean": 2.911241209204542e-05
      },
      "feedback": {
        "observations": "Overall performance is mixed but slightly improved vs SOTA on portfolio-level outcomes. Annualized return without cost improved (0.054329 vs 0.052010), and max drawdown is less severe (-0.069428 vs -0.072585, smaller drawdown is better). However, predictive quality metrics deteriorated: Information Ratio decreased (0.834346 vs 0.972561) and IC decreased (0.004998 vs 0.005798). This pattern suggests the signal may still monetize, but is noisier/less stable cross-sectionally than the current SOTA factor set.",
        "hypothesis_evaluation": "The results weakly support (but do not strongly confirm) the hypothesis. The contrarian gap + rejection + volatility-expansion idea appears to retain economic edge (higher annualized return and improved drawdown), consistent with mean-reversion behavior after dislocation-like gaps. However, the lower IC and IR indicate the implementation likely lacks precise conditioning for “transient dislocation vs information” days. In other words, the core effect may exist, but current gating/measurement of (i) rejection strength and (ii) volume/information filter is not sharp enough, reducing consistency.\n\nWhat this run implies about the hypothesis components:\n- Gap magnitude scaling works directionally (still monetizes), but the chosen z-score lookbacks may not be optimal.\n- Rejection logic likely needs to be more selective (e.g., true ‘close back into prior range’ vs wick proxy; avoid ambiguous candles).\n- Vol-expansion filter helps risk (better drawdown) but may be overly broad, hurting IC/IR.\n- The “volume unusually high => informational day” clause is plausible but likely under-specified (simple exp(-max(z,0)) may over-penalize or misclassify).",
        "decision": true,
        "reason": "Your current metrics suggest monetization but weaker forecasting consistency. That typically happens when the signal is correct in some regimes but diluted elsewhere. The hypothesis already points to regime specificity (high |gap_z|, strong rejection, vol-expansion, low abnormal volume). The next iterations should tighten these gates and normalize magnitudes to reduce heteroskedasticity:\n\n1) Tighten “rejection” definition (reduce noisy positives):\n- Use a strict BackIntoPriorRange condition with margin: for up-gap require Close <= PriorHigh - k*ATR_n; for down-gap require Close >= PriorLow + k*ATR_n (k small like 0.05–0.2). This reduces ambiguous cases where price barely tags back inside.\n- Consider a ‘gap-side wick dominance’ ratio rather than raw wick: (gap-side wick) / (true range) and require it exceed a threshold.\n\n2) Replace/augment z-scored gap with ATR-scaled gap:\n- Instead of (or in addition to) TS_ZSCORE(log(O/C-1), L), use: gap_atr = log(O/C-1) / ATR_n. This often improves cross-sectional comparability and stability.\n\n3) Re-think the “information day” filter:\n- Volume penalty should be conditional: zVol - beta*zAbsRet (or zVol / (1+zAbsRet)) so that high volume on high-vol days is not automatically treated as informational.\n- Alternatively gate on both: high volume AND small intraday rejection (i.e., if there is strong rejection, allow some volume).\n\n4) Vol-expansion filter sensitivity:\n- Current ratios: RangeMA(5)/RangeMA(20) and StdRet(5)/StdRet(20). These may be too reactive/noisy. Test smoother alternatives (e.g., 10/60) or rank-transform the ratio cross-sectionally per day.\n\nParameter/hyperparameter inventory (explicit) and recommended sweeps:\n- Gap z-score lookback: currently 40 (GapZ40_*), 30 (GapZ30_*). Sweep: 20, 30, 40, 60.\n- Overextension lookback: currently 10 (OverExt10). Sweep: 5, 10, 20.\n- Vol-expansion windows: currently 5/20 (both range ratio and return-vol ratio). Sweep: 3/15, 5/30, 10/60.\n- Volume z-score lookback: currently 20 (VolumeDamp_20). Sweep: 10, 20, 60.\n- Penalty function: exp(-max(z,0)) is asymmetric; try logistic/(1+exp(z)) or clipped linear; also test two-sided penalty (penalize both extreme high and extreme low volume if microstructure effects exist).\n\nImplementation-level improvements still within the same theoretical framework:\n- Use True Range (ATR) rather than (H-L) to capture gap contributions to volatility.\n- Add a “gap fill distance” term: distance from close to prior close (or to prior range boundary) normalized by ATR, to quantify actual recapture.\n- Winsorize or clip extreme z-scores (e.g., clip |gap_z| to 3–5) to improve robustness and potentially raise IC/IR.\n\nNet: The hypothesis direction remains viable; the next iteration should focus on stricter event definitions and better normalization/conditioning to recover IC/IR while keeping the improved return/drawdown."
      }
    },
    "cbbf9c475864fff8": {
      "factor_id": "cbbf9c475864fff8",
      "factor_name": "LowVol_GapShock_Rejection_Contrarian_20ATR_60Rank",
      "factor_expression": "-SIGN($open-DELAY($close,1))*TS_RANK(ABS($open/(DELAY($close,1)+1e-8)-1)/(TS_MEAN($high-$low,20)+1e-8),60)*(($high-MAX($open,$close)+MIN($open,$close)-$low)/($high-$low+1e-8))*MAX(0,1-$volume/(TS_MEAN($volume,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN($open-DELAY($close,1))*TS_RANK(ABS($open/(DELAY($close,1)+1e-8)-1)/(TS_MEAN($high-$low,20)+1e-8),60)*(($high-MAX($open,$close)+MIN($open,$close)-$low)/($high-$low+1e-8))*MAX(0,1-$volume/(TS_MEAN($volume,20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"LowVol_GapShock_Rejection_Contrarian_20ATR_60Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian mean-reversion score for liquidity-vacuum gap shocks: large open-to-prior-close gaps (scaled by 20D average range) that show strong intraday wick rejection and low relative volume are expected to revert over the next 1–5 days in the direction opposite the gap.",
      "factor_formulation": "F_t=-\\operatorname{sign}(O_t-C_{t-1})\\cdot \\operatorname{TS\\_RANK}\\left(\\frac{|O_t/C_{t-1}-1|}{\\operatorname{MA}_{20}(H-L)} ,60\\right)\\cdot \\frac{(H_t-\\max(O_t,C_t))+(\\min(O_t,C_t)-L_t)}{H_t-L_t}\\cdot \\max\\left(0,1-\\frac{V_t}{\\operatorname{MA}_{20}(V)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "756a5519a434",
        "parent_trajectory_ids": [
          "d559c63feb0c"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit mean-reversion after liquidity-vacuum gap shocks: when the open-to-prior-close gap is abnormally large versus recent true-range (ATR proxy), but the gap day shows low relative volume and strong intraday rejection back toward the prior close (large wick/close-back), the move is more likely an inventory/liquidity imbalance than new information and prices tend to revert over the next few days; gap shocks with high confirming volume should have weaker or opposite reversion.\n                Concise Observation: The available daily OHLCV data (open/high/low/close/volume) allows constructing event-style, single-day microstructure proxies—gap size vs rolling true-range, relative volume vs ADV, and wick/rejection anatomy—which are orthogonal to multi-day trend/breakout confirmation features emphasized by the parent strategy.\n                Concise Justification: A gap with low volume indicates weak participation and limited informational conviction, while an intraday rejection (wick + close-back toward prior close) indicates order-flow absorption and price discovery failure; under volatility expansion these dislocations are more frequent and, absent volume confirmation, tend to unwind via short-horizon mean-reversion.\n                Concise Knowledge: If a large overnight price gap is not supported by proportional trading volume and is reversed intraday (close-back with long wick), then the gap is more likely driven by transient liquidity/positioning rather than persistent information, so the next 1–5 trading days should exhibit mean-reversion in the direction opposite the gap; when volume confirms the gap, continuation risk increases and contrarian signals should be down-weighted.\n                concise Specification: Define gap_t = (open_t/(close_{t-1}+1e-8) - 1); TR_t = max(high_t-low_t, abs(high_t-close_{t-1}), abs(low_t-close_{t-1})); ATR20_t = TS_MEAN(TR,20); GapShock_t = abs(gap_t)/(ATR20_t+1e-8); RelVol_t = volume_t/(TS_MEAN(volume,20)+1e-8); Rejection_t = ( (high_t-max(open_t,close_t)) + (min(open_t,close_t)-low_t) )/(high_t-low_t+1e-8) * (1 - abs(close_t-close_{t-1})/(high_t-low_t+1e-8)); VolExpGate_t = 1{ TS_ZSCORE(TR,60) > 1.0 }; Hypothesis expects next 1–5D return ~ +[ -sign(gap_t) ] when VolExpGate_t=1, GapShock_t in top tail (e.g., TS_ZSCORE(GapShock,60)>1.5) AND RelVol_t low (e.g., RelVol_t<0.8) AND Rejection_t high (e.g., TS_ZSCORE(Rejection,60)>1.0), with the effect weakened or reversed when RelVol_t>1.2 (volume-confirmed gaps).\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-21T18:37:48.818362"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1092471247904156,
        "ICIR": 0.0373983474804837,
        "1day.excess_return_without_cost.std": 0.0041082972802677,
        "1day.excess_return_with_cost.annualized_return": 0.0204467743317592,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002858175547241,
        "1day.excess_return_without_cost.annualized_return": 0.0680245780243483,
        "1day.excess_return_with_cost.std": 0.0041095214693639,
        "Rank IC": 0.0196407613359077,
        "IC": 0.0049612872603487,
        "1day.excess_return_without_cost.max_drawdown": -0.0987065894936264,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.073286127083129,
        "1day.pa": 0.0,
        "l2.valid": 0.9969316814828256,
        "Rank ICIR": 0.1489881663966943,
        "l2.train": 0.9930197612880052,
        "1day.excess_return_with_cost.information_ratio": 0.3225114007867323,
        "1day.excess_return_with_cost.mean": 8.591081651999702e-05
      },
      "feedback": {
        "observations": "Compared to SOTA, the combined factor set improved portfolio-level performance but weakened pure predictive correlation.\n- Annualized return: 0.0680 vs 0.0520 (improved)\n- Information ratio: 1.0733 vs 0.9726 (improved)\n- Max drawdown: -0.0987 vs -0.0726 (worse; larger drawdown)\n- IC: 0.00496 vs 0.00580 (worse)\nInterpretation: the construction is generating more profitable trades on average (higher return/IR) but with worse tail behavior (drawdown) and weaker linear day-ahead correlation (IC). This pattern is consistent with a regime/conditional effect (works well only in specific “gap shock + rejection + low vol” subsets), which can lift realized returns while depressing overall IC when evaluated across all days/instruments.",
        "hypothesis_evaluation": "Overall, the results **support** the hypothesis directionally, but only partially.\n- Support: The improvement in annualized return and IR is consistent with exploitable mean-reversion after certain gap shocks (liquidity-vacuum interpretation), especially because your features explicitly encode (i) abnormal gap size vs recent range, (ii) rejection via wick/close-back, and (iii) low relative volume gating.\n- Partial/refinement needed: The lower IC suggests the effect is not consistently present cross-sectionally every day; it likely behaves like a conditional/tail event alpha (strong when triggered, noisy otherwise). The worse max drawdown also suggests the signal can be wrong in “true information gap” regimes (earnings/news), or the current continuation vs contrarian mixing is not cleanly separating regimes.\n- Key implication: the framework seems right (gap + volume + rejection), but regime separation and robustness controls (news/high-vol trend days) need tightening to reduce drawdown and improve generalization.",
        "decision": true,
        "reason": "Why this refinement fits the observed metrics:\n- Higher return/IR but lower IC implies the alpha is concentrated in fewer event days (good PnL impact) but not a broad, stable correlation.\n- The worse drawdown is consistent with misclassifying some high-information gaps as mean-reverting. Your current “HighVol confirmation” factor uses only volume and gap size; it does not check whether price action actually *confirms* (e.g., closes near high/low, low wick, strong CLV).\n- Adding confirmation via price-action (close location / close-to-open / close-back fraction) should reduce contrarian trades during true trend continuation days.\n\nConcrete next-step factor enhancements (same theoretical framework, with explicit hyperparameters to explore):\n1) **Replace MA(H-L) with a closer ATR proxy**\n   - Current ATR proxy: MA_20(H-L)\n   - Try: MA_n( max(H-L, |H-C_{t-1}|, |L-C_{t-1}|) ) with n ∈ {10, 14, 20, 30}\n   - Rationale: true-range better captures gap risk and should normalize shock size more robustly.\n\n2) **Use “close-back fraction” of the gap rather than wick ratio alone**\n   - Define: CloseBack = 1 - |C_t - C_{t-1}| / (|O_t - C_{t-1}| + eps)\n   - Gate contrarian when CloseBack > θ, with θ ∈ {0.3, 0.5, 0.7}\n   - Keeps the core “rejection back toward prior close” concept but ties it directly to the gap event.\n\n3) **Stronger regime switch for continuation vs contrarian**\n   - Contrarian activation (low-information): RelVol = V_t / MA_m(V), m ∈ {10, 20, 60}; require RelVol < 1\n   - Continuation activation (high-information): require RelVol > 1 AND CLV close-to-extreme:\n     CLV = (2*C_t - H_t - L_t) / (H_t - L_t + eps); require |CLV| > κ with κ ∈ {0.3, 0.5, 0.7}\n   - This should directly address drawdown by avoiding fading days that close strongly at extremes.\n\n4) **Revisit TS_RANK windowing and simplify gating**\n   - Current: TS_RANK( gap_scaled, 60 ) and MA_20 normalizers\n   - Sweep: TS_RANK window r ∈ {20, 40, 60, 120}; range window n ∈ {10, 14, 20, 30}\n   - Consider replacing TS_RANK with TS_ZSCORE over r to reduce discontinuities.\n\n5) **Turnover/drawdown control aligned to 1–5D horizon**\n   - Even though evaluation shown is 1-day, your hypothesis is 1–5D. Consider a factor version that outputs a smoother signal:\n     Signal_smooth = TS_MEAN(F, k), k ∈ {2, 3, 5}\n   - This often reduces drawdown and improves stability (and will matter once costs are included).\n\nComplexity control check:\n- Current expressions are moderate and use a small base feature set ($open,$close,$high,$low,$volume). No obvious symbol-length or feature-count red flags. Keep it that way; add only 1–2 additional price-action terms (CloseBack/CLV) rather than layering many gates."
      }
    },
    "beffdb76d76468c0": {
      "factor_id": "beffdb76d76468c0",
      "factor_name": "HighVol_GapShock_Confirmation_Continuation_20ATR_60Rank",
      "factor_expression": "SIGN($open-DELAY($close,1))*TS_RANK(ABS($open/(DELAY($close,1)+1e-8)-1)/(TS_MEAN($high-$low,20)+1e-8),60)*MAX(0,$volume/(TS_MEAN($volume,20)+1e-8)-1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open-DELAY($close,1))*TS_RANK(ABS($open/(DELAY($close,1)+1e-8)-1)/(TS_MEAN($high-$low,20)+1e-8),60)*MAX(0,$volume/(TS_MEAN($volume,20)+1e-8)-1)\" # Your output factor expression will be filled in here\n    name = \"HighVol_GapShock_Confirmation_Continuation_20ATR_60Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation/anti-reversion score for volume-confirmed gaps: large gap shocks (scaled by 20D average range) with high relative volume are treated as higher-information events and thus aligned with the gap direction (reversion down-weighted).",
      "factor_formulation": "F_t=\\operatorname{sign}(O_t-C_{t-1})\\cdot \\operatorname{TS\\_RANK}\\left(\\frac{|O_t/C_{t-1}-1|}{\\operatorname{MA}_{20}(H-L)} ,60\\right)\\cdot \\max\\left(0,\\frac{V_t}{\\operatorname{MA}_{20}(V)}-1\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "756a5519a434",
        "parent_trajectory_ids": [
          "d559c63feb0c"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit mean-reversion after liquidity-vacuum gap shocks: when the open-to-prior-close gap is abnormally large versus recent true-range (ATR proxy), but the gap day shows low relative volume and strong intraday rejection back toward the prior close (large wick/close-back), the move is more likely an inventory/liquidity imbalance than new information and prices tend to revert over the next few days; gap shocks with high confirming volume should have weaker or opposite reversion.\n                Concise Observation: The available daily OHLCV data (open/high/low/close/volume) allows constructing event-style, single-day microstructure proxies—gap size vs rolling true-range, relative volume vs ADV, and wick/rejection anatomy—which are orthogonal to multi-day trend/breakout confirmation features emphasized by the parent strategy.\n                Concise Justification: A gap with low volume indicates weak participation and limited informational conviction, while an intraday rejection (wick + close-back toward prior close) indicates order-flow absorption and price discovery failure; under volatility expansion these dislocations are more frequent and, absent volume confirmation, tend to unwind via short-horizon mean-reversion.\n                Concise Knowledge: If a large overnight price gap is not supported by proportional trading volume and is reversed intraday (close-back with long wick), then the gap is more likely driven by transient liquidity/positioning rather than persistent information, so the next 1–5 trading days should exhibit mean-reversion in the direction opposite the gap; when volume confirms the gap, continuation risk increases and contrarian signals should be down-weighted.\n                concise Specification: Define gap_t = (open_t/(close_{t-1}+1e-8) - 1); TR_t = max(high_t-low_t, abs(high_t-close_{t-1}), abs(low_t-close_{t-1})); ATR20_t = TS_MEAN(TR,20); GapShock_t = abs(gap_t)/(ATR20_t+1e-8); RelVol_t = volume_t/(TS_MEAN(volume,20)+1e-8); Rejection_t = ( (high_t-max(open_t,close_t)) + (min(open_t,close_t)-low_t) )/(high_t-low_t+1e-8) * (1 - abs(close_t-close_{t-1})/(high_t-low_t+1e-8)); VolExpGate_t = 1{ TS_ZSCORE(TR,60) > 1.0 }; Hypothesis expects next 1–5D return ~ +[ -sign(gap_t) ] when VolExpGate_t=1, GapShock_t in top tail (e.g., TS_ZSCORE(GapShock,60)>1.5) AND RelVol_t low (e.g., RelVol_t<0.8) AND Rejection_t high (e.g., TS_ZSCORE(Rejection,60)>1.0), with the effect weakened or reversed when RelVol_t>1.2 (volume-confirmed gaps).\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-21T18:37:48.818362"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1092471247904156,
        "ICIR": 0.0373983474804837,
        "1day.excess_return_without_cost.std": 0.0041082972802677,
        "1day.excess_return_with_cost.annualized_return": 0.0204467743317592,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002858175547241,
        "1day.excess_return_without_cost.annualized_return": 0.0680245780243483,
        "1day.excess_return_with_cost.std": 0.0041095214693639,
        "Rank IC": 0.0196407613359077,
        "IC": 0.0049612872603487,
        "1day.excess_return_without_cost.max_drawdown": -0.0987065894936264,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.073286127083129,
        "1day.pa": 0.0,
        "l2.valid": 0.9969316814828256,
        "Rank ICIR": 0.1489881663966943,
        "l2.train": 0.9930197612880052,
        "1day.excess_return_with_cost.information_ratio": 0.3225114007867323,
        "1day.excess_return_with_cost.mean": 8.591081651999702e-05
      },
      "feedback": {
        "observations": "Compared to SOTA, the combined factor set improved portfolio-level performance but weakened pure predictive correlation.\n- Annualized return: 0.0680 vs 0.0520 (improved)\n- Information ratio: 1.0733 vs 0.9726 (improved)\n- Max drawdown: -0.0987 vs -0.0726 (worse; larger drawdown)\n- IC: 0.00496 vs 0.00580 (worse)\nInterpretation: the construction is generating more profitable trades on average (higher return/IR) but with worse tail behavior (drawdown) and weaker linear day-ahead correlation (IC). This pattern is consistent with a regime/conditional effect (works well only in specific “gap shock + rejection + low vol” subsets), which can lift realized returns while depressing overall IC when evaluated across all days/instruments.",
        "hypothesis_evaluation": "Overall, the results **support** the hypothesis directionally, but only partially.\n- Support: The improvement in annualized return and IR is consistent with exploitable mean-reversion after certain gap shocks (liquidity-vacuum interpretation), especially because your features explicitly encode (i) abnormal gap size vs recent range, (ii) rejection via wick/close-back, and (iii) low relative volume gating.\n- Partial/refinement needed: The lower IC suggests the effect is not consistently present cross-sectionally every day; it likely behaves like a conditional/tail event alpha (strong when triggered, noisy otherwise). The worse max drawdown also suggests the signal can be wrong in “true information gap” regimes (earnings/news), or the current continuation vs contrarian mixing is not cleanly separating regimes.\n- Key implication: the framework seems right (gap + volume + rejection), but regime separation and robustness controls (news/high-vol trend days) need tightening to reduce drawdown and improve generalization.",
        "decision": true,
        "reason": "Why this refinement fits the observed metrics:\n- Higher return/IR but lower IC implies the alpha is concentrated in fewer event days (good PnL impact) but not a broad, stable correlation.\n- The worse drawdown is consistent with misclassifying some high-information gaps as mean-reverting. Your current “HighVol confirmation” factor uses only volume and gap size; it does not check whether price action actually *confirms* (e.g., closes near high/low, low wick, strong CLV).\n- Adding confirmation via price-action (close location / close-to-open / close-back fraction) should reduce contrarian trades during true trend continuation days.\n\nConcrete next-step factor enhancements (same theoretical framework, with explicit hyperparameters to explore):\n1) **Replace MA(H-L) with a closer ATR proxy**\n   - Current ATR proxy: MA_20(H-L)\n   - Try: MA_n( max(H-L, |H-C_{t-1}|, |L-C_{t-1}|) ) with n ∈ {10, 14, 20, 30}\n   - Rationale: true-range better captures gap risk and should normalize shock size more robustly.\n\n2) **Use “close-back fraction” of the gap rather than wick ratio alone**\n   - Define: CloseBack = 1 - |C_t - C_{t-1}| / (|O_t - C_{t-1}| + eps)\n   - Gate contrarian when CloseBack > θ, with θ ∈ {0.3, 0.5, 0.7}\n   - Keeps the core “rejection back toward prior close” concept but ties it directly to the gap event.\n\n3) **Stronger regime switch for continuation vs contrarian**\n   - Contrarian activation (low-information): RelVol = V_t / MA_m(V), m ∈ {10, 20, 60}; require RelVol < 1\n   - Continuation activation (high-information): require RelVol > 1 AND CLV close-to-extreme:\n     CLV = (2*C_t - H_t - L_t) / (H_t - L_t + eps); require |CLV| > κ with κ ∈ {0.3, 0.5, 0.7}\n   - This should directly address drawdown by avoiding fading days that close strongly at extremes.\n\n4) **Revisit TS_RANK windowing and simplify gating**\n   - Current: TS_RANK( gap_scaled, 60 ) and MA_20 normalizers\n   - Sweep: TS_RANK window r ∈ {20, 40, 60, 120}; range window n ∈ {10, 14, 20, 30}\n   - Consider replacing TS_RANK with TS_ZSCORE over r to reduce discontinuities.\n\n5) **Turnover/drawdown control aligned to 1–5D horizon**\n   - Even though evaluation shown is 1-day, your hypothesis is 1–5D. Consider a factor version that outputs a smoother signal:\n     Signal_smooth = TS_MEAN(F, k), k ∈ {2, 3, 5}\n   - This often reduces drawdown and improves stability (and will matter once costs are included).\n\nComplexity control check:\n- Current expressions are moderate and use a small base feature set ($open,$close,$high,$low,$volume). No obvious symbol-length or feature-count red flags. Keep it that way; add only 1–2 additional price-action terms (CloseBack/CLV) rather than layering many gates."
      }
    },
    "25989c9981249031": {
      "factor_id": "25989c9981249031",
      "factor_name": "VolExp_Gated_LowVol_Rejection_Contrarian_60Z_20ADV",
      "factor_expression": "(TS_ZSCORE($high-$low,60)>1)?(-SIGN($open-DELAY($close,1))*(($high-MAX($open,$close)+MIN($open,$close)-$low)/($high-$low+1e-8))*MAX(0,1-$volume/(TS_MEAN($volume,20)+1e-8))):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_ZSCORE($high-$low,60)>1)?(-SIGN($open-DELAY($close,1))*(($high-MAX($open,$close)+MIN($open,$close)-$low)/($high-$low+1e-8))*MAX(0,1-$volume/(TS_MEAN($volume,20)+1e-8))):(0)\" # Your output factor expression will be filled in here\n    name = \"VolExp_Gated_LowVol_Rejection_Contrarian_60Z_20ADV\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Volatility-expansion gated contrarian signal: only activates when the daily range is abnormally high (60D z-score > 1). Within that regime, gaps with strong wick rejection and low relative volume are expected to mean-revert.",
      "factor_formulation": "F_t=\\mathbf{1}\\{Z_{60}(H_t-L_t)>1\\}\\cdot\\left[-\\operatorname{sign}(O_t-C_{t-1})\\cdot \\frac{(H_t-\\max(O_t,C_t))+(\\min(O_t,C_t)-L_t)}{H_t-L_t}\\cdot \\max\\left(0,1-\\frac{V_t}{\\operatorname{MA}_{20}(V)}\\right)\\right]",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "756a5519a434",
        "parent_trajectory_ids": [
          "d559c63feb0c"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit mean-reversion after liquidity-vacuum gap shocks: when the open-to-prior-close gap is abnormally large versus recent true-range (ATR proxy), but the gap day shows low relative volume and strong intraday rejection back toward the prior close (large wick/close-back), the move is more likely an inventory/liquidity imbalance than new information and prices tend to revert over the next few days; gap shocks with high confirming volume should have weaker or opposite reversion.\n                Concise Observation: The available daily OHLCV data (open/high/low/close/volume) allows constructing event-style, single-day microstructure proxies—gap size vs rolling true-range, relative volume vs ADV, and wick/rejection anatomy—which are orthogonal to multi-day trend/breakout confirmation features emphasized by the parent strategy.\n                Concise Justification: A gap with low volume indicates weak participation and limited informational conviction, while an intraday rejection (wick + close-back toward prior close) indicates order-flow absorption and price discovery failure; under volatility expansion these dislocations are more frequent and, absent volume confirmation, tend to unwind via short-horizon mean-reversion.\n                Concise Knowledge: If a large overnight price gap is not supported by proportional trading volume and is reversed intraday (close-back with long wick), then the gap is more likely driven by transient liquidity/positioning rather than persistent information, so the next 1–5 trading days should exhibit mean-reversion in the direction opposite the gap; when volume confirms the gap, continuation risk increases and contrarian signals should be down-weighted.\n                concise Specification: Define gap_t = (open_t/(close_{t-1}+1e-8) - 1); TR_t = max(high_t-low_t, abs(high_t-close_{t-1}), abs(low_t-close_{t-1})); ATR20_t = TS_MEAN(TR,20); GapShock_t = abs(gap_t)/(ATR20_t+1e-8); RelVol_t = volume_t/(TS_MEAN(volume,20)+1e-8); Rejection_t = ( (high_t-max(open_t,close_t)) + (min(open_t,close_t)-low_t) )/(high_t-low_t+1e-8) * (1 - abs(close_t-close_{t-1})/(high_t-low_t+1e-8)); VolExpGate_t = 1{ TS_ZSCORE(TR,60) > 1.0 }; Hypothesis expects next 1–5D return ~ +[ -sign(gap_t) ] when VolExpGate_t=1, GapShock_t in top tail (e.g., TS_ZSCORE(GapShock,60)>1.5) AND RelVol_t low (e.g., RelVol_t<0.8) AND Rejection_t high (e.g., TS_ZSCORE(Rejection,60)>1.0), with the effect weakened or reversed when RelVol_t>1.2 (volume-confirmed gaps).\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-21T18:37:48.818362"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1092471247904156,
        "ICIR": 0.0373983474804837,
        "1day.excess_return_without_cost.std": 0.0041082972802677,
        "1day.excess_return_with_cost.annualized_return": 0.0204467743317592,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002858175547241,
        "1day.excess_return_without_cost.annualized_return": 0.0680245780243483,
        "1day.excess_return_with_cost.std": 0.0041095214693639,
        "Rank IC": 0.0196407613359077,
        "IC": 0.0049612872603487,
        "1day.excess_return_without_cost.max_drawdown": -0.0987065894936264,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.073286127083129,
        "1day.pa": 0.0,
        "l2.valid": 0.9969316814828256,
        "Rank ICIR": 0.1489881663966943,
        "l2.train": 0.9930197612880052,
        "1day.excess_return_with_cost.information_ratio": 0.3225114007867323,
        "1day.excess_return_with_cost.mean": 8.591081651999702e-05
      },
      "feedback": {
        "observations": "Compared to SOTA, the combined factor set improved portfolio-level performance but weakened pure predictive correlation.\n- Annualized return: 0.0680 vs 0.0520 (improved)\n- Information ratio: 1.0733 vs 0.9726 (improved)\n- Max drawdown: -0.0987 vs -0.0726 (worse; larger drawdown)\n- IC: 0.00496 vs 0.00580 (worse)\nInterpretation: the construction is generating more profitable trades on average (higher return/IR) but with worse tail behavior (drawdown) and weaker linear day-ahead correlation (IC). This pattern is consistent with a regime/conditional effect (works well only in specific “gap shock + rejection + low vol” subsets), which can lift realized returns while depressing overall IC when evaluated across all days/instruments.",
        "hypothesis_evaluation": "Overall, the results **support** the hypothesis directionally, but only partially.\n- Support: The improvement in annualized return and IR is consistent with exploitable mean-reversion after certain gap shocks (liquidity-vacuum interpretation), especially because your features explicitly encode (i) abnormal gap size vs recent range, (ii) rejection via wick/close-back, and (iii) low relative volume gating.\n- Partial/refinement needed: The lower IC suggests the effect is not consistently present cross-sectionally every day; it likely behaves like a conditional/tail event alpha (strong when triggered, noisy otherwise). The worse max drawdown also suggests the signal can be wrong in “true information gap” regimes (earnings/news), or the current continuation vs contrarian mixing is not cleanly separating regimes.\n- Key implication: the framework seems right (gap + volume + rejection), but regime separation and robustness controls (news/high-vol trend days) need tightening to reduce drawdown and improve generalization.",
        "decision": true,
        "reason": "Why this refinement fits the observed metrics:\n- Higher return/IR but lower IC implies the alpha is concentrated in fewer event days (good PnL impact) but not a broad, stable correlation.\n- The worse drawdown is consistent with misclassifying some high-information gaps as mean-reverting. Your current “HighVol confirmation” factor uses only volume and gap size; it does not check whether price action actually *confirms* (e.g., closes near high/low, low wick, strong CLV).\n- Adding confirmation via price-action (close location / close-to-open / close-back fraction) should reduce contrarian trades during true trend continuation days.\n\nConcrete next-step factor enhancements (same theoretical framework, with explicit hyperparameters to explore):\n1) **Replace MA(H-L) with a closer ATR proxy**\n   - Current ATR proxy: MA_20(H-L)\n   - Try: MA_n( max(H-L, |H-C_{t-1}|, |L-C_{t-1}|) ) with n ∈ {10, 14, 20, 30}\n   - Rationale: true-range better captures gap risk and should normalize shock size more robustly.\n\n2) **Use “close-back fraction” of the gap rather than wick ratio alone**\n   - Define: CloseBack = 1 - |C_t - C_{t-1}| / (|O_t - C_{t-1}| + eps)\n   - Gate contrarian when CloseBack > θ, with θ ∈ {0.3, 0.5, 0.7}\n   - Keeps the core “rejection back toward prior close” concept but ties it directly to the gap event.\n\n3) **Stronger regime switch for continuation vs contrarian**\n   - Contrarian activation (low-information): RelVol = V_t / MA_m(V), m ∈ {10, 20, 60}; require RelVol < 1\n   - Continuation activation (high-information): require RelVol > 1 AND CLV close-to-extreme:\n     CLV = (2*C_t - H_t - L_t) / (H_t - L_t + eps); require |CLV| > κ with κ ∈ {0.3, 0.5, 0.7}\n   - This should directly address drawdown by avoiding fading days that close strongly at extremes.\n\n4) **Revisit TS_RANK windowing and simplify gating**\n   - Current: TS_RANK( gap_scaled, 60 ) and MA_20 normalizers\n   - Sweep: TS_RANK window r ∈ {20, 40, 60, 120}; range window n ∈ {10, 14, 20, 30}\n   - Consider replacing TS_RANK with TS_ZSCORE over r to reduce discontinuities.\n\n5) **Turnover/drawdown control aligned to 1–5D horizon**\n   - Even though evaluation shown is 1-day, your hypothesis is 1–5D. Consider a factor version that outputs a smoother signal:\n     Signal_smooth = TS_MEAN(F, k), k ∈ {2, 3, 5}\n   - This often reduces drawdown and improves stability (and will matter once costs are included).\n\nComplexity control check:\n- Current expressions are moderate and use a small base feature set ($open,$close,$high,$low,$volume). No obvious symbol-length or feature-count red flags. Keep it that way; add only 1–2 additional price-action terms (CloseBack/CLV) rather than layering many gates."
      }
    },
    "a7a1f0f562d82339": {
      "factor_id": "a7a1f0f562d82339",
      "factor_name": "Underreaction_CMF20_Cap15",
      "factor_expression": "(ABS($close/DELAY($close,20)-1)<0.15)?(TS_SUM(((2*$close-$high-$low)/($high-$low+1e-8))*$volume,20)/(TS_SUM($volume,20)+1e-8)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($close/DELAY($close,20)-1)<0.15)?(TS_SUM(((2*$close-$high-$low)/($high-$low+1e-8))*$volume,20)/(TS_SUM($volume,20)+1e-8)):(0)\" # Your output factor expression will be filled in here\n    name = \"Underreaction_CMF20_Cap15\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "20-day close-location value (CLV) weighted by volume (CMF-style) to proxy persistent directional money-flow pressure, applied only when the last 20-day price move is non-extreme (|RET_20|<0.15) to target underreaction-driven 10–30D continuation.",
      "factor_formulation": "F=\\mathbf{1}(|\\frac{C_t}{C_{t-20}}-1|<0.15)\\cdot\\frac{\\sum_{i=0}^{19}\\left(\\frac{2C_{t-i}-H_{t-i}-L_{t-i}}{H_{t-i}-L_{t-i}+\\epsilon}\\right)V_{t-i}}{\\sum_{i=0}^{19}V_{t-i}+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "da30c1e09918",
        "parent_trajectory_ids": [
          "6bb324f23e35"
        ],
        "hypothesis": "Hypothesis: Intermediate-horizon (10–30D) return continuation is stronger when a stock shows persistent close-location dominance (closes repeatedly near the daily high/low) on above-normal volume while cumulative returns remain non-extreme, consistent with stealth accumulation/distribution that underreacts in price and later drifts in the same direction.\n                Concise Observation: Only OHLCV is available, so stealth positioning can be proxied by rolling money-flow pressure (CLV×volume), its persistence/slope, and a filter that caps recent return magnitude to avoid obvious momentum; this uses multi-week flow persistence rather than short-horizon gap/shock/rejection anatomy in the parent strategy.\n                Concise Justification: Persistent closes near the high (low) with elevated volume imply directional demand (supply) absorbing liquidity without large daily repricing; limiting the recent return magnitude targets underreaction regimes where the remaining drift is highest, aligning the signal with 10–30D continuation rather than 1–5D reversal after dislocations.\n                Concise Knowledge: If informed inventory transfer occurs incrementally, then multi-week persistence of positive (negative) close-location value weighted by volume can precede 10–30D upside (downside) drift even when realized returns are only moderate; when returns are already extreme, the same flow signal is more likely fully priced and less predictive.\n                concise Specification: Construct a 20–60D flow-pressure factor such as (i) CMF_20 = SUM(((2*close-low-high)/(high-low+1e-6))*volume,20)/SUM(volume,20) and/or (ii) AD_slope_60 = TS_SLOPE(SUM(((2*close-low-high)/(high-low+1e-6))*volume,1).cumsum(),60); apply an underreaction filter requiring ABS(RET_20) below a fixed cap (e.g., ABS(close/DELAY(close,20)-1) < 0.15) or below a 20D return z-score threshold; expected sign: higher flow-pressure predicts higher 10–30D forward returns, lower predicts lower, tested cross-sectionally with fixed windows (e.g., 20D CMF and 60D slope as separate factors).\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-21T18:45:57.155870"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0927241159383997,
        "ICIR": 0.0375207012589348,
        "1day.excess_return_without_cost.std": 0.0040143101794668,
        "1day.excess_return_with_cost.annualized_return": 0.0038202304872767,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002148028353866,
        "1day.excess_return_without_cost.annualized_return": 0.0511230748220318,
        "1day.excess_return_with_cost.std": 0.0040152238242816,
        "Rank IC": 0.0193248252251404,
        "IC": 0.0049539926479577,
        "1day.excess_return_without_cost.max_drawdown": -0.0701441360949088,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8255009198984776,
        "1day.pa": 0.0,
        "l2.valid": 0.9967349656428652,
        "Rank ICIR": 0.1499627887731965,
        "l2.train": 0.9935540786548483,
        "1day.excess_return_with_cost.information_ratio": 0.0616724679631856,
        "1day.excess_return_with_cost.mean": 1.605138860200336e-05
      },
      "feedback": {
        "observations": "All three implemented factors are consistent with the same “persistent close-location dominance × volume” concept and include an explicit non-extreme 20D return regime filter (|RET_20| or |SUM(r,20)| < 0.15). The combined run delivers positive predictability (IC=0.004954, IR=0.8255) and a positive annualized excess return (5.11%), so the signal is not random. However, versus SOTA the predictive strength and return efficiency deteriorate: IC (0.004954 < 0.005798), IR (0.8255 < 0.9726), and annualized return (0.0511 < 0.0520). Max drawdown is slightly better (smaller is better): -0.0701 vs -0.0726.",
        "hypothesis_evaluation": "Overall this run weakly supports the hypothesis directionally (positive IC/IR and positive annualized return), but it does NOT strengthen the evidence relative to SOTA because the key “skill” metrics (IC, IR) and annualized return all decline.\n\nWhat likely happened within this hypothesis framework:\n- The hard regime gate (indicator 1(|RET_20|<0.15) with threshold=0.15) may be too blunt: it can drop many samples and introduce discontinuities, reducing model stability and cross-sectional coverage.\n- The CLV definition ( (2C-H-L)/(H-L+eps) ) is sensitive to small intraday ranges (H≈L). Even with eps, micro-range days can inject noise, especially when multiplied by raw volume.\n- Using raw volume (not normalized by ADV or z-scored) makes the factor partly a size/liquidity proxy; this can dilute the intended “stealth accumulation/distribution” effect unless explicitly normalized or neutralized.\n\nHyperparameters explicitly present in this iteration:\n- Underreaction_CMF20_Cap15: window=20 for TS_SUM numerator/denominator; return lookback=20 via C_t/C_{t-20}-1; cap threshold=0.15; epsilon in range/volume denominators.\n- FlowPressure_Trend10of20_CapRet20_015: MA window=20; DELTA lookback=10; return cap uses TS_SUM window=20 and threshold=0.15.\n- CLV_VolumeZ_Corr30_CapRet20_015: correlation window=30; volume z-score window=30; return cap TS_SUM window=20 and threshold=0.15.\n\nConclusion: the hypothesis is not refuted (signal remains positive), but current implementations/parameterization are not yet an improvement over the best-known configuration.",
        "decision": false,
        "reason": "Your current framework is right, but the weakest link is likely regime definition + scaling:\n- A hard cap |RET_20|<0.15 treats a +14.9% move as “underreaction” and a +15.1% move as “not underreaction,” which is economically arbitrary and statistically discontinuous.\n- “Non-extreme” should be volatility-aware (e.g., |RET_20| / Vol_20 < k) or smoothly downweighted (e.g., multiply by max(0, 1 - |RET_20|/0.15)). This keeps coverage and reduces threshold sensitivity.\n- Raw volume multiplication makes the factor sensitive to structural differences in trading activity. Normalizing volume by ADV (e.g., V/MA(V,20)) or using time-series z-scored volume inside the CMF-style aggregation should align better with “above-normal volume” in the hypothesis.\n\nConcrete next iterations (stay within the same hypothesis, but refine construction):\n1) Replace hard indicator with a smooth gate (same cap value, less discontinuity):\n   - GateSmooth = clip(1 - |RET_20|/0.15, 0, 1)\n   - or GateVolAdj = clip(1 - |RET_20|/(k*Vol_20), 0, 1) (test k in [1.5, 2.0, 2.5]).\n2) Volume normalization variants (define as separate factors, not parameterized on the fly):\n   - Use V_norm = V / MA(V,20) (ADV20) instead of raw V.\n   - Use Z_30(V) or rank(V/ADV20) inside the CMF aggregation.\n3) Persistence emphasis (closer to “repeatedly near high/low”):\n   - Add a persistence operator on CLV: TS_MEAN(CLV,20) or TS_SUM(sign(CLV),20) and then weight by abnormal volume.\n4) Parameter sweeps (create distinct factors):\n   - Windows: 10/15/20/30 for CMF-style; Corr windows: 20/30/60; Delta: 5/10/20.\n   - Return cap thresholds: 0.10 / 0.15 / 0.20 (each as separate factor definitions).\n5) Robustness tweaks to CLV:\n   - Exclude or downweight days with very small (H-L) relative to price (e.g., (H-L)/C below a percentile), because CLV becomes noisy.\n\nThese changes directly target the hypothesis statement (persistent close-location + above-normal volume + non-extreme returns) while improving stability and reducing sensitivity to arbitrary thresholds."
      }
    },
    "8d1d3c934f6a3ac0": {
      "factor_id": "8d1d3c934f6a3ac0",
      "factor_name": "FlowPressure_Trend10of20_CapRet20_015",
      "factor_expression": "(ABS(TS_SUM($return,20))<0.15)?(DELTA(TS_MEAN(((2*$close-$high-$low)/($high-$low+1e-8))*$volume,20),10)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(TS_SUM($close/DELAY($close,1)-1,20))<0.15)?(DELTA(TS_MEAN(((2*$close-$high-$low)/($high-$low+1e-8))*$volume,20),10)):(0)\" # Your output factor expression will be filled in here\n    name = \"FlowPressure_Trend10of20_CapRet20_015\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the 10-day change in the 20-day average of CLV×volume (a simple flow-pressure trend proxy). Activates only when the cumulative 20-day return is non-extreme (|SUM(return,20)|<0.15) to focus on stealth accumulation/distribution regimes that may drift over the next 10–30D.",
      "factor_formulation": "F=\\mathbf{1}(|\\sum_{i=0}^{19}r_{t-i}|<0.15)\\cdot\\Delta_{10}\\left(\\text{MA}_{20}\\left(\\frac{2C-H-L}{H-L+\\epsilon}\\cdot V\\right)\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "da30c1e09918",
        "parent_trajectory_ids": [
          "6bb324f23e35"
        ],
        "hypothesis": "Hypothesis: Intermediate-horizon (10–30D) return continuation is stronger when a stock shows persistent close-location dominance (closes repeatedly near the daily high/low) on above-normal volume while cumulative returns remain non-extreme, consistent with stealth accumulation/distribution that underreacts in price and later drifts in the same direction.\n                Concise Observation: Only OHLCV is available, so stealth positioning can be proxied by rolling money-flow pressure (CLV×volume), its persistence/slope, and a filter that caps recent return magnitude to avoid obvious momentum; this uses multi-week flow persistence rather than short-horizon gap/shock/rejection anatomy in the parent strategy.\n                Concise Justification: Persistent closes near the high (low) with elevated volume imply directional demand (supply) absorbing liquidity without large daily repricing; limiting the recent return magnitude targets underreaction regimes where the remaining drift is highest, aligning the signal with 10–30D continuation rather than 1–5D reversal after dislocations.\n                Concise Knowledge: If informed inventory transfer occurs incrementally, then multi-week persistence of positive (negative) close-location value weighted by volume can precede 10–30D upside (downside) drift even when realized returns are only moderate; when returns are already extreme, the same flow signal is more likely fully priced and less predictive.\n                concise Specification: Construct a 20–60D flow-pressure factor such as (i) CMF_20 = SUM(((2*close-low-high)/(high-low+1e-6))*volume,20)/SUM(volume,20) and/or (ii) AD_slope_60 = TS_SLOPE(SUM(((2*close-low-high)/(high-low+1e-6))*volume,1).cumsum(),60); apply an underreaction filter requiring ABS(RET_20) below a fixed cap (e.g., ABS(close/DELAY(close,20)-1) < 0.15) or below a 20D return z-score threshold; expected sign: higher flow-pressure predicts higher 10–30D forward returns, lower predicts lower, tested cross-sectionally with fixed windows (e.g., 20D CMF and 60D slope as separate factors).\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-21T18:45:57.155870"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0927241159383997,
        "ICIR": 0.0375207012589348,
        "1day.excess_return_without_cost.std": 0.0040143101794668,
        "1day.excess_return_with_cost.annualized_return": 0.0038202304872767,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002148028353866,
        "1day.excess_return_without_cost.annualized_return": 0.0511230748220318,
        "1day.excess_return_with_cost.std": 0.0040152238242816,
        "Rank IC": 0.0193248252251404,
        "IC": 0.0049539926479577,
        "1day.excess_return_without_cost.max_drawdown": -0.0701441360949088,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8255009198984776,
        "1day.pa": 0.0,
        "l2.valid": 0.9967349656428652,
        "Rank ICIR": 0.1499627887731965,
        "l2.train": 0.9935540786548483,
        "1day.excess_return_with_cost.information_ratio": 0.0616724679631856,
        "1day.excess_return_with_cost.mean": 1.605138860200336e-05
      },
      "feedback": {
        "observations": "All three implemented factors are consistent with the same “persistent close-location dominance × volume” concept and include an explicit non-extreme 20D return regime filter (|RET_20| or |SUM(r,20)| < 0.15). The combined run delivers positive predictability (IC=0.004954, IR=0.8255) and a positive annualized excess return (5.11%), so the signal is not random. However, versus SOTA the predictive strength and return efficiency deteriorate: IC (0.004954 < 0.005798), IR (0.8255 < 0.9726), and annualized return (0.0511 < 0.0520). Max drawdown is slightly better (smaller is better): -0.0701 vs -0.0726.",
        "hypothesis_evaluation": "Overall this run weakly supports the hypothesis directionally (positive IC/IR and positive annualized return), but it does NOT strengthen the evidence relative to SOTA because the key “skill” metrics (IC, IR) and annualized return all decline.\n\nWhat likely happened within this hypothesis framework:\n- The hard regime gate (indicator 1(|RET_20|<0.15) with threshold=0.15) may be too blunt: it can drop many samples and introduce discontinuities, reducing model stability and cross-sectional coverage.\n- The CLV definition ( (2C-H-L)/(H-L+eps) ) is sensitive to small intraday ranges (H≈L). Even with eps, micro-range days can inject noise, especially when multiplied by raw volume.\n- Using raw volume (not normalized by ADV or z-scored) makes the factor partly a size/liquidity proxy; this can dilute the intended “stealth accumulation/distribution” effect unless explicitly normalized or neutralized.\n\nHyperparameters explicitly present in this iteration:\n- Underreaction_CMF20_Cap15: window=20 for TS_SUM numerator/denominator; return lookback=20 via C_t/C_{t-20}-1; cap threshold=0.15; epsilon in range/volume denominators.\n- FlowPressure_Trend10of20_CapRet20_015: MA window=20; DELTA lookback=10; return cap uses TS_SUM window=20 and threshold=0.15.\n- CLV_VolumeZ_Corr30_CapRet20_015: correlation window=30; volume z-score window=30; return cap TS_SUM window=20 and threshold=0.15.\n\nConclusion: the hypothesis is not refuted (signal remains positive), but current implementations/parameterization are not yet an improvement over the best-known configuration.",
        "decision": false,
        "reason": "Your current framework is right, but the weakest link is likely regime definition + scaling:\n- A hard cap |RET_20|<0.15 treats a +14.9% move as “underreaction” and a +15.1% move as “not underreaction,” which is economically arbitrary and statistically discontinuous.\n- “Non-extreme” should be volatility-aware (e.g., |RET_20| / Vol_20 < k) or smoothly downweighted (e.g., multiply by max(0, 1 - |RET_20|/0.15)). This keeps coverage and reduces threshold sensitivity.\n- Raw volume multiplication makes the factor sensitive to structural differences in trading activity. Normalizing volume by ADV (e.g., V/MA(V,20)) or using time-series z-scored volume inside the CMF-style aggregation should align better with “above-normal volume” in the hypothesis.\n\nConcrete next iterations (stay within the same hypothesis, but refine construction):\n1) Replace hard indicator with a smooth gate (same cap value, less discontinuity):\n   - GateSmooth = clip(1 - |RET_20|/0.15, 0, 1)\n   - or GateVolAdj = clip(1 - |RET_20|/(k*Vol_20), 0, 1) (test k in [1.5, 2.0, 2.5]).\n2) Volume normalization variants (define as separate factors, not parameterized on the fly):\n   - Use V_norm = V / MA(V,20) (ADV20) instead of raw V.\n   - Use Z_30(V) or rank(V/ADV20) inside the CMF aggregation.\n3) Persistence emphasis (closer to “repeatedly near high/low”):\n   - Add a persistence operator on CLV: TS_MEAN(CLV,20) or TS_SUM(sign(CLV),20) and then weight by abnormal volume.\n4) Parameter sweeps (create distinct factors):\n   - Windows: 10/15/20/30 for CMF-style; Corr windows: 20/30/60; Delta: 5/10/20.\n   - Return cap thresholds: 0.10 / 0.15 / 0.20 (each as separate factor definitions).\n5) Robustness tweaks to CLV:\n   - Exclude or downweight days with very small (H-L) relative to price (e.g., (H-L)/C below a percentile), because CLV becomes noisy.\n\nThese changes directly target the hypothesis statement (persistent close-location + above-normal volume + non-extreme returns) while improving stability and reducing sensitivity to arbitrary thresholds."
      }
    },
    "900bee891344de6e": {
      "factor_id": "900bee891344de6e",
      "factor_name": "CLV_VolumeZ_Corr30_CapRet20_015",
      "factor_expression": "(ABS(TS_SUM($return,20))<0.15)?(TS_CORR((2*$close-$high-$low)/($high-$low+1e-8),TS_ZSCORE($volume,30),30)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(TS_SUM($close/DELAY($close,1)-1,20))<0.15)?(TS_CORR((2*$close-$high-$low)/($high-$low+1e-8),TS_ZSCORE($volume,30),30)):(0)\" # Your output factor expression will be filled in here\n    name = \"CLV_VolumeZ_Corr30_CapRet20_015\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "30-day correlation between CLV (close location within the daily range) and abnormal volume (30D time-series z-score). Positive values indicate closes near the high (low) tend to coincide with above-normal volume persistently; filtered to non-extreme 20D returns (|SUM(return,20)|<0.15).",
      "factor_formulation": "F=\\mathbf{1}(|\\sum_{i=0}^{19}r_{t-i}|<0.15)\\cdot\\text{Corr}_{30}\\left(\\frac{2C-H-L}{H-L+\\epsilon},\\;Z_{30}(V)\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "da30c1e09918",
        "parent_trajectory_ids": [
          "6bb324f23e35"
        ],
        "hypothesis": "Hypothesis: Intermediate-horizon (10–30D) return continuation is stronger when a stock shows persistent close-location dominance (closes repeatedly near the daily high/low) on above-normal volume while cumulative returns remain non-extreme, consistent with stealth accumulation/distribution that underreacts in price and later drifts in the same direction.\n                Concise Observation: Only OHLCV is available, so stealth positioning can be proxied by rolling money-flow pressure (CLV×volume), its persistence/slope, and a filter that caps recent return magnitude to avoid obvious momentum; this uses multi-week flow persistence rather than short-horizon gap/shock/rejection anatomy in the parent strategy.\n                Concise Justification: Persistent closes near the high (low) with elevated volume imply directional demand (supply) absorbing liquidity without large daily repricing; limiting the recent return magnitude targets underreaction regimes where the remaining drift is highest, aligning the signal with 10–30D continuation rather than 1–5D reversal after dislocations.\n                Concise Knowledge: If informed inventory transfer occurs incrementally, then multi-week persistence of positive (negative) close-location value weighted by volume can precede 10–30D upside (downside) drift even when realized returns are only moderate; when returns are already extreme, the same flow signal is more likely fully priced and less predictive.\n                concise Specification: Construct a 20–60D flow-pressure factor such as (i) CMF_20 = SUM(((2*close-low-high)/(high-low+1e-6))*volume,20)/SUM(volume,20) and/or (ii) AD_slope_60 = TS_SLOPE(SUM(((2*close-low-high)/(high-low+1e-6))*volume,1).cumsum(),60); apply an underreaction filter requiring ABS(RET_20) below a fixed cap (e.g., ABS(close/DELAY(close,20)-1) < 0.15) or below a 20D return z-score threshold; expected sign: higher flow-pressure predicts higher 10–30D forward returns, lower predicts lower, tested cross-sectionally with fixed windows (e.g., 20D CMF and 60D slope as separate factors).\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-21T18:45:57.155870"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0927241159383997,
        "ICIR": 0.0375207012589348,
        "1day.excess_return_without_cost.std": 0.0040143101794668,
        "1day.excess_return_with_cost.annualized_return": 0.0038202304872767,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002148028353866,
        "1day.excess_return_without_cost.annualized_return": 0.0511230748220318,
        "1day.excess_return_with_cost.std": 0.0040152238242816,
        "Rank IC": 0.0193248252251404,
        "IC": 0.0049539926479577,
        "1day.excess_return_without_cost.max_drawdown": -0.0701441360949088,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8255009198984776,
        "1day.pa": 0.0,
        "l2.valid": 0.9967349656428652,
        "Rank ICIR": 0.1499627887731965,
        "l2.train": 0.9935540786548483,
        "1day.excess_return_with_cost.information_ratio": 0.0616724679631856,
        "1day.excess_return_with_cost.mean": 1.605138860200336e-05
      },
      "feedback": {
        "observations": "All three implemented factors are consistent with the same “persistent close-location dominance × volume” concept and include an explicit non-extreme 20D return regime filter (|RET_20| or |SUM(r,20)| < 0.15). The combined run delivers positive predictability (IC=0.004954, IR=0.8255) and a positive annualized excess return (5.11%), so the signal is not random. However, versus SOTA the predictive strength and return efficiency deteriorate: IC (0.004954 < 0.005798), IR (0.8255 < 0.9726), and annualized return (0.0511 < 0.0520). Max drawdown is slightly better (smaller is better): -0.0701 vs -0.0726.",
        "hypothesis_evaluation": "Overall this run weakly supports the hypothesis directionally (positive IC/IR and positive annualized return), but it does NOT strengthen the evidence relative to SOTA because the key “skill” metrics (IC, IR) and annualized return all decline.\n\nWhat likely happened within this hypothesis framework:\n- The hard regime gate (indicator 1(|RET_20|<0.15) with threshold=0.15) may be too blunt: it can drop many samples and introduce discontinuities, reducing model stability and cross-sectional coverage.\n- The CLV definition ( (2C-H-L)/(H-L+eps) ) is sensitive to small intraday ranges (H≈L). Even with eps, micro-range days can inject noise, especially when multiplied by raw volume.\n- Using raw volume (not normalized by ADV or z-scored) makes the factor partly a size/liquidity proxy; this can dilute the intended “stealth accumulation/distribution” effect unless explicitly normalized or neutralized.\n\nHyperparameters explicitly present in this iteration:\n- Underreaction_CMF20_Cap15: window=20 for TS_SUM numerator/denominator; return lookback=20 via C_t/C_{t-20}-1; cap threshold=0.15; epsilon in range/volume denominators.\n- FlowPressure_Trend10of20_CapRet20_015: MA window=20; DELTA lookback=10; return cap uses TS_SUM window=20 and threshold=0.15.\n- CLV_VolumeZ_Corr30_CapRet20_015: correlation window=30; volume z-score window=30; return cap TS_SUM window=20 and threshold=0.15.\n\nConclusion: the hypothesis is not refuted (signal remains positive), but current implementations/parameterization are not yet an improvement over the best-known configuration.",
        "decision": false,
        "reason": "Your current framework is right, but the weakest link is likely regime definition + scaling:\n- A hard cap |RET_20|<0.15 treats a +14.9% move as “underreaction” and a +15.1% move as “not underreaction,” which is economically arbitrary and statistically discontinuous.\n- “Non-extreme” should be volatility-aware (e.g., |RET_20| / Vol_20 < k) or smoothly downweighted (e.g., multiply by max(0, 1 - |RET_20|/0.15)). This keeps coverage and reduces threshold sensitivity.\n- Raw volume multiplication makes the factor sensitive to structural differences in trading activity. Normalizing volume by ADV (e.g., V/MA(V,20)) or using time-series z-scored volume inside the CMF-style aggregation should align better with “above-normal volume” in the hypothesis.\n\nConcrete next iterations (stay within the same hypothesis, but refine construction):\n1) Replace hard indicator with a smooth gate (same cap value, less discontinuity):\n   - GateSmooth = clip(1 - |RET_20|/0.15, 0, 1)\n   - or GateVolAdj = clip(1 - |RET_20|/(k*Vol_20), 0, 1) (test k in [1.5, 2.0, 2.5]).\n2) Volume normalization variants (define as separate factors, not parameterized on the fly):\n   - Use V_norm = V / MA(V,20) (ADV20) instead of raw V.\n   - Use Z_30(V) or rank(V/ADV20) inside the CMF aggregation.\n3) Persistence emphasis (closer to “repeatedly near high/low”):\n   - Add a persistence operator on CLV: TS_MEAN(CLV,20) or TS_SUM(sign(CLV),20) and then weight by abnormal volume.\n4) Parameter sweeps (create distinct factors):\n   - Windows: 10/15/20/30 for CMF-style; Corr windows: 20/30/60; Delta: 5/10/20.\n   - Return cap thresholds: 0.10 / 0.15 / 0.20 (each as separate factor definitions).\n5) Robustness tweaks to CLV:\n   - Exclude or downweight days with very small (H-L) relative to price (e.g., (H-L)/C below a percentile), because CLV becomes noisy.\n\nThese changes directly target the hypothesis statement (persistent close-location + above-normal volume + non-extreme returns) while improving stability and reducing sensitivity to arbitrary thresholds."
      }
    },
    "9a0fcd5092821202": {
      "factor_id": "9a0fcd5092821202",
      "factor_name": "GapFade_Rejection_VolWeak_20D",
      "factor_expression": "(($open/DELAY($close,1)-1)/(TS_MEAN(ABS($open/DELAY($close,1)-1),20)+1e-8))*(-SIGN($open-DELAY($close,1))*((($close-$low)-($high-$close))/(($high-$low)+1e-8)))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open/DELAY($close,1)-1)/(TS_MEAN(ABS($open/DELAY($close,1)-1),20)+1e-8))*(-SIGN($open-DELAY($close,1))*((($close-$low)-($high-$close))/(($high-$low)+1e-8)))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))\" # Your output factor expression will be filled in here\n    name = \"GapFade_Rejection_VolWeak_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Symmetric gap-fade score: large overnight gap (open vs prior close) normalized by 20D average absolute gap, multiplied by intraday rejection (close-location-in-range aligned against the gap direction) and penalized by weak volume confirmation (below 20D average volume). Lookback=20 days.",
      "factor_formulation": "g_t=\\frac{open_t}{close_{t-1}}-1,\\quad g^{norm}_t=\\frac{g_t}{\\text{MEAN}_{20}(|g|)+\\epsilon}\\\\CLV_t=\\frac{(close_t-low_t)-(high_t-close_t)}{(high_t-low_t)+\\epsilon}\\\\rej_t=-\\text{SIGN}(open_t-close_{t-1})\\cdot CLV_t\\\\volweak_t=1-\\min\\left(\\frac{vol_t}{\\text{MEAN}_{20}(vol)+\\epsilon},1\\right)\\\\Factor_t=g^{norm}_t\\cdot rej_t\\cdot volweak_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "fce14873707e",
        "parent_trajectory_ids": [
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: If a stock exhibits an abnormally large overnight gap (open vs prev_close) but shows intraday rejection (close ends near the opposite end of the day’s range and intraday return offsets the gap) with weak volume confirmation, then the gap is more likely an overreaction and the stock will mean-revert over the next 1–3 trading days (gap-fade), symmetrically for gap-ups and gap-downs.\n                Concise Observation: Available OHLCV data supports direct construction of gap magnitude, intraday rejection (close-location in range, wick/body style), and volume confirmation features that target a different mechanism than trend-quality/liquidity re-rating continuation signals, helping reduce factor correlation with the parent strategy.\n                Concise Justification: A large gap without intraday follow-through and without volume confirmation implies that marginal buyers/sellers were exhausted near the open and subsequent trading rejected the new price level; market makers and short-term traders commonly fade such failed breakouts, creating predictable 1–3 day mean-reversion pressure.\n                Concise Knowledge: If price discovery is incomplete at the open, then large overnight gaps that fail to attract sustained daytime participation (rejection candles + sub-average volume) tend to reflect temporary order-imbalance and liquidity-provider inventory effects; when this occurs, short-horizon returns are more likely to reverse than continue, especially when the gap size is large relative to recent true range/gap volatility.\n                concise Specification: Construct a symmetric gap-fade score using only daily_pv.h5 OHLCV with fixed hyperparameters: gap = (open/DELAY(close,1)-1); gap_z = gap / (TS_MEAN(ABS(gap),20)+1e-8) and/or gap_atr = gap / (TS_MEAN(high-low,20)+1e-8); rejection = -SIGN(gap)*CLV where CLV = ((close-low)-(high-close))/((high-low)+1e-8) (so gap-up + close near low => high rejection, gap-down + close near high => high rejection); followthrough = -SIGN(gap)*(close/open-1) (positive when the session moves against the gap); vol_confirm = 1 - MIN(volume/(TS_MEAN(volume,20)+1e-8), 1) (higher when volume is below average); final factor = gap_z * (0.5*rejection + 0.5*followthrough) * vol_confirm, optionally winsorized by capping |gap_z| at 3 to avoid earnings-like extremes; expected relationship: higher factor predicts stronger next 1–3 day reversal (negative next-day return after positive gap-fade signal for gap-ups, and vice versa for gap-downs).\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-21T18:51:30.638303"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1036469815146556,
        "ICIR": 0.0462818174363058,
        "1day.excess_return_without_cost.std": 0.0041020001430463,
        "1day.excess_return_with_cost.annualized_return": 0.0401780589079599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003673799470357,
        "1day.excess_return_without_cost.annualized_return": 0.0874364273945147,
        "1day.excess_return_with_cost.std": 0.0041030137297135,
        "Rank IC": 0.0208088401469987,
        "IC": 0.0064056347016531,
        "1day.excess_return_without_cost.max_drawdown": -0.0894843221430379,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3816824923153743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967628683606692,
        "Rank ICIR": 0.152838071150687,
        "l2.train": 0.9934570258322084,
        "1day.excess_return_with_cost.information_ratio": 0.6347423894936896,
        "1day.excess_return_with_cost.mean": 0.0001688153735628
      },
      "feedback": {
        "observations": "The combined experiment improves the core predictive/return metrics versus SOTA: annualized excess return rises from 0.0520 to 0.0874, information ratio from 0.9726 to 1.3817, and IC from 0.00580 to 0.00641. However, max drawdown worsens (more negative) from -0.0726 to -0.0895, indicating the signal likely concentrates risk in a subset of adverse regimes/events (e.g., news/earnings gaps, market stress, or illiquidity) even though the average edge is stronger.",
        "hypothesis_evaluation": "Overall the results support the hypothesis: the factor family designed to capture (i) abnormal overnight gap, (ii) intraday rejection/lack of follow-through, and (iii) weak volume confirmation appears to predict next-day mean reversion (higher IC and materially better IR/return). The deterioration in max drawdown does not refute the hypothesis, but it suggests the gap-fade effect is regime-dependent and occasionally fails catastrophically (likely on true-information gaps) — exactly the scenario where \"overreaction\" is false. This implies the framework is correct, but it needs a robustness filter to separate overreaction gaps from information gaps.\n\nHyperparameters explicitly present in your current implementations:\n- Lookback window for normalization/means/zscore: 20 trading days (all three)\n- Gap normalization method: 20D mean(|gap|) vs 20D mean(high-low) vs 20D z-score\n- Z-score cap: |z| <= 3 (third factor)\n- Volume weakness definition: 1 - min(vol / mean_20(vol), 1)\n\nKey construction notes to refine within the same framework:\n1) Volume confirmation is one-sided capped (only penalizes high volume; treats very low volume almost linearly). Consider making it symmetric/robust (z-score or log ratio) to avoid overweighting microcap/illiquid artifacts.\n2) Intraday rejection via CLV is good, but sensitive to (high-low) near zero and to noisy extremes; consider alternative rejection proxies (close vs VWAP if available; otherwise close position vs open and midpoint) and add small-range guards.\n3) The worse drawdown strongly hints the signal is getting hit on “true breakaway gaps” (earnings/news). Your capped z-score variant helps, but may not be sufficient; consider explicit gating rather than only capping.",
        "decision": true,
        "reason": "Why the current metrics pattern happens:\n- Higher annualized return + higher IR + slightly higher IC indicates the signal is directionally correct and exploitable on average.\n- Worse max drawdown suggests tail events where the model repeatedly fades gaps that continue trending (information gaps). This is consistent with the hypothesis boundary conditions.\n\nConcrete next iterations (still the same theoretical concept; just refined implementations):\n1) Add a gap-magnitude gate (separate factors by design; static hyperparameters):\n   - Only trade when |g_norm| > q (e.g., 80th/90th percentile over 252D) OR |z_20| > 1.0/1.5/2.0.\n   - This should reduce small/noisy gaps that add turnover and dilute edge.\n2) Replace/extend volweak with a more robust relative-volume measure:\n   - Use log(vol / mean_20(vol)) then clip to a range (e.g., [-2, 2]) before converting to a “weakness” score.\n   - Or TS_ZSCORE(volume, 20) and define volweak = max(0, -zvol) (weak only when unusually low), which aligns better with the hypothesis (“weak confirmation”).\n3) Improve drawdown control via explicit anti-information-gap filters:\n   - Exclude days with extremely large gaps relative to recent volatility (e.g., |z_gap_20| > 4) rather than just capping.\n   - Exclude days with extreme intraday trend continuation: |close/open - 1| > k * mean_20(|close/open - 1|).\n4) Parameter sensitivity to explore (each should be its own factor version):\n   - Lookback windows: 10, 20, 60 (gap normalization and volume baseline may have different optimal windows).\n   - Z-cap: 2, 3, 4.\n   - Range scaler: use mean(high-low) vs mean(true_range proxy) where proxy = max(high-low, |high-prev_close|, |low-prev_close|) if you can approximate with available fields.\n5) Hold-period alignment with hypothesis (1–3 day mean reversion):\n   - Even if evaluation is “1day”, consider building factors that explicitly target 2–3 day reversal by smoothing the signal (e.g., EMA_3 of today’s score) to reduce whipsaw; test separately.\n\nComplexity check:\n- These factors are structurally simple (few raw features: open/close/high/low/volume; limited free parameters: window=20, cap=3). No complexity red flags; the main risk is not over-parameterization but regime-tail exposure. Focus on gating/filtering rather than adding many new terms."
      }
    },
    "e8d9c603c625bcaf": {
      "factor_id": "e8d9c603c625bcaf",
      "factor_name": "GapFade_FollowThrough_VolWeak_ATR20",
      "factor_expression": "(($open/DELAY($close,1)-1)/(TS_MEAN($high-$low,20)+1e-8))*(-SIGN($open-DELAY($close,1))*($close/$open-1))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open/DELAY($close,1)-1)/(TS_MEAN($high-$low,20)+1e-8))*(-SIGN($open-DELAY($close,1))*($close/$open-1))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))\" # Your output factor expression will be filled in here\n    name = \"GapFade_FollowThrough_VolWeak_ATR20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Symmetric gap-fade score emphasizing lack of intraday follow-through: gap size scaled by 20D average daily range (high-low), multiplied by intraday move against the gap (close/open) and by weak-volume confirmation (below 20D average). Lookback=20 days.",
      "factor_formulation": "g_t=\\frac{open_t}{close_{t-1}}-1,\\quad range20_t=\\text{MEAN}_{20}(high-low)\\\\ft_t=-\\text{SIGN}(open_t-close_{t-1})\\cdot\\left(\\frac{close_t}{open_t}-1\\right)\\\\volweak_t=1-\\min\\left(\\frac{vol_t}{\\text{MEAN}_{20}(vol)+\\epsilon},1\\right)\\\\Factor_t=\\frac{g_t}{range20_t+\\epsilon}\\cdot ft_t\\cdot volweak_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "fce14873707e",
        "parent_trajectory_ids": [
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: If a stock exhibits an abnormally large overnight gap (open vs prev_close) but shows intraday rejection (close ends near the opposite end of the day’s range and intraday return offsets the gap) with weak volume confirmation, then the gap is more likely an overreaction and the stock will mean-revert over the next 1–3 trading days (gap-fade), symmetrically for gap-ups and gap-downs.\n                Concise Observation: Available OHLCV data supports direct construction of gap magnitude, intraday rejection (close-location in range, wick/body style), and volume confirmation features that target a different mechanism than trend-quality/liquidity re-rating continuation signals, helping reduce factor correlation with the parent strategy.\n                Concise Justification: A large gap without intraday follow-through and without volume confirmation implies that marginal buyers/sellers were exhausted near the open and subsequent trading rejected the new price level; market makers and short-term traders commonly fade such failed breakouts, creating predictable 1–3 day mean-reversion pressure.\n                Concise Knowledge: If price discovery is incomplete at the open, then large overnight gaps that fail to attract sustained daytime participation (rejection candles + sub-average volume) tend to reflect temporary order-imbalance and liquidity-provider inventory effects; when this occurs, short-horizon returns are more likely to reverse than continue, especially when the gap size is large relative to recent true range/gap volatility.\n                concise Specification: Construct a symmetric gap-fade score using only daily_pv.h5 OHLCV with fixed hyperparameters: gap = (open/DELAY(close,1)-1); gap_z = gap / (TS_MEAN(ABS(gap),20)+1e-8) and/or gap_atr = gap / (TS_MEAN(high-low,20)+1e-8); rejection = -SIGN(gap)*CLV where CLV = ((close-low)-(high-close))/((high-low)+1e-8) (so gap-up + close near low => high rejection, gap-down + close near high => high rejection); followthrough = -SIGN(gap)*(close/open-1) (positive when the session moves against the gap); vol_confirm = 1 - MIN(volume/(TS_MEAN(volume,20)+1e-8), 1) (higher when volume is below average); final factor = gap_z * (0.5*rejection + 0.5*followthrough) * vol_confirm, optionally winsorized by capping |gap_z| at 3 to avoid earnings-like extremes; expected relationship: higher factor predicts stronger next 1–3 day reversal (negative next-day return after positive gap-fade signal for gap-ups, and vice versa for gap-downs).\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-21T18:51:30.638303"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1036469815146556,
        "ICIR": 0.0462818174363058,
        "1day.excess_return_without_cost.std": 0.0041020001430463,
        "1day.excess_return_with_cost.annualized_return": 0.0401780589079599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003673799470357,
        "1day.excess_return_without_cost.annualized_return": 0.0874364273945147,
        "1day.excess_return_with_cost.std": 0.0041030137297135,
        "Rank IC": 0.0208088401469987,
        "IC": 0.0064056347016531,
        "1day.excess_return_without_cost.max_drawdown": -0.0894843221430379,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3816824923153743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967628683606692,
        "Rank ICIR": 0.152838071150687,
        "l2.train": 0.9934570258322084,
        "1day.excess_return_with_cost.information_ratio": 0.6347423894936896,
        "1day.excess_return_with_cost.mean": 0.0001688153735628
      },
      "feedback": {
        "observations": "The combined experiment improves the core predictive/return metrics versus SOTA: annualized excess return rises from 0.0520 to 0.0874, information ratio from 0.9726 to 1.3817, and IC from 0.00580 to 0.00641. However, max drawdown worsens (more negative) from -0.0726 to -0.0895, indicating the signal likely concentrates risk in a subset of adverse regimes/events (e.g., news/earnings gaps, market stress, or illiquidity) even though the average edge is stronger.",
        "hypothesis_evaluation": "Overall the results support the hypothesis: the factor family designed to capture (i) abnormal overnight gap, (ii) intraday rejection/lack of follow-through, and (iii) weak volume confirmation appears to predict next-day mean reversion (higher IC and materially better IR/return). The deterioration in max drawdown does not refute the hypothesis, but it suggests the gap-fade effect is regime-dependent and occasionally fails catastrophically (likely on true-information gaps) — exactly the scenario where \"overreaction\" is false. This implies the framework is correct, but it needs a robustness filter to separate overreaction gaps from information gaps.\n\nHyperparameters explicitly present in your current implementations:\n- Lookback window for normalization/means/zscore: 20 trading days (all three)\n- Gap normalization method: 20D mean(|gap|) vs 20D mean(high-low) vs 20D z-score\n- Z-score cap: |z| <= 3 (third factor)\n- Volume weakness definition: 1 - min(vol / mean_20(vol), 1)\n\nKey construction notes to refine within the same framework:\n1) Volume confirmation is one-sided capped (only penalizes high volume; treats very low volume almost linearly). Consider making it symmetric/robust (z-score or log ratio) to avoid overweighting microcap/illiquid artifacts.\n2) Intraday rejection via CLV is good, but sensitive to (high-low) near zero and to noisy extremes; consider alternative rejection proxies (close vs VWAP if available; otherwise close position vs open and midpoint) and add small-range guards.\n3) The worse drawdown strongly hints the signal is getting hit on “true breakaway gaps” (earnings/news). Your capped z-score variant helps, but may not be sufficient; consider explicit gating rather than only capping.",
        "decision": true,
        "reason": "Why the current metrics pattern happens:\n- Higher annualized return + higher IR + slightly higher IC indicates the signal is directionally correct and exploitable on average.\n- Worse max drawdown suggests tail events where the model repeatedly fades gaps that continue trending (information gaps). This is consistent with the hypothesis boundary conditions.\n\nConcrete next iterations (still the same theoretical concept; just refined implementations):\n1) Add a gap-magnitude gate (separate factors by design; static hyperparameters):\n   - Only trade when |g_norm| > q (e.g., 80th/90th percentile over 252D) OR |z_20| > 1.0/1.5/2.0.\n   - This should reduce small/noisy gaps that add turnover and dilute edge.\n2) Replace/extend volweak with a more robust relative-volume measure:\n   - Use log(vol / mean_20(vol)) then clip to a range (e.g., [-2, 2]) before converting to a “weakness” score.\n   - Or TS_ZSCORE(volume, 20) and define volweak = max(0, -zvol) (weak only when unusually low), which aligns better with the hypothesis (“weak confirmation”).\n3) Improve drawdown control via explicit anti-information-gap filters:\n   - Exclude days with extremely large gaps relative to recent volatility (e.g., |z_gap_20| > 4) rather than just capping.\n   - Exclude days with extreme intraday trend continuation: |close/open - 1| > k * mean_20(|close/open - 1|).\n4) Parameter sensitivity to explore (each should be its own factor version):\n   - Lookback windows: 10, 20, 60 (gap normalization and volume baseline may have different optimal windows).\n   - Z-cap: 2, 3, 4.\n   - Range scaler: use mean(high-low) vs mean(true_range proxy) where proxy = max(high-low, |high-prev_close|, |low-prev_close|) if you can approximate with available fields.\n5) Hold-period alignment with hypothesis (1–3 day mean reversion):\n   - Even if evaluation is “1day”, consider building factors that explicitly target 2–3 day reversal by smoothing the signal (e.g., EMA_3 of today’s score) to reduce whipsaw; test separately.\n\nComplexity check:\n- These factors are structurally simple (few raw features: open/close/high/low/volume; limited free parameters: window=20, cap=3). No complexity red flags; the main risk is not over-parameterization but regime-tail exposure. Focus on gating/filtering rather than adding many new terms."
      }
    },
    "670c5a9c6fe3951b": {
      "factor_id": "670c5a9c6fe3951b",
      "factor_name": "GapFade_CappedZ_Rejection_VolWeak_20D",
      "factor_expression": "(SIGN(TS_ZSCORE($open/DELAY($close,1)-1,20))*MIN(ABS(TS_ZSCORE($open/DELAY($close,1)-1,20)),3))*(-SIGN($open-DELAY($close,1))*((($close-$low)-($high-$close))/(($high-$low)+1e-8)))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(SIGN(TS_ZSCORE($open/DELAY($close,1)-1,20))*MIN(ABS(TS_ZSCORE($open/DELAY($close,1)-1,20)),3))*(-SIGN($open-DELAY($close,1))*((($close-$low)-($high-$close))/(($high-$low)+1e-8)))*(1-MIN($volume/(TS_MEAN($volume,20)+1e-8),1))\" # Your output factor expression will be filled in here\n    name = \"GapFade_CappedZ_Rejection_VolWeak_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Capped, robust gap-fade score: uses 20D time-series z-score of the overnight gap (open vs prior close), caps extreme gaps at |z|<=3 to reduce earnings-like outliers, then multiplies by gap-aligned intraday rejection (CLV) and weak-volume confirmation (below 20D average). Lookback=20 days, cap=3.",
      "factor_formulation": "g_t=\\frac{open_t}{close_{t-1}}-1,\\quad z_t=\\text{ZSCORE}_{20}(g)\\\\z^{cap}_t=\\text{SIGN}(z_t)\\cdot\\min(|z_t|,3)\\\\CLV_t=\\frac{(close_t-low_t)-(high_t-close_t)}{(high_t-low_t)+\\epsilon}\\\\rej_t=-\\text{SIGN}(open_t-close_{t-1})\\cdot CLV_t\\\\volweak_t=1-\\min\\left(\\frac{vol_t}{\\text{MEAN}_{20}(vol)+\\epsilon},1\\right)\\\\Factor_t=z^{cap}_t\\cdot rej_t\\cdot volweak_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "fce14873707e",
        "parent_trajectory_ids": [
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: If a stock exhibits an abnormally large overnight gap (open vs prev_close) but shows intraday rejection (close ends near the opposite end of the day’s range and intraday return offsets the gap) with weak volume confirmation, then the gap is more likely an overreaction and the stock will mean-revert over the next 1–3 trading days (gap-fade), symmetrically for gap-ups and gap-downs.\n                Concise Observation: Available OHLCV data supports direct construction of gap magnitude, intraday rejection (close-location in range, wick/body style), and volume confirmation features that target a different mechanism than trend-quality/liquidity re-rating continuation signals, helping reduce factor correlation with the parent strategy.\n                Concise Justification: A large gap without intraday follow-through and without volume confirmation implies that marginal buyers/sellers were exhausted near the open and subsequent trading rejected the new price level; market makers and short-term traders commonly fade such failed breakouts, creating predictable 1–3 day mean-reversion pressure.\n                Concise Knowledge: If price discovery is incomplete at the open, then large overnight gaps that fail to attract sustained daytime participation (rejection candles + sub-average volume) tend to reflect temporary order-imbalance and liquidity-provider inventory effects; when this occurs, short-horizon returns are more likely to reverse than continue, especially when the gap size is large relative to recent true range/gap volatility.\n                concise Specification: Construct a symmetric gap-fade score using only daily_pv.h5 OHLCV with fixed hyperparameters: gap = (open/DELAY(close,1)-1); gap_z = gap / (TS_MEAN(ABS(gap),20)+1e-8) and/or gap_atr = gap / (TS_MEAN(high-low,20)+1e-8); rejection = -SIGN(gap)*CLV where CLV = ((close-low)-(high-close))/((high-low)+1e-8) (so gap-up + close near low => high rejection, gap-down + close near high => high rejection); followthrough = -SIGN(gap)*(close/open-1) (positive when the session moves against the gap); vol_confirm = 1 - MIN(volume/(TS_MEAN(volume,20)+1e-8), 1) (higher when volume is below average); final factor = gap_z * (0.5*rejection + 0.5*followthrough) * vol_confirm, optionally winsorized by capping |gap_z| at 3 to avoid earnings-like extremes; expected relationship: higher factor predicts stronger next 1–3 day reversal (negative next-day return after positive gap-fade signal for gap-ups, and vice versa for gap-downs).\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-21T18:51:30.638303"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1036469815146556,
        "ICIR": 0.0462818174363058,
        "1day.excess_return_without_cost.std": 0.0041020001430463,
        "1day.excess_return_with_cost.annualized_return": 0.0401780589079599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003673799470357,
        "1day.excess_return_without_cost.annualized_return": 0.0874364273945147,
        "1day.excess_return_with_cost.std": 0.0041030137297135,
        "Rank IC": 0.0208088401469987,
        "IC": 0.0064056347016531,
        "1day.excess_return_without_cost.max_drawdown": -0.0894843221430379,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3816824923153743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967628683606692,
        "Rank ICIR": 0.152838071150687,
        "l2.train": 0.9934570258322084,
        "1day.excess_return_with_cost.information_ratio": 0.6347423894936896,
        "1day.excess_return_with_cost.mean": 0.0001688153735628
      },
      "feedback": {
        "observations": "The combined experiment improves the core predictive/return metrics versus SOTA: annualized excess return rises from 0.0520 to 0.0874, information ratio from 0.9726 to 1.3817, and IC from 0.00580 to 0.00641. However, max drawdown worsens (more negative) from -0.0726 to -0.0895, indicating the signal likely concentrates risk in a subset of adverse regimes/events (e.g., news/earnings gaps, market stress, or illiquidity) even though the average edge is stronger.",
        "hypothesis_evaluation": "Overall the results support the hypothesis: the factor family designed to capture (i) abnormal overnight gap, (ii) intraday rejection/lack of follow-through, and (iii) weak volume confirmation appears to predict next-day mean reversion (higher IC and materially better IR/return). The deterioration in max drawdown does not refute the hypothesis, but it suggests the gap-fade effect is regime-dependent and occasionally fails catastrophically (likely on true-information gaps) — exactly the scenario where \"overreaction\" is false. This implies the framework is correct, but it needs a robustness filter to separate overreaction gaps from information gaps.\n\nHyperparameters explicitly present in your current implementations:\n- Lookback window for normalization/means/zscore: 20 trading days (all three)\n- Gap normalization method: 20D mean(|gap|) vs 20D mean(high-low) vs 20D z-score\n- Z-score cap: |z| <= 3 (third factor)\n- Volume weakness definition: 1 - min(vol / mean_20(vol), 1)\n\nKey construction notes to refine within the same framework:\n1) Volume confirmation is one-sided capped (only penalizes high volume; treats very low volume almost linearly). Consider making it symmetric/robust (z-score or log ratio) to avoid overweighting microcap/illiquid artifacts.\n2) Intraday rejection via CLV is good, but sensitive to (high-low) near zero and to noisy extremes; consider alternative rejection proxies (close vs VWAP if available; otherwise close position vs open and midpoint) and add small-range guards.\n3) The worse drawdown strongly hints the signal is getting hit on “true breakaway gaps” (earnings/news). Your capped z-score variant helps, but may not be sufficient; consider explicit gating rather than only capping.",
        "decision": true,
        "reason": "Why the current metrics pattern happens:\n- Higher annualized return + higher IR + slightly higher IC indicates the signal is directionally correct and exploitable on average.\n- Worse max drawdown suggests tail events where the model repeatedly fades gaps that continue trending (information gaps). This is consistent with the hypothesis boundary conditions.\n\nConcrete next iterations (still the same theoretical concept; just refined implementations):\n1) Add a gap-magnitude gate (separate factors by design; static hyperparameters):\n   - Only trade when |g_norm| > q (e.g., 80th/90th percentile over 252D) OR |z_20| > 1.0/1.5/2.0.\n   - This should reduce small/noisy gaps that add turnover and dilute edge.\n2) Replace/extend volweak with a more robust relative-volume measure:\n   - Use log(vol / mean_20(vol)) then clip to a range (e.g., [-2, 2]) before converting to a “weakness” score.\n   - Or TS_ZSCORE(volume, 20) and define volweak = max(0, -zvol) (weak only when unusually low), which aligns better with the hypothesis (“weak confirmation”).\n3) Improve drawdown control via explicit anti-information-gap filters:\n   - Exclude days with extremely large gaps relative to recent volatility (e.g., |z_gap_20| > 4) rather than just capping.\n   - Exclude days with extreme intraday trend continuation: |close/open - 1| > k * mean_20(|close/open - 1|).\n4) Parameter sensitivity to explore (each should be its own factor version):\n   - Lookback windows: 10, 20, 60 (gap normalization and volume baseline may have different optimal windows).\n   - Z-cap: 2, 3, 4.\n   - Range scaler: use mean(high-low) vs mean(true_range proxy) where proxy = max(high-low, |high-prev_close|, |low-prev_close|) if you can approximate with available fields.\n5) Hold-period alignment with hypothesis (1–3 day mean reversion):\n   - Even if evaluation is “1day”, consider building factors that explicitly target 2–3 day reversal by smoothing the signal (e.g., EMA_3 of today’s score) to reduce whipsaw; test separately.\n\nComplexity check:\n- These factors are structurally simple (few raw features: open/close/high/low/volume; limited free parameters: window=20, cap=3). No complexity red flags; the main risk is not over-parameterization but regime-tail exposure. Focus on gating/filtering rather than adding many new terms."
      }
    },
    "8a85012b09ad902e": {
      "factor_id": "8a85012b09ad902e",
      "factor_name": "Compression_Donchian_CLV_RelVol_20_60",
      "factor_expression": "(($close>TS_MAX($high,20))-($close<TS_MIN($low,20)))*(-TS_RANK(TS_MEAN(($high-$low)/($close+1e-8),20),60)-TS_RANK(TS_STD($return,20),60))*((($close-$low)-($high-$close))/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((($close>DELAY(TS_MAX($high,20),1))?(1):(0))-(($close<DELAY(TS_MIN($low,20),1))?(1):(0)))*(-TS_RANK(TS_MEAN(($high-$low)/($close+1e-8),20),60)-TS_RANK(TS_STD(TS_PCTCHANGE($close,1),20),60))*((($close-$low)-($high-$close))/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compression_Donchian_CLV_RelVol_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Directional breakout-continuation factor: 20D Donchian breakout direction scaled by prior 20D compression (range/close and return volatility ranked over a 60D context), trend-day close location value (CLV), and 20D relative volume.",
      "factor_formulation": "F = (\\mathbb{1}[C>\\max(H,20)]-\\mathbb{1}[C<\\min(L,20)])\\cdot\\Big(-\\text{TSRANK}(\\overline{(H-L)/C}_{20},60)-\\text{TSRANK}(\\sigma(r)_{20},60)\\Big)\\cdot\\frac{(C-L)-(H-C)}{H-L}\\cdot\\frac{V}{\\overline{V}_{20}}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "70b62839247a",
        "parent_trajectory_ids": [
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Volatility-compression breakout continuation: if a stock exhibits sustained 20-day range/volatility compression (low TS_MEAN((high-low)/close,20) and low TS_STD(log(close/REF(close,1)),20)) and then breaks out via a 20-day Donchian close (close > TS_MAX(high,20) for up or close < TS_MIN(low,20) for down) on a trend-day anatomy (close-location value near the breakout extreme with low wick share) confirmed by elevated relative volume (volume/TS_MEAN(volume,20) high), then the breakout direction is more likely information-driven and continues over the next 5–20 trading days (positive forward return for up-breaks, negative for down-breaks), whereas breakouts without prior compression or with rejection anatomy tend to mean-revert.\n                Concise Observation: Given only daily OHLCV, volatility-compression can be proxied by low rolling averages/ranks of (high-low)/close and TS_STD(returns,20), while breakout/acceptance can be proxied by Donchian-style close-to-extreme events plus close-location and wick-share filters, and participation by volume relative to its 20-day mean—this explores a momentum/continuation mechanism orthogonal to the parent contrarian capitulation-reversal logic.\n                Concise Justification: Compression regimes often reflect temporary equilibrium where supply/demand imbalances accumulate; a confirmed breakout (new 20-day extreme close) with trend-day anatomy and volume expansion implies imbalance resolution and information-driven repricing, which typically continues as liquidity providers and slower investors adjust positions over subsequent sessions, producing predictable 5–20D drift rather than immediate snapback.\n                Concise Knowledge: If pre-event realized volatility and intraday range are persistently compressed, then order-flow is more likely to be latent and price discovery deferred; when price exits the compressed regime by closing beyond a recent high/low with strong close-at-extreme anatomy and above-normal participation, the move is more likely an acceptance/information shock and tends to drift in the same direction over a medium horizon (5–20D), while large wick share/poor close location indicates rejection and weakens continuation.\n                concise Specification: Construct a directional factor using only daily_pv.h5 OHLCV with fixed hyperparameters: CompressionWindow=20 (compute CompressionScore as negative zscore or rank of TS_MEAN((high-low)/close,20) and TS_STD(log(close/REF(close,1)),20)); BreakoutWindow=20 (UpBreak=I(close>TS_MAX(high,20)), DownBreak=I(close<TS_MIN(low,20))); TrendQuality computed on trigger day using CLV=((close-low)-(high-close))/(high-low+1e-8) with thresholds |CLV|>=0.6 and WickShare=( (high-max(open,close))+(min(open,close)-low) )/(high-low+1e-8) with WickShare<=0.3; ParticipationScore=volume/TS_MEAN(volume,20) with threshold>=1.2; final factor = (UpBreak-DownBreak)*CompressionScore*TrendQuality*ParticipationScore, intended to predict forward returns over Horizon={5,10,20} days with expected sign aligned to breakout direction and diminished effect when CompressionScore is weak or WickShare is high.\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-21T19:17:44.768541"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1019732559219474,
        "ICIR": 0.021929696463819,
        "1day.excess_return_without_cost.std": 0.004113557493416,
        "1day.excess_return_with_cost.annualized_return": 0.0180411663743608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002723199993016,
        "1day.excess_return_without_cost.annualized_return": 0.0648121598337869,
        "1day.excess_return_with_cost.std": 0.0041160929950232,
        "Rank IC": 0.018376094953304,
        "IC": 0.0030880742948006,
        "1day.excess_return_without_cost.max_drawdown": -0.0885515569378456,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0212932091738218,
        "1day.pa": 0.0,
        "l2.valid": 0.9963034072742836,
        "Rank ICIR": 0.1310918656062153,
        "l2.train": 0.9926257126426214,
        "1day.excess_return_with_cost.information_ratio": 0.284112901123092,
        "1day.excess_return_with_cost.mean": 7.580322006033972e-05
      },
      "feedback": {
        "observations": "The combined factors improve portfolio-level performance (annualized excess return 0.0648 vs 0.0520; information ratio 1.021 vs 0.973), but degrade risk/skill proxies (max drawdown worsens: -0.0886 vs -0.0726; IC falls: 0.00309 vs 0.00580). This pattern suggests the signal may be helping the strategy make money via a subset of regimes/trades (tail outcomes), while being less stable cross-sectionally day-to-day (lower IC) and exposing the portfolio to deeper peak-to-trough losses.\n\nNo explicit complexity warnings were provided. The constructions are moderately complex but still within a reasonable feature set (OHLCV + returns). Main hyperparameters are static and clear: Donchian window=20; compression window=20; context rank window=60; rel-vol mean window=20; Bollinger window=20; MAD window=20.",
        "hypothesis_evaluation": "Overall, the results partially support the hypothesis at the portfolio/strategy level but are weaker at the pure predictive-correlation level:\n- Support: Higher annualized return and higher information ratio are consistent with “compression + breakout + acceptance + volume confirmation” capturing continuation episodes that monetarily matter.\n- Weak/contradictory evidence: The IC deterioration indicates the factor is not consistently ranking next-day returns cross-sectionally, which is what we would expect if the breakout continuation effect were broadly reliable. The worse max drawdown also suggests the “continuation” logic may be regime-dependent and can fail in mean-reversion or high-volatility reversal regimes.\n\nInterpretation: Your hypothesis may be directionally correct, but the current implementation likely mixes (a) rare strong continuation events (helpful for return/IR) with (b) many false breakouts/rejections not fully filtered (hurting IC and drawdown).",
        "decision": true,
        "reason": "1) Hard breakout indicators (±1 else 0) create sparse, discontinuous signals; this can improve portfolio returns if the strategy concentrates on rare events, but often hurts IC because most days are near-zero and the ranking becomes noisy. Using a continuous breakout strength (e.g., (C - prev_TS_MAX(H,20))/ATR or /TS_STD(r,20)) should stabilize cross-sectional ranking.\n\n2) Relative volume as V/MA20(V) can overweight extreme “news/climax” days that frequently mean-revert. Clipping/log-scaling rel-vol (e.g., log(1+V/MA20(V)) or winsorize to [0, p95]) typically reduces drawdown and can improve IC.\n\n3) A critical implementation detail: Donchian breakout should use prior range (exclude today) to avoid inadvertent self-referential boundaries. Use TS_MAX(H,20).shift(1) and TS_MIN(L,20).shift(1) as the breakout thresholds. If not shifted, the breakout condition becomes stricter and may distort event timing, which can reduce IC.\n\n4) Anatomy filters: CLV and body-fraction are good, but they can be refined to specifically penalize rejection (long opposite-side wick). A direct wick-share term often works better than CLV alone. This can reduce false breakouts and drawdown.\n\nConcrete next iterations within the same framework (keep factors simple, vary only a few knobs):\n- Parameter sweeps (static factors, separate definitions):\n  * Donchian window: 10, 20, 55 (three separate factors)\n  * Compression window: 10, 20, 30\n  * Context rank window: 60 vs 120\n  * Rel-vol window: 10 vs 20\n- Replace indicator with breakout distance:\n  * UpStrength = (C - prev_TS_MAX(H,n)) / C (or /ATR20), DownStrength = (prev_TS_MIN(L,n) - C)/C; Factor = UpStrength - DownStrength.\n- Robust normalization:\n  * Use z-score or TSRANK only on compression components; clip rel-vol and breakout strength.\n- Separate long/short legs as separate factors (two outputs):\n  * One factor for up-break continuation only, another for down-break continuation only. This often improves stability because down-breaks behave differently (short-sale constraints, limit-down effects).\n- Add a minimal regime filter (still same hypothesis):\n  * Only act when market/stock is in low-vol regime: TS_STD(r,20) below its TS_RANK(120) threshold; this targets “compression” regimes and can reduce drawdown.\n\nComplexity control note: keep expressions short by choosing either (range/close + ret vol) OR (BB width) OR (MAD versions) as the compression proxy, not all combined in one factor; avoid adding many extra terms beyond 1–2 anatomy terms + 1 volume term + 1 breakout-strength term."
      }
    },
    "9625ae09929b8f80": {
      "factor_id": "9625ae09929b8f80",
      "factor_name": "BBandWidth_Compress_Breakout_CLV_RelVol_20_60",
      "factor_expression": "(($close>TS_MAX($high,20))-($close<TS_MIN($low,20)))*(-TS_RANK((BB_UPPER($close,20)-BB_LOWER($close,20))/($close+1e-8),60))*((($close-$low)-($high-$close))/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((($close>TS_MAX($high,20))?(1):(0))-(($close<TS_MIN($low,20))?(1):(0)))*(-TS_RANK((BB_UPPER($close,20)-BB_LOWER($close,20))/($close+1e-8),60))*((($close-$low)-($high-$close))/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"BBandWidth_Compress_Breakout_CLV_RelVol_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Uses Bollinger Band width as a compact volatility-compression proxy (low bandwidth over 60D context) and combines it with 20D Donchian breakout direction, CLV trend-day acceptance, and 20D relative volume.",
      "factor_formulation": "F = (\\mathbb{1}[C>\\max(H,20)]-\\mathbb{1}[C<\\min(L,20)])\\cdot\\Big(-\\text{TSRANK}(\\frac{BB_u(C,20)-BB_l(C,20)}{C},60)\\Big)\\cdot\\frac{(C-L)-(H-C)}{H-L}\\cdot\\frac{V}{\\overline{V}_{20}}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "70b62839247a",
        "parent_trajectory_ids": [
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Volatility-compression breakout continuation: if a stock exhibits sustained 20-day range/volatility compression (low TS_MEAN((high-low)/close,20) and low TS_STD(log(close/REF(close,1)),20)) and then breaks out via a 20-day Donchian close (close > TS_MAX(high,20) for up or close < TS_MIN(low,20) for down) on a trend-day anatomy (close-location value near the breakout extreme with low wick share) confirmed by elevated relative volume (volume/TS_MEAN(volume,20) high), then the breakout direction is more likely information-driven and continues over the next 5–20 trading days (positive forward return for up-breaks, negative for down-breaks), whereas breakouts without prior compression or with rejection anatomy tend to mean-revert.\n                Concise Observation: Given only daily OHLCV, volatility-compression can be proxied by low rolling averages/ranks of (high-low)/close and TS_STD(returns,20), while breakout/acceptance can be proxied by Donchian-style close-to-extreme events plus close-location and wick-share filters, and participation by volume relative to its 20-day mean—this explores a momentum/continuation mechanism orthogonal to the parent contrarian capitulation-reversal logic.\n                Concise Justification: Compression regimes often reflect temporary equilibrium where supply/demand imbalances accumulate; a confirmed breakout (new 20-day extreme close) with trend-day anatomy and volume expansion implies imbalance resolution and information-driven repricing, which typically continues as liquidity providers and slower investors adjust positions over subsequent sessions, producing predictable 5–20D drift rather than immediate snapback.\n                Concise Knowledge: If pre-event realized volatility and intraday range are persistently compressed, then order-flow is more likely to be latent and price discovery deferred; when price exits the compressed regime by closing beyond a recent high/low with strong close-at-extreme anatomy and above-normal participation, the move is more likely an acceptance/information shock and tends to drift in the same direction over a medium horizon (5–20D), while large wick share/poor close location indicates rejection and weakens continuation.\n                concise Specification: Construct a directional factor using only daily_pv.h5 OHLCV with fixed hyperparameters: CompressionWindow=20 (compute CompressionScore as negative zscore or rank of TS_MEAN((high-low)/close,20) and TS_STD(log(close/REF(close,1)),20)); BreakoutWindow=20 (UpBreak=I(close>TS_MAX(high,20)), DownBreak=I(close<TS_MIN(low,20))); TrendQuality computed on trigger day using CLV=((close-low)-(high-close))/(high-low+1e-8) with thresholds |CLV|>=0.6 and WickShare=( (high-max(open,close))+(min(open,close)-low) )/(high-low+1e-8) with WickShare<=0.3; ParticipationScore=volume/TS_MEAN(volume,20) with threshold>=1.2; final factor = (UpBreak-DownBreak)*CompressionScore*TrendQuality*ParticipationScore, intended to predict forward returns over Horizon={5,10,20} days with expected sign aligned to breakout direction and diminished effect when CompressionScore is weak or WickShare is high.\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-21T19:17:44.768541"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1019732559219474,
        "ICIR": 0.021929696463819,
        "1day.excess_return_without_cost.std": 0.004113557493416,
        "1day.excess_return_with_cost.annualized_return": 0.0180411663743608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002723199993016,
        "1day.excess_return_without_cost.annualized_return": 0.0648121598337869,
        "1day.excess_return_with_cost.std": 0.0041160929950232,
        "Rank IC": 0.018376094953304,
        "IC": 0.0030880742948006,
        "1day.excess_return_without_cost.max_drawdown": -0.0885515569378456,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0212932091738218,
        "1day.pa": 0.0,
        "l2.valid": 0.9963034072742836,
        "Rank ICIR": 0.1310918656062153,
        "l2.train": 0.9926257126426214,
        "1day.excess_return_with_cost.information_ratio": 0.284112901123092,
        "1day.excess_return_with_cost.mean": 7.580322006033972e-05
      },
      "feedback": {
        "observations": "The combined factors improve portfolio-level performance (annualized excess return 0.0648 vs 0.0520; information ratio 1.021 vs 0.973), but degrade risk/skill proxies (max drawdown worsens: -0.0886 vs -0.0726; IC falls: 0.00309 vs 0.00580). This pattern suggests the signal may be helping the strategy make money via a subset of regimes/trades (tail outcomes), while being less stable cross-sectionally day-to-day (lower IC) and exposing the portfolio to deeper peak-to-trough losses.\n\nNo explicit complexity warnings were provided. The constructions are moderately complex but still within a reasonable feature set (OHLCV + returns). Main hyperparameters are static and clear: Donchian window=20; compression window=20; context rank window=60; rel-vol mean window=20; Bollinger window=20; MAD window=20.",
        "hypothesis_evaluation": "Overall, the results partially support the hypothesis at the portfolio/strategy level but are weaker at the pure predictive-correlation level:\n- Support: Higher annualized return and higher information ratio are consistent with “compression + breakout + acceptance + volume confirmation” capturing continuation episodes that monetarily matter.\n- Weak/contradictory evidence: The IC deterioration indicates the factor is not consistently ranking next-day returns cross-sectionally, which is what we would expect if the breakout continuation effect were broadly reliable. The worse max drawdown also suggests the “continuation” logic may be regime-dependent and can fail in mean-reversion or high-volatility reversal regimes.\n\nInterpretation: Your hypothesis may be directionally correct, but the current implementation likely mixes (a) rare strong continuation events (helpful for return/IR) with (b) many false breakouts/rejections not fully filtered (hurting IC and drawdown).",
        "decision": true,
        "reason": "1) Hard breakout indicators (±1 else 0) create sparse, discontinuous signals; this can improve portfolio returns if the strategy concentrates on rare events, but often hurts IC because most days are near-zero and the ranking becomes noisy. Using a continuous breakout strength (e.g., (C - prev_TS_MAX(H,20))/ATR or /TS_STD(r,20)) should stabilize cross-sectional ranking.\n\n2) Relative volume as V/MA20(V) can overweight extreme “news/climax” days that frequently mean-revert. Clipping/log-scaling rel-vol (e.g., log(1+V/MA20(V)) or winsorize to [0, p95]) typically reduces drawdown and can improve IC.\n\n3) A critical implementation detail: Donchian breakout should use prior range (exclude today) to avoid inadvertent self-referential boundaries. Use TS_MAX(H,20).shift(1) and TS_MIN(L,20).shift(1) as the breakout thresholds. If not shifted, the breakout condition becomes stricter and may distort event timing, which can reduce IC.\n\n4) Anatomy filters: CLV and body-fraction are good, but they can be refined to specifically penalize rejection (long opposite-side wick). A direct wick-share term often works better than CLV alone. This can reduce false breakouts and drawdown.\n\nConcrete next iterations within the same framework (keep factors simple, vary only a few knobs):\n- Parameter sweeps (static factors, separate definitions):\n  * Donchian window: 10, 20, 55 (three separate factors)\n  * Compression window: 10, 20, 30\n  * Context rank window: 60 vs 120\n  * Rel-vol window: 10 vs 20\n- Replace indicator with breakout distance:\n  * UpStrength = (C - prev_TS_MAX(H,n)) / C (or /ATR20), DownStrength = (prev_TS_MIN(L,n) - C)/C; Factor = UpStrength - DownStrength.\n- Robust normalization:\n  * Use z-score or TSRANK only on compression components; clip rel-vol and breakout strength.\n- Separate long/short legs as separate factors (two outputs):\n  * One factor for up-break continuation only, another for down-break continuation only. This often improves stability because down-breaks behave differently (short-sale constraints, limit-down effects).\n- Add a minimal regime filter (still same hypothesis):\n  * Only act when market/stock is in low-vol regime: TS_STD(r,20) below its TS_RANK(120) threshold; this targets “compression” regimes and can reduce drawdown.\n\nComplexity control note: keep expressions short by choosing either (range/close + ret vol) OR (BB width) OR (MAD versions) as the compression proxy, not all combined in one factor; avoid adding many extra terms beyond 1–2 anatomy terms + 1 volume term + 1 breakout-strength term."
      }
    },
    "a85f663c0bf33a37": {
      "factor_id": "a85f663c0bf33a37",
      "factor_name": "MAD_Compress_Breakout_BodyRelVol_20_60",
      "factor_expression": "(($close>TS_MAX($high,20))-($close<TS_MIN($low,20)))*(-TS_RANK(TS_MAD($return,20),60)-TS_RANK(TS_MAD(($high-$low)/($close+1e-8),20),60))*SIGN($close-$open)*(ABS($close-$open)/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((($close>DELAY(TS_MAX($high,20),1))?(1):(0))-(($close<DELAY(TS_MIN($low,20),1))?(1):(0)))*(-TS_RANK(TS_MAD(TS_PCTCHANGE($close,1),20),60)-TS_RANK(TS_MAD((($high-$low)/($close+1e-8)),20),60))*SIGN($close-$open)*(ABS($close-$open)/($high-$low+1e-8))*($volume/(TS_MEAN($volume,20)+1e-8))\" # Your output factor expression will be filled in here\n    name = \"MAD_Compress_Breakout_BodyRelVol_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Alternative compression + breakout continuation: uses robust MAD-based compression (returns and range/close) ranked over 60D, combined with 20D Donchian breakout direction, directional real body fraction (trend-day body), and 20D relative volume.",
      "factor_formulation": "F=(\\mathbb{1}[C>\\max(H,20)]-\\mathbb{1}[C<\\min(L,20)])\\cdot\\Big(-\\text{TSRANK}(\\text{MAD}(r,20),60)-\\text{TSRANK}(\\text{MAD}((H-L)/C,20),60)\\Big)\\cdot\\text{sign}(C-O)\\cdot\\frac{|C-O|}{H-L}\\cdot\\frac{V}{\\overline{V}_{20}}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "70b62839247a",
        "parent_trajectory_ids": [
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Volatility-compression breakout continuation: if a stock exhibits sustained 20-day range/volatility compression (low TS_MEAN((high-low)/close,20) and low TS_STD(log(close/REF(close,1)),20)) and then breaks out via a 20-day Donchian close (close > TS_MAX(high,20) for up or close < TS_MIN(low,20) for down) on a trend-day anatomy (close-location value near the breakout extreme with low wick share) confirmed by elevated relative volume (volume/TS_MEAN(volume,20) high), then the breakout direction is more likely information-driven and continues over the next 5–20 trading days (positive forward return for up-breaks, negative for down-breaks), whereas breakouts without prior compression or with rejection anatomy tend to mean-revert.\n                Concise Observation: Given only daily OHLCV, volatility-compression can be proxied by low rolling averages/ranks of (high-low)/close and TS_STD(returns,20), while breakout/acceptance can be proxied by Donchian-style close-to-extreme events plus close-location and wick-share filters, and participation by volume relative to its 20-day mean—this explores a momentum/continuation mechanism orthogonal to the parent contrarian capitulation-reversal logic.\n                Concise Justification: Compression regimes often reflect temporary equilibrium where supply/demand imbalances accumulate; a confirmed breakout (new 20-day extreme close) with trend-day anatomy and volume expansion implies imbalance resolution and information-driven repricing, which typically continues as liquidity providers and slower investors adjust positions over subsequent sessions, producing predictable 5–20D drift rather than immediate snapback.\n                Concise Knowledge: If pre-event realized volatility and intraday range are persistently compressed, then order-flow is more likely to be latent and price discovery deferred; when price exits the compressed regime by closing beyond a recent high/low with strong close-at-extreme anatomy and above-normal participation, the move is more likely an acceptance/information shock and tends to drift in the same direction over a medium horizon (5–20D), while large wick share/poor close location indicates rejection and weakens continuation.\n                concise Specification: Construct a directional factor using only daily_pv.h5 OHLCV with fixed hyperparameters: CompressionWindow=20 (compute CompressionScore as negative zscore or rank of TS_MEAN((high-low)/close,20) and TS_STD(log(close/REF(close,1)),20)); BreakoutWindow=20 (UpBreak=I(close>TS_MAX(high,20)), DownBreak=I(close<TS_MIN(low,20))); TrendQuality computed on trigger day using CLV=((close-low)-(high-close))/(high-low+1e-8) with thresholds |CLV|>=0.6 and WickShare=( (high-max(open,close))+(min(open,close)-low) )/(high-low+1e-8) with WickShare<=0.3; ParticipationScore=volume/TS_MEAN(volume,20) with threshold>=1.2; final factor = (UpBreak-DownBreak)*CompressionScore*TrendQuality*ParticipationScore, intended to predict forward returns over Horizon={5,10,20} days with expected sign aligned to breakout direction and diminished effect when CompressionScore is weak or WickShare is high.\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-21T19:17:44.768541"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1019732559219474,
        "ICIR": 0.021929696463819,
        "1day.excess_return_without_cost.std": 0.004113557493416,
        "1day.excess_return_with_cost.annualized_return": 0.0180411663743608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002723199993016,
        "1day.excess_return_without_cost.annualized_return": 0.0648121598337869,
        "1day.excess_return_with_cost.std": 0.0041160929950232,
        "Rank IC": 0.018376094953304,
        "IC": 0.0030880742948006,
        "1day.excess_return_without_cost.max_drawdown": -0.0885515569378456,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0212932091738218,
        "1day.pa": 0.0,
        "l2.valid": 0.9963034072742836,
        "Rank ICIR": 0.1310918656062153,
        "l2.train": 0.9926257126426214,
        "1day.excess_return_with_cost.information_ratio": 0.284112901123092,
        "1day.excess_return_with_cost.mean": 7.580322006033972e-05
      },
      "feedback": {
        "observations": "The combined factors improve portfolio-level performance (annualized excess return 0.0648 vs 0.0520; information ratio 1.021 vs 0.973), but degrade risk/skill proxies (max drawdown worsens: -0.0886 vs -0.0726; IC falls: 0.00309 vs 0.00580). This pattern suggests the signal may be helping the strategy make money via a subset of regimes/trades (tail outcomes), while being less stable cross-sectionally day-to-day (lower IC) and exposing the portfolio to deeper peak-to-trough losses.\n\nNo explicit complexity warnings were provided. The constructions are moderately complex but still within a reasonable feature set (OHLCV + returns). Main hyperparameters are static and clear: Donchian window=20; compression window=20; context rank window=60; rel-vol mean window=20; Bollinger window=20; MAD window=20.",
        "hypothesis_evaluation": "Overall, the results partially support the hypothesis at the portfolio/strategy level but are weaker at the pure predictive-correlation level:\n- Support: Higher annualized return and higher information ratio are consistent with “compression + breakout + acceptance + volume confirmation” capturing continuation episodes that monetarily matter.\n- Weak/contradictory evidence: The IC deterioration indicates the factor is not consistently ranking next-day returns cross-sectionally, which is what we would expect if the breakout continuation effect were broadly reliable. The worse max drawdown also suggests the “continuation” logic may be regime-dependent and can fail in mean-reversion or high-volatility reversal regimes.\n\nInterpretation: Your hypothesis may be directionally correct, but the current implementation likely mixes (a) rare strong continuation events (helpful for return/IR) with (b) many false breakouts/rejections not fully filtered (hurting IC and drawdown).",
        "decision": true,
        "reason": "1) Hard breakout indicators (±1 else 0) create sparse, discontinuous signals; this can improve portfolio returns if the strategy concentrates on rare events, but often hurts IC because most days are near-zero and the ranking becomes noisy. Using a continuous breakout strength (e.g., (C - prev_TS_MAX(H,20))/ATR or /TS_STD(r,20)) should stabilize cross-sectional ranking.\n\n2) Relative volume as V/MA20(V) can overweight extreme “news/climax” days that frequently mean-revert. Clipping/log-scaling rel-vol (e.g., log(1+V/MA20(V)) or winsorize to [0, p95]) typically reduces drawdown and can improve IC.\n\n3) A critical implementation detail: Donchian breakout should use prior range (exclude today) to avoid inadvertent self-referential boundaries. Use TS_MAX(H,20).shift(1) and TS_MIN(L,20).shift(1) as the breakout thresholds. If not shifted, the breakout condition becomes stricter and may distort event timing, which can reduce IC.\n\n4) Anatomy filters: CLV and body-fraction are good, but they can be refined to specifically penalize rejection (long opposite-side wick). A direct wick-share term often works better than CLV alone. This can reduce false breakouts and drawdown.\n\nConcrete next iterations within the same framework (keep factors simple, vary only a few knobs):\n- Parameter sweeps (static factors, separate definitions):\n  * Donchian window: 10, 20, 55 (three separate factors)\n  * Compression window: 10, 20, 30\n  * Context rank window: 60 vs 120\n  * Rel-vol window: 10 vs 20\n- Replace indicator with breakout distance:\n  * UpStrength = (C - prev_TS_MAX(H,n)) / C (or /ATR20), DownStrength = (prev_TS_MIN(L,n) - C)/C; Factor = UpStrength - DownStrength.\n- Robust normalization:\n  * Use z-score or TSRANK only on compression components; clip rel-vol and breakout strength.\n- Separate long/short legs as separate factors (two outputs):\n  * One factor for up-break continuation only, another for down-break continuation only. This often improves stability because down-breaks behave differently (short-sale constraints, limit-down effects).\n- Add a minimal regime filter (still same hypothesis):\n  * Only act when market/stock is in low-vol regime: TS_STD(r,20) below its TS_RANK(120) threshold; this targets “compression” regimes and can reduce drawdown.\n\nComplexity control note: keep expressions short by choosing either (range/close + ret vol) OR (BB width) OR (MAD versions) as the compression proxy, not all combined in one factor; avoid adding many extra terms beyond 1–2 anatomy terms + 1 volume term + 1 breakout-strength term."
      }
    },
    "a42cd3d3dc67596e": {
      "factor_id": "a42cd3d3dc67596e",
      "factor_name": "BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60",
      "factor_expression": "((ABS(TS_SUM(MEAN($return),3))>TS_QUANTILE(ABS(TS_SUM(MEAN($return),3)),60,0.7))?1:0)*RANK(TS_MEAN(REGBETA($return,MEAN($return),20)*MEAN($return)-$return,3))*RANK(TS_MEAN(ABS($return)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "",
      "factor_description": "Beta-adjusted missed move vs equal-weight market return, smoothed over 3 days, and emphasized when the 3-day market impulse is unusually large (top 30% over a 60D rolling window). Multiplied by a 20D Amihud-style illiquidity proxy so delayed catch-up is stronger in low-attention/illiquid names. Expected sign: higher predicts higher next 1–5D returns.",
      "factor_formulation": "I_t=\\sum_{k=0}^{2}r_{m,t-k},\\; \\beta_{i,t}=\\text{REGBETA}(r_i,r_m,20),\\; MM_{i,t}=\\beta_{i,t}r_{m,t}-r_{i,t},\\; Illiq_{i,t}=\\frac{|r_{i,t}|}{P_{i,t}V_{i,t}};\\; F=\\mathbf{1}\\{|I_t|>Q_{0.7}^{60}(|I|)\\}\\cdot \\text{RANK}(\\overline{MM}^{3})\\cdot \\text{RANK}(\\overline{Illiq}^{20})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f26521eca1c0",
        "parent_trajectory_ids": [
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Stocks that underreact contemporaneously to a strong market-wide impulse (i.e., exhibit a large beta-adjusted ‘missed move’ versus the equal-weight universe return) will tend to catch up over the next 1–5 trading days, and this delayed adjustment is stronger in illiquid/low-attention names measured from OHLCV (e.g., Amihud illiquidity).\n                Concise Observation: The available data (daily OHLCV across a universe) supports building a market proxy from cross-sectional returns and measuring cross-sectional reaction-speed differences via contemporaneous vs lagged co-movement and liquidity proxies, which is orthogonal to purely single-name breakout/reversion regime signals.\n                Concise Justification: A market-proxy lead–lag mechanism captures diffusion/attention frictions: when the common shock is strong and persistent, stocks that fail to co-move on the same day (after controlling for beta) are more likely to adjust in subsequent days, especially when trading frictions (illiquidity) slow immediate price discovery.\n                Concise Knowledge: If information is first incorporated into liquid/high-attention stocks and only later diffuses to illiquid/low-attention stocks, then a stock’s beta-adjusted short-horizon deviation from the market proxy (market move minus own move) should predict same-direction catch-up returns over the next few days, with larger effects when illiquidity is high and when the market impulse is persistent across multiple days.\n                concise Specification: Define daily returns r_i,t=close_i,t/close_i,t-1-1 and equal-weight market return r_mkt,t=MEAN_i(r_i,t); estimate beta_i,t via rolling 20D OLS slope of r_i on r_mkt (intercept optional), compute MissedMove_i,t = beta_i,t*r_mkt,t - r_i,t, and MarketImpulse_t = SUM_{k=0..2} r_mkt,t-k (3D); the factor is DelayCatchup_20_3_20 = ZSCORE(TS_MEAN(MissedMove_i,t,3))*RANK( TS_MEDIAN(|r_i,t|/(close_i,t*volume_i,t+1e-8),20) ) gated by |MarketImpulse_t| in the top 30% of its 60D rolling distribution and optionally excluding idiosyncratic jump days where RANK((high-low)/close) > 0.95; expected sign: higher factor predicts higher next 1–5D returns (catch-up).\n                ",
        "initial_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "planning_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "created_at": "2026-01-21T19:38:34.072613"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1059203940353926,
        "ICIR": 0.0312479041079875,
        "1day.excess_return_without_cost.std": 0.0041023956122041,
        "1day.excess_return_with_cost.annualized_return": 0.0310938624220972,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003293489421932,
        "1day.excess_return_without_cost.annualized_return": 0.0783850482419956,
        "1day.excess_return_with_cost.std": 0.0041050080357826,
        "Rank IC": 0.0191775548234439,
        "IC": 0.0040421822227627,
        "1day.excess_return_without_cost.max_drawdown": -0.0847845385224995,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.2385319443625804,
        "1day.pa": 0.0,
        "l2.valid": 0.9964579902416691,
        "Rank ICIR": 0.1451255816797675,
        "l2.train": 0.9943412603661492,
        "1day.excess_return_with_cost.information_ratio": 0.4909894749518868,
        "1day.excess_return_with_cost.mean": 0.0001306464807651
      },
      "feedback": {
        "observations": "This run only tests two implemented factors (LeadLagMarketLoadingDiff_20D_L1_Illiq20 and ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20). The combined portfolio metrics improved meaningfully on return efficiency (annualized return 0.0784 vs 0.0520; IR 1.2385 vs 0.9726), but deteriorated on risk tail and alignment metrics (max drawdown -0.0848 vs -0.0726 is worse; IC 0.00404 vs 0.00580 is worse). The pattern “higher realized strategy performance with lower IC” suggests either (a) the signal works mainly in extremes/conditional regimes (ranks/products create nonlinearity), or (b) the alpha is not well-captured by a global linear IC metric but still monetizes via the portfolio construction (e.g., top/bottom selection).",
        "hypothesis_evaluation": "Overall, the results provide **partial support** for the hypothesis that underreaction to market-wide impulses leads to short-horizon catch-up, especially in illiquid/low-attention names: both implemented factors explicitly target delayed market adjustment (lead-lag market loading difference; signed residual catch-up) and both are interacted with illiquidity proxies. However, the weaker IC and worse drawdown indicate the effect may be **fragile / regime-dependent** or that the current constructions inject noise (e.g., correlation difference is noisy; residual estimation error; multiplicative rank interaction amplifies tails). Importantly, the most “direct” hypothesis expression (BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60) was **not implemented**, so the strongest test of the missed-move + impulse-gating mechanism has not yet been validated in this experiment.\n\nHyperparameters (explicit):\n- LeadLagMarketLoadingDiff_20D_L1_Illiq20\n  - Market proxy: equal-weight universe return (cross-sectional mean of r_i,t)\n  - Correlation lookback window: 20 trading days\n  - Lag for market return in lead/lag term: 1 day (r_m,t-1)\n  - Illiquidity window: 20 days\n  - Illiquidity definition: Amihud-like |r_i,t|/(P_t*V_t), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK on (corr diff) and RANK on illiq, combined by multiplication\n- ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20\n  - Residual estimation: rolling regression residual over 20 days (REGRESI / market-model)\n  - Residual smoothing window: 3 days (TS_MEAN of -epsilon)\n  - Market impulse window: 2 days (TS_SUM of r_m)\n  - Impulse sign: SIGN(I_t)\n  - Illiquidity proxy window: 20 days\n  - Illiquidity definition: (H-L)/(P*V), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK of signed-smoothed residual term and RANK of illiq, combined by multiplication\n- Not implemented but central to hypothesis test: BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60\n  - Beta window: 20 days (REGBETA)\n  - Missed-move smoothing: 3 days\n  - Impulse window: 3 days (TS_SUM over 3)\n  - Gate quantile level: 0.7 (top 30% absolute impulse)\n  - Gate lookback: 60 days (rolling quantile of |I|)\n  - Illiquidity window: 20 days (Amihud-like)\n  - Combination: indicator gate * RANK(MM_smooth) * RANK(Illiq_smooth)",
        "decision": true,
        "reason": "1) Your stated mechanism is explicitly “strong market-wide impulse → contemporaneous underreaction → 1–5D catch-up,” but the tested factors only approximate the impulse condition (ResidualCatchup uses SIGN of 2D impulse but no magnitude gate; LeadLag corr diff has no impulse gating at all). That mismatch can dilute IC while still allowing profitable extreme sorting.\n2) Both implemented signals rely on noisy estimators (rolling CORR differences; rolling regression residuals). Estimation noise can hurt IC and increase drawdowns. Stabilizing beta/residual (longer window, shrinkage, EWMA weights, or volatility scaling) should improve robustness.\n3) The multiplicative RANK×RANK interaction concentrates exposure in extremes; this can improve annualized return/IR but worsen drawdown and reduce global IC (nonlinear payoff). Testing alternative combination schemes can preserve alpha while reducing tail risk."
      }
    },
    "3777a8c4fb1b8379": {
      "factor_id": "3777a8c4fb1b8379",
      "factor_name": "LeadLagMarketLoadingDiff_20D_L1_Illiq20",
      "factor_expression": "RANK(TS_CORR($return,DELAY(MEAN($return),1),20)-TS_CORR($return,MEAN($return),20))*RANK(TS_MEAN(ABS($return)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close,1),DELAY(MEAN(TS_PCTCHANGE($close,1))+$close*0,1),20)-TS_CORR(TS_PCTCHANGE($close,1),MEAN(TS_PCTCHANGE($close,1))+$close*0,20))*RANK(TS_MEAN(ABS(TS_PCTCHANGE($close,1))/($close*$volume+0.00000001),20))\" # Your output factor expression will be filled in here\n    name = \"LeadLagMarketLoadingDiff_20D_L1_Illiq20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures underreaction by comparing lagged vs contemporaneous co-movement with the equal-weight market: (corr with yesterday market) minus (corr with same-day market), both over 20 days. Multiplied by 20D Amihud-style illiquidity to target slower-adjusting names. Expected sign: higher predicts positive short-horizon catch-up.",
      "factor_formulation": "F=\\text{RANK}(\\text{CORR}_{20}(r_i,r_{m,t-1})-\\text{CORR}_{20}(r_i,r_{m,t}))\\cdot \\text{RANK}\\left(\\overline{\\frac{|r_i|}{PV}}^{20}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f26521eca1c0",
        "parent_trajectory_ids": [
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Stocks that underreact contemporaneously to a strong market-wide impulse (i.e., exhibit a large beta-adjusted ‘missed move’ versus the equal-weight universe return) will tend to catch up over the next 1–5 trading days, and this delayed adjustment is stronger in illiquid/low-attention names measured from OHLCV (e.g., Amihud illiquidity).\n                Concise Observation: The available data (daily OHLCV across a universe) supports building a market proxy from cross-sectional returns and measuring cross-sectional reaction-speed differences via contemporaneous vs lagged co-movement and liquidity proxies, which is orthogonal to purely single-name breakout/reversion regime signals.\n                Concise Justification: A market-proxy lead–lag mechanism captures diffusion/attention frictions: when the common shock is strong and persistent, stocks that fail to co-move on the same day (after controlling for beta) are more likely to adjust in subsequent days, especially when trading frictions (illiquidity) slow immediate price discovery.\n                Concise Knowledge: If information is first incorporated into liquid/high-attention stocks and only later diffuses to illiquid/low-attention stocks, then a stock’s beta-adjusted short-horizon deviation from the market proxy (market move minus own move) should predict same-direction catch-up returns over the next few days, with larger effects when illiquidity is high and when the market impulse is persistent across multiple days.\n                concise Specification: Define daily returns r_i,t=close_i,t/close_i,t-1-1 and equal-weight market return r_mkt,t=MEAN_i(r_i,t); estimate beta_i,t via rolling 20D OLS slope of r_i on r_mkt (intercept optional), compute MissedMove_i,t = beta_i,t*r_mkt,t - r_i,t, and MarketImpulse_t = SUM_{k=0..2} r_mkt,t-k (3D); the factor is DelayCatchup_20_3_20 = ZSCORE(TS_MEAN(MissedMove_i,t,3))*RANK( TS_MEDIAN(|r_i,t|/(close_i,t*volume_i,t+1e-8),20) ) gated by |MarketImpulse_t| in the top 30% of its 60D rolling distribution and optionally excluding idiosyncratic jump days where RANK((high-low)/close) > 0.95; expected sign: higher factor predicts higher next 1–5D returns (catch-up).\n                ",
        "initial_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "planning_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "created_at": "2026-01-21T19:38:34.072613"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1059203940353926,
        "ICIR": 0.0312479041079875,
        "1day.excess_return_without_cost.std": 0.0041023956122041,
        "1day.excess_return_with_cost.annualized_return": 0.0310938624220972,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003293489421932,
        "1day.excess_return_without_cost.annualized_return": 0.0783850482419956,
        "1day.excess_return_with_cost.std": 0.0041050080357826,
        "Rank IC": 0.0191775548234439,
        "IC": 0.0040421822227627,
        "1day.excess_return_without_cost.max_drawdown": -0.0847845385224995,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.2385319443625804,
        "1day.pa": 0.0,
        "l2.valid": 0.9964579902416691,
        "Rank ICIR": 0.1451255816797675,
        "l2.train": 0.9943412603661492,
        "1day.excess_return_with_cost.information_ratio": 0.4909894749518868,
        "1day.excess_return_with_cost.mean": 0.0001306464807651
      },
      "feedback": {
        "observations": "This run only tests two implemented factors (LeadLagMarketLoadingDiff_20D_L1_Illiq20 and ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20). The combined portfolio metrics improved meaningfully on return efficiency (annualized return 0.0784 vs 0.0520; IR 1.2385 vs 0.9726), but deteriorated on risk tail and alignment metrics (max drawdown -0.0848 vs -0.0726 is worse; IC 0.00404 vs 0.00580 is worse). The pattern “higher realized strategy performance with lower IC” suggests either (a) the signal works mainly in extremes/conditional regimes (ranks/products create nonlinearity), or (b) the alpha is not well-captured by a global linear IC metric but still monetizes via the portfolio construction (e.g., top/bottom selection).",
        "hypothesis_evaluation": "Overall, the results provide **partial support** for the hypothesis that underreaction to market-wide impulses leads to short-horizon catch-up, especially in illiquid/low-attention names: both implemented factors explicitly target delayed market adjustment (lead-lag market loading difference; signed residual catch-up) and both are interacted with illiquidity proxies. However, the weaker IC and worse drawdown indicate the effect may be **fragile / regime-dependent** or that the current constructions inject noise (e.g., correlation difference is noisy; residual estimation error; multiplicative rank interaction amplifies tails). Importantly, the most “direct” hypothesis expression (BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60) was **not implemented**, so the strongest test of the missed-move + impulse-gating mechanism has not yet been validated in this experiment.\n\nHyperparameters (explicit):\n- LeadLagMarketLoadingDiff_20D_L1_Illiq20\n  - Market proxy: equal-weight universe return (cross-sectional mean of r_i,t)\n  - Correlation lookback window: 20 trading days\n  - Lag for market return in lead/lag term: 1 day (r_m,t-1)\n  - Illiquidity window: 20 days\n  - Illiquidity definition: Amihud-like |r_i,t|/(P_t*V_t), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK on (corr diff) and RANK on illiq, combined by multiplication\n- ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20\n  - Residual estimation: rolling regression residual over 20 days (REGRESI / market-model)\n  - Residual smoothing window: 3 days (TS_MEAN of -epsilon)\n  - Market impulse window: 2 days (TS_SUM of r_m)\n  - Impulse sign: SIGN(I_t)\n  - Illiquidity proxy window: 20 days\n  - Illiquidity definition: (H-L)/(P*V), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK of signed-smoothed residual term and RANK of illiq, combined by multiplication\n- Not implemented but central to hypothesis test: BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60\n  - Beta window: 20 days (REGBETA)\n  - Missed-move smoothing: 3 days\n  - Impulse window: 3 days (TS_SUM over 3)\n  - Gate quantile level: 0.7 (top 30% absolute impulse)\n  - Gate lookback: 60 days (rolling quantile of |I|)\n  - Illiquidity window: 20 days (Amihud-like)\n  - Combination: indicator gate * RANK(MM_smooth) * RANK(Illiq_smooth)",
        "decision": true,
        "reason": "1) Your stated mechanism is explicitly “strong market-wide impulse → contemporaneous underreaction → 1–5D catch-up,” but the tested factors only approximate the impulse condition (ResidualCatchup uses SIGN of 2D impulse but no magnitude gate; LeadLag corr diff has no impulse gating at all). That mismatch can dilute IC while still allowing profitable extreme sorting.\n2) Both implemented signals rely on noisy estimators (rolling CORR differences; rolling regression residuals). Estimation noise can hurt IC and increase drawdowns. Stabilizing beta/residual (longer window, shrinkage, EWMA weights, or volatility scaling) should improve robustness.\n3) The multiplicative RANK×RANK interaction concentrates exposure in extremes; this can improve annualized return/IR but worsen drawdown and reduce global IC (nonlinear payoff). Testing alternative combination schemes can preserve alpha while reducing tail risk."
      }
    },
    "a2e17a3d79c4338a": {
      "factor_id": "a2e17a3d79c4338a",
      "factor_name": "ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20",
      "factor_expression": "RANK(SIGN(TS_SUM(MEAN($return),2))*TS_MEAN(-REGRESI($return,MEAN($return),20),3))*RANK(TS_MEAN(($high-$low)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SIGN(TS_SUM(MEAN(TS_PCTCHANGE($close,1))+$close*0,2))*TS_MEAN(-REGRESI(TS_PCTCHANGE($close,1),MEAN(TS_PCTCHANGE($close,1))+$close*0,20),3))*RANK(TS_MEAN(($high-$low)/($close*$volume+0.00000001),20))\" # Your output factor expression will be filled in here\n    name = \"ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Uses the negative market-model residual (20D regression of stock return on equal-weight market return) as a beta-adjusted missed-move proxy, smoothed over 3 days and signed by a 2D market impulse direction. Emphasizes illiquid names using a 20D price-range-per-dollar-volume proxy. Expected sign: higher predicts same-direction catch-up over next 1–5 days.",
      "factor_formulation": "I_t=\\sum_{k=0}^{1}r_{m,t-k},\\; \\epsilon_{i,t}=r_{i,t}-\\hat\\beta r_{m,t}-\\hat\\alpha,\\; F=\\text{RANK}(\\text{SIGN}(I_t)\\cdot \\overline{-\\epsilon}^{3})\\cdot \\text{RANK}\\left(\\overline{\\frac{H-L}{PV}}^{20}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f26521eca1c0",
        "parent_trajectory_ids": [
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Stocks that underreact contemporaneously to a strong market-wide impulse (i.e., exhibit a large beta-adjusted ‘missed move’ versus the equal-weight universe return) will tend to catch up over the next 1–5 trading days, and this delayed adjustment is stronger in illiquid/low-attention names measured from OHLCV (e.g., Amihud illiquidity).\n                Concise Observation: The available data (daily OHLCV across a universe) supports building a market proxy from cross-sectional returns and measuring cross-sectional reaction-speed differences via contemporaneous vs lagged co-movement and liquidity proxies, which is orthogonal to purely single-name breakout/reversion regime signals.\n                Concise Justification: A market-proxy lead–lag mechanism captures diffusion/attention frictions: when the common shock is strong and persistent, stocks that fail to co-move on the same day (after controlling for beta) are more likely to adjust in subsequent days, especially when trading frictions (illiquidity) slow immediate price discovery.\n                Concise Knowledge: If information is first incorporated into liquid/high-attention stocks and only later diffuses to illiquid/low-attention stocks, then a stock’s beta-adjusted short-horizon deviation from the market proxy (market move minus own move) should predict same-direction catch-up returns over the next few days, with larger effects when illiquidity is high and when the market impulse is persistent across multiple days.\n                concise Specification: Define daily returns r_i,t=close_i,t/close_i,t-1-1 and equal-weight market return r_mkt,t=MEAN_i(r_i,t); estimate beta_i,t via rolling 20D OLS slope of r_i on r_mkt (intercept optional), compute MissedMove_i,t = beta_i,t*r_mkt,t - r_i,t, and MarketImpulse_t = SUM_{k=0..2} r_mkt,t-k (3D); the factor is DelayCatchup_20_3_20 = ZSCORE(TS_MEAN(MissedMove_i,t,3))*RANK( TS_MEDIAN(|r_i,t|/(close_i,t*volume_i,t+1e-8),20) ) gated by |MarketImpulse_t| in the top 30% of its 60D rolling distribution and optionally excluding idiosyncratic jump days where RANK((high-low)/close) > 0.95; expected sign: higher factor predicts higher next 1–5D returns (catch-up).\n                ",
        "initial_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "planning_direction": "Decompose volatility into price vs volume-driven: Contrast STD5 (pure price vol) against WVMA5 (price-volume resonance); hypothesize that when STD5 is high but WVMA5 is low (price moving without volume confirmation), subsequent returns mean-revert, while high WVMA5 relative to STD5 indicates informed moves that persist.",
        "created_at": "2026-01-21T19:38:34.072613"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1059203940353926,
        "ICIR": 0.0312479041079875,
        "1day.excess_return_without_cost.std": 0.0041023956122041,
        "1day.excess_return_with_cost.annualized_return": 0.0310938624220972,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003293489421932,
        "1day.excess_return_without_cost.annualized_return": 0.0783850482419956,
        "1day.excess_return_with_cost.std": 0.0041050080357826,
        "Rank IC": 0.0191775548234439,
        "IC": 0.0040421822227627,
        "1day.excess_return_without_cost.max_drawdown": -0.0847845385224995,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.2385319443625804,
        "1day.pa": 0.0,
        "l2.valid": 0.9964579902416691,
        "Rank ICIR": 0.1451255816797675,
        "l2.train": 0.9943412603661492,
        "1day.excess_return_with_cost.information_ratio": 0.4909894749518868,
        "1day.excess_return_with_cost.mean": 0.0001306464807651
      },
      "feedback": {
        "observations": "This run only tests two implemented factors (LeadLagMarketLoadingDiff_20D_L1_Illiq20 and ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20). The combined portfolio metrics improved meaningfully on return efficiency (annualized return 0.0784 vs 0.0520; IR 1.2385 vs 0.9726), but deteriorated on risk tail and alignment metrics (max drawdown -0.0848 vs -0.0726 is worse; IC 0.00404 vs 0.00580 is worse). The pattern “higher realized strategy performance with lower IC” suggests either (a) the signal works mainly in extremes/conditional regimes (ranks/products create nonlinearity), or (b) the alpha is not well-captured by a global linear IC metric but still monetizes via the portfolio construction (e.g., top/bottom selection).",
        "hypothesis_evaluation": "Overall, the results provide **partial support** for the hypothesis that underreaction to market-wide impulses leads to short-horizon catch-up, especially in illiquid/low-attention names: both implemented factors explicitly target delayed market adjustment (lead-lag market loading difference; signed residual catch-up) and both are interacted with illiquidity proxies. However, the weaker IC and worse drawdown indicate the effect may be **fragile / regime-dependent** or that the current constructions inject noise (e.g., correlation difference is noisy; residual estimation error; multiplicative rank interaction amplifies tails). Importantly, the most “direct” hypothesis expression (BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60) was **not implemented**, so the strongest test of the missed-move + impulse-gating mechanism has not yet been validated in this experiment.\n\nHyperparameters (explicit):\n- LeadLagMarketLoadingDiff_20D_L1_Illiq20\n  - Market proxy: equal-weight universe return (cross-sectional mean of r_i,t)\n  - Correlation lookback window: 20 trading days\n  - Lag for market return in lead/lag term: 1 day (r_m,t-1)\n  - Illiquidity window: 20 days\n  - Illiquidity definition: Amihud-like |r_i,t|/(P_t*V_t), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK on (corr diff) and RANK on illiq, combined by multiplication\n- ResidualCatchup_SignedImpulse_20Res_3Mean_2Imp_RangeIlliq20\n  - Residual estimation: rolling regression residual over 20 days (REGRESI / market-model)\n  - Residual smoothing window: 3 days (TS_MEAN of -epsilon)\n  - Market impulse window: 2 days (TS_SUM of r_m)\n  - Impulse sign: SIGN(I_t)\n  - Illiquidity proxy window: 20 days\n  - Illiquidity definition: (H-L)/(P*V), then TS_MEAN over 20\n  - Cross-sectional transforms: RANK of signed-smoothed residual term and RANK of illiq, combined by multiplication\n- Not implemented but central to hypothesis test: BetaMissedMove_ImpulseGate_20B_3MM_20Illiq_Q60\n  - Beta window: 20 days (REGBETA)\n  - Missed-move smoothing: 3 days\n  - Impulse window: 3 days (TS_SUM over 3)\n  - Gate quantile level: 0.7 (top 30% absolute impulse)\n  - Gate lookback: 60 days (rolling quantile of |I|)\n  - Illiquidity window: 20 days (Amihud-like)\n  - Combination: indicator gate * RANK(MM_smooth) * RANK(Illiq_smooth)",
        "decision": true,
        "reason": "1) Your stated mechanism is explicitly “strong market-wide impulse → contemporaneous underreaction → 1–5D catch-up,” but the tested factors only approximate the impulse condition (ResidualCatchup uses SIGN of 2D impulse but no magnitude gate; LeadLag corr diff has no impulse gating at all). That mismatch can dilute IC while still allowing profitable extreme sorting.\n2) Both implemented signals rely on noisy estimators (rolling CORR differences; rolling regression residuals). Estimation noise can hurt IC and increase drawdowns. Stabilizing beta/residual (longer window, shrinkage, EWMA weights, or volatility scaling) should improve robustness.\n3) The multiplicative RANK×RANK interaction concentrates exposure in extremes; this can improve annualized return/IR but worsen drawdown and reduce global IC (nonlinear payoff). Testing alternative combination schemes can preserve alpha while reducing tail risk."
      }
    },
    "18c0420c7738a57d": {
      "factor_id": "18c0420c7738a57d",
      "factor_name": "RangeVol_Compression_Gated_10_60_252",
      "factor_expression": "(TS_STD(($high-$low)/($close+1e-8),10) < TS_QUANTILE(TS_STD(($high-$low)/($close+1e-8),10),252,0.1)) ? (TS_STD(($high-$low)/($close+1e-8),10)/(TS_STD(($high-$low)/($close+1e-8),60)+1e-8)) : 0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD(($high-$low)/($close+1e-8),10) < TS_QUANTILE(TS_STD(($high-$low)/($close+1e-8),10),252,0.1)) ? (TS_STD(($high-$low)/($close+1e-8),10)/(TS_STD(($high-$low)/($close+1e-8),60)+1e-8)) : 0\" # Your output factor expression will be filled in here\n    name = \"RangeVol_Compression_Gated_10_60_252\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Volatility-compression (coil) state using normalized daily range. Outputs a positive compression intensity only when 10D range-volatility is below its rolling 252D 10th percentile; otherwise outputs 0.",
      "factor_formulation": "F_t=\\begin{cases}\\frac{\\sigma_{10}(r_t)}{\\sigma_{60}(r_t)+\\epsilon}, & \\sigma_{10}(r_t) < Q_{0.1,252}(\\sigma_{10}(r_t))\\\\0, & \\text{otherwise}\\end{cases},\\quad r_t=\\frac{high_t-low_t}{close_t+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "16cfbf6a8863",
        "parent_trajectory_ids": [
          "f7399d5acc6c"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns exhibit trend continuation after a multi-week volatility-compression “coil” resolves via a channel breakout: if (i) realized true-range volatility over 10D is low relative to 60D and is in the bottom decile of its past-252D distribution, (ii) price breaks above the 20D high (or below the 20D low) with a directional close-in-range (CLV close to +1 for upside / -1 for downside), and (iii) participation is orderly (20D log-volume instability is below its 252D median), then the subsequent 20D return tends to be positive for upside breakouts and negative for downside breakouts; cross-sectionally ranking the combined score should produce a profitable long-short factor.\n                Concise Observation: The available OHLCV data supports constructing orthogonal, longer-horizon continuation features (true-range compression, breakout distance to rolling highs/lows, CLV-based breakout quality, and volume stability) that differ from the parent’s short-horizon, downside-shock mean-reversion and stress/forced-flow conditioning.\n                Concise Justification: A coil-to-breakout regime is economically distinct from shock/exhaustion mean-reversion: compression indicates latent disagreement and constrained trading ranges, while a decisive breakout with strong closing location signals directional control; stable volume suggests broad, non-distressed participation that is more consistent with sustained trends over 10–60 trading days.\n                Concise Knowledge: If volatility compresses for weeks, positioning and information can build without large price movement; when price breaks a recent extreme with a strong close-in-range, delayed trend-following and stop/CTA rebalancing can create intermediate-horizon continuation, and the effect should be stronger when volume is stable (low dispersion of log(volume)) rather than stressed/erratic participation.\n                concise Specification: Define TrueRange_t = max(high-low, |high-delay(close,1)|, |low-delay(close,1)|); CompressionState = (STD(TrueRange/close,10) / (STD(TrueRange/close,60)+1e-12)) * (PCTRANK_252(STD(TrueRange/close,10)) ) with a compression gate PCTRANK_252(STD(TrueRange/close,10)) <= 0.10; BreakoutUp = (close >= TS_MAX(high,20)) and BreakoutDn = (close <= TS_MIN(low,20)); CLV1 = ((close-low)-(high-close))/((high-low)+1e-12); OrderlyVol = STD(LOG(volume+1),20) <= TS_MEDIAN(STD(LOG(volume+1),20),252); Score = OrderlyVol * CompressionGate * [BreakoutUp*CLV1 - BreakoutDn*CLV1]; test cross-sectional rank/standardized Score as a factor targeting forward returns over 10D/20D/60D horizons (separately evaluated), expecting positive association for long (up-breakout) and negative for short (down-breakout).\n                ",
        "initial_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "planning_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "created_at": "2026-01-21T20:08:20.977270"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0888303012235854,
        "ICIR": 0.0468261740321309,
        "1day.excess_return_without_cost.std": 0.0040417875092029,
        "1day.excess_return_with_cost.annualized_return": 0.0419924304897141,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000374988802442,
        "1day.excess_return_without_cost.annualized_return": 0.089247334981206,
        "1day.excess_return_with_cost.std": 0.0040428512357482,
        "Rank IC": 0.0221297872223342,
        "IC": 0.0059759807324776,
        "1day.excess_return_without_cost.max_drawdown": -0.0790868859468466,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4313086652923506,
        "1day.pa": 0.0,
        "l2.valid": 0.99677532623537,
        "Rank ICIR": 0.178958602553461,
        "l2.train": 0.9935725856856964,
        "1day.excess_return_with_cost.information_ratio": 0.6732785407425619,
        "1day.excess_return_with_cost.mean": 0.0001764387835702
      },
      "feedback": {
        "observations": "The combined “coil + channel breakout + orderly volume” implementation improves most return/alpha metrics versus SOTA: annualized return increases from 0.0520 to 0.0892, information ratio rises from 0.9726 to 1.4313, and IC edges up from 0.005798 to 0.005976. The only clear deterioration is max drawdown, which worsens from -0.0726 to -0.0791 (more negative = worse). Net: stronger average performance and efficiency, but with slightly worse tail risk/peak-to-trough behavior.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that volatility-compression breakouts with a quality/participation filter have predictive power cross-sectionally (IC up, IR up, return up). However, the worse max drawdown indicates the current gating/combination may still admit some “false breakouts” or regime-dependent losses (e.g., choppy markets) that hurt tail risk. In other words, the core thesis is validated, but the risk control part (“orderly participation” and/or breakout confirmation) likely needs tightening to reduce drawdown without giving up much return.\n\nFactor-by-factor alignment with hypothesis:\n- RangeVol_Compression_Gated_10_60_252 matches condition (i) well (10D vs 60D, plus bottom-decile-of-252D gating).\n- CLV_Signed_ChannelBreak_20D matches condition (ii), but pay attention to implementation detail: TS_MAX/TS_MIN should be computed on the prior 20 days excluding today’s close to avoid implicit lookahead/self-inclusion effects (use H_20 = rolling max of high with a 1-day lag, similarly for L_20).\n- Orderly_LogVolChange_MAD_Gate_20_252 matches condition (iii) directionally, but it currently outputs negative values when orderly and 0 otherwise; depending on how you combine signals, that sign convention may unintentionally dampen good trades or create nonlinear interactions. Consider making it a positive “quality weight” (higher = more orderly) to simplify downstream combination.",
        "decision": true,
        "reason": "Why this refinement is suggested by the metrics:\n- The big IR/return improvement indicates the signal is real and monetizable.\n- The drawdown deterioration implies episodic adverse clusters—classic for breakout systems when volatility re-expands but price fails to trend (whipsaws). Hard gates (0 else) can create discontinuous exposure and higher turnover around thresholds, which often worsens drawdowns.\n\nConcrete next iterations (keep the same theoretical framework, exhaust variations):\n1) Fix/confirm channel-break computation to avoid self-inclusion\n   - Hyperparameters: channel window = 20D, lag = 1D.\n   - Use H20_prev = TS_MAX(high, 20) shifted by 1 day; L20_prev similarly. This makes the ‘break above prior 20D high’ definition clean.\n\n2) Replace hard quantile gates with continuous weights (smoother risk profile)\n   - Compression weight: instead of outputting 0 when not in bottom decile, use a monotone mapping of the 10D vol percentile over 252D, e.g., Weight = clamp((0.2 - pct_rank)/0.2, 0, 1).\n   - Hyperparameters to sweep: percentile threshold 5%/10%/15%/20%; lookback for percentile = 126/252/504.\n\n3) Combine signals multiplicatively (true ‘setup AND trigger AND quality’)\n   - Proposed composite (example):\n     Score_t = CompressionWeight_t * BreakoutScore_t * OrderlyWeight_t\n   - This enforces the hypothesis logic structurally and usually reduces false positives (often lowering drawdown).\n\n4) Re-parameterize volume “orderly” filter into a positive weight\n   - Current: -MAD if orderly else 0 (negative values).\n   - Alternative: OrderlyWeight = 1 / (1 + MAD20(u)) or (Median252(MAD)-MAD)/Median252(MAD) clipped to [0,1].\n   - Hyperparameters: MAD window = 10/20/30; regime baseline = 126/252; threshold = median vs 60th percentile.\n\n5) Breakout confirmation variants (reduce whipsaws)\n   - Require close above H20_prev by a minimum fraction of ATR or range-vol (e.g., (close - H20_prev) / ATR14 > k).\n   - Hyperparameters: ATR window 10/14/20; k in [0.0, 0.5].\n\n6) Directional asymmetry check (long vs short may behave differently)\n   - Run separate factors for upside-only and downside-only breakouts (two distinct static factors), then test whether short leg is the drawdown driver.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the simplest form that preserves gains: avoid stacking too many gates/windows. The suggested changes (lagging channels, continuous weights, multiplicative combination) improve robustness without materially increasing symbol length or base feature count."
      }
    },
    "4c0347abb450e232": {
      "factor_id": "4c0347abb450e232",
      "factor_name": "CLV_Signed_ChannelBreak_20D",
      "factor_expression": "($close>TS_MAX($high,20))?((((($close-$low)-($high-$close))/($high-$low+1e-8))*($close-TS_MAX($high,20)))/($close+1e-8)):(($close<TS_MIN($low,20))?((((($close-$low)-($high-$close))/($high-$low+1e-8))*($close-TS_MIN($low,20)))/($close+1e-8)):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close>TS_MAX($high,20))?((((($close-$low)-($high-$close))/($high-$low+1e-8))*($close-TS_MAX($high,20)))/($close+1e-8)):(($close<TS_MIN($low,20))?((((($close-$low)-($high-$close))/($high-$low+1e-8))*($close-TS_MIN($low,20)))/($close+1e-8)):0)\" # Your output factor expression will be filled in here\n    name = \"CLV_Signed_ChannelBreak_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Signed breakout quality combining channel break (20D high/low) with close-location value (CLV). Produces positive values for upside breaks with strong closes and negative values for downside breaks with weak closes; otherwise 0.",
      "factor_formulation": "CLV_t=\\frac{(close_t-low_t)-(high_t-close_t)}{(high_t-low_t)+\\epsilon};\\quad F_t=\\mathbb{1}[close_t>H_{20}]\\,CLV_t\\frac{close_t-H_{20}}{close_t+\\epsilon}+\\mathbb{1}[close_t<L_{20}]\\,CLV_t\\frac{close_t-L_{20}}{close_t+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "16cfbf6a8863",
        "parent_trajectory_ids": [
          "f7399d5acc6c"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns exhibit trend continuation after a multi-week volatility-compression “coil” resolves via a channel breakout: if (i) realized true-range volatility over 10D is low relative to 60D and is in the bottom decile of its past-252D distribution, (ii) price breaks above the 20D high (or below the 20D low) with a directional close-in-range (CLV close to +1 for upside / -1 for downside), and (iii) participation is orderly (20D log-volume instability is below its 252D median), then the subsequent 20D return tends to be positive for upside breakouts and negative for downside breakouts; cross-sectionally ranking the combined score should produce a profitable long-short factor.\n                Concise Observation: The available OHLCV data supports constructing orthogonal, longer-horizon continuation features (true-range compression, breakout distance to rolling highs/lows, CLV-based breakout quality, and volume stability) that differ from the parent’s short-horizon, downside-shock mean-reversion and stress/forced-flow conditioning.\n                Concise Justification: A coil-to-breakout regime is economically distinct from shock/exhaustion mean-reversion: compression indicates latent disagreement and constrained trading ranges, while a decisive breakout with strong closing location signals directional control; stable volume suggests broad, non-distressed participation that is more consistent with sustained trends over 10–60 trading days.\n                Concise Knowledge: If volatility compresses for weeks, positioning and information can build without large price movement; when price breaks a recent extreme with a strong close-in-range, delayed trend-following and stop/CTA rebalancing can create intermediate-horizon continuation, and the effect should be stronger when volume is stable (low dispersion of log(volume)) rather than stressed/erratic participation.\n                concise Specification: Define TrueRange_t = max(high-low, |high-delay(close,1)|, |low-delay(close,1)|); CompressionState = (STD(TrueRange/close,10) / (STD(TrueRange/close,60)+1e-12)) * (PCTRANK_252(STD(TrueRange/close,10)) ) with a compression gate PCTRANK_252(STD(TrueRange/close,10)) <= 0.10; BreakoutUp = (close >= TS_MAX(high,20)) and BreakoutDn = (close <= TS_MIN(low,20)); CLV1 = ((close-low)-(high-close))/((high-low)+1e-12); OrderlyVol = STD(LOG(volume+1),20) <= TS_MEDIAN(STD(LOG(volume+1),20),252); Score = OrderlyVol * CompressionGate * [BreakoutUp*CLV1 - BreakoutDn*CLV1]; test cross-sectional rank/standardized Score as a factor targeting forward returns over 10D/20D/60D horizons (separately evaluated), expecting positive association for long (up-breakout) and negative for short (down-breakout).\n                ",
        "initial_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "planning_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "created_at": "2026-01-21T20:08:20.977270"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0888303012235854,
        "ICIR": 0.0468261740321309,
        "1day.excess_return_without_cost.std": 0.0040417875092029,
        "1day.excess_return_with_cost.annualized_return": 0.0419924304897141,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000374988802442,
        "1day.excess_return_without_cost.annualized_return": 0.089247334981206,
        "1day.excess_return_with_cost.std": 0.0040428512357482,
        "Rank IC": 0.0221297872223342,
        "IC": 0.0059759807324776,
        "1day.excess_return_without_cost.max_drawdown": -0.0790868859468466,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4313086652923506,
        "1day.pa": 0.0,
        "l2.valid": 0.99677532623537,
        "Rank ICIR": 0.178958602553461,
        "l2.train": 0.9935725856856964,
        "1day.excess_return_with_cost.information_ratio": 0.6732785407425619,
        "1day.excess_return_with_cost.mean": 0.0001764387835702
      },
      "feedback": {
        "observations": "The combined “coil + channel breakout + orderly volume” implementation improves most return/alpha metrics versus SOTA: annualized return increases from 0.0520 to 0.0892, information ratio rises from 0.9726 to 1.4313, and IC edges up from 0.005798 to 0.005976. The only clear deterioration is max drawdown, which worsens from -0.0726 to -0.0791 (more negative = worse). Net: stronger average performance and efficiency, but with slightly worse tail risk/peak-to-trough behavior.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that volatility-compression breakouts with a quality/participation filter have predictive power cross-sectionally (IC up, IR up, return up). However, the worse max drawdown indicates the current gating/combination may still admit some “false breakouts” or regime-dependent losses (e.g., choppy markets) that hurt tail risk. In other words, the core thesis is validated, but the risk control part (“orderly participation” and/or breakout confirmation) likely needs tightening to reduce drawdown without giving up much return.\n\nFactor-by-factor alignment with hypothesis:\n- RangeVol_Compression_Gated_10_60_252 matches condition (i) well (10D vs 60D, plus bottom-decile-of-252D gating).\n- CLV_Signed_ChannelBreak_20D matches condition (ii), but pay attention to implementation detail: TS_MAX/TS_MIN should be computed on the prior 20 days excluding today’s close to avoid implicit lookahead/self-inclusion effects (use H_20 = rolling max of high with a 1-day lag, similarly for L_20).\n- Orderly_LogVolChange_MAD_Gate_20_252 matches condition (iii) directionally, but it currently outputs negative values when orderly and 0 otherwise; depending on how you combine signals, that sign convention may unintentionally dampen good trades or create nonlinear interactions. Consider making it a positive “quality weight” (higher = more orderly) to simplify downstream combination.",
        "decision": true,
        "reason": "Why this refinement is suggested by the metrics:\n- The big IR/return improvement indicates the signal is real and monetizable.\n- The drawdown deterioration implies episodic adverse clusters—classic for breakout systems when volatility re-expands but price fails to trend (whipsaws). Hard gates (0 else) can create discontinuous exposure and higher turnover around thresholds, which often worsens drawdowns.\n\nConcrete next iterations (keep the same theoretical framework, exhaust variations):\n1) Fix/confirm channel-break computation to avoid self-inclusion\n   - Hyperparameters: channel window = 20D, lag = 1D.\n   - Use H20_prev = TS_MAX(high, 20) shifted by 1 day; L20_prev similarly. This makes the ‘break above prior 20D high’ definition clean.\n\n2) Replace hard quantile gates with continuous weights (smoother risk profile)\n   - Compression weight: instead of outputting 0 when not in bottom decile, use a monotone mapping of the 10D vol percentile over 252D, e.g., Weight = clamp((0.2 - pct_rank)/0.2, 0, 1).\n   - Hyperparameters to sweep: percentile threshold 5%/10%/15%/20%; lookback for percentile = 126/252/504.\n\n3) Combine signals multiplicatively (true ‘setup AND trigger AND quality’)\n   - Proposed composite (example):\n     Score_t = CompressionWeight_t * BreakoutScore_t * OrderlyWeight_t\n   - This enforces the hypothesis logic structurally and usually reduces false positives (often lowering drawdown).\n\n4) Re-parameterize volume “orderly” filter into a positive weight\n   - Current: -MAD if orderly else 0 (negative values).\n   - Alternative: OrderlyWeight = 1 / (1 + MAD20(u)) or (Median252(MAD)-MAD)/Median252(MAD) clipped to [0,1].\n   - Hyperparameters: MAD window = 10/20/30; regime baseline = 126/252; threshold = median vs 60th percentile.\n\n5) Breakout confirmation variants (reduce whipsaws)\n   - Require close above H20_prev by a minimum fraction of ATR or range-vol (e.g., (close - H20_prev) / ATR14 > k).\n   - Hyperparameters: ATR window 10/14/20; k in [0.0, 0.5].\n\n6) Directional asymmetry check (long vs short may behave differently)\n   - Run separate factors for upside-only and downside-only breakouts (two distinct static factors), then test whether short leg is the drawdown driver.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the simplest form that preserves gains: avoid stacking too many gates/windows. The suggested changes (lagging channels, continuous weights, multiplicative combination) improve robustness without materially increasing symbol length or base feature count."
      }
    },
    "3e69641fe8496267": {
      "factor_id": "3e69641fe8496267",
      "factor_name": "Orderly_LogVolChange_MAD_Gate_20_252",
      "factor_expression": "(TS_MAD(DELTA(LOG($volume+1),1),20) < TS_MEDIAN(TS_MAD(DELTA(LOG($volume+1),1),20),252)) ? (-TS_MAD(DELTA(LOG($volume+1),1),20)) : 0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MAD(DELTA(LOG($volume+1),1),20) < TS_MEDIAN(TS_MAD(DELTA(LOG($volume+1),1),20),252)) ? (-TS_MAD(DELTA(LOG($volume+1),1),20)) : 0\" # Your output factor expression will be filled in here\n    name = \"Orderly_LogVolChange_MAD_Gate_20_252\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Orderly participation proxy: penalizes unstable volume by measuring 20D MAD of log-volume daily changes. Emits negative instability only when instability is below its rolling 252D median (orderly regime); otherwise 0.",
      "factor_formulation": "u_t=\\Delta\\log(volume_t+1);\\quad m_t=\\text{MAD}_{20}(u_t);\\quad F_t=\\begin{cases}-m_t,& m_t<\\text{Median}_{252}(m_t)\\\\0,&\\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "16cfbf6a8863",
        "parent_trajectory_ids": [
          "f7399d5acc6c"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns exhibit trend continuation after a multi-week volatility-compression “coil” resolves via a channel breakout: if (i) realized true-range volatility over 10D is low relative to 60D and is in the bottom decile of its past-252D distribution, (ii) price breaks above the 20D high (or below the 20D low) with a directional close-in-range (CLV close to +1 for upside / -1 for downside), and (iii) participation is orderly (20D log-volume instability is below its 252D median), then the subsequent 20D return tends to be positive for upside breakouts and negative for downside breakouts; cross-sectionally ranking the combined score should produce a profitable long-short factor.\n                Concise Observation: The available OHLCV data supports constructing orthogonal, longer-horizon continuation features (true-range compression, breakout distance to rolling highs/lows, CLV-based breakout quality, and volume stability) that differ from the parent’s short-horizon, downside-shock mean-reversion and stress/forced-flow conditioning.\n                Concise Justification: A coil-to-breakout regime is economically distinct from shock/exhaustion mean-reversion: compression indicates latent disagreement and constrained trading ranges, while a decisive breakout with strong closing location signals directional control; stable volume suggests broad, non-distressed participation that is more consistent with sustained trends over 10–60 trading days.\n                Concise Knowledge: If volatility compresses for weeks, positioning and information can build without large price movement; when price breaks a recent extreme with a strong close-in-range, delayed trend-following and stop/CTA rebalancing can create intermediate-horizon continuation, and the effect should be stronger when volume is stable (low dispersion of log(volume)) rather than stressed/erratic participation.\n                concise Specification: Define TrueRange_t = max(high-low, |high-delay(close,1)|, |low-delay(close,1)|); CompressionState = (STD(TrueRange/close,10) / (STD(TrueRange/close,60)+1e-12)) * (PCTRANK_252(STD(TrueRange/close,10)) ) with a compression gate PCTRANK_252(STD(TrueRange/close,10)) <= 0.10; BreakoutUp = (close >= TS_MAX(high,20)) and BreakoutDn = (close <= TS_MIN(low,20)); CLV1 = ((close-low)-(high-close))/((high-low)+1e-12); OrderlyVol = STD(LOG(volume+1),20) <= TS_MEDIAN(STD(LOG(volume+1),20),252); Score = OrderlyVol * CompressionGate * [BreakoutUp*CLV1 - BreakoutDn*CLV1]; test cross-sectional rank/standardized Score as a factor targeting forward returns over 10D/20D/60D horizons (separately evaluated), expecting positive association for long (up-breakout) and negative for short (down-breakout).\n                ",
        "initial_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "planning_direction": "Cross-sectional interaction ranking: Build a composite score using z(RSQR10) - z(KLEN) - z(WVMA5) for trend-quality and another using z(ROC60) * (-z(CORR20)) * z(VSTD5) for capitulation; test whether a long-short portfolio combining top trend-quality and top capitulation outperforms either alone over 5–20d horizons.",
        "created_at": "2026-01-21T20:08:20.977270"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0888303012235854,
        "ICIR": 0.0468261740321309,
        "1day.excess_return_without_cost.std": 0.0040417875092029,
        "1day.excess_return_with_cost.annualized_return": 0.0419924304897141,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000374988802442,
        "1day.excess_return_without_cost.annualized_return": 0.089247334981206,
        "1day.excess_return_with_cost.std": 0.0040428512357482,
        "Rank IC": 0.0221297872223342,
        "IC": 0.0059759807324776,
        "1day.excess_return_without_cost.max_drawdown": -0.0790868859468466,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4313086652923506,
        "1day.pa": 0.0,
        "l2.valid": 0.99677532623537,
        "Rank ICIR": 0.178958602553461,
        "l2.train": 0.9935725856856964,
        "1day.excess_return_with_cost.information_ratio": 0.6732785407425619,
        "1day.excess_return_with_cost.mean": 0.0001764387835702
      },
      "feedback": {
        "observations": "The combined “coil + channel breakout + orderly volume” implementation improves most return/alpha metrics versus SOTA: annualized return increases from 0.0520 to 0.0892, information ratio rises from 0.9726 to 1.4313, and IC edges up from 0.005798 to 0.005976. The only clear deterioration is max drawdown, which worsens from -0.0726 to -0.0791 (more negative = worse). Net: stronger average performance and efficiency, but with slightly worse tail risk/peak-to-trough behavior.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that volatility-compression breakouts with a quality/participation filter have predictive power cross-sectionally (IC up, IR up, return up). However, the worse max drawdown indicates the current gating/combination may still admit some “false breakouts” or regime-dependent losses (e.g., choppy markets) that hurt tail risk. In other words, the core thesis is validated, but the risk control part (“orderly participation” and/or breakout confirmation) likely needs tightening to reduce drawdown without giving up much return.\n\nFactor-by-factor alignment with hypothesis:\n- RangeVol_Compression_Gated_10_60_252 matches condition (i) well (10D vs 60D, plus bottom-decile-of-252D gating).\n- CLV_Signed_ChannelBreak_20D matches condition (ii), but pay attention to implementation detail: TS_MAX/TS_MIN should be computed on the prior 20 days excluding today’s close to avoid implicit lookahead/self-inclusion effects (use H_20 = rolling max of high with a 1-day lag, similarly for L_20).\n- Orderly_LogVolChange_MAD_Gate_20_252 matches condition (iii) directionally, but it currently outputs negative values when orderly and 0 otherwise; depending on how you combine signals, that sign convention may unintentionally dampen good trades or create nonlinear interactions. Consider making it a positive “quality weight” (higher = more orderly) to simplify downstream combination.",
        "decision": true,
        "reason": "Why this refinement is suggested by the metrics:\n- The big IR/return improvement indicates the signal is real and monetizable.\n- The drawdown deterioration implies episodic adverse clusters—classic for breakout systems when volatility re-expands but price fails to trend (whipsaws). Hard gates (0 else) can create discontinuous exposure and higher turnover around thresholds, which often worsens drawdowns.\n\nConcrete next iterations (keep the same theoretical framework, exhaust variations):\n1) Fix/confirm channel-break computation to avoid self-inclusion\n   - Hyperparameters: channel window = 20D, lag = 1D.\n   - Use H20_prev = TS_MAX(high, 20) shifted by 1 day; L20_prev similarly. This makes the ‘break above prior 20D high’ definition clean.\n\n2) Replace hard quantile gates with continuous weights (smoother risk profile)\n   - Compression weight: instead of outputting 0 when not in bottom decile, use a monotone mapping of the 10D vol percentile over 252D, e.g., Weight = clamp((0.2 - pct_rank)/0.2, 0, 1).\n   - Hyperparameters to sweep: percentile threshold 5%/10%/15%/20%; lookback for percentile = 126/252/504.\n\n3) Combine signals multiplicatively (true ‘setup AND trigger AND quality’)\n   - Proposed composite (example):\n     Score_t = CompressionWeight_t * BreakoutScore_t * OrderlyWeight_t\n   - This enforces the hypothesis logic structurally and usually reduces false positives (often lowering drawdown).\n\n4) Re-parameterize volume “orderly” filter into a positive weight\n   - Current: -MAD if orderly else 0 (negative values).\n   - Alternative: OrderlyWeight = 1 / (1 + MAD20(u)) or (Median252(MAD)-MAD)/Median252(MAD) clipped to [0,1].\n   - Hyperparameters: MAD window = 10/20/30; regime baseline = 126/252; threshold = median vs 60th percentile.\n\n5) Breakout confirmation variants (reduce whipsaws)\n   - Require close above H20_prev by a minimum fraction of ATR or range-vol (e.g., (close - H20_prev) / ATR14 > k).\n   - Hyperparameters: ATR window 10/14/20; k in [0.0, 0.5].\n\n6) Directional asymmetry check (long vs short may behave differently)\n   - Run separate factors for upside-only and downside-only breakouts (two distinct static factors), then test whether short leg is the drawdown driver.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the simplest form that preserves gains: avoid stacking too many gates/windows. The suggested changes (lagging channels, continuous weights, multiplicative combination) improve robustness without materially increasing symbol length or base feature count."
      }
    },
    "efac4dc19571ba6e": {
      "factor_id": "efac4dc19571ba6e",
      "factor_name": "AmihudShock_ContrarianGate_Z60_Top10_Bot10",
      "factor_expression": "((RANK(TS_ZSCORE(ABS($return)/($close*$volume+1e-8),60))>0.9)&&(RANK(TS_ZSCORE($close*$volume,60))<0.1)&&(RANK(ABS($return))>0.9))?(-SIGN($return)*TS_ZSCORE(ABS($return)/($close*$volume+1e-8),60)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($close*$volume+1e-8),60))>0.9)&&(RANK(TS_ZSCORE($close*$volume,60))<0.1)&&(RANK(ABS(TS_PCTCHANGE($close,1)))>0.9))?(-SIGN(TS_PCTCHANGE($close,1))*TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($close*$volume+1e-8),60)):(0)\" # Your output factor expression will be filled in here\n    name = \"AmihudShock_ContrarianGate_Z60_Top10_Bot10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Nonlinear mean-reversion signal after suspected price-impact shocks: take a contrarian direction only when (i) Amihud illiquidity is extreme (top 10% cross-section), (ii) dollar volume is unusually low (bottom 10% cross-section), and (iii) absolute return is extreme (top 10% cross-section). Illiquidity is time-series standardized over 60D. Hyperparameters: TS_ZSCORE window=60, gates=0.9/0.1, eps=1e-8.",
      "factor_formulation": "ILLIQ_t=\\frac{|r_t|}{Close_t\\,Vol_t+\\epsilon},\\; z_t=\\text{ZSCORE}_{60}(ILLIQ_t)\\\\F_t=\\begin{cases}-\\text{sign}(r_t)\\,z_t,& \\text{if }\\text{rank}(z_t)>0.9\\wedge\\text{rank}(\\text{ZSCORE}_{60}(Close\\cdot Vol))<0.1\\wedge\\text{rank}(|r_t|)>0.9\\\\0,&\\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "00d42e908965",
        "parent_trajectory_ids": [
          "2741a81b9699"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit nonlinear mean-reversion after liquidity/price-impact shocks: when a stock has an unusually large absolute daily return on unusually low dollar volume (high Amihud illiquidity z-score) the move is dominated by temporary price pressure and partially reverses over the next few days, so a contrarian signal gated by extreme impact and thin-trading thresholds should predict next-horizon returns.\n                Concise Observation: The available OHLCV data supports direct construction of Amihud-style illiquidity (|r|/(close*volume)), time-series standardization (e.g., 60D z-scores), and cross-sectional daily percentile/decile gating, enabling explicit testing of tail-event liquidity shocks without using the parent strategy’s drawdown/compression/breakout regime features.\n                Concise Justification: A large return printed on thin dollar volume implies high inventory/impact costs and lower information content, so the price is more likely to revert as liquidity replenishes; using nonlinear quantile gates isolates these transient, microstructure-driven dislocations and reduces contamination from information-driven high-volume moves that tend to persist.\n                Concise Knowledge: If daily price changes are driven by order-imbalance under limited liquidity (high |r| per unit dollar volume), then the marginal trade has high price impact and the resulting move is more likely to be transitory; when impact shocks cluster in the extreme tails (e.g., top-decile illiquidity with bottom-decile dollar volume), a thresholded contrarian rule should outperform a linear score for predicting 1–5D mean reversion.\n                concise Specification: Define r1_t=close_t/close_{t-1}-1 and DollarVol_t=close_t*volume_t; compute ILLIQ_t=abs(r1_t)/(DollarVol_t+1e-12), zILLIQ60_t=(ILLIQ_t-mean(ILLIQ_{t-59:t}))/(std(ILLIQ_{t-59:t})+1e-12), zDV60_t=(DollarVol_t-mean(DollarVol_{t-59:t}))/(std(DollarVol_{t-59:t})+1e-12), and cross-sectional ranks each day; factor (single output) = -sign(r1_t)*zILLIQ60_t * 1{rank(zILLIQ60_t) in top 10% AND rank(zDV60_t) in bottom 10% AND rank(abs(r1_t)) in top 10%}, expecting positive next 1–5D returns after negative shocks and negative next 1–5D returns after positive shocks; hyperparameters are fixed: TS z-score window=60, tail thresholds=10%/90%, eps=1e-12, inputs limited to daily_pv.h5 (close, volume).\n                ",
        "initial_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "planning_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "created_at": "2026-01-21T20:18:54.082156"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0970308108347253,
        "ICIR": 0.0430682344333483,
        "1day.excess_return_without_cost.std": 0.0041990383271403,
        "1day.excess_return_with_cost.annualized_return": 0.0312460580217528,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003282976545676,
        "1day.excess_return_without_cost.annualized_return": 0.0781348417870964,
        "1day.excess_return_with_cost.std": 0.0041991168226794,
        "Rank IC": 0.0222304087744675,
        "IC": 0.0057215907563037,
        "1day.excess_return_without_cost.max_drawdown": -0.0896807877292842,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.206164160450686,
        "1day.pa": 0.0,
        "l2.valid": 0.9966115778012706,
        "Rank ICIR": 0.1778998816583012,
        "l2.train": 0.9935100056009158,
        "1day.excess_return_with_cost.information_ratio": 0.4823350245136325,
        "1day.excess_return_with_cost.mean": 0.0001312859580745
      },
      "feedback": {
        "observations": "Across the three implemented variants, the combined experiment improves return efficiency vs the prior SOTA but gives up some downside control and slightly weakens IC. Specifically: (1) Annualized excess return improves (0.0781 vs 0.0520), and information ratio improves materially (1.206 vs 0.973), which indicates the signal is monetizing something systematic and not purely noise. (2) Max drawdown is worse (0.0897 vs 0.0726; smaller is better), suggesting the strategy’s tail events/risk clustering are not well controlled under the current gating/position-sizing. (3) IC is marginally lower (0.00572 vs 0.00580), implying the predictive relationship is not stronger in pure correlation terms; the PnL improvement likely comes from nonlinearity (rare-event capture), better payoff asymmetry, or implicit risk/turnover differences rather than broad monotonic prediction across the universe.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that short-horizon mean reversion exists after price-impact/liquidity shocks, because the contrarian, shock-gated construction produces higher annualized return and higher IR than SOTA. However, two caveats temper the support: (i) the slightly weaker IC suggests the effect may be concentrated in a small subset of days/stocks (consistent with a “shock” story), rather than a pervasive cross-sectional predictor; and (ii) the worse max drawdown indicates that the current hard-gating and scaling (e.g., -sign(r)*z) may expose the portfolio to episodic continuation/crash risk (e.g., genuine information shocks misclassified as temporary pressure), which is exactly the primary failure mode of contrarian-after-big-move signals. Net: hypothesis is directionally validated, but robustness/risk filters are the next priority within the same framework.",
        "decision": true,
        "reason": "Hard cross-sectional gates (top 10% / bottom 10–20%) create discontinuous exposures: a small change in ranks flips positions on/off, which can amplify drawdowns during stress and make performance sensitive to threshold choice. Also, using raw daily return magnitude can confound impact pressure with high-volatility regimes (earnings/news), where continuation is more likely. Therefore, within the same theoretical concept (impact-shock mean reversion), the next iteration should focus on (a) continuous/soft gating and (b) regime discrimination (volatility and market-move conditioning) to avoid betting against genuine information-driven jumps."
      }
    },
    "5447861ef4d0772d": {
      "factor_id": "5447861ef4d0772d",
      "factor_name": "ILLIQShock_Contrarian_TSQuantile60_90_10",
      "factor_expression": "((ABS($return)/($close*$volume+1e-8)>TS_QUANTILE(ABS($return)/($close*$volume+1e-8),60,0.9))&&($close*$volume<TS_QUANTILE($close*$volume,60,0.1))&&(ABS($return)>TS_QUANTILE(ABS($return),60,0.9)))?(-SIGN($return)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((ABS(TS_PCTCHANGE($close,1))/($close*$volume+1e-8)>TS_QUANTILE(ABS(TS_PCTCHANGE($close,1))/($close*$volume+1e-8),60,0.9))&&($close*$volume<TS_QUANTILE($close*$volume,60,0.1))&&(ABS(TS_PCTCHANGE($close,1))>TS_QUANTILE(ABS(TS_PCTCHANGE($close,1)),60,0.9)))?(-SIGN(TS_PCTCHANGE($close,1))):(0)\" # Your output factor expression will be filled in here\n    name = \"ILLIQShock_Contrarian_TSQuantile60_90_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "History-relative (per-stock) liquidity-shock contrarian: trigger only when current Amihud illiquidity exceeds its own 60D 90th percentile, dollar volume is below its own 60D 10th percentile, and |return| exceeds its own 60D 90th percentile. Outputs pure direction (-sign(return)) to isolate nonlinear mean reversion. Hyperparameters: rolling window=60, quantiles=0.9/0.1, eps=1e-8.",
      "factor_formulation": "ILLIQ_t=\\frac{|r_t|}{Close_t\\,Vol_t+\\epsilon}\\\\F_t=\\begin{cases}-\\text{sign}(r_t),& ILLIQ_t>Q_{0.9}^{60}(ILLIQ)\\wedge DV_t<Q_{0.1}^{60}(DV)\\wedge |r_t|>Q_{0.9}^{60}(|r|)\\\\0,&\\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "00d42e908965",
        "parent_trajectory_ids": [
          "2741a81b9699"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit nonlinear mean-reversion after liquidity/price-impact shocks: when a stock has an unusually large absolute daily return on unusually low dollar volume (high Amihud illiquidity z-score) the move is dominated by temporary price pressure and partially reverses over the next few days, so a contrarian signal gated by extreme impact and thin-trading thresholds should predict next-horizon returns.\n                Concise Observation: The available OHLCV data supports direct construction of Amihud-style illiquidity (|r|/(close*volume)), time-series standardization (e.g., 60D z-scores), and cross-sectional daily percentile/decile gating, enabling explicit testing of tail-event liquidity shocks without using the parent strategy’s drawdown/compression/breakout regime features.\n                Concise Justification: A large return printed on thin dollar volume implies high inventory/impact costs and lower information content, so the price is more likely to revert as liquidity replenishes; using nonlinear quantile gates isolates these transient, microstructure-driven dislocations and reduces contamination from information-driven high-volume moves that tend to persist.\n                Concise Knowledge: If daily price changes are driven by order-imbalance under limited liquidity (high |r| per unit dollar volume), then the marginal trade has high price impact and the resulting move is more likely to be transitory; when impact shocks cluster in the extreme tails (e.g., top-decile illiquidity with bottom-decile dollar volume), a thresholded contrarian rule should outperform a linear score for predicting 1–5D mean reversion.\n                concise Specification: Define r1_t=close_t/close_{t-1}-1 and DollarVol_t=close_t*volume_t; compute ILLIQ_t=abs(r1_t)/(DollarVol_t+1e-12), zILLIQ60_t=(ILLIQ_t-mean(ILLIQ_{t-59:t}))/(std(ILLIQ_{t-59:t})+1e-12), zDV60_t=(DollarVol_t-mean(DollarVol_{t-59:t}))/(std(DollarVol_{t-59:t})+1e-12), and cross-sectional ranks each day; factor (single output) = -sign(r1_t)*zILLIQ60_t * 1{rank(zILLIQ60_t) in top 10% AND rank(zDV60_t) in bottom 10% AND rank(abs(r1_t)) in top 10%}, expecting positive next 1–5D returns after negative shocks and negative next 1–5D returns after positive shocks; hyperparameters are fixed: TS z-score window=60, tail thresholds=10%/90%, eps=1e-12, inputs limited to daily_pv.h5 (close, volume).\n                ",
        "initial_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "planning_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "created_at": "2026-01-21T20:18:54.082156"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0970308108347253,
        "ICIR": 0.0430682344333483,
        "1day.excess_return_without_cost.std": 0.0041990383271403,
        "1day.excess_return_with_cost.annualized_return": 0.0312460580217528,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003282976545676,
        "1day.excess_return_without_cost.annualized_return": 0.0781348417870964,
        "1day.excess_return_with_cost.std": 0.0041991168226794,
        "Rank IC": 0.0222304087744675,
        "IC": 0.0057215907563037,
        "1day.excess_return_without_cost.max_drawdown": -0.0896807877292842,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.206164160450686,
        "1day.pa": 0.0,
        "l2.valid": 0.9966115778012706,
        "Rank ICIR": 0.1778998816583012,
        "l2.train": 0.9935100056009158,
        "1day.excess_return_with_cost.information_ratio": 0.4823350245136325,
        "1day.excess_return_with_cost.mean": 0.0001312859580745
      },
      "feedback": {
        "observations": "Across the three implemented variants, the combined experiment improves return efficiency vs the prior SOTA but gives up some downside control and slightly weakens IC. Specifically: (1) Annualized excess return improves (0.0781 vs 0.0520), and information ratio improves materially (1.206 vs 0.973), which indicates the signal is monetizing something systematic and not purely noise. (2) Max drawdown is worse (0.0897 vs 0.0726; smaller is better), suggesting the strategy’s tail events/risk clustering are not well controlled under the current gating/position-sizing. (3) IC is marginally lower (0.00572 vs 0.00580), implying the predictive relationship is not stronger in pure correlation terms; the PnL improvement likely comes from nonlinearity (rare-event capture), better payoff asymmetry, or implicit risk/turnover differences rather than broad monotonic prediction across the universe.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that short-horizon mean reversion exists after price-impact/liquidity shocks, because the contrarian, shock-gated construction produces higher annualized return and higher IR than SOTA. However, two caveats temper the support: (i) the slightly weaker IC suggests the effect may be concentrated in a small subset of days/stocks (consistent with a “shock” story), rather than a pervasive cross-sectional predictor; and (ii) the worse max drawdown indicates that the current hard-gating and scaling (e.g., -sign(r)*z) may expose the portfolio to episodic continuation/crash risk (e.g., genuine information shocks misclassified as temporary pressure), which is exactly the primary failure mode of contrarian-after-big-move signals. Net: hypothesis is directionally validated, but robustness/risk filters are the next priority within the same framework.",
        "decision": true,
        "reason": "Hard cross-sectional gates (top 10% / bottom 10–20%) create discontinuous exposures: a small change in ranks flips positions on/off, which can amplify drawdowns during stress and make performance sensitive to threshold choice. Also, using raw daily return magnitude can confound impact pressure with high-volatility regimes (earnings/news), where continuation is more likely. Therefore, within the same theoretical concept (impact-shock mean reversion), the next iteration should focus on (a) continuous/soft gating and (b) regime discrimination (volatility and market-move conditioning) to avoid betting against genuine information-driven jumps."
      }
    },
    "71e38a0a55593b12": {
      "factor_id": "71e38a0a55593b12",
      "factor_name": "LogILLIQShock_ContrarianGate_Z60_Top10_Bot20",
      "factor_expression": "((RANK(TS_ZSCORE(LOG(ABS($return)+1e-8)-LOG($close*$volume+1e-8),60))>0.9)&&(RANK($close*$volume)<0.2))?(-SIGN($return)*TS_ZSCORE(LOG(ABS($return)+1e-8)-LOG($close*$volume+1e-8),60)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(((RANK(TS_ZSCORE(LOG(ABS(TS_PCTCHANGE($close,1))+1e-8)-LOG($close*$volume+1e-8),60))>0.9))&&((RANK($close*$volume)<0.2)))?(-SIGN(TS_PCTCHANGE($close,1))*TS_ZSCORE(LOG(ABS(TS_PCTCHANGE($close,1))+1e-8)-LOG($close*$volume+1e-8),60)):(0)\" # Your output factor expression will be filled in here\n    name = \"LogILLIQShock_ContrarianGate_Z60_Top10_Bot20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Log-amihud variant to reduce scale effects: use 60D z-score of log(|return|) minus log(dollar volume) as an impact proxy, then apply cross-sectional tail gates (top 10% impact, bottom 20% dollar volume) and take contrarian direction scaled by the standardized impact. Hyperparameters: TS_ZSCORE window=60, gates=0.9/0.2, eps=1e-8.",
      "factor_formulation": "x_t=\\log(|r_t|+\\epsilon)-\\log(Close_t\\,Vol_t+\\epsilon),\\; z_t=\\text{ZSCORE}_{60}(x_t)\\\\F_t=\\begin{cases}-\\text{sign}(r_t)\\,z_t,& \\text{if }\\text{rank}(z_t)>0.9\\wedge\\text{rank}(DV_t)<0.2\\\\0,&\\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "00d42e908965",
        "parent_trajectory_ids": [
          "2741a81b9699"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–5D) returns exhibit nonlinear mean-reversion after liquidity/price-impact shocks: when a stock has an unusually large absolute daily return on unusually low dollar volume (high Amihud illiquidity z-score) the move is dominated by temporary price pressure and partially reverses over the next few days, so a contrarian signal gated by extreme impact and thin-trading thresholds should predict next-horizon returns.\n                Concise Observation: The available OHLCV data supports direct construction of Amihud-style illiquidity (|r|/(close*volume)), time-series standardization (e.g., 60D z-scores), and cross-sectional daily percentile/decile gating, enabling explicit testing of tail-event liquidity shocks without using the parent strategy’s drawdown/compression/breakout regime features.\n                Concise Justification: A large return printed on thin dollar volume implies high inventory/impact costs and lower information content, so the price is more likely to revert as liquidity replenishes; using nonlinear quantile gates isolates these transient, microstructure-driven dislocations and reduces contamination from information-driven high-volume moves that tend to persist.\n                Concise Knowledge: If daily price changes are driven by order-imbalance under limited liquidity (high |r| per unit dollar volume), then the marginal trade has high price impact and the resulting move is more likely to be transitory; when impact shocks cluster in the extreme tails (e.g., top-decile illiquidity with bottom-decile dollar volume), a thresholded contrarian rule should outperform a linear score for predicting 1–5D mean reversion.\n                concise Specification: Define r1_t=close_t/close_{t-1}-1 and DollarVol_t=close_t*volume_t; compute ILLIQ_t=abs(r1_t)/(DollarVol_t+1e-12), zILLIQ60_t=(ILLIQ_t-mean(ILLIQ_{t-59:t}))/(std(ILLIQ_{t-59:t})+1e-12), zDV60_t=(DollarVol_t-mean(DollarVol_{t-59:t}))/(std(DollarVol_{t-59:t})+1e-12), and cross-sectional ranks each day; factor (single output) = -sign(r1_t)*zILLIQ60_t * 1{rank(zILLIQ60_t) in top 10% AND rank(zDV60_t) in bottom 10% AND rank(abs(r1_t)) in top 10%}, expecting positive next 1–5D returns after negative shocks and negative next 1–5D returns after positive shocks; hyperparameters are fixed: TS z-score window=60, tail thresholds=10%/90%, eps=1e-12, inputs limited to daily_pv.h5 (close, volume).\n                ",
        "initial_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "planning_direction": "Nonlinear threshold effects: Instead of linear combinations, test quantile-based rules such as: go long when ROC60 in top decile AND CORR20 in bottom decile AND VSTD5 in top decile; separately test short rules using opposite tails, to capture tail-event dynamics.",
        "created_at": "2026-01-21T20:18:54.082156"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0970308108347253,
        "ICIR": 0.0430682344333483,
        "1day.excess_return_without_cost.std": 0.0041990383271403,
        "1day.excess_return_with_cost.annualized_return": 0.0312460580217528,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003282976545676,
        "1day.excess_return_without_cost.annualized_return": 0.0781348417870964,
        "1day.excess_return_with_cost.std": 0.0041991168226794,
        "Rank IC": 0.0222304087744675,
        "IC": 0.0057215907563037,
        "1day.excess_return_without_cost.max_drawdown": -0.0896807877292842,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.206164160450686,
        "1day.pa": 0.0,
        "l2.valid": 0.9966115778012706,
        "Rank ICIR": 0.1778998816583012,
        "l2.train": 0.9935100056009158,
        "1day.excess_return_with_cost.information_ratio": 0.4823350245136325,
        "1day.excess_return_with_cost.mean": 0.0001312859580745
      },
      "feedback": {
        "observations": "Across the three implemented variants, the combined experiment improves return efficiency vs the prior SOTA but gives up some downside control and slightly weakens IC. Specifically: (1) Annualized excess return improves (0.0781 vs 0.0520), and information ratio improves materially (1.206 vs 0.973), which indicates the signal is monetizing something systematic and not purely noise. (2) Max drawdown is worse (0.0897 vs 0.0726; smaller is better), suggesting the strategy’s tail events/risk clustering are not well controlled under the current gating/position-sizing. (3) IC is marginally lower (0.00572 vs 0.00580), implying the predictive relationship is not stronger in pure correlation terms; the PnL improvement likely comes from nonlinearity (rare-event capture), better payoff asymmetry, or implicit risk/turnover differences rather than broad monotonic prediction across the universe.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that short-horizon mean reversion exists after price-impact/liquidity shocks, because the contrarian, shock-gated construction produces higher annualized return and higher IR than SOTA. However, two caveats temper the support: (i) the slightly weaker IC suggests the effect may be concentrated in a small subset of days/stocks (consistent with a “shock” story), rather than a pervasive cross-sectional predictor; and (ii) the worse max drawdown indicates that the current hard-gating and scaling (e.g., -sign(r)*z) may expose the portfolio to episodic continuation/crash risk (e.g., genuine information shocks misclassified as temporary pressure), which is exactly the primary failure mode of contrarian-after-big-move signals. Net: hypothesis is directionally validated, but robustness/risk filters are the next priority within the same framework.",
        "decision": true,
        "reason": "Hard cross-sectional gates (top 10% / bottom 10–20%) create discontinuous exposures: a small change in ranks flips positions on/off, which can amplify drawdowns during stress and make performance sensitive to threshold choice. Also, using raw daily return magnitude can confound impact pressure with high-volatility regimes (earnings/news), where continuation is more likely. Therefore, within the same theoretical concept (impact-shock mean reversion), the next iteration should focus on (a) continuous/soft gating and (b) regime discrimination (volatility and market-move conditioning) to avoid betting against genuine information-driven jumps."
      }
    },
    "192295de2b785e4c": {
      "factor_id": "192295de2b785e4c",
      "factor_name": "LiquidityShockRejection_Reversal_60D",
      "factor_expression": "-SIGN($return)*MAX(TS_ZSCORE($volume,60),0)*MAX(TS_ZSCORE(ABS($return)/($volume+1e-8),60),0)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*(1-ABS($close-$open)/($high-$low+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1))*MAX(TS_ZSCORE($volume,60),0)*MAX(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($volume+1e-8),60),0)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*(1-ABS($close-$open)/($high-$low+1e-8))\" # Your output factor expression will be filled in here\n    name = \"LiquidityShockRejection_Reversal_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian exhaustion signal for next 1~3D: activates when a 1D move occurs with unusually high volume (liquidity event) and unusually high price impact per unit volume, and the candle shows intraday rejection (close away from extremes + small body vs range). Direction is set to mean-revert opposite the 1D return. Lookback windows: 60D for liquidity/impact normalization; same-day candle anatomy.",
      "factor_formulation": "F= -\\operatorname{sign}(r_1)\\cdot\\max(z_v,0)\\cdot\\max(z_{imp},0)\\cdot\\left(1-|clv|\\right)\\cdot\\left(1-\\frac{|c-o|}{h-l+\\epsilon}\\right),\\; z_v=\\text{TSZ}(vol,60),\\; z_{imp}=\\text{TSZ}(|r_1|/(vol+\\epsilon),60),\\; clv=\\frac{2c-h-l}{h-l+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ea6a92775693",
        "parent_trajectory_ids": [
          "d527d4cd9dac"
        ],
        "hypothesis": "Hypothesis: Liquidity-shock exhaustion reversal: If a stock exhibits a 1-day large move that is simultaneously (i) liquidity-expensive (high |return| per unit volume / high range-per-volume) and (ii) accompanied by intraday rejection (high wickiness / weak close-location), then the move is likely driven by transient order-flow imbalance and next-1~3D returns will mean-revert opposite to the 1D move.\n                Concise Observation: The available daily data (OHLCV) supports constructing orthogonal signals to volatility-compression/trend/overnight-gap features by directly measuring (a) volume shocks, (b) impact per volume, and (c) candle anatomy (wick/close-location), enabling a distinct short-horizon contrarian mechanism testable with next-1~3D returns.\n                Concise Justification: A high-volume, high-impact day with strong intraday rejection suggests adverse selection and liquidity-provider inventory pressure; the price is pushed away from local equilibrium but fails to hold at the extremes, so subsequent days tend to retrace as order-flow normalizes and liquidity providers/arbitrageurs mean-revert the dislocation.\n                Concise Knowledge: If price changes are large relative to trading activity (high illiquidity/price-impact proxies such as |r1|/(vol+eps) or (high-low)/(vol+eps)) and the candle shows rejection (close not near extremes; long wick against the move), then the move is more consistent with temporary liquidity demand/supply imbalance; when that imbalance fades, short-horizon (1~3D) reversals become more likely than continuation.\n                concise Specification: Use daily_pv.h5 OHLCV; compute r1=close/DELAY(close,1)-1, vol_z60=ZSCORE(volume,60), impact=ABS(r1)/(volume+1e-8), impact_z60=ZSCORE(impact,60), range_impact=(high-low)/(volume+1e-8), clv=(2*close-high-low)/(high-low+1e-8), wickiness=(high-low-ABS(close-open))/(high-low+1e-8); define ExhaustionReversal_60_1D as signal = -SIGN(r1) * CLIP(vol_z60,0,3) * CLIP(impact_z60,0,3) * (1-ABS(clv)) * wickiness, optionally gated to activate only when vol_z60>=2 and impact_z60>=2 (else 0), and target predict horizon next-1~3D returns.\n                ",
        "initial_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "planning_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "created_at": "2026-01-21T20:26:46.502072"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0981690974436502,
        "ICIR": 0.0365573228089347,
        "1day.excess_return_without_cost.std": 0.0042713716129582,
        "1day.excess_return_with_cost.annualized_return": 0.0514482453626702,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000413893726716,
        "1day.excess_return_without_cost.annualized_return": 0.0985067069584161,
        "1day.excess_return_with_cost.std": 0.0042731917716184,
        "Rank IC": 0.019548284554843,
        "IC": 0.0052357871998158,
        "1day.excess_return_without_cost.max_drawdown": -0.0902720312984561,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.494892508336079,
        "1day.pa": 0.0,
        "l2.valid": 0.996659446359214,
        "Rank ICIR": 0.1396358778764938,
        "l2.train": 0.9925962239035332,
        "1day.excess_return_with_cost.information_ratio": 0.7804223633445229,
        "1day.excess_return_with_cost.mean": 0.0002161690981624
      },
      "feedback": {
        "observations": "The combined factor set improves return efficiency meaningfully versus SOTA: annualized return rises from 0.0520 to 0.0985 and information ratio rises from 0.9726 to 1.4949. However, max drawdown worsens (more negative: -0.0903 vs -0.0726) and IC slightly declines (0.00524 vs 0.00580). This pattern is consistent with a signal that can monetize short-horizon reversal in PnL terms but may be more episodic/heavy-tailed (worse drawdowns) and/or more nonlinear/conditional (lower global linear IC).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis directionally: a contrarian “liquidity-expensive + intraday rejection” exhaustion concept appears to generate stronger short-horizon excess returns (annualized return) and better risk-adjusted performance (IR), which is exactly what a transient order-flow imbalance mean-reversion story would predict. The deterioration in IC suggests the effect may be conditional (only works in certain regimes or on tail events) rather than broadly monotonic each day, which is still compatible with the hypothesis because the construction explicitly gates on shocks (e.g., max(z,0), TSRank). The worse max drawdown indicates that when the reversal fails (trend days, news continuation), losses cluster—also consistent with the hypothesis needing better regime/continuation filters or exposure scaling.",
        "decision": true,
        "reason": "Your current design correctly gates on (i) illiquidity/impact surprise (|r|/vol) and (ii) rejection anatomy (CLV, body/range), and the PnL uplift vs SOTA indicates this core mechanism is real. The increased drawdown and slightly lower IC point to: (1) tail-event dependence (signal fires on rare days; linear IC underestimates), and (2) continuation regimes where contrarian positioning is punished. Therefore, the next iteration should keep the same theoretical framework but add minimal, interpretable conditioning to avoid trend/news continuation and to control tail risk.\n\nConcrete within-framework refinements to explore (keep expressions simple, low parameter count):\n1) Add a continuation/trend filter (static hyperparameters):\n   - Filter A (trend): only trade if sign(r1) != sign(TS_MEAN(r, 5)) or if |TS_MEAN(r,5)| is small.\n     Hyperparameters: lookback=5 (and test 3, 10 as separate factors).\n   - Filter B (gap/news proxy): downweight if |(open/prev_close-1)| is large (gap continuation often persists).\n     Hyperparameters: gap threshold via TSRank over 60 or z-score over 60.\n\n2) Volatility normalization to reduce drawdown concentration:\n   - Replace |r1| with |r1|/TS_STD(r,20) inside the impact term or add an extra multiplier 1/TS_STD(r,20).\n     Hyperparameters: vol window=20 (also 10, 60 as separate factors).\n\n3) Make activation more selective (reduce false positives):\n   - Current uses max(z,0) and TSRank/40. Try hard gating with an indicator:\n     I[z_imp > 1] * I[z_v > 1] (or TSRank > 0.8) to focus on true shocks.\n     Hyperparameters: thresholds {0.5, 1.0, 1.5} or rank cutoffs {0.7, 0.8, 0.9} as separate factors.\n\n4) Candle rejection decomposition (same-day, no extra features):\n   - Separate upper-wick vs lower-wick rejection depending on direction:\n     For up-move exhaustion: emphasize upper wick = (high - max(open,close))/(high-low+eps)\n     For down-move exhaustion: emphasize lower wick = (min(open,close) - low)/(high-low+eps)\n     Then apply -sign(r1) * wick_directional.\n     Hyperparameters: none beyond existing eps; this often improves alignment vs symmetric (1-|clv|).\n\n5) Impact proxy robustness:\n   - Use dollar volume if available (here only volume): approximate with vol*close.\n     Replace |r1|/(vol+eps) with |r1|/(vol*close+eps).\n     Hyperparameters: same lookbacks (20/40/60) as separate factors.\n\n6) Reduce drawdown via smoothing/decay (still same concept):\n   - Apply a short EMA/SMA on the final signal to avoid single-day spikes:\n     TS_MEAN(F_raw, 3) (and 5).\n     Hyperparameters: smoothing window=3,5.\n\nInterpretation of current three factors (parameter sensitivity guidance):\n- LiquidityShockRejection_Reversal_60D: longer normalization likely more stable but may miss fast regime changes; test 30D and 90D variants as separate factors.\n- RangePerVolume_Rejection_Reversal_40D: TSRank is robust; consider 20D/60D ranks and/or using z-score instead of rank to capture magnitude.\n- VolumeJump_Impact_Reversal_20D: fastest and likely most reactive; consider adding a simple trend filter to reduce worst continuation losses."
      }
    },
    "099095de71e36b05": {
      "factor_id": "099095de71e36b05",
      "factor_name": "RangePerVolume_Rejection_Reversal_40D",
      "factor_expression": "-SIGN($return)*(TS_RANK(($high-$low)/($volume+1e-8),40)/40)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*(1-ABS($close-$open)/($high-$low+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1))*(TS_RANK((($high-$low)/($volume+1e-8)),40)/40)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*(1-ABS($close-$open)/($high-$low+1e-8))\" # Your output factor expression will be filled in here\n    name = \"RangePerVolume_Rejection_Reversal_40D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Exhaustion reversal proxy emphasizing range-based illiquidity: ranks today's range-per-volume versus the past 40D (impact from intraday trading), then weights by rejection anatomy (weak close-location and wickiness). Takes the opposite sign of the 1D return to target short-horizon mean reversion. Lookback: 40D TS rank; same-day candle anatomy.",
      "factor_formulation": "F= -\\operatorname{sign}(r_1)\\cdot \\frac{\\text{TSRANK}((h-l)/(vol+\\epsilon),40)}{40}\\cdot (1-|clv|)\\cdot\\left(1-\\frac{|c-o|}{h-l+\\epsilon}\\right),\\; clv=\\frac{2c-h-l}{h-l+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ea6a92775693",
        "parent_trajectory_ids": [
          "d527d4cd9dac"
        ],
        "hypothesis": "Hypothesis: Liquidity-shock exhaustion reversal: If a stock exhibits a 1-day large move that is simultaneously (i) liquidity-expensive (high |return| per unit volume / high range-per-volume) and (ii) accompanied by intraday rejection (high wickiness / weak close-location), then the move is likely driven by transient order-flow imbalance and next-1~3D returns will mean-revert opposite to the 1D move.\n                Concise Observation: The available daily data (OHLCV) supports constructing orthogonal signals to volatility-compression/trend/overnight-gap features by directly measuring (a) volume shocks, (b) impact per volume, and (c) candle anatomy (wick/close-location), enabling a distinct short-horizon contrarian mechanism testable with next-1~3D returns.\n                Concise Justification: A high-volume, high-impact day with strong intraday rejection suggests adverse selection and liquidity-provider inventory pressure; the price is pushed away from local equilibrium but fails to hold at the extremes, so subsequent days tend to retrace as order-flow normalizes and liquidity providers/arbitrageurs mean-revert the dislocation.\n                Concise Knowledge: If price changes are large relative to trading activity (high illiquidity/price-impact proxies such as |r1|/(vol+eps) or (high-low)/(vol+eps)) and the candle shows rejection (close not near extremes; long wick against the move), then the move is more consistent with temporary liquidity demand/supply imbalance; when that imbalance fades, short-horizon (1~3D) reversals become more likely than continuation.\n                concise Specification: Use daily_pv.h5 OHLCV; compute r1=close/DELAY(close,1)-1, vol_z60=ZSCORE(volume,60), impact=ABS(r1)/(volume+1e-8), impact_z60=ZSCORE(impact,60), range_impact=(high-low)/(volume+1e-8), clv=(2*close-high-low)/(high-low+1e-8), wickiness=(high-low-ABS(close-open))/(high-low+1e-8); define ExhaustionReversal_60_1D as signal = -SIGN(r1) * CLIP(vol_z60,0,3) * CLIP(impact_z60,0,3) * (1-ABS(clv)) * wickiness, optionally gated to activate only when vol_z60>=2 and impact_z60>=2 (else 0), and target predict horizon next-1~3D returns.\n                ",
        "initial_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "planning_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "created_at": "2026-01-21T20:26:46.502072"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0981690974436502,
        "ICIR": 0.0365573228089347,
        "1day.excess_return_without_cost.std": 0.0042713716129582,
        "1day.excess_return_with_cost.annualized_return": 0.0514482453626702,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000413893726716,
        "1day.excess_return_without_cost.annualized_return": 0.0985067069584161,
        "1day.excess_return_with_cost.std": 0.0042731917716184,
        "Rank IC": 0.019548284554843,
        "IC": 0.0052357871998158,
        "1day.excess_return_without_cost.max_drawdown": -0.0902720312984561,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.494892508336079,
        "1day.pa": 0.0,
        "l2.valid": 0.996659446359214,
        "Rank ICIR": 0.1396358778764938,
        "l2.train": 0.9925962239035332,
        "1day.excess_return_with_cost.information_ratio": 0.7804223633445229,
        "1day.excess_return_with_cost.mean": 0.0002161690981624
      },
      "feedback": {
        "observations": "The combined factor set improves return efficiency meaningfully versus SOTA: annualized return rises from 0.0520 to 0.0985 and information ratio rises from 0.9726 to 1.4949. However, max drawdown worsens (more negative: -0.0903 vs -0.0726) and IC slightly declines (0.00524 vs 0.00580). This pattern is consistent with a signal that can monetize short-horizon reversal in PnL terms but may be more episodic/heavy-tailed (worse drawdowns) and/or more nonlinear/conditional (lower global linear IC).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis directionally: a contrarian “liquidity-expensive + intraday rejection” exhaustion concept appears to generate stronger short-horizon excess returns (annualized return) and better risk-adjusted performance (IR), which is exactly what a transient order-flow imbalance mean-reversion story would predict. The deterioration in IC suggests the effect may be conditional (only works in certain regimes or on tail events) rather than broadly monotonic each day, which is still compatible with the hypothesis because the construction explicitly gates on shocks (e.g., max(z,0), TSRank). The worse max drawdown indicates that when the reversal fails (trend days, news continuation), losses cluster—also consistent with the hypothesis needing better regime/continuation filters or exposure scaling.",
        "decision": true,
        "reason": "Your current design correctly gates on (i) illiquidity/impact surprise (|r|/vol) and (ii) rejection anatomy (CLV, body/range), and the PnL uplift vs SOTA indicates this core mechanism is real. The increased drawdown and slightly lower IC point to: (1) tail-event dependence (signal fires on rare days; linear IC underestimates), and (2) continuation regimes where contrarian positioning is punished. Therefore, the next iteration should keep the same theoretical framework but add minimal, interpretable conditioning to avoid trend/news continuation and to control tail risk.\n\nConcrete within-framework refinements to explore (keep expressions simple, low parameter count):\n1) Add a continuation/trend filter (static hyperparameters):\n   - Filter A (trend): only trade if sign(r1) != sign(TS_MEAN(r, 5)) or if |TS_MEAN(r,5)| is small.\n     Hyperparameters: lookback=5 (and test 3, 10 as separate factors).\n   - Filter B (gap/news proxy): downweight if |(open/prev_close-1)| is large (gap continuation often persists).\n     Hyperparameters: gap threshold via TSRank over 60 or z-score over 60.\n\n2) Volatility normalization to reduce drawdown concentration:\n   - Replace |r1| with |r1|/TS_STD(r,20) inside the impact term or add an extra multiplier 1/TS_STD(r,20).\n     Hyperparameters: vol window=20 (also 10, 60 as separate factors).\n\n3) Make activation more selective (reduce false positives):\n   - Current uses max(z,0) and TSRank/40. Try hard gating with an indicator:\n     I[z_imp > 1] * I[z_v > 1] (or TSRank > 0.8) to focus on true shocks.\n     Hyperparameters: thresholds {0.5, 1.0, 1.5} or rank cutoffs {0.7, 0.8, 0.9} as separate factors.\n\n4) Candle rejection decomposition (same-day, no extra features):\n   - Separate upper-wick vs lower-wick rejection depending on direction:\n     For up-move exhaustion: emphasize upper wick = (high - max(open,close))/(high-low+eps)\n     For down-move exhaustion: emphasize lower wick = (min(open,close) - low)/(high-low+eps)\n     Then apply -sign(r1) * wick_directional.\n     Hyperparameters: none beyond existing eps; this often improves alignment vs symmetric (1-|clv|).\n\n5) Impact proxy robustness:\n   - Use dollar volume if available (here only volume): approximate with vol*close.\n     Replace |r1|/(vol+eps) with |r1|/(vol*close+eps).\n     Hyperparameters: same lookbacks (20/40/60) as separate factors.\n\n6) Reduce drawdown via smoothing/decay (still same concept):\n   - Apply a short EMA/SMA on the final signal to avoid single-day spikes:\n     TS_MEAN(F_raw, 3) (and 5).\n     Hyperparameters: smoothing window=3,5.\n\nInterpretation of current three factors (parameter sensitivity guidance):\n- LiquidityShockRejection_Reversal_60D: longer normalization likely more stable but may miss fast regime changes; test 30D and 90D variants as separate factors.\n- RangePerVolume_Rejection_Reversal_40D: TSRank is robust; consider 20D/60D ranks and/or using z-score instead of rank to capture magnitude.\n- VolumeJump_Impact_Reversal_20D: fastest and likely most reactive; consider adding a simple trend filter to reduce worst continuation losses."
      }
    },
    "25d45328d27318e0": {
      "factor_id": "25d45328d27318e0",
      "factor_name": "VolumeJump_Impact_Reversal_20D",
      "factor_expression": "-SIGN($return)*MAX(TS_ZSCORE(TS_PCTCHANGE($volume,1),20),0)*MAX(TS_ZSCORE(ABS($return)/($volume+1e-8),20),0)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1))*MAX(TS_ZSCORE(TS_PCTCHANGE($volume,1),20),0)*MAX(TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/($volume+1e-8),20),0)*(1-ABS((2*$close-$high-$low)/($high-$low+1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VolumeJump_Impact_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Short-window liquidity-shock exhaustion: combines a 1D volume jump (z-scored over 20D) with an illiquidity/impact shock (|return| per volume z-scored over 20D), then applies contrarian sign and requires intraday rejection via weak close-location. Lookbacks: 1D volume pct change; 20D z-scores; same-day close-location.",
      "factor_formulation": "F= -\\operatorname{sign}(r_1)\\cdot\\max(\\text{TSZ}(\\Delta vol/vol,20),0)\\cdot\\max(\\text{TSZ}(|r_1|/(vol+\\epsilon),20),0)\\cdot(1-|clv|),\\; clv=\\frac{2c-h-l}{h-l+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "ea6a92775693",
        "parent_trajectory_ids": [
          "d527d4cd9dac"
        ],
        "hypothesis": "Hypothesis: Liquidity-shock exhaustion reversal: If a stock exhibits a 1-day large move that is simultaneously (i) liquidity-expensive (high |return| per unit volume / high range-per-volume) and (ii) accompanied by intraday rejection (high wickiness / weak close-location), then the move is likely driven by transient order-flow imbalance and next-1~3D returns will mean-revert opposite to the 1D move.\n                Concise Observation: The available daily data (OHLCV) supports constructing orthogonal signals to volatility-compression/trend/overnight-gap features by directly measuring (a) volume shocks, (b) impact per volume, and (c) candle anatomy (wick/close-location), enabling a distinct short-horizon contrarian mechanism testable with next-1~3D returns.\n                Concise Justification: A high-volume, high-impact day with strong intraday rejection suggests adverse selection and liquidity-provider inventory pressure; the price is pushed away from local equilibrium but fails to hold at the extremes, so subsequent days tend to retrace as order-flow normalizes and liquidity providers/arbitrageurs mean-revert the dislocation.\n                Concise Knowledge: If price changes are large relative to trading activity (high illiquidity/price-impact proxies such as |r1|/(vol+eps) or (high-low)/(vol+eps)) and the candle shows rejection (close not near extremes; long wick against the move), then the move is more consistent with temporary liquidity demand/supply imbalance; when that imbalance fades, short-horizon (1~3D) reversals become more likely than continuation.\n                concise Specification: Use daily_pv.h5 OHLCV; compute r1=close/DELAY(close,1)-1, vol_z60=ZSCORE(volume,60), impact=ABS(r1)/(volume+1e-8), impact_z60=ZSCORE(impact,60), range_impact=(high-low)/(volume+1e-8), clv=(2*close-high-low)/(high-low+1e-8), wickiness=(high-low-ABS(close-open))/(high-low+1e-8); define ExhaustionReversal_60_1D as signal = -SIGN(r1) * CLIP(vol_z60,0,3) * CLIP(impact_z60,0,3) * (1-ABS(clv)) * wickiness, optionally gated to activate only when vol_z60>=2 and impact_z60>=2 (else 0), and target predict horizon next-1~3D returns.\n                ",
        "initial_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "planning_direction": "Time-scale mismatch signals: Explore whether short-term noise (RESI5, KLEN, WVMA5, VSTD5 at 5d) predicts the effectiveness of medium/long signals (RSQR10 10d, ROC60 60d); e.g., hypothesize that long-term reversal (ROC60) works best when short-term measures indicate stabilization (declining WVMA5 and VSTD5 over the last 5d).",
        "created_at": "2026-01-21T20:26:46.502072"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0981690974436502,
        "ICIR": 0.0365573228089347,
        "1day.excess_return_without_cost.std": 0.0042713716129582,
        "1day.excess_return_with_cost.annualized_return": 0.0514482453626702,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000413893726716,
        "1day.excess_return_without_cost.annualized_return": 0.0985067069584161,
        "1day.excess_return_with_cost.std": 0.0042731917716184,
        "Rank IC": 0.019548284554843,
        "IC": 0.0052357871998158,
        "1day.excess_return_without_cost.max_drawdown": -0.0902720312984561,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.494892508336079,
        "1day.pa": 0.0,
        "l2.valid": 0.996659446359214,
        "Rank ICIR": 0.1396358778764938,
        "l2.train": 0.9925962239035332,
        "1day.excess_return_with_cost.information_ratio": 0.7804223633445229,
        "1day.excess_return_with_cost.mean": 0.0002161690981624
      },
      "feedback": {
        "observations": "The combined factor set improves return efficiency meaningfully versus SOTA: annualized return rises from 0.0520 to 0.0985 and information ratio rises from 0.9726 to 1.4949. However, max drawdown worsens (more negative: -0.0903 vs -0.0726) and IC slightly declines (0.00524 vs 0.00580). This pattern is consistent with a signal that can monetize short-horizon reversal in PnL terms but may be more episodic/heavy-tailed (worse drawdowns) and/or more nonlinear/conditional (lower global linear IC).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis directionally: a contrarian “liquidity-expensive + intraday rejection” exhaustion concept appears to generate stronger short-horizon excess returns (annualized return) and better risk-adjusted performance (IR), which is exactly what a transient order-flow imbalance mean-reversion story would predict. The deterioration in IC suggests the effect may be conditional (only works in certain regimes or on tail events) rather than broadly monotonic each day, which is still compatible with the hypothesis because the construction explicitly gates on shocks (e.g., max(z,0), TSRank). The worse max drawdown indicates that when the reversal fails (trend days, news continuation), losses cluster—also consistent with the hypothesis needing better regime/continuation filters or exposure scaling.",
        "decision": true,
        "reason": "Your current design correctly gates on (i) illiquidity/impact surprise (|r|/vol) and (ii) rejection anatomy (CLV, body/range), and the PnL uplift vs SOTA indicates this core mechanism is real. The increased drawdown and slightly lower IC point to: (1) tail-event dependence (signal fires on rare days; linear IC underestimates), and (2) continuation regimes where contrarian positioning is punished. Therefore, the next iteration should keep the same theoretical framework but add minimal, interpretable conditioning to avoid trend/news continuation and to control tail risk.\n\nConcrete within-framework refinements to explore (keep expressions simple, low parameter count):\n1) Add a continuation/trend filter (static hyperparameters):\n   - Filter A (trend): only trade if sign(r1) != sign(TS_MEAN(r, 5)) or if |TS_MEAN(r,5)| is small.\n     Hyperparameters: lookback=5 (and test 3, 10 as separate factors).\n   - Filter B (gap/news proxy): downweight if |(open/prev_close-1)| is large (gap continuation often persists).\n     Hyperparameters: gap threshold via TSRank over 60 or z-score over 60.\n\n2) Volatility normalization to reduce drawdown concentration:\n   - Replace |r1| with |r1|/TS_STD(r,20) inside the impact term or add an extra multiplier 1/TS_STD(r,20).\n     Hyperparameters: vol window=20 (also 10, 60 as separate factors).\n\n3) Make activation more selective (reduce false positives):\n   - Current uses max(z,0) and TSRank/40. Try hard gating with an indicator:\n     I[z_imp > 1] * I[z_v > 1] (or TSRank > 0.8) to focus on true shocks.\n     Hyperparameters: thresholds {0.5, 1.0, 1.5} or rank cutoffs {0.7, 0.8, 0.9} as separate factors.\n\n4) Candle rejection decomposition (same-day, no extra features):\n   - Separate upper-wick vs lower-wick rejection depending on direction:\n     For up-move exhaustion: emphasize upper wick = (high - max(open,close))/(high-low+eps)\n     For down-move exhaustion: emphasize lower wick = (min(open,close) - low)/(high-low+eps)\n     Then apply -sign(r1) * wick_directional.\n     Hyperparameters: none beyond existing eps; this often improves alignment vs symmetric (1-|clv|).\n\n5) Impact proxy robustness:\n   - Use dollar volume if available (here only volume): approximate with vol*close.\n     Replace |r1|/(vol+eps) with |r1|/(vol*close+eps).\n     Hyperparameters: same lookbacks (20/40/60) as separate factors.\n\n6) Reduce drawdown via smoothing/decay (still same concept):\n   - Apply a short EMA/SMA on the final signal to avoid single-day spikes:\n     TS_MEAN(F_raw, 3) (and 5).\n     Hyperparameters: smoothing window=3,5.\n\nInterpretation of current three factors (parameter sensitivity guidance):\n- LiquidityShockRejection_Reversal_60D: longer normalization likely more stable but may miss fast regime changes; test 30D and 90D variants as separate factors.\n- RangePerVolume_Rejection_Reversal_40D: TSRank is robust; consider 20D/60D ranks and/or using z-score instead of rank to capture magnitude.\n- VolumeJump_Impact_Reversal_20D: fastest and likely most reactive; consider adding a simple trend filter to reduce worst continuation losses."
      }
    },
    "159002c0f3d74ef0": {
      "factor_id": "159002c0f3d74ef0",
      "factor_name": "Liquidity_Regime_Score_DV_Amihud_RV_20_60_20",
      "factor_expression": "RANK(LOG((TS_MEAN($close*$volume,20)+1e-8)/(TS_MEAN($close*$volume,60)+1e-8))) - RANK(DELTA(ABS($return)/(($close*$volume)+1e-8),20)) - RANK(TS_STD($return,20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_MEAN($close*$volume,20)+1e-8)/(TS_MEAN($close*$volume,60)+1e-8))) - RANK(DELTA(ABS(TS_PCTCHANGE($close,1))/(($close*$volume)+1e-8),20)) - RANK(TS_STD(TS_PCTCHANGE($close,1),20))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Regime_Score_DV_Amihud_RV_20_60_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Cross-sectional liquidity-regime score: higher when dollar-volume is rising versus a longer baseline, illiquidity (Amihud proxy) is improving over 20D, and realized volatility is contained. Intended as a regime proxy for when continuation is more reliable.",
      "factor_formulation": "LRS=\\operatorname{rank}\\left(\\log\\frac{\\overline{DV}_{20}}{\\overline{DV}_{60}}\\right)-\\operatorname{rank}(\\Delta_{20}Amihud)-\\operatorname{rank}(RV_{20}),\\quad DV=close\\cdot volume,\\ Amihud=\\frac{|r_1|}{DV}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "9e371740b450",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: A regime-aware microstructure factor that soft-switches between (i) fading large, low-participation/high-impact dislocations and (ii) riding price continuation only during sustained liquidity re-rating (rising dollar-volume vs a longer baseline, improving Amihud illiquidity, and contained realized volatility) will predict near-term returns better than either pure mean-reversion or pure liquidity-trend signals.\n                Concise Observation: The available OHLCV data supports constructing both a one-day dislocation/participation proxy (return/range vs rolling baselines, dollar-volume, Amihud impact) and a slow-moving liquidity-regime proxy (DV short/long ratio, change in Amihud, realized vol), enabling a single-factor soft blend without needing intraday trades or fundamentals.\n                Concise Justification: Large moves can be either (a) transient price-impact shocks caused by thin participation, which tend to revert as liquidity normalizes, or (b) moves supported by persistent liquidity improvement that indicates structural demand and tends to continue; weighting contrarian vs trend components by a continuous liquidity-regime score should improve robustness by filtering regime mismatch and reducing whipsaw compared with hard rules.\n                Concise Knowledge: If a large price move occurs with abnormally low dollar-volume and elevated price impact, it is more likely to reflect a temporary liquidity vacuum and mean-revert; when dollar-volume is persistently rising relative to a longer baseline while illiquidity improves and realized volatility stays contained, order-flow is more likely informed/accumulative so trend continuation is more reliable; therefore a smooth liquidity-regime gate can reduce tail losses from applying the wrong style in the wrong microstructure regime.\n                concise Specification: Construct VR (vacuum-reversion) from 1D return and 1D high-low range normalized by 20D z-scores and gated by low 20D dollar-volume z-score and/or high 20D Amihud=(|ret1|/(close*volume)) z-score; construct RC (rerating-continuation) from 10D price trend (e.g., regression beta of log(close) over 10D) plus log(DV20/DV60) and improving illiquidity (negative ΔAmihud over 20D), gated by low realized volatility (20D std of ret1); compute LRS = rank(log(DV20/DV60)) − rank(ΔAmihud_20) − rank(rv20); set w = sigmoid((LRS−0.5)/0.1) using cross-sectional percentile LRS in [0,1]; final factor = w*RC + (1−w)*VR, with optional conflict cap when |VR−RC| is above the 90th percentile cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T20:51:51.376691"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1941155437344872,
        "ICIR": 0.02121044661908,
        "1day.excess_return_without_cost.std": 0.0050256696804139,
        "1day.excess_return_with_cost.annualized_return": 0.0091980822727099,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002371694198485,
        "1day.excess_return_without_cost.annualized_return": 0.0564463219239461,
        "1day.excess_return_with_cost.std": 0.0050273113965143,
        "Rank IC": 0.0172080073259813,
        "IC": 0.0028898534834127,
        "1day.excess_return_without_cost.max_drawdown": -0.1483672744255232,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7280366275268704,
        "1day.pa": 0.0,
        "l2.valid": 0.9964126469148624,
        "Rank ICIR": 0.1277776029313712,
        "l2.train": 0.9935705878678032,
        "1day.excess_return_with_cost.information_ratio": 0.1185968146481554,
        "1day.excess_return_with_cost.mean": 3.864740450718472e-05
      },
      "feedback": {
        "observations": "Only two components of the stated framework were implemented/tested: (1) Liquidity_Regime_Score_DV_Amihud_RV_20_60_20 (regime proxy) and (2) Rerating_Continuation_Trend_DV_RV_10_20_60 (continuation under re-rating). The mean-reversion “dislocation fade” leg (Vacuum_Reversion_Dislocation_Fade_20D) was not implemented, so the core claim of a *soft-switch between reversion and continuation* is not actually evaluated in this run.\n\nPerformance vs SOTA is mixed but mostly worse on quality/risk metrics:\n- Annualized return: 0.05645 vs 0.05201 (improved)\n- Max drawdown: -0.14837 vs -0.07259 (materially worse; ~2x deeper drawdown)\n- Information ratio: 0.7280 vs 0.9726 (worse; less efficient return per risk)\n- IC: 0.00289 vs 0.00580 (worse; weaker predictive correlation)\n\nInterpretation: the “return” uplift looks fragile because both IC and IR deteriorated meaningfully while drawdown worsened, suggesting the improvement may come from higher exposure/risk or tail events rather than better forecasting.",
        "hypothesis_evaluation": "This experiment does **not** provide strong support for the target hypothesis as stated. The hypothesis requires a regime-aware factor that *soft-switches between fading dislocations (mean reversion)* and *riding continuation* under a favorable liquidity regime. Since the mean-reversion leg was not implemented, we cannot test whether the switching mechanism improves predictability versus pure mean-reversion or pure liquidity-trend.\n\nEven within the implemented half (regime proxy + continuation), the results **weakly refute** the practical benefit so far: IC and IR are notably below SOTA and max drawdown is substantially worse. That pattern is consistent with either (a) the regime proxy not gating continuation effectively, (b) the continuation signal being too easy to crowd into high-risk names, or (c) the combination method effectively increasing risk rather than increasing signal quality.",
        "decision": false,
        "reason": "Right now the “regime-aware” idea seems to be expressed as additive ranked components, which may not actually *switch* behavior; it may just create a composite that still loads on common liquidity/size risk. The large drawdown and lower IR/IC suggest the signal is not becoming cleaner; it’s likely increasing exposure to unstable liquidity events.\n\nTo stay within the same theoretical framework (microstructure dislocation vs liquidity-supported continuation), the next iteration should focus on (1) implementing the missing reversion leg and (2) turning regime awareness into an actual gating/mixture mechanism rather than another additive rank.\n\nConcrete next steps (keep factors static with explicit hyperparameters):\n1) Implement the missing mean-reversion leg exactly as specified (or a simplified robust variant) and test it standalone.\n   - Vacuum_Reversion_Dislocation_Fade_20D hyperparameters: TS_ZSCORE window = 20; inputs: |r1|/Range, Amihud=|r1|/DV, DV=close*volume.\n2) Build an explicit soft-switch factor (new factor, separate from the components):\n   - Weight w_t = sigmoid(k * (LRS_t - c)), where LRS_t is Liquidity_Regime_Score_DV_Amihud_RV_20_60_20.\n   - Combined signal: Alpha_t = w_t * RC_t + (1 - w_t) * VR_t.\n   - Hyperparameters to sweep (each setting = different factor definition):\n     - k ∈ {1, 2, 3, 5}\n     - c ∈ {0 (cross-sectional median), 0.25-quantile, 0.75-quantile of LRS}\n3) Improve regime robustness without changing the concept:\n   - Replace DELTA_20(Amihud) with a normalized change: (Amihud - TS_MEAN(Amihud, 60)) / TS_STD(Amihud, 60). (Hyperparameters: 60/60)\n   - Try RV windows {10, 20, 30} and DV baseline {60, 120}. (Each combination is a separate factor.)\n4) Control unintended exposures:\n   - Cross-sectionally neutralize the final factor vs log(DV) or vs rank(log(DV)) each day (one-step linear demeaning) to reduce pure liquidity/size bets that can inflate drawdown.\n\nThis keeps the same framework, but makes the “soft-switch” real and addresses the likely driver of worse drawdown/IR: uncontrolled liquidity/size exposure and insufficient gating precision."
      }
    },
    "6db2a96ede4f2b5b": {
      "factor_id": "6db2a96ede4f2b5b",
      "factor_name": "Vacuum_Reversion_Dislocation_Fade_20D",
      "factor_expression": "-SIGN($return) * (ZSCORE(TS_ZSCORE(ABS($return)/(($high-$low)+1e-8),20)) + ZSCORE(TS_ZSCORE(ABS($return)/(($close*$volume)+1e-8),20)) - ZSCORE(TS_ZSCORE($close*$volume,20)))",
      "factor_implementation_code": "",
      "factor_description": "Mean-reversion microstructure proxy: fades large directional daily moves that are large relative to the day’s range, occur with low participation (low dollar-volume), and elevated price impact (Amihud proxy).",
      "factor_formulation": "VR=-\\operatorname{sign}(r_1)\\Big[z_{cs}(z_{ts,20}(|r_1|/Range))+z_{cs}(z_{ts,20}(Amihud))-z_{cs}(z_{ts,20}(DV))\\Big],\\ Range=high-low",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "9e371740b450",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: A regime-aware microstructure factor that soft-switches between (i) fading large, low-participation/high-impact dislocations and (ii) riding price continuation only during sustained liquidity re-rating (rising dollar-volume vs a longer baseline, improving Amihud illiquidity, and contained realized volatility) will predict near-term returns better than either pure mean-reversion or pure liquidity-trend signals.\n                Concise Observation: The available OHLCV data supports constructing both a one-day dislocation/participation proxy (return/range vs rolling baselines, dollar-volume, Amihud impact) and a slow-moving liquidity-regime proxy (DV short/long ratio, change in Amihud, realized vol), enabling a single-factor soft blend without needing intraday trades or fundamentals.\n                Concise Justification: Large moves can be either (a) transient price-impact shocks caused by thin participation, which tend to revert as liquidity normalizes, or (b) moves supported by persistent liquidity improvement that indicates structural demand and tends to continue; weighting contrarian vs trend components by a continuous liquidity-regime score should improve robustness by filtering regime mismatch and reducing whipsaw compared with hard rules.\n                Concise Knowledge: If a large price move occurs with abnormally low dollar-volume and elevated price impact, it is more likely to reflect a temporary liquidity vacuum and mean-revert; when dollar-volume is persistently rising relative to a longer baseline while illiquidity improves and realized volatility stays contained, order-flow is more likely informed/accumulative so trend continuation is more reliable; therefore a smooth liquidity-regime gate can reduce tail losses from applying the wrong style in the wrong microstructure regime.\n                concise Specification: Construct VR (vacuum-reversion) from 1D return and 1D high-low range normalized by 20D z-scores and gated by low 20D dollar-volume z-score and/or high 20D Amihud=(|ret1|/(close*volume)) z-score; construct RC (rerating-continuation) from 10D price trend (e.g., regression beta of log(close) over 10D) plus log(DV20/DV60) and improving illiquidity (negative ΔAmihud over 20D), gated by low realized volatility (20D std of ret1); compute LRS = rank(log(DV20/DV60)) − rank(ΔAmihud_20) − rank(rv20); set w = sigmoid((LRS−0.5)/0.1) using cross-sectional percentile LRS in [0,1]; final factor = w*RC + (1−w)*VR, with optional conflict cap when |VR−RC| is above the 90th percentile cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T20:51:51.376691"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1941155437344872,
        "ICIR": 0.02121044661908,
        "1day.excess_return_without_cost.std": 0.0050256696804139,
        "1day.excess_return_with_cost.annualized_return": 0.0091980822727099,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002371694198485,
        "1day.excess_return_without_cost.annualized_return": 0.0564463219239461,
        "1day.excess_return_with_cost.std": 0.0050273113965143,
        "Rank IC": 0.0172080073259813,
        "IC": 0.0028898534834127,
        "1day.excess_return_without_cost.max_drawdown": -0.1483672744255232,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7280366275268704,
        "1day.pa": 0.0,
        "l2.valid": 0.9964126469148624,
        "Rank ICIR": 0.1277776029313712,
        "l2.train": 0.9935705878678032,
        "1day.excess_return_with_cost.information_ratio": 0.1185968146481554,
        "1day.excess_return_with_cost.mean": 3.864740450718472e-05
      },
      "feedback": {
        "observations": "Only two components of the stated framework were implemented/tested: (1) Liquidity_Regime_Score_DV_Amihud_RV_20_60_20 (regime proxy) and (2) Rerating_Continuation_Trend_DV_RV_10_20_60 (continuation under re-rating). The mean-reversion “dislocation fade” leg (Vacuum_Reversion_Dislocation_Fade_20D) was not implemented, so the core claim of a *soft-switch between reversion and continuation* is not actually evaluated in this run.\n\nPerformance vs SOTA is mixed but mostly worse on quality/risk metrics:\n- Annualized return: 0.05645 vs 0.05201 (improved)\n- Max drawdown: -0.14837 vs -0.07259 (materially worse; ~2x deeper drawdown)\n- Information ratio: 0.7280 vs 0.9726 (worse; less efficient return per risk)\n- IC: 0.00289 vs 0.00580 (worse; weaker predictive correlation)\n\nInterpretation: the “return” uplift looks fragile because both IC and IR deteriorated meaningfully while drawdown worsened, suggesting the improvement may come from higher exposure/risk or tail events rather than better forecasting.",
        "hypothesis_evaluation": "This experiment does **not** provide strong support for the target hypothesis as stated. The hypothesis requires a regime-aware factor that *soft-switches between fading dislocations (mean reversion)* and *riding continuation* under a favorable liquidity regime. Since the mean-reversion leg was not implemented, we cannot test whether the switching mechanism improves predictability versus pure mean-reversion or pure liquidity-trend.\n\nEven within the implemented half (regime proxy + continuation), the results **weakly refute** the practical benefit so far: IC and IR are notably below SOTA and max drawdown is substantially worse. That pattern is consistent with either (a) the regime proxy not gating continuation effectively, (b) the continuation signal being too easy to crowd into high-risk names, or (c) the combination method effectively increasing risk rather than increasing signal quality.",
        "decision": false,
        "reason": "Right now the “regime-aware” idea seems to be expressed as additive ranked components, which may not actually *switch* behavior; it may just create a composite that still loads on common liquidity/size risk. The large drawdown and lower IR/IC suggest the signal is not becoming cleaner; it’s likely increasing exposure to unstable liquidity events.\n\nTo stay within the same theoretical framework (microstructure dislocation vs liquidity-supported continuation), the next iteration should focus on (1) implementing the missing reversion leg and (2) turning regime awareness into an actual gating/mixture mechanism rather than another additive rank.\n\nConcrete next steps (keep factors static with explicit hyperparameters):\n1) Implement the missing mean-reversion leg exactly as specified (or a simplified robust variant) and test it standalone.\n   - Vacuum_Reversion_Dislocation_Fade_20D hyperparameters: TS_ZSCORE window = 20; inputs: |r1|/Range, Amihud=|r1|/DV, DV=close*volume.\n2) Build an explicit soft-switch factor (new factor, separate from the components):\n   - Weight w_t = sigmoid(k * (LRS_t - c)), where LRS_t is Liquidity_Regime_Score_DV_Amihud_RV_20_60_20.\n   - Combined signal: Alpha_t = w_t * RC_t + (1 - w_t) * VR_t.\n   - Hyperparameters to sweep (each setting = different factor definition):\n     - k ∈ {1, 2, 3, 5}\n     - c ∈ {0 (cross-sectional median), 0.25-quantile, 0.75-quantile of LRS}\n3) Improve regime robustness without changing the concept:\n   - Replace DELTA_20(Amihud) with a normalized change: (Amihud - TS_MEAN(Amihud, 60)) / TS_STD(Amihud, 60). (Hyperparameters: 60/60)\n   - Try RV windows {10, 20, 30} and DV baseline {60, 120}. (Each combination is a separate factor.)\n4) Control unintended exposures:\n   - Cross-sectionally neutralize the final factor vs log(DV) or vs rank(log(DV)) each day (one-step linear demeaning) to reduce pure liquidity/size bets that can inflate drawdown.\n\nThis keeps the same framework, but makes the “soft-switch” real and addresses the likely driver of worse drawdown/IR: uncontrolled liquidity/size exposure and insufficient gating precision."
      }
    },
    "78252a4fab58dbad": {
      "factor_id": "78252a4fab58dbad",
      "factor_name": "Rerating_Continuation_Trend_DV_RV_10_20_60",
      "factor_expression": "RANK(REGBETA(LOG($close),SEQUENCE(10),10)) + RANK(LOG((TS_MEAN($close*$volume,20)+1e-8)/(TS_MEAN($close*$volume,60)+1e-8))) - RANK(TS_STD($return,20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(LOG($close),10)) + RANK(LOG((TS_MEAN($close*$volume,20)+1e-8)/(TS_MEAN($close*$volume,60)+1e-8))) - RANK(TS_STD(TS_PCTCHANGE($close,1),20))\" # Your output factor expression will be filled in here\n    name = \"Rerating_Continuation_Trend_DV_RV_10_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation under liquidity re-rating: rewards short-term price trend when supported by rising dollar-volume vs a longer baseline and penalized by high realized volatility (to avoid fragile trends).",
      "factor_formulation": "RC=\\operatorname{rank}(\\beta_{10}(\\log close\\sim t))+\\operatorname{rank}\\left(\\log\\frac{\\overline{DV}_{20}}{\\overline{DV}_{60}}\\right)-\\operatorname{rank}(RV_{20})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "9e371740b450",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: A regime-aware microstructure factor that soft-switches between (i) fading large, low-participation/high-impact dislocations and (ii) riding price continuation only during sustained liquidity re-rating (rising dollar-volume vs a longer baseline, improving Amihud illiquidity, and contained realized volatility) will predict near-term returns better than either pure mean-reversion or pure liquidity-trend signals.\n                Concise Observation: The available OHLCV data supports constructing both a one-day dislocation/participation proxy (return/range vs rolling baselines, dollar-volume, Amihud impact) and a slow-moving liquidity-regime proxy (DV short/long ratio, change in Amihud, realized vol), enabling a single-factor soft blend without needing intraday trades or fundamentals.\n                Concise Justification: Large moves can be either (a) transient price-impact shocks caused by thin participation, which tend to revert as liquidity normalizes, or (b) moves supported by persistent liquidity improvement that indicates structural demand and tends to continue; weighting contrarian vs trend components by a continuous liquidity-regime score should improve robustness by filtering regime mismatch and reducing whipsaw compared with hard rules.\n                Concise Knowledge: If a large price move occurs with abnormally low dollar-volume and elevated price impact, it is more likely to reflect a temporary liquidity vacuum and mean-revert; when dollar-volume is persistently rising relative to a longer baseline while illiquidity improves and realized volatility stays contained, order-flow is more likely informed/accumulative so trend continuation is more reliable; therefore a smooth liquidity-regime gate can reduce tail losses from applying the wrong style in the wrong microstructure regime.\n                concise Specification: Construct VR (vacuum-reversion) from 1D return and 1D high-low range normalized by 20D z-scores and gated by low 20D dollar-volume z-score and/or high 20D Amihud=(|ret1|/(close*volume)) z-score; construct RC (rerating-continuation) from 10D price trend (e.g., regression beta of log(close) over 10D) plus log(DV20/DV60) and improving illiquidity (negative ΔAmihud over 20D), gated by low realized volatility (20D std of ret1); compute LRS = rank(log(DV20/DV60)) − rank(ΔAmihud_20) − rank(rv20); set w = sigmoid((LRS−0.5)/0.1) using cross-sectional percentile LRS in [0,1]; final factor = w*RC + (1−w)*VR, with optional conflict cap when |VR−RC| is above the 90th percentile cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T20:51:51.376691"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1941155437344872,
        "ICIR": 0.02121044661908,
        "1day.excess_return_without_cost.std": 0.0050256696804139,
        "1day.excess_return_with_cost.annualized_return": 0.0091980822727099,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002371694198485,
        "1day.excess_return_without_cost.annualized_return": 0.0564463219239461,
        "1day.excess_return_with_cost.std": 0.0050273113965143,
        "Rank IC": 0.0172080073259813,
        "IC": 0.0028898534834127,
        "1day.excess_return_without_cost.max_drawdown": -0.1483672744255232,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7280366275268704,
        "1day.pa": 0.0,
        "l2.valid": 0.9964126469148624,
        "Rank ICIR": 0.1277776029313712,
        "l2.train": 0.9935705878678032,
        "1day.excess_return_with_cost.information_ratio": 0.1185968146481554,
        "1day.excess_return_with_cost.mean": 3.864740450718472e-05
      },
      "feedback": {
        "observations": "Only two components of the stated framework were implemented/tested: (1) Liquidity_Regime_Score_DV_Amihud_RV_20_60_20 (regime proxy) and (2) Rerating_Continuation_Trend_DV_RV_10_20_60 (continuation under re-rating). The mean-reversion “dislocation fade” leg (Vacuum_Reversion_Dislocation_Fade_20D) was not implemented, so the core claim of a *soft-switch between reversion and continuation* is not actually evaluated in this run.\n\nPerformance vs SOTA is mixed but mostly worse on quality/risk metrics:\n- Annualized return: 0.05645 vs 0.05201 (improved)\n- Max drawdown: -0.14837 vs -0.07259 (materially worse; ~2x deeper drawdown)\n- Information ratio: 0.7280 vs 0.9726 (worse; less efficient return per risk)\n- IC: 0.00289 vs 0.00580 (worse; weaker predictive correlation)\n\nInterpretation: the “return” uplift looks fragile because both IC and IR deteriorated meaningfully while drawdown worsened, suggesting the improvement may come from higher exposure/risk or tail events rather than better forecasting.",
        "hypothesis_evaluation": "This experiment does **not** provide strong support for the target hypothesis as stated. The hypothesis requires a regime-aware factor that *soft-switches between fading dislocations (mean reversion)* and *riding continuation* under a favorable liquidity regime. Since the mean-reversion leg was not implemented, we cannot test whether the switching mechanism improves predictability versus pure mean-reversion or pure liquidity-trend.\n\nEven within the implemented half (regime proxy + continuation), the results **weakly refute** the practical benefit so far: IC and IR are notably below SOTA and max drawdown is substantially worse. That pattern is consistent with either (a) the regime proxy not gating continuation effectively, (b) the continuation signal being too easy to crowd into high-risk names, or (c) the combination method effectively increasing risk rather than increasing signal quality.",
        "decision": false,
        "reason": "Right now the “regime-aware” idea seems to be expressed as additive ranked components, which may not actually *switch* behavior; it may just create a composite that still loads on common liquidity/size risk. The large drawdown and lower IR/IC suggest the signal is not becoming cleaner; it’s likely increasing exposure to unstable liquidity events.\n\nTo stay within the same theoretical framework (microstructure dislocation vs liquidity-supported continuation), the next iteration should focus on (1) implementing the missing reversion leg and (2) turning regime awareness into an actual gating/mixture mechanism rather than another additive rank.\n\nConcrete next steps (keep factors static with explicit hyperparameters):\n1) Implement the missing mean-reversion leg exactly as specified (or a simplified robust variant) and test it standalone.\n   - Vacuum_Reversion_Dislocation_Fade_20D hyperparameters: TS_ZSCORE window = 20; inputs: |r1|/Range, Amihud=|r1|/DV, DV=close*volume.\n2) Build an explicit soft-switch factor (new factor, separate from the components):\n   - Weight w_t = sigmoid(k * (LRS_t - c)), where LRS_t is Liquidity_Regime_Score_DV_Amihud_RV_20_60_20.\n   - Combined signal: Alpha_t = w_t * RC_t + (1 - w_t) * VR_t.\n   - Hyperparameters to sweep (each setting = different factor definition):\n     - k ∈ {1, 2, 3, 5}\n     - c ∈ {0 (cross-sectional median), 0.25-quantile, 0.75-quantile of LRS}\n3) Improve regime robustness without changing the concept:\n   - Replace DELTA_20(Amihud) with a normalized change: (Amihud - TS_MEAN(Amihud, 60)) / TS_STD(Amihud, 60). (Hyperparameters: 60/60)\n   - Try RV windows {10, 20, 30} and DV baseline {60, 120}. (Each combination is a separate factor.)\n4) Control unintended exposures:\n   - Cross-sectionally neutralize the final factor vs log(DV) or vs rank(log(DV)) each day (one-step linear demeaning) to reduce pure liquidity/size bets that can inflate drawdown.\n\nThis keeps the same framework, but makes the “soft-switch” real and addresses the likely driver of worse drawdown/IR: uncontrolled liquidity/size exposure and insufficient gating precision."
      }
    },
    "883bfcda2f8b663c": {
      "factor_id": "883bfcda2f8b663c",
      "factor_name": "Vacuum_Contrarian_Impact_1D20D",
      "factor_expression": "(RANK(ABS($return))>0.9&&$volume/(TS_MEAN($volume,20)+1e-8)<0.7)?(-SIGN($return)*ABS($return)*TS_MEAN($volume,20)/($volume+1e-8)):0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((RANK(ABS(TS_PCTCHANGE($close,1)))>0.9)&&($volume/(TS_MEAN($volume,20)+1e-8)<0.7))?(-TS_PCTCHANGE($close,1)*TS_MEAN($volume,20)/($volume+1e-8)):0\" # Your output factor expression will be filled in here\n    name = \"Vacuum_Contrarian_Impact_1D20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian signal designed for liquidity-vacuum dislocations: activates when the 1D absolute return is in the cross-sectional top tail while volume is abnormally low vs its own 20D average. The score takes the opposite sign of the 1D return and scales by an impact proxy (20D avg volume divided by today volume). Hyperparameters: 1D shock, 20D volume baseline, tail=0.9, low-volume ratio<0.7.",
      "factor_formulation": "F_t=\\begin{cases}-\\operatorname{sign}(r_t)\\,|r_t|\\,\\frac{\\overline{V}_{20}}{V_t} & \\text{if } \\operatorname{rank}(|r_t|)>0.9 \\wedge \\frac{V_t}{\\overline{V}_{20}}<0.7\\\\0 & \\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "879532aab9fc",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: A regime-gated hybrid factor that distinguishes (A) liquidity-vacuum dislocations from (B) participation-confirmed squeeze breakouts will predict next-day-to-next-week returns: large 1D return/range shocks with abnormally low volume (high estimated price impact) mean-revert over 2–5 days, while breakouts above a 55D high emerging from 20D volatility/range compression and confirmed by positive 20D volume surprise trend-continue over 10–20 days; a conditional mixture-of-experts that activates contrarian vs continuation only in its matched regime outperforms linear blends and reduces false-breakout drawdowns.\n                Concise Observation: Daily OHLCV enables two complementary diagnostics from the same inputs—(i) abnormal move intensity via 1D close-to-close return and intraday range, and (ii) participation via volume surprise/impact proxy—so false breakouts (low participation) and liquidity-vacuum spikes (high impact) can be separated from genuine high-participation breakouts coming out of 20D compression.\n                Concise Justification: Mean reversion is expected when price changes reflect transient liquidity shocks (large move + thin volume implies higher impact and reversal pressure), whereas continuation is expected when a compressed-volatility regime resolves via a breakout that is widely participated (volume surprise) and thus more likely to embed new information; gating avoids the shared weakness of both parents—trading ambiguous regimes where neither dislocation nor validated-breakout conditions hold.\n                Concise Knowledge: If a large price move occurs with weak participation (low volume relative to recent history), it is more likely driven by temporary liquidity/impact and should mean-revert; when a breakout occurs after multi-week volatility compression and is validated by strong volume surprise (high participation), it is more likely information-driven and should continue over a longer horizon; therefore, conditioning factor direction on a participation-and-compression regime diagnosis should improve signal purity in daily OHLCV data.\n                concise Specification: Define two sub-scores using only daily_pv.h5 OHLCV: (1) Vacuum-Contrarian score uses 1D return r1=close/lag(close,1)-1 and 1D range tr1=(high-low)/lag(close,1) combined with low participation proxied by volume z-score over 20D (zVol20) and/or impact proxy |r1|/volume (Amihud-like); activate contrarian when (|r1| or tr1 is in top tail cross-sectionally) AND (zVol20 is below a low threshold) AND (impact is high), and set factor sign = -sign(r1) * magnitude. (2) Squeeze-Breakout-Continuation score uses compression over 20D (e.g., low 20D realized volatility of returns or low 20D average true range) plus breakout condition close > rolling 55D max(high) and participation confirmation zVol20 above a high threshold; activate continuation when (compression high) AND (breakout true) AND (zVol20 high), and set factor sign = +1 * magnitude. Combine via conditional mixture: if continuation regime true use continuation score; else if vacuum regime true use contrarian score; else output 0 (neutral). Fixed hyperparameters for testability: lookbacks {1D move, 20D compression/volume z-score, 55D breakout level}; optional holding-horizon alignment for evaluation: contrarian 2–5D, continuation 10–20D.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T00:50:25.489568"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1190766427808237,
        "ICIR": 0.0323337554257122,
        "1day.excess_return_without_cost.std": 0.0041903669768645,
        "1day.excess_return_with_cost.annualized_return": 0.0247528506730481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003019647129696,
        "1day.excess_return_without_cost.annualized_return": 0.0718676016867666,
        "1day.excess_return_with_cost.std": 0.0041912243490934,
        "Rank IC": 0.0215025212649754,
        "IC": 0.0043617492908002,
        "1day.excess_return_without_cost.max_drawdown": -0.1074534523318084,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1117128230850748,
        "1day.pa": 0.0,
        "l2.valid": 0.9968180754287644,
        "Rank ICIR": 0.1687282579511601,
        "l2.train": 0.9933274148114488,
        "1day.excess_return_with_cost.information_ratio": 0.3828210718013895,
        "1day.excess_return_with_cost.mean": 0.0001040035742565
      },
      "feedback": {
        "observations": "The new regime-gated hybrid improves portfolio-level performance without costs: annualized return rises from 0.0520 to 0.0719 and information ratio rises from 0.9726 to 1.1117. However, risk and signal-quality indicators deteriorate: max drawdown worsens (from -0.0726 to -0.1075, i.e., larger peak-to-trough loss) and IC drops (0.00580 -> 0.00436). This combination suggests the factor is generating payoff through episodic/option-like exposures (sparse regime triggers) that can help returns/IR but create fatter tails and weaker average cross-sectional correlation.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The hypothesis claims regime-gating should outperform linear blends and reduce false-breakout drawdowns. The improvement in annualized return and IR is consistent with the “mixture-of-experts” idea adding value. But the drawdown got meaningfully worse, which contradicts the claim of drawdown reduction (at least in the current hard-gated implementation/thresholds). The lower IC also suggests the regime conditions may be too sparse/noisy or that the payoff is not well-captured by contemporaneous cross-sectional correlation (e.g., concentrated in a few large moves). Net: gating helps returns, but the current regime definitions/thresholds are not yet robust enough to control downside and maintain consistent predictive correlation.",
        "decision": true,
        "reason": "1) Drawdown worsening is often caused by discontinuous exposures (hard gates) and uncapped impact scaling (e.g., avgV/Vt can explode on very low volume days). Soft gating (continuous weights) and winsorization/capping should reduce tail risk. 2) IC dropping while returns rise is consistent with sparse activation: when the factor is nonzero only in rare regimes, average daily cross-sectional correlation can fall even if those rare days drive PnL. Increasing regime persistence (multi-day confirmation) and normalizing signals cross-sectionally can increase IC stability. 3) The current breakout branch in the hybrid outputs only breakout distance, whereas the standalone breakout factor multiplies by volume z-score; this mismatch can weaken the continuation expert and blur the intended “participation-confirmed” concept, potentially increasing false breakouts and drawdowns. Aligning the hybrid’s breakout magnitude with the confirmed breakout definition should help both IC and drawdown.\n\nConcrete iteration directions (keep the same theoretical framework, tune hyperparameters explicitly):\n- Align hybrid breakout expert with confirmation: use (C/TS_MAX(high,55)-1) * max(ZSCORE(volume,20),0) or * RANK(ZSCORE(volume,20)) rather than distance-only.\n- Cap impact scaling for vacuum expert: impact = clip(TS_MEAN(volume,20)/volume_t, 0, cap) with cap in {3,5,10}; also consider using log(impact) to reduce blow-ups.\n- Volatility-normalize the shock: use |r_t|/TS_STD(r,20) or true-range-based normalization; explore tail thresholds in {0.85, 0.90, 0.95}.\n- Smooth regime detection: require regime condition to hold for k of last m days (e.g., 2/3) or add a 3–5D decay on the signal to match the hypothesis horizons (vacuum mean-revert 2–5D; breakout continue 10–20D).\n- Replace cross-sectional rank for compression with within-name compression percentile (e.g., TS_RANK(σ20, 252) < p) to avoid “always compressed” artifacts in quiet markets; test p in {0.1, 0.2, 0.3}.\n- Add simple cross-sectional standardization on output (daily z-score or rank) to stabilize IC.\n- Keep factors separated for model learning: in addition to the hybrid, provide two standalone factors (vacuum-only and breakout-only) with fixed hyperparameters so the downstream model can learn mixtures; then compare against the single hybrid output to see whether gating truly helps generalization."
      }
    },
    "77c1a878430cd38f": {
      "factor_id": "77c1a878430cd38f",
      "factor_name": "Squeeze_Breakout_Confirm_20D55D",
      "factor_expression": "($close>TS_MAX($high,55)&&RANK(TS_STD($return,20))<0.2&&TS_ZSCORE($volume,20)>1)?(($close/(TS_MAX($high,55)+1e-8)-1)*TS_ZSCORE($volume,20)):0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close>TS_MAX($high,55))&&(RANK(TS_STD(TS_PCTCHANGE($close,1),20))<0.2)&&(TS_ZSCORE($volume,20)>1))?((($close/(TS_MAX($high,55)+1e-8))-1)*TS_ZSCORE($volume,20)):0\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Breakout_Confirm_20D55D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation signal for participation-confirmed squeeze breakouts: activates when 20D realized volatility is cross-sectionally compressed, price breaks above the 55D high, and volume is a positive 20D z-score surprise. Magnitude is breakout distance times volume confirmation. Hyperparameters: compression=20D, breakout lookback=55D, volume zscore=20D, compression rank<0.2, vol zscore>1.",
      "factor_formulation": "F_t=\\begin{cases}\\left(\\frac{C_t}{\\max(H,55)}-1\\right)\\cdot Z_{20}(V_t) & \\text{if } C_t>\\max(H,55) \\wedge \\operatorname{rank}(\\sigma_{20}(r))<0.2 \\wedge Z_{20}(V_t)>1\\\\0 & \\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "879532aab9fc",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: A regime-gated hybrid factor that distinguishes (A) liquidity-vacuum dislocations from (B) participation-confirmed squeeze breakouts will predict next-day-to-next-week returns: large 1D return/range shocks with abnormally low volume (high estimated price impact) mean-revert over 2–5 days, while breakouts above a 55D high emerging from 20D volatility/range compression and confirmed by positive 20D volume surprise trend-continue over 10–20 days; a conditional mixture-of-experts that activates contrarian vs continuation only in its matched regime outperforms linear blends and reduces false-breakout drawdowns.\n                Concise Observation: Daily OHLCV enables two complementary diagnostics from the same inputs—(i) abnormal move intensity via 1D close-to-close return and intraday range, and (ii) participation via volume surprise/impact proxy—so false breakouts (low participation) and liquidity-vacuum spikes (high impact) can be separated from genuine high-participation breakouts coming out of 20D compression.\n                Concise Justification: Mean reversion is expected when price changes reflect transient liquidity shocks (large move + thin volume implies higher impact and reversal pressure), whereas continuation is expected when a compressed-volatility regime resolves via a breakout that is widely participated (volume surprise) and thus more likely to embed new information; gating avoids the shared weakness of both parents—trading ambiguous regimes where neither dislocation nor validated-breakout conditions hold.\n                Concise Knowledge: If a large price move occurs with weak participation (low volume relative to recent history), it is more likely driven by temporary liquidity/impact and should mean-revert; when a breakout occurs after multi-week volatility compression and is validated by strong volume surprise (high participation), it is more likely information-driven and should continue over a longer horizon; therefore, conditioning factor direction on a participation-and-compression regime diagnosis should improve signal purity in daily OHLCV data.\n                concise Specification: Define two sub-scores using only daily_pv.h5 OHLCV: (1) Vacuum-Contrarian score uses 1D return r1=close/lag(close,1)-1 and 1D range tr1=(high-low)/lag(close,1) combined with low participation proxied by volume z-score over 20D (zVol20) and/or impact proxy |r1|/volume (Amihud-like); activate contrarian when (|r1| or tr1 is in top tail cross-sectionally) AND (zVol20 is below a low threshold) AND (impact is high), and set factor sign = -sign(r1) * magnitude. (2) Squeeze-Breakout-Continuation score uses compression over 20D (e.g., low 20D realized volatility of returns or low 20D average true range) plus breakout condition close > rolling 55D max(high) and participation confirmation zVol20 above a high threshold; activate continuation when (compression high) AND (breakout true) AND (zVol20 high), and set factor sign = +1 * magnitude. Combine via conditional mixture: if continuation regime true use continuation score; else if vacuum regime true use contrarian score; else output 0 (neutral). Fixed hyperparameters for testability: lookbacks {1D move, 20D compression/volume z-score, 55D breakout level}; optional holding-horizon alignment for evaluation: contrarian 2–5D, continuation 10–20D.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T00:50:25.489568"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1190766427808237,
        "ICIR": 0.0323337554257122,
        "1day.excess_return_without_cost.std": 0.0041903669768645,
        "1day.excess_return_with_cost.annualized_return": 0.0247528506730481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003019647129696,
        "1day.excess_return_without_cost.annualized_return": 0.0718676016867666,
        "1day.excess_return_with_cost.std": 0.0041912243490934,
        "Rank IC": 0.0215025212649754,
        "IC": 0.0043617492908002,
        "1day.excess_return_without_cost.max_drawdown": -0.1074534523318084,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1117128230850748,
        "1day.pa": 0.0,
        "l2.valid": 0.9968180754287644,
        "Rank ICIR": 0.1687282579511601,
        "l2.train": 0.9933274148114488,
        "1day.excess_return_with_cost.information_ratio": 0.3828210718013895,
        "1day.excess_return_with_cost.mean": 0.0001040035742565
      },
      "feedback": {
        "observations": "The new regime-gated hybrid improves portfolio-level performance without costs: annualized return rises from 0.0520 to 0.0719 and information ratio rises from 0.9726 to 1.1117. However, risk and signal-quality indicators deteriorate: max drawdown worsens (from -0.0726 to -0.1075, i.e., larger peak-to-trough loss) and IC drops (0.00580 -> 0.00436). This combination suggests the factor is generating payoff through episodic/option-like exposures (sparse regime triggers) that can help returns/IR but create fatter tails and weaker average cross-sectional correlation.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The hypothesis claims regime-gating should outperform linear blends and reduce false-breakout drawdowns. The improvement in annualized return and IR is consistent with the “mixture-of-experts” idea adding value. But the drawdown got meaningfully worse, which contradicts the claim of drawdown reduction (at least in the current hard-gated implementation/thresholds). The lower IC also suggests the regime conditions may be too sparse/noisy or that the payoff is not well-captured by contemporaneous cross-sectional correlation (e.g., concentrated in a few large moves). Net: gating helps returns, but the current regime definitions/thresholds are not yet robust enough to control downside and maintain consistent predictive correlation.",
        "decision": true,
        "reason": "1) Drawdown worsening is often caused by discontinuous exposures (hard gates) and uncapped impact scaling (e.g., avgV/Vt can explode on very low volume days). Soft gating (continuous weights) and winsorization/capping should reduce tail risk. 2) IC dropping while returns rise is consistent with sparse activation: when the factor is nonzero only in rare regimes, average daily cross-sectional correlation can fall even if those rare days drive PnL. Increasing regime persistence (multi-day confirmation) and normalizing signals cross-sectionally can increase IC stability. 3) The current breakout branch in the hybrid outputs only breakout distance, whereas the standalone breakout factor multiplies by volume z-score; this mismatch can weaken the continuation expert and blur the intended “participation-confirmed” concept, potentially increasing false breakouts and drawdowns. Aligning the hybrid’s breakout magnitude with the confirmed breakout definition should help both IC and drawdown.\n\nConcrete iteration directions (keep the same theoretical framework, tune hyperparameters explicitly):\n- Align hybrid breakout expert with confirmation: use (C/TS_MAX(high,55)-1) * max(ZSCORE(volume,20),0) or * RANK(ZSCORE(volume,20)) rather than distance-only.\n- Cap impact scaling for vacuum expert: impact = clip(TS_MEAN(volume,20)/volume_t, 0, cap) with cap in {3,5,10}; also consider using log(impact) to reduce blow-ups.\n- Volatility-normalize the shock: use |r_t|/TS_STD(r,20) or true-range-based normalization; explore tail thresholds in {0.85, 0.90, 0.95}.\n- Smooth regime detection: require regime condition to hold for k of last m days (e.g., 2/3) or add a 3–5D decay on the signal to match the hypothesis horizons (vacuum mean-revert 2–5D; breakout continue 10–20D).\n- Replace cross-sectional rank for compression with within-name compression percentile (e.g., TS_RANK(σ20, 252) < p) to avoid “always compressed” artifacts in quiet markets; test p in {0.1, 0.2, 0.3}.\n- Add simple cross-sectional standardization on output (daily z-score or rank) to stabilize IC.\n- Keep factors separated for model learning: in addition to the hybrid, provide two standalone factors (vacuum-only and breakout-only) with fixed hyperparameters so the downstream model can learn mixtures; then compare against the single hybrid output to see whether gating truly helps generalization."
      }
    },
    "b309f018298d75dc": {
      "factor_id": "b309f018298d75dc",
      "factor_name": "RegimeGated_Hybrid_Vacuum_vs_Breakout_1D20D55D",
      "factor_expression": "($close>TS_MAX($high,55)&&RANK(TS_STD($return,20))<0.2&&TS_ZSCORE($volume,20)>1)?($close/(TS_MAX($high,55)+1e-8)-1):((RANK(ABS($return))>0.9&&$volume/(TS_MEAN($volume,20)+1e-8)<0.7)?(-SIGN($return)*ABS($return)):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close>DELAY(TS_MAX($high,55),1))&&(RANK(TS_STD(TS_PCTCHANGE($close,1),20))<0.2)&&(TS_ZSCORE($volume,20)>1))?($close/(DELAY(TS_MAX($high,55),1)+1e-8)-1):((RANK(ABS(TS_PCTCHANGE($close,1)))>0.9&&($volume/(TS_MEAN($volume,20)+1e-8)<0.7))?(-TS_PCTCHANGE($close,1)):0)\" # Your output factor expression will be filled in here\n    name = \"RegimeGated_Hybrid_Vacuum_vs_Breakout_1D20D55D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Conditional mixture-of-experts in a single output: if a participation-confirmed squeeze breakout regime holds, output a continuation score (breakout distance). Otherwise, if a liquidity-vacuum dislocation regime holds, output a contrarian score (opposite of 1D return). Else output 0. Hyperparameters: shock tail=0.9, low-volume ratio<0.7, compression=20D with rank<0.2, breakout=55D, volume zscore=20D with >1.",
      "factor_formulation": "F_t=\\begin{cases}\\left(\\frac{C_t}{\\max(H,55)}-1\\right) & \\text{if breakout\\_confirm}\\\\-\\operatorname{sign}(r_t)|r_t| & \\text{else if vacuum\\_shock}\\\\0 & \\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "879532aab9fc",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: A regime-gated hybrid factor that distinguishes (A) liquidity-vacuum dislocations from (B) participation-confirmed squeeze breakouts will predict next-day-to-next-week returns: large 1D return/range shocks with abnormally low volume (high estimated price impact) mean-revert over 2–5 days, while breakouts above a 55D high emerging from 20D volatility/range compression and confirmed by positive 20D volume surprise trend-continue over 10–20 days; a conditional mixture-of-experts that activates contrarian vs continuation only in its matched regime outperforms linear blends and reduces false-breakout drawdowns.\n                Concise Observation: Daily OHLCV enables two complementary diagnostics from the same inputs—(i) abnormal move intensity via 1D close-to-close return and intraday range, and (ii) participation via volume surprise/impact proxy—so false breakouts (low participation) and liquidity-vacuum spikes (high impact) can be separated from genuine high-participation breakouts coming out of 20D compression.\n                Concise Justification: Mean reversion is expected when price changes reflect transient liquidity shocks (large move + thin volume implies higher impact and reversal pressure), whereas continuation is expected when a compressed-volatility regime resolves via a breakout that is widely participated (volume surprise) and thus more likely to embed new information; gating avoids the shared weakness of both parents—trading ambiguous regimes where neither dislocation nor validated-breakout conditions hold.\n                Concise Knowledge: If a large price move occurs with weak participation (low volume relative to recent history), it is more likely driven by temporary liquidity/impact and should mean-revert; when a breakout occurs after multi-week volatility compression and is validated by strong volume surprise (high participation), it is more likely information-driven and should continue over a longer horizon; therefore, conditioning factor direction on a participation-and-compression regime diagnosis should improve signal purity in daily OHLCV data.\n                concise Specification: Define two sub-scores using only daily_pv.h5 OHLCV: (1) Vacuum-Contrarian score uses 1D return r1=close/lag(close,1)-1 and 1D range tr1=(high-low)/lag(close,1) combined with low participation proxied by volume z-score over 20D (zVol20) and/or impact proxy |r1|/volume (Amihud-like); activate contrarian when (|r1| or tr1 is in top tail cross-sectionally) AND (zVol20 is below a low threshold) AND (impact is high), and set factor sign = -sign(r1) * magnitude. (2) Squeeze-Breakout-Continuation score uses compression over 20D (e.g., low 20D realized volatility of returns or low 20D average true range) plus breakout condition close > rolling 55D max(high) and participation confirmation zVol20 above a high threshold; activate continuation when (compression high) AND (breakout true) AND (zVol20 high), and set factor sign = +1 * magnitude. Combine via conditional mixture: if continuation regime true use continuation score; else if vacuum regime true use contrarian score; else output 0 (neutral). Fixed hyperparameters for testability: lookbacks {1D move, 20D compression/volume z-score, 55D breakout level}; optional holding-horizon alignment for evaluation: contrarian 2–5D, continuation 10–20D.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T00:50:25.489568"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1190766427808237,
        "ICIR": 0.0323337554257122,
        "1day.excess_return_without_cost.std": 0.0041903669768645,
        "1day.excess_return_with_cost.annualized_return": 0.0247528506730481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003019647129696,
        "1day.excess_return_without_cost.annualized_return": 0.0718676016867666,
        "1day.excess_return_with_cost.std": 0.0041912243490934,
        "Rank IC": 0.0215025212649754,
        "IC": 0.0043617492908002,
        "1day.excess_return_without_cost.max_drawdown": -0.1074534523318084,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1117128230850748,
        "1day.pa": 0.0,
        "l2.valid": 0.9968180754287644,
        "Rank ICIR": 0.1687282579511601,
        "l2.train": 0.9933274148114488,
        "1day.excess_return_with_cost.information_ratio": 0.3828210718013895,
        "1day.excess_return_with_cost.mean": 0.0001040035742565
      },
      "feedback": {
        "observations": "The new regime-gated hybrid improves portfolio-level performance without costs: annualized return rises from 0.0520 to 0.0719 and information ratio rises from 0.9726 to 1.1117. However, risk and signal-quality indicators deteriorate: max drawdown worsens (from -0.0726 to -0.1075, i.e., larger peak-to-trough loss) and IC drops (0.00580 -> 0.00436). This combination suggests the factor is generating payoff through episodic/option-like exposures (sparse regime triggers) that can help returns/IR but create fatter tails and weaker average cross-sectional correlation.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The hypothesis claims regime-gating should outperform linear blends and reduce false-breakout drawdowns. The improvement in annualized return and IR is consistent with the “mixture-of-experts” idea adding value. But the drawdown got meaningfully worse, which contradicts the claim of drawdown reduction (at least in the current hard-gated implementation/thresholds). The lower IC also suggests the regime conditions may be too sparse/noisy or that the payoff is not well-captured by contemporaneous cross-sectional correlation (e.g., concentrated in a few large moves). Net: gating helps returns, but the current regime definitions/thresholds are not yet robust enough to control downside and maintain consistent predictive correlation.",
        "decision": true,
        "reason": "1) Drawdown worsening is often caused by discontinuous exposures (hard gates) and uncapped impact scaling (e.g., avgV/Vt can explode on very low volume days). Soft gating (continuous weights) and winsorization/capping should reduce tail risk. 2) IC dropping while returns rise is consistent with sparse activation: when the factor is nonzero only in rare regimes, average daily cross-sectional correlation can fall even if those rare days drive PnL. Increasing regime persistence (multi-day confirmation) and normalizing signals cross-sectionally can increase IC stability. 3) The current breakout branch in the hybrid outputs only breakout distance, whereas the standalone breakout factor multiplies by volume z-score; this mismatch can weaken the continuation expert and blur the intended “participation-confirmed” concept, potentially increasing false breakouts and drawdowns. Aligning the hybrid’s breakout magnitude with the confirmed breakout definition should help both IC and drawdown.\n\nConcrete iteration directions (keep the same theoretical framework, tune hyperparameters explicitly):\n- Align hybrid breakout expert with confirmation: use (C/TS_MAX(high,55)-1) * max(ZSCORE(volume,20),0) or * RANK(ZSCORE(volume,20)) rather than distance-only.\n- Cap impact scaling for vacuum expert: impact = clip(TS_MEAN(volume,20)/volume_t, 0, cap) with cap in {3,5,10}; also consider using log(impact) to reduce blow-ups.\n- Volatility-normalize the shock: use |r_t|/TS_STD(r,20) or true-range-based normalization; explore tail thresholds in {0.85, 0.90, 0.95}.\n- Smooth regime detection: require regime condition to hold for k of last m days (e.g., 2/3) or add a 3–5D decay on the signal to match the hypothesis horizons (vacuum mean-revert 2–5D; breakout continue 10–20D).\n- Replace cross-sectional rank for compression with within-name compression percentile (e.g., TS_RANK(σ20, 252) < p) to avoid “always compressed” artifacts in quiet markets; test p in {0.1, 0.2, 0.3}.\n- Add simple cross-sectional standardization on output (daily z-score or rank) to stabilize IC.\n- Keep factors separated for model learning: in addition to the hybrid, provide two standalone factors (vacuum-only and breakout-only) with fixed hyperparameters so the downstream model can learn mixtures; then compare against the single hybrid output to see whether gating truly helps generalization."
      }
    },
    "686d757980d4577c": {
      "factor_id": "686d757980d4577c",
      "factor_name": "SoftRouted_LiqRegime_RankFactor_60_20_5_20",
      "factor_expression": "RANK(((1-TS_RANK($close*$volume,60)/60)*TS_RANK(ABS($return),60)/60)*(-SIGN($return))+(TS_RANK(LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8)),60)/60)*(1-TS_RANK(TS_STD($return,20),60)/60)*SIGN(TS_MEAN($return,5)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((1-TS_RANK($close*$volume,60)/60)*(TS_RANK(ABS(TS_PCTCHANGE($close,1)),60)/60)*(-1*SIGN(TS_PCTCHANGE($close,1)))+(TS_RANK(LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8)),60)/60)*(1-TS_RANK(TS_STD(TS_PCTCHANGE($close,1),20),60)/60)*SIGN(TS_MEAN(TS_PCTCHANGE($close,1),5)))\" # Your output factor expression will be filled in here\n    name = \"SoftRouted_LiqRegime_RankFactor_60_20_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Single-factor soft routing between (A) contrarian exposure after high-impact/low-liquidity shock days and (B) trend-following exposure during persistent dollar-volume expansion with low realized volatility. Uses smooth time-series ranks as confidence weights (no hard regime switch).",
      "factor_formulation": "F_t=\\mathrm{RANK}\\Big(w^A_t\\cdot(-\\mathrm{sign}(r_t)) + w^B_t\\cdot \\mathrm{sign}(\\overline{r}_{t,5})\\Big),\\;w^A_t=(1-\\tfrac{\\mathrm{TSRANK}(DV_t,60)}{60})\\tfrac{\\mathrm{TSRANK}(|r_t|,60)}{60},\\;w^B_t=\\tfrac{\\mathrm{TSRANK}(\\log(\\overline{DV}_{20}/\\overline{DV}_{60}),60)}{60}(1-\\tfrac{\\mathrm{TSRANK}(\\sigma_{20},60)}{60})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "2cc65793a8a9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Short-horizon equity returns are driven by two distinct liquidity microstructure regimes that can be detected from OHLCV alone: (A) transient price-pressure shocks (large |1D return| occurring on abnormally low dollar volume implying high price impact) that mean-revert over the next 1–5 trading days, and (B) persistent liquidity re-rating/stealth accumulation (sustained dollar-volume expansion vs a 60D baseline with improving illiquidity proxy and contained realized volatility) that continues in the same direction over the next 3–10 trading days; a regime-aware routed factor that takes contrarian exposure only under (A) and trend-following exposure only under (B), with soft confidence-weighting and volatility gating, should produce higher and more stable RankIC than either standalone signal.\n                Concise Observation: The available dataset (daily OHLCV) supports constructing (i) 1D returns, (ii) dollar volume proxies, (iii) Amihud-like illiquidity measures, (iv) rolling z-scores/relative ratios over 20D/60D windows, and (v) realized volatility gates; this enables a single-factor implementation that blends two sub-signals via regime-confidence weights rather than brittle hard switches.\n                Concise Justification: A liquidity-shock day with unusually high price impact (high |ret| relative to dollar volume) is consistent with temporary supply/demand imbalance that tends to revert as liquidity replenishes, while a multi-week liquidity improvement with stable volatility is consistent with informed accumulation and lower trading frictions that supports continuation; using soft regime weights (e.g., sigmoid/softmax of standardized regime scores) and volatility gating should attenuate tail risk and whipsaw that often hurts pure short-horizon contrarian or pure short-horizon trend signals.\n                Concise Knowledge: If a large return occurs when depth is low (low dollar volume), the move is more likely dominated by temporary price impact and should partially reverse within 1–5D; when dollar volume persistently expands while an OHLCV-based illiquidity proxy (|ret|/dollar_volume) declines and realized volatility remains low, order-flow is more likely durable and the return direction should persist for 3–10D; therefore, conditioning (routing) mean-reversion vs continuation on these liquidity/impact state variables should reduce the main error modes (contrarian fighting true trends; trend-following chasing transient dislocations) in short-horizon prediction tasks.\n                concise Specification: Use only daily_pv.h5 OHLCV: define ret1=close/close.shift(1)-1 and dollar_vol=close*volume; ShockScore = Z60( |ret1| / dollar_vol ) * Z60(|ret1|) * (-sign(ret1)) with an additional liquidity filter Z60(dollar_vol)<0; RerateScore = [log(MA20(dollar_vol)/MA60(dollar_vol))] + [-Z60(MA20(|ret1|/dollar_vol))] + [sign(MOM5(close))] with a volatility gate RV20 = std20(ret1) below its 60D median (or Z60(RV20)<0); combine via soft routing weights w_shock=sigmoid(a*ShockRegime), w_rerate=sigmoid(b*RerateRegime), normalize w_shock+w_rerate<=1 and set final factor = w_shock*ShockScore + w_rerate*RerateScore; hyperparameters must be fixed in the factor definition (e.g., zscore_window=60, short_ma=20, long_ma=60, mom_window=5, rv_short=20, horizon_targets 1–5D for shock and 3–10D for rerate for evaluation).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T01:04:40.588648"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1606780361892489,
        "ICIR": 0.0585444199017734,
        "1day.excess_return_without_cost.std": 0.0045745569933027,
        "1day.excess_return_with_cost.annualized_return": 0.003207057744098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000212184062997,
        "1day.excess_return_without_cost.annualized_return": 0.050499806993309,
        "1day.excess_return_with_cost.std": 0.0045753612097675,
        "Rank IC": 0.0233422784688402,
        "IC": 0.0088385813176718,
        "1day.excess_return_without_cost.max_drawdown": -0.0976954758381251,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7155701192411004,
        "1day.pa": 0.0,
        "l2.valid": 0.9962528189209676,
        "Rank ICIR": 0.1671577593276472,
        "l2.train": 0.9927278547343652,
        "1day.excess_return_with_cost.information_ratio": 0.0454352492855257,
        "1day.excess_return_with_cost.mean": 1.3475032538226923e-05
      },
      "feedback": {
        "observations": "The current run improves the predictive correlation (IC = 0.008839 vs SOTA 0.005798), but portfolio-level outcomes deteriorate: max drawdown is worse (−0.0977 vs −0.0726; smaller is better), information ratio is lower (0.7156 vs 0.9726), and annualized return is slightly lower (0.0505 vs 0.0520). This pattern suggests the signal has more raw rank-order information, but that information is not being translated into stable PnL—likely due to higher tail risk, weaker calibration of exposures, or regime-mixing that increases variance.",
        "hypothesis_evaluation": "Partially supports the hypothesis at the “predictability” layer but not at the “routed factor improves stability” layer.\n\nSupport:\n- The routed/regime-aware construction appears to extract incremental cross-sectional information (higher IC), consistent with the idea that microstructure/liquidity regimes exist in OHLCV and are exploitable.\n\nRefute / not yet achieved:\n- The key hypothesis claim is “higher and more stable RankIC than either standalone signal,” and ultimately better portfolio stability. In this combined result, stability metrics worsen (drawdown up, IR down), indicating the current soft-routing and volatility gating are not yet adequately controlling risk or are routing the wrong days with too much confidence.\n\nLikely causes within the same framework:\n1) Sign-only exposure is too coarse: using only SIGN(r_t) and SIGN(mean_5d r) discards magnitude information. The factor may be directionally correct more often (IC), but position sizing may not downweight high-risk names/days, hurting drawdown/IR.\n2) Regime separation may be too “ranky”: TSRANK-based weights can be unstable around the median and can overreact to small distributional shifts, causing noisy routing (more turnover and tail exposure even if IC rises).\n3) The shock leg may be catching continuation (not mean reversion) in some environments: large |1D return| on low DV can also reflect true information shocks in illiquid names; contrarianing those without an additional “exhaustion” filter can increase drawdowns.\n\nComplexity control:\n- No explicit complexity warnings were provided. Expression length and feature count (close, volume, derived return) are reasonable; keep it simple and focus on calibration/robustness rather than adding many new primitives.",
        "decision": false,
        "reason": "The observed metric split (IC up, IR/return down, drawdown worse) is classic “good ranking but poor risk translation.” That usually comes from unstable weights, overly aggressive exposure during high-risk episodes, or mis-specified regime triggers. The current design relies heavily on TSRANK windows (60) and sign-based direction, which can increase trading in noisy boundary cases. Making the confidence smoother and adding conservative magnitude/clip rules should reduce tail losses while keeping the IC gain.\n\nConcrete next iterations (stay in-framework, enumerate hyperparameters explicitly):\n1) Replace SIGN-only with magnitude-aware but capped exposure:\n- Shock leg: use (−r_t) rather than −SIGN(r_t), multiplied by a clipped shock score.\n- Trend leg: use mean return over lookback L (e.g., TS_MEAN(r,5)) rather than SIGN(mean).\n- Add CLIP on the combined pre-rank signal (e.g., clip to [−k, k]) to control tail bets.\n\n2) Make regime confidence less jittery than TSRANK/60:\n- Try TS_ZSCORE and a sigmoid-like transform via clipping (since you may not have sigmoid, approximate with Z then CLIP).\n- Example alternatives while keeping the same windows: wA = CLIP(TS_ZSCORE(|r|/DV,60),0,c) * (1-TSRANK(DV,60)/60).\n\n3) Add an “information shock exclusion” filter for regime (A):\n- Use intraday reversal proxy from OHLC: (close-open)/(high-low) or (close-open)/open to detect trend days vs reversal days.\n- Only apply contrarian when the candle indicates exhaustion (e.g., large range but close near mid) rather than close near high/low.\n\n4) Parameter sensitivity grid to run (each is a distinct factor, static windows):\n- Shock lookback n_shock ∈ {40, 60, 120}\n- Shock return horizon: use r_1d vs r_2d (close/close.shift(2)-1)\n- DV baseline n_dv ∈ {40, 60, 120}\n- Trend mean-return horizon L_trend ∈ {3, 5, 10}\n- DV expansion windows: (short,long) ∈ {(10,60), (20,60), (20,120)}\n- Vol gate window n_vol ∈ {10, 20, 30} and rank window n_gate ∈ {60, 120}\nThese directly test the hypothesis horizons (A: 1–5 days mean reversion; B: 3–10 days continuation).\n\n5) Cross-sectional neutralization (still simple, no new raw features):\n- After computing the raw combined signal, optionally de-mean by day (cross-sectional mean) before final RANK to reduce market-mode contamination that can inflate drawdown.\n\n6) Reduce regime mixing by sharpening routing slightly (but remain soft):\n- Instead of wA and wB both active, use normalized weights: wA' = wA/(wA+wB+eps), wB' = wB/(wA+wB+eps). This keeps soft routing but prevents “double-counting” when both ranks are moderate.\n\nGiven the current results, the framework is promising (IC gain), but routing/calibration needs iteration to achieve the hypothesis goal of more stable performance."
      }
    },
    "32c9f5de2c9de59c": {
      "factor_id": "32c9f5de2c9de59c",
      "factor_name": "ShockImpact_MeanRevert_60D",
      "factor_expression": "RANK(-SIGN($return)*TS_ZSCORE(ABS($return)/(($close*$volume)+1e-8),60)*(1-TS_RANK($close*$volume,60)/60))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-SIGN(TS_PCTCHANGE($close,1))*TS_ZSCORE(ABS(TS_PCTCHANGE($close,1))/(($close*$volume)+1e-8),60)*(1-TS_RANK($close*$volume,60)/60))\" # Your output factor expression will be filled in here\n    name = \"ShockImpact_MeanRevert_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian shock factor: mean-reversion signal strongest when return impact per dollar volume is high and dollar volume is abnormally low (both measured over a 60D lookback).",
      "factor_formulation": "F_t=\\mathrm{RANK}\\Big(-\\mathrm{sign}(r_t)\\cdot Z_{60}(|r_t|/DV_t)\\cdot(1-\\tfrac{\\mathrm{TSRANK}(DV_t,60)}{60})\\Big),\\;DV_t=\\mathrm{close}_t\\cdot\\mathrm{volume}_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "2cc65793a8a9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Short-horizon equity returns are driven by two distinct liquidity microstructure regimes that can be detected from OHLCV alone: (A) transient price-pressure shocks (large |1D return| occurring on abnormally low dollar volume implying high price impact) that mean-revert over the next 1–5 trading days, and (B) persistent liquidity re-rating/stealth accumulation (sustained dollar-volume expansion vs a 60D baseline with improving illiquidity proxy and contained realized volatility) that continues in the same direction over the next 3–10 trading days; a regime-aware routed factor that takes contrarian exposure only under (A) and trend-following exposure only under (B), with soft confidence-weighting and volatility gating, should produce higher and more stable RankIC than either standalone signal.\n                Concise Observation: The available dataset (daily OHLCV) supports constructing (i) 1D returns, (ii) dollar volume proxies, (iii) Amihud-like illiquidity measures, (iv) rolling z-scores/relative ratios over 20D/60D windows, and (v) realized volatility gates; this enables a single-factor implementation that blends two sub-signals via regime-confidence weights rather than brittle hard switches.\n                Concise Justification: A liquidity-shock day with unusually high price impact (high |ret| relative to dollar volume) is consistent with temporary supply/demand imbalance that tends to revert as liquidity replenishes, while a multi-week liquidity improvement with stable volatility is consistent with informed accumulation and lower trading frictions that supports continuation; using soft regime weights (e.g., sigmoid/softmax of standardized regime scores) and volatility gating should attenuate tail risk and whipsaw that often hurts pure short-horizon contrarian or pure short-horizon trend signals.\n                Concise Knowledge: If a large return occurs when depth is low (low dollar volume), the move is more likely dominated by temporary price impact and should partially reverse within 1–5D; when dollar volume persistently expands while an OHLCV-based illiquidity proxy (|ret|/dollar_volume) declines and realized volatility remains low, order-flow is more likely durable and the return direction should persist for 3–10D; therefore, conditioning (routing) mean-reversion vs continuation on these liquidity/impact state variables should reduce the main error modes (contrarian fighting true trends; trend-following chasing transient dislocations) in short-horizon prediction tasks.\n                concise Specification: Use only daily_pv.h5 OHLCV: define ret1=close/close.shift(1)-1 and dollar_vol=close*volume; ShockScore = Z60( |ret1| / dollar_vol ) * Z60(|ret1|) * (-sign(ret1)) with an additional liquidity filter Z60(dollar_vol)<0; RerateScore = [log(MA20(dollar_vol)/MA60(dollar_vol))] + [-Z60(MA20(|ret1|/dollar_vol))] + [sign(MOM5(close))] with a volatility gate RV20 = std20(ret1) below its 60D median (or Z60(RV20)<0); combine via soft routing weights w_shock=sigmoid(a*ShockRegime), w_rerate=sigmoid(b*RerateRegime), normalize w_shock+w_rerate<=1 and set final factor = w_shock*ShockScore + w_rerate*RerateScore; hyperparameters must be fixed in the factor definition (e.g., zscore_window=60, short_ma=20, long_ma=60, mom_window=5, rv_short=20, horizon_targets 1–5D for shock and 3–10D for rerate for evaluation).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T01:04:40.588648"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1606780361892489,
        "ICIR": 0.0585444199017734,
        "1day.excess_return_without_cost.std": 0.0045745569933027,
        "1day.excess_return_with_cost.annualized_return": 0.003207057744098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000212184062997,
        "1day.excess_return_without_cost.annualized_return": 0.050499806993309,
        "1day.excess_return_with_cost.std": 0.0045753612097675,
        "Rank IC": 0.0233422784688402,
        "IC": 0.0088385813176718,
        "1day.excess_return_without_cost.max_drawdown": -0.0976954758381251,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7155701192411004,
        "1day.pa": 0.0,
        "l2.valid": 0.9962528189209676,
        "Rank ICIR": 0.1671577593276472,
        "l2.train": 0.9927278547343652,
        "1day.excess_return_with_cost.information_ratio": 0.0454352492855257,
        "1day.excess_return_with_cost.mean": 1.3475032538226923e-05
      },
      "feedback": {
        "observations": "The current run improves the predictive correlation (IC = 0.008839 vs SOTA 0.005798), but portfolio-level outcomes deteriorate: max drawdown is worse (−0.0977 vs −0.0726; smaller is better), information ratio is lower (0.7156 vs 0.9726), and annualized return is slightly lower (0.0505 vs 0.0520). This pattern suggests the signal has more raw rank-order information, but that information is not being translated into stable PnL—likely due to higher tail risk, weaker calibration of exposures, or regime-mixing that increases variance.",
        "hypothesis_evaluation": "Partially supports the hypothesis at the “predictability” layer but not at the “routed factor improves stability” layer.\n\nSupport:\n- The routed/regime-aware construction appears to extract incremental cross-sectional information (higher IC), consistent with the idea that microstructure/liquidity regimes exist in OHLCV and are exploitable.\n\nRefute / not yet achieved:\n- The key hypothesis claim is “higher and more stable RankIC than either standalone signal,” and ultimately better portfolio stability. In this combined result, stability metrics worsen (drawdown up, IR down), indicating the current soft-routing and volatility gating are not yet adequately controlling risk or are routing the wrong days with too much confidence.\n\nLikely causes within the same framework:\n1) Sign-only exposure is too coarse: using only SIGN(r_t) and SIGN(mean_5d r) discards magnitude information. The factor may be directionally correct more often (IC), but position sizing may not downweight high-risk names/days, hurting drawdown/IR.\n2) Regime separation may be too “ranky”: TSRANK-based weights can be unstable around the median and can overreact to small distributional shifts, causing noisy routing (more turnover and tail exposure even if IC rises).\n3) The shock leg may be catching continuation (not mean reversion) in some environments: large |1D return| on low DV can also reflect true information shocks in illiquid names; contrarianing those without an additional “exhaustion” filter can increase drawdowns.\n\nComplexity control:\n- No explicit complexity warnings were provided. Expression length and feature count (close, volume, derived return) are reasonable; keep it simple and focus on calibration/robustness rather than adding many new primitives.",
        "decision": false,
        "reason": "The observed metric split (IC up, IR/return down, drawdown worse) is classic “good ranking but poor risk translation.” That usually comes from unstable weights, overly aggressive exposure during high-risk episodes, or mis-specified regime triggers. The current design relies heavily on TSRANK windows (60) and sign-based direction, which can increase trading in noisy boundary cases. Making the confidence smoother and adding conservative magnitude/clip rules should reduce tail losses while keeping the IC gain.\n\nConcrete next iterations (stay in-framework, enumerate hyperparameters explicitly):\n1) Replace SIGN-only with magnitude-aware but capped exposure:\n- Shock leg: use (−r_t) rather than −SIGN(r_t), multiplied by a clipped shock score.\n- Trend leg: use mean return over lookback L (e.g., TS_MEAN(r,5)) rather than SIGN(mean).\n- Add CLIP on the combined pre-rank signal (e.g., clip to [−k, k]) to control tail bets.\n\n2) Make regime confidence less jittery than TSRANK/60:\n- Try TS_ZSCORE and a sigmoid-like transform via clipping (since you may not have sigmoid, approximate with Z then CLIP).\n- Example alternatives while keeping the same windows: wA = CLIP(TS_ZSCORE(|r|/DV,60),0,c) * (1-TSRANK(DV,60)/60).\n\n3) Add an “information shock exclusion” filter for regime (A):\n- Use intraday reversal proxy from OHLC: (close-open)/(high-low) or (close-open)/open to detect trend days vs reversal days.\n- Only apply contrarian when the candle indicates exhaustion (e.g., large range but close near mid) rather than close near high/low.\n\n4) Parameter sensitivity grid to run (each is a distinct factor, static windows):\n- Shock lookback n_shock ∈ {40, 60, 120}\n- Shock return horizon: use r_1d vs r_2d (close/close.shift(2)-1)\n- DV baseline n_dv ∈ {40, 60, 120}\n- Trend mean-return horizon L_trend ∈ {3, 5, 10}\n- DV expansion windows: (short,long) ∈ {(10,60), (20,60), (20,120)}\n- Vol gate window n_vol ∈ {10, 20, 30} and rank window n_gate ∈ {60, 120}\nThese directly test the hypothesis horizons (A: 1–5 days mean reversion; B: 3–10 days continuation).\n\n5) Cross-sectional neutralization (still simple, no new raw features):\n- After computing the raw combined signal, optionally de-mean by day (cross-sectional mean) before final RANK to reduce market-mode contamination that can inflate drawdown.\n\n6) Reduce regime mixing by sharpening routing slightly (but remain soft):\n- Instead of wA and wB both active, use normalized weights: wA' = wA/(wA+wB+eps), wB' = wB/(wA+wB+eps). This keeps soft routing but prevents “double-counting” when both ranks are moderate.\n\nGiven the current results, the framework is promising (IC gain), but routing/calibration needs iteration to achieve the hypothesis goal of more stable performance."
      }
    },
    "70501146bb5028e0": {
      "factor_id": "70501146bb5028e0",
      "factor_name": "LiqRerate_Trend_VolGate_20_60_5",
      "factor_expression": "RANK(SIGN(TS_MEAN($return,5))*LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8))*(1-TS_RANK(TS_STD($return,20),60)/60))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SIGN(TS_MEAN(TS_PCTCHANGE($close,1),5))*LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8))*(1-TS_RANK(TS_STD(TS_PCTCHANGE($close,1),20),60)/60))\" # Your output factor expression will be filled in here\n    name = \"LiqRerate_Trend_VolGate_20_60_5\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Persistent liquidity re-rating / stealth accumulation proxy: trend-following exposure when dollar volume expands versus a 60D baseline, gated down when 20D realized volatility is high (softly via 60D time-series rank).",
      "factor_formulation": "F_t=\\mathrm{RANK}\\Big(\\mathrm{sign}(\\overline{r}_{t,5})\\cdot \\log(\\overline{DV}_{t,20}/\\overline{DV}_{t,60})\\cdot(1-\\tfrac{\\mathrm{TSRANK}(\\sigma_{t,20},60)}{60})\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "2cc65793a8a9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Short-horizon equity returns are driven by two distinct liquidity microstructure regimes that can be detected from OHLCV alone: (A) transient price-pressure shocks (large |1D return| occurring on abnormally low dollar volume implying high price impact) that mean-revert over the next 1–5 trading days, and (B) persistent liquidity re-rating/stealth accumulation (sustained dollar-volume expansion vs a 60D baseline with improving illiquidity proxy and contained realized volatility) that continues in the same direction over the next 3–10 trading days; a regime-aware routed factor that takes contrarian exposure only under (A) and trend-following exposure only under (B), with soft confidence-weighting and volatility gating, should produce higher and more stable RankIC than either standalone signal.\n                Concise Observation: The available dataset (daily OHLCV) supports constructing (i) 1D returns, (ii) dollar volume proxies, (iii) Amihud-like illiquidity measures, (iv) rolling z-scores/relative ratios over 20D/60D windows, and (v) realized volatility gates; this enables a single-factor implementation that blends two sub-signals via regime-confidence weights rather than brittle hard switches.\n                Concise Justification: A liquidity-shock day with unusually high price impact (high |ret| relative to dollar volume) is consistent with temporary supply/demand imbalance that tends to revert as liquidity replenishes, while a multi-week liquidity improvement with stable volatility is consistent with informed accumulation and lower trading frictions that supports continuation; using soft regime weights (e.g., sigmoid/softmax of standardized regime scores) and volatility gating should attenuate tail risk and whipsaw that often hurts pure short-horizon contrarian or pure short-horizon trend signals.\n                Concise Knowledge: If a large return occurs when depth is low (low dollar volume), the move is more likely dominated by temporary price impact and should partially reverse within 1–5D; when dollar volume persistently expands while an OHLCV-based illiquidity proxy (|ret|/dollar_volume) declines and realized volatility remains low, order-flow is more likely durable and the return direction should persist for 3–10D; therefore, conditioning (routing) mean-reversion vs continuation on these liquidity/impact state variables should reduce the main error modes (contrarian fighting true trends; trend-following chasing transient dislocations) in short-horizon prediction tasks.\n                concise Specification: Use only daily_pv.h5 OHLCV: define ret1=close/close.shift(1)-1 and dollar_vol=close*volume; ShockScore = Z60( |ret1| / dollar_vol ) * Z60(|ret1|) * (-sign(ret1)) with an additional liquidity filter Z60(dollar_vol)<0; RerateScore = [log(MA20(dollar_vol)/MA60(dollar_vol))] + [-Z60(MA20(|ret1|/dollar_vol))] + [sign(MOM5(close))] with a volatility gate RV20 = std20(ret1) below its 60D median (or Z60(RV20)<0); combine via soft routing weights w_shock=sigmoid(a*ShockRegime), w_rerate=sigmoid(b*RerateRegime), normalize w_shock+w_rerate<=1 and set final factor = w_shock*ShockScore + w_rerate*RerateScore; hyperparameters must be fixed in the factor definition (e.g., zscore_window=60, short_ma=20, long_ma=60, mom_window=5, rv_short=20, horizon_targets 1–5D for shock and 3–10D for rerate for evaluation).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T01:04:40.588648"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1606780361892489,
        "ICIR": 0.0585444199017734,
        "1day.excess_return_without_cost.std": 0.0045745569933027,
        "1day.excess_return_with_cost.annualized_return": 0.003207057744098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000212184062997,
        "1day.excess_return_without_cost.annualized_return": 0.050499806993309,
        "1day.excess_return_with_cost.std": 0.0045753612097675,
        "Rank IC": 0.0233422784688402,
        "IC": 0.0088385813176718,
        "1day.excess_return_without_cost.max_drawdown": -0.0976954758381251,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7155701192411004,
        "1day.pa": 0.0,
        "l2.valid": 0.9962528189209676,
        "Rank ICIR": 0.1671577593276472,
        "l2.train": 0.9927278547343652,
        "1day.excess_return_with_cost.information_ratio": 0.0454352492855257,
        "1day.excess_return_with_cost.mean": 1.3475032538226923e-05
      },
      "feedback": {
        "observations": "The current run improves the predictive correlation (IC = 0.008839 vs SOTA 0.005798), but portfolio-level outcomes deteriorate: max drawdown is worse (−0.0977 vs −0.0726; smaller is better), information ratio is lower (0.7156 vs 0.9726), and annualized return is slightly lower (0.0505 vs 0.0520). This pattern suggests the signal has more raw rank-order information, but that information is not being translated into stable PnL—likely due to higher tail risk, weaker calibration of exposures, or regime-mixing that increases variance.",
        "hypothesis_evaluation": "Partially supports the hypothesis at the “predictability” layer but not at the “routed factor improves stability” layer.\n\nSupport:\n- The routed/regime-aware construction appears to extract incremental cross-sectional information (higher IC), consistent with the idea that microstructure/liquidity regimes exist in OHLCV and are exploitable.\n\nRefute / not yet achieved:\n- The key hypothesis claim is “higher and more stable RankIC than either standalone signal,” and ultimately better portfolio stability. In this combined result, stability metrics worsen (drawdown up, IR down), indicating the current soft-routing and volatility gating are not yet adequately controlling risk or are routing the wrong days with too much confidence.\n\nLikely causes within the same framework:\n1) Sign-only exposure is too coarse: using only SIGN(r_t) and SIGN(mean_5d r) discards magnitude information. The factor may be directionally correct more often (IC), but position sizing may not downweight high-risk names/days, hurting drawdown/IR.\n2) Regime separation may be too “ranky”: TSRANK-based weights can be unstable around the median and can overreact to small distributional shifts, causing noisy routing (more turnover and tail exposure even if IC rises).\n3) The shock leg may be catching continuation (not mean reversion) in some environments: large |1D return| on low DV can also reflect true information shocks in illiquid names; contrarianing those without an additional “exhaustion” filter can increase drawdowns.\n\nComplexity control:\n- No explicit complexity warnings were provided. Expression length and feature count (close, volume, derived return) are reasonable; keep it simple and focus on calibration/robustness rather than adding many new primitives.",
        "decision": false,
        "reason": "The observed metric split (IC up, IR/return down, drawdown worse) is classic “good ranking but poor risk translation.” That usually comes from unstable weights, overly aggressive exposure during high-risk episodes, or mis-specified regime triggers. The current design relies heavily on TSRANK windows (60) and sign-based direction, which can increase trading in noisy boundary cases. Making the confidence smoother and adding conservative magnitude/clip rules should reduce tail losses while keeping the IC gain.\n\nConcrete next iterations (stay in-framework, enumerate hyperparameters explicitly):\n1) Replace SIGN-only with magnitude-aware but capped exposure:\n- Shock leg: use (−r_t) rather than −SIGN(r_t), multiplied by a clipped shock score.\n- Trend leg: use mean return over lookback L (e.g., TS_MEAN(r,5)) rather than SIGN(mean).\n- Add CLIP on the combined pre-rank signal (e.g., clip to [−k, k]) to control tail bets.\n\n2) Make regime confidence less jittery than TSRANK/60:\n- Try TS_ZSCORE and a sigmoid-like transform via clipping (since you may not have sigmoid, approximate with Z then CLIP).\n- Example alternatives while keeping the same windows: wA = CLIP(TS_ZSCORE(|r|/DV,60),0,c) * (1-TSRANK(DV,60)/60).\n\n3) Add an “information shock exclusion” filter for regime (A):\n- Use intraday reversal proxy from OHLC: (close-open)/(high-low) or (close-open)/open to detect trend days vs reversal days.\n- Only apply contrarian when the candle indicates exhaustion (e.g., large range but close near mid) rather than close near high/low.\n\n4) Parameter sensitivity grid to run (each is a distinct factor, static windows):\n- Shock lookback n_shock ∈ {40, 60, 120}\n- Shock return horizon: use r_1d vs r_2d (close/close.shift(2)-1)\n- DV baseline n_dv ∈ {40, 60, 120}\n- Trend mean-return horizon L_trend ∈ {3, 5, 10}\n- DV expansion windows: (short,long) ∈ {(10,60), (20,60), (20,120)}\n- Vol gate window n_vol ∈ {10, 20, 30} and rank window n_gate ∈ {60, 120}\nThese directly test the hypothesis horizons (A: 1–5 days mean reversion; B: 3–10 days continuation).\n\n5) Cross-sectional neutralization (still simple, no new raw features):\n- After computing the raw combined signal, optionally de-mean by day (cross-sectional mean) before final RANK to reduce market-mode contamination that can inflate drawdown.\n\n6) Reduce regime mixing by sharpening routing slightly (but remain soft):\n- Instead of wA and wB both active, use normalized weights: wA' = wA/(wA+wB+eps), wB' = wB/(wA+wB+eps). This keeps soft routing but prevents “double-counting” when both ranks are moderate.\n\nGiven the current results, the framework is promising (IC gain), but routing/calibration needs iteration to achieve the hypothesis goal of more stable performance."
      }
    },
    "ded9bb67a3871124": {
      "factor_id": "ded9bb67a3871124",
      "factor_name": "Liquidity_Shock_Reversal_60D_20D",
      "factor_expression": "((TS_RANK(ABS($return)/($close*$volume+1e-8),60)>54)&&(TS_RANK(ABS($return),60)>54)&&(ABS(TS_CORR(LOG($close),SEQUENCE(20),20))<0.7))?(-SIGN($return)*TS_ZSCORE(ABS($return),60)):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(((TS_RANK(ABS(TS_PCTCHANGE($close,1))/((($close*$volume)+0.00000001)),60)>54)&&(TS_RANK(ABS(TS_PCTCHANGE($close,1)),60)>54)&&(ABS(TS_CORR(LOG($close),SEQUENCE(20),20))<0.7))?(-SIGN(TS_PCTCHANGE($close,1))*TS_ZSCORE(ABS(TS_PCTCHANGE($close,1)),60)):(0))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Shock_Reversal_60D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Contrarian signal for transient liquidity/price-impact shocks: activates when Amihud-style illiquidity (|r|/(close*volume)) and |r| are both extreme over 60D, and suppresses (veto) when 20D trend quality is high (strong linear trend proxy). Output fades the 1D move direction with size scaled by 60D z-score of |r|.",
      "factor_formulation": "LSR_{60,20}=\\begin{cases}-\\operatorname{sign}(r_t)\\cdot z_{60}(|r_t|), & \\text{if } \\operatorname{rank}_{60}(\\frac{|r_t|}{C_t V_t})>54 \\wedge \\operatorname{rank}_{60}(|r_t|)>54 \\wedge |\\rho_{20}(\\log C, t)|<0.7\\\\0, & \\text{otherwise}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "a3a2db0f967f",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–15D) return predictability improves when a single regime-switching factor explicitly distinguishes (A) transient liquidity/price-impact shocks—identified by extreme Amihud illiquidity (|r1|/dollar_volume) and extreme |r1|—that mean-revert over 1–5 days, from (B) information-driven repricing—identified by 20D volatility/range compression followed by an upside/downside breakout above/below a 55D extreme with positive volume surprise and strong trend-fit quality—that tends to continue over 5–15 days; the factor should take contrarian sign in regime A, momentum sign in regime B, and suppress signals when veto conditions indicate the opposite regime.\n                Concise Observation: The available data (daily OHLCV) supports constructing both microstructure-like proxies (Amihud illiquidity via |return|/dollar_volume) and pattern/confirmation features (rolling realized volatility, rolling high/low breakouts, volume z-scores, and trend-fit R²), enabling a gated fusion where contrarian and momentum components are activated only when their respective conditions are met.\n                Concise Justification: Liquidity/price-impact shocks mechanically decouple price from fundamentals and often reverse as liquidity normalizes, while volatility compression followed by breakout with volume confirmation reflects a resolution of uncertainty and broader participation, making continuation more likely; adding two-way vetoes (do not fade high-quality trends; do not chase breakouts during illiquidity shocks) targets each parent’s weakness (trend-fading drawdowns and low-liquidity breakout traps) within a unified, testable factor.\n                Concise Knowledge: If an outsized 1D price move occurs when dollar volume is unusually low (high price-impact/illiquidity), then the move is more likely to be temporary and mean-revert within a few days; when volatility compresses for weeks and price breaks out of a multi-week range with volume surprise and a clean trend (high trend-fit), then the move is more likely information-driven and continues over the next 1–3 weeks; conditioning signal direction on these regime diagnostics can reduce whipsaw versus applying pure mean-reversion or pure momentum indiscriminately.\n                concise Specification: Construct two gated sub-signals from daily_pv.h5: (1) Liquidity-Shock Reversal gate ON when Amihud_z60 = zscore_60(|r1|/(close*volume)) is in the top 10% cross-section AND |r1| is in the top 10% of its 60D history; set LSR score = -sign(r1)*min(|r1|_z60, cap) and optionally veto if TrendFit_R2_20 (R² of 20D linear fit of log(close) vs time) is above a high threshold (e.g., >0.7). (2) Squeeze-Breakout Continuation gate ON when VolRatio = RV_20/RV_60 is in the bottom 20% (compression), AND close breaks above 55D high (or below 55D low for downside) AND VolumeSurprise_z20 = zscore_20(volume/MA_20(volume)) is positive; set SBC score = +sign(breakout_direction)*min(TrendFit_R2_20, cap) and veto if Amihud_z60 is extreme (e.g., top decile). Final fusion factor = LSR score if LSR gate ON else SBC score if SBC gate ON else 0 (or small weighted blend with low weight); all windows/hyperparameters are fixed per factor: {lookbacks: 1D return, 20D/60D volatility, 55D breakout, 20D volume surprise, 60D illiquidity zscore, 20D trend-fit}; expected relationship: negative next 1–5D returns after positive LSR and positive next 5–15D returns after positive SBC, with reduced signal when vetoes trigger.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:15:57.691565"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1114229151412787,
        "ICIR": 0.0378326399978071,
        "1day.excess_return_without_cost.std": 0.0042956189373063,
        "1day.excess_return_with_cost.annualized_return": 0.0376195754325876,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003555260319057,
        "1day.excess_return_without_cost.annualized_return": 0.0846151955935682,
        "1day.excess_return_with_cost.std": 0.0042959664510644,
        "Rank IC": 0.0218279550161853,
        "IC": 0.0051297293054178,
        "1day.excess_return_without_cost.max_drawdown": -0.1005141801983582,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.2768331095783645,
        "1day.pa": 0.0,
        "l2.valid": 0.9965408028878796,
        "Rank ICIR": 0.1674974912581557,
        "l2.train": 0.9946920901697148,
        "1day.excess_return_with_cost.information_ratio": 0.5676289410456812,
        "1day.excess_return_with_cost.mean": 0.000158065442994
      },
      "feedback": {
        "observations": "Only Liquidity_Shock_Reversal_60D_20D (LSR_{60,20}) was implemented, so the experiment primarily tests the “transient liquidity/price-impact shock mean-reversion” leg (Regime A) rather than the full regime-switching hypothesis (A vs B).\n\nRelative to SOTA: annualized return improved (0.0846 vs 0.0520) and information ratio improved (1.2768 vs 0.9726), but max drawdown worsened (-0.1005 vs -0.0726) and IC decreased (0.00513 vs 0.00580). This pattern suggests the factor may be helping realized PnL via episodic payoffs (e.g., capturing a subset of reversals with larger magnitude), but with weaker overall monotonic predictive correlation (IC) and worse tail behavior (drawdown).",
        "hypothesis_evaluation": "Partially supportive, but not a full validation.\n\n1) What is supported:\n- The implemented Regime A concept (extreme illiquidity + extreme |r1| leading to short-term reversal) appears directionally useful in portfolio terms: higher annualized return and IR indicate the contrarian shock-reversal component can add value.\n\n2) What is not yet verified / refuted:\n- The core hypothesis explicitly requires a single regime-switching factor that distinguishes A (mean-reverting liquidity shocks) from B (information-driven continuation after squeeze/breakout) with veto logic. Since the Regime B factor (Squeeze_Breakout_Continuation_20_60_55_20) was not implemented, the key claim—“predictability improves when explicitly switching between contrarian A and momentum B and suppressing opposite-regime signals”—cannot be confirmed in this run.\n\n3) Risk/robustness concern revealed by metrics:\n- Lower IC vs SOTA implies weaker average day-to-day rank-order predictability. The improvement in IR/return alongside worse IC can happen when returns are driven by a smaller set of high-impact events (fat-tailed payoff) rather than broad, stable cross-sectional signal.\n- Worse max drawdown indicates the current veto condition (|corr_{20}(logC, t)| < 0.7) is likely insufficient to prevent trading into persistent trends where contrarian positioning is punished (classic “falling knife / melt-up” regime).",
        "decision": true,
        "reason": "Why the current result looks the way it does:\n- LSR_{60,20} uses hard activation gates: TS_RANK_{60}(Amihud) > 54 and TS_RANK_{60}(|r|) > 54, then a contrarian sign scaled by TS_ZSCORE_{60}(|r|). This creates sparse, high-conviction trades—good for episodic PnL and IR, but not necessarily for IC.\n- The only veto is |corr_{20}(logC, t)| < 0.7, which is a coarse proxy for trend quality. Many adverse trend regimes can still have |corr| below 0.7 (noisy trend, but still persistent), leading to larger drawdowns.\n\nConcrete next iterations (stay within the same theoretical framework; include hyperparameters explicitly):\n1) Strengthen Regime A (LSR) without adding complexity:\n- Replace/augment scaling: use z-score of Amihud itself, not only z-score of |r|:\n  - Current scaling: TS_ZSCORE_{60}(|r|)\n  - Try: TS_ZSCORE_{60}(|r|/(C*V)) or a blend: 0.5*ZS_{60}(|r|)+0.5*ZS_{60}(Amihud)\n- Add a short-horizon “continuation hazard” veto with explicit windows:\n  - Example veto: if past 5D return has same sign and large magnitude, suppress contrarian\n  - Hyperparameters to try: lookback 3D, 5D, 10D; thresholds using TS_ZSCORE_{60} or TS_RANK_{20}\n- Add signal decay/holding consistency to reduce turnover-driven drawdowns (even though costs aren’t included, stability matters):\n  - Apply a 3D or 5D moving average to the signal (window=3/5) OR cap extremes (winsorize at e.g. 1%/99% cross-section daily).\n\n2) Implement Regime B (SBC_{20,60,55,20}) to actually test the hypothesis:\n- Keep the stated hyperparameters as fixed factor definitions:\n  - vol windows: 20D and 60D\n  - breakout extreme window: 55D\n  - volume surprise window: 20D (z-score)\n  - illiquidity veto window: 60D rank threshold\n- After implementation, test a single “regime-switching composite factor” with explicit gating (still simple):\n  - Regime score = 1{SBC condition} - 1{LSR condition}\n  - Output = if SBC active -> + momentum signal; elif LSR active -> contrarian; else 0\n  - Avoid blending both simultaneously unless you add a clear priority rule.\n\n3) Parameter sensitivity grid (minimal but targeted):\n- LSR ranks: TS_RANK_{60} threshold 54/55/56 (i.e., ~90%/92%/93% percentile)\n- LSR z-score window: 40D / 60D / 90D\n- Trend veto window: 10D / 20D / 30D and threshold 0.6 / 0.7 / 0.8\n- SBC breakout window: 40D / 55D / 80D; squeeze ratio threshold: 0.6 / 0.7 / 0.8\n\n4) Complexity control:\n- No explicit complexity warnings were provided; keep it that way. Prefer small modifications (one new veto or one alternative scaling) rather than stacking many conditions. The biggest win is implementing SBC and a clean switch rule rather than making LSR more ornate."
      }
    },
    "01b76df765e74cfd": {
      "factor_id": "01b76df765e74cfd",
      "factor_name": "Squeeze_Breakout_Continuation_20_60_55_20",
      "factor_expression": "((TS_STD($return,20)/(TS_STD($return,60)+1e-8)<0.7)&&(($close>TS_MAX($close,55))||($close<TS_MIN($close,55)))&&(TS_ZSCORE($volume,20)>0)&&(TS_RANK(ABS($return)/($close*$volume+1e-8),60)<55))?((($close>TS_MAX($close,55))?(1):(-1))*ABS(TS_CORR(LOG($close),SEQUENCE(20),20))):(0)",
      "factor_implementation_code": "",
      "factor_description": "Momentum signal for information-driven repricing: activates when realized volatility is compressed (20D/60D vol ratio low), price breaks out above/below a 55D close extreme, volume shows positive 20D surprise (z-score), and illiquidity is NOT extreme (veto). Signal direction follows breakout direction and is scaled by 20D trend quality proxy (|corr(log(close), time)|).",
      "factor_formulation": "SBC_{20,60,55,20}=\\begin{cases}s\\cdot |\\rho_{20}(\\log C, t)|, & \\text{if } \\frac{\\sigma_{20}(r)}{\\sigma_{60}(r)}<0.7 \\wedge (C>\\max_{55}C \\vee C<\\min_{55}C)\\\\ \\wedge z_{20}(V)>0 \\wedge \\operatorname{rank}_{60}(\\frac{|r|}{CV})<55\\\\0, & \\text{otherwise}\\end{cases},\\ \\ s=\\mathbb{1}[C>\\max_{55}C]-\\mathbb{1}[C<\\min_{55}C]",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "a3a2db0f967f",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–15D) return predictability improves when a single regime-switching factor explicitly distinguishes (A) transient liquidity/price-impact shocks—identified by extreme Amihud illiquidity (|r1|/dollar_volume) and extreme |r1|—that mean-revert over 1–5 days, from (B) information-driven repricing—identified by 20D volatility/range compression followed by an upside/downside breakout above/below a 55D extreme with positive volume surprise and strong trend-fit quality—that tends to continue over 5–15 days; the factor should take contrarian sign in regime A, momentum sign in regime B, and suppress signals when veto conditions indicate the opposite regime.\n                Concise Observation: The available data (daily OHLCV) supports constructing both microstructure-like proxies (Amihud illiquidity via |return|/dollar_volume) and pattern/confirmation features (rolling realized volatility, rolling high/low breakouts, volume z-scores, and trend-fit R²), enabling a gated fusion where contrarian and momentum components are activated only when their respective conditions are met.\n                Concise Justification: Liquidity/price-impact shocks mechanically decouple price from fundamentals and often reverse as liquidity normalizes, while volatility compression followed by breakout with volume confirmation reflects a resolution of uncertainty and broader participation, making continuation more likely; adding two-way vetoes (do not fade high-quality trends; do not chase breakouts during illiquidity shocks) targets each parent’s weakness (trend-fading drawdowns and low-liquidity breakout traps) within a unified, testable factor.\n                Concise Knowledge: If an outsized 1D price move occurs when dollar volume is unusually low (high price-impact/illiquidity), then the move is more likely to be temporary and mean-revert within a few days; when volatility compresses for weeks and price breaks out of a multi-week range with volume surprise and a clean trend (high trend-fit), then the move is more likely information-driven and continues over the next 1–3 weeks; conditioning signal direction on these regime diagnostics can reduce whipsaw versus applying pure mean-reversion or pure momentum indiscriminately.\n                concise Specification: Construct two gated sub-signals from daily_pv.h5: (1) Liquidity-Shock Reversal gate ON when Amihud_z60 = zscore_60(|r1|/(close*volume)) is in the top 10% cross-section AND |r1| is in the top 10% of its 60D history; set LSR score = -sign(r1)*min(|r1|_z60, cap) and optionally veto if TrendFit_R2_20 (R² of 20D linear fit of log(close) vs time) is above a high threshold (e.g., >0.7). (2) Squeeze-Breakout Continuation gate ON when VolRatio = RV_20/RV_60 is in the bottom 20% (compression), AND close breaks above 55D high (or below 55D low for downside) AND VolumeSurprise_z20 = zscore_20(volume/MA_20(volume)) is positive; set SBC score = +sign(breakout_direction)*min(TrendFit_R2_20, cap) and veto if Amihud_z60 is extreme (e.g., top decile). Final fusion factor = LSR score if LSR gate ON else SBC score if SBC gate ON else 0 (or small weighted blend with low weight); all windows/hyperparameters are fixed per factor: {lookbacks: 1D return, 20D/60D volatility, 55D breakout, 20D volume surprise, 60D illiquidity zscore, 20D trend-fit}; expected relationship: negative next 1–5D returns after positive LSR and positive next 5–15D returns after positive SBC, with reduced signal when vetoes trigger.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:15:57.691565"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1114229151412787,
        "ICIR": 0.0378326399978071,
        "1day.excess_return_without_cost.std": 0.0042956189373063,
        "1day.excess_return_with_cost.annualized_return": 0.0376195754325876,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003555260319057,
        "1day.excess_return_without_cost.annualized_return": 0.0846151955935682,
        "1day.excess_return_with_cost.std": 0.0042959664510644,
        "Rank IC": 0.0218279550161853,
        "IC": 0.0051297293054178,
        "1day.excess_return_without_cost.max_drawdown": -0.1005141801983582,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.2768331095783645,
        "1day.pa": 0.0,
        "l2.valid": 0.9965408028878796,
        "Rank ICIR": 0.1674974912581557,
        "l2.train": 0.9946920901697148,
        "1day.excess_return_with_cost.information_ratio": 0.5676289410456812,
        "1day.excess_return_with_cost.mean": 0.000158065442994
      },
      "feedback": {
        "observations": "Only Liquidity_Shock_Reversal_60D_20D (LSR_{60,20}) was implemented, so the experiment primarily tests the “transient liquidity/price-impact shock mean-reversion” leg (Regime A) rather than the full regime-switching hypothesis (A vs B).\n\nRelative to SOTA: annualized return improved (0.0846 vs 0.0520) and information ratio improved (1.2768 vs 0.9726), but max drawdown worsened (-0.1005 vs -0.0726) and IC decreased (0.00513 vs 0.00580). This pattern suggests the factor may be helping realized PnL via episodic payoffs (e.g., capturing a subset of reversals with larger magnitude), but with weaker overall monotonic predictive correlation (IC) and worse tail behavior (drawdown).",
        "hypothesis_evaluation": "Partially supportive, but not a full validation.\n\n1) What is supported:\n- The implemented Regime A concept (extreme illiquidity + extreme |r1| leading to short-term reversal) appears directionally useful in portfolio terms: higher annualized return and IR indicate the contrarian shock-reversal component can add value.\n\n2) What is not yet verified / refuted:\n- The core hypothesis explicitly requires a single regime-switching factor that distinguishes A (mean-reverting liquidity shocks) from B (information-driven continuation after squeeze/breakout) with veto logic. Since the Regime B factor (Squeeze_Breakout_Continuation_20_60_55_20) was not implemented, the key claim—“predictability improves when explicitly switching between contrarian A and momentum B and suppressing opposite-regime signals”—cannot be confirmed in this run.\n\n3) Risk/robustness concern revealed by metrics:\n- Lower IC vs SOTA implies weaker average day-to-day rank-order predictability. The improvement in IR/return alongside worse IC can happen when returns are driven by a smaller set of high-impact events (fat-tailed payoff) rather than broad, stable cross-sectional signal.\n- Worse max drawdown indicates the current veto condition (|corr_{20}(logC, t)| < 0.7) is likely insufficient to prevent trading into persistent trends where contrarian positioning is punished (classic “falling knife / melt-up” regime).",
        "decision": true,
        "reason": "Why the current result looks the way it does:\n- LSR_{60,20} uses hard activation gates: TS_RANK_{60}(Amihud) > 54 and TS_RANK_{60}(|r|) > 54, then a contrarian sign scaled by TS_ZSCORE_{60}(|r|). This creates sparse, high-conviction trades—good for episodic PnL and IR, but not necessarily for IC.\n- The only veto is |corr_{20}(logC, t)| < 0.7, which is a coarse proxy for trend quality. Many adverse trend regimes can still have |corr| below 0.7 (noisy trend, but still persistent), leading to larger drawdowns.\n\nConcrete next iterations (stay within the same theoretical framework; include hyperparameters explicitly):\n1) Strengthen Regime A (LSR) without adding complexity:\n- Replace/augment scaling: use z-score of Amihud itself, not only z-score of |r|:\n  - Current scaling: TS_ZSCORE_{60}(|r|)\n  - Try: TS_ZSCORE_{60}(|r|/(C*V)) or a blend: 0.5*ZS_{60}(|r|)+0.5*ZS_{60}(Amihud)\n- Add a short-horizon “continuation hazard” veto with explicit windows:\n  - Example veto: if past 5D return has same sign and large magnitude, suppress contrarian\n  - Hyperparameters to try: lookback 3D, 5D, 10D; thresholds using TS_ZSCORE_{60} or TS_RANK_{20}\n- Add signal decay/holding consistency to reduce turnover-driven drawdowns (even though costs aren’t included, stability matters):\n  - Apply a 3D or 5D moving average to the signal (window=3/5) OR cap extremes (winsorize at e.g. 1%/99% cross-section daily).\n\n2) Implement Regime B (SBC_{20,60,55,20}) to actually test the hypothesis:\n- Keep the stated hyperparameters as fixed factor definitions:\n  - vol windows: 20D and 60D\n  - breakout extreme window: 55D\n  - volume surprise window: 20D (z-score)\n  - illiquidity veto window: 60D rank threshold\n- After implementation, test a single “regime-switching composite factor” with explicit gating (still simple):\n  - Regime score = 1{SBC condition} - 1{LSR condition}\n  - Output = if SBC active -> + momentum signal; elif LSR active -> contrarian; else 0\n  - Avoid blending both simultaneously unless you add a clear priority rule.\n\n3) Parameter sensitivity grid (minimal but targeted):\n- LSR ranks: TS_RANK_{60} threshold 54/55/56 (i.e., ~90%/92%/93% percentile)\n- LSR z-score window: 40D / 60D / 90D\n- Trend veto window: 10D / 20D / 30D and threshold 0.6 / 0.7 / 0.8\n- SBC breakout window: 40D / 55D / 80D; squeeze ratio threshold: 0.6 / 0.7 / 0.8\n\n4) Complexity control:\n- No explicit complexity warnings were provided; keep it that way. Prefer small modifications (one new veto or one alternative scaling) rather than stacking many conditions. The biggest win is implementing SBC and a clean switch rule rather than making LSR more ornate."
      }
    },
    "2b15d33c45ee628a": {
      "factor_id": "2b15d33c45ee628a",
      "factor_name": "Participatory_Donchian_Breakout_Cont_55_20_20",
      "factor_expression": "RANK(($close-TS_MIN($low,55))/(TS_MAX($high,55)-TS_MIN($low,55)+1e-8))*RANK(-TS_STD($return,20))*RANK(TS_ZSCORE(LOG($volume+1),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close-TS_MIN($low,55))/(TS_MAX($high,55)-TS_MIN($low,55)+1e-8))*RANK(-TS_STD(TS_PCTCHANGE($close,1),20))*RANK(TS_ZSCORE(LOG($volume+1),20))\" # Your output factor expression will be filled in here\n    name = \"Participatory_Donchian_Breakout_Cont_55_20_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Participatory breakout continuation signal: favors instruments near the top of a 55D Donchian channel, with 20D volatility compression (lower realized vol) and 20D volume confirmation (higher abnormal volume). Hyperparameters: Donchian=55D, vol=20D, volume zscore=20D.",
      "factor_formulation": "F = \\operatorname{RANK}\\left(\\frac{C-\\min(L,55)}{\\max(H,55)-\\min(L,55)+\\epsilon}\\right)\\cdot \\operatorname{RANK}(-\\sigma(R,20))\\cdot \\operatorname{RANK}(Z(\\log(V+1),20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "5e176cee36e7",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A soft-regime-gated hybrid alpha that classifies each instrument-day into (i) participatory breakout (55D Donchian strength with 20D volatility compression and 20D volume confirmation), (ii) liquidity-vacuum shock (1D |return|/intraday-range shock with low 20D dollar-volume and high Amihud-like impact), or (iii) downtrend forced-flow stress (60D loser with elevated 5D volume-instability and gap dominance), will improve next-horizon return predictability by going with continuation only in regime (i) and fading moves in regimes (ii)/(iii), with risk scaled down under extreme volatility/impact to reduce drawdowns.\n                Concise Observation: The available daily OHLCV data supports construction of Donchian breakouts (55D), trend filters (ROC60), volatility compression (20D realized vol), participation measures (20D dollar-volume z-score), impact proxies (Amihud-like using |ret|/dollar-volume), and short-horizon stress metrics (5D volume MAD and gap), enabling a single fused factor via cross-sectional ranking and soft gating rather than brittle hard thresholds.\n                Concise Justification: Separating information-driven continuation from liquidity/flow-driven dislocations reduces false breakouts and whipsaws: continuation signals are concentrated where volume confirms and volatility is orderly, while contrarian signals are activated where thin liquidity and high impact imply transient price pressure; probability-weighted (soft) regime mixing reduces misclassification risk and stabilizes exposure, addressing drawdown issues associated with always-on breakout or always-on mean reversion.\n                Concise Knowledge: If a breakout is information-driven and broadly participated (price breaks highs while volatility is compressed and volume is elevated), continuation is more likely; when large price moves occur with low participation and high price-impact proxies, reversal is more likely; when a medium-term downtrend coincides with short-term volume/gap instability, forced-flow dislocations tend to mean-revert over the next few days, so a regime-weighted blend of momentum and contrarian signals should dominate either alone in noisy markets.\n                concise Specification: Use only daily_pv.h5 OHLCV; define fixed hyperparameters: Donchian lookback=55D, trend ROC lookback=60D, vol compression window=20D, volume confirmation window=20D, liquidity-vacuum shock windows: 1D return and 1D log(high/low) with 20D z-scores, impact proxy window=20D using |ret_1|/(close*volume), forced-flow windows: 5D volume-instability (MAD or std of log(volume)) and 1D gap=|open/prev_close-1|; compute three sub-signals (breakout continuation, liquidity-vacuum contrarian, loser-stress contrarian) as cross-sectional ranks each day, compute regime weights via normalized (e.g., softmax) scores from the corresponding regime conditions, then output a single fused factor = w_break*sig_break + w_liqvac*sig_liqvac + w_stress*sig_stress with optional multiplicative risk-scaling by inverse 20D realized volatility and capped by extreme 20D impact rank.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:33:53.206987"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0849533823181888,
        "ICIR": 0.0665215060528526,
        "1day.excess_return_without_cost.std": 0.0040689628186594,
        "1day.excess_return_with_cost.annualized_return": 0.0362344936803595,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003508615726574,
        "1day.excess_return_without_cost.annualized_return": 0.0835050542924812,
        "1day.excess_return_with_cost.std": 0.0040692112796904,
        "Rank IC": 0.0264516616666101,
        "IC": 0.0090421758861881,
        "1day.excess_return_without_cost.max_drawdown": -0.0709243750232105,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.330272345561644,
        "1day.pa": 0.0,
        "l2.valid": 0.9965033503808146,
        "Rank ICIR": 0.1981180353072424,
        "l2.train": 0.9936467987506328,
        "1day.excess_return_with_cost.information_ratio": 0.5771962208465864,
        "1day.excess_return_with_cost.mean": 0.0001522457717662
      },
      "feedback": {
        "observations": "The combined factor set materially improves all reported metrics versus the previous SOTA: annualized excess return increases (0.0835 vs 0.0520), information ratio improves strongly (1.33 vs 0.97), IC increases (0.00904 vs 0.00580), and max drawdown is slightly better/shallower (−0.0709 vs −0.0726; closer to 0 is better). This is a consistent improvement rather than a trade-off where one metric improves at the expense of others.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis. The regime-framed idea—trend-continuation in a breakout/participation regime and contrarian positioning in liquidity-vacuum and forced-flow stress regimes—appears to add predictable structure to next-horizon returns, as evidenced by higher IC and a large IR uplift. That said, this experiment seems to be an additive combination of three regime proxies rather than a true “soft-regime-gated hybrid” (i.e., explicit gating/mixture weights that turn continuation on only in regime (i) and fade only in (ii)/(iii) with volatility/impact-based risk scaling). The fact that performance improves without explicit gating suggests (a) each component has standalone signal, and (b) implementing the missing gating/risk-scaling logic is a high-priority next step that may further reduce drawdowns and improve stability (especially once transaction costs are included).",
        "decision": true,
        "reason": "1) Why gating is likely to help: The current improvement indicates the three signals contain predictive information, but without an explicit gate they can conflict on the same instrument-day (e.g., breakout strength coinciding with a liquidity shock). A soft gate can resolve these conflicts by allocating weight to the most probable regime instead of multiplying/adding partially contradictory ranks.\n\n2) What to change next (still within the same framework):\n- Soft gate construction (explicit hyperparameters):\n  - Regime (i) score si: DonchianStrength_55 * VolCompression_20 * VolumeZ_20 (keep current core), then map to probability via cross-sectional zscore + sigmoid.\n  - Regime (ii) score sii: Shock(|R1|/log(H/L))_1 * IlliquidityLowDollarVol_Z_20 * ImpactMean_20.\n  - Regime (iii) score siii: Loser_60 * VolInstability(MADlogV)_5 * GapAbs_1.\n  - Gate: wi = softmax([αi*si, αii*sii, αiii*siii]) with α parameters initially = 1 (avoid over-parameterization), or use normalized positive-part weights: wi = relu(zscore(si)) / sum(relu(zscore(s•))).\n  - Final alpha: F = +wi * ContinuationSignal_i  − wii * ContrarianSignal_ii − wiii * ContrarianSignal_iii.\n\n- Risk scaling (explicit hyperparameters):\n  - Volatility scaler: scale = 1 / (1 + k * zscore(RealizedVol_n)), start with n=20 and k in {0.5, 1.0, 2.0}.\n  - Impact scaler: scale *= 1 / (1 + k2 * zscore(ImpactMean_m)), start with m=20 and k2 in {0.5, 1.0, 2.0}.\n  - Apply scale multiplicatively to F; optionally clip scale to [0.25, 1.0] to avoid fully shutting off.\n\n- Parameter sensitivity to explore (keep factors “static” per configuration):\n  - Donchian window: 40/55/70 (3 separate factors).\n  - Vol compression window: 10/20/30.\n  - Volume confirmation zscore window: 10/20/40.\n  - Liquidity-vacuum impact mean window: 10/20/60.\n  - Loser trend horizon: 40/60/120.\n  - Volume instability (MAD) window: 3/5/10.\n  - Gap dominance: 1D vs 2D (e.g., max(|open/prev_close−1|) over last 2 days).\n\n3) Practical concerns to address next iteration:\n- Costs/turnover: both contrarian components use SIGN(R1) and shock intensity, which can induce high turnover. Add one simple turnover damper (choose one):\n  - 3–5D EMA smoothing of the final alpha; or\n  - “banded trading” proxy in factor: only activate if shock percentile > p (e.g., 80th), making the signal sparse.\n- Robustness: winsorize extreme shock and impact inputs (e.g., clip at 1st/99th percentile cross-sectionally) before ranking to reduce tail sensitivity.\n\n4) Complexity control: No explicit complexity warnings were provided, and the expressions are reasonably interpretable with a limited base feature set (close/high/low/open/volume/return). Keep it that way—avoid adding many additional raw inputs or many numeric constants (free parameters). Prefer a small grid of window sizes over introducing many tunable coefficients."
      }
    },
    "99341268fc789009": {
      "factor_id": "99341268fc789009",
      "factor_name": "Liquidity_Vacuum_Shock_Contrarian_1_20",
      "factor_expression": "-SIGN($return)*RANK(ABS($return)/(LOG($high/($low+1e-8))+1e-8))*RANK(-TS_ZSCORE(LOG($close*$volume+1),20))*RANK(TS_MEAN(ABS($return)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1))*RANK(ABS(TS_PCTCHANGE($close,1))/(LOG($high/($low+1e-8))+1e-8))*RANK(-TS_ZSCORE(LOG($close*$volume+1),20))*RANK(TS_MEAN(ABS(TS_PCTCHANGE($close,1))/($close*$volume+1e-8),20))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Shock_Contrarian_1_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity-vacuum contrarian signal: fades large 1D moves that are outsized versus intraday range (|ret| / log(high/low)), occurring under low 20D dollar-volume (close*volume) and high 20D price-impact proxy (mean(|ret|/(close*volume))). Hyperparameters: shock=1D, liquidity zscore=20D, impact mean=20D.",
      "factor_formulation": "F = -\\operatorname{SIGN}(R_1)\\cdot \\operatorname{RANK}\\left(\\frac{|R_1|}{\\log(H/L)+\\epsilon}\\right)\\cdot \\operatorname{RANK}(-Z(\\log(CV+1),20))\\cdot \\operatorname{RANK}\\left(\\operatorname{MEAN}_{20}\\frac{|R_1|}{CV+\\epsilon}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "5e176cee36e7",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A soft-regime-gated hybrid alpha that classifies each instrument-day into (i) participatory breakout (55D Donchian strength with 20D volatility compression and 20D volume confirmation), (ii) liquidity-vacuum shock (1D |return|/intraday-range shock with low 20D dollar-volume and high Amihud-like impact), or (iii) downtrend forced-flow stress (60D loser with elevated 5D volume-instability and gap dominance), will improve next-horizon return predictability by going with continuation only in regime (i) and fading moves in regimes (ii)/(iii), with risk scaled down under extreme volatility/impact to reduce drawdowns.\n                Concise Observation: The available daily OHLCV data supports construction of Donchian breakouts (55D), trend filters (ROC60), volatility compression (20D realized vol), participation measures (20D dollar-volume z-score), impact proxies (Amihud-like using |ret|/dollar-volume), and short-horizon stress metrics (5D volume MAD and gap), enabling a single fused factor via cross-sectional ranking and soft gating rather than brittle hard thresholds.\n                Concise Justification: Separating information-driven continuation from liquidity/flow-driven dislocations reduces false breakouts and whipsaws: continuation signals are concentrated where volume confirms and volatility is orderly, while contrarian signals are activated where thin liquidity and high impact imply transient price pressure; probability-weighted (soft) regime mixing reduces misclassification risk and stabilizes exposure, addressing drawdown issues associated with always-on breakout or always-on mean reversion.\n                Concise Knowledge: If a breakout is information-driven and broadly participated (price breaks highs while volatility is compressed and volume is elevated), continuation is more likely; when large price moves occur with low participation and high price-impact proxies, reversal is more likely; when a medium-term downtrend coincides with short-term volume/gap instability, forced-flow dislocations tend to mean-revert over the next few days, so a regime-weighted blend of momentum and contrarian signals should dominate either alone in noisy markets.\n                concise Specification: Use only daily_pv.h5 OHLCV; define fixed hyperparameters: Donchian lookback=55D, trend ROC lookback=60D, vol compression window=20D, volume confirmation window=20D, liquidity-vacuum shock windows: 1D return and 1D log(high/low) with 20D z-scores, impact proxy window=20D using |ret_1|/(close*volume), forced-flow windows: 5D volume-instability (MAD or std of log(volume)) and 1D gap=|open/prev_close-1|; compute three sub-signals (breakout continuation, liquidity-vacuum contrarian, loser-stress contrarian) as cross-sectional ranks each day, compute regime weights via normalized (e.g., softmax) scores from the corresponding regime conditions, then output a single fused factor = w_break*sig_break + w_liqvac*sig_liqvac + w_stress*sig_stress with optional multiplicative risk-scaling by inverse 20D realized volatility and capped by extreme 20D impact rank.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:33:53.206987"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0849533823181888,
        "ICIR": 0.0665215060528526,
        "1day.excess_return_without_cost.std": 0.0040689628186594,
        "1day.excess_return_with_cost.annualized_return": 0.0362344936803595,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003508615726574,
        "1day.excess_return_without_cost.annualized_return": 0.0835050542924812,
        "1day.excess_return_with_cost.std": 0.0040692112796904,
        "Rank IC": 0.0264516616666101,
        "IC": 0.0090421758861881,
        "1day.excess_return_without_cost.max_drawdown": -0.0709243750232105,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.330272345561644,
        "1day.pa": 0.0,
        "l2.valid": 0.9965033503808146,
        "Rank ICIR": 0.1981180353072424,
        "l2.train": 0.9936467987506328,
        "1day.excess_return_with_cost.information_ratio": 0.5771962208465864,
        "1day.excess_return_with_cost.mean": 0.0001522457717662
      },
      "feedback": {
        "observations": "The combined factor set materially improves all reported metrics versus the previous SOTA: annualized excess return increases (0.0835 vs 0.0520), information ratio improves strongly (1.33 vs 0.97), IC increases (0.00904 vs 0.00580), and max drawdown is slightly better/shallower (−0.0709 vs −0.0726; closer to 0 is better). This is a consistent improvement rather than a trade-off where one metric improves at the expense of others.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis. The regime-framed idea—trend-continuation in a breakout/participation regime and contrarian positioning in liquidity-vacuum and forced-flow stress regimes—appears to add predictable structure to next-horizon returns, as evidenced by higher IC and a large IR uplift. That said, this experiment seems to be an additive combination of three regime proxies rather than a true “soft-regime-gated hybrid” (i.e., explicit gating/mixture weights that turn continuation on only in regime (i) and fade only in (ii)/(iii) with volatility/impact-based risk scaling). The fact that performance improves without explicit gating suggests (a) each component has standalone signal, and (b) implementing the missing gating/risk-scaling logic is a high-priority next step that may further reduce drawdowns and improve stability (especially once transaction costs are included).",
        "decision": true,
        "reason": "1) Why gating is likely to help: The current improvement indicates the three signals contain predictive information, but without an explicit gate they can conflict on the same instrument-day (e.g., breakout strength coinciding with a liquidity shock). A soft gate can resolve these conflicts by allocating weight to the most probable regime instead of multiplying/adding partially contradictory ranks.\n\n2) What to change next (still within the same framework):\n- Soft gate construction (explicit hyperparameters):\n  - Regime (i) score si: DonchianStrength_55 * VolCompression_20 * VolumeZ_20 (keep current core), then map to probability via cross-sectional zscore + sigmoid.\n  - Regime (ii) score sii: Shock(|R1|/log(H/L))_1 * IlliquidityLowDollarVol_Z_20 * ImpactMean_20.\n  - Regime (iii) score siii: Loser_60 * VolInstability(MADlogV)_5 * GapAbs_1.\n  - Gate: wi = softmax([αi*si, αii*sii, αiii*siii]) with α parameters initially = 1 (avoid over-parameterization), or use normalized positive-part weights: wi = relu(zscore(si)) / sum(relu(zscore(s•))).\n  - Final alpha: F = +wi * ContinuationSignal_i  − wii * ContrarianSignal_ii − wiii * ContrarianSignal_iii.\n\n- Risk scaling (explicit hyperparameters):\n  - Volatility scaler: scale = 1 / (1 + k * zscore(RealizedVol_n)), start with n=20 and k in {0.5, 1.0, 2.0}.\n  - Impact scaler: scale *= 1 / (1 + k2 * zscore(ImpactMean_m)), start with m=20 and k2 in {0.5, 1.0, 2.0}.\n  - Apply scale multiplicatively to F; optionally clip scale to [0.25, 1.0] to avoid fully shutting off.\n\n- Parameter sensitivity to explore (keep factors “static” per configuration):\n  - Donchian window: 40/55/70 (3 separate factors).\n  - Vol compression window: 10/20/30.\n  - Volume confirmation zscore window: 10/20/40.\n  - Liquidity-vacuum impact mean window: 10/20/60.\n  - Loser trend horizon: 40/60/120.\n  - Volume instability (MAD) window: 3/5/10.\n  - Gap dominance: 1D vs 2D (e.g., max(|open/prev_close−1|) over last 2 days).\n\n3) Practical concerns to address next iteration:\n- Costs/turnover: both contrarian components use SIGN(R1) and shock intensity, which can induce high turnover. Add one simple turnover damper (choose one):\n  - 3–5D EMA smoothing of the final alpha; or\n  - “banded trading” proxy in factor: only activate if shock percentile > p (e.g., 80th), making the signal sparse.\n- Robustness: winsorize extreme shock and impact inputs (e.g., clip at 1st/99th percentile cross-sectionally) before ranking to reduce tail sensitivity.\n\n4) Complexity control: No explicit complexity warnings were provided, and the expressions are reasonably interpretable with a limited base feature set (close/high/low/open/volume/return). Keep it that way—avoid adding many additional raw inputs or many numeric constants (free parameters). Prefer a small grid of window sizes over introducing many tunable coefficients."
      }
    },
    "21621f2ed669e9da": {
      "factor_id": "21621f2ed669e9da",
      "factor_name": "Loser_ForcedFlow_GapVol_Contrarian_60_5_1",
      "factor_expression": "-SIGN($return)*RANK(-TS_PCTCHANGE($close,60))*RANK(TS_MAD(LOG($volume+1),5))*RANK(ABS($open/(DELAY($close,1)+1e-8)-1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-SIGN(TS_PCTCHANGE($close,1))*RANK(-DELTA($close,60))*RANK(TS_MAD(LOG($volume+1),5))*RANK(ABS($open/(DELAY($close,1)+1e-12)-1))\" # Your output factor expression will be filled in here\n    name = \"Loser_ForcedFlow_GapVol_Contrarian_60_5_1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Downtrend forced-flow stress contrarian: activates in 60D losers with elevated 5D volume instability (MAD of log(volume)) and large 1D opening gap (|open/prev_close-1|), then fades the current-day move. Hyperparameters: loser trend=60D, volume instability=5D, gap=1D.",
      "factor_formulation": "F = -\\operatorname{SIGN}(R_1)\\cdot \\operatorname{RANK}(-\\Delta_{60}C)\\cdot \\operatorname{RANK}(\\operatorname{MAD}_5(\\log(V+1)))\\cdot \\operatorname{RANK}\\left(\\left|\\frac{O}{C_{-1}}-1\\right|\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "5e176cee36e7",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A soft-regime-gated hybrid alpha that classifies each instrument-day into (i) participatory breakout (55D Donchian strength with 20D volatility compression and 20D volume confirmation), (ii) liquidity-vacuum shock (1D |return|/intraday-range shock with low 20D dollar-volume and high Amihud-like impact), or (iii) downtrend forced-flow stress (60D loser with elevated 5D volume-instability and gap dominance), will improve next-horizon return predictability by going with continuation only in regime (i) and fading moves in regimes (ii)/(iii), with risk scaled down under extreme volatility/impact to reduce drawdowns.\n                Concise Observation: The available daily OHLCV data supports construction of Donchian breakouts (55D), trend filters (ROC60), volatility compression (20D realized vol), participation measures (20D dollar-volume z-score), impact proxies (Amihud-like using |ret|/dollar-volume), and short-horizon stress metrics (5D volume MAD and gap), enabling a single fused factor via cross-sectional ranking and soft gating rather than brittle hard thresholds.\n                Concise Justification: Separating information-driven continuation from liquidity/flow-driven dislocations reduces false breakouts and whipsaws: continuation signals are concentrated where volume confirms and volatility is orderly, while contrarian signals are activated where thin liquidity and high impact imply transient price pressure; probability-weighted (soft) regime mixing reduces misclassification risk and stabilizes exposure, addressing drawdown issues associated with always-on breakout or always-on mean reversion.\n                Concise Knowledge: If a breakout is information-driven and broadly participated (price breaks highs while volatility is compressed and volume is elevated), continuation is more likely; when large price moves occur with low participation and high price-impact proxies, reversal is more likely; when a medium-term downtrend coincides with short-term volume/gap instability, forced-flow dislocations tend to mean-revert over the next few days, so a regime-weighted blend of momentum and contrarian signals should dominate either alone in noisy markets.\n                concise Specification: Use only daily_pv.h5 OHLCV; define fixed hyperparameters: Donchian lookback=55D, trend ROC lookback=60D, vol compression window=20D, volume confirmation window=20D, liquidity-vacuum shock windows: 1D return and 1D log(high/low) with 20D z-scores, impact proxy window=20D using |ret_1|/(close*volume), forced-flow windows: 5D volume-instability (MAD or std of log(volume)) and 1D gap=|open/prev_close-1|; compute three sub-signals (breakout continuation, liquidity-vacuum contrarian, loser-stress contrarian) as cross-sectional ranks each day, compute regime weights via normalized (e.g., softmax) scores from the corresponding regime conditions, then output a single fused factor = w_break*sig_break + w_liqvac*sig_liqvac + w_stress*sig_stress with optional multiplicative risk-scaling by inverse 20D realized volatility and capped by extreme 20D impact rank.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:33:53.206987"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0849533823181888,
        "ICIR": 0.0665215060528526,
        "1day.excess_return_without_cost.std": 0.0040689628186594,
        "1day.excess_return_with_cost.annualized_return": 0.0362344936803595,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003508615726574,
        "1day.excess_return_without_cost.annualized_return": 0.0835050542924812,
        "1day.excess_return_with_cost.std": 0.0040692112796904,
        "Rank IC": 0.0264516616666101,
        "IC": 0.0090421758861881,
        "1day.excess_return_without_cost.max_drawdown": -0.0709243750232105,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.330272345561644,
        "1day.pa": 0.0,
        "l2.valid": 0.9965033503808146,
        "Rank ICIR": 0.1981180353072424,
        "l2.train": 0.9936467987506328,
        "1day.excess_return_with_cost.information_ratio": 0.5771962208465864,
        "1day.excess_return_with_cost.mean": 0.0001522457717662
      },
      "feedback": {
        "observations": "The combined factor set materially improves all reported metrics versus the previous SOTA: annualized excess return increases (0.0835 vs 0.0520), information ratio improves strongly (1.33 vs 0.97), IC increases (0.00904 vs 0.00580), and max drawdown is slightly better/shallower (−0.0709 vs −0.0726; closer to 0 is better). This is a consistent improvement rather than a trade-off where one metric improves at the expense of others.",
        "hypothesis_evaluation": "Overall, the results support the hypothesis. The regime-framed idea—trend-continuation in a breakout/participation regime and contrarian positioning in liquidity-vacuum and forced-flow stress regimes—appears to add predictable structure to next-horizon returns, as evidenced by higher IC and a large IR uplift. That said, this experiment seems to be an additive combination of three regime proxies rather than a true “soft-regime-gated hybrid” (i.e., explicit gating/mixture weights that turn continuation on only in regime (i) and fade only in (ii)/(iii) with volatility/impact-based risk scaling). The fact that performance improves without explicit gating suggests (a) each component has standalone signal, and (b) implementing the missing gating/risk-scaling logic is a high-priority next step that may further reduce drawdowns and improve stability (especially once transaction costs are included).",
        "decision": true,
        "reason": "1) Why gating is likely to help: The current improvement indicates the three signals contain predictive information, but without an explicit gate they can conflict on the same instrument-day (e.g., breakout strength coinciding with a liquidity shock). A soft gate can resolve these conflicts by allocating weight to the most probable regime instead of multiplying/adding partially contradictory ranks.\n\n2) What to change next (still within the same framework):\n- Soft gate construction (explicit hyperparameters):\n  - Regime (i) score si: DonchianStrength_55 * VolCompression_20 * VolumeZ_20 (keep current core), then map to probability via cross-sectional zscore + sigmoid.\n  - Regime (ii) score sii: Shock(|R1|/log(H/L))_1 * IlliquidityLowDollarVol_Z_20 * ImpactMean_20.\n  - Regime (iii) score siii: Loser_60 * VolInstability(MADlogV)_5 * GapAbs_1.\n  - Gate: wi = softmax([αi*si, αii*sii, αiii*siii]) with α parameters initially = 1 (avoid over-parameterization), or use normalized positive-part weights: wi = relu(zscore(si)) / sum(relu(zscore(s•))).\n  - Final alpha: F = +wi * ContinuationSignal_i  − wii * ContrarianSignal_ii − wiii * ContrarianSignal_iii.\n\n- Risk scaling (explicit hyperparameters):\n  - Volatility scaler: scale = 1 / (1 + k * zscore(RealizedVol_n)), start with n=20 and k in {0.5, 1.0, 2.0}.\n  - Impact scaler: scale *= 1 / (1 + k2 * zscore(ImpactMean_m)), start with m=20 and k2 in {0.5, 1.0, 2.0}.\n  - Apply scale multiplicatively to F; optionally clip scale to [0.25, 1.0] to avoid fully shutting off.\n\n- Parameter sensitivity to explore (keep factors “static” per configuration):\n  - Donchian window: 40/55/70 (3 separate factors).\n  - Vol compression window: 10/20/30.\n  - Volume confirmation zscore window: 10/20/40.\n  - Liquidity-vacuum impact mean window: 10/20/60.\n  - Loser trend horizon: 40/60/120.\n  - Volume instability (MAD) window: 3/5/10.\n  - Gap dominance: 1D vs 2D (e.g., max(|open/prev_close−1|) over last 2 days).\n\n3) Practical concerns to address next iteration:\n- Costs/turnover: both contrarian components use SIGN(R1) and shock intensity, which can induce high turnover. Add one simple turnover damper (choose one):\n  - 3–5D EMA smoothing of the final alpha; or\n  - “banded trading” proxy in factor: only activate if shock percentile > p (e.g., 80th), making the signal sparse.\n- Robustness: winsorize extreme shock and impact inputs (e.g., clip at 1st/99th percentile cross-sectionally) before ranking to reduce tail sensitivity.\n\n4) Complexity control: No explicit complexity warnings were provided, and the expressions are reasonably interpretable with a limited base feature set (close/high/low/open/volume/return). Keep it that way—avoid adding many additional raw inputs or many numeric constants (free parameters). Prefer a small grid of window sizes over introducing many tunable coefficients."
      }
    },
    "35511ee346c435a7": {
      "factor_id": "35511ee346c435a7",
      "factor_name": "BreakoutStrength_CLV_Pos_20D",
      "factor_expression": "MAX($close-DELAY(TS_MAX($high,20),1),0)/(DELAY(TS_MAX($high,20),1)+1e-8)*MAX((2*$close-$high-$low)/($high-$low+1e-8),0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MAX($close-DELAY(TS_MAX($high,20),1),0)/(DELAY(TS_MAX($high,20),1)+1e-8)*MAX((2*$close-$high-$low)/($high-$low+1e-8),0)\" # Your output factor expression will be filled in here\n    name = \"BreakoutStrength_CLV_Pos_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "20-day channel breakout strength gated by positive close-location-in-range (CLV). Measures how far the close exceeds the prior 20D high (if any), and rewards closes near the day’s high to reduce false breakouts.",
      "factor_formulation": "F=\\frac{\\max\\left(C-\\text{HHV}_{20}(H)_{t-1},0\\right)}{\\text{HHV}_{20}(H)_{t-1}+\\epsilon}\\cdot\\max\\left(\\frac{2C-H-L}{H-L+\\epsilon},0\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "dc5110b2a31c",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Single-stock medium-horizon (10–60 trading days) continuation is strongest when an extreme short-term volatility compression (“coil”) resolves into a decisive 20D channel breakout that is preceded by a 20–60D liquidity re-rating (rising dollar-volume and improving Amihud illiquidity) and confirmed by stable (non-spiky) volume dynamics plus consistent 10D overnight drift; therefore a gated composite factor combining (i) 10D/60D true-range compression vs its 252D history, (ii) 20D breakout strength with close-location-in-range, (iii) 20D vs 60D dollar-volume expansion and 20D illiquidity improvement, (iv) low 10D dispersion of volume changes, and (v) 10D overnight-trend quality should positively predict next several-days returns cross-sectionally.\n                Concise Observation: Available data (open/high/low/close/volume) supports constructing true-range based compression, channel-breakout signals, dollar-volume and Amihud illiquidity proxies, volume-change dispersion filters, and overnight (close-to-next-open) trend quality metrics on fixed windows (e.g., 10/20/60/252D) suitable for cross-sectional ranking in Qlib.\n                Concise Justification: This fusion reduces common failure modes of standalone breakout signals (false breakouts from news spikes or illiquid prints) by requiring a cause-before-effect sequence—liquidity re-rating and absorption during compression—then validating release via decisive breakout geometry and stable overnight drift, so the composite score targets breakouts supported by broad, informed positioning rather than transient intraday noise.\n                Concise Knowledge: If volatility compression reflects supply absorption, then breakouts tend to persist only when participation/tradability improves beforehand (higher dollar-volume, lower price-impact/Amihud) and volume is orderly (low dispersion rather than event spikes); when the breakout close is near the day’s high and overnight returns show a stable positive drift (high slope/fit over 10D), the move is more likely information-driven than intraday mean-reversion, increasing short-horizon continuation odds.\n                concise Specification: Define a single long-only factor score per (instrument, day) using fixed hyperparameters: TR_t=max(high_t-low_t, |high_t-close_{t-1}|, |low_t-close_{t-1}|); CompressionGate=I[ (MA_10(TR)/MA_60(TR)) in bottom 10% of its rolling 252D history ]; OrderlyVolGate=I[ MAD_10(Δlog(volume)) in bottom 50% cross-section or bottom 50% of its own 252D history ]; LiquidityGate=I[ MA_20(close*volume)/MA_60(close*volume) > 1.1 AND (MA_20(|close_ret|/(close*volume)) < MA_60(|close_ret|/(close*volume))) AND MA_20(TR) <= MA_60(TR) ]; BreakoutStrength=((close_t - HHV_20(high))/HHV_20(high)) clipped at [0, +∞) with Trigger I[close_t>HHV_20(high)]; CLV=(2*close_t-high_t-low_t)/(high_t-low_t) (set 0 when high=low); OvernightRet_t=log(open_t/close_{t-1}); OvernightQuality=Slope_10(OvernightRet) * R2_10(OvernightRet~time); FinalFactor = CompressionGate * OrderlyVolGate * LiquidityGate * BreakoutStrength * max(CLV,0) * max(OvernightQuality,0), then cross-sectionally rank on each day for modeling; expected relationship: higher FinalFactor -> higher forward returns over the next 5–20 trading days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:53:00.651014"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.111897314485086,
        "ICIR": 0.0322796282269955,
        "1day.excess_return_without_cost.std": 0.004557493581731,
        "1day.excess_return_with_cost.annualized_return": 0.034579718842182,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003447041996748,
        "1day.excess_return_without_cost.annualized_return": 0.0820395995226208,
        "1day.excess_return_with_cost.std": 0.0045574398497798,
        "Rank IC": 0.0200427484776002,
        "IC": 0.004882593170981,
        "1day.excess_return_without_cost.max_drawdown": -0.1026494075710868,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1668337636822992,
        "1day.pa": 0.0,
        "l2.valid": 0.996357234644066,
        "Rank ICIR": 0.1301171855121951,
        "l2.train": 0.9915770775676817,
        "1day.excess_return_with_cost.information_ratio": 0.4918266230978798,
        "1day.excess_return_with_cost.mean": 0.0001452929363116
      },
      "feedback": {
        "observations": "The current run improves return efficiency versus the prior SOTA but deteriorates in drawdown and cross-sectional correlation (IC). Specifically: (1) annualized excess return increases (0.0820 vs 0.0520) and information ratio increases (1.1668 vs 0.9726), indicating the implemented signals contain exploitable predictive content and/or better portfolio-level behavior in this backtest configuration; (2) max drawdown is worse (more negative: -0.1026 vs -0.0726), implying the signal is taking on more tail risk / regime sensitivity; (3) IC declines (0.00488 vs 0.00580), suggesting weaker pure cross-sectional ranking quality even though the strategy-level returns improved—this often happens when the signal becomes more “timing/regime” dependent or when a few episodic winners dominate PnL.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not fully validate the stated ‘coil → breakout + liquidity rerating + stable volume + overnight drift’ mechanism because key hypothesis components were not yet implemented in this iteration.\n\nSupport:\n- BreakoutStrength_CLV_Pos_20D + LiquidityRerating_DV_20v60_x_AmihudImprove + OvernightDrift_Sharpe_10D together generate materially higher annualized return and IR than SOTA, consistent with the idea that breakout confirmation plus liquidity improvement plus steady overnight accumulation can help medium-horizon continuation.\n\nRefutation / gaps:\n- The hypothesis emphasizes a volatility-compression (“coil”) condition and “stable (non-spiky) volume dynamics” as gates/confirmations. Those two components are absent here, so the observed higher drawdown is consistent with missing the intended risk-control gates (i.e., you may be buying breakouts that are not true coil-resolutions and are accompanied by unstable volume).\n- IC deterioration suggests the current combination may not be improving cross-sectional ranking quality; it may instead be introducing exposure to common risk factors (size/liquidity/volatility regimes). This is consistent with a liquidity rerating term that can inadvertently load on liquidity/size beta unless explicitly neutralized.\n\nNet: The result leans toward supporting the framework’s direction (breakout + liquidity + overnight drift), but it also indicates the framework’s promised robustness likely requires the missing coil/volume-stability gating to reduce drawdowns and improve generalization.",
        "decision": true,
        "reason": "Why annualized/IR improved but IC and drawdown worsened:\n- Liquidity re-rating (DV expansion × Amihud improvement) can create strong episodic winners (boosting annualized return/IR) while also increasing crash sensitivity in liquidity shocks (worsening max drawdown).\n- Breakout strength without an explicit ‘coil’ precondition tends to chase high-volatility continuation *and* false breakouts; CLV helps, but it is a same-day confirmation and may not eliminate regime-dependent breakouts.\n- Overnight drift Sharpe can be structurally related to sentiment/positioning effects that work in some regimes but gap violently in others, contributing to drawdown.\n\nConcrete next iteration recommendations (still same theoretical framework; focus on gates + simplification + parameter sweeps):\n1) Implement the missing coil term exactly as a standalone factor and as a hard gate:\n   - Coil/TR compression: compute True Range TR = max(H-L, |H-prevC|, |L-prevC|).\n   - Hyperparameters to try (separate factors): lookback {10, 20, 30, 60}, long-history window {252}, and use percentile rank of current TR/MA(TR,lookback) within 252D.\n   - Gate example: only allow breakout signal when compression_percentile <= {10%, 20%}.\n2) Add the volume-stability confirmation as another gate rather than a linear add:\n   - Volume change series: dv_t = log(1 + V_t) or log(C*V) change.\n   - Dispersion metric: STD_10(ΔlogV) or MAD_10(ΔlogV).\n   - Gate: dispersion in bottom {30%, 50%} cross-sectionally to avoid spiky volume.\n3) Rework LiquidityRerating into a more robust and less regime-leaky form:\n   - Replace multiplicative form with rank-based combination to reduce outlier dominance:\n     rank(log(MA20(DV)/MA60(DV))) + rank(MA60(Amihud) - MA20(Amihud)).\n   - Hyperparameters to sweep as separate factors: DV windows (20/60 vs 10/40 vs 30/90), Amihud windows (20/60 vs 10/30 vs 30/120).\n4) Improve breakout definition robustness (same concept, fewer false breakouts):\n   - Try breakout over prior 20D *close* highs (HHV20(C)) vs highs (HHV20(H)).\n   - Add ATR scaling: (C - HHV)/ATR_14 to normalize across vol regimes.\n   - Keep CLV gate but test thresholds: max(CLV, 0) vs indicator(CLV>0.3) to reduce borderline closes.\n5) Address IC drop and drawdown via neutralization and monotonic transforms:\n   - Use cross-sectional z-score or rank for each component before combining.\n   - Consider neutralizing composite vs ln(market cap proxy) or vs liquidity proxy (e.g., MA60(C*V)) to reduce unintended liquidity/size beta.\n6) Composite structure suggestion (gated, not over-engineered):\n   - Score = rank(BreakoutStrength_20D) + rank(LiquidityRerating_20v60) + rank(OvernightDriftSharpe_10D)\n   - Active only if (CoilCompression_10v60_in_252 <= q) AND (VolumeDispersion_10 <= q2).\n   - This matches the hypothesis wording (“strongest when… preceded by… confirmed by…”) more faithfully than a purely additive factor.\n\nComplexity control note:\n- No explicit complexity warnings were provided, but the next step should still prioritize a small number of interpretable gates and rank/zscore transforms over adding many new primitives. The biggest expected gain here is structural (gating + robust normalization), not longer expressions."
      }
    },
    "ddaf9910d8d14cbb": {
      "factor_id": "ddaf9910d8d14cbb",
      "factor_name": "LiquidityRerating_DV_20v60_x_AmihudImprove",
      "factor_expression": "LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8)+1e-8)*(TS_MEAN(ABS($return)/($close*$volume+1e-8),60)-TS_MEAN(ABS($return)/($close*$volume+1e-8),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"LOG(TS_MEAN($close*$volume,20)/(TS_MEAN($close*$volume,60)+1e-8)+1e-8)*(TS_MEAN(ABS(LOG($close/(DELAY($close,1)+1e-8)))/($close*$volume+1e-8),60)-TS_MEAN(ABS(LOG($close/(DELAY($close,1)+1e-8)))/($close*$volume+1e-8),20))\" # Your output factor expression will be filled in here\n    name = \"LiquidityRerating_DV_20v60_x_AmihudImprove\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity re-rating proxy combining dollar-volume expansion (20D vs 60D) with improving Amihud illiquidity (60D average minus 20D average). Higher values indicate rising tradability with decreasing price impact.",
      "factor_formulation": "F=\\log\\left(\\frac{\\text{MA}_{20}(C\\cdot V)}{\\text{MA}_{60}(C\\cdot V)+\\epsilon}+\\epsilon\\right)\\cdot\\left[\\text{MA}_{60}\\left(\\frac{|r|}{C\\cdot V+\\epsilon}\\right)-\\text{MA}_{20}\\left(\\frac{|r|}{C\\cdot V+\\epsilon}\\right)\\right]",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "dc5110b2a31c",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Single-stock medium-horizon (10–60 trading days) continuation is strongest when an extreme short-term volatility compression (“coil”) resolves into a decisive 20D channel breakout that is preceded by a 20–60D liquidity re-rating (rising dollar-volume and improving Amihud illiquidity) and confirmed by stable (non-spiky) volume dynamics plus consistent 10D overnight drift; therefore a gated composite factor combining (i) 10D/60D true-range compression vs its 252D history, (ii) 20D breakout strength with close-location-in-range, (iii) 20D vs 60D dollar-volume expansion and 20D illiquidity improvement, (iv) low 10D dispersion of volume changes, and (v) 10D overnight-trend quality should positively predict next several-days returns cross-sectionally.\n                Concise Observation: Available data (open/high/low/close/volume) supports constructing true-range based compression, channel-breakout signals, dollar-volume and Amihud illiquidity proxies, volume-change dispersion filters, and overnight (close-to-next-open) trend quality metrics on fixed windows (e.g., 10/20/60/252D) suitable for cross-sectional ranking in Qlib.\n                Concise Justification: This fusion reduces common failure modes of standalone breakout signals (false breakouts from news spikes or illiquid prints) by requiring a cause-before-effect sequence—liquidity re-rating and absorption during compression—then validating release via decisive breakout geometry and stable overnight drift, so the composite score targets breakouts supported by broad, informed positioning rather than transient intraday noise.\n                Concise Knowledge: If volatility compression reflects supply absorption, then breakouts tend to persist only when participation/tradability improves beforehand (higher dollar-volume, lower price-impact/Amihud) and volume is orderly (low dispersion rather than event spikes); when the breakout close is near the day’s high and overnight returns show a stable positive drift (high slope/fit over 10D), the move is more likely information-driven than intraday mean-reversion, increasing short-horizon continuation odds.\n                concise Specification: Define a single long-only factor score per (instrument, day) using fixed hyperparameters: TR_t=max(high_t-low_t, |high_t-close_{t-1}|, |low_t-close_{t-1}|); CompressionGate=I[ (MA_10(TR)/MA_60(TR)) in bottom 10% of its rolling 252D history ]; OrderlyVolGate=I[ MAD_10(Δlog(volume)) in bottom 50% cross-section or bottom 50% of its own 252D history ]; LiquidityGate=I[ MA_20(close*volume)/MA_60(close*volume) > 1.1 AND (MA_20(|close_ret|/(close*volume)) < MA_60(|close_ret|/(close*volume))) AND MA_20(TR) <= MA_60(TR) ]; BreakoutStrength=((close_t - HHV_20(high))/HHV_20(high)) clipped at [0, +∞) with Trigger I[close_t>HHV_20(high)]; CLV=(2*close_t-high_t-low_t)/(high_t-low_t) (set 0 when high=low); OvernightRet_t=log(open_t/close_{t-1}); OvernightQuality=Slope_10(OvernightRet) * R2_10(OvernightRet~time); FinalFactor = CompressionGate * OrderlyVolGate * LiquidityGate * BreakoutStrength * max(CLV,0) * max(OvernightQuality,0), then cross-sectionally rank on each day for modeling; expected relationship: higher FinalFactor -> higher forward returns over the next 5–20 trading days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:53:00.651014"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.111897314485086,
        "ICIR": 0.0322796282269955,
        "1day.excess_return_without_cost.std": 0.004557493581731,
        "1day.excess_return_with_cost.annualized_return": 0.034579718842182,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003447041996748,
        "1day.excess_return_without_cost.annualized_return": 0.0820395995226208,
        "1day.excess_return_with_cost.std": 0.0045574398497798,
        "Rank IC": 0.0200427484776002,
        "IC": 0.004882593170981,
        "1day.excess_return_without_cost.max_drawdown": -0.1026494075710868,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1668337636822992,
        "1day.pa": 0.0,
        "l2.valid": 0.996357234644066,
        "Rank ICIR": 0.1301171855121951,
        "l2.train": 0.9915770775676817,
        "1day.excess_return_with_cost.information_ratio": 0.4918266230978798,
        "1day.excess_return_with_cost.mean": 0.0001452929363116
      },
      "feedback": {
        "observations": "The current run improves return efficiency versus the prior SOTA but deteriorates in drawdown and cross-sectional correlation (IC). Specifically: (1) annualized excess return increases (0.0820 vs 0.0520) and information ratio increases (1.1668 vs 0.9726), indicating the implemented signals contain exploitable predictive content and/or better portfolio-level behavior in this backtest configuration; (2) max drawdown is worse (more negative: -0.1026 vs -0.0726), implying the signal is taking on more tail risk / regime sensitivity; (3) IC declines (0.00488 vs 0.00580), suggesting weaker pure cross-sectional ranking quality even though the strategy-level returns improved—this often happens when the signal becomes more “timing/regime” dependent or when a few episodic winners dominate PnL.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not fully validate the stated ‘coil → breakout + liquidity rerating + stable volume + overnight drift’ mechanism because key hypothesis components were not yet implemented in this iteration.\n\nSupport:\n- BreakoutStrength_CLV_Pos_20D + LiquidityRerating_DV_20v60_x_AmihudImprove + OvernightDrift_Sharpe_10D together generate materially higher annualized return and IR than SOTA, consistent with the idea that breakout confirmation plus liquidity improvement plus steady overnight accumulation can help medium-horizon continuation.\n\nRefutation / gaps:\n- The hypothesis emphasizes a volatility-compression (“coil”) condition and “stable (non-spiky) volume dynamics” as gates/confirmations. Those two components are absent here, so the observed higher drawdown is consistent with missing the intended risk-control gates (i.e., you may be buying breakouts that are not true coil-resolutions and are accompanied by unstable volume).\n- IC deterioration suggests the current combination may not be improving cross-sectional ranking quality; it may instead be introducing exposure to common risk factors (size/liquidity/volatility regimes). This is consistent with a liquidity rerating term that can inadvertently load on liquidity/size beta unless explicitly neutralized.\n\nNet: The result leans toward supporting the framework’s direction (breakout + liquidity + overnight drift), but it also indicates the framework’s promised robustness likely requires the missing coil/volume-stability gating to reduce drawdowns and improve generalization.",
        "decision": true,
        "reason": "Why annualized/IR improved but IC and drawdown worsened:\n- Liquidity re-rating (DV expansion × Amihud improvement) can create strong episodic winners (boosting annualized return/IR) while also increasing crash sensitivity in liquidity shocks (worsening max drawdown).\n- Breakout strength without an explicit ‘coil’ precondition tends to chase high-volatility continuation *and* false breakouts; CLV helps, but it is a same-day confirmation and may not eliminate regime-dependent breakouts.\n- Overnight drift Sharpe can be structurally related to sentiment/positioning effects that work in some regimes but gap violently in others, contributing to drawdown.\n\nConcrete next iteration recommendations (still same theoretical framework; focus on gates + simplification + parameter sweeps):\n1) Implement the missing coil term exactly as a standalone factor and as a hard gate:\n   - Coil/TR compression: compute True Range TR = max(H-L, |H-prevC|, |L-prevC|).\n   - Hyperparameters to try (separate factors): lookback {10, 20, 30, 60}, long-history window {252}, and use percentile rank of current TR/MA(TR,lookback) within 252D.\n   - Gate example: only allow breakout signal when compression_percentile <= {10%, 20%}.\n2) Add the volume-stability confirmation as another gate rather than a linear add:\n   - Volume change series: dv_t = log(1 + V_t) or log(C*V) change.\n   - Dispersion metric: STD_10(ΔlogV) or MAD_10(ΔlogV).\n   - Gate: dispersion in bottom {30%, 50%} cross-sectionally to avoid spiky volume.\n3) Rework LiquidityRerating into a more robust and less regime-leaky form:\n   - Replace multiplicative form with rank-based combination to reduce outlier dominance:\n     rank(log(MA20(DV)/MA60(DV))) + rank(MA60(Amihud) - MA20(Amihud)).\n   - Hyperparameters to sweep as separate factors: DV windows (20/60 vs 10/40 vs 30/90), Amihud windows (20/60 vs 10/30 vs 30/120).\n4) Improve breakout definition robustness (same concept, fewer false breakouts):\n   - Try breakout over prior 20D *close* highs (HHV20(C)) vs highs (HHV20(H)).\n   - Add ATR scaling: (C - HHV)/ATR_14 to normalize across vol regimes.\n   - Keep CLV gate but test thresholds: max(CLV, 0) vs indicator(CLV>0.3) to reduce borderline closes.\n5) Address IC drop and drawdown via neutralization and monotonic transforms:\n   - Use cross-sectional z-score or rank for each component before combining.\n   - Consider neutralizing composite vs ln(market cap proxy) or vs liquidity proxy (e.g., MA60(C*V)) to reduce unintended liquidity/size beta.\n6) Composite structure suggestion (gated, not over-engineered):\n   - Score = rank(BreakoutStrength_20D) + rank(LiquidityRerating_20v60) + rank(OvernightDriftSharpe_10D)\n   - Active only if (CoilCompression_10v60_in_252 <= q) AND (VolumeDispersion_10 <= q2).\n   - This matches the hypothesis wording (“strongest when… preceded by… confirmed by…”) more faithfully than a purely additive factor.\n\nComplexity control note:\n- No explicit complexity warnings were provided, but the next step should still prioritize a small number of interpretable gates and rank/zscore transforms over adding many new primitives. The biggest expected gain here is structural (gating + robust normalization), not longer expressions."
      }
    },
    "d4b33fc7df90ce65": {
      "factor_id": "d4b33fc7df90ce65",
      "factor_name": "OvernightDrift_Sharpe_10D",
      "factor_expression": "TS_MEAN(LOG($open/(DELAY($close,1)+1e-8)),10)/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),10)+1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(LOG($open/(DELAY($close,1)+1e-8)),10)/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),10)+1e-8)\" # Your output factor expression will be filled in here\n    name = \"OvernightDrift_Sharpe_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "10-day overnight drift quality: mean overnight return (close-to-next-open) scaled by its 10-day volatility. Rewards consistent overnight accumulation rather than noisy gaps.",
      "factor_formulation": "F=\\frac{\\text{MA}_{10}(\\log(O/(C_{t-1}+\\epsilon)))}{\\text{STD}_{10}(\\log(O/(C_{t-1}+\\epsilon)))+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "dc5110b2a31c",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "d77915ad7025"
        ],
        "hypothesis": "Hypothesis: Single-stock medium-horizon (10–60 trading days) continuation is strongest when an extreme short-term volatility compression (“coil”) resolves into a decisive 20D channel breakout that is preceded by a 20–60D liquidity re-rating (rising dollar-volume and improving Amihud illiquidity) and confirmed by stable (non-spiky) volume dynamics plus consistent 10D overnight drift; therefore a gated composite factor combining (i) 10D/60D true-range compression vs its 252D history, (ii) 20D breakout strength with close-location-in-range, (iii) 20D vs 60D dollar-volume expansion and 20D illiquidity improvement, (iv) low 10D dispersion of volume changes, and (v) 10D overnight-trend quality should positively predict next several-days returns cross-sectionally.\n                Concise Observation: Available data (open/high/low/close/volume) supports constructing true-range based compression, channel-breakout signals, dollar-volume and Amihud illiquidity proxies, volume-change dispersion filters, and overnight (close-to-next-open) trend quality metrics on fixed windows (e.g., 10/20/60/252D) suitable for cross-sectional ranking in Qlib.\n                Concise Justification: This fusion reduces common failure modes of standalone breakout signals (false breakouts from news spikes or illiquid prints) by requiring a cause-before-effect sequence—liquidity re-rating and absorption during compression—then validating release via decisive breakout geometry and stable overnight drift, so the composite score targets breakouts supported by broad, informed positioning rather than transient intraday noise.\n                Concise Knowledge: If volatility compression reflects supply absorption, then breakouts tend to persist only when participation/tradability improves beforehand (higher dollar-volume, lower price-impact/Amihud) and volume is orderly (low dispersion rather than event spikes); when the breakout close is near the day’s high and overnight returns show a stable positive drift (high slope/fit over 10D), the move is more likely information-driven than intraday mean-reversion, increasing short-horizon continuation odds.\n                concise Specification: Define a single long-only factor score per (instrument, day) using fixed hyperparameters: TR_t=max(high_t-low_t, |high_t-close_{t-1}|, |low_t-close_{t-1}|); CompressionGate=I[ (MA_10(TR)/MA_60(TR)) in bottom 10% of its rolling 252D history ]; OrderlyVolGate=I[ MAD_10(Δlog(volume)) in bottom 50% cross-section or bottom 50% of its own 252D history ]; LiquidityGate=I[ MA_20(close*volume)/MA_60(close*volume) > 1.1 AND (MA_20(|close_ret|/(close*volume)) < MA_60(|close_ret|/(close*volume))) AND MA_20(TR) <= MA_60(TR) ]; BreakoutStrength=((close_t - HHV_20(high))/HHV_20(high)) clipped at [0, +∞) with Trigger I[close_t>HHV_20(high)]; CLV=(2*close_t-high_t-low_t)/(high_t-low_t) (set 0 when high=low); OvernightRet_t=log(open_t/close_{t-1}); OvernightQuality=Slope_10(OvernightRet) * R2_10(OvernightRet~time); FinalFactor = CompressionGate * OrderlyVolGate * LiquidityGate * BreakoutStrength * max(CLV,0) * max(OvernightQuality,0), then cross-sectionally rank on each day for modeling; expected relationship: higher FinalFactor -> higher forward returns over the next 5–20 trading days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T02:53:00.651014"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.111897314485086,
        "ICIR": 0.0322796282269955,
        "1day.excess_return_without_cost.std": 0.004557493581731,
        "1day.excess_return_with_cost.annualized_return": 0.034579718842182,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003447041996748,
        "1day.excess_return_without_cost.annualized_return": 0.0820395995226208,
        "1day.excess_return_with_cost.std": 0.0045574398497798,
        "Rank IC": 0.0200427484776002,
        "IC": 0.004882593170981,
        "1day.excess_return_without_cost.max_drawdown": -0.1026494075710868,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1668337636822992,
        "1day.pa": 0.0,
        "l2.valid": 0.996357234644066,
        "Rank ICIR": 0.1301171855121951,
        "l2.train": 0.9915770775676817,
        "1day.excess_return_with_cost.information_ratio": 0.4918266230978798,
        "1day.excess_return_with_cost.mean": 0.0001452929363116
      },
      "feedback": {
        "observations": "The current run improves return efficiency versus the prior SOTA but deteriorates in drawdown and cross-sectional correlation (IC). Specifically: (1) annualized excess return increases (0.0820 vs 0.0520) and information ratio increases (1.1668 vs 0.9726), indicating the implemented signals contain exploitable predictive content and/or better portfolio-level behavior in this backtest configuration; (2) max drawdown is worse (more negative: -0.1026 vs -0.0726), implying the signal is taking on more tail risk / regime sensitivity; (3) IC declines (0.00488 vs 0.00580), suggesting weaker pure cross-sectional ranking quality even though the strategy-level returns improved—this often happens when the signal becomes more “timing/regime” dependent or when a few episodic winners dominate PnL.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not fully validate the stated ‘coil → breakout + liquidity rerating + stable volume + overnight drift’ mechanism because key hypothesis components were not yet implemented in this iteration.\n\nSupport:\n- BreakoutStrength_CLV_Pos_20D + LiquidityRerating_DV_20v60_x_AmihudImprove + OvernightDrift_Sharpe_10D together generate materially higher annualized return and IR than SOTA, consistent with the idea that breakout confirmation plus liquidity improvement plus steady overnight accumulation can help medium-horizon continuation.\n\nRefutation / gaps:\n- The hypothesis emphasizes a volatility-compression (“coil”) condition and “stable (non-spiky) volume dynamics” as gates/confirmations. Those two components are absent here, so the observed higher drawdown is consistent with missing the intended risk-control gates (i.e., you may be buying breakouts that are not true coil-resolutions and are accompanied by unstable volume).\n- IC deterioration suggests the current combination may not be improving cross-sectional ranking quality; it may instead be introducing exposure to common risk factors (size/liquidity/volatility regimes). This is consistent with a liquidity rerating term that can inadvertently load on liquidity/size beta unless explicitly neutralized.\n\nNet: The result leans toward supporting the framework’s direction (breakout + liquidity + overnight drift), but it also indicates the framework’s promised robustness likely requires the missing coil/volume-stability gating to reduce drawdowns and improve generalization.",
        "decision": true,
        "reason": "Why annualized/IR improved but IC and drawdown worsened:\n- Liquidity re-rating (DV expansion × Amihud improvement) can create strong episodic winners (boosting annualized return/IR) while also increasing crash sensitivity in liquidity shocks (worsening max drawdown).\n- Breakout strength without an explicit ‘coil’ precondition tends to chase high-volatility continuation *and* false breakouts; CLV helps, but it is a same-day confirmation and may not eliminate regime-dependent breakouts.\n- Overnight drift Sharpe can be structurally related to sentiment/positioning effects that work in some regimes but gap violently in others, contributing to drawdown.\n\nConcrete next iteration recommendations (still same theoretical framework; focus on gates + simplification + parameter sweeps):\n1) Implement the missing coil term exactly as a standalone factor and as a hard gate:\n   - Coil/TR compression: compute True Range TR = max(H-L, |H-prevC|, |L-prevC|).\n   - Hyperparameters to try (separate factors): lookback {10, 20, 30, 60}, long-history window {252}, and use percentile rank of current TR/MA(TR,lookback) within 252D.\n   - Gate example: only allow breakout signal when compression_percentile <= {10%, 20%}.\n2) Add the volume-stability confirmation as another gate rather than a linear add:\n   - Volume change series: dv_t = log(1 + V_t) or log(C*V) change.\n   - Dispersion metric: STD_10(ΔlogV) or MAD_10(ΔlogV).\n   - Gate: dispersion in bottom {30%, 50%} cross-sectionally to avoid spiky volume.\n3) Rework LiquidityRerating into a more robust and less regime-leaky form:\n   - Replace multiplicative form with rank-based combination to reduce outlier dominance:\n     rank(log(MA20(DV)/MA60(DV))) + rank(MA60(Amihud) - MA20(Amihud)).\n   - Hyperparameters to sweep as separate factors: DV windows (20/60 vs 10/40 vs 30/90), Amihud windows (20/60 vs 10/30 vs 30/120).\n4) Improve breakout definition robustness (same concept, fewer false breakouts):\n   - Try breakout over prior 20D *close* highs (HHV20(C)) vs highs (HHV20(H)).\n   - Add ATR scaling: (C - HHV)/ATR_14 to normalize across vol regimes.\n   - Keep CLV gate but test thresholds: max(CLV, 0) vs indicator(CLV>0.3) to reduce borderline closes.\n5) Address IC drop and drawdown via neutralization and monotonic transforms:\n   - Use cross-sectional z-score or rank for each component before combining.\n   - Consider neutralizing composite vs ln(market cap proxy) or vs liquidity proxy (e.g., MA60(C*V)) to reduce unintended liquidity/size beta.\n6) Composite structure suggestion (gated, not over-engineered):\n   - Score = rank(BreakoutStrength_20D) + rank(LiquidityRerating_20v60) + rank(OvernightDriftSharpe_10D)\n   - Active only if (CoilCompression_10v60_in_252 <= q) AND (VolumeDispersion_10 <= q2).\n   - This matches the hypothesis wording (“strongest when… preceded by… confirmed by…”) more faithfully than a purely additive factor.\n\nComplexity control note:\n- No explicit complexity warnings were provided, but the next step should still prioritize a small number of interpretable gates and rank/zscore transforms over adding many new primitives. The biggest expected gain here is structural (gating + robust normalization), not longer expressions."
      }
    },
    "0352ddf4f8c17428": {
      "factor_id": "0352ddf4f8c17428",
      "factor_name": "Volatility_Coil_Compression_RV_10_20_60_252",
      "factor_expression": "ZSCORE(-(TS_STD($return,10)/(TS_STD($return,60)+1e-8)+TS_STD($return,20)/(TS_STD($return,60)+1e-8)+TS_RANK(TS_STD($return,10),252)/252))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(-(TS_STD(TS_PCTCHANGE($close,1),10)/(TS_STD(TS_PCTCHANGE($close,1),60)+1e-8)+TS_STD(TS_PCTCHANGE($close,1),20)/(TS_STD(TS_PCTCHANGE($close,1),60)+1e-8)+TS_RANK(TS_STD(TS_PCTCHANGE($close,1),10),252)/252))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Coil_Compression_RV_10_20_60_252\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures multi-horizon realized-volatility compression: short-horizon return volatility compressed vs medium horizon, plus a 1Y low-volatility regime proxy via time-series rank. Higher values indicate tighter 'coil' conditions.",
      "factor_formulation": "F=\\text{ZSCORE}\\Big(-[\\frac{\\sigma_{10}}{\\sigma_{60}}+\\frac{\\sigma_{20}}{\\sigma_{60}}+\\frac{\\text{TS\\_RANK}(\\sigma_{10},252)}{252}]\\Big),\\;\\sigma_k=\\text{STD}(r,k)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "e145ed1d7004",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns will be higher after a breakout if a multi-week volatility “coil” regime (short-horizon true-range/realized volatility compressed vs medium horizon and vs its own 1Y history) resolves via a dual-horizon price breakout (close exceeding both prior 20D channel high and prior 55D high), and the breakout is confirmed by strong close-location (close near day’s high), abnormal-but-orderly volume (positive volume surprise with low instability of volume changes), a clean low-noise pre-breakout micro-trend (high trend-fit quality over 10D), and positive overnight drift dominance over the last 10D.\n                Concise Observation: With only OHLCV available, the most robust way to reduce false breakouts is to gate on multi-window volatility compression and require a stronger (dual-horizon) breakout, then rank candidates by breakout quality proxies that are measurable from OHLCV (CLV, volume surprise vs instability, trend-fit quality, and overnight-vs-intraday return dominance).\n                Concise Justification: Volatility-coil regimes indicate temporary equilibrium; a breakout above both short and medium lookback highs filters out local whipsaws, while close near highs, stable elevated volume, clean pre-breakout drift, and positive overnight dominance jointly indicate higher-conviction accumulation (lower adverse selection), which should increase the probability of multi-week continuation rather than immediate mean-reversion.\n                Concise Knowledge: If volatility compression reduces noise and the subsequent breakout clears longer reference highs, then trend continuation is more likely; when breakout days also show strong close-location and broad participation (volume surprise) without chaotic volume shocks, and pre-breakout prices trend with high fit quality plus persistent overnight contribution, the move is more likely driven by sustained demand and thus predicts positive forward 10–60D returns in cross-section.\n                concise Specification: Use daily OHLCV; define TR_t=max(high-low,|high-prev_close|,|low-prev_close|), ATR_k=MA(TR,k); coil gate requires (ATR10/ATR60<0.70) AND (ATR20/ATR60<0.80) AND rank_pct(ATR10 over past 252D)<0.10; breakout gate requires close_t>rolling_max(high,20)_{t-1} AND close_t>rolling_max(high,55)_{t-1}; compute breakout_dist=ln(close_t/max(rolling_max(high,20)_{t-1},rolling_max(high,55)_{t-1})), CLV=(close-low)/(high-low) (set 0 if high==low), vol_surprise=zscore(ln(volume),20), vol_instability=MAD(Δln(volume),20), trend_quality=(slope of OLS on ln(close) over 10D)/(std of residuals over 10D), overnight_dom=MA( ( (open/prev_close-1) / (|open/prev_close-1|+|close/open-1|+1e-6) ),10 ); final factor=gate*(breakout_dist+CLV+vol_surprise+trend_quality+overnight_dom - vol_instability), where hyperparameters are fixed at {ATR:10,20,60; history:252; breakout highs:20,55; trend:10; volume surprise:20; volume MAD:20; overnight:10}.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T03:05:32.788191"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1483114033898221,
        "ICIR": 0.0344784344688049,
        "1day.excess_return_without_cost.std": 0.004335907948582,
        "1day.excess_return_with_cost.annualized_return": 0.0126621664704969,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002512117926436,
        "1day.excess_return_without_cost.annualized_return": 0.0597884066491878,
        "1day.excess_return_with_cost.std": 0.0043380128854402,
        "Rank IC": 0.0164376507113416,
        "IC": 0.0043890384579026,
        "1day.excess_return_without_cost.max_drawdown": -0.1145757694755345,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8938166648101531,
        "1day.pa": 0.0,
        "l2.valid": 0.996404921850602,
        "Rank ICIR": 0.1273407317769747,
        "l2.train": 0.9915065636375922,
        "1day.excess_return_with_cost.information_ratio": 0.1892032981727894,
        "1day.excess_return_with_cost.mean": 5.320238012813832e-05
      },
      "feedback": {
        "observations": "This run implements and tests only 3 components (volatility coil compression, dual-horizon breakout distance, and breakout confirmation via CLV/volume). Two key hypothesis components—(a) pre-breakout micro-trend cleanliness (10D trend-fit quality) and (b) positive overnight drift dominance over last 10D—are not included, so the hypothesis is only partially tested.\n\nPerformance vs SOTA:\n- Annualized return: 0.059788 vs 0.052010 (better; +0.00778 absolute, ~+15% relative).\n- Max drawdown: -0.114576 vs -0.072585 (worse; larger drawdown).\n- Information ratio: 0.893817 vs 0.972561 (worse; lower risk-adjusted performance).\n- IC: 0.004389 vs 0.005798 (worse; weaker predictive correlation).\n\nInterpretation: the portfolio-level return improved, but predictive quality (IC) and risk-adjusted performance (IR) deteriorated, and drawdown worsened—consistent with a noisier / less stable signal that may be picking up episodic returns but not generalizing well.",
        "hypothesis_evaluation": "Overall, results provide only weak/partial support for the hypothesis.\n- Support: higher annualized return is consistent with the idea that combining coil + breakout + confirmation can capture upside.\n- Refute / weaken: lower IC and lower IR indicate the model’s predictions are less consistently aligned with realized returns, and the worse drawdown suggests the breakout filters are not sufficiently excluding false breakouts or adverse regimes.\n- Incompleteness: because the micro-trend quality (10D trend-fit) and overnight drift dominance (10D) were not implemented, the central claim that these confirmations improve post-breakout returns is not validated in this experiment.\n\nFactor-level construction comments and hyperparameters to revisit:\n1) Volatility_Coil_Compression_RV_10_20_60_252\n- Hyperparameters: STD windows = {10, 20, 60}; TS_RANK window = 252; cross-sectional ZSCORE.\n- Potential issue: pure close-to-close realized vol can miss true-range compression (gap + intraday range). Coil regimes are often better captured by ATR/true-range compression.\n\n2) DualHorizon_Breakout_Distance_Log_20_55\n- Hyperparameters: channel lookbacks = {20, 55}; reference uses prior highs t-20..t-1 and t-55..t-1; gating requires both conditions.\n- Potential issue: using “high” to define channels but confirming with close can be sensitive to single-day high spikes. Consider using prior close channel or robust high (e.g., percentile of highs) to reduce one-day noise.\n\n3) Breakout_Confirmation_CLV_VolSurprise_Instability_20\n- Hyperparameters: volume z-score window = 20; volume instability MAD window = 20; uses Δlog(volume) with implicit n=1.\n- Potential issue: volume surprise is not scaled by liquidity/turnover, and the instability term may penalize legitimate ramp-up phases pre-breakout. This can hurt consistency (IC) while still occasionally catching big winners (annualized return).",
        "decision": false,
        "reason": "Why annualized return up but IC/IR down:\n- Your current combination can create a ‘lottery ticket’ profile: occasional strong winners (improving annualized return) but inconsistent ranking across the universe (lower IC) and worse tail behavior (higher drawdown).\n- The missing components in the stated hypothesis (10D trend-fit quality, 10D overnight drift dominance) are exactly the kinds of filters that reduce false breakouts and improve robustness/risk-adjusted metrics.\n\nConcrete next iterations (stay within the same framework; prioritize simplicity):\n1) Implement the two missing confirmations as separate, static factors (each with explicit hyperparameters)\n- TrendFit_R2_10: R^2 of linear regression of log(close) on time over past 10 days (window=10). Higher = cleaner micro-trend.\n- Overnight_Drift_Dominance_10: sum(overnight returns, 10) / (sum(|intraday returns|, 10) + eps) (window=10). Higher = overnight drift dominates.\n\n2) Improve coil definition using true range (same concept, better measurement)\n- ATR_Compression_10_60_252: ATR(10)/ATR(60) + TS_RANK(ATR(10),252) (windows 10,60,252). This aligns more directly with “true-range compressed vs medium horizon and vs 1Y history”.\n\n3) Make the combination more “event-gated” to reduce drawdowns\n- Instead of cross-sectional Z-scoring each component and summing daily, compute a gated score:\n  Score = 1[coil strong AND breakout true] * (breakout_distance) * (confirmation)\n  This keeps the factor mostly inactive outside the regime, which typically improves drawdown/IR.\n\n4) Parameter sensitivity to explore (define as distinct factors)\n- Coil windows: (8,16,48,252), (10,20,60,252), (12,24,72,252)\n- Breakout windows: (20,55), (20,60), (10,50) while keeping the “dual-horizon” idea.\n- Volume windows: 20 vs 30; instability as TS_STD(Δlog(v),20) vs MAD(20).\n\n5) Normalization/robustness\n- Winsorize CLV and volume z-scores cross-sectionally before ZSCORE to reduce outliers.\n- Consider neutralizing by size/liquidity bucket if available (if not, approximate with rolling log(volume) rank as a control signal).\n\nComplexity control:\n- Current factors are short and use a limited set of base features ($close/$high/$low/$volume), with few free parameters; no complexity red flags. Keep subsequent additions similarly modular (avoid one huge expression)."
      }
    },
    "5676d8e5edfbcf89": {
      "factor_id": "5676d8e5edfbcf89",
      "factor_name": "DualHorizon_Breakout_Distance_Log_20_55",
      "factor_expression": "ZSCORE((($close>DELAY(TS_MAX($high,20),1))&&($close>DELAY(TS_MAX($high,55),1)))?LOG($close/(MAX(DELAY(TS_MAX($high,20),1),DELAY(TS_MAX($high,55),1))+1e-8)):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($close>DELAY(TS_MAX($high,20),1))&&($close>DELAY(TS_MAX($high,55),1)))?LOG($close/(MAX(DELAY(TS_MAX($high,20),1),DELAY(TS_MAX($high,55),1))+1e-8)):0)\" # Your output factor expression will be filled in here\n    name = \"DualHorizon_Breakout_Distance_Log_20_55\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures breakout strength beyond both prior 20D and 55D channel highs. Outputs log distance above the stricter (higher) reference, gated to zero unless both breakouts occur.",
      "factor_formulation": "H_{20}=\\max(\\text{high}_{t-20..t-1}),\\;H_{55}=\\max(\\text{high}_{t-55..t-1});\\quad F=\\text{ZSCORE}(\\mathbf{1}[c_t>H_{20}\\wedge c_t>H_{55}]\\cdot \\ln(\\frac{c_t}{\\max(H_{20},H_{55})}))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "e145ed1d7004",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns will be higher after a breakout if a multi-week volatility “coil” regime (short-horizon true-range/realized volatility compressed vs medium horizon and vs its own 1Y history) resolves via a dual-horizon price breakout (close exceeding both prior 20D channel high and prior 55D high), and the breakout is confirmed by strong close-location (close near day’s high), abnormal-but-orderly volume (positive volume surprise with low instability of volume changes), a clean low-noise pre-breakout micro-trend (high trend-fit quality over 10D), and positive overnight drift dominance over the last 10D.\n                Concise Observation: With only OHLCV available, the most robust way to reduce false breakouts is to gate on multi-window volatility compression and require a stronger (dual-horizon) breakout, then rank candidates by breakout quality proxies that are measurable from OHLCV (CLV, volume surprise vs instability, trend-fit quality, and overnight-vs-intraday return dominance).\n                Concise Justification: Volatility-coil regimes indicate temporary equilibrium; a breakout above both short and medium lookback highs filters out local whipsaws, while close near highs, stable elevated volume, clean pre-breakout drift, and positive overnight dominance jointly indicate higher-conviction accumulation (lower adverse selection), which should increase the probability of multi-week continuation rather than immediate mean-reversion.\n                Concise Knowledge: If volatility compression reduces noise and the subsequent breakout clears longer reference highs, then trend continuation is more likely; when breakout days also show strong close-location and broad participation (volume surprise) without chaotic volume shocks, and pre-breakout prices trend with high fit quality plus persistent overnight contribution, the move is more likely driven by sustained demand and thus predicts positive forward 10–60D returns in cross-section.\n                concise Specification: Use daily OHLCV; define TR_t=max(high-low,|high-prev_close|,|low-prev_close|), ATR_k=MA(TR,k); coil gate requires (ATR10/ATR60<0.70) AND (ATR20/ATR60<0.80) AND rank_pct(ATR10 over past 252D)<0.10; breakout gate requires close_t>rolling_max(high,20)_{t-1} AND close_t>rolling_max(high,55)_{t-1}; compute breakout_dist=ln(close_t/max(rolling_max(high,20)_{t-1},rolling_max(high,55)_{t-1})), CLV=(close-low)/(high-low) (set 0 if high==low), vol_surprise=zscore(ln(volume),20), vol_instability=MAD(Δln(volume),20), trend_quality=(slope of OLS on ln(close) over 10D)/(std of residuals over 10D), overnight_dom=MA( ( (open/prev_close-1) / (|open/prev_close-1|+|close/open-1|+1e-6) ),10 ); final factor=gate*(breakout_dist+CLV+vol_surprise+trend_quality+overnight_dom - vol_instability), where hyperparameters are fixed at {ATR:10,20,60; history:252; breakout highs:20,55; trend:10; volume surprise:20; volume MAD:20; overnight:10}.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T03:05:32.788191"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1483114033898221,
        "ICIR": 0.0344784344688049,
        "1day.excess_return_without_cost.std": 0.004335907948582,
        "1day.excess_return_with_cost.annualized_return": 0.0126621664704969,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002512117926436,
        "1day.excess_return_without_cost.annualized_return": 0.0597884066491878,
        "1day.excess_return_with_cost.std": 0.0043380128854402,
        "Rank IC": 0.0164376507113416,
        "IC": 0.0043890384579026,
        "1day.excess_return_without_cost.max_drawdown": -0.1145757694755345,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8938166648101531,
        "1day.pa": 0.0,
        "l2.valid": 0.996404921850602,
        "Rank ICIR": 0.1273407317769747,
        "l2.train": 0.9915065636375922,
        "1day.excess_return_with_cost.information_ratio": 0.1892032981727894,
        "1day.excess_return_with_cost.mean": 5.320238012813832e-05
      },
      "feedback": {
        "observations": "This run implements and tests only 3 components (volatility coil compression, dual-horizon breakout distance, and breakout confirmation via CLV/volume). Two key hypothesis components—(a) pre-breakout micro-trend cleanliness (10D trend-fit quality) and (b) positive overnight drift dominance over last 10D—are not included, so the hypothesis is only partially tested.\n\nPerformance vs SOTA:\n- Annualized return: 0.059788 vs 0.052010 (better; +0.00778 absolute, ~+15% relative).\n- Max drawdown: -0.114576 vs -0.072585 (worse; larger drawdown).\n- Information ratio: 0.893817 vs 0.972561 (worse; lower risk-adjusted performance).\n- IC: 0.004389 vs 0.005798 (worse; weaker predictive correlation).\n\nInterpretation: the portfolio-level return improved, but predictive quality (IC) and risk-adjusted performance (IR) deteriorated, and drawdown worsened—consistent with a noisier / less stable signal that may be picking up episodic returns but not generalizing well.",
        "hypothesis_evaluation": "Overall, results provide only weak/partial support for the hypothesis.\n- Support: higher annualized return is consistent with the idea that combining coil + breakout + confirmation can capture upside.\n- Refute / weaken: lower IC and lower IR indicate the model’s predictions are less consistently aligned with realized returns, and the worse drawdown suggests the breakout filters are not sufficiently excluding false breakouts or adverse regimes.\n- Incompleteness: because the micro-trend quality (10D trend-fit) and overnight drift dominance (10D) were not implemented, the central claim that these confirmations improve post-breakout returns is not validated in this experiment.\n\nFactor-level construction comments and hyperparameters to revisit:\n1) Volatility_Coil_Compression_RV_10_20_60_252\n- Hyperparameters: STD windows = {10, 20, 60}; TS_RANK window = 252; cross-sectional ZSCORE.\n- Potential issue: pure close-to-close realized vol can miss true-range compression (gap + intraday range). Coil regimes are often better captured by ATR/true-range compression.\n\n2) DualHorizon_Breakout_Distance_Log_20_55\n- Hyperparameters: channel lookbacks = {20, 55}; reference uses prior highs t-20..t-1 and t-55..t-1; gating requires both conditions.\n- Potential issue: using “high” to define channels but confirming with close can be sensitive to single-day high spikes. Consider using prior close channel or robust high (e.g., percentile of highs) to reduce one-day noise.\n\n3) Breakout_Confirmation_CLV_VolSurprise_Instability_20\n- Hyperparameters: volume z-score window = 20; volume instability MAD window = 20; uses Δlog(volume) with implicit n=1.\n- Potential issue: volume surprise is not scaled by liquidity/turnover, and the instability term may penalize legitimate ramp-up phases pre-breakout. This can hurt consistency (IC) while still occasionally catching big winners (annualized return).",
        "decision": false,
        "reason": "Why annualized return up but IC/IR down:\n- Your current combination can create a ‘lottery ticket’ profile: occasional strong winners (improving annualized return) but inconsistent ranking across the universe (lower IC) and worse tail behavior (higher drawdown).\n- The missing components in the stated hypothesis (10D trend-fit quality, 10D overnight drift dominance) are exactly the kinds of filters that reduce false breakouts and improve robustness/risk-adjusted metrics.\n\nConcrete next iterations (stay within the same framework; prioritize simplicity):\n1) Implement the two missing confirmations as separate, static factors (each with explicit hyperparameters)\n- TrendFit_R2_10: R^2 of linear regression of log(close) on time over past 10 days (window=10). Higher = cleaner micro-trend.\n- Overnight_Drift_Dominance_10: sum(overnight returns, 10) / (sum(|intraday returns|, 10) + eps) (window=10). Higher = overnight drift dominates.\n\n2) Improve coil definition using true range (same concept, better measurement)\n- ATR_Compression_10_60_252: ATR(10)/ATR(60) + TS_RANK(ATR(10),252) (windows 10,60,252). This aligns more directly with “true-range compressed vs medium horizon and vs 1Y history”.\n\n3) Make the combination more “event-gated” to reduce drawdowns\n- Instead of cross-sectional Z-scoring each component and summing daily, compute a gated score:\n  Score = 1[coil strong AND breakout true] * (breakout_distance) * (confirmation)\n  This keeps the factor mostly inactive outside the regime, which typically improves drawdown/IR.\n\n4) Parameter sensitivity to explore (define as distinct factors)\n- Coil windows: (8,16,48,252), (10,20,60,252), (12,24,72,252)\n- Breakout windows: (20,55), (20,60), (10,50) while keeping the “dual-horizon” idea.\n- Volume windows: 20 vs 30; instability as TS_STD(Δlog(v),20) vs MAD(20).\n\n5) Normalization/robustness\n- Winsorize CLV and volume z-scores cross-sectionally before ZSCORE to reduce outliers.\n- Consider neutralizing by size/liquidity bucket if available (if not, approximate with rolling log(volume) rank as a control signal).\n\nComplexity control:\n- Current factors are short and use a limited set of base features ($close/$high/$low/$volume), with few free parameters; no complexity red flags. Keep subsequent additions similarly modular (avoid one huge expression)."
      }
    },
    "db76dd545f4112a8": {
      "factor_id": "db76dd545f4112a8",
      "factor_name": "Breakout_Confirmation_CLV_VolSurprise_Instability_20",
      "factor_expression": "ZSCORE((($high>$low)?(($close-$low)/($high-$low+1e-8)):0)+TS_ZSCORE(LOG($volume+1),20)-TS_MAD(DELTA(LOG($volume+1),1),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high>$low)?(($close-$low)/($high-$low+1e-8)):0)+TS_ZSCORE(LOG($volume+1),20)-TS_MAD(DELTA(LOG($volume+1),1),20))\" # Your output factor expression will be filled in here\n    name = \"Breakout_Confirmation_CLV_VolSurprise_Instability_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Breakout-quality proxy combining (i) close-location value (close near high), (ii) abnormal volume via 20D z-score of log volume, and (iii) penalty for unstable volume changes via 20D MAD of daily log-volume changes. Higher values imply stronger, more orderly participation.",
      "factor_formulation": "CLV=\\begin{cases}\\frac{c-l}{h-l},&h\\neq l\\\\0,&h=l\\end{cases};\\;VS=\\text{Z}(\\ln(v),20);\\;VI=\\text{MAD}(\\Delta\\ln(v),20);\\;F=\\text{ZSCORE}(CLV+VS-VI)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "e145ed1d7004",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "b62c61606b7e"
        ],
        "hypothesis": "Hypothesis: Single-stock 10–60D returns will be higher after a breakout if a multi-week volatility “coil” regime (short-horizon true-range/realized volatility compressed vs medium horizon and vs its own 1Y history) resolves via a dual-horizon price breakout (close exceeding both prior 20D channel high and prior 55D high), and the breakout is confirmed by strong close-location (close near day’s high), abnormal-but-orderly volume (positive volume surprise with low instability of volume changes), a clean low-noise pre-breakout micro-trend (high trend-fit quality over 10D), and positive overnight drift dominance over the last 10D.\n                Concise Observation: With only OHLCV available, the most robust way to reduce false breakouts is to gate on multi-window volatility compression and require a stronger (dual-horizon) breakout, then rank candidates by breakout quality proxies that are measurable from OHLCV (CLV, volume surprise vs instability, trend-fit quality, and overnight-vs-intraday return dominance).\n                Concise Justification: Volatility-coil regimes indicate temporary equilibrium; a breakout above both short and medium lookback highs filters out local whipsaws, while close near highs, stable elevated volume, clean pre-breakout drift, and positive overnight dominance jointly indicate higher-conviction accumulation (lower adverse selection), which should increase the probability of multi-week continuation rather than immediate mean-reversion.\n                Concise Knowledge: If volatility compression reduces noise and the subsequent breakout clears longer reference highs, then trend continuation is more likely; when breakout days also show strong close-location and broad participation (volume surprise) without chaotic volume shocks, and pre-breakout prices trend with high fit quality plus persistent overnight contribution, the move is more likely driven by sustained demand and thus predicts positive forward 10–60D returns in cross-section.\n                concise Specification: Use daily OHLCV; define TR_t=max(high-low,|high-prev_close|,|low-prev_close|), ATR_k=MA(TR,k); coil gate requires (ATR10/ATR60<0.70) AND (ATR20/ATR60<0.80) AND rank_pct(ATR10 over past 252D)<0.10; breakout gate requires close_t>rolling_max(high,20)_{t-1} AND close_t>rolling_max(high,55)_{t-1}; compute breakout_dist=ln(close_t/max(rolling_max(high,20)_{t-1},rolling_max(high,55)_{t-1})), CLV=(close-low)/(high-low) (set 0 if high==low), vol_surprise=zscore(ln(volume),20), vol_instability=MAD(Δln(volume),20), trend_quality=(slope of OLS on ln(close) over 10D)/(std of residuals over 10D), overnight_dom=MA( ( (open/prev_close-1) / (|open/prev_close-1|+|close/open-1|+1e-6) ),10 ); final factor=gate*(breakout_dist+CLV+vol_surprise+trend_quality+overnight_dom - vol_instability), where hyperparameters are fixed at {ATR:10,20,60; history:252; breakout highs:20,55; trend:10; volume surprise:20; volume MAD:20; overnight:10}.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T03:05:32.788191"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1483114033898221,
        "ICIR": 0.0344784344688049,
        "1day.excess_return_without_cost.std": 0.004335907948582,
        "1day.excess_return_with_cost.annualized_return": 0.0126621664704969,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002512117926436,
        "1day.excess_return_without_cost.annualized_return": 0.0597884066491878,
        "1day.excess_return_with_cost.std": 0.0043380128854402,
        "Rank IC": 0.0164376507113416,
        "IC": 0.0043890384579026,
        "1day.excess_return_without_cost.max_drawdown": -0.1145757694755345,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8938166648101531,
        "1day.pa": 0.0,
        "l2.valid": 0.996404921850602,
        "Rank ICIR": 0.1273407317769747,
        "l2.train": 0.9915065636375922,
        "1day.excess_return_with_cost.information_ratio": 0.1892032981727894,
        "1day.excess_return_with_cost.mean": 5.320238012813832e-05
      },
      "feedback": {
        "observations": "This run implements and tests only 3 components (volatility coil compression, dual-horizon breakout distance, and breakout confirmation via CLV/volume). Two key hypothesis components—(a) pre-breakout micro-trend cleanliness (10D trend-fit quality) and (b) positive overnight drift dominance over last 10D—are not included, so the hypothesis is only partially tested.\n\nPerformance vs SOTA:\n- Annualized return: 0.059788 vs 0.052010 (better; +0.00778 absolute, ~+15% relative).\n- Max drawdown: -0.114576 vs -0.072585 (worse; larger drawdown).\n- Information ratio: 0.893817 vs 0.972561 (worse; lower risk-adjusted performance).\n- IC: 0.004389 vs 0.005798 (worse; weaker predictive correlation).\n\nInterpretation: the portfolio-level return improved, but predictive quality (IC) and risk-adjusted performance (IR) deteriorated, and drawdown worsened—consistent with a noisier / less stable signal that may be picking up episodic returns but not generalizing well.",
        "hypothesis_evaluation": "Overall, results provide only weak/partial support for the hypothesis.\n- Support: higher annualized return is consistent with the idea that combining coil + breakout + confirmation can capture upside.\n- Refute / weaken: lower IC and lower IR indicate the model’s predictions are less consistently aligned with realized returns, and the worse drawdown suggests the breakout filters are not sufficiently excluding false breakouts or adverse regimes.\n- Incompleteness: because the micro-trend quality (10D trend-fit) and overnight drift dominance (10D) were not implemented, the central claim that these confirmations improve post-breakout returns is not validated in this experiment.\n\nFactor-level construction comments and hyperparameters to revisit:\n1) Volatility_Coil_Compression_RV_10_20_60_252\n- Hyperparameters: STD windows = {10, 20, 60}; TS_RANK window = 252; cross-sectional ZSCORE.\n- Potential issue: pure close-to-close realized vol can miss true-range compression (gap + intraday range). Coil regimes are often better captured by ATR/true-range compression.\n\n2) DualHorizon_Breakout_Distance_Log_20_55\n- Hyperparameters: channel lookbacks = {20, 55}; reference uses prior highs t-20..t-1 and t-55..t-1; gating requires both conditions.\n- Potential issue: using “high” to define channels but confirming with close can be sensitive to single-day high spikes. Consider using prior close channel or robust high (e.g., percentile of highs) to reduce one-day noise.\n\n3) Breakout_Confirmation_CLV_VolSurprise_Instability_20\n- Hyperparameters: volume z-score window = 20; volume instability MAD window = 20; uses Δlog(volume) with implicit n=1.\n- Potential issue: volume surprise is not scaled by liquidity/turnover, and the instability term may penalize legitimate ramp-up phases pre-breakout. This can hurt consistency (IC) while still occasionally catching big winners (annualized return).",
        "decision": false,
        "reason": "Why annualized return up but IC/IR down:\n- Your current combination can create a ‘lottery ticket’ profile: occasional strong winners (improving annualized return) but inconsistent ranking across the universe (lower IC) and worse tail behavior (higher drawdown).\n- The missing components in the stated hypothesis (10D trend-fit quality, 10D overnight drift dominance) are exactly the kinds of filters that reduce false breakouts and improve robustness/risk-adjusted metrics.\n\nConcrete next iterations (stay within the same framework; prioritize simplicity):\n1) Implement the two missing confirmations as separate, static factors (each with explicit hyperparameters)\n- TrendFit_R2_10: R^2 of linear regression of log(close) on time over past 10 days (window=10). Higher = cleaner micro-trend.\n- Overnight_Drift_Dominance_10: sum(overnight returns, 10) / (sum(|intraday returns|, 10) + eps) (window=10). Higher = overnight drift dominates.\n\n2) Improve coil definition using true range (same concept, better measurement)\n- ATR_Compression_10_60_252: ATR(10)/ATR(60) + TS_RANK(ATR(10),252) (windows 10,60,252). This aligns more directly with “true-range compressed vs medium horizon and vs 1Y history”.\n\n3) Make the combination more “event-gated” to reduce drawdowns\n- Instead of cross-sectional Z-scoring each component and summing daily, compute a gated score:\n  Score = 1[coil strong AND breakout true] * (breakout_distance) * (confirmation)\n  This keeps the factor mostly inactive outside the regime, which typically improves drawdown/IR.\n\n4) Parameter sensitivity to explore (define as distinct factors)\n- Coil windows: (8,16,48,252), (10,20,60,252), (12,24,72,252)\n- Breakout windows: (20,55), (20,60), (10,50) while keeping the “dual-horizon” idea.\n- Volume windows: 20 vs 30; instability as TS_STD(Δlog(v),20) vs MAD(20).\n\n5) Normalization/robustness\n- Winsorize CLV and volume z-scores cross-sectionally before ZSCORE to reduce outliers.\n- Consider neutralizing by size/liquidity bucket if available (if not, approximate with rolling log(volume) rank as a control signal).\n\nComplexity control:\n- Current factors are short and use a limited set of base features ($close/$high/$low/$volume), with few free parameters; no complexity red flags. Keep subsequent additions similarly modular (avoid one huge expression)."
      }
    },
    "0b8a44701cdeafd2": {
      "factor_id": "0b8a44701cdeafd2",
      "factor_name": "Amihud_ShockRevert_60D_Extreme90_LoserBoost",
      "factor_expression": "((TS_ZSCORE(ABS($return)*INV($close*$volume+1e-8),60)>2)&&(TS_RANK(ABS($return),60)>54))?(-SIGN($return)*TS_ZSCORE(ABS($return)*INV($close*$volume+1e-8),60)*(($close/DELAY($close,60)-1)<0?2:1)):0",
      "factor_implementation_code": "",
      "factor_description": "Contrarian shock-reversion signal: fades extreme 1-day moves when illiquidity (Amihud proxy) is unusually high versus its 60D history, with a 2x boost if the stock is a 60-day loser (ROC60<0). Designed to capture forced-flow/illiquid pressure that mean-reverts over 1–5 days.",
      "factor_formulation": "F_t=\\mathbf{1}[Z60(Amihud_t)>2\\wedge TSRANK60(|r_t|)>54]\\cdot\\left(-\\operatorname{sign}(r_t)\\right)\\cdot Z60(Amihud_t)\\cdot \\left(\\mathbf{1}[ROC60_t<0]+1\\right),\\; Amihud_t=\\frac{|r_t|}{Close_t\\,Vol_t}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "247a5cbd20e9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are generated by a stock-level regime switch between (A) “clean trend” price discovery, where volatility-compressed and volume-confirmed 55-day Donchian breakouts exhibit continuation, and (B) “illiquid shock/forced-flow” price pressure, where an extreme 1-day move on abnormally low dollar volume (high Amihud-illiquidity shock) partially mean-reverts over the next 1–5 days, with stronger reversion when the stock is a 60-day loser; a single factor that enforces mutually exclusive regime gating (priority to shock-reversion over breakout-trend) should improve predictive RankIC and reduce whipsaw/tail-risk relative to using either engine alone.\n                Concise Observation: The available daily OHLCV data supports constructing (i) Amihud-style illiquidity shocks from close-to-close returns and dollar volume, (ii) 55D Donchian breakout states from highs/closes, (iii) volatility compression from rolling realized volatility/ATR proxies, and (iv) loser context from 60D ROC, enabling a testable regime-exclusive fusion factor within a single daily cross-sectional table.\n                Concise Justification: A regime-exclusive allocator reduces contradictory exposures by only trend-following when price discovery is liquid and stable (vol-compressed + volume-confirmed breakouts) while fading moves that are statistically consistent with transient impact (extreme return + high illiquidity), and the loser-condition intensifies the contrarian edge by targeting names where forced-flow and gap-like discovery are more prevalent.\n                Concise Knowledge: If a large 1-day return occurs with unusually low dollar volume (high |r1|/$vol relative to its own history), then the move is more likely dominated by temporary liquidity/price-impact pressure and mean-reverts over 1–5 days; when volatility is compressed and price breaks a long lookback channel high with concurrent volume expansion, then the breakout is more likely information-driven and continues over a medium horizon; conditioning reversion signals on structural weakness (e.g., negative 60D ROC) increases the likelihood that shocks are flow-driven rather than fundamental.\n                concise Specification: Define daily inputs per instrument: r1=close/close(-1)-1; dollar_vol=close*volume; Amihud=abs(r1)/dollar_vol; z_Amihud=(Amihud-mean_60(Amihud))/std_60(Amihud); ret_extreme=abs(r1) > quantile_60(abs(r1),0.90); ROC60=close/close(-60)-1; Donchian55High=max_55(high); breakout=close>=Donchian55High; vol20=std_20(r1); vol_compress=vol20 < quantile_252(vol20,0.30); vol_expand_kill=vol20 > quantile_252(vol20,0.95); vol_confirm=z_20(dollar_vol)>0; Regime priority per day: (1) ShockRevert if z_Amihud>=quantile_cs(z_Amihud,0.90) AND ret_extreme, with strength multiplied by (1+I[ROC60<0]); (2) CleanTrend if breakout AND vol_compress AND vol_confirm; else neutral; Signal: if ShockRevert then score= -sign(r1)*z_Amihud*(1+I[ROC60<0]); if CleanTrend then score= +rank_cs((close/Donchian55High)-1)*rank_cs(z_20(dollar_vol)) - rank_cs(vol20); apply kill-switch: set score=0 when z_Amihud>=quantile_cs(z_Amihud,0.99) OR vol_expand_kill; final factor is cross-sectionally z-scored score each day for model input.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T04:23:48.465297"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1192431536734259,
        "ICIR": 0.0571613695148931,
        "1day.excess_return_without_cost.std": 0.0041039939467453,
        "1day.excess_return_with_cost.annualized_return": 0.027456752356365,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000313126396925,
        "1day.excess_return_without_cost.annualized_return": 0.0745240824681589,
        "1day.excess_return_with_cost.std": 0.0041034842803208,
        "Rank IC": 0.0237532984719519,
        "IC": 0.0074791429112698,
        "1day.excess_return_without_cost.max_drawdown": -0.1061838337194696,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1770677144511477,
        "1day.pa": 0.0,
        "l2.valid": 0.9964059745527934,
        "Rank ICIR": 0.1880262200093975,
        "l2.train": 0.9936311238119204,
        "1day.excess_return_with_cost.information_ratio": 0.4337184669963861,
        "1day.excess_return_with_cost.mean": 0.000115364505699
      },
      "feedback": {
        "observations": "Only one factor was implemented/tested in this run: CleanTrend_Donchian55_VolCompress252_30_VolConfirm20. The shock-reversion engine and the regime-exclusive gating factor (shock-priority) were not implemented, so the key “mutually exclusive regime gating” claim cannot be directly validated yet.\n\nPerformance vs SOTA:\n- Annualized return: 0.074524 vs 0.052010 (improves; bigger is better)\n- Information ratio: 1.177068 vs 0.972561 (improves)\n- IC: 0.007479 vs 0.005798 (improves)\n- Max drawdown: -0.106184 vs -0.072585 (worsens; smaller magnitude is better)\n\nInterpretation: the implemented “clean trend” breakout signal improves return efficiency (IR) and predictive correlation (IC), but it increases tail risk/whipsaw exposure as seen in the deeper drawdown. This pattern is consistent with an ungated trend/breakout factor that performs well on average but suffers in adverse regimes—exactly what the hypothesis claims regime gating should mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but cannot confirm the central mechanism.\n\nWhat is supported:\n- The trend component (“clean price discovery” via Donchian breakout + vol compression + volume confirmation) appears to add alpha: higher IC, higher annualized return, higher IR than SOTA.\n\nWhat is not yet tested / not supported directly:\n- The hypothesis’ core claim is that a single factor with mutually exclusive regime gating (shock-reversion priority over trend) should improve RankIC and reduce whipsaw/tail-risk relative to using either engine alone. Since neither (a) the shock-reversion factor nor (b) the regime gate were implemented, we cannot evaluate whether gating reduces drawdown or improves robustness.\n\nRisk takeaway:\n- The worsened max drawdown is a strong signal that the missing “shock/illiquid pressure” regime handling is important. Next iteration should prioritize implementing the regime gate and/or incorporating shock-priority suppression of trend signals during illiquidity spikes.",
        "decision": true,
        "reason": "Why the current outcome points here:\n- CleanTrend improved IC/IR/return but worsened max drawdown, suggesting regime-dependent failure modes.\n- Hard binary conditions (e.g., breakout AND vol-rank<0.30 AND Z20(vol)>0) can create sparse exposure and abrupt on/off switching, which often amplifies drawdowns when conditions flip.\n- A continuous gating weight (e.g., w_shock in [0,1]) allows the factor to progressively suppress trend exposure as shock likelihood rises, which is aligned with the hypothesis’ “priority to shock-reversion over breakout-trend” while avoiding brittle thresholds.\n\nConcrete refinement directions (staying within the same theoretical framework):\n1) Implement the missing shock engine exactly as specified (hyperparameters explicitly):\n   - Amihud_t = |r_t| / (Close_t * Vol_t)\n   - Z-score window: 60 (TS_ZSCORE(Amihud, 60))\n   - Extreme move filter: TS_RANK(|r_t|, 60) > 54 (i.e., top 10% of last 60)\n   - Shock threshold: Z60(Amihud) > 2\n   - Loser boost lookback: ROC60 < 0, multiplier (1 + 1[ROC60<0]) = 1x or 2x\n   - Output: (-sign(r_t)) * Z60(Amihud) * (1 + 1[ROC60<0]) under the joint shock conditions, else 0\n\n2) Implement the regime-exclusive gate (hyperparameters explicitly):\n   - Kill-switch: TS_RANK(Amihud, 60) > 59 => factor = 0\n   - Shock-reversion priority: TS_RANK(Amihud, 60) > 54 => factor = -sign(r_t)\n   - Trend branch requires ALL:\n     * Breakout window: 55 (Close >= TS_MAX(High, 55))\n     * Volatility compression: TS_RANK(sigma20, 252) < 0.30 where sigma20 = TS_STD(return, 20)\n     * Volume filter: TS_RANK(Vol, 20) > 10\n     * Trend score: RANK(Close/TS_MAX(High,55) - 1)\n   - Else: 0\n\n3) Parameter sensitivity to explore next (define as separate factors per your rule):\n   - Donchian breakout window: 20 / 55 / 120\n   - Vol-compression window: 126 / 252 / 504\n   - Realized vol window inside compression: 10 / 20 / 40 days (sigma_n)\n   - Volume confirmation: Z-score window 10 / 20 / 60 OR TS_RANK volume threshold > 8, 10, 12 (out of 20)\n   - Shock extremity: TS_RANK(|r|, 60) > 50, 54, 57 and/or Z60(Amihud) > 1.5, 2.0, 2.5\n   - Kill-switch strictness: top 1/60 (rank>59) vs top 2/60 (rank>58)\n\n4) Construction improvements to reduce drawdown without changing the concept:\n   - Replace some hard indicators with continuous scores (soft gates):\n     * Example: w_shock = clip((TS_RANK(Amihud,60)-54)/6, 0, 1); final = (1-w_shock)*TrendScore + w_shock*ShockScore, with kill-switch setting w_shock=0 and factor=0 at extreme tail.\n   - Robustness transforms: winsorize |r| and Amihud inputs (or use log(1+Amihud)) before z-score to reduce single-day outlier domination.\n   - Ensure cross-sectional comparability: if TrendScore uses RANK, consider also ranking/shaping shock branch (e.g., cross-sectional rank of shock intensity) so the combined factor has consistent cross-sectional distribution.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the regime-gate expression to remain short and interpretable (avoid stacking too many nested ranks/z-scores beyond the current set of windows: 20/55/60/252)."
      }
    },
    "1f743abc14604ea4": {
      "factor_id": "1f743abc14604ea4",
      "factor_name": "CleanTrend_Donchian55_VolCompress252_30_VolConfirm20",
      "factor_expression": "(($close>=TS_MAX($high,55))&&(TS_RANK(TS_STD($return,20),252)<76)&&(TS_ZSCORE($volume,20)>0))?(RANK($close/(TS_MAX($high,55)+1e-8)-1)+RANK(TS_ZSCORE($volume,20))-RANK(TS_STD($return,20))):0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((($close>=DELAY(TS_MAX($high,55),1))&&((TS_STD(TS_PCTCHANGE($close,1),20))<=TS_QUANTILE((TS_STD(TS_PCTCHANGE($close,1),20)),252,0.3))&&(TS_ZSCORE($volume,20)>0))?(RANK($close/(DELAY(TS_MAX($high,55),1)+1e-8)-1)+RANK(TS_ZSCORE($volume,20))-RANK(TS_STD(TS_PCTCHANGE($close,1),20))):0)\" # Your output factor expression will be filled in here\n    name = \"CleanTrend_Donchian55_VolCompress252_30_VolConfirm20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Trend-continuation signal for 'clean price discovery': activates on 55D Donchian breakout with volatility compression (bottom 30% of 252D realized vol rank) and 20D volume confirmation. Scores higher for larger breakout distance and stronger volume, penalized by short-term volatility.",
      "factor_formulation": "F_t=\\mathbf{1}[Close_t\\ge \\max_{55}(High)\\wedge TSRANK_{252}(\\sigma_{20})<0.30\\wedge Z20(Vol)>0]\\cdot\\left(\\operatorname{rank}\\left(\\frac{Close}{\\max_{55}(High)}-1\\right)+\\operatorname{rank}(Z20(Vol)) - \\operatorname{rank}(\\sigma_{20})\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "247a5cbd20e9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are generated by a stock-level regime switch between (A) “clean trend” price discovery, where volatility-compressed and volume-confirmed 55-day Donchian breakouts exhibit continuation, and (B) “illiquid shock/forced-flow” price pressure, where an extreme 1-day move on abnormally low dollar volume (high Amihud-illiquidity shock) partially mean-reverts over the next 1–5 days, with stronger reversion when the stock is a 60-day loser; a single factor that enforces mutually exclusive regime gating (priority to shock-reversion over breakout-trend) should improve predictive RankIC and reduce whipsaw/tail-risk relative to using either engine alone.\n                Concise Observation: The available daily OHLCV data supports constructing (i) Amihud-style illiquidity shocks from close-to-close returns and dollar volume, (ii) 55D Donchian breakout states from highs/closes, (iii) volatility compression from rolling realized volatility/ATR proxies, and (iv) loser context from 60D ROC, enabling a testable regime-exclusive fusion factor within a single daily cross-sectional table.\n                Concise Justification: A regime-exclusive allocator reduces contradictory exposures by only trend-following when price discovery is liquid and stable (vol-compressed + volume-confirmed breakouts) while fading moves that are statistically consistent with transient impact (extreme return + high illiquidity), and the loser-condition intensifies the contrarian edge by targeting names where forced-flow and gap-like discovery are more prevalent.\n                Concise Knowledge: If a large 1-day return occurs with unusually low dollar volume (high |r1|/$vol relative to its own history), then the move is more likely dominated by temporary liquidity/price-impact pressure and mean-reverts over 1–5 days; when volatility is compressed and price breaks a long lookback channel high with concurrent volume expansion, then the breakout is more likely information-driven and continues over a medium horizon; conditioning reversion signals on structural weakness (e.g., negative 60D ROC) increases the likelihood that shocks are flow-driven rather than fundamental.\n                concise Specification: Define daily inputs per instrument: r1=close/close(-1)-1; dollar_vol=close*volume; Amihud=abs(r1)/dollar_vol; z_Amihud=(Amihud-mean_60(Amihud))/std_60(Amihud); ret_extreme=abs(r1) > quantile_60(abs(r1),0.90); ROC60=close/close(-60)-1; Donchian55High=max_55(high); breakout=close>=Donchian55High; vol20=std_20(r1); vol_compress=vol20 < quantile_252(vol20,0.30); vol_expand_kill=vol20 > quantile_252(vol20,0.95); vol_confirm=z_20(dollar_vol)>0; Regime priority per day: (1) ShockRevert if z_Amihud>=quantile_cs(z_Amihud,0.90) AND ret_extreme, with strength multiplied by (1+I[ROC60<0]); (2) CleanTrend if breakout AND vol_compress AND vol_confirm; else neutral; Signal: if ShockRevert then score= -sign(r1)*z_Amihud*(1+I[ROC60<0]); if CleanTrend then score= +rank_cs((close/Donchian55High)-1)*rank_cs(z_20(dollar_vol)) - rank_cs(vol20); apply kill-switch: set score=0 when z_Amihud>=quantile_cs(z_Amihud,0.99) OR vol_expand_kill; final factor is cross-sectionally z-scored score each day for model input.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T04:23:48.465297"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1192431536734259,
        "ICIR": 0.0571613695148931,
        "1day.excess_return_without_cost.std": 0.0041039939467453,
        "1day.excess_return_with_cost.annualized_return": 0.027456752356365,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000313126396925,
        "1day.excess_return_without_cost.annualized_return": 0.0745240824681589,
        "1day.excess_return_with_cost.std": 0.0041034842803208,
        "Rank IC": 0.0237532984719519,
        "IC": 0.0074791429112698,
        "1day.excess_return_without_cost.max_drawdown": -0.1061838337194696,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1770677144511477,
        "1day.pa": 0.0,
        "l2.valid": 0.9964059745527934,
        "Rank ICIR": 0.1880262200093975,
        "l2.train": 0.9936311238119204,
        "1day.excess_return_with_cost.information_ratio": 0.4337184669963861,
        "1day.excess_return_with_cost.mean": 0.000115364505699
      },
      "feedback": {
        "observations": "Only one factor was implemented/tested in this run: CleanTrend_Donchian55_VolCompress252_30_VolConfirm20. The shock-reversion engine and the regime-exclusive gating factor (shock-priority) were not implemented, so the key “mutually exclusive regime gating” claim cannot be directly validated yet.\n\nPerformance vs SOTA:\n- Annualized return: 0.074524 vs 0.052010 (improves; bigger is better)\n- Information ratio: 1.177068 vs 0.972561 (improves)\n- IC: 0.007479 vs 0.005798 (improves)\n- Max drawdown: -0.106184 vs -0.072585 (worsens; smaller magnitude is better)\n\nInterpretation: the implemented “clean trend” breakout signal improves return efficiency (IR) and predictive correlation (IC), but it increases tail risk/whipsaw exposure as seen in the deeper drawdown. This pattern is consistent with an ungated trend/breakout factor that performs well on average but suffers in adverse regimes—exactly what the hypothesis claims regime gating should mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but cannot confirm the central mechanism.\n\nWhat is supported:\n- The trend component (“clean price discovery” via Donchian breakout + vol compression + volume confirmation) appears to add alpha: higher IC, higher annualized return, higher IR than SOTA.\n\nWhat is not yet tested / not supported directly:\n- The hypothesis’ core claim is that a single factor with mutually exclusive regime gating (shock-reversion priority over trend) should improve RankIC and reduce whipsaw/tail-risk relative to using either engine alone. Since neither (a) the shock-reversion factor nor (b) the regime gate were implemented, we cannot evaluate whether gating reduces drawdown or improves robustness.\n\nRisk takeaway:\n- The worsened max drawdown is a strong signal that the missing “shock/illiquid pressure” regime handling is important. Next iteration should prioritize implementing the regime gate and/or incorporating shock-priority suppression of trend signals during illiquidity spikes.",
        "decision": true,
        "reason": "Why the current outcome points here:\n- CleanTrend improved IC/IR/return but worsened max drawdown, suggesting regime-dependent failure modes.\n- Hard binary conditions (e.g., breakout AND vol-rank<0.30 AND Z20(vol)>0) can create sparse exposure and abrupt on/off switching, which often amplifies drawdowns when conditions flip.\n- A continuous gating weight (e.g., w_shock in [0,1]) allows the factor to progressively suppress trend exposure as shock likelihood rises, which is aligned with the hypothesis’ “priority to shock-reversion over breakout-trend” while avoiding brittle thresholds.\n\nConcrete refinement directions (staying within the same theoretical framework):\n1) Implement the missing shock engine exactly as specified (hyperparameters explicitly):\n   - Amihud_t = |r_t| / (Close_t * Vol_t)\n   - Z-score window: 60 (TS_ZSCORE(Amihud, 60))\n   - Extreme move filter: TS_RANK(|r_t|, 60) > 54 (i.e., top 10% of last 60)\n   - Shock threshold: Z60(Amihud) > 2\n   - Loser boost lookback: ROC60 < 0, multiplier (1 + 1[ROC60<0]) = 1x or 2x\n   - Output: (-sign(r_t)) * Z60(Amihud) * (1 + 1[ROC60<0]) under the joint shock conditions, else 0\n\n2) Implement the regime-exclusive gate (hyperparameters explicitly):\n   - Kill-switch: TS_RANK(Amihud, 60) > 59 => factor = 0\n   - Shock-reversion priority: TS_RANK(Amihud, 60) > 54 => factor = -sign(r_t)\n   - Trend branch requires ALL:\n     * Breakout window: 55 (Close >= TS_MAX(High, 55))\n     * Volatility compression: TS_RANK(sigma20, 252) < 0.30 where sigma20 = TS_STD(return, 20)\n     * Volume filter: TS_RANK(Vol, 20) > 10\n     * Trend score: RANK(Close/TS_MAX(High,55) - 1)\n   - Else: 0\n\n3) Parameter sensitivity to explore next (define as separate factors per your rule):\n   - Donchian breakout window: 20 / 55 / 120\n   - Vol-compression window: 126 / 252 / 504\n   - Realized vol window inside compression: 10 / 20 / 40 days (sigma_n)\n   - Volume confirmation: Z-score window 10 / 20 / 60 OR TS_RANK volume threshold > 8, 10, 12 (out of 20)\n   - Shock extremity: TS_RANK(|r|, 60) > 50, 54, 57 and/or Z60(Amihud) > 1.5, 2.0, 2.5\n   - Kill-switch strictness: top 1/60 (rank>59) vs top 2/60 (rank>58)\n\n4) Construction improvements to reduce drawdown without changing the concept:\n   - Replace some hard indicators with continuous scores (soft gates):\n     * Example: w_shock = clip((TS_RANK(Amihud,60)-54)/6, 0, 1); final = (1-w_shock)*TrendScore + w_shock*ShockScore, with kill-switch setting w_shock=0 and factor=0 at extreme tail.\n   - Robustness transforms: winsorize |r| and Amihud inputs (or use log(1+Amihud)) before z-score to reduce single-day outlier domination.\n   - Ensure cross-sectional comparability: if TrendScore uses RANK, consider also ranking/shaping shock branch (e.g., cross-sectional rank of shock intensity) so the combined factor has consistent cross-sectional distribution.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the regime-gate expression to remain short and interpretable (avoid stacking too many nested ranks/z-scores beyond the current set of windows: 20/55/60/252)."
      }
    },
    "d45fa2e8450f590a": {
      "factor_id": "d45fa2e8450f590a",
      "factor_name": "RegimeGate_ShockPriority_IlliqRank60_Breakout55",
      "factor_expression": "(TS_RANK(ABS($return)*INV($close*$volume+1e-8),60)>59)?0:((TS_RANK(ABS($return)*INV($close*$volume+1e-8),60)>54)?(-SIGN($return)):((($close>=TS_MAX($high,55))&&(TS_RANK(TS_STD($return,20),252)<76)&&(TS_RANK($volume,20)>10))?RANK($close/(TS_MAX($high,55)+1e-8)-1):0))",
      "factor_implementation_code": "",
      "factor_description": "Single-factor regime-exclusive gate with priority to shock-reversion: (1) kill-switch when illiquidity shock is extremely high (top ~1/60), (2) otherwise fade direction on illiquidity-shock days (top decile), (3) else follow 55D breakout only when volatility is compressed and recent volume is not weak. Produces one daily scalar per instrument.",
      "factor_formulation": "F_t=\\begin{cases}0,& TSRANK_{60}(Amihud_t)>59\\\\-\\operatorname{sign}(r_t),& TSRANK_{60}(Amihud_t)>54\\\\\\operatorname{rank}(Close/\\max_{55}(High)-1),& Close\\ge\\max_{55}(High)\\wedge TSRANK_{252}(\\sigma_{20})<0.30\\wedge TSRANK_{20}(Vol)>10\\\\0,&\\text{else}\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "247a5cbd20e9",
        "parent_trajectory_ids": [
          "fc3a5610d683",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are generated by a stock-level regime switch between (A) “clean trend” price discovery, where volatility-compressed and volume-confirmed 55-day Donchian breakouts exhibit continuation, and (B) “illiquid shock/forced-flow” price pressure, where an extreme 1-day move on abnormally low dollar volume (high Amihud-illiquidity shock) partially mean-reverts over the next 1–5 days, with stronger reversion when the stock is a 60-day loser; a single factor that enforces mutually exclusive regime gating (priority to shock-reversion over breakout-trend) should improve predictive RankIC and reduce whipsaw/tail-risk relative to using either engine alone.\n                Concise Observation: The available daily OHLCV data supports constructing (i) Amihud-style illiquidity shocks from close-to-close returns and dollar volume, (ii) 55D Donchian breakout states from highs/closes, (iii) volatility compression from rolling realized volatility/ATR proxies, and (iv) loser context from 60D ROC, enabling a testable regime-exclusive fusion factor within a single daily cross-sectional table.\n                Concise Justification: A regime-exclusive allocator reduces contradictory exposures by only trend-following when price discovery is liquid and stable (vol-compressed + volume-confirmed breakouts) while fading moves that are statistically consistent with transient impact (extreme return + high illiquidity), and the loser-condition intensifies the contrarian edge by targeting names where forced-flow and gap-like discovery are more prevalent.\n                Concise Knowledge: If a large 1-day return occurs with unusually low dollar volume (high |r1|/$vol relative to its own history), then the move is more likely dominated by temporary liquidity/price-impact pressure and mean-reverts over 1–5 days; when volatility is compressed and price breaks a long lookback channel high with concurrent volume expansion, then the breakout is more likely information-driven and continues over a medium horizon; conditioning reversion signals on structural weakness (e.g., negative 60D ROC) increases the likelihood that shocks are flow-driven rather than fundamental.\n                concise Specification: Define daily inputs per instrument: r1=close/close(-1)-1; dollar_vol=close*volume; Amihud=abs(r1)/dollar_vol; z_Amihud=(Amihud-mean_60(Amihud))/std_60(Amihud); ret_extreme=abs(r1) > quantile_60(abs(r1),0.90); ROC60=close/close(-60)-1; Donchian55High=max_55(high); breakout=close>=Donchian55High; vol20=std_20(r1); vol_compress=vol20 < quantile_252(vol20,0.30); vol_expand_kill=vol20 > quantile_252(vol20,0.95); vol_confirm=z_20(dollar_vol)>0; Regime priority per day: (1) ShockRevert if z_Amihud>=quantile_cs(z_Amihud,0.90) AND ret_extreme, with strength multiplied by (1+I[ROC60<0]); (2) CleanTrend if breakout AND vol_compress AND vol_confirm; else neutral; Signal: if ShockRevert then score= -sign(r1)*z_Amihud*(1+I[ROC60<0]); if CleanTrend then score= +rank_cs((close/Donchian55High)-1)*rank_cs(z_20(dollar_vol)) - rank_cs(vol20); apply kill-switch: set score=0 when z_Amihud>=quantile_cs(z_Amihud,0.99) OR vol_expand_kill; final factor is cross-sectionally z-scored score each day for model input.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T04:23:48.465297"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1192431536734259,
        "ICIR": 0.0571613695148931,
        "1day.excess_return_without_cost.std": 0.0041039939467453,
        "1day.excess_return_with_cost.annualized_return": 0.027456752356365,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000313126396925,
        "1day.excess_return_without_cost.annualized_return": 0.0745240824681589,
        "1day.excess_return_with_cost.std": 0.0041034842803208,
        "Rank IC": 0.0237532984719519,
        "IC": 0.0074791429112698,
        "1day.excess_return_without_cost.max_drawdown": -0.1061838337194696,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1770677144511477,
        "1day.pa": 0.0,
        "l2.valid": 0.9964059745527934,
        "Rank ICIR": 0.1880262200093975,
        "l2.train": 0.9936311238119204,
        "1day.excess_return_with_cost.information_ratio": 0.4337184669963861,
        "1day.excess_return_with_cost.mean": 0.000115364505699
      },
      "feedback": {
        "observations": "Only one factor was implemented/tested in this run: CleanTrend_Donchian55_VolCompress252_30_VolConfirm20. The shock-reversion engine and the regime-exclusive gating factor (shock-priority) were not implemented, so the key “mutually exclusive regime gating” claim cannot be directly validated yet.\n\nPerformance vs SOTA:\n- Annualized return: 0.074524 vs 0.052010 (improves; bigger is better)\n- Information ratio: 1.177068 vs 0.972561 (improves)\n- IC: 0.007479 vs 0.005798 (improves)\n- Max drawdown: -0.106184 vs -0.072585 (worsens; smaller magnitude is better)\n\nInterpretation: the implemented “clean trend” breakout signal improves return efficiency (IR) and predictive correlation (IC), but it increases tail risk/whipsaw exposure as seen in the deeper drawdown. This pattern is consistent with an ungated trend/breakout factor that performs well on average but suffers in adverse regimes—exactly what the hypothesis claims regime gating should mitigate.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but cannot confirm the central mechanism.\n\nWhat is supported:\n- The trend component (“clean price discovery” via Donchian breakout + vol compression + volume confirmation) appears to add alpha: higher IC, higher annualized return, higher IR than SOTA.\n\nWhat is not yet tested / not supported directly:\n- The hypothesis’ core claim is that a single factor with mutually exclusive regime gating (shock-reversion priority over trend) should improve RankIC and reduce whipsaw/tail-risk relative to using either engine alone. Since neither (a) the shock-reversion factor nor (b) the regime gate were implemented, we cannot evaluate whether gating reduces drawdown or improves robustness.\n\nRisk takeaway:\n- The worsened max drawdown is a strong signal that the missing “shock/illiquid pressure” regime handling is important. Next iteration should prioritize implementing the regime gate and/or incorporating shock-priority suppression of trend signals during illiquidity spikes.",
        "decision": true,
        "reason": "Why the current outcome points here:\n- CleanTrend improved IC/IR/return but worsened max drawdown, suggesting regime-dependent failure modes.\n- Hard binary conditions (e.g., breakout AND vol-rank<0.30 AND Z20(vol)>0) can create sparse exposure and abrupt on/off switching, which often amplifies drawdowns when conditions flip.\n- A continuous gating weight (e.g., w_shock in [0,1]) allows the factor to progressively suppress trend exposure as shock likelihood rises, which is aligned with the hypothesis’ “priority to shock-reversion over breakout-trend” while avoiding brittle thresholds.\n\nConcrete refinement directions (staying within the same theoretical framework):\n1) Implement the missing shock engine exactly as specified (hyperparameters explicitly):\n   - Amihud_t = |r_t| / (Close_t * Vol_t)\n   - Z-score window: 60 (TS_ZSCORE(Amihud, 60))\n   - Extreme move filter: TS_RANK(|r_t|, 60) > 54 (i.e., top 10% of last 60)\n   - Shock threshold: Z60(Amihud) > 2\n   - Loser boost lookback: ROC60 < 0, multiplier (1 + 1[ROC60<0]) = 1x or 2x\n   - Output: (-sign(r_t)) * Z60(Amihud) * (1 + 1[ROC60<0]) under the joint shock conditions, else 0\n\n2) Implement the regime-exclusive gate (hyperparameters explicitly):\n   - Kill-switch: TS_RANK(Amihud, 60) > 59 => factor = 0\n   - Shock-reversion priority: TS_RANK(Amihud, 60) > 54 => factor = -sign(r_t)\n   - Trend branch requires ALL:\n     * Breakout window: 55 (Close >= TS_MAX(High, 55))\n     * Volatility compression: TS_RANK(sigma20, 252) < 0.30 where sigma20 = TS_STD(return, 20)\n     * Volume filter: TS_RANK(Vol, 20) > 10\n     * Trend score: RANK(Close/TS_MAX(High,55) - 1)\n   - Else: 0\n\n3) Parameter sensitivity to explore next (define as separate factors per your rule):\n   - Donchian breakout window: 20 / 55 / 120\n   - Vol-compression window: 126 / 252 / 504\n   - Realized vol window inside compression: 10 / 20 / 40 days (sigma_n)\n   - Volume confirmation: Z-score window 10 / 20 / 60 OR TS_RANK volume threshold > 8, 10, 12 (out of 20)\n   - Shock extremity: TS_RANK(|r|, 60) > 50, 54, 57 and/or Z60(Amihud) > 1.5, 2.0, 2.5\n   - Kill-switch strictness: top 1/60 (rank>59) vs top 2/60 (rank>58)\n\n4) Construction improvements to reduce drawdown without changing the concept:\n   - Replace some hard indicators with continuous scores (soft gates):\n     * Example: w_shock = clip((TS_RANK(Amihud,60)-54)/6, 0, 1); final = (1-w_shock)*TrendScore + w_shock*ShockScore, with kill-switch setting w_shock=0 and factor=0 at extreme tail.\n   - Robustness transforms: winsorize |r| and Amihud inputs (or use log(1+Amihud)) before z-score to reduce single-day outlier domination.\n   - Ensure cross-sectional comparability: if TrendScore uses RANK, consider also ranking/shaping shock branch (e.g., cross-sectional rank of shock intensity) so the combined factor has consistent cross-sectional distribution.\n\nComplexity control:\n- No explicit complexity warnings were provided. Still, prefer the regime-gate expression to remain short and interpretable (avoid stacking too many nested ranks/z-scores beyond the current set of windows: 20/55/60/252)."
      }
    },
    "0878afcca3886b07": {
      "factor_id": "0878afcca3886b07",
      "factor_name": "CoilCompression_BreakoutBias_55D",
      "factor_expression": "TS_ZSCORE($close/(TS_MAX($high,55)+1e-8)-1,126)*(LOG(TS_STD($return,60)+1e-8)-LOG(TS_STD($return,10)+1e-8))*(1-ABS($open-DELAY($close,1))/($high-$low+1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close/(TS_MAX($high,55)+1e-8)-1,126)*(LOG(TS_STD(TS_PCTCHANGE($close,1),60)+1e-8)-LOG(TS_STD(TS_PCTCHANGE($close,1),10)+1e-8))*MAX(1-ABS($open-DELAY($close,1))/($high-$low+1e-8),0)\" # Your output factor expression will be filled in here\n    name = \"CoilCompression_BreakoutBias_55D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Breakout-continuation proxy that rewards (i) stronger relative position vs 55D channel, (ii) volatility compression (60D vol >> 10D vol), and (iii) orderly discovery (small overnight gap vs intraday range). Hyperparameters: Donchian lookback=55; vol windows=10,60; zscore window=126.",
      "factor_formulation": "F_t=Z_{126}(\\frac{C_t}{\\max(H,55)}-1)\\cdot\\big(\\ln(\\sigma_{60}(r)+\\epsilon)-\\ln(\\sigma_{10}(r)+\\epsilon)\\big)\\cdot\\Big(1-\\frac{|O_t-C_{t-1}|}{H_t-L_t+\\epsilon}\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "4a7c1426a43b",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A regime-router factor that (i) scores trend-continuation only when a stock exits a volatility-compression “coil” via a 55D Donchian breakout with strong close-location and orderly (non-gap-dominated), stable participation, and (ii) otherwise scores short-horizon mean-reversion only within 60D losers when selloff stress is characterized by unstable volume + large overnight gaps but shows intraday absorption (close off lows) and is not a fresh breakdown to new lows with expanding range; this conditional fusion should produce more consistent next-3-to-10D and next-10-to-60D return predictability than either standalone breakout or loser-reversion signals.\n                Concise Observation: With only daily OHLCV available, coil quality (ATR10 vs ATR60 and its 252D percentile), breakout structure (Close vs 55D High), gap-dominance (|Open/PrevClose−1| vs true range), volume instability (MAD of Δlog(Volume)), and absorption (CLV) are all directly measurable, enabling an explicit router that avoids the common failure mode of additive blending where trend and reversion signals conflict on the same day.\n                Concise Justification: The breakout sleeve targets orderly information diffusion after compression (reducing false breakouts driven by gaps/noisy participation), while the loser-stress sleeve targets transient liquidity shocks inside structurally weak names but blocks knife-catching by requiring absorption and forbidding simultaneous new-low breakdowns with rising range volatility; a conditional router should reduce drawdowns from chasing noisy breakouts and from buying true trend collapses.\n                Concise Knowledge: If volatility contraction precedes a channel breakout and the breakout day’s price discovery is continuous (small overnight gap share) with stable volume dynamics and a strong close within the day’s range, continuation over the next several weeks is more likely; when long-horizon momentum is negative, a selloff dominated by overnight gaps and erratic volume can indicate forced-flow liquidation that mean-reverts only if intraday absorption is visible and the move is not simultaneously confirming a new-low breakdown with accelerating true-range volatility.\n                concise Specification: Universe: daily OHLCV per instrument; compute TrueRange_t=max(High−Low,|High−PrevClose|,|Low−PrevClose|), ATR10=SMA(TrueRange,10), ATR60=SMA(TrueRange,60), CoilFlag=1 if (ATR10/ATR60) is in bottom 10% of its trailing 252D history; BreakoutFlag=1 if Close_t>rolling_max(High,55) and CLV_t=((Close−Low)−(High−Close))/(High−Low)≥0.6; ParticipationClean=1 if GapShare=|Open/PrevClose−1|/(TrueRange/PrevClose)≤0.35 and VolInstability=MAD(Δlog(Volume),20)≤median(MAD(Δlog(Volume),20) over trailing 252D); TrendScore= zscore(Close/rolling_max(High,55)−1,252) * CLV_t if CoilFlag&BreakoutFlag&ParticipationClean else 0; LoserRegime=1 if ROC60=Close/Close.shift(60)−1<0; StressFlag=1 if VolInstability is in top 20% of trailing 252D and GapShare≥0.5; AbsorptionFlag=1 if CLV_t≥0.2; BreakdownExclusion=1 if Low_t≤rolling_min(Low,20) and (ATR10/ATR60) in top 30% of trailing 252D; MeanRevScore= −zscore((Close/Close.shift(5)−1),252) * CLV_t if LoserRegime&StressFlag&AbsorptionFlag&(~BreakdownExclusion) else 0; RouterFactor = TrendScore if TrendScore≠0 else MeanRevScore (else 0), producing one daily factor value per instrument.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:29:55.167486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1390277056132401,
        "ICIR": 0.0387471637226642,
        "1day.excess_return_without_cost.std": 0.0042716819027007,
        "1day.excess_return_with_cost.annualized_return": 0.0288826852449576,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003198726404708,
        "1day.excess_return_without_cost.annualized_return": 0.0761296884320608,
        "1day.excess_return_with_cost.std": 0.004272770138916,
        "Rank IC": 0.024027126717325,
        "IC": 0.0054540553029527,
        "1day.excess_return_without_cost.max_drawdown": -0.1207304730046944,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1552252400472094,
        "1day.pa": 0.0,
        "l2.valid": 0.9963896104925783,
        "Rank ICIR": 0.1766832524702683,
        "l2.train": 0.9935837974575856,
        "1day.excess_return_with_cost.information_ratio": 0.4381668920462046,
        "1day.excess_return_with_cost.mean": 0.0001213558203569
      },
      "feedback": {
        "observations": "The combined experiment improves risk-adjusted performance and raw return versus SOTA (Information Ratio 1.155 > 0.973; Annualized Return 0.0761 > 0.0520), but deteriorates on tail risk and slightly on pure predictiveness (Max Drawdown -0.1207 is worse than -0.0726; IC 0.00545 < 0.00580). This pattern is consistent with the signals occasionally entering high-adversity regimes (large gaps / unstable participation) where the strategy experiences deeper equity troughs, even though average returns improved.\n\nImportant constraint: the core “regime-router” part of the hypothesis is not fully testable in this run because the routing/stress discriminator factor (VolumeInstability_x_GapShare_20D) was not implemented, and the current setup appears closer to “multi-signal input to the model” rather than an explicit conditional fusion/gating mechanism.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not conclusively validate it.\n\nWhat is supported:\n- The idea that combining a breakout-continuation proxy with a loser-gap/absorption mean-reversion proxy can improve portfolio-level outcomes is supported by the higher annualized return and higher information ratio than SOTA.\n\nWhat is not validated (and likely explains the worse drawdown / weaker IC):\n- The hypothesis specifically claims a conditional fusion (“route to trend only when orderly breakout; otherwise route to MR under gap-stress with absorption”). Without implementing the VolumeInstability_x_GapShare_20D discriminator and without an explicit gating formula, the model may be mixing the two regimes imperfectly, allowing breakout exposure during gap-dominated forced-flow periods (or applying MR in fresh-breakdown states), which can increase drawdown.\n\nMetric-level interpretation vs SOTA:\n- Annualized return: improved materially (good).\n- Information ratio: improved (good).\n- Max drawdown: meaningfully worse (bad; suggests regime misclassification / adverse selection during stress).\n- IC: slightly worse (suggests the added return may be coming from nonlinear interactions/portfolio construction effects rather than cleaner pointwise predictiveness).",
        "decision": true,
        "reason": "1) Why drawdown worsened despite better IR/return:\n- The breakout factor already penalizes gaps via (1 - |O-C_{t-1}|/(H-L)), but this is a soft penalty and can still leave the strategy exposed during discontinuous moves.\n- The MR factor activates on gap-dominance and losers, but it lacks an explicit ‘not a fresh breakdown’ filter beyond ROC60<0 and a 5D z-score. That can still trigger early catching of falling knives when the selloff is expanding in range / making new lows.\n\n2) What to implement next (within the same framework, with explicit hyperparameters):\n- Implement VolumeInstability_x_GapShare_20D exactly as specified (volume baseline=20; instability window=20; zscore window=252). This is the missing router component.\n- Create one *single* regime-routed composite factor (static definition) instead of relying on the model to learn the routing:\n  - Gate variables (all fully specified):\n    - gap_share_t = |O_t - C_{t-1}| / (H_t - L_t + eps)\n    - vol_instab_t = STD_{20}( V / (MEAN_{20}(V)+eps) )\n    - stress_z_t = Z_{252}( gap_share_t * vol_instab_t )\n  - Breakout gate (orderly discovery):\n    - I_breakout = 1[ C_t >= TS_MAX(H,55) * (1 - bbuf) ] * 1[ stress_z_t < s_low ]\n    - Hyperparameters to sweep (start tight, then widen): bbuf ∈ {0.00, 0.01}; s_low ∈ {-0.5, 0.0, 0.5}\n  - MR gate (forced-flow + absorption, but not fresh breakdown):\n    - I_mr = 1[ROC_{60}(C)<0] * 1[ gap_share_t > 0.6 ] * 1[ C_t > TS_MIN(L, n_low) * (1 + lbuf) ] * 1[ stress_z_t > s_high ]\n    - Hyperparameters to sweep: n_low ∈ {20, 55}; lbuf ∈ {0.00, 0.01}; s_high ∈ {0.0, 0.5, 1.0}\n  - Composite output (single factor):\n    - F = I_breakout * CoilCompression_BreakoutBias_55D  +  I_mr * LoserGapStress_AbsorptionMR_5D\n    - This directly tests the hypothesis’ conditional fusion.\n\n3) Parameter sensitivity / refinements to explore next (keep expressions short):\n- Donchian lookback: 20/55/100 (separate factors; do not overload one factor).\n- Vol compression: compare (60 vs 10), (120 vs 20), (40 vs 10). The current log(σ60)-log(σ10) may be too noisy for some names.\n- MR horizon: 3D, 5D, 10D versions (separate factors) to match the stated 3–10D target.\n- Gap threshold: 0.4/0.6/0.8 (separate MR factors) to tune “gap-dominated” definition.\n- Add a minimal “range expansion” avoidance term for MR using only existing OHLC (no extra base features): e.g., block MR when (H-L) / MEAN_{20}(H-L) is above a threshold; thresholds to test: 1.5, 2.0.\n\n4) Complexity control:\n- No explicit complexity warnings were provided, and the formulas are reasonably compact with few base features (OHLCV). Keep the next iteration similarly simple: avoid adding many extra conditions; prefer 1–2 gates + 2 core signals.\n\n5) Evaluation suggestion aligned with observed metrics:\n- Because max drawdown worsened, prioritize gating changes that explicitly suppress signals during high stress_z regimes for breakouts and suppress MR during fresh-breakdown/expanding-range regimes. This is the most direct lever to improve MDD without sacrificing too much return."
      }
    },
    "4f4c2021663a2061": {
      "factor_id": "4f4c2021663a2061",
      "factor_name": "LoserGapStress_AbsorptionMR_5D",
      "factor_expression": "(TS_PCTCHANGE($close,60)<0&&ABS($open-DELAY($close,1))/($high-$low+1e-8)>0.6)?(-TS_ZSCORE(TS_PCTCHANGE($close,5),252)*(2*$close-$high-$low)/($high-$low+1e-8)):0",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close,60)<0&&ABS($open-DELAY($close,1))/($high-$low+1e-8)>0.6)?(-TS_ZSCORE(TS_PCTCHANGE($close,5),252)*(2*$close-$high-$low)/($high-$low+1e-8)):0\" # Your output factor expression will be filled in here\n    name = \"LoserGapStress_AbsorptionMR_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Conditional mean-reversion proxy inside long-horizon losers: only active when 60D return is negative and the move is gap-dominated (overnight gap large vs intraday range). Signal strength is 5D selloff z-score times intraday absorption (close high in range). Hyperparameters: loser lookback=60; gap threshold=0.6; MR horizon=5; zscore window=252.",
      "factor_formulation": "F_t=\\mathbf{1}[\\text{ROC}_{60}(C)<0]\\,\\mathbf{1}[\\frac{|O_t-C_{t-1}|}{H_t-L_t+\\epsilon}>0.6]\\cdot\\Big(-Z_{252}(\\text{ROC}_5(C))\\Big)\\cdot\\frac{2C_t-H_t-L_t}{H_t-L_t+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "4a7c1426a43b",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A regime-router factor that (i) scores trend-continuation only when a stock exits a volatility-compression “coil” via a 55D Donchian breakout with strong close-location and orderly (non-gap-dominated), stable participation, and (ii) otherwise scores short-horizon mean-reversion only within 60D losers when selloff stress is characterized by unstable volume + large overnight gaps but shows intraday absorption (close off lows) and is not a fresh breakdown to new lows with expanding range; this conditional fusion should produce more consistent next-3-to-10D and next-10-to-60D return predictability than either standalone breakout or loser-reversion signals.\n                Concise Observation: With only daily OHLCV available, coil quality (ATR10 vs ATR60 and its 252D percentile), breakout structure (Close vs 55D High), gap-dominance (|Open/PrevClose−1| vs true range), volume instability (MAD of Δlog(Volume)), and absorption (CLV) are all directly measurable, enabling an explicit router that avoids the common failure mode of additive blending where trend and reversion signals conflict on the same day.\n                Concise Justification: The breakout sleeve targets orderly information diffusion after compression (reducing false breakouts driven by gaps/noisy participation), while the loser-stress sleeve targets transient liquidity shocks inside structurally weak names but blocks knife-catching by requiring absorption and forbidding simultaneous new-low breakdowns with rising range volatility; a conditional router should reduce drawdowns from chasing noisy breakouts and from buying true trend collapses.\n                Concise Knowledge: If volatility contraction precedes a channel breakout and the breakout day’s price discovery is continuous (small overnight gap share) with stable volume dynamics and a strong close within the day’s range, continuation over the next several weeks is more likely; when long-horizon momentum is negative, a selloff dominated by overnight gaps and erratic volume can indicate forced-flow liquidation that mean-reverts only if intraday absorption is visible and the move is not simultaneously confirming a new-low breakdown with accelerating true-range volatility.\n                concise Specification: Universe: daily OHLCV per instrument; compute TrueRange_t=max(High−Low,|High−PrevClose|,|Low−PrevClose|), ATR10=SMA(TrueRange,10), ATR60=SMA(TrueRange,60), CoilFlag=1 if (ATR10/ATR60) is in bottom 10% of its trailing 252D history; BreakoutFlag=1 if Close_t>rolling_max(High,55) and CLV_t=((Close−Low)−(High−Close))/(High−Low)≥0.6; ParticipationClean=1 if GapShare=|Open/PrevClose−1|/(TrueRange/PrevClose)≤0.35 and VolInstability=MAD(Δlog(Volume),20)≤median(MAD(Δlog(Volume),20) over trailing 252D); TrendScore= zscore(Close/rolling_max(High,55)−1,252) * CLV_t if CoilFlag&BreakoutFlag&ParticipationClean else 0; LoserRegime=1 if ROC60=Close/Close.shift(60)−1<0; StressFlag=1 if VolInstability is in top 20% of trailing 252D and GapShare≥0.5; AbsorptionFlag=1 if CLV_t≥0.2; BreakdownExclusion=1 if Low_t≤rolling_min(Low,20) and (ATR10/ATR60) in top 30% of trailing 252D; MeanRevScore= −zscore((Close/Close.shift(5)−1),252) * CLV_t if LoserRegime&StressFlag&AbsorptionFlag&(~BreakdownExclusion) else 0; RouterFactor = TrendScore if TrendScore≠0 else MeanRevScore (else 0), producing one daily factor value per instrument.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:29:55.167486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1390277056132401,
        "ICIR": 0.0387471637226642,
        "1day.excess_return_without_cost.std": 0.0042716819027007,
        "1day.excess_return_with_cost.annualized_return": 0.0288826852449576,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003198726404708,
        "1day.excess_return_without_cost.annualized_return": 0.0761296884320608,
        "1day.excess_return_with_cost.std": 0.004272770138916,
        "Rank IC": 0.024027126717325,
        "IC": 0.0054540553029527,
        "1day.excess_return_without_cost.max_drawdown": -0.1207304730046944,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1552252400472094,
        "1day.pa": 0.0,
        "l2.valid": 0.9963896104925783,
        "Rank ICIR": 0.1766832524702683,
        "l2.train": 0.9935837974575856,
        "1day.excess_return_with_cost.information_ratio": 0.4381668920462046,
        "1day.excess_return_with_cost.mean": 0.0001213558203569
      },
      "feedback": {
        "observations": "The combined experiment improves risk-adjusted performance and raw return versus SOTA (Information Ratio 1.155 > 0.973; Annualized Return 0.0761 > 0.0520), but deteriorates on tail risk and slightly on pure predictiveness (Max Drawdown -0.1207 is worse than -0.0726; IC 0.00545 < 0.00580). This pattern is consistent with the signals occasionally entering high-adversity regimes (large gaps / unstable participation) where the strategy experiences deeper equity troughs, even though average returns improved.\n\nImportant constraint: the core “regime-router” part of the hypothesis is not fully testable in this run because the routing/stress discriminator factor (VolumeInstability_x_GapShare_20D) was not implemented, and the current setup appears closer to “multi-signal input to the model” rather than an explicit conditional fusion/gating mechanism.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not conclusively validate it.\n\nWhat is supported:\n- The idea that combining a breakout-continuation proxy with a loser-gap/absorption mean-reversion proxy can improve portfolio-level outcomes is supported by the higher annualized return and higher information ratio than SOTA.\n\nWhat is not validated (and likely explains the worse drawdown / weaker IC):\n- The hypothesis specifically claims a conditional fusion (“route to trend only when orderly breakout; otherwise route to MR under gap-stress with absorption”). Without implementing the VolumeInstability_x_GapShare_20D discriminator and without an explicit gating formula, the model may be mixing the two regimes imperfectly, allowing breakout exposure during gap-dominated forced-flow periods (or applying MR in fresh-breakdown states), which can increase drawdown.\n\nMetric-level interpretation vs SOTA:\n- Annualized return: improved materially (good).\n- Information ratio: improved (good).\n- Max drawdown: meaningfully worse (bad; suggests regime misclassification / adverse selection during stress).\n- IC: slightly worse (suggests the added return may be coming from nonlinear interactions/portfolio construction effects rather than cleaner pointwise predictiveness).",
        "decision": true,
        "reason": "1) Why drawdown worsened despite better IR/return:\n- The breakout factor already penalizes gaps via (1 - |O-C_{t-1}|/(H-L)), but this is a soft penalty and can still leave the strategy exposed during discontinuous moves.\n- The MR factor activates on gap-dominance and losers, but it lacks an explicit ‘not a fresh breakdown’ filter beyond ROC60<0 and a 5D z-score. That can still trigger early catching of falling knives when the selloff is expanding in range / making new lows.\n\n2) What to implement next (within the same framework, with explicit hyperparameters):\n- Implement VolumeInstability_x_GapShare_20D exactly as specified (volume baseline=20; instability window=20; zscore window=252). This is the missing router component.\n- Create one *single* regime-routed composite factor (static definition) instead of relying on the model to learn the routing:\n  - Gate variables (all fully specified):\n    - gap_share_t = |O_t - C_{t-1}| / (H_t - L_t + eps)\n    - vol_instab_t = STD_{20}( V / (MEAN_{20}(V)+eps) )\n    - stress_z_t = Z_{252}( gap_share_t * vol_instab_t )\n  - Breakout gate (orderly discovery):\n    - I_breakout = 1[ C_t >= TS_MAX(H,55) * (1 - bbuf) ] * 1[ stress_z_t < s_low ]\n    - Hyperparameters to sweep (start tight, then widen): bbuf ∈ {0.00, 0.01}; s_low ∈ {-0.5, 0.0, 0.5}\n  - MR gate (forced-flow + absorption, but not fresh breakdown):\n    - I_mr = 1[ROC_{60}(C)<0] * 1[ gap_share_t > 0.6 ] * 1[ C_t > TS_MIN(L, n_low) * (1 + lbuf) ] * 1[ stress_z_t > s_high ]\n    - Hyperparameters to sweep: n_low ∈ {20, 55}; lbuf ∈ {0.00, 0.01}; s_high ∈ {0.0, 0.5, 1.0}\n  - Composite output (single factor):\n    - F = I_breakout * CoilCompression_BreakoutBias_55D  +  I_mr * LoserGapStress_AbsorptionMR_5D\n    - This directly tests the hypothesis’ conditional fusion.\n\n3) Parameter sensitivity / refinements to explore next (keep expressions short):\n- Donchian lookback: 20/55/100 (separate factors; do not overload one factor).\n- Vol compression: compare (60 vs 10), (120 vs 20), (40 vs 10). The current log(σ60)-log(σ10) may be too noisy for some names.\n- MR horizon: 3D, 5D, 10D versions (separate factors) to match the stated 3–10D target.\n- Gap threshold: 0.4/0.6/0.8 (separate MR factors) to tune “gap-dominated” definition.\n- Add a minimal “range expansion” avoidance term for MR using only existing OHLC (no extra base features): e.g., block MR when (H-L) / MEAN_{20}(H-L) is above a threshold; thresholds to test: 1.5, 2.0.\n\n4) Complexity control:\n- No explicit complexity warnings were provided, and the formulas are reasonably compact with few base features (OHLCV). Keep the next iteration similarly simple: avoid adding many extra conditions; prefer 1–2 gates + 2 core signals.\n\n5) Evaluation suggestion aligned with observed metrics:\n- Because max drawdown worsened, prioritize gating changes that explicitly suppress signals during high stress_z regimes for breakouts and suppress MR during fresh-breakdown/expanding-range regimes. This is the most direct lever to improve MDD without sacrificing too much return."
      }
    },
    "1d036632f4c6930c": {
      "factor_id": "1d036632f4c6930c",
      "factor_name": "VolumeInstability_x_GapShare_20D",
      "factor_expression": "TS_ZSCORE(ABS($open-DELAY($close,1))/($high-$low+1e-8)*TS_STD($volume/(TS_MEAN($volume,20)+1e-8),20),252)",
      "factor_implementation_code": "",
      "factor_description": "Stress/participation-quality component: multiplies normalized overnight gap share by rolling volume instability (std of volume relative to its 20D mean), then standardizes over 252D. Useful for routing between orderly breakouts vs forced-flow selloffs. Hyperparameters: volume baseline=20; instability window=20; zscore window=252.",
      "factor_formulation": "F_t=Z_{252}\\Big(\\frac{|O_t-C_{t-1}|}{H_t-L_t+\\epsilon}\\cdot \\sigma_{20}(\\frac{V}{\\mu_{20}(V)+\\epsilon})\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "4a7c1426a43b",
        "parent_trajectory_ids": [
          "4b00349fb69f",
          "53a14cd60d04"
        ],
        "hypothesis": "Hypothesis: A regime-router factor that (i) scores trend-continuation only when a stock exits a volatility-compression “coil” via a 55D Donchian breakout with strong close-location and orderly (non-gap-dominated), stable participation, and (ii) otherwise scores short-horizon mean-reversion only within 60D losers when selloff stress is characterized by unstable volume + large overnight gaps but shows intraday absorption (close off lows) and is not a fresh breakdown to new lows with expanding range; this conditional fusion should produce more consistent next-3-to-10D and next-10-to-60D return predictability than either standalone breakout or loser-reversion signals.\n                Concise Observation: With only daily OHLCV available, coil quality (ATR10 vs ATR60 and its 252D percentile), breakout structure (Close vs 55D High), gap-dominance (|Open/PrevClose−1| vs true range), volume instability (MAD of Δlog(Volume)), and absorption (CLV) are all directly measurable, enabling an explicit router that avoids the common failure mode of additive blending where trend and reversion signals conflict on the same day.\n                Concise Justification: The breakout sleeve targets orderly information diffusion after compression (reducing false breakouts driven by gaps/noisy participation), while the loser-stress sleeve targets transient liquidity shocks inside structurally weak names but blocks knife-catching by requiring absorption and forbidding simultaneous new-low breakdowns with rising range volatility; a conditional router should reduce drawdowns from chasing noisy breakouts and from buying true trend collapses.\n                Concise Knowledge: If volatility contraction precedes a channel breakout and the breakout day’s price discovery is continuous (small overnight gap share) with stable volume dynamics and a strong close within the day’s range, continuation over the next several weeks is more likely; when long-horizon momentum is negative, a selloff dominated by overnight gaps and erratic volume can indicate forced-flow liquidation that mean-reverts only if intraday absorption is visible and the move is not simultaneously confirming a new-low breakdown with accelerating true-range volatility.\n                concise Specification: Universe: daily OHLCV per instrument; compute TrueRange_t=max(High−Low,|High−PrevClose|,|Low−PrevClose|), ATR10=SMA(TrueRange,10), ATR60=SMA(TrueRange,60), CoilFlag=1 if (ATR10/ATR60) is in bottom 10% of its trailing 252D history; BreakoutFlag=1 if Close_t>rolling_max(High,55) and CLV_t=((Close−Low)−(High−Close))/(High−Low)≥0.6; ParticipationClean=1 if GapShare=|Open/PrevClose−1|/(TrueRange/PrevClose)≤0.35 and VolInstability=MAD(Δlog(Volume),20)≤median(MAD(Δlog(Volume),20) over trailing 252D); TrendScore= zscore(Close/rolling_max(High,55)−1,252) * CLV_t if CoilFlag&BreakoutFlag&ParticipationClean else 0; LoserRegime=1 if ROC60=Close/Close.shift(60)−1<0; StressFlag=1 if VolInstability is in top 20% of trailing 252D and GapShare≥0.5; AbsorptionFlag=1 if CLV_t≥0.2; BreakdownExclusion=1 if Low_t≤rolling_min(Low,20) and (ATR10/ATR60) in top 30% of trailing 252D; MeanRevScore= −zscore((Close/Close.shift(5)−1),252) * CLV_t if LoserRegime&StressFlag&AbsorptionFlag&(~BreakdownExclusion) else 0; RouterFactor = TrendScore if TrendScore≠0 else MeanRevScore (else 0), producing one daily factor value per instrument.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:29:55.167486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1390277056132401,
        "ICIR": 0.0387471637226642,
        "1day.excess_return_without_cost.std": 0.0042716819027007,
        "1day.excess_return_with_cost.annualized_return": 0.0288826852449576,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003198726404708,
        "1day.excess_return_without_cost.annualized_return": 0.0761296884320608,
        "1day.excess_return_with_cost.std": 0.004272770138916,
        "Rank IC": 0.024027126717325,
        "IC": 0.0054540553029527,
        "1day.excess_return_without_cost.max_drawdown": -0.1207304730046944,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1552252400472094,
        "1day.pa": 0.0,
        "l2.valid": 0.9963896104925783,
        "Rank ICIR": 0.1766832524702683,
        "l2.train": 0.9935837974575856,
        "1day.excess_return_with_cost.information_ratio": 0.4381668920462046,
        "1day.excess_return_with_cost.mean": 0.0001213558203569
      },
      "feedback": {
        "observations": "The combined experiment improves risk-adjusted performance and raw return versus SOTA (Information Ratio 1.155 > 0.973; Annualized Return 0.0761 > 0.0520), but deteriorates on tail risk and slightly on pure predictiveness (Max Drawdown -0.1207 is worse than -0.0726; IC 0.00545 < 0.00580). This pattern is consistent with the signals occasionally entering high-adversity regimes (large gaps / unstable participation) where the strategy experiences deeper equity troughs, even though average returns improved.\n\nImportant constraint: the core “regime-router” part of the hypothesis is not fully testable in this run because the routing/stress discriminator factor (VolumeInstability_x_GapShare_20D) was not implemented, and the current setup appears closer to “multi-signal input to the model” rather than an explicit conditional fusion/gating mechanism.",
        "hypothesis_evaluation": "Partially supports the hypothesis, but does not conclusively validate it.\n\nWhat is supported:\n- The idea that combining a breakout-continuation proxy with a loser-gap/absorption mean-reversion proxy can improve portfolio-level outcomes is supported by the higher annualized return and higher information ratio than SOTA.\n\nWhat is not validated (and likely explains the worse drawdown / weaker IC):\n- The hypothesis specifically claims a conditional fusion (“route to trend only when orderly breakout; otherwise route to MR under gap-stress with absorption”). Without implementing the VolumeInstability_x_GapShare_20D discriminator and without an explicit gating formula, the model may be mixing the two regimes imperfectly, allowing breakout exposure during gap-dominated forced-flow periods (or applying MR in fresh-breakdown states), which can increase drawdown.\n\nMetric-level interpretation vs SOTA:\n- Annualized return: improved materially (good).\n- Information ratio: improved (good).\n- Max drawdown: meaningfully worse (bad; suggests regime misclassification / adverse selection during stress).\n- IC: slightly worse (suggests the added return may be coming from nonlinear interactions/portfolio construction effects rather than cleaner pointwise predictiveness).",
        "decision": true,
        "reason": "1) Why drawdown worsened despite better IR/return:\n- The breakout factor already penalizes gaps via (1 - |O-C_{t-1}|/(H-L)), but this is a soft penalty and can still leave the strategy exposed during discontinuous moves.\n- The MR factor activates on gap-dominance and losers, but it lacks an explicit ‘not a fresh breakdown’ filter beyond ROC60<0 and a 5D z-score. That can still trigger early catching of falling knives when the selloff is expanding in range / making new lows.\n\n2) What to implement next (within the same framework, with explicit hyperparameters):\n- Implement VolumeInstability_x_GapShare_20D exactly as specified (volume baseline=20; instability window=20; zscore window=252). This is the missing router component.\n- Create one *single* regime-routed composite factor (static definition) instead of relying on the model to learn the routing:\n  - Gate variables (all fully specified):\n    - gap_share_t = |O_t - C_{t-1}| / (H_t - L_t + eps)\n    - vol_instab_t = STD_{20}( V / (MEAN_{20}(V)+eps) )\n    - stress_z_t = Z_{252}( gap_share_t * vol_instab_t )\n  - Breakout gate (orderly discovery):\n    - I_breakout = 1[ C_t >= TS_MAX(H,55) * (1 - bbuf) ] * 1[ stress_z_t < s_low ]\n    - Hyperparameters to sweep (start tight, then widen): bbuf ∈ {0.00, 0.01}; s_low ∈ {-0.5, 0.0, 0.5}\n  - MR gate (forced-flow + absorption, but not fresh breakdown):\n    - I_mr = 1[ROC_{60}(C)<0] * 1[ gap_share_t > 0.6 ] * 1[ C_t > TS_MIN(L, n_low) * (1 + lbuf) ] * 1[ stress_z_t > s_high ]\n    - Hyperparameters to sweep: n_low ∈ {20, 55}; lbuf ∈ {0.00, 0.01}; s_high ∈ {0.0, 0.5, 1.0}\n  - Composite output (single factor):\n    - F = I_breakout * CoilCompression_BreakoutBias_55D  +  I_mr * LoserGapStress_AbsorptionMR_5D\n    - This directly tests the hypothesis’ conditional fusion.\n\n3) Parameter sensitivity / refinements to explore next (keep expressions short):\n- Donchian lookback: 20/55/100 (separate factors; do not overload one factor).\n- Vol compression: compare (60 vs 10), (120 vs 20), (40 vs 10). The current log(σ60)-log(σ10) may be too noisy for some names.\n- MR horizon: 3D, 5D, 10D versions (separate factors) to match the stated 3–10D target.\n- Gap threshold: 0.4/0.6/0.8 (separate MR factors) to tune “gap-dominated” definition.\n- Add a minimal “range expansion” avoidance term for MR using only existing OHLC (no extra base features): e.g., block MR when (H-L) / MEAN_{20}(H-L) is above a threshold; thresholds to test: 1.5, 2.0.\n\n4) Complexity control:\n- No explicit complexity warnings were provided, and the formulas are reasonably compact with few base features (OHLCV). Keep the next iteration similarly simple: avoid adding many extra conditions; prefer 1–2 gates + 2 core signals.\n\n5) Evaluation suggestion aligned with observed metrics:\n- Because max drawdown worsened, prioritize gating changes that explicitly suppress signals during high stress_z regimes for breakouts and suppress MR during fresh-breakdown/expanding-range regimes. This is the most direct lever to improve MDD without sacrificing too much return."
      }
    },
    "48135d2c4d8acb9e": {
      "factor_id": "48135d2c4d8acb9e",
      "factor_name": "Capitulation_Regime_Drawdown60_CorrRetVolChg20",
      "factor_expression": "RANK(1 - $close/(TS_MAX($close, 60)+1e-8)) * RANK(MAX(0, -TS_CORR($return, DELTA(LOG($volume+1), 1), 20)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(1 - $close/TS_MAX($close, 60)) * RANK(MAX(0, -TS_CORR(TS_PCTCHANGE($close, 1), DELTA(LOG($volume+1), 1), 20)))\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Regime_Drawdown60_CorrRetVolChg20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Capitulation regime score: deep 60-day drawdown from rolling peak combined with strongly negative 20-day correlation between daily returns and log-volume change (flow-driven selling proxy). Higher values indicate more likely forced-selling capitulation.",
      "factor_formulation": "CR = \\operatorname{Rank}\\Big(1-\\frac{C}{\\max_{60}(C)}\\Big)\\cdot \\operatorname{Rank}\\Big(\\max(0, -\\operatorname{Corr}_{20}(r, \\Delta\\log(V)))\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ce51371f692c",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Impact-driven capitulation mean reversion: next-day (and short-horizon) returns are positively predicted when a stock is simultaneously (i) in a capitulation regime (deep 60D drawdown from rolling peak and a strongly negative 20D correlation between daily returns and volume-change, indicating flow-driven selling) and (ii) experiences a one-day dislocation consistent with a liquidity vacuum (abnormally large |close-to-close return| and intraday range versus a 20D baseline, occurring on abnormally low volume and low dollar-volume), with timing strengthened when intraday price action shows rejection of the move (close-location value implying rejection of lows on down days or rejection of highs on up days).\n                Concise Observation: The available OHLCV data supports constructing (a) drawdown-from-rolling-peak, (b) rolling correlation between returns and volume-change, (c) liquidity-vacuum proxies via |return|/range z-scores gated by low volume and low (close×volume), and (d) intraday rejection using CLV; combining regime + dislocation + trigger can narrow contrarian exposure to higher-conviction, impact-driven events rather than broad mean reversion.\n                Concise Justification: Forced-selling regimes create persistent undervaluation risk, but contrarian signals fail when moves are information-driven or high-participation trends; explicitly requiring a liquidity vacuum (high price movement per unit participation) and a microstructure rejection signature filters out informed trending and targets temporary impact/overshoot episodes that should revert as liquidity returns.\n                Concise Knowledge: If selling pressure is flow-driven (returns co-move negatively with volume changes) and price is already depressed (large drawdown), then large adverse moves occurring on low participation (low volume/dollar-volume with high range/|return|) are more likely to be temporary price-impact overshoots; when the same day shows intraday rejection (CLV opposite to the day’s return direction), the probability of short-horizon mean reversion increases because liquidity replenishment and fading forced flow dominate information-based trending.\n                concise Specification: Construct daily alpha as: Alpha = Rank(CapitulationScore) * Rank(LiquidityVacuumScore) * TriggerStrength * (-sign(Ret_1D)); where CapitulationScore = Rank(Drawdown_60D) * Rank(max(0, -Corr_20D(Ret_1D, Δlog(Volume)))); Drawdown_60D = 1 - Close / RollingMax(Close, 60); LiquidityVacuumScore = Rank(max(0, Z20(|Ret_1D|)) + max(0, Z20((High-Low)/Close))) * Rank(max(0, -Z20(log(Volume)))) * Rank(max(0, -Z20(log(Close*Volume)))); TriggerStrength = max(0, (-sign(Ret_1D)) * CLV), CLV = ((Close-Low) - (High-Close)) / (High-Low) with High==Low set to 0; apply hard gates: LiquidityVacuumScore in top 30% cross-section AND CapitulationScore in top 40% cross-section each day, else Alpha=0, using only OHLCV and fixed windows (60D, 20D) for testability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:54:14.897909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1038551199536672,
        "ICIR": 0.0616491236506652,
        "1day.excess_return_without_cost.std": 0.004452396588457,
        "1day.excess_return_with_cost.annualized_return": 0.046117002165768,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003910352743398,
        "1day.excess_return_without_cost.annualized_return": 0.0930663952928743,
        "1day.excess_return_with_cost.std": 0.0044537074606865,
        "Rank IC": 0.0276139235792766,
        "IC": 0.008581628534301,
        "1day.excess_return_without_cost.max_drawdown": -0.0946835295510843,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3549103896722794,
        "1day.pa": 0.0,
        "l2.valid": 0.9969218332413706,
        "Rank ICIR": 0.2025014688599385,
        "l2.train": 0.9925838762928092,
        "1day.excess_return_with_cost.information_ratio": 0.6711983844198353,
        "1day.excess_return_with_cost.mean": 0.0001937689166628
      },
      "feedback": {
        "observations": "The combined factor set materially improves predictive quality and return metrics vs SOTA: IC rises from 0.005798 to 0.008582, information ratio from 0.9726 to 1.3549, and annualized return from 5.20% to 9.31% (all better). However, max drawdown deteriorates (more negative): -9.47% vs -7.26%, indicating the signal is stronger but comes with worse tail/risk concentration (likely episodic crash exposure when “capitulation” keeps trending instead of mean-reverting). No explicit complexity warnings were provided; the formulas are moderate and interpretable (mainly rolling windows + ranks + z-scores).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that \"capitulation regime + liquidity-vacuum dislocation + intraday rejection\" positively predicts next-day returns: the IC and IR improvements suggest the combined construction is capturing a repeatable short-horizon edge consistent with impact-driven mean reversion.\n\nWhere the hypothesis is only partially validated is risk behavior: the worse max drawdown suggests the signal may fire into genuine negative-information events (fundamental breaks) or into prolonged forced-selling cascades where mean reversion is delayed. In other words, the mechanism seems real, but the current implementation is not sufficiently selective about *which* capitulations are mean-reverting vs continuation.\n\nHyperparameters explicitly used (should remain static per factor definition):\n- Capitulation_Regime_Drawdown60_CorrRetVolChg20: TS_MAX window=60 for rolling peak; TS_CORR window=20; DELTA lag=1 for Δlog(V) (if implemented as daily change).\n- LiquidityVacuum_DislocationZ20_LowVol_LowDollarVol20: TS_ZSCORE window=20 for |r|, (H-L)/C, log(V), log(C*V).\n- Rejection_Trigger_CLV_OpposesMove_Z20AbsRet20: TS_ZSCORE window=20 on |r|; CLV computed daily; gating uses sign(r).",
        "decision": true,
        "reason": "Why metrics look like this:\n- IC/IR/annualized return improved: the interaction of (A) deep drawdown + negative corr(ret, ΔlogV) and (B) large move on low participation + (C) rejection signature is a coherent microstructure story for next-day bounce.\n- Max drawdown worsened: likely due to clustered exposures during market selloffs (many names simultaneously in drawdown), and/or catching “falling knives” when selling pressure persists beyond 1 day.\n\nConcrete next iterations (stay within the same theoretical framework, prioritize simplicity):\n1) Make the signal more selective (reduce crash/tail exposure) while keeping the same primitives:\n   - Add a *trend persistence veto* (simple): require that the last k-day return is not too negative, or that short-term momentum is stabilizing.\n     *Example variants as separate factors (static params):*\n     - Add condition: r_5d > -x (try x in {3%, 5%, 8%}) or TS_ZSCORE(r, 20) > -1.\n     - Or require 2-day reversal confirmation: r_t < 0 and r_{t+1} > 0 (for next-day prediction, use only info up to t: require r_t < 0 AND CLV rejection strong).\n\n2) Parameter sensitivity sweeps (create distinct factors per setting):\n   - Drawdown window: 40 / 60 / 80 days (Drawdown40, Drawdown60, Drawdown80).\n   - Corr window: 10 / 20 / 30 days for Corr(r, ΔlogV).\n   - Z-score window: 10 / 20 / 40 days for dislocation/volume z-scores.\n   Rationale: the best horizon for “forced flow” and “liquidity vacuum” is market-regime dependent; the current result suggests signal exists, so optimizing these few integers is high ROI.\n\n3) Improve robustness of cross-sectional ranking interactions:\n   - Current construction multiplies several cross-sectional RANK() terms, which can create extreme tails and concentration (helping return but hurting drawdown).\n   - Try simpler combination rules (each should be a separate factor):\n     - Replace product of ranks with an average/sum of ranks.\n     - Cap each component before combining (e.g., clip Z-scores at 3, or clip ranks to [0.05, 0.95]).\n   Expected effect: slightly lower peak returns but better drawdown and stability.\n\n4) Make the liquidity-vacuum definition more “impact-like” with minimal added complexity:\n   - Instead of separate low-volume and low-dollar-volume ranks, consider one participation proxy to reduce redundancy (ER control) and over-amplification:\n     - Use only log(C*V) z-score (dollar volume) and drop log(V), or vice versa.\n   This can reduce factor noise and tail risk while keeping the same concept.\n\n5) Add a simple market/sector stress filter (still same framework: avoid systematic capitulation):\n   - Neutralize or condition on cross-sectional median return of the day (proxy for market shock). For example: only trigger when market return is not extremely negative (e.g., market zscore > -2).\n   If the platform doesn’t provide an index series, approximate with cross-sectional average return across instruments for that date.\n\nComplexity control note:\n- No explicit SL/ER/PC warnings were provided. Keep it that way: prefer 2–4 primitives + 2–3 windows; avoid adding many extra branches/conditions that could overfit. Focus on window sweeps and combination-rule simplification first.\n\nWhat to aim for next:\n- Keep IC/IR near current levels while improving max drawdown back toward or better than -7.26% (SOTA). The most likely lever is reducing rank-product extremeness and adding one simple persistence/stress veto."
      }
    },
    "b9f1e1e5668ec3f1": {
      "factor_id": "b9f1e1e5668ec3f1",
      "factor_name": "LiquidityVacuum_DislocationZ20_LowVol_LowDollarVol20",
      "factor_expression": "RANK(MAX(0, TS_ZSCORE(ABS($return), 20)) + MAX(0, TS_ZSCORE(($high-$low)/($close+1e-8), 20))) * RANK(MAX(0, -TS_ZSCORE(LOG($volume+1), 20))) * RANK(MAX(0, -TS_ZSCORE(LOG($close*$volume+1), 20)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(MAX(0, TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)), 20)) + MAX(0, TS_ZSCORE(($high-$low)/($close+1e-8), 20))) * RANK(MAX(0, -TS_ZSCORE(LOG($volume+1), 20))) * RANK(MAX(0, -TS_ZSCORE(LOG($close*$volume+1), 20)))\" # Your output factor expression will be filled in here\n    name = \"LiquidityVacuum_DislocationZ20_LowVol_LowDollarVol20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity-vacuum dislocation score: abnormally large absolute return and normalized intraday range (20D z-scores) occurring alongside abnormally low volume and low dollar-volume (proxied by close×volume, 20D z-scores). Higher values indicate larger price move per unit participation.",
      "factor_formulation": "LV = \\operatorname{Rank}(\\max(0,Z_{20}(|r|)) + \\max(0,Z_{20}(\\tfrac{H-L}{C})))\\cdot \\operatorname{Rank}(\\max(0,-Z_{20}(\\log V)))\\cdot \\operatorname{Rank}(\\max(0,-Z_{20}(\\log (CV))))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ce51371f692c",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Impact-driven capitulation mean reversion: next-day (and short-horizon) returns are positively predicted when a stock is simultaneously (i) in a capitulation regime (deep 60D drawdown from rolling peak and a strongly negative 20D correlation between daily returns and volume-change, indicating flow-driven selling) and (ii) experiences a one-day dislocation consistent with a liquidity vacuum (abnormally large |close-to-close return| and intraday range versus a 20D baseline, occurring on abnormally low volume and low dollar-volume), with timing strengthened when intraday price action shows rejection of the move (close-location value implying rejection of lows on down days or rejection of highs on up days).\n                Concise Observation: The available OHLCV data supports constructing (a) drawdown-from-rolling-peak, (b) rolling correlation between returns and volume-change, (c) liquidity-vacuum proxies via |return|/range z-scores gated by low volume and low (close×volume), and (d) intraday rejection using CLV; combining regime + dislocation + trigger can narrow contrarian exposure to higher-conviction, impact-driven events rather than broad mean reversion.\n                Concise Justification: Forced-selling regimes create persistent undervaluation risk, but contrarian signals fail when moves are information-driven or high-participation trends; explicitly requiring a liquidity vacuum (high price movement per unit participation) and a microstructure rejection signature filters out informed trending and targets temporary impact/overshoot episodes that should revert as liquidity returns.\n                Concise Knowledge: If selling pressure is flow-driven (returns co-move negatively with volume changes) and price is already depressed (large drawdown), then large adverse moves occurring on low participation (low volume/dollar-volume with high range/|return|) are more likely to be temporary price-impact overshoots; when the same day shows intraday rejection (CLV opposite to the day’s return direction), the probability of short-horizon mean reversion increases because liquidity replenishment and fading forced flow dominate information-based trending.\n                concise Specification: Construct daily alpha as: Alpha = Rank(CapitulationScore) * Rank(LiquidityVacuumScore) * TriggerStrength * (-sign(Ret_1D)); where CapitulationScore = Rank(Drawdown_60D) * Rank(max(0, -Corr_20D(Ret_1D, Δlog(Volume)))); Drawdown_60D = 1 - Close / RollingMax(Close, 60); LiquidityVacuumScore = Rank(max(0, Z20(|Ret_1D|)) + max(0, Z20((High-Low)/Close))) * Rank(max(0, -Z20(log(Volume)))) * Rank(max(0, -Z20(log(Close*Volume)))); TriggerStrength = max(0, (-sign(Ret_1D)) * CLV), CLV = ((Close-Low) - (High-Close)) / (High-Low) with High==Low set to 0; apply hard gates: LiquidityVacuumScore in top 30% cross-section AND CapitulationScore in top 40% cross-section each day, else Alpha=0, using only OHLCV and fixed windows (60D, 20D) for testability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:54:14.897909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1038551199536672,
        "ICIR": 0.0616491236506652,
        "1day.excess_return_without_cost.std": 0.004452396588457,
        "1day.excess_return_with_cost.annualized_return": 0.046117002165768,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003910352743398,
        "1day.excess_return_without_cost.annualized_return": 0.0930663952928743,
        "1day.excess_return_with_cost.std": 0.0044537074606865,
        "Rank IC": 0.0276139235792766,
        "IC": 0.008581628534301,
        "1day.excess_return_without_cost.max_drawdown": -0.0946835295510843,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3549103896722794,
        "1day.pa": 0.0,
        "l2.valid": 0.9969218332413706,
        "Rank ICIR": 0.2025014688599385,
        "l2.train": 0.9925838762928092,
        "1day.excess_return_with_cost.information_ratio": 0.6711983844198353,
        "1day.excess_return_with_cost.mean": 0.0001937689166628
      },
      "feedback": {
        "observations": "The combined factor set materially improves predictive quality and return metrics vs SOTA: IC rises from 0.005798 to 0.008582, information ratio from 0.9726 to 1.3549, and annualized return from 5.20% to 9.31% (all better). However, max drawdown deteriorates (more negative): -9.47% vs -7.26%, indicating the signal is stronger but comes with worse tail/risk concentration (likely episodic crash exposure when “capitulation” keeps trending instead of mean-reverting). No explicit complexity warnings were provided; the formulas are moderate and interpretable (mainly rolling windows + ranks + z-scores).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that \"capitulation regime + liquidity-vacuum dislocation + intraday rejection\" positively predicts next-day returns: the IC and IR improvements suggest the combined construction is capturing a repeatable short-horizon edge consistent with impact-driven mean reversion.\n\nWhere the hypothesis is only partially validated is risk behavior: the worse max drawdown suggests the signal may fire into genuine negative-information events (fundamental breaks) or into prolonged forced-selling cascades where mean reversion is delayed. In other words, the mechanism seems real, but the current implementation is not sufficiently selective about *which* capitulations are mean-reverting vs continuation.\n\nHyperparameters explicitly used (should remain static per factor definition):\n- Capitulation_Regime_Drawdown60_CorrRetVolChg20: TS_MAX window=60 for rolling peak; TS_CORR window=20; DELTA lag=1 for Δlog(V) (if implemented as daily change).\n- LiquidityVacuum_DislocationZ20_LowVol_LowDollarVol20: TS_ZSCORE window=20 for |r|, (H-L)/C, log(V), log(C*V).\n- Rejection_Trigger_CLV_OpposesMove_Z20AbsRet20: TS_ZSCORE window=20 on |r|; CLV computed daily; gating uses sign(r).",
        "decision": true,
        "reason": "Why metrics look like this:\n- IC/IR/annualized return improved: the interaction of (A) deep drawdown + negative corr(ret, ΔlogV) and (B) large move on low participation + (C) rejection signature is a coherent microstructure story for next-day bounce.\n- Max drawdown worsened: likely due to clustered exposures during market selloffs (many names simultaneously in drawdown), and/or catching “falling knives” when selling pressure persists beyond 1 day.\n\nConcrete next iterations (stay within the same theoretical framework, prioritize simplicity):\n1) Make the signal more selective (reduce crash/tail exposure) while keeping the same primitives:\n   - Add a *trend persistence veto* (simple): require that the last k-day return is not too negative, or that short-term momentum is stabilizing.\n     *Example variants as separate factors (static params):*\n     - Add condition: r_5d > -x (try x in {3%, 5%, 8%}) or TS_ZSCORE(r, 20) > -1.\n     - Or require 2-day reversal confirmation: r_t < 0 and r_{t+1} > 0 (for next-day prediction, use only info up to t: require r_t < 0 AND CLV rejection strong).\n\n2) Parameter sensitivity sweeps (create distinct factors per setting):\n   - Drawdown window: 40 / 60 / 80 days (Drawdown40, Drawdown60, Drawdown80).\n   - Corr window: 10 / 20 / 30 days for Corr(r, ΔlogV).\n   - Z-score window: 10 / 20 / 40 days for dislocation/volume z-scores.\n   Rationale: the best horizon for “forced flow” and “liquidity vacuum” is market-regime dependent; the current result suggests signal exists, so optimizing these few integers is high ROI.\n\n3) Improve robustness of cross-sectional ranking interactions:\n   - Current construction multiplies several cross-sectional RANK() terms, which can create extreme tails and concentration (helping return but hurting drawdown).\n   - Try simpler combination rules (each should be a separate factor):\n     - Replace product of ranks with an average/sum of ranks.\n     - Cap each component before combining (e.g., clip Z-scores at 3, or clip ranks to [0.05, 0.95]).\n   Expected effect: slightly lower peak returns but better drawdown and stability.\n\n4) Make the liquidity-vacuum definition more “impact-like” with minimal added complexity:\n   - Instead of separate low-volume and low-dollar-volume ranks, consider one participation proxy to reduce redundancy (ER control) and over-amplification:\n     - Use only log(C*V) z-score (dollar volume) and drop log(V), or vice versa.\n   This can reduce factor noise and tail risk while keeping the same concept.\n\n5) Add a simple market/sector stress filter (still same framework: avoid systematic capitulation):\n   - Neutralize or condition on cross-sectional median return of the day (proxy for market shock). For example: only trigger when market return is not extremely negative (e.g., market zscore > -2).\n   If the platform doesn’t provide an index series, approximate with cross-sectional average return across instruments for that date.\n\nComplexity control note:\n- No explicit SL/ER/PC warnings were provided. Keep it that way: prefer 2–4 primitives + 2–3 windows; avoid adding many extra branches/conditions that could overfit. Focus on window sweeps and combination-rule simplification first.\n\nWhat to aim for next:\n- Keep IC/IR near current levels while improving max drawdown back toward or better than -7.26% (SOTA). The most likely lever is reducing rank-product extremeness and adding one simple persistence/stress veto."
      }
    },
    "3c544d5ebe697586": {
      "factor_id": "3c544d5ebe697586",
      "factor_name": "Rejection_Trigger_CLV_OpposesMove_Z20AbsRet20",
      "factor_expression": "MAX(0, TS_ZSCORE(ABS($return), 20)) * MAX(0, (-SIGN($return)) * ((($high-$low)>0)?((($close-$low)-($high-$close))/($high-$low)):0))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MAX(0, TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)), 20)) * MAX(0, (-SIGN(TS_PCTCHANGE($close, 1))) * (($high>$low)?((($close-$low)-($high-$close))/($high-$low)):0))\" # Your output factor expression will be filled in here\n    name = \"Rejection_Trigger_CLV_OpposesMove_Z20AbsRet20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Intraday rejection trigger: measures whether the close-location value (CLV) rejects the direction of the day’s return, strengthened when the absolute return is unusually large versus a 20D baseline. Higher values indicate stronger rejection after a dislocating move (mean-reversion-friendly microstructure signature).",
      "factor_formulation": "T = \\max(0, Z_{20}(|r|))\\cdot \\max\\Big(0, -\\operatorname{sign}(r)\\cdot \\text{CLV}\\Big),\\quad \\text{CLV}=\\begin{cases}\\frac{(C-L)-(H-C)}{H-L},&H>L\\\\0,&H=L\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ce51371f692c",
        "parent_trajectory_ids": [
          "a59f19aac397",
          "3c72d23bcf9c"
        ],
        "hypothesis": "Hypothesis: Impact-driven capitulation mean reversion: next-day (and short-horizon) returns are positively predicted when a stock is simultaneously (i) in a capitulation regime (deep 60D drawdown from rolling peak and a strongly negative 20D correlation between daily returns and volume-change, indicating flow-driven selling) and (ii) experiences a one-day dislocation consistent with a liquidity vacuum (abnormally large |close-to-close return| and intraday range versus a 20D baseline, occurring on abnormally low volume and low dollar-volume), with timing strengthened when intraday price action shows rejection of the move (close-location value implying rejection of lows on down days or rejection of highs on up days).\n                Concise Observation: The available OHLCV data supports constructing (a) drawdown-from-rolling-peak, (b) rolling correlation between returns and volume-change, (c) liquidity-vacuum proxies via |return|/range z-scores gated by low volume and low (close×volume), and (d) intraday rejection using CLV; combining regime + dislocation + trigger can narrow contrarian exposure to higher-conviction, impact-driven events rather than broad mean reversion.\n                Concise Justification: Forced-selling regimes create persistent undervaluation risk, but contrarian signals fail when moves are information-driven or high-participation trends; explicitly requiring a liquidity vacuum (high price movement per unit participation) and a microstructure rejection signature filters out informed trending and targets temporary impact/overshoot episodes that should revert as liquidity returns.\n                Concise Knowledge: If selling pressure is flow-driven (returns co-move negatively with volume changes) and price is already depressed (large drawdown), then large adverse moves occurring on low participation (low volume/dollar-volume with high range/|return|) are more likely to be temporary price-impact overshoots; when the same day shows intraday rejection (CLV opposite to the day’s return direction), the probability of short-horizon mean reversion increases because liquidity replenishment and fading forced flow dominate information-based trending.\n                concise Specification: Construct daily alpha as: Alpha = Rank(CapitulationScore) * Rank(LiquidityVacuumScore) * TriggerStrength * (-sign(Ret_1D)); where CapitulationScore = Rank(Drawdown_60D) * Rank(max(0, -Corr_20D(Ret_1D, Δlog(Volume)))); Drawdown_60D = 1 - Close / RollingMax(Close, 60); LiquidityVacuumScore = Rank(max(0, Z20(|Ret_1D|)) + max(0, Z20((High-Low)/Close))) * Rank(max(0, -Z20(log(Volume)))) * Rank(max(0, -Z20(log(Close*Volume)))); TriggerStrength = max(0, (-sign(Ret_1D)) * CLV), CLV = ((Close-Low) - (High-Close)) / (High-Low) with High==Low set to 0; apply hard gates: LiquidityVacuumScore in top 30% cross-section AND CapitulationScore in top 40% cross-section each day, else Alpha=0, using only OHLCV and fixed windows (60D, 20D) for testability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-22T06:54:14.897909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1038551199536672,
        "ICIR": 0.0616491236506652,
        "1day.excess_return_without_cost.std": 0.004452396588457,
        "1day.excess_return_with_cost.annualized_return": 0.046117002165768,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003910352743398,
        "1day.excess_return_without_cost.annualized_return": 0.0930663952928743,
        "1day.excess_return_with_cost.std": 0.0044537074606865,
        "Rank IC": 0.0276139235792766,
        "IC": 0.008581628534301,
        "1day.excess_return_without_cost.max_drawdown": -0.0946835295510843,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3549103896722794,
        "1day.pa": 0.0,
        "l2.valid": 0.9969218332413706,
        "Rank ICIR": 0.2025014688599385,
        "l2.train": 0.9925838762928092,
        "1day.excess_return_with_cost.information_ratio": 0.6711983844198353,
        "1day.excess_return_with_cost.mean": 0.0001937689166628
      },
      "feedback": {
        "observations": "The combined factor set materially improves predictive quality and return metrics vs SOTA: IC rises from 0.005798 to 0.008582, information ratio from 0.9726 to 1.3549, and annualized return from 5.20% to 9.31% (all better). However, max drawdown deteriorates (more negative): -9.47% vs -7.26%, indicating the signal is stronger but comes with worse tail/risk concentration (likely episodic crash exposure when “capitulation” keeps trending instead of mean-reverting). No explicit complexity warnings were provided; the formulas are moderate and interpretable (mainly rolling windows + ranks + z-scores).",
        "hypothesis_evaluation": "Overall, the results support the hypothesis that \"capitulation regime + liquidity-vacuum dislocation + intraday rejection\" positively predicts next-day returns: the IC and IR improvements suggest the combined construction is capturing a repeatable short-horizon edge consistent with impact-driven mean reversion.\n\nWhere the hypothesis is only partially validated is risk behavior: the worse max drawdown suggests the signal may fire into genuine negative-information events (fundamental breaks) or into prolonged forced-selling cascades where mean reversion is delayed. In other words, the mechanism seems real, but the current implementation is not sufficiently selective about *which* capitulations are mean-reverting vs continuation.\n\nHyperparameters explicitly used (should remain static per factor definition):\n- Capitulation_Regime_Drawdown60_CorrRetVolChg20: TS_MAX window=60 for rolling peak; TS_CORR window=20; DELTA lag=1 for Δlog(V) (if implemented as daily change).\n- LiquidityVacuum_DislocationZ20_LowVol_LowDollarVol20: TS_ZSCORE window=20 for |r|, (H-L)/C, log(V), log(C*V).\n- Rejection_Trigger_CLV_OpposesMove_Z20AbsRet20: TS_ZSCORE window=20 on |r|; CLV computed daily; gating uses sign(r).",
        "decision": true,
        "reason": "Why metrics look like this:\n- IC/IR/annualized return improved: the interaction of (A) deep drawdown + negative corr(ret, ΔlogV) and (B) large move on low participation + (C) rejection signature is a coherent microstructure story for next-day bounce.\n- Max drawdown worsened: likely due to clustered exposures during market selloffs (many names simultaneously in drawdown), and/or catching “falling knives” when selling pressure persists beyond 1 day.\n\nConcrete next iterations (stay within the same theoretical framework, prioritize simplicity):\n1) Make the signal more selective (reduce crash/tail exposure) while keeping the same primitives:\n   - Add a *trend persistence veto* (simple): require that the last k-day return is not too negative, or that short-term momentum is stabilizing.\n     *Example variants as separate factors (static params):*\n     - Add condition: r_5d > -x (try x in {3%, 5%, 8%}) or TS_ZSCORE(r, 20) > -1.\n     - Or require 2-day reversal confirmation: r_t < 0 and r_{t+1} > 0 (for next-day prediction, use only info up to t: require r_t < 0 AND CLV rejection strong).\n\n2) Parameter sensitivity sweeps (create distinct factors per setting):\n   - Drawdown window: 40 / 60 / 80 days (Drawdown40, Drawdown60, Drawdown80).\n   - Corr window: 10 / 20 / 30 days for Corr(r, ΔlogV).\n   - Z-score window: 10 / 20 / 40 days for dislocation/volume z-scores.\n   Rationale: the best horizon for “forced flow” and “liquidity vacuum” is market-regime dependent; the current result suggests signal exists, so optimizing these few integers is high ROI.\n\n3) Improve robustness of cross-sectional ranking interactions:\n   - Current construction multiplies several cross-sectional RANK() terms, which can create extreme tails and concentration (helping return but hurting drawdown).\n   - Try simpler combination rules (each should be a separate factor):\n     - Replace product of ranks with an average/sum of ranks.\n     - Cap each component before combining (e.g., clip Z-scores at 3, or clip ranks to [0.05, 0.95]).\n   Expected effect: slightly lower peak returns but better drawdown and stability.\n\n4) Make the liquidity-vacuum definition more “impact-like” with minimal added complexity:\n   - Instead of separate low-volume and low-dollar-volume ranks, consider one participation proxy to reduce redundancy (ER control) and over-amplification:\n     - Use only log(C*V) z-score (dollar volume) and drop log(V), or vice versa.\n   This can reduce factor noise and tail risk while keeping the same concept.\n\n5) Add a simple market/sector stress filter (still same framework: avoid systematic capitulation):\n   - Neutralize or condition on cross-sectional median return of the day (proxy for market shock). For example: only trigger when market return is not extremely negative (e.g., market zscore > -2).\n   If the platform doesn’t provide an index series, approximate with cross-sectional average return across instruments for that date.\n\nComplexity control note:\n- No explicit SL/ER/PC warnings were provided. Keep it that way: prefer 2–4 primitives + 2–3 windows; avoid adding many extra branches/conditions that could overfit. Focus on window sweeps and combination-rule simplification first.\n\nWhat to aim for next:\n- Keep IC/IR near current levels while improving max drawdown back toward or better than -7.26% (SOTA). The most likely lever is reducing rank-product extremeness and adding one simple persistence/stress veto."
      }
    },
    "b9d83f08bb876e14": {
      "factor_id": "b9d83f08bb876e14",
      "factor_name": "OvernightGap_ContinuationScore_Align10_GapZ60",
      "factor_expression": "RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * MAX(TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10),0) * MAX(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8)),0) )",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * MAX(TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10),0) * MAX(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8)),0) )\" # Your output factor expression will be filled in here\n    name = \"OvernightGap_ContinuationScore_Align10_GapZ60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation score for statistically large overnight gaps that are 'accepted' intraday: same-signed overnight vs intraday returns and a close located toward the gap-direction extreme (CLV aligned with gap sign). Higher values imply stronger continuation tendency over next 5/10 days.",
      "factor_formulation": "r_{on}=\\ln(\\frac{open_t}{close_{t-1}}),\\; r_{id}=\\ln(\\frac{close_t}{open_t}),\\; CLV=\\frac{2c-h-l}{h-l+\\epsilon};\\; GapZ=\\frac{|r_{on}|}{\\sigma_{60}(r_{on})+\\epsilon};\\; Align=\\mu_{10}(\\text{sign}(r_{on})\\text{sign}(r_{id}));\\; Hold=\\text{sign}(r_{on})\\cdot CLV;\\; F=\\text{rank}(GapZ\\cdot \\max(Align,0)\\cdot \\max(Hold,0)).",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "4217c81ecb02",
        "parent_trajectory_ids": [
          "06ea1f2a601a"
        ],
        "hypothesis": "Hypothesis: Overnight gap acceptance predicts short-horizon returns: when a stock shows a statistically large overnight return (r_on) that is consistently followed by same-signed intraday return (r_id) and a close near the day’s extreme in the gap direction (high signed CLV), the gap reflects informed repricing and tends to continue over the next 5/10 trading days; when large overnight gaps are systematically faded intraday with closes near the opposite extreme, they represent transient shocks and tend to mean-revert over the next 1–3 days, and a regime score based on rolling overnight–intraday alignment should soft-switch between continuation and reversal signals.\n                Concise Observation: The provided dataset contains only OHLCV, so decomposing returns into overnight (open vs prior close), intraday (close vs open), and close-location-within-range (CLV) enables a regime definition and signal construction that is fully testable without using dollar-volume, Amihud illiquidity, or realized-volatility gating used by the parent strategy.\n                Concise Justification: Overnight gaps proxy discrete information shocks, while intraday path and close location proxy whether that shock is accepted or reversed by continuous trading; therefore, conditioning on multi-day persistence of r_on–r_id sign agreement should separate informed repricing (continuation) from overreaction/temporary pressure (reversal), producing a predictive factor that is orthogonal to liquidity/impact-based regime signals.\n                Concise Knowledge: If new information is incorporated primarily in the opening auction, then large overnight gaps that are accepted (same-signed r_id and close near the gap-direction extreme) imply demand/supply imbalance persists and next-5/10d returns should continue; when the market rejects the open (opposite-signed r_id and close near the opposite extreme), the gap is more likely liquidity/positioning-driven and subsequent returns should mean-revert over the next few days.\n                concise Specification: Use only open/high/low/close (no volume) and define: r_on(t)=log(open_t/close_{t-1}), r_id(t)=log(close_t/open_t), CLV(t)=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), Hold(t)=sign(r_on(t))*CLV(t); GapZ(t)=|r_on(t)| / (TS_STD(r_on,60)+1e-8) (lookback=60); Alignment(t)=TS_MEAN(sign(r_on)*sign(r_id),10) (lookback=10); ContinuationScore(t)=GapZ(t)*max(0,Alignment(t))*max(0,Hold(t)); ReversalScore(t)=GapZ(t)*max(0,-Alignment(t))*max(0,-Hold(t)); FinalFactor(t)=RANK(ContinuationScore(t)) - RANK(ReversalScore(t)) computed cross-sectionally each day; expected relationship: higher FinalFactor predicts higher next-5d and next-10d returns, while strongly negative FinalFactor predicts lower/mean-reverting near-term returns; hyperparameters are fixed at Alignment window=10, GapZ window=60, CLV epsilon=1e-8, and horizons to evaluate are 5d and 10d.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-22T07:09:17.335237"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191241001857718,
        "ICIR": 0.0352785819025865,
        "1day.excess_return_without_cost.std": 0.0045245889282566,
        "1day.excess_return_with_cost.annualized_return": 0.0170968648005002,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002690060484233,
        "1day.excess_return_without_cost.annualized_return": 0.0640234395247516,
        "1day.excess_return_with_cost.std": 0.0045269733205749,
        "Rank IC": 0.021713631097361,
        "IC": 0.004853034693216,
        "1day.excess_return_without_cost.max_drawdown": -0.0938172367718469,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9172155206274506,
        "1day.pa": 0.0,
        "l2.valid": 0.9964641576726604,
        "Rank ICIR": 0.1613350115769271,
        "l2.train": 0.9931204955787544,
        "1day.excess_return_with_cost.information_ratio": 0.2448048760169127,
        "1day.excess_return_with_cost.mean": 7.183556638865645e-05
      },
      "feedback": {
        "observations": "The combined run improves annualized return (0.0640 vs 0.0520 SOTA), but deteriorates on risk-adjusted quality and signal quality: max drawdown is worse (0.0938 vs 0.0726; smaller is better), information ratio is lower (0.9172 vs 0.9726), and IC is lower (0.00485 vs 0.00580). This pattern suggests the factor family is capturing some profitable behavior, but with weaker consistency/cross-sectional predictability and poorer downside control than the prior best.",
        "hypothesis_evaluation": "Partially supports the hypothesis: the improved annualized return is consistent with the idea that an overnight-gap “acceptance vs rejection” regime contains exploitable information. However, the lower IC and IR indicate the regime/acceptance definition (Align10 × Hold × GapZ60 with ranks) is not yet reliably separating winners/losers cross-sectionally, and the worse drawdown suggests the signal may be intermittently wrong in stress/whipsaw regimes (e.g., large gaps around market-wide events) or is too reactive.\n\nWithin-hypothesis interpretation:\n- The annualized uplift supports that overnight gaps + intraday confirmation contains continuation/reversal structure.\n- The deterioration in IC/IR refutes (or at least weakens) the claim that the current “soft-switch” implementation is a robust regime classifier; it may be capturing return via exposure/tilts rather than stable predictive correlation.\n\nHyperparameters explicitly present in the tested factors:\n- Align lookback window: 10 days (TS_MEAN of sign agreement)\n- GapZ volatility window: 60 days (TS_STD of r_on)\n- Returns definition: overnight r_on = log(open_t/close_{t-1}); intraday r_id = log(close_t/open_t)\n- CLV definition uses daily range (high-low) with epsilon in denominator\n- Cross-sectional transformation: RANK(·) applied to the final composite\nThese are the key knobs to vary next; treat each (AlignX, GapZY) as a distinct factor instance.",
        "decision": true,
        "reason": "Why the current implementation likely under-delivers on IC/IR while improving return:\n- Using SIGN(r_on)*SIGN(r_id) discards magnitude; a tiny intraday move counts as full “acceptance,” adding noise.\n- CLV can be unstable on small-range days (high≈low) even with epsilon; it may inject noise exactly when the range is compressed.\n- Full cross-sectional RANK on the final product may distort the intended regime interpretation (continuation vs reversal) and can amplify small measurement errors.\n- GapZ = |r_on|/std60(r_on) treats upside and downside symmetrically; continuation/reversal may be asymmetric (down gaps often behave differently).\n\nConcrete next iterations (stay in the same theoretical framework, prioritize simplicity):\n1) Magnitude-aware alignment (replace pure sign agreement):\n   - AlignMag10 = TS_MEAN( r_on * r_id, 10 ) or TS_MEAN( tanh(k*r_on)*tanh(k*r_id), 10 ) with a fixed k (e.g., k=5) to bound extremes.\n   - Keep windows identical initially: AlignMag10 + GapZ60 to isolate impact.\n2) Make GapZ more robust:\n   - Use TS_STD on winsorized r_on (e.g., clip at ±3σ using rolling std/mean) or use EWMA volatility (still one window parameter, e.g., 60).\n   - Test GapZ windows: 20/60/120 (each is a different factor).\n3) Improve “hold/acceptance” proxy:\n   - Replace CLV with a simpler close-position metric that’s less unstable: Hold2 = sign(r_on) * ( (close-low)/(high-low+eps) - 0.5 )*2 (equivalent scale but easier to reason about), and/or require a minimum range filter: (high-low)/close > threshold (fixed threshold becomes a parameter; keep small count).\n4) Regime gating instead of multiplying everything:\n   - Soft gate: F = GapZ * (Align) * (Hold) is sensitive to noise sign flips. Try F = GapZ * sign(r_on) * (w1*Align + w2*Hold) with fixed simple weights (e.g., 0.5/0.5) to reduce multiplicative brittleness.\n   - Alternatively: F = GapZ * min(Align, Hold) to enforce “both must agree” without explosive scaling.\n5) Asymmetry checks (separate up-gap and down-gap):\n   - Build two separate factors: one computed only when r_on>0, one when r_on<0 (set others to NaN). Often down gaps have stronger reversal dynamics.\n6) Horizon-consistent labeling alignment:\n   - Since hypothesis mentions 1–3 day reversal vs 5/10 day continuation, consider producing two distinct signals explicitly optimized for each horizon (don’t force one soft-switch to serve both). Even if Qlib model learns combination, clearer primitives often improve IC.\n\nParameter sensitivity grid to explore next (each combination is a distinct factor):\n- Align window: 5, 10, 20\n- GapZ vol window: 20, 60, 120\n- Optional: replace simple std with EWMA(halflife=20/60) if supported; otherwise keep TS_STD.\n\nComplexity control:\n- Current expressions are relatively compact and use only OHLC (4 base features) and simple rolling ops; no explicit complexity red flags here. Keep it that way—avoid adding many conditional branches/extra raw features at once. If adding volume confirmation, do it as one minimal modifier (e.g., multiply by rank(volume/TS_MEAN(volume,20)))."
      }
    },
    "9b18066c474324d1": {
      "factor_id": "9b18066c474324d1",
      "factor_name": "OvernightGap_ReversalScore_Align10_GapZ60",
      "factor_expression": "RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * MAX(-TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10),0) * MAX(-(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8))),0) )",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * MAX(-TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10),0) * MAX(-(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8))),0) )\" # Your output factor expression will be filled in here\n    name = \"OvernightGap_ReversalScore_Align10_GapZ60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Reversal score for statistically large overnight gaps that are 'rejected' intraday: overnight and intraday returns tend to have opposite signs and the close finishes toward the opposite extreme of the range relative to the gap direction. Higher values imply stronger short-horizon mean-reversion tendency (1–3 days).",
      "factor_formulation": "F=\\text{rank}(GapZ\\cdot \\max(-Align,0)\\cdot \\max(-Hold,0)) \\;\\text{with}\\; Align=\\mu_{10}(\\text{sign}(r_{on})\\text{sign}(r_{id})),\\; Hold=\\text{sign}(r_{on})CLV,\\; GapZ=\\frac{|r_{on}|}{\\sigma_{60}(r_{on})+\\epsilon}.",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "4217c81ecb02",
        "parent_trajectory_ids": [
          "06ea1f2a601a"
        ],
        "hypothesis": "Hypothesis: Overnight gap acceptance predicts short-horizon returns: when a stock shows a statistically large overnight return (r_on) that is consistently followed by same-signed intraday return (r_id) and a close near the day’s extreme in the gap direction (high signed CLV), the gap reflects informed repricing and tends to continue over the next 5/10 trading days; when large overnight gaps are systematically faded intraday with closes near the opposite extreme, they represent transient shocks and tend to mean-revert over the next 1–3 days, and a regime score based on rolling overnight–intraday alignment should soft-switch between continuation and reversal signals.\n                Concise Observation: The provided dataset contains only OHLCV, so decomposing returns into overnight (open vs prior close), intraday (close vs open), and close-location-within-range (CLV) enables a regime definition and signal construction that is fully testable without using dollar-volume, Amihud illiquidity, or realized-volatility gating used by the parent strategy.\n                Concise Justification: Overnight gaps proxy discrete information shocks, while intraday path and close location proxy whether that shock is accepted or reversed by continuous trading; therefore, conditioning on multi-day persistence of r_on–r_id sign agreement should separate informed repricing (continuation) from overreaction/temporary pressure (reversal), producing a predictive factor that is orthogonal to liquidity/impact-based regime signals.\n                Concise Knowledge: If new information is incorporated primarily in the opening auction, then large overnight gaps that are accepted (same-signed r_id and close near the gap-direction extreme) imply demand/supply imbalance persists and next-5/10d returns should continue; when the market rejects the open (opposite-signed r_id and close near the opposite extreme), the gap is more likely liquidity/positioning-driven and subsequent returns should mean-revert over the next few days.\n                concise Specification: Use only open/high/low/close (no volume) and define: r_on(t)=log(open_t/close_{t-1}), r_id(t)=log(close_t/open_t), CLV(t)=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), Hold(t)=sign(r_on(t))*CLV(t); GapZ(t)=|r_on(t)| / (TS_STD(r_on,60)+1e-8) (lookback=60); Alignment(t)=TS_MEAN(sign(r_on)*sign(r_id),10) (lookback=10); ContinuationScore(t)=GapZ(t)*max(0,Alignment(t))*max(0,Hold(t)); ReversalScore(t)=GapZ(t)*max(0,-Alignment(t))*max(0,-Hold(t)); FinalFactor(t)=RANK(ContinuationScore(t)) - RANK(ReversalScore(t)) computed cross-sectionally each day; expected relationship: higher FinalFactor predicts higher next-5d and next-10d returns, while strongly negative FinalFactor predicts lower/mean-reverting near-term returns; hyperparameters are fixed at Alignment window=10, GapZ window=60, CLV epsilon=1e-8, and horizons to evaluate are 5d and 10d.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-22T07:09:17.335237"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191241001857718,
        "ICIR": 0.0352785819025865,
        "1day.excess_return_without_cost.std": 0.0045245889282566,
        "1day.excess_return_with_cost.annualized_return": 0.0170968648005002,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002690060484233,
        "1day.excess_return_without_cost.annualized_return": 0.0640234395247516,
        "1day.excess_return_with_cost.std": 0.0045269733205749,
        "Rank IC": 0.021713631097361,
        "IC": 0.004853034693216,
        "1day.excess_return_without_cost.max_drawdown": -0.0938172367718469,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9172155206274506,
        "1day.pa": 0.0,
        "l2.valid": 0.9964641576726604,
        "Rank ICIR": 0.1613350115769271,
        "l2.train": 0.9931204955787544,
        "1day.excess_return_with_cost.information_ratio": 0.2448048760169127,
        "1day.excess_return_with_cost.mean": 7.183556638865645e-05
      },
      "feedback": {
        "observations": "The combined run improves annualized return (0.0640 vs 0.0520 SOTA), but deteriorates on risk-adjusted quality and signal quality: max drawdown is worse (0.0938 vs 0.0726; smaller is better), information ratio is lower (0.9172 vs 0.9726), and IC is lower (0.00485 vs 0.00580). This pattern suggests the factor family is capturing some profitable behavior, but with weaker consistency/cross-sectional predictability and poorer downside control than the prior best.",
        "hypothesis_evaluation": "Partially supports the hypothesis: the improved annualized return is consistent with the idea that an overnight-gap “acceptance vs rejection” regime contains exploitable information. However, the lower IC and IR indicate the regime/acceptance definition (Align10 × Hold × GapZ60 with ranks) is not yet reliably separating winners/losers cross-sectionally, and the worse drawdown suggests the signal may be intermittently wrong in stress/whipsaw regimes (e.g., large gaps around market-wide events) or is too reactive.\n\nWithin-hypothesis interpretation:\n- The annualized uplift supports that overnight gaps + intraday confirmation contains continuation/reversal structure.\n- The deterioration in IC/IR refutes (or at least weakens) the claim that the current “soft-switch” implementation is a robust regime classifier; it may be capturing return via exposure/tilts rather than stable predictive correlation.\n\nHyperparameters explicitly present in the tested factors:\n- Align lookback window: 10 days (TS_MEAN of sign agreement)\n- GapZ volatility window: 60 days (TS_STD of r_on)\n- Returns definition: overnight r_on = log(open_t/close_{t-1}); intraday r_id = log(close_t/open_t)\n- CLV definition uses daily range (high-low) with epsilon in denominator\n- Cross-sectional transformation: RANK(·) applied to the final composite\nThese are the key knobs to vary next; treat each (AlignX, GapZY) as a distinct factor instance.",
        "decision": true,
        "reason": "Why the current implementation likely under-delivers on IC/IR while improving return:\n- Using SIGN(r_on)*SIGN(r_id) discards magnitude; a tiny intraday move counts as full “acceptance,” adding noise.\n- CLV can be unstable on small-range days (high≈low) even with epsilon; it may inject noise exactly when the range is compressed.\n- Full cross-sectional RANK on the final product may distort the intended regime interpretation (continuation vs reversal) and can amplify small measurement errors.\n- GapZ = |r_on|/std60(r_on) treats upside and downside symmetrically; continuation/reversal may be asymmetric (down gaps often behave differently).\n\nConcrete next iterations (stay in the same theoretical framework, prioritize simplicity):\n1) Magnitude-aware alignment (replace pure sign agreement):\n   - AlignMag10 = TS_MEAN( r_on * r_id, 10 ) or TS_MEAN( tanh(k*r_on)*tanh(k*r_id), 10 ) with a fixed k (e.g., k=5) to bound extremes.\n   - Keep windows identical initially: AlignMag10 + GapZ60 to isolate impact.\n2) Make GapZ more robust:\n   - Use TS_STD on winsorized r_on (e.g., clip at ±3σ using rolling std/mean) or use EWMA volatility (still one window parameter, e.g., 60).\n   - Test GapZ windows: 20/60/120 (each is a different factor).\n3) Improve “hold/acceptance” proxy:\n   - Replace CLV with a simpler close-position metric that’s less unstable: Hold2 = sign(r_on) * ( (close-low)/(high-low+eps) - 0.5 )*2 (equivalent scale but easier to reason about), and/or require a minimum range filter: (high-low)/close > threshold (fixed threshold becomes a parameter; keep small count).\n4) Regime gating instead of multiplying everything:\n   - Soft gate: F = GapZ * (Align) * (Hold) is sensitive to noise sign flips. Try F = GapZ * sign(r_on) * (w1*Align + w2*Hold) with fixed simple weights (e.g., 0.5/0.5) to reduce multiplicative brittleness.\n   - Alternatively: F = GapZ * min(Align, Hold) to enforce “both must agree” without explosive scaling.\n5) Asymmetry checks (separate up-gap and down-gap):\n   - Build two separate factors: one computed only when r_on>0, one when r_on<0 (set others to NaN). Often down gaps have stronger reversal dynamics.\n6) Horizon-consistent labeling alignment:\n   - Since hypothesis mentions 1–3 day reversal vs 5/10 day continuation, consider producing two distinct signals explicitly optimized for each horizon (don’t force one soft-switch to serve both). Even if Qlib model learns combination, clearer primitives often improve IC.\n\nParameter sensitivity grid to explore next (each combination is a distinct factor):\n- Align window: 5, 10, 20\n- GapZ vol window: 20, 60, 120\n- Optional: replace simple std with EWMA(halflife=20/60) if supported; otherwise keep TS_STD.\n\nComplexity control:\n- Current expressions are relatively compact and use only OHLC (4 base features) and simple rolling ops; no explicit complexity red flags here. Keep it that way—avoid adding many conditional branches/extra raw features at once. If adding volume confirmation, do it as one minimal modifier (e.g., multiply by rank(volume/TS_MEAN(volume,20)))."
      }
    },
    "e63f3efb75fa8b86": {
      "factor_id": "e63f3efb75fa8b86",
      "factor_name": "OvernightGap_SoftSwitchSignal_Align10_GapZ60",
      "factor_expression": "RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10) * (SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8))) )",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK( (ABS(LOG($open/(DELAY($close,1)+1e-8)))/(TS_STD(LOG($open/(DELAY($close,1)+1e-8)),60)+1e-8)) * TS_MEAN(SIGN(LOG($open/(DELAY($close,1)+1e-8)))*SIGN(LOG(($close+1e-8)/($open+1e-8))),10) * (SIGN(LOG($open/(DELAY($close,1)+1e-8)))*((2*$close-$high-$low)/($high-$low+1e-8))) )\" # Your output factor expression will be filled in here\n    name = \"OvernightGap_SoftSwitchSignal_Align10_GapZ60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Single soft-switch signal that continuously transitions between continuation (positive) and reversal (negative) regimes using rolling overnight–intraday sign alignment and CLV directionality, scaled by an overnight-gap z-score. Positive values favor continuation; negative values favor reversal.",
      "factor_formulation": "F=\\text{rank}\\Big( GapZ \\cdot Align \\cdot Hold \\Big),\\; GapZ=\\frac{|r_{on}|}{\\sigma_{60}(r_{on})+\\epsilon},\\; Align=\\mu_{10}(\\text{sign}(r_{on})\\text{sign}(r_{id})),\\; Hold=\\text{sign}(r_{on})\\cdot CLV.",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "4217c81ecb02",
        "parent_trajectory_ids": [
          "06ea1f2a601a"
        ],
        "hypothesis": "Hypothesis: Overnight gap acceptance predicts short-horizon returns: when a stock shows a statistically large overnight return (r_on) that is consistently followed by same-signed intraday return (r_id) and a close near the day’s extreme in the gap direction (high signed CLV), the gap reflects informed repricing and tends to continue over the next 5/10 trading days; when large overnight gaps are systematically faded intraday with closes near the opposite extreme, they represent transient shocks and tend to mean-revert over the next 1–3 days, and a regime score based on rolling overnight–intraday alignment should soft-switch between continuation and reversal signals.\n                Concise Observation: The provided dataset contains only OHLCV, so decomposing returns into overnight (open vs prior close), intraday (close vs open), and close-location-within-range (CLV) enables a regime definition and signal construction that is fully testable without using dollar-volume, Amihud illiquidity, or realized-volatility gating used by the parent strategy.\n                Concise Justification: Overnight gaps proxy discrete information shocks, while intraday path and close location proxy whether that shock is accepted or reversed by continuous trading; therefore, conditioning on multi-day persistence of r_on–r_id sign agreement should separate informed repricing (continuation) from overreaction/temporary pressure (reversal), producing a predictive factor that is orthogonal to liquidity/impact-based regime signals.\n                Concise Knowledge: If new information is incorporated primarily in the opening auction, then large overnight gaps that are accepted (same-signed r_id and close near the gap-direction extreme) imply demand/supply imbalance persists and next-5/10d returns should continue; when the market rejects the open (opposite-signed r_id and close near the opposite extreme), the gap is more likely liquidity/positioning-driven and subsequent returns should mean-revert over the next few days.\n                concise Specification: Use only open/high/low/close (no volume) and define: r_on(t)=log(open_t/close_{t-1}), r_id(t)=log(close_t/open_t), CLV(t)=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), Hold(t)=sign(r_on(t))*CLV(t); GapZ(t)=|r_on(t)| / (TS_STD(r_on,60)+1e-8) (lookback=60); Alignment(t)=TS_MEAN(sign(r_on)*sign(r_id),10) (lookback=10); ContinuationScore(t)=GapZ(t)*max(0,Alignment(t))*max(0,Hold(t)); ReversalScore(t)=GapZ(t)*max(0,-Alignment(t))*max(0,-Hold(t)); FinalFactor(t)=RANK(ContinuationScore(t)) - RANK(ReversalScore(t)) computed cross-sectionally each day; expected relationship: higher FinalFactor predicts higher next-5d and next-10d returns, while strongly negative FinalFactor predicts lower/mean-reverting near-term returns; hyperparameters are fixed at Alignment window=10, GapZ window=60, CLV epsilon=1e-8, and horizons to evaluate are 5d and 10d.\n                ",
        "initial_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "planning_direction": "Regime-conditional trend stability: Test whether high RSQR10 (stable 10d trend) combined with low KLEN and low WVMA5 predicts positive next-5/10d returns (trend continuation), versus the opposite regime (low RSQR10 + high KLEN/WVMA5) predicting mean reversion.",
        "created_at": "2026-01-22T07:09:17.335237"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191241001857718,
        "ICIR": 0.0352785819025865,
        "1day.excess_return_without_cost.std": 0.0045245889282566,
        "1day.excess_return_with_cost.annualized_return": 0.0170968648005002,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002690060484233,
        "1day.excess_return_without_cost.annualized_return": 0.0640234395247516,
        "1day.excess_return_with_cost.std": 0.0045269733205749,
        "Rank IC": 0.021713631097361,
        "IC": 0.004853034693216,
        "1day.excess_return_without_cost.max_drawdown": -0.0938172367718469,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9172155206274506,
        "1day.pa": 0.0,
        "l2.valid": 0.9964641576726604,
        "Rank ICIR": 0.1613350115769271,
        "l2.train": 0.9931204955787544,
        "1day.excess_return_with_cost.information_ratio": 0.2448048760169127,
        "1day.excess_return_with_cost.mean": 7.183556638865645e-05
      },
      "feedback": {
        "observations": "The combined run improves annualized return (0.0640 vs 0.0520 SOTA), but deteriorates on risk-adjusted quality and signal quality: max drawdown is worse (0.0938 vs 0.0726; smaller is better), information ratio is lower (0.9172 vs 0.9726), and IC is lower (0.00485 vs 0.00580). This pattern suggests the factor family is capturing some profitable behavior, but with weaker consistency/cross-sectional predictability and poorer downside control than the prior best.",
        "hypothesis_evaluation": "Partially supports the hypothesis: the improved annualized return is consistent with the idea that an overnight-gap “acceptance vs rejection” regime contains exploitable information. However, the lower IC and IR indicate the regime/acceptance definition (Align10 × Hold × GapZ60 with ranks) is not yet reliably separating winners/losers cross-sectionally, and the worse drawdown suggests the signal may be intermittently wrong in stress/whipsaw regimes (e.g., large gaps around market-wide events) or is too reactive.\n\nWithin-hypothesis interpretation:\n- The annualized uplift supports that overnight gaps + intraday confirmation contains continuation/reversal structure.\n- The deterioration in IC/IR refutes (or at least weakens) the claim that the current “soft-switch” implementation is a robust regime classifier; it may be capturing return via exposure/tilts rather than stable predictive correlation.\n\nHyperparameters explicitly present in the tested factors:\n- Align lookback window: 10 days (TS_MEAN of sign agreement)\n- GapZ volatility window: 60 days (TS_STD of r_on)\n- Returns definition: overnight r_on = log(open_t/close_{t-1}); intraday r_id = log(close_t/open_t)\n- CLV definition uses daily range (high-low) with epsilon in denominator\n- Cross-sectional transformation: RANK(·) applied to the final composite\nThese are the key knobs to vary next; treat each (AlignX, GapZY) as a distinct factor instance.",
        "decision": true,
        "reason": "Why the current implementation likely under-delivers on IC/IR while improving return:\n- Using SIGN(r_on)*SIGN(r_id) discards magnitude; a tiny intraday move counts as full “acceptance,” adding noise.\n- CLV can be unstable on small-range days (high≈low) even with epsilon; it may inject noise exactly when the range is compressed.\n- Full cross-sectional RANK on the final product may distort the intended regime interpretation (continuation vs reversal) and can amplify small measurement errors.\n- GapZ = |r_on|/std60(r_on) treats upside and downside symmetrically; continuation/reversal may be asymmetric (down gaps often behave differently).\n\nConcrete next iterations (stay in the same theoretical framework, prioritize simplicity):\n1) Magnitude-aware alignment (replace pure sign agreement):\n   - AlignMag10 = TS_MEAN( r_on * r_id, 10 ) or TS_MEAN( tanh(k*r_on)*tanh(k*r_id), 10 ) with a fixed k (e.g., k=5) to bound extremes.\n   - Keep windows identical initially: AlignMag10 + GapZ60 to isolate impact.\n2) Make GapZ more robust:\n   - Use TS_STD on winsorized r_on (e.g., clip at ±3σ using rolling std/mean) or use EWMA volatility (still one window parameter, e.g., 60).\n   - Test GapZ windows: 20/60/120 (each is a different factor).\n3) Improve “hold/acceptance” proxy:\n   - Replace CLV with a simpler close-position metric that’s less unstable: Hold2 = sign(r_on) * ( (close-low)/(high-low+eps) - 0.5 )*2 (equivalent scale but easier to reason about), and/or require a minimum range filter: (high-low)/close > threshold (fixed threshold becomes a parameter; keep small count).\n4) Regime gating instead of multiplying everything:\n   - Soft gate: F = GapZ * (Align) * (Hold) is sensitive to noise sign flips. Try F = GapZ * sign(r_on) * (w1*Align + w2*Hold) with fixed simple weights (e.g., 0.5/0.5) to reduce multiplicative brittleness.\n   - Alternatively: F = GapZ * min(Align, Hold) to enforce “both must agree” without explosive scaling.\n5) Asymmetry checks (separate up-gap and down-gap):\n   - Build two separate factors: one computed only when r_on>0, one when r_on<0 (set others to NaN). Often down gaps have stronger reversal dynamics.\n6) Horizon-consistent labeling alignment:\n   - Since hypothesis mentions 1–3 day reversal vs 5/10 day continuation, consider producing two distinct signals explicitly optimized for each horizon (don’t force one soft-switch to serve both). Even if Qlib model learns combination, clearer primitives often improve IC.\n\nParameter sensitivity grid to explore next (each combination is a distinct factor):\n- Align window: 5, 10, 20\n- GapZ vol window: 20, 60, 120\n- Optional: replace simple std with EWMA(halflife=20/60) if supported; otherwise keep TS_STD.\n\nComplexity control:\n- Current expressions are relatively compact and use only OHLC (4 base features) and simple rolling ops; no explicit complexity red flags here. Keep it that way—avoid adding many conditional branches/extra raw features at once. If adding volume confirmation, do it as one minimal modifier (e.g., multiply by rank(volume/TS_MEAN(volume,20)))."
      }
    },
    "62bd7738cc3ce19d": {
      "factor_id": "62bd7738cc3ce19d",
      "factor_name": "Overnight_Share_Acceptance_10D",
      "factor_expression": "RANK(TS_MEAN(SIGN($open/DELAY($close,1)-1)*(2*$close-$high-$low)/($high-$low+1e-8)*ABS($open/DELAY($close,1)-1)/(ABS($open/DELAY($close,1)-1)+ABS($close/$open-1)+1e-8),10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(SIGN($open/DELAY($close,1)-1)*(2*$close-$high-$low)/($high-$low+1e-8)*ABS($open/DELAY($close,1)-1)/(ABS($open/DELAY($close,1)-1)+ABS($close/$open-1)+1e-8),10))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Share_Acceptance_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures whether returns are primarily realized overnight and then accepted intraday. Positive when the overnight gap dominates total (gap+intraday) move and the close finishes aligned with the gap direction within the daily range; averaged over 10 days.",
      "factor_formulation": "F_t=\\operatorname{RANK}\\left(\\frac{1}{10}\\sum_{i=0}^{9}\\Big[\\frac{|r^{ON}_{t-i}|}{|r^{ON}_{t-i}|+|r^{ID}_{t-i}|+\\epsilon}\\cdot \\operatorname{sign}(r^{ON}_{t-i})\\cdot CLV_{t-i}\\Big]\\right),\\; r^{ON}_t=\\frac{open_t}{close_{t-1}}-1,\\; r^{ID}_t=\\frac{close_t}{open_t}-1,\\; CLV_t=\\frac{2close_t-high_t-low_t}{high_t-low_t+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "23d11b9192a3",
        "parent_trajectory_ids": [
          "597c8ddd966c"
        ],
        "hypothesis": "Hypothesis: OHLC-only time-of-day price discovery is predictive: stocks whose returns are primarily realized overnight (prev_close→open gaps) and are intraday-accepted (close near the gap direction extreme) will trend-continue over the next 3–10 trading days, while stocks with large normalized gaps that are intraday-faded (open gap reversed by open→close move and close away from the gap direction) will mean-revert over the next 1–3 trading days.\n                Concise Observation: The available dataset provides daily OHLC (and volume, though not required here), enabling explicit decomposition into overnight return rON=open/lag(close,1)-1 and intraday return rID=close/open-1, plus acceptance/rejection proxies like close-location-value (CLV) and gap size normalized by recent average range, which are orthogonal to the parent strategy’s volume/impact and volatility-compression/breakout constructs.\n                Concise Justification: Overnight gaps can reflect discrete information arrival and repricing, whereas intraday moves are more exposed to liquidity provision and mean-reversion; combining (i) where the return occurred (overnight share) with (ii) whether the market accepted or rejected that move intraday (CLV and fade) yields a testable, structurally distinct signal that can separate continuation from reversal without using volume, impact proxies, or breakout/vol-compression regimes.\n                Concise Knowledge: If information is incorporated outside regular trading hours, then close→open gaps that are not reversed intraday (acceptance: close remains near the gap-direction extreme) should persist for several days; when a large gap is quickly offset during the open→close session (rejection: strong fade and weak close-location in the gap direction), the move is more likely liquidity-driven and should revert over short horizons.\n                concise Specification: Define rON_t=open_t/close_{t-1}-1, rID_t=close_t/open_t-1, range_t=(high_t-low_t)/(close_{t-1}+1e-8), CLV_t=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), gapNorm_t=rON_t/(TS_MEAN(range,20)+1e-8), fade_t=-SIGN(rON_t)*rID_t (positive=fading the gap), accept_t=SIGN(rON_t)*CLV_t (positive=close aligned with gap direction); test a single regime-gated OHLC factor with fixed hyperparameters: Continuation leg = TS_SUM(rON,5)*TS_MEAN(accept,5) applied when TS_MEAN(|rON|/(|rON|+|rID|+1e-8),10)>0.6, and Reversal leg = -fade_t*|gapNorm_t| applied only when |gapNorm_t|>1.5 and accept_t<0; the factor output is (Continuation leg) + (Reversal leg), producing one daily value per instrument.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-22T07:16:11.291612"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1101712468649927,
        "ICIR": 0.0451876851284083,
        "1day.excess_return_without_cost.std": 0.0039765850729095,
        "1day.excess_return_with_cost.annualized_return": 0.0095868089933018,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002388152178642,
        "1day.excess_return_without_cost.annualized_return": 0.0568380218516809,
        "1day.excess_return_with_cost.std": 0.0039773513892881,
        "Rank IC": 0.0221239584971658,
        "IC": 0.006200789125935,
        "1day.excess_return_without_cost.max_drawdown": -0.0843326966216749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.926488852321773,
        "1day.pa": 0.0,
        "l2.valid": 0.9964933009488044,
        "Rank ICIR": 0.1653984771182664,
        "l2.train": 0.9940714395248224,
        "1day.excess_return_with_cost.information_ratio": 0.1562397856819422,
        "1day.excess_return_with_cost.mean": 4.028071005589008e-05
      },
      "feedback": {
        "observations": "The combined OHLC-only gap/acceptance family delivers a small but clear uplift in predictive signal: IC improves from 0.005798 → 0.006201 and annualized return improves from 0.0520 → 0.0568. However, risk-adjusted quality deteriorates: information ratio drops (0.9726 → 0.9265) and max drawdown worsens (-0.0726 → -0.0843). This pattern is consistent with a signal that is directionally helpful but currently expressed with higher variance/less stable payoff (likely mixing continuation and reversal regimes without enough gating).\n\nHyperparameters explicitly present in the tested factors:\n- Overnight_Share_Acceptance_10D: lookback/aggregation window = 10 trading days; uses CLV computed from (high, low, close) per day; epsilon constant for denominators.\n- Gap_Accepted_Continuation_5x20: gap z-score window = 20; acceptance averaging window = 5; epsilon for CLV denominator.\n- Normalized_Gap_Fade_Reversal_20D: rolling STD window on overnight returns = 20; epsilon for denominator.\n\nComplexity check: All three are short expressions, use only OHLC (4 raw fields), and have few free parameters (10/5/20 windows + epsilon). No overfitting red flags from symbol length or feature-count perspective.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that overnight price discovery + intraday acceptance carries predictive information. The fact that both IC and annualized return improved suggests the overnight-vs-intraday decomposition is capturing a real return component.\n\nWhat is not yet fully validated is the *two-regime horizon claim* (trend-continue for accepted gaps over 3–10 days vs mean-revert for faded large gaps over 1–3 days), because the current evaluation is presented at 1-day excess return metrics only. The mixed outcomes (higher return but lower IR and worse drawdown) are consistent with regime mixing: continuation and reversal signals may be firing simultaneously or canceling in some market states, creating noisier day-to-day PnL.\n\nFactor-by-factor construction notes (within the same framework):\n- Overnight_Share_Acceptance_10D: The “overnight share” term |rON|/(|rON|+|rID|) is sensible, but it can become unstable when both legs are small; consider adding a *minimum move filter* (see suggestions) rather than relying solely on epsilon.\n- Gap_Accepted_Continuation_5x20: Using Z(rON;20) on day t multiplied by 5-day mean of sign(rON)*CLV is coherent for continuation, but it may be overly sensitive to single-day gap shocks; consider smoothing rON or using a 2–3 day mean of rON before z-scoring.\n- Normalized_Gap_Fade_Reversal_20D: The “fade” term (-sign(rON)*rID*|rON/std20|) is aligned to the hypothesis. If this is mixed into a single combined alpha with continuation proxies, it can increase variance unless you gate it to high-gap-shock days.\n\nCompared to SOTA: you improved on the two key ‘edge’ metrics (annualized return and IC) but lost on stability metrics (IR, drawdown). That suggests the hypothesis is promising, but the implementation likely needs regime control / robustness improvements.",
        "decision": true,
        "reason": "Your three implemented factors implicitly represent two different behaviors (acceptance/continuation vs fade/reversal). When both are simultaneously active (e.g., large gap day that partially fades but still closes mid-range), a linear combination or naive model ingestion can produce unstable exposures. This plausibly explains: higher average returns (signal exists) but worse IR and max drawdown (payoff is less consistent).\n\nConcrete refinement directions (still OHLC-only, and keeping simplicity):\n1) Add explicit regime gates (hard or soft) rather than blending:\n   - Continuation gate: Gc = 1[ |Z(rON;20)| < z_th ] * 1[ sign(rON)*CLV > clv_th ] (or a smooth sigmoid). Then ContinuationFactor = RANK( TS_MEAN(sign(rON)*CLV, 5) * TS_MEAN(rON, 2–3) ).\n   - Reversal gate: Gr = 1[ |Z(rON;20)| > z_th ] * 1[ -sign(rON)*rID > id_th ]. Then ReversalFactor = RANK( (-sign(rON)*rID) * |Z(rON;20)| ).\n   Hyperparameters to sweep: z_th in {1.0, 1.5, 2.0}; clv_th in {0.2, 0.3, 0.4}; id_th in {0, 0.25%, 0.5%}.\n\n2) Horizon-specific labeling / evaluation:\n   - Since the hypothesis is explicitly 1–3 day reversal vs 3–10 day continuation, evaluate and/or train separate models per horizon (e.g., y=next 2-day return for reversal; y=next 5- or 10-day return for continuation). The current 1-day metrics may under-represent the continuation leg.\n\n3) Robustness against small-move noise:\n   - Replace |rON|+|rID| in the denominator with (|rON|+|rID|) clipped by a small threshold based on range: max(|rON|+|rID|, k*(high-low)/close). Sweep k in {0.1, 0.2, 0.3}.\n\n4) Simplify cross-sectional transforms to reduce tail risk:\n   - Try winsorization/clipping of the pre-rank signal (e.g., clip to [-3, 3] in z-space) before RANK. This often improves drawdown/IR with minimal IC loss.\n\n5) Reduce redundancy / collinearity:\n   - Orthogonalize the reversal proxy against the continuation proxy cross-sectionally (simple regression residual each day). This can improve IR and reduce drawdown by preventing unintended net exposures when both fire.\n\nThese changes preserve the original theory (overnight discovery + intraday acceptance/fade) while directly targeting the observed weakness (lower IR, higher drawdown)."
      }
    },
    "bda19c9cde69be67": {
      "factor_id": "bda19c9cde69be67",
      "factor_name": "Gap_Accepted_Continuation_5x20",
      "factor_expression": "RANK(TS_ZSCORE($open/DELAY($close,1)-1,20)*TS_MEAN(SIGN($open/DELAY($close,1)-1)*(2*$close-$high-$low)/($high-$low+1e-8),5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($open/DELAY($close,1)-1,20)*TS_MEAN(SIGN($open/DELAY($close,1)-1)*(2*$close-$high-$low)/($high-$low+1e-8),5))\" # Your output factor expression will be filled in here\n    name = \"Gap_Accepted_Continuation_5x20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation proxy: large recent overnight gaps (standardized over 20 days) that are consistently accepted intraday (5-day mean close-location aligned with gap sign).",
      "factor_formulation": "F_t=\\operatorname{RANK}\\Big(\\operatorname{Z}(r^{ON}_t;20)\\cdot \\frac{1}{5}\\sum_{i=0}^{4}[\\operatorname{sign}(r^{ON}_{t-i})\\cdot CLV_{t-i}]\\Big)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "23d11b9192a3",
        "parent_trajectory_ids": [
          "597c8ddd966c"
        ],
        "hypothesis": "Hypothesis: OHLC-only time-of-day price discovery is predictive: stocks whose returns are primarily realized overnight (prev_close→open gaps) and are intraday-accepted (close near the gap direction extreme) will trend-continue over the next 3–10 trading days, while stocks with large normalized gaps that are intraday-faded (open gap reversed by open→close move and close away from the gap direction) will mean-revert over the next 1–3 trading days.\n                Concise Observation: The available dataset provides daily OHLC (and volume, though not required here), enabling explicit decomposition into overnight return rON=open/lag(close,1)-1 and intraday return rID=close/open-1, plus acceptance/rejection proxies like close-location-value (CLV) and gap size normalized by recent average range, which are orthogonal to the parent strategy’s volume/impact and volatility-compression/breakout constructs.\n                Concise Justification: Overnight gaps can reflect discrete information arrival and repricing, whereas intraday moves are more exposed to liquidity provision and mean-reversion; combining (i) where the return occurred (overnight share) with (ii) whether the market accepted or rejected that move intraday (CLV and fade) yields a testable, structurally distinct signal that can separate continuation from reversal without using volume, impact proxies, or breakout/vol-compression regimes.\n                Concise Knowledge: If information is incorporated outside regular trading hours, then close→open gaps that are not reversed intraday (acceptance: close remains near the gap-direction extreme) should persist for several days; when a large gap is quickly offset during the open→close session (rejection: strong fade and weak close-location in the gap direction), the move is more likely liquidity-driven and should revert over short horizons.\n                concise Specification: Define rON_t=open_t/close_{t-1}-1, rID_t=close_t/open_t-1, range_t=(high_t-low_t)/(close_{t-1}+1e-8), CLV_t=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), gapNorm_t=rON_t/(TS_MEAN(range,20)+1e-8), fade_t=-SIGN(rON_t)*rID_t (positive=fading the gap), accept_t=SIGN(rON_t)*CLV_t (positive=close aligned with gap direction); test a single regime-gated OHLC factor with fixed hyperparameters: Continuation leg = TS_SUM(rON,5)*TS_MEAN(accept,5) applied when TS_MEAN(|rON|/(|rON|+|rID|+1e-8),10)>0.6, and Reversal leg = -fade_t*|gapNorm_t| applied only when |gapNorm_t|>1.5 and accept_t<0; the factor output is (Continuation leg) + (Reversal leg), producing one daily value per instrument.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-22T07:16:11.291612"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1101712468649927,
        "ICIR": 0.0451876851284083,
        "1day.excess_return_without_cost.std": 0.0039765850729095,
        "1day.excess_return_with_cost.annualized_return": 0.0095868089933018,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002388152178642,
        "1day.excess_return_without_cost.annualized_return": 0.0568380218516809,
        "1day.excess_return_with_cost.std": 0.0039773513892881,
        "Rank IC": 0.0221239584971658,
        "IC": 0.006200789125935,
        "1day.excess_return_without_cost.max_drawdown": -0.0843326966216749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.926488852321773,
        "1day.pa": 0.0,
        "l2.valid": 0.9964933009488044,
        "Rank ICIR": 0.1653984771182664,
        "l2.train": 0.9940714395248224,
        "1day.excess_return_with_cost.information_ratio": 0.1562397856819422,
        "1day.excess_return_with_cost.mean": 4.028071005589008e-05
      },
      "feedback": {
        "observations": "The combined OHLC-only gap/acceptance family delivers a small but clear uplift in predictive signal: IC improves from 0.005798 → 0.006201 and annualized return improves from 0.0520 → 0.0568. However, risk-adjusted quality deteriorates: information ratio drops (0.9726 → 0.9265) and max drawdown worsens (-0.0726 → -0.0843). This pattern is consistent with a signal that is directionally helpful but currently expressed with higher variance/less stable payoff (likely mixing continuation and reversal regimes without enough gating).\n\nHyperparameters explicitly present in the tested factors:\n- Overnight_Share_Acceptance_10D: lookback/aggregation window = 10 trading days; uses CLV computed from (high, low, close) per day; epsilon constant for denominators.\n- Gap_Accepted_Continuation_5x20: gap z-score window = 20; acceptance averaging window = 5; epsilon for CLV denominator.\n- Normalized_Gap_Fade_Reversal_20D: rolling STD window on overnight returns = 20; epsilon for denominator.\n\nComplexity check: All three are short expressions, use only OHLC (4 raw fields), and have few free parameters (10/5/20 windows + epsilon). No overfitting red flags from symbol length or feature-count perspective.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that overnight price discovery + intraday acceptance carries predictive information. The fact that both IC and annualized return improved suggests the overnight-vs-intraday decomposition is capturing a real return component.\n\nWhat is not yet fully validated is the *two-regime horizon claim* (trend-continue for accepted gaps over 3–10 days vs mean-revert for faded large gaps over 1–3 days), because the current evaluation is presented at 1-day excess return metrics only. The mixed outcomes (higher return but lower IR and worse drawdown) are consistent with regime mixing: continuation and reversal signals may be firing simultaneously or canceling in some market states, creating noisier day-to-day PnL.\n\nFactor-by-factor construction notes (within the same framework):\n- Overnight_Share_Acceptance_10D: The “overnight share” term |rON|/(|rON|+|rID|) is sensible, but it can become unstable when both legs are small; consider adding a *minimum move filter* (see suggestions) rather than relying solely on epsilon.\n- Gap_Accepted_Continuation_5x20: Using Z(rON;20) on day t multiplied by 5-day mean of sign(rON)*CLV is coherent for continuation, but it may be overly sensitive to single-day gap shocks; consider smoothing rON or using a 2–3 day mean of rON before z-scoring.\n- Normalized_Gap_Fade_Reversal_20D: The “fade” term (-sign(rON)*rID*|rON/std20|) is aligned to the hypothesis. If this is mixed into a single combined alpha with continuation proxies, it can increase variance unless you gate it to high-gap-shock days.\n\nCompared to SOTA: you improved on the two key ‘edge’ metrics (annualized return and IC) but lost on stability metrics (IR, drawdown). That suggests the hypothesis is promising, but the implementation likely needs regime control / robustness improvements.",
        "decision": true,
        "reason": "Your three implemented factors implicitly represent two different behaviors (acceptance/continuation vs fade/reversal). When both are simultaneously active (e.g., large gap day that partially fades but still closes mid-range), a linear combination or naive model ingestion can produce unstable exposures. This plausibly explains: higher average returns (signal exists) but worse IR and max drawdown (payoff is less consistent).\n\nConcrete refinement directions (still OHLC-only, and keeping simplicity):\n1) Add explicit regime gates (hard or soft) rather than blending:\n   - Continuation gate: Gc = 1[ |Z(rON;20)| < z_th ] * 1[ sign(rON)*CLV > clv_th ] (or a smooth sigmoid). Then ContinuationFactor = RANK( TS_MEAN(sign(rON)*CLV, 5) * TS_MEAN(rON, 2–3) ).\n   - Reversal gate: Gr = 1[ |Z(rON;20)| > z_th ] * 1[ -sign(rON)*rID > id_th ]. Then ReversalFactor = RANK( (-sign(rON)*rID) * |Z(rON;20)| ).\n   Hyperparameters to sweep: z_th in {1.0, 1.5, 2.0}; clv_th in {0.2, 0.3, 0.4}; id_th in {0, 0.25%, 0.5%}.\n\n2) Horizon-specific labeling / evaluation:\n   - Since the hypothesis is explicitly 1–3 day reversal vs 3–10 day continuation, evaluate and/or train separate models per horizon (e.g., y=next 2-day return for reversal; y=next 5- or 10-day return for continuation). The current 1-day metrics may under-represent the continuation leg.\n\n3) Robustness against small-move noise:\n   - Replace |rON|+|rID| in the denominator with (|rON|+|rID|) clipped by a small threshold based on range: max(|rON|+|rID|, k*(high-low)/close). Sweep k in {0.1, 0.2, 0.3}.\n\n4) Simplify cross-sectional transforms to reduce tail risk:\n   - Try winsorization/clipping of the pre-rank signal (e.g., clip to [-3, 3] in z-space) before RANK. This often improves drawdown/IR with minimal IC loss.\n\n5) Reduce redundancy / collinearity:\n   - Orthogonalize the reversal proxy against the continuation proxy cross-sectionally (simple regression residual each day). This can improve IR and reduce drawdown by preventing unintended net exposures when both fire.\n\nThese changes preserve the original theory (overnight discovery + intraday acceptance/fade) while directly targeting the observed weakness (lower IR, higher drawdown)."
      }
    },
    "2c424b6fdd101ad7": {
      "factor_id": "2c424b6fdd101ad7",
      "factor_name": "Normalized_Gap_Fade_Reversal_20D",
      "factor_expression": "RANK(-SIGN($open/DELAY($close,1)-1)*($close/$open-1)*ABS(($open/DELAY($close,1)-1)/(TS_STD($open/DELAY($close,1)-1,20)+1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-SIGN($open/DELAY($close,1)-1)*($close/$open-1)*ABS(($open/DELAY($close,1)-1)/(TS_STD($open/DELAY($close,1)-1,20)+1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Gap_Fade_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Mean-reversion proxy: penalizes intraday moves that fade the overnight gap, scaled by how unusually large the gap is versus its own 20-day volatility (gap shock). More positive indicates stronger fade of an unusually large gap (reversal pressure).",
      "factor_formulation": "F_t=\\operatorname{RANK}\\left(-\\operatorname{sign}(r^{ON}_t)\\cdot r^{ID}_t\\cdot \\left|\\frac{r^{ON}_t}{\\operatorname{STD}(r^{ON};20)+\\epsilon}\\right|\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "23d11b9192a3",
        "parent_trajectory_ids": [
          "597c8ddd966c"
        ],
        "hypothesis": "Hypothesis: OHLC-only time-of-day price discovery is predictive: stocks whose returns are primarily realized overnight (prev_close→open gaps) and are intraday-accepted (close near the gap direction extreme) will trend-continue over the next 3–10 trading days, while stocks with large normalized gaps that are intraday-faded (open gap reversed by open→close move and close away from the gap direction) will mean-revert over the next 1–3 trading days.\n                Concise Observation: The available dataset provides daily OHLC (and volume, though not required here), enabling explicit decomposition into overnight return rON=open/lag(close,1)-1 and intraday return rID=close/open-1, plus acceptance/rejection proxies like close-location-value (CLV) and gap size normalized by recent average range, which are orthogonal to the parent strategy’s volume/impact and volatility-compression/breakout constructs.\n                Concise Justification: Overnight gaps can reflect discrete information arrival and repricing, whereas intraday moves are more exposed to liquidity provision and mean-reversion; combining (i) where the return occurred (overnight share) with (ii) whether the market accepted or rejected that move intraday (CLV and fade) yields a testable, structurally distinct signal that can separate continuation from reversal without using volume, impact proxies, or breakout/vol-compression regimes.\n                Concise Knowledge: If information is incorporated outside regular trading hours, then close→open gaps that are not reversed intraday (acceptance: close remains near the gap-direction extreme) should persist for several days; when a large gap is quickly offset during the open→close session (rejection: strong fade and weak close-location in the gap direction), the move is more likely liquidity-driven and should revert over short horizons.\n                concise Specification: Define rON_t=open_t/close_{t-1}-1, rID_t=close_t/open_t-1, range_t=(high_t-low_t)/(close_{t-1}+1e-8), CLV_t=(2*close_t-high_t-low_t)/(high_t-low_t+1e-8), gapNorm_t=rON_t/(TS_MEAN(range,20)+1e-8), fade_t=-SIGN(rON_t)*rID_t (positive=fading the gap), accept_t=SIGN(rON_t)*CLV_t (positive=close aligned with gap direction); test a single regime-gated OHLC factor with fixed hyperparameters: Continuation leg = TS_SUM(rON,5)*TS_MEAN(accept,5) applied when TS_MEAN(|rON|/(|rON|+|rID|+1e-8),10)>0.6, and Reversal leg = -fade_t*|gapNorm_t| applied only when |gapNorm_t|>1.5 and accept_t<0; the factor output is (Continuation leg) + (Reversal leg), producing one daily value per instrument.\n                ",
        "initial_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "planning_direction": "Asymmetry of volatility with price-volume resonance: Construct a signed factor = sign(ROC1)*WVMA5 and interact with KLEN; hypothesize that high WVMA5 with large KLEN after negative daily returns forecasts further downside (panic continuation) while the same after positive daily returns forecasts reversal (exhaustion).",
        "created_at": "2026-01-22T07:16:11.291612"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1101712468649927,
        "ICIR": 0.0451876851284083,
        "1day.excess_return_without_cost.std": 0.0039765850729095,
        "1day.excess_return_with_cost.annualized_return": 0.0095868089933018,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002388152178642,
        "1day.excess_return_without_cost.annualized_return": 0.0568380218516809,
        "1day.excess_return_with_cost.std": 0.0039773513892881,
        "Rank IC": 0.0221239584971658,
        "IC": 0.006200789125935,
        "1day.excess_return_without_cost.max_drawdown": -0.0843326966216749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.926488852321773,
        "1day.pa": 0.0,
        "l2.valid": 0.9964933009488044,
        "Rank ICIR": 0.1653984771182664,
        "l2.train": 0.9940714395248224,
        "1day.excess_return_with_cost.information_ratio": 0.1562397856819422,
        "1day.excess_return_with_cost.mean": 4.028071005589008e-05
      },
      "feedback": {
        "observations": "The combined OHLC-only gap/acceptance family delivers a small but clear uplift in predictive signal: IC improves from 0.005798 → 0.006201 and annualized return improves from 0.0520 → 0.0568. However, risk-adjusted quality deteriorates: information ratio drops (0.9726 → 0.9265) and max drawdown worsens (-0.0726 → -0.0843). This pattern is consistent with a signal that is directionally helpful but currently expressed with higher variance/less stable payoff (likely mixing continuation and reversal regimes without enough gating).\n\nHyperparameters explicitly present in the tested factors:\n- Overnight_Share_Acceptance_10D: lookback/aggregation window = 10 trading days; uses CLV computed from (high, low, close) per day; epsilon constant for denominators.\n- Gap_Accepted_Continuation_5x20: gap z-score window = 20; acceptance averaging window = 5; epsilon for CLV denominator.\n- Normalized_Gap_Fade_Reversal_20D: rolling STD window on overnight returns = 20; epsilon for denominator.\n\nComplexity check: All three are short expressions, use only OHLC (4 raw fields), and have few free parameters (10/5/20 windows + epsilon). No overfitting red flags from symbol length or feature-count perspective.",
        "hypothesis_evaluation": "Overall, the results support (not refute) the hypothesis that overnight price discovery + intraday acceptance carries predictive information. The fact that both IC and annualized return improved suggests the overnight-vs-intraday decomposition is capturing a real return component.\n\nWhat is not yet fully validated is the *two-regime horizon claim* (trend-continue for accepted gaps over 3–10 days vs mean-revert for faded large gaps over 1–3 days), because the current evaluation is presented at 1-day excess return metrics only. The mixed outcomes (higher return but lower IR and worse drawdown) are consistent with regime mixing: continuation and reversal signals may be firing simultaneously or canceling in some market states, creating noisier day-to-day PnL.\n\nFactor-by-factor construction notes (within the same framework):\n- Overnight_Share_Acceptance_10D: The “overnight share” term |rON|/(|rON|+|rID|) is sensible, but it can become unstable when both legs are small; consider adding a *minimum move filter* (see suggestions) rather than relying solely on epsilon.\n- Gap_Accepted_Continuation_5x20: Using Z(rON;20) on day t multiplied by 5-day mean of sign(rON)*CLV is coherent for continuation, but it may be overly sensitive to single-day gap shocks; consider smoothing rON or using a 2–3 day mean of rON before z-scoring.\n- Normalized_Gap_Fade_Reversal_20D: The “fade” term (-sign(rON)*rID*|rON/std20|) is aligned to the hypothesis. If this is mixed into a single combined alpha with continuation proxies, it can increase variance unless you gate it to high-gap-shock days.\n\nCompared to SOTA: you improved on the two key ‘edge’ metrics (annualized return and IC) but lost on stability metrics (IR, drawdown). That suggests the hypothesis is promising, but the implementation likely needs regime control / robustness improvements.",
        "decision": true,
        "reason": "Your three implemented factors implicitly represent two different behaviors (acceptance/continuation vs fade/reversal). When both are simultaneously active (e.g., large gap day that partially fades but still closes mid-range), a linear combination or naive model ingestion can produce unstable exposures. This plausibly explains: higher average returns (signal exists) but worse IR and max drawdown (payoff is less consistent).\n\nConcrete refinement directions (still OHLC-only, and keeping simplicity):\n1) Add explicit regime gates (hard or soft) rather than blending:\n   - Continuation gate: Gc = 1[ |Z(rON;20)| < z_th ] * 1[ sign(rON)*CLV > clv_th ] (or a smooth sigmoid). Then ContinuationFactor = RANK( TS_MEAN(sign(rON)*CLV, 5) * TS_MEAN(rON, 2–3) ).\n   - Reversal gate: Gr = 1[ |Z(rON;20)| > z_th ] * 1[ -sign(rON)*rID > id_th ]. Then ReversalFactor = RANK( (-sign(rON)*rID) * |Z(rON;20)| ).\n   Hyperparameters to sweep: z_th in {1.0, 1.5, 2.0}; clv_th in {0.2, 0.3, 0.4}; id_th in {0, 0.25%, 0.5%}.\n\n2) Horizon-specific labeling / evaluation:\n   - Since the hypothesis is explicitly 1–3 day reversal vs 3–10 day continuation, evaluate and/or train separate models per horizon (e.g., y=next 2-day return for reversal; y=next 5- or 10-day return for continuation). The current 1-day metrics may under-represent the continuation leg.\n\n3) Robustness against small-move noise:\n   - Replace |rON|+|rID| in the denominator with (|rON|+|rID|) clipped by a small threshold based on range: max(|rON|+|rID|, k*(high-low)/close). Sweep k in {0.1, 0.2, 0.3}.\n\n4) Simplify cross-sectional transforms to reduce tail risk:\n   - Try winsorization/clipping of the pre-rank signal (e.g., clip to [-3, 3] in z-space) before RANK. This often improves drawdown/IR with minimal IC loss.\n\n5) Reduce redundancy / collinearity:\n   - Orthogonalize the reversal proxy against the continuation proxy cross-sectionally (simple regression residual each day). This can improve IR and reduce drawdown by preventing unintended net exposures when both fire.\n\nThese changes preserve the original theory (overnight discovery + intraday acceptance/fade) while directly targeting the observed weakness (lower IR, higher drawdown)."
      }
    },
    "414904318013ae44": {
      "factor_id": "414904318013ae44",
      "factor_name": "Normalized_Gap_Rejection_Flag_20D",
      "factor_expression": "RANK(-SIGN($open-DELAY($close,1))*ABS(($open-DELAY($close,1))/(TS_MEAN($high-$low,20)+1e-8))*((($close-$open)*($open-DELAY($close,1))<0)?1:0))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-SIGN($open-DELAY($close,1))*ABS(($open-DELAY($close,1))/(TS_MEAN($high-$low,20)+1e-8))*((($close-$open)*($open-DELAY($close,1))<0)?1:0))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Gap_Rejection_Flag_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Mean-reversion proxy for large overnight gaps that are rejected intraday. It scales the open-vs-prev-close gap by a 20-day average range and activates only when the intraday move (close-open) has opposite sign to the gap (rejection).",
      "factor_formulation": "F_t=\\operatorname{RANK}\\Big(-\\operatorname{SIGN}(g_t)\\cdot\\Big|\\frac{g_t}{\\overline{R}_{20,t}+\\epsilon}\\Big|\\cdot\\mathbb{1}[(c_t-o_t)\\cdot g_t<0]\\Big),\\quad g_t=o_t-c_{t-1},\\ \\overline{R}_{20,t}=\\text{TS\\_MEAN}(h_t-l_t,20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8052a4ed296d",
        "parent_trajectory_ids": [
          "155c66a4d708"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are better predicted by OHLC-only “gap acceptance vs rejection” behavior: large normalized overnight gaps that are rejected intraday (close moves back toward prior close/into prior range with strong counter-wick) mean-revert over the next 1–3 days, while large normalized overnight gaps that are accepted intraday (close holds near the extreme in the gap direction and remains outside the prior-day range) exhibit continuation over the next 2–7 days.\n                Concise Observation: Because the available data include open/high/low/close but the parent factors already exploit volume/dollar-volume and impact proxies, focusing on overnight-vs-intraday return decomposition plus candlestick acceptance anatomy (CLV, wick/body ratios, prior-range interaction) uses an orthogonal information channel while remaining fully testable from daily_pv.h5.\n                Concise Justification: Overnight gaps concentrate information and positioning shocks into the opening auction, and the subsequent intraday ‘acceptance’ or ‘rejection’ revealed by close location and wick structure provides a microstructure-like signal about whether the market validates or fades the gap, implying continuation when accepted and mean reversion when rejected.\n                Concise Knowledge: If a large open-to-prev-close gap is not confirmed by the regular session (intraday price action closes back toward prior reference levels and shows strong counter-direction wick), then the gap likely reflects transient overnight overreaction and should revert; when a large gap is confirmed by a close near the day extreme and sustained trading outside the prior day’s range, then the gap likely reflects true repricing and should persist.\n                concise Specification: Compute rON=open/DELAY(close,1)-1 and normalize by ATR20/DELAY(close,1) where ATR20=TS_MEAN(TrueRange(high,low,DELAY(close,1)),20); define acceptance_score using (|gap_z|>1.5) AND close outside prior-day [low,high] AND CLV20? (daily CLV=(close-low)/(high-low+1e-8) mapped to [-0.5,+0.5]) aligned with sign(rON) with small counter-wick ratio, and define rejection_score using (|gap_z|>1.5) AND close returns into prior-day range or toward prior close with large counter-wick and/or sign(rON) != sign(close/DELAY(close,1)-1); test two routed factors: (i) -rejection_score*sign(rON) for 1–3D mean reversion and (ii) +acceptance_score*sign(rON) for 2–7D continuation, using fixed windows {ATR=20, gap threshold=1.5, wick/body computed on 1D range}.\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-22T08:09:50.559824"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.110936534017339,
        "ICIR": 0.0309403611161179,
        "1day.excess_return_without_cost.std": 0.0042093694456759,
        "1day.excess_return_with_cost.annualized_return": 0.0148672213189328,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002599658895775,
        "1day.excess_return_without_cost.annualized_return": 0.0618718817194618,
        "1day.excess_return_with_cost.std": 0.0042103067473731,
        "Rank IC": 0.021938385939547,
        "IC": 0.0043473647932784,
        "1day.excess_return_without_cost.max_drawdown": -0.10347387207149,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9527694024322874,
        "1day.pa": 0.0,
        "l2.valid": 0.9967031076997724,
        "Rank ICIR": 0.1590274742675351,
        "l2.train": 0.9931878992087478,
        "1day.excess_return_with_cost.information_ratio": 0.2288904062351038,
        "1day.excess_return_with_cost.mean": 6.246731646610427e-05
      },
      "feedback": {
        "observations": "The combined gap-acceptance/rejection factor set delivers a higher annualized return than SOTA (0.0619 vs 0.0520), but it deteriorates on risk/consistency metrics: max drawdown is worse (more negative: -0.1035 vs -0.0726), information ratio is lower (0.9528 vs 0.9726), and IC is lower (0.00435 vs 0.00580). This pattern suggests the signals can create profitable exposures but are less stable and/or more tail-risky than the current best.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The improvement in annualized return is consistent with the idea that gap “acceptance vs rejection” contains exploitable short-horizon information. However, the lower IC and IR relative to SOTA indicates the predictive relationship is weaker on average and less reliable cross-sectionally; the higher drawdown suggests the current construction may be too “event-driven” without sufficient filtering (e.g., it may be capturing noisy gaps or adverse gap regimes) or that it concentrates risk on specific market states. In short: the core idea seems directionally valid, but the current implementation likely needs better conditioning/gating and more robust normalization to improve stability.",
        "decision": true,
        "reason": "Per the replacement rule, annualized return improved versus SOTA, and there are no explicit complexity warnings. Despite worse drawdown/IC, the new result should replace SOTA as the current best while immediately prioritizing robustness improvements to address the stability and tail-risk issues."
      }
    },
    "628180b524668ccf": {
      "factor_id": "628180b524668ccf",
      "factor_name": "Gap_Acceptance_Breakout_CLV_20D",
      "factor_expression": "RANK(ABS(($open-DELAY($close,1))/(TS_MEAN($high-$low,20)+1e-8))*ABS((2*$close-$high-$low)/($high-$low+1e-8))*((SIGN(2*$close-$high-$low)==SIGN($open-DELAY($close,1)))?1:0)*((SIGN($open-DELAY($close,1))>0?($close-DELAY($high,1)):(DELAY($low,1)-$close))>0?1:0))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(($open-DELAY($close,1))/(TS_MEAN($high-$low,20)+1e-8))*ABS((2*$close-$high-$low)/($high-$low+1e-8))*((SIGN(2*$close-$high-$low)==SIGN($open-DELAY($close,1)))?1:0)*((SIGN($open-DELAY($close,1))>0?($close-DELAY($high,1)):(DELAY($low,1)-$close))>0?1:0))\" # Your output factor expression will be filled in here\n    name = \"Gap_Acceptance_Breakout_CLV_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuation proxy for large gaps that are accepted: (1) gap magnitude normalized by 20-day average range, (2) close-location value (CLV) shows close near the day extreme in the gap direction, and (3) close remains beyond the prior-day range in the gap direction.",
      "factor_formulation": "F_t=\\operatorname{RANK}\\Big(\\Big|\\frac{g_t}{\\overline{R}_{20,t}+\\epsilon}\\Big|\\cdot |\\text{CLV}_t|\\cdot \\mathbb{1}[\\operatorname{SIGN}(\\text{CLV}_t)=\\operatorname{SIGN}(g_t)]\\cdot \\mathbb{1}[b_t>0]\\Big),\\ \\text{CLV}_t=\\frac{2c_t-h_t-l_t}{h_t-l_t+\\epsilon},\\ b_t=\\begin{cases}c_t-h_{t-1},& g_t>0\\\\ l_{t-1}-c_t,& g_t<0\\end{cases}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8052a4ed296d",
        "parent_trajectory_ids": [
          "155c66a4d708"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are better predicted by OHLC-only “gap acceptance vs rejection” behavior: large normalized overnight gaps that are rejected intraday (close moves back toward prior close/into prior range with strong counter-wick) mean-revert over the next 1–3 days, while large normalized overnight gaps that are accepted intraday (close holds near the extreme in the gap direction and remains outside the prior-day range) exhibit continuation over the next 2–7 days.\n                Concise Observation: Because the available data include open/high/low/close but the parent factors already exploit volume/dollar-volume and impact proxies, focusing on overnight-vs-intraday return decomposition plus candlestick acceptance anatomy (CLV, wick/body ratios, prior-range interaction) uses an orthogonal information channel while remaining fully testable from daily_pv.h5.\n                Concise Justification: Overnight gaps concentrate information and positioning shocks into the opening auction, and the subsequent intraday ‘acceptance’ or ‘rejection’ revealed by close location and wick structure provides a microstructure-like signal about whether the market validates or fades the gap, implying continuation when accepted and mean reversion when rejected.\n                Concise Knowledge: If a large open-to-prev-close gap is not confirmed by the regular session (intraday price action closes back toward prior reference levels and shows strong counter-direction wick), then the gap likely reflects transient overnight overreaction and should revert; when a large gap is confirmed by a close near the day extreme and sustained trading outside the prior day’s range, then the gap likely reflects true repricing and should persist.\n                concise Specification: Compute rON=open/DELAY(close,1)-1 and normalize by ATR20/DELAY(close,1) where ATR20=TS_MEAN(TrueRange(high,low,DELAY(close,1)),20); define acceptance_score using (|gap_z|>1.5) AND close outside prior-day [low,high] AND CLV20? (daily CLV=(close-low)/(high-low+1e-8) mapped to [-0.5,+0.5]) aligned with sign(rON) with small counter-wick ratio, and define rejection_score using (|gap_z|>1.5) AND close returns into prior-day range or toward prior close with large counter-wick and/or sign(rON) != sign(close/DELAY(close,1)-1); test two routed factors: (i) -rejection_score*sign(rON) for 1–3D mean reversion and (ii) +acceptance_score*sign(rON) for 2–7D continuation, using fixed windows {ATR=20, gap threshold=1.5, wick/body computed on 1D range}.\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-22T08:09:50.559824"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.110936534017339,
        "ICIR": 0.0309403611161179,
        "1day.excess_return_without_cost.std": 0.0042093694456759,
        "1day.excess_return_with_cost.annualized_return": 0.0148672213189328,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002599658895775,
        "1day.excess_return_without_cost.annualized_return": 0.0618718817194618,
        "1day.excess_return_with_cost.std": 0.0042103067473731,
        "Rank IC": 0.021938385939547,
        "IC": 0.0043473647932784,
        "1day.excess_return_without_cost.max_drawdown": -0.10347387207149,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9527694024322874,
        "1day.pa": 0.0,
        "l2.valid": 0.9967031076997724,
        "Rank ICIR": 0.1590274742675351,
        "l2.train": 0.9931878992087478,
        "1day.excess_return_with_cost.information_ratio": 0.2288904062351038,
        "1day.excess_return_with_cost.mean": 6.246731646610427e-05
      },
      "feedback": {
        "observations": "The combined gap-acceptance/rejection factor set delivers a higher annualized return than SOTA (0.0619 vs 0.0520), but it deteriorates on risk/consistency metrics: max drawdown is worse (more negative: -0.1035 vs -0.0726), information ratio is lower (0.9528 vs 0.9726), and IC is lower (0.00435 vs 0.00580). This pattern suggests the signals can create profitable exposures but are less stable and/or more tail-risky than the current best.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The improvement in annualized return is consistent with the idea that gap “acceptance vs rejection” contains exploitable short-horizon information. However, the lower IC and IR relative to SOTA indicates the predictive relationship is weaker on average and less reliable cross-sectionally; the higher drawdown suggests the current construction may be too “event-driven” without sufficient filtering (e.g., it may be capturing noisy gaps or adverse gap regimes) or that it concentrates risk on specific market states. In short: the core idea seems directionally valid, but the current implementation likely needs better conditioning/gating and more robust normalization to improve stability.",
        "decision": true,
        "reason": "Per the replacement rule, annualized return improved versus SOTA, and there are no explicit complexity warnings. Despite worse drawdown/IC, the new result should replace SOTA as the current best while immediately prioritizing robustness improvements to address the stability and tail-risk issues."
      }
    },
    "24d2eb0a388e5be8": {
      "factor_id": "24d2eb0a388e5be8",
      "factor_name": "Gap_Fill_Ratio_x_GapRank_20D",
      "factor_expression": "RANK(SIGN($open-DELAY($close,1))*($open-$close)/(ABS($open-DELAY($close,1))+1e-8)*TS_RANK(ABS($open-DELAY($close,1)),20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SIGN($open-DELAY($close,1))*($open-$close)/(ABS($open-DELAY($close,1))+1e-8)*TS_RANK(ABS($open-DELAY($close,1)),20))\" # Your output factor expression will be filled in here\n    name = \"Gap_Fill_Ratio_x_GapRank_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Directional gap-fill intensity for rejection behavior. It measures how much of the overnight gap is filled intraday (open-to-close move back toward prior close) and weights it by how extreme today's gap is versus the past 20 days (TS_RANK).",
      "factor_formulation": "F_t=\\operatorname{RANK}\\Big(\\frac{\\operatorname{SIGN}(g_t)\\,(o_t-c_t)}{|g_t|+\\epsilon}\\cdot \\text{TS\\_RANK}(|g_t|,20)\\Big),\\quad g_t=o_t-c_{t-1}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8052a4ed296d",
        "parent_trajectory_ids": [
          "155c66a4d708"
        ],
        "hypothesis": "Hypothesis: Short-horizon returns are better predicted by OHLC-only “gap acceptance vs rejection” behavior: large normalized overnight gaps that are rejected intraday (close moves back toward prior close/into prior range with strong counter-wick) mean-revert over the next 1–3 days, while large normalized overnight gaps that are accepted intraday (close holds near the extreme in the gap direction and remains outside the prior-day range) exhibit continuation over the next 2–7 days.\n                Concise Observation: Because the available data include open/high/low/close but the parent factors already exploit volume/dollar-volume and impact proxies, focusing on overnight-vs-intraday return decomposition plus candlestick acceptance anatomy (CLV, wick/body ratios, prior-range interaction) uses an orthogonal information channel while remaining fully testable from daily_pv.h5.\n                Concise Justification: Overnight gaps concentrate information and positioning shocks into the opening auction, and the subsequent intraday ‘acceptance’ or ‘rejection’ revealed by close location and wick structure provides a microstructure-like signal about whether the market validates or fades the gap, implying continuation when accepted and mean reversion when rejected.\n                Concise Knowledge: If a large open-to-prev-close gap is not confirmed by the regular session (intraday price action closes back toward prior reference levels and shows strong counter-direction wick), then the gap likely reflects transient overnight overreaction and should revert; when a large gap is confirmed by a close near the day extreme and sustained trading outside the prior day’s range, then the gap likely reflects true repricing and should persist.\n                concise Specification: Compute rON=open/DELAY(close,1)-1 and normalize by ATR20/DELAY(close,1) where ATR20=TS_MEAN(TrueRange(high,low,DELAY(close,1)),20); define acceptance_score using (|gap_z|>1.5) AND close outside prior-day [low,high] AND CLV20? (daily CLV=(close-low)/(high-low+1e-8) mapped to [-0.5,+0.5]) aligned with sign(rON) with small counter-wick ratio, and define rejection_score using (|gap_z|>1.5) AND close returns into prior-day range or toward prior close with large counter-wick and/or sign(rON) != sign(close/DELAY(close,1)-1); test two routed factors: (i) -rejection_score*sign(rON) for 1–3D mean reversion and (ii) +acceptance_score*sign(rON) for 2–7D continuation, using fixed windows {ATR=20, gap threshold=1.5, wick/body computed on 1D range}.\n                ",
        "initial_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "planning_direction": "Long-horizon reversal gated by volume-price coupling: Use ROC60 as the core signal and condition it on CORR20; hypothesize that ROC60>1 (downtrend) predicts rebound only when CORR20 is strongly negative (price falls on rising volume = capitulation), but underperforms when CORR20 is positive (distribution).",
        "created_at": "2026-01-22T08:09:50.559824"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.110936534017339,
        "ICIR": 0.0309403611161179,
        "1day.excess_return_without_cost.std": 0.0042093694456759,
        "1day.excess_return_with_cost.annualized_return": 0.0148672213189328,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002599658895775,
        "1day.excess_return_without_cost.annualized_return": 0.0618718817194618,
        "1day.excess_return_with_cost.std": 0.0042103067473731,
        "Rank IC": 0.021938385939547,
        "IC": 0.0043473647932784,
        "1day.excess_return_without_cost.max_drawdown": -0.10347387207149,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9527694024322874,
        "1day.pa": 0.0,
        "l2.valid": 0.9967031076997724,
        "Rank ICIR": 0.1590274742675351,
        "l2.train": 0.9931878992087478,
        "1day.excess_return_with_cost.information_ratio": 0.2288904062351038,
        "1day.excess_return_with_cost.mean": 6.246731646610427e-05
      },
      "feedback": {
        "observations": "The combined gap-acceptance/rejection factor set delivers a higher annualized return than SOTA (0.0619 vs 0.0520), but it deteriorates on risk/consistency metrics: max drawdown is worse (more negative: -0.1035 vs -0.0726), information ratio is lower (0.9528 vs 0.9726), and IC is lower (0.00435 vs 0.00580). This pattern suggests the signals can create profitable exposures but are less stable and/or more tail-risky than the current best.",
        "hypothesis_evaluation": "Partially supports the hypothesis. The improvement in annualized return is consistent with the idea that gap “acceptance vs rejection” contains exploitable short-horizon information. However, the lower IC and IR relative to SOTA indicates the predictive relationship is weaker on average and less reliable cross-sectionally; the higher drawdown suggests the current construction may be too “event-driven” without sufficient filtering (e.g., it may be capturing noisy gaps or adverse gap regimes) or that it concentrates risk on specific market states. In short: the core idea seems directionally valid, but the current implementation likely needs better conditioning/gating and more robust normalization to improve stability.",
        "decision": true,
        "reason": "Per the replacement rule, annualized return improved versus SOTA, and there are no explicit complexity warnings. Despite worse drawdown/IC, the new result should replace SOTA as the current best while immediately prioritizing robustness improvements to address the stability and tail-risk issues."
      }
    },
    "ed121c7125c5f37c": {
      "factor_id": "ed121c7125c5f37c",
      "factor_name": "Gap_Direction_CLV_Confirm_RangeNorm_14",
      "factor_expression": "((ABS($open-DELAY($close,1))/(TS_MEAN($high-$low,14)+1e-8)>1)?(SIGN($open-DELAY($close,1))*SIGN($close-$open)*((2*$close-$high-$low)/($high-$low+1e-8))):(0))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((ABS($open-DELAY($close,1))/(TS_MEAN($high-$low,14)+1e-8)>1)?(SIGN($open-DELAY($close,1))*SIGN($close-$open)*((2*$close-$high-$low)/($high-$low+1e-8))):(0))\" # Your output factor expression will be filled in here\n    name = \"Gap_Direction_CLV_Confirm_RangeNorm_14\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Regime-style gap acceptance vs rejection proxy. Activates on large overnight gap scaled by 14D average daily range. Output is positive when intraday direction confirms the gap and the close is near the gap-direction extreme (via CLV), negative when intraday action rejects it (opposite intraday sign), else 0.",
      "factor_formulation": "f_t=\\mathbf{1}\\left(\\frac{|O_t-C_{t-1}|}{\\text{MA}_{14}(H-L)+\\epsilon}>1\\right)\\cdot \\text{SIGN}(O_t-C_{t-1})\\cdot \\text{SIGN}(C_t-O_t)\\cdot \\frac{2C_t-H_t-L_t}{H_t-L_t+\\epsilon}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "b3f71fe0e3dc",
        "parent_trajectory_ids": [
          "6f936c0f62eb"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–10D) returns are regime-dependent on overnight gap acceptance vs rejection: when the normalized overnight gap (|log(Open_t/Close_{t-1})| scaled by ATR_14 or 60D z-score) is large and intraday price action confirms the gap (same-sign log(Close_t/Open_t) and Close near the day’s extreme in the gap direction with no prior-day range re-entry), returns tend to continue in the gap direction for the next several days; when the gap is large but intraday action rejects it (opposite-sign intraday return and/or Close re-enters the prior day’s [Low_{t-1}, High_{t-1}] range), returns tend to mean-revert over the next 1–5 days.\n                Concise Observation: The available data includes daily OHLC, enabling decomposition into overnight vs intraday returns, range-position (CLV) and prior-range overlap tests, which are orthogonal to the parent factor’s reliance on close-to-close liquidity/Amihud proxies and multi-week squeeze/breakout logic.\n                Concise Justification: Overnight gaps concentrate discontinuous information and auction imbalances, while intraday trading reveals whether that shock is validated (acceptance) or faded (rejection); therefore a single OHLC-only factor that conditions on large normalized gaps and switches sign based on acceptance/rejection should capture a different microstructure-driven return component than illiquidity-shock or breakout regimes.\n                Concise Knowledge: If an overnight gap reflects information/positioning that is accepted by the continuous session (same-direction intraday follow-through and close near the extreme), then price impact is likely permanent and short-term continuation should dominate; if the gap is absorbed by liquidity and the close returns into the prior range (gap rejection), then the open auction imbalance is likely temporary and short-term reversal should dominate, especially when the gap is large relative to recent true range.\n                concise Specification: Construct an OHLC-only regime-switching gap factor with fixed hyperparameters: rON_t=log(Open_t/Close_{t-1}), rID_t=log(Close_t/Open_t); gap_normalizer=ATR_14 where ATR_14=MA_14(TrueRange), TrueRange_t=max(High_t-Low_t, |High_t-Close_{t-1}|, |Low_t-Close_{t-1}|); activate only if GapATR_t=|Open_t-Close_{t-1}|/(ATR_14+1e-8) >= 1.0 (or alternatively |rON_t| has 60D z-score >= 1.5 with lookback=60); define acceptance if sign(rON_t)=sign(rID_t) AND CLV_t=(2*Close_t-High_t-Low_t)/(High_t-Low_t+1e-8) has the same sign as rON_t with |CLV_t|>=0.5 AND Close_t is outside prior range (Close_t>High_{t-1} for gap up, Close_t<Low_{t-1} for gap down); define rejection if sign(rON_t)=-sign(rID_t) OR Close_t lies within [Low_{t-1}, High_{t-1}]; factor output: +sign(rON_t) for acceptance, -sign(rON_t) for rejection, else 0, producing a single daily scalar per instrument.\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-22T08:31:31.025868"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1203732878312778,
        "ICIR": 0.0403995712340878,
        "1day.excess_return_without_cost.std": 0.0041150620322882,
        "1day.excess_return_with_cost.annualized_return": -0.0031307502919019,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001850671740642,
        "1day.excess_return_without_cost.annualized_return": 0.0440459874272989,
        "1day.excess_return_with_cost.std": 0.0041167349422584,
        "Rank IC": 0.0159693669987382,
        "IC": 0.0055719626123953,
        "1day.excess_return_without_cost.max_drawdown": -0.1113897225514326,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6938114865313728,
        "1day.pa": 0.0,
        "l2.valid": 0.9961087667721856,
        "Rank ICIR": 0.1150816824923983,
        "l2.train": 0.9907903503589458,
        "1day.excess_return_with_cost.information_ratio": -0.0492954738448511,
        "1day.excess_return_with_cost.mean": -1.3154412991184707e-05
      },
      "feedback": {
        "observations": "The combined factor set underperforms the current SOTA on all reported metrics: max drawdown is worse (-0.1114 vs -0.0726), information ratio is lower (0.6938 vs 0.9726), annualized return is lower (0.0440 vs 0.0520), and IC is slightly lower (0.00557 vs 0.00580). The gap-acceptance/rejection idea may still be valid, but the present implementations/parameterization are not extracting a stronger or more robust edge than SOTA in this run. No complexity red flags are apparent (expressions are short, few base features, few free parameters), so the deterioration is more likely due to signal definition/thresholding and horizon mismatch rather than overfitting from expression complexity.",
        "hypothesis_evaluation": "Current results weakly refute (or at least fail to support) the hypothesis *as implemented and evaluated here*, because the signal does not translate into improved 1-day excess-return performance relative to SOTA. Two key points:\n1) Horizon alignment: The hypothesis explicitly mentions continuation for “next several days” and mean reversion over “next 1–5 days”. Your evaluation shown is 1-day excess return. It’s plausible the edge is primarily 3–5D, so a 1D evaluation can understate it. You should re-run evaluation for 3D/5D/10D targets (or multi-horizon labels) to properly validate the regime claim.\n2) Regime classification quality: The current factors rely heavily on hard gates and sign products (e.g., SIGN(gap)*SIGN(intraday)*CLV). This can be brittle: (a) small moves near zero flip sign, (b) CLV can be noisy when (H-L) is small, (c) the “gap acceptance vs rejection” logic is only partially captured (e.g., explicit ‘no prior-day range re-entry’ is not consistently enforced across the acceptance factors).\n\nNet: The hypothesis is not disproven conceptually, but this iteration’s factor engineering + parameter choices do not beat SOTA on the provided 1D metrics, so it does not yet provide empirical support in this setting.",
        "decision": false,
        "reason": "Your current construction uses (a) a 14D mean of (H-L) as a volatility proxy, and (b) hard thresholds (gap/range > 1, zscore60 > 1.5) and sign products. These choices can discard too many observations (sparse activation) and introduce discontinuities that reduce IC/IR. Additionally, the hypothesis expects multi-day continuation/mean-reversion; optimizing and reporting only a 1-day metric can make a valid regime signal look weak. A continuous gap outcome measure (e.g., fraction of gap filled by close, or close position relative to prior range) plus volatility-normalized gap sizing tends to be more stable cross-sectionally.\n\nConcrete refinement directions (keep same theory, iterate implementations):\n- Replace MA14(H-L) with ATR14 or TR14 (true range) if available/derivable from OHLC; otherwise use MA14(TR) where TR_t=max(H-L, |H-C_{t-1}|, |L-C_{t-1}|). Hyperparameter: lookback=14.\n- Use a continuous acceptance score:\n  • gap = log(Open_t/Close_{t-1})\n  • intraday = log(Close_t/Open_t)\n  • gap_fill_ratio = clip((Close_t - Open_t)/(-gap * Open_t?), or simpler: (Close_t - Open_t)/(Close_{t-1} - Open_t) for gap-down; define piecewise)\n  • prior_range_reentry = indicator(Close_t within [Low_{t-1}, High_{t-1}])\n  Then score ≈ z(|gap|)*sign(gap)*tanh(k*intraday)*CLV*(1 - prior_range_reentry) for acceptance, and a separate rejection score that increases with re-entry/fill.\n  Hyperparameters to sweep: k in {1,2,3}, use tanh/clip to stabilize.\n- Reduce brittleness from SIGN(): replace SIGN(x) with smooth approximations like tanh(x/scale). Hyperparameter: scale tied to rolling volatility (e.g., ATR14).\n- Threshold sensitivity sweeps (define separate factors per setting, per your requirement):\n  • z-window: 20, 60, 120\n  • z-threshold: 1.0, 1.5, 2.0\n  • range/ATR window: 10, 14, 20\n  • gap/range threshold: 0.75, 1.0, 1.25\n- Explicitly enforce the hypothesis condition “no prior-day range re-entry” for acceptance-type factors (currently the rejection factor has it; acceptance factors do not). Create distinct acceptance factors with re-entry filter on/off.\n- Label alignment: evaluate forward returns at 1D, 3D, 5D, 10D; the regime effect may peak at 3–5D.\n\nHyperparameters explicitly present in current factors (to document and vary next):\n- Gap_Direction_CLV_Confirm_RangeNorm_14:\n  • volatility proxy window = 14 (TS_MEAN of H-L)\n  • activation threshold = 1.0 on |O-C_{t-1}| / MA14(H-L)\n  • uses CLV with epsilon stabilization\n- LargeGap_PriorRange_Reentry_Reversal_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • re-entry condition: Close_t in (Low_{t-1}, High_{t-1})\n- LargeGap_AcceptanceScore_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • acceptance uses SIGN(intraday)*CLV gating\n\nGiven no complexity warnings, prioritize *signal quality + horizon fit* over adding more terms/features."
      }
    },
    "8158ca3c80c79265": {
      "factor_id": "8158ca3c80c79265",
      "factor_name": "LargeGap_PriorRange_Reentry_Reversal_Z60",
      "factor_expression": "((TS_ZSCORE(ABS(LOG($open/DELAY($close,1))),60)>1.5)&&($close<DELAY($high,1))&&($close>DELAY($low,1)))?(-SIGN(LOG($open/DELAY($close,1)))):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_ZSCORE(ABS(LOG($open/DELAY($close,1))),60)>1.5)&&($close<DELAY($high,1))&&($close>DELAY($low,1)))?(-SIGN(LOG($open/DELAY($close,1)))):(0)\" # Your output factor expression will be filled in here\n    name = \"LargeGap_PriorRange_Reentry_Reversal_Z60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Large overnight gap (60D z-score) that gets absorbed back into the prior day's range. Interpreted as gap rejection; outputs the reversal sign (-sign of the overnight gap) when today's close re-enters yesterday's [low, high].",
      "factor_formulation": "g_t=\\mathbf{1}\\left(\\text{ZS}_{60}(|\\log(O_t/C_{t-1})|)>1.5\\right)\\mathbf{1}(L_{t-1}<C_t<H_{t-1})\\cdot\\left(-\\text{SIGN}(\\log(O_t/C_{t-1}))\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "b3f71fe0e3dc",
        "parent_trajectory_ids": [
          "6f936c0f62eb"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–10D) returns are regime-dependent on overnight gap acceptance vs rejection: when the normalized overnight gap (|log(Open_t/Close_{t-1})| scaled by ATR_14 or 60D z-score) is large and intraday price action confirms the gap (same-sign log(Close_t/Open_t) and Close near the day’s extreme in the gap direction with no prior-day range re-entry), returns tend to continue in the gap direction for the next several days; when the gap is large but intraday action rejects it (opposite-sign intraday return and/or Close re-enters the prior day’s [Low_{t-1}, High_{t-1}] range), returns tend to mean-revert over the next 1–5 days.\n                Concise Observation: The available data includes daily OHLC, enabling decomposition into overnight vs intraday returns, range-position (CLV) and prior-range overlap tests, which are orthogonal to the parent factor’s reliance on close-to-close liquidity/Amihud proxies and multi-week squeeze/breakout logic.\n                Concise Justification: Overnight gaps concentrate discontinuous information and auction imbalances, while intraday trading reveals whether that shock is validated (acceptance) or faded (rejection); therefore a single OHLC-only factor that conditions on large normalized gaps and switches sign based on acceptance/rejection should capture a different microstructure-driven return component than illiquidity-shock or breakout regimes.\n                Concise Knowledge: If an overnight gap reflects information/positioning that is accepted by the continuous session (same-direction intraday follow-through and close near the extreme), then price impact is likely permanent and short-term continuation should dominate; if the gap is absorbed by liquidity and the close returns into the prior range (gap rejection), then the open auction imbalance is likely temporary and short-term reversal should dominate, especially when the gap is large relative to recent true range.\n                concise Specification: Construct an OHLC-only regime-switching gap factor with fixed hyperparameters: rON_t=log(Open_t/Close_{t-1}), rID_t=log(Close_t/Open_t); gap_normalizer=ATR_14 where ATR_14=MA_14(TrueRange), TrueRange_t=max(High_t-Low_t, |High_t-Close_{t-1}|, |Low_t-Close_{t-1}|); activate only if GapATR_t=|Open_t-Close_{t-1}|/(ATR_14+1e-8) >= 1.0 (or alternatively |rON_t| has 60D z-score >= 1.5 with lookback=60); define acceptance if sign(rON_t)=sign(rID_t) AND CLV_t=(2*Close_t-High_t-Low_t)/(High_t-Low_t+1e-8) has the same sign as rON_t with |CLV_t|>=0.5 AND Close_t is outside prior range (Close_t>High_{t-1} for gap up, Close_t<Low_{t-1} for gap down); define rejection if sign(rON_t)=-sign(rID_t) OR Close_t lies within [Low_{t-1}, High_{t-1}]; factor output: +sign(rON_t) for acceptance, -sign(rON_t) for rejection, else 0, producing a single daily scalar per instrument.\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-22T08:31:31.025868"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1203732878312778,
        "ICIR": 0.0403995712340878,
        "1day.excess_return_without_cost.std": 0.0041150620322882,
        "1day.excess_return_with_cost.annualized_return": -0.0031307502919019,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001850671740642,
        "1day.excess_return_without_cost.annualized_return": 0.0440459874272989,
        "1day.excess_return_with_cost.std": 0.0041167349422584,
        "Rank IC": 0.0159693669987382,
        "IC": 0.0055719626123953,
        "1day.excess_return_without_cost.max_drawdown": -0.1113897225514326,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6938114865313728,
        "1day.pa": 0.0,
        "l2.valid": 0.9961087667721856,
        "Rank ICIR": 0.1150816824923983,
        "l2.train": 0.9907903503589458,
        "1day.excess_return_with_cost.information_ratio": -0.0492954738448511,
        "1day.excess_return_with_cost.mean": -1.3154412991184707e-05
      },
      "feedback": {
        "observations": "The combined factor set underperforms the current SOTA on all reported metrics: max drawdown is worse (-0.1114 vs -0.0726), information ratio is lower (0.6938 vs 0.9726), annualized return is lower (0.0440 vs 0.0520), and IC is slightly lower (0.00557 vs 0.00580). The gap-acceptance/rejection idea may still be valid, but the present implementations/parameterization are not extracting a stronger or more robust edge than SOTA in this run. No complexity red flags are apparent (expressions are short, few base features, few free parameters), so the deterioration is more likely due to signal definition/thresholding and horizon mismatch rather than overfitting from expression complexity.",
        "hypothesis_evaluation": "Current results weakly refute (or at least fail to support) the hypothesis *as implemented and evaluated here*, because the signal does not translate into improved 1-day excess-return performance relative to SOTA. Two key points:\n1) Horizon alignment: The hypothesis explicitly mentions continuation for “next several days” and mean reversion over “next 1–5 days”. Your evaluation shown is 1-day excess return. It’s plausible the edge is primarily 3–5D, so a 1D evaluation can understate it. You should re-run evaluation for 3D/5D/10D targets (or multi-horizon labels) to properly validate the regime claim.\n2) Regime classification quality: The current factors rely heavily on hard gates and sign products (e.g., SIGN(gap)*SIGN(intraday)*CLV). This can be brittle: (a) small moves near zero flip sign, (b) CLV can be noisy when (H-L) is small, (c) the “gap acceptance vs rejection” logic is only partially captured (e.g., explicit ‘no prior-day range re-entry’ is not consistently enforced across the acceptance factors).\n\nNet: The hypothesis is not disproven conceptually, but this iteration’s factor engineering + parameter choices do not beat SOTA on the provided 1D metrics, so it does not yet provide empirical support in this setting.",
        "decision": false,
        "reason": "Your current construction uses (a) a 14D mean of (H-L) as a volatility proxy, and (b) hard thresholds (gap/range > 1, zscore60 > 1.5) and sign products. These choices can discard too many observations (sparse activation) and introduce discontinuities that reduce IC/IR. Additionally, the hypothesis expects multi-day continuation/mean-reversion; optimizing and reporting only a 1-day metric can make a valid regime signal look weak. A continuous gap outcome measure (e.g., fraction of gap filled by close, or close position relative to prior range) plus volatility-normalized gap sizing tends to be more stable cross-sectionally.\n\nConcrete refinement directions (keep same theory, iterate implementations):\n- Replace MA14(H-L) with ATR14 or TR14 (true range) if available/derivable from OHLC; otherwise use MA14(TR) where TR_t=max(H-L, |H-C_{t-1}|, |L-C_{t-1}|). Hyperparameter: lookback=14.\n- Use a continuous acceptance score:\n  • gap = log(Open_t/Close_{t-1})\n  • intraday = log(Close_t/Open_t)\n  • gap_fill_ratio = clip((Close_t - Open_t)/(-gap * Open_t?), or simpler: (Close_t - Open_t)/(Close_{t-1} - Open_t) for gap-down; define piecewise)\n  • prior_range_reentry = indicator(Close_t within [Low_{t-1}, High_{t-1}])\n  Then score ≈ z(|gap|)*sign(gap)*tanh(k*intraday)*CLV*(1 - prior_range_reentry) for acceptance, and a separate rejection score that increases with re-entry/fill.\n  Hyperparameters to sweep: k in {1,2,3}, use tanh/clip to stabilize.\n- Reduce brittleness from SIGN(): replace SIGN(x) with smooth approximations like tanh(x/scale). Hyperparameter: scale tied to rolling volatility (e.g., ATR14).\n- Threshold sensitivity sweeps (define separate factors per setting, per your requirement):\n  • z-window: 20, 60, 120\n  • z-threshold: 1.0, 1.5, 2.0\n  • range/ATR window: 10, 14, 20\n  • gap/range threshold: 0.75, 1.0, 1.25\n- Explicitly enforce the hypothesis condition “no prior-day range re-entry” for acceptance-type factors (currently the rejection factor has it; acceptance factors do not). Create distinct acceptance factors with re-entry filter on/off.\n- Label alignment: evaluate forward returns at 1D, 3D, 5D, 10D; the regime effect may peak at 3–5D.\n\nHyperparameters explicitly present in current factors (to document and vary next):\n- Gap_Direction_CLV_Confirm_RangeNorm_14:\n  • volatility proxy window = 14 (TS_MEAN of H-L)\n  • activation threshold = 1.0 on |O-C_{t-1}| / MA14(H-L)\n  • uses CLV with epsilon stabilization\n- LargeGap_PriorRange_Reentry_Reversal_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • re-entry condition: Close_t in (Low_{t-1}, High_{t-1})\n- LargeGap_AcceptanceScore_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • acceptance uses SIGN(intraday)*CLV gating\n\nGiven no complexity warnings, prioritize *signal quality + horizon fit* over adding more terms/features."
      }
    },
    "a5f1ad998ea50db1": {
      "factor_id": "a5f1ad998ea50db1",
      "factor_name": "LargeGap_AcceptanceScore_Z60",
      "factor_expression": "(TS_ZSCORE(ABS(LOG($open/DELAY($close,1))),60)>1.5)?(ABS(LOG($open/DELAY($close,1)))*SIGN(LOG($open/DELAY($close,1)))*SIGN(LOG($close/$open))*((2*$close-$high-$low)/($high-$low+1e-8))):(0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_ZSCORE(ABS(LOG($open/DELAY($close,1))),60)>1.5)?(ABS(LOG($open/DELAY($close,1)))*SIGN(LOG($open/DELAY($close,1)))*SIGN(LOG($close/$open))*((2*$close-$high-$low)/($high-$low+1e-8))):(0)\" # Your output factor expression will be filled in here\n    name = \"LargeGap_AcceptanceScore_Z60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Large-gap acceptance score using only OHLC: activates when the overnight gap magnitude is extreme (60D z-score). Signed magnitude is boosted when intraday return has the same sign as the gap and the close is near the day’s extreme in the gap direction (CLV).",
      "factor_formulation": "h_t=\\mathbf{1}(\\text{ZS}_{60}(|r^{ON}_t|)>1.5)\\cdot |r^{ON}_t|\\cdot \\text{SIGN}(r^{ON}_t)\\cdot \\text{SIGN}(r^{ID}_t)\\cdot \\text{CLV}_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "b3f71fe0e3dc",
        "parent_trajectory_ids": [
          "6f936c0f62eb"
        ],
        "hypothesis": "Hypothesis: Short-horizon (1–10D) returns are regime-dependent on overnight gap acceptance vs rejection: when the normalized overnight gap (|log(Open_t/Close_{t-1})| scaled by ATR_14 or 60D z-score) is large and intraday price action confirms the gap (same-sign log(Close_t/Open_t) and Close near the day’s extreme in the gap direction with no prior-day range re-entry), returns tend to continue in the gap direction for the next several days; when the gap is large but intraday action rejects it (opposite-sign intraday return and/or Close re-enters the prior day’s [Low_{t-1}, High_{t-1}] range), returns tend to mean-revert over the next 1–5 days.\n                Concise Observation: The available data includes daily OHLC, enabling decomposition into overnight vs intraday returns, range-position (CLV) and prior-range overlap tests, which are orthogonal to the parent factor’s reliance on close-to-close liquidity/Amihud proxies and multi-week squeeze/breakout logic.\n                Concise Justification: Overnight gaps concentrate discontinuous information and auction imbalances, while intraday trading reveals whether that shock is validated (acceptance) or faded (rejection); therefore a single OHLC-only factor that conditions on large normalized gaps and switches sign based on acceptance/rejection should capture a different microstructure-driven return component than illiquidity-shock or breakout regimes.\n                Concise Knowledge: If an overnight gap reflects information/positioning that is accepted by the continuous session (same-direction intraday follow-through and close near the extreme), then price impact is likely permanent and short-term continuation should dominate; if the gap is absorbed by liquidity and the close returns into the prior range (gap rejection), then the open auction imbalance is likely temporary and short-term reversal should dominate, especially when the gap is large relative to recent true range.\n                concise Specification: Construct an OHLC-only regime-switching gap factor with fixed hyperparameters: rON_t=log(Open_t/Close_{t-1}), rID_t=log(Close_t/Open_t); gap_normalizer=ATR_14 where ATR_14=MA_14(TrueRange), TrueRange_t=max(High_t-Low_t, |High_t-Close_{t-1}|, |Low_t-Close_{t-1}|); activate only if GapATR_t=|Open_t-Close_{t-1}|/(ATR_14+1e-8) >= 1.0 (or alternatively |rON_t| has 60D z-score >= 1.5 with lookback=60); define acceptance if sign(rON_t)=sign(rID_t) AND CLV_t=(2*Close_t-High_t-Low_t)/(High_t-Low_t+1e-8) has the same sign as rON_t with |CLV_t|>=0.5 AND Close_t is outside prior range (Close_t>High_{t-1} for gap up, Close_t<Low_{t-1} for gap down); define rejection if sign(rON_t)=-sign(rID_t) OR Close_t lies within [Low_{t-1}, High_{t-1}]; factor output: +sign(rON_t) for acceptance, -sign(rON_t) for rejection, else 0, producing a single daily scalar per instrument.\n                ",
        "initial_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "planning_direction": "Volume instability as a filter for reversal: Combine ROC60 with VSTD5; hypothesize that long-term losers (high ROC60) with low VSTD5 (stable volume) exhibit slower mean reversion (value trap), while high ROC60 with high VSTD5 show faster bounce due to turnover shocks.",
        "created_at": "2026-01-22T08:31:31.025868"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1203732878312778,
        "ICIR": 0.0403995712340878,
        "1day.excess_return_without_cost.std": 0.0041150620322882,
        "1day.excess_return_with_cost.annualized_return": -0.0031307502919019,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001850671740642,
        "1day.excess_return_without_cost.annualized_return": 0.0440459874272989,
        "1day.excess_return_with_cost.std": 0.0041167349422584,
        "Rank IC": 0.0159693669987382,
        "IC": 0.0055719626123953,
        "1day.excess_return_without_cost.max_drawdown": -0.1113897225514326,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6938114865313728,
        "1day.pa": 0.0,
        "l2.valid": 0.9961087667721856,
        "Rank ICIR": 0.1150816824923983,
        "l2.train": 0.9907903503589458,
        "1day.excess_return_with_cost.information_ratio": -0.0492954738448511,
        "1day.excess_return_with_cost.mean": -1.3154412991184707e-05
      },
      "feedback": {
        "observations": "The combined factor set underperforms the current SOTA on all reported metrics: max drawdown is worse (-0.1114 vs -0.0726), information ratio is lower (0.6938 vs 0.9726), annualized return is lower (0.0440 vs 0.0520), and IC is slightly lower (0.00557 vs 0.00580). The gap-acceptance/rejection idea may still be valid, but the present implementations/parameterization are not extracting a stronger or more robust edge than SOTA in this run. No complexity red flags are apparent (expressions are short, few base features, few free parameters), so the deterioration is more likely due to signal definition/thresholding and horizon mismatch rather than overfitting from expression complexity.",
        "hypothesis_evaluation": "Current results weakly refute (or at least fail to support) the hypothesis *as implemented and evaluated here*, because the signal does not translate into improved 1-day excess-return performance relative to SOTA. Two key points:\n1) Horizon alignment: The hypothesis explicitly mentions continuation for “next several days” and mean reversion over “next 1–5 days”. Your evaluation shown is 1-day excess return. It’s plausible the edge is primarily 3–5D, so a 1D evaluation can understate it. You should re-run evaluation for 3D/5D/10D targets (or multi-horizon labels) to properly validate the regime claim.\n2) Regime classification quality: The current factors rely heavily on hard gates and sign products (e.g., SIGN(gap)*SIGN(intraday)*CLV). This can be brittle: (a) small moves near zero flip sign, (b) CLV can be noisy when (H-L) is small, (c) the “gap acceptance vs rejection” logic is only partially captured (e.g., explicit ‘no prior-day range re-entry’ is not consistently enforced across the acceptance factors).\n\nNet: The hypothesis is not disproven conceptually, but this iteration’s factor engineering + parameter choices do not beat SOTA on the provided 1D metrics, so it does not yet provide empirical support in this setting.",
        "decision": false,
        "reason": "Your current construction uses (a) a 14D mean of (H-L) as a volatility proxy, and (b) hard thresholds (gap/range > 1, zscore60 > 1.5) and sign products. These choices can discard too many observations (sparse activation) and introduce discontinuities that reduce IC/IR. Additionally, the hypothesis expects multi-day continuation/mean-reversion; optimizing and reporting only a 1-day metric can make a valid regime signal look weak. A continuous gap outcome measure (e.g., fraction of gap filled by close, or close position relative to prior range) plus volatility-normalized gap sizing tends to be more stable cross-sectionally.\n\nConcrete refinement directions (keep same theory, iterate implementations):\n- Replace MA14(H-L) with ATR14 or TR14 (true range) if available/derivable from OHLC; otherwise use MA14(TR) where TR_t=max(H-L, |H-C_{t-1}|, |L-C_{t-1}|). Hyperparameter: lookback=14.\n- Use a continuous acceptance score:\n  • gap = log(Open_t/Close_{t-1})\n  • intraday = log(Close_t/Open_t)\n  • gap_fill_ratio = clip((Close_t - Open_t)/(-gap * Open_t?), or simpler: (Close_t - Open_t)/(Close_{t-1} - Open_t) for gap-down; define piecewise)\n  • prior_range_reentry = indicator(Close_t within [Low_{t-1}, High_{t-1}])\n  Then score ≈ z(|gap|)*sign(gap)*tanh(k*intraday)*CLV*(1 - prior_range_reentry) for acceptance, and a separate rejection score that increases with re-entry/fill.\n  Hyperparameters to sweep: k in {1,2,3}, use tanh/clip to stabilize.\n- Reduce brittleness from SIGN(): replace SIGN(x) with smooth approximations like tanh(x/scale). Hyperparameter: scale tied to rolling volatility (e.g., ATR14).\n- Threshold sensitivity sweeps (define separate factors per setting, per your requirement):\n  • z-window: 20, 60, 120\n  • z-threshold: 1.0, 1.5, 2.0\n  • range/ATR window: 10, 14, 20\n  • gap/range threshold: 0.75, 1.0, 1.25\n- Explicitly enforce the hypothesis condition “no prior-day range re-entry” for acceptance-type factors (currently the rejection factor has it; acceptance factors do not). Create distinct acceptance factors with re-entry filter on/off.\n- Label alignment: evaluate forward returns at 1D, 3D, 5D, 10D; the regime effect may peak at 3–5D.\n\nHyperparameters explicitly present in current factors (to document and vary next):\n- Gap_Direction_CLV_Confirm_RangeNorm_14:\n  • volatility proxy window = 14 (TS_MEAN of H-L)\n  • activation threshold = 1.0 on |O-C_{t-1}| / MA14(H-L)\n  • uses CLV with epsilon stabilization\n- LargeGap_PriorRange_Reentry_Reversal_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • re-entry condition: Close_t in (Low_{t-1}, High_{t-1})\n- LargeGap_AcceptanceScore_Z60:\n  • zscore window = 60\n  • zscore threshold = 1.5\n  • acceptance uses SIGN(intraday)*CLV gating\n\nGiven no complexity warnings, prioritize *signal quality + horizon fit* over adding more terms/features."
      }
    },
    "88d2af1f23dd8bac": {
      "factor_id": "88d2af1f23dd8bac",
      "factor_name": "Streak5_Exhaustion_Reversal_TRz20_CLV_Volz20",
      "factor_expression": "(((COUNT($return>0,5)==5)||(COUNT($return<0,5)==5))?(-SIGN(TS_SUM($return,5))*RANK(TS_ZSCORE(MAX($high-$low,ABS($close-DELAY($close,1))),20))*RANK(ABS((2*$close-$high-$low)/($high-$low+1e-8)))*RANK(-TS_ZSCORE(LOG($volume+1),20))):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((COUNT(TS_PCTCHANGE($close,1)>0,5)==5)||(COUNT(TS_PCTCHANGE($close,1)<0,5)==5)) * (-SIGN(TS_SUM(TS_PCTCHANGE($close,1),5)) * RANK(TS_ZSCORE(MAX($high-$low,ABS($close-DELAY($close,1))),20)) * RANK(ABS((2*$close-$high-$low)/($high-$low+1e-8))) * RANK(-TS_ZSCORE(LOG($volume+1),20)))\" # Your output factor expression will be filled in here\n    name = \"Streak5_Exhaustion_Reversal_TRz20_CLV_Volz20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "5-day directional streak exhaustion reversal score. Active only when the past 5 daily returns are all positive or all negative. Higher values indicate higher reversal risk over the next 3–5 days (i.e., negative return in the streak direction), driven by (i) abnormal true-range proxy expansion vs 20D, (ii) close pinned near range extreme via |CLV|, and (iii) weak volume via low log-volume z-score vs 20D.",
      "factor_formulation": "f_t=\\mathbf{1}[\\forall i\\in\\{0..4\\}:r_{t-i}>0\\ \\text{or}\\ r_{t-i}<0]\\cdot\\Big(-\\operatorname{sign}(\\sum_{i=0}^4 r_{t-i})\\Big)\\cdot\\operatorname{rank}(z_{20}(TR'_t))\\cdot\\operatorname{rank}(|CLV_t|)\\cdot\\operatorname{rank}(-z_{20}(\\log(V_t+1)))\\\\TR'_t=\\max(H_t-L_t,|C_t-C_{t-1}|),\\quad CLV_t=\\frac{2C_t-H_t-L_t}{H_t-L_t+10^{-8}}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "7b2871a1586f",
        "parent_trajectory_ids": [
          "d11eb432cad7"
        ],
        "hypothesis": "Hypothesis: A short-horizon “streak exhaustion reversal” effect exists: after a 5-day directional return streak, if the last day shows exhaustion (TrueRange z-score over 20D is high, close is pinned near the streak-direction extreme via high |CLV|, and log-volume is below its 20D z-score), then the next 3–5 trading day return tends to reverse; when the same streak occurs without exhaustion (low TrueRange z-score and weak extreme-close), reversal probability is lower and continuation is more likely.\n                Concise Observation: The available OHLCV data supports orthogonal, microstructure-like signals (streak length, true range expansion, close-in-range pressure, and volume divergence) that do not reuse the parent strategy’s 55D Donchian/60D trend or impact/liquidity-vacuum constructs and are naturally aligned to 1–5 day horizons.\n                Concise Justification: A 5-day streak proxies for short-term positioning buildup; combining (i) abnormal TrueRange vs a 20D baseline, (ii) extreme close location (CLV) in the streak direction, and (iii) negative volume confirmation creates a testable exhaustion filter that should isolate end-of-move candles where continuation fuel is scarce and reversal risk is elevated.\n                Concise Knowledge: If short-term trend-followers become crowded over several consecutive days, then a late-stage range-expansion candle with close-at-extreme but weakening volume indicates marginal demand/supply depletion; when this depletion is present, liquidity provision and profit-taking should dominate over the next few days, producing mean reversion, whereas absent depletion signals, continuation is more likely.\n                concise Specification: Compute per instrument-day: streak_length_5 = consecutive same-sign daily returns capped at 5; TR = max(high-low, |high-prev_close|, |low-prev_close|); TR_z20 = zscore(TR, 20); CLV = (2*close-high-low)/(high-low+1e-8); VOL_z20 = zscore(log(volume+1), 20); define ExhaustionScore_5_20 = I(streak_length_5==5)*SIGN(sum(return over last 5d))*RANK(TR_z20)*RANK(ABS(CLV))*RANK(-VOL_z20), where higher score predicts negative next-3/5d return in the streak direction (reversal), and test the contrast set where TR_z20 is low and ABS(CLV) is low for weaker reversal/possible continuation.\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-22T08:57:49.843798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0968333873527188,
        "ICIR": 0.0376780199854975,
        "1day.excess_return_without_cost.std": 0.0041849215471846,
        "1day.excess_return_with_cost.annualized_return": 0.0410710034128783,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003717542057139,
        "1day.excess_return_without_cost.annualized_return": 0.0884775009599302,
        "1day.excess_return_with_cost.std": 0.004186772394951,
        "Rank IC": 0.0217072263204846,
        "IC": 0.0052058079282313,
        "1day.excess_return_without_cost.max_drawdown": -0.0873329609293837,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3704306024900246,
        "1day.pa": 0.0,
        "l2.valid": 0.9961150853999317,
        "Rank ICIR": 0.1588763689571593,
        "l2.train": 0.9929814709139256,
        "1day.excess_return_with_cost.information_ratio": 0.6358687511734816,
        "1day.excess_return_with_cost.mean": 0.0001725672412305
      },
      "feedback": {
        "observations": "The combined run improves portfolio-level performance materially versus SOTA on risk-adjusted return (information_ratio 1.370 vs 0.973) and absolute return (annualized_return 0.0885 vs 0.0520), but worsens downside tail behavior and pointwise predictive correlation (max_drawdown -0.0873 vs -0.0726; IC 0.00521 vs 0.00580). This pattern is consistent with a signal that is useful when translated into a trading/portfolio rule (e.g., via nonlinear model or ranking/selection), but whose linear cross-sectional correlation (IC) is weaker and/or whose exposure occasionally loads into drawdown-prone regimes.",
        "hypothesis_evaluation": "Overall, the results are supportive-but-not-clean for the ‘streak exhaustion reversal’ hypothesis.\n\nSupport:\n- The large improvement in annualized return and information ratio suggests the factors are extracting economically meaningful structure consistent with reversal/continuation conditioning after 5-day same-sign streaks.\n- The contrast construction (exhaustion reversal vs no-exhaustion continuation) is conceptually aligned with the hypothesis and likely helps the model form a regime-dependent mapping.\n\nCaveats / partial refutation signals:\n- IC deteriorated vs SOTA, implying the cross-sectional monotonic relationship between factor score and next-day return is weaker than before. This can happen if (a) the effect is horizon-specific (3–5D) but you are being judged largely through 1D/next-day labels or trading mechanics, (b) the signal is highly conditional and sparse (only active on 5D streak days), or (c) the rank-product structure creates extreme/nonlinear outputs that help portfolio selection but reduce linear correlation.\n- Max drawdown is worse, suggesting the reversal logic may fail in strong trend regimes (where streaks continue despite “exhaustion-like” prints), or that the gating is too permissive and triggers contrarian bets into momentum markets.\n\nHyperparameters explicitly present in this framework (critical for next iteration sweeps; each setting should be a separate static factor definition):\n- Streak lookback: 5 days (hard gate: last 5 returns same sign)\n- Streak direction aggregator: TS_SUM(return, 5) then SIGN\n- Volatility/range normalization window: 20D z-score (TR’ z20; range z20)\n- Volume normalization window: 20D z-score in two factors; 5D z-score in the variant\n- Volume transform: LOG(volume+1)\n- CLV transform: ABS(CLV) (i.e., ignores whether close pinned to high vs low)\n- True range proxy: TR’ = MAX(high-low, |close - DELAY(close,1)|)\n- Cross-sectional transform: RANK(.) then multiplicative combination (rank-product)\n\nNet: the hypothesis is directionally supported (portfolio metrics up), but the weaker IC + worse drawdown indicate the exhaustion conditions and/or gating need refinement to improve robustness and generalization.",
        "decision": true,
        "reason": "1) Signed vs absolute CLV: Using |CLV| treats closes pinned to highs and lows as equivalent, but reversal should depend on whether the close is pinned to the extreme in the streak direction (e.g., after an up-streak, CLV near +1 is more relevant than CLV near -1). Switching to direction-consistent CLV (e.g., CLV * sign(streak)) should reduce false positives and may improve IC and drawdown.\n\n2) Streak intensity normalization: A simple 5-day same-sign gate can trigger on weak drifts; adding a magnitude condition like TS_SUM(return,5) / TS_STD(return,20) (or z-scoring the 5D return) targets true “extended” moves, likely reducing noisy contrarian trades.\n\n3) Regime filter to address drawdown: Worse max drawdown vs SOTA strongly hints at failure during strong momentum regimes. Add a regime qualifier (within the same theoretical framework) such as: only take reversal signals when medium-horizon trend is flat (e.g., 20D momentum near 0) or when volatility is elevated relative to its own history.\n\n4) Sensitivity to windows: Current windows (z20 for TR/range, z20 or z5 for volume) are plausible but arbitrary. Because performance improved in IR/return but degraded in IC/drawdown, the next step is parameter sensitivity rather than changing the core idea.\n\nConcrete next-iteration suggestions (keep expressions simple; avoid extra raw features beyond high/low/close/volume):\n- Define separate factors for each window choice:\n  - Streak length L ∈ {3, 4, 5, 7}\n  - TR/range z-score window Wtr ∈ {10, 20, 40}\n  - Volume z-score window Wv ∈ {5, 10, 20}\n- Replace ABS(CLV) with direction-consistent pinning:\n  - pin_t = CLV_t * SIGN(TS_SUM(r,5)) (then rank of pin_t, not |CLV|)\n  - or pin_t = -CLV_t * SIGN(TS_SUM(r,5)) depending on convention; test both as distinct factors\n- Add streak magnitude conditioning as a separate factor variant:\n  - gate = 1[COUNT(r>0,5)=5 or COUNT(r<0,5)=5] * RANK( TS_SUM(r,5) / (TS_STD(r,20)+1e-8) )\n  - then multiply exhaustion components by gate (but keep it minimal to control complexity)\n- Reduce drawdown via a simple regime filter variant:\n  - e.g., only activate reversal when 20D momentum rank is low/neutral (define as separate factor)\n\nComplexity control note:\n- Your current formulations are not obviously over-complex (mostly a few rolling ops + ranks). Keep it that way. The biggest robustness gains here likely come from (a) signed CLV alignment and (b) window/streak sensitivity sweeps, not from adding more terms."
      }
    },
    "dc98cbf1dec41493": {
      "factor_id": "dc98cbf1dec41493",
      "factor_name": "Streak5_NoExhaustion_Continuation_TRz20_CLV_Volz20",
      "factor_expression": "(((COUNT($return>0,5)==5)||(COUNT($return<0,5)==5))?(SIGN(TS_SUM($return,5))*RANK(-TS_ZSCORE(MAX($high-$low,ABS($close-DELAY($close,1))),20))*RANK(-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*RANK(TS_ZSCORE(LOG($volume+1),20))):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((COUNT(TS_PCTCHANGE($close,1)>0,5)==5)||(COUNT(TS_PCTCHANGE($close,1)<0,5)==5))*(SIGN(TS_SUM(TS_PCTCHANGE($close,1),5))*RANK(-TS_ZSCORE(MAX($high-$low,ABS($close-DELAY($close,1))),20))*RANK(-ABS((2*$close-$high-$low)/($high-$low+1e-8)))*RANK(TS_ZSCORE(LOG($volume+1),20)))\" # Your output factor expression will be filled in here\n    name = \"Streak5_NoExhaustion_Continuation_TRz20_CLV_Volz20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "5-day directional streak continuation score (contrast set). Active only when the past 5 daily returns are all positive or all negative. It loads on LOW range expansion (low TR z-score), weak close-at-extreme (low |CLV|), and supportive volume (high log-volume z-score). Higher values indicate higher continuation likelihood over the next 3–5 days (i.e., positive return in the streak direction).",
      "factor_formulation": "g_t=\\mathbf{1}[\\text{5D same-sign streak}]\\cdot\\operatorname{sign}(\\sum_{i=0}^4 r_{t-i})\\cdot\\operatorname{rank}(-z_{20}(TR'_t))\\cdot\\operatorname{rank}(-|CLV_t|)\\cdot\\operatorname{rank}(z_{20}(\\log(V_t+1)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "7b2871a1586f",
        "parent_trajectory_ids": [
          "d11eb432cad7"
        ],
        "hypothesis": "Hypothesis: A short-horizon “streak exhaustion reversal” effect exists: after a 5-day directional return streak, if the last day shows exhaustion (TrueRange z-score over 20D is high, close is pinned near the streak-direction extreme via high |CLV|, and log-volume is below its 20D z-score), then the next 3–5 trading day return tends to reverse; when the same streak occurs without exhaustion (low TrueRange z-score and weak extreme-close), reversal probability is lower and continuation is more likely.\n                Concise Observation: The available OHLCV data supports orthogonal, microstructure-like signals (streak length, true range expansion, close-in-range pressure, and volume divergence) that do not reuse the parent strategy’s 55D Donchian/60D trend or impact/liquidity-vacuum constructs and are naturally aligned to 1–5 day horizons.\n                Concise Justification: A 5-day streak proxies for short-term positioning buildup; combining (i) abnormal TrueRange vs a 20D baseline, (ii) extreme close location (CLV) in the streak direction, and (iii) negative volume confirmation creates a testable exhaustion filter that should isolate end-of-move candles where continuation fuel is scarce and reversal risk is elevated.\n                Concise Knowledge: If short-term trend-followers become crowded over several consecutive days, then a late-stage range-expansion candle with close-at-extreme but weakening volume indicates marginal demand/supply depletion; when this depletion is present, liquidity provision and profit-taking should dominate over the next few days, producing mean reversion, whereas absent depletion signals, continuation is more likely.\n                concise Specification: Compute per instrument-day: streak_length_5 = consecutive same-sign daily returns capped at 5; TR = max(high-low, |high-prev_close|, |low-prev_close|); TR_z20 = zscore(TR, 20); CLV = (2*close-high-low)/(high-low+1e-8); VOL_z20 = zscore(log(volume+1), 20); define ExhaustionScore_5_20 = I(streak_length_5==5)*SIGN(sum(return over last 5d))*RANK(TR_z20)*RANK(ABS(CLV))*RANK(-VOL_z20), where higher score predicts negative next-3/5d return in the streak direction (reversal), and test the contrast set where TR_z20 is low and ABS(CLV) is low for weaker reversal/possible continuation.\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-22T08:57:49.843798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0968333873527188,
        "ICIR": 0.0376780199854975,
        "1day.excess_return_without_cost.std": 0.0041849215471846,
        "1day.excess_return_with_cost.annualized_return": 0.0410710034128783,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003717542057139,
        "1day.excess_return_without_cost.annualized_return": 0.0884775009599302,
        "1day.excess_return_with_cost.std": 0.004186772394951,
        "Rank IC": 0.0217072263204846,
        "IC": 0.0052058079282313,
        "1day.excess_return_without_cost.max_drawdown": -0.0873329609293837,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3704306024900246,
        "1day.pa": 0.0,
        "l2.valid": 0.9961150853999317,
        "Rank ICIR": 0.1588763689571593,
        "l2.train": 0.9929814709139256,
        "1day.excess_return_with_cost.information_ratio": 0.6358687511734816,
        "1day.excess_return_with_cost.mean": 0.0001725672412305
      },
      "feedback": {
        "observations": "The combined run improves portfolio-level performance materially versus SOTA on risk-adjusted return (information_ratio 1.370 vs 0.973) and absolute return (annualized_return 0.0885 vs 0.0520), but worsens downside tail behavior and pointwise predictive correlation (max_drawdown -0.0873 vs -0.0726; IC 0.00521 vs 0.00580). This pattern is consistent with a signal that is useful when translated into a trading/portfolio rule (e.g., via nonlinear model or ranking/selection), but whose linear cross-sectional correlation (IC) is weaker and/or whose exposure occasionally loads into drawdown-prone regimes.",
        "hypothesis_evaluation": "Overall, the results are supportive-but-not-clean for the ‘streak exhaustion reversal’ hypothesis.\n\nSupport:\n- The large improvement in annualized return and information ratio suggests the factors are extracting economically meaningful structure consistent with reversal/continuation conditioning after 5-day same-sign streaks.\n- The contrast construction (exhaustion reversal vs no-exhaustion continuation) is conceptually aligned with the hypothesis and likely helps the model form a regime-dependent mapping.\n\nCaveats / partial refutation signals:\n- IC deteriorated vs SOTA, implying the cross-sectional monotonic relationship between factor score and next-day return is weaker than before. This can happen if (a) the effect is horizon-specific (3–5D) but you are being judged largely through 1D/next-day labels or trading mechanics, (b) the signal is highly conditional and sparse (only active on 5D streak days), or (c) the rank-product structure creates extreme/nonlinear outputs that help portfolio selection but reduce linear correlation.\n- Max drawdown is worse, suggesting the reversal logic may fail in strong trend regimes (where streaks continue despite “exhaustion-like” prints), or that the gating is too permissive and triggers contrarian bets into momentum markets.\n\nHyperparameters explicitly present in this framework (critical for next iteration sweeps; each setting should be a separate static factor definition):\n- Streak lookback: 5 days (hard gate: last 5 returns same sign)\n- Streak direction aggregator: TS_SUM(return, 5) then SIGN\n- Volatility/range normalization window: 20D z-score (TR’ z20; range z20)\n- Volume normalization window: 20D z-score in two factors; 5D z-score in the variant\n- Volume transform: LOG(volume+1)\n- CLV transform: ABS(CLV) (i.e., ignores whether close pinned to high vs low)\n- True range proxy: TR’ = MAX(high-low, |close - DELAY(close,1)|)\n- Cross-sectional transform: RANK(.) then multiplicative combination (rank-product)\n\nNet: the hypothesis is directionally supported (portfolio metrics up), but the weaker IC + worse drawdown indicate the exhaustion conditions and/or gating need refinement to improve robustness and generalization.",
        "decision": true,
        "reason": "1) Signed vs absolute CLV: Using |CLV| treats closes pinned to highs and lows as equivalent, but reversal should depend on whether the close is pinned to the extreme in the streak direction (e.g., after an up-streak, CLV near +1 is more relevant than CLV near -1). Switching to direction-consistent CLV (e.g., CLV * sign(streak)) should reduce false positives and may improve IC and drawdown.\n\n2) Streak intensity normalization: A simple 5-day same-sign gate can trigger on weak drifts; adding a magnitude condition like TS_SUM(return,5) / TS_STD(return,20) (or z-scoring the 5D return) targets true “extended” moves, likely reducing noisy contrarian trades.\n\n3) Regime filter to address drawdown: Worse max drawdown vs SOTA strongly hints at failure during strong momentum regimes. Add a regime qualifier (within the same theoretical framework) such as: only take reversal signals when medium-horizon trend is flat (e.g., 20D momentum near 0) or when volatility is elevated relative to its own history.\n\n4) Sensitivity to windows: Current windows (z20 for TR/range, z20 or z5 for volume) are plausible but arbitrary. Because performance improved in IR/return but degraded in IC/drawdown, the next step is parameter sensitivity rather than changing the core idea.\n\nConcrete next-iteration suggestions (keep expressions simple; avoid extra raw features beyond high/low/close/volume):\n- Define separate factors for each window choice:\n  - Streak length L ∈ {3, 4, 5, 7}\n  - TR/range z-score window Wtr ∈ {10, 20, 40}\n  - Volume z-score window Wv ∈ {5, 10, 20}\n- Replace ABS(CLV) with direction-consistent pinning:\n  - pin_t = CLV_t * SIGN(TS_SUM(r,5)) (then rank of pin_t, not |CLV|)\n  - or pin_t = -CLV_t * SIGN(TS_SUM(r,5)) depending on convention; test both as distinct factors\n- Add streak magnitude conditioning as a separate factor variant:\n  - gate = 1[COUNT(r>0,5)=5 or COUNT(r<0,5)=5] * RANK( TS_SUM(r,5) / (TS_STD(r,20)+1e-8) )\n  - then multiply exhaustion components by gate (but keep it minimal to control complexity)\n- Reduce drawdown via a simple regime filter variant:\n  - e.g., only activate reversal when 20D momentum rank is low/neutral (define as separate factor)\n\nComplexity control note:\n- Your current formulations are not obviously over-complex (mostly a few rolling ops + ranks). Keep it that way. The biggest robustness gains here likely come from (a) signed CLV alignment and (b) window/streak sensitivity sweeps, not from adding more terms."
      }
    },
    "7d8f8e9075fb1758": {
      "factor_id": "7d8f8e9075fb1758",
      "factor_name": "Streak5_Exhaustion_Reversal_Rangez20_CLV_Volz5",
      "factor_expression": "(((COUNT($return>0,5)==5)||(COUNT($return<0,5)==5))?(-SIGN(TS_SUM($return,5))*RANK(TS_ZSCORE($high-$low,20))*RANK(ABS((2*$close-$high-$low)/($high-$low+1e-8)))*RANK(-TS_ZSCORE(LOG($volume+1),5))):0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(((COUNT(TS_PCTCHANGE($close,1)>0,5)==5)||(COUNT(TS_PCTCHANGE($close,1)<0,5)==5))?(-SIGN(TS_SUM(TS_PCTCHANGE($close,1),5))*RANK(TS_ZSCORE(($high-$low),20))*RANK(ABS((2*$close-$high-$low)/($high-$low+1e-8)))*RANK(-TS_ZSCORE(LOG($volume+1),5))):0)\" # Your output factor expression will be filled in here\n    name = \"Streak5_Exhaustion_Reversal_Rangez20_CLV_Volz5\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Variant exhaustion reversal score emphasizing intraday range expansion (high-low) vs 20D and short-horizon volume weakness (log-volume z-score vs 5D), while still requiring a 5-day same-sign return streak and close-at-extreme pressure via |CLV|. Higher values predict reversal over the next 3–5 days in the streak direction.",
      "factor_formulation": "h_t=\\mathbf{1}[\\text{5D same-sign streak}]\\cdot\\Big(-\\operatorname{sign}(\\sum_{i=0}^4 r_{t-i})\\Big)\\cdot\\operatorname{rank}(z_{20}(H_t-L_t))\\cdot\\operatorname{rank}(|CLV_t|)\\cdot\\operatorname{rank}(-z_{5}(\\log(V_t+1)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "7b2871a1586f",
        "parent_trajectory_ids": [
          "d11eb432cad7"
        ],
        "hypothesis": "Hypothesis: A short-horizon “streak exhaustion reversal” effect exists: after a 5-day directional return streak, if the last day shows exhaustion (TrueRange z-score over 20D is high, close is pinned near the streak-direction extreme via high |CLV|, and log-volume is below its 20D z-score), then the next 3–5 trading day return tends to reverse; when the same streak occurs without exhaustion (low TrueRange z-score and weak extreme-close), reversal probability is lower and continuation is more likely.\n                Concise Observation: The available OHLCV data supports orthogonal, microstructure-like signals (streak length, true range expansion, close-in-range pressure, and volume divergence) that do not reuse the parent strategy’s 55D Donchian/60D trend or impact/liquidity-vacuum constructs and are naturally aligned to 1–5 day horizons.\n                Concise Justification: A 5-day streak proxies for short-term positioning buildup; combining (i) abnormal TrueRange vs a 20D baseline, (ii) extreme close location (CLV) in the streak direction, and (iii) negative volume confirmation creates a testable exhaustion filter that should isolate end-of-move candles where continuation fuel is scarce and reversal risk is elevated.\n                Concise Knowledge: If short-term trend-followers become crowded over several consecutive days, then a late-stage range-expansion candle with close-at-extreme but weakening volume indicates marginal demand/supply depletion; when this depletion is present, liquidity provision and profit-taking should dominate over the next few days, producing mean reversion, whereas absent depletion signals, continuation is more likely.\n                concise Specification: Compute per instrument-day: streak_length_5 = consecutive same-sign daily returns capped at 5; TR = max(high-low, |high-prev_close|, |low-prev_close|); TR_z20 = zscore(TR, 20); CLV = (2*close-high-low)/(high-low+1e-8); VOL_z20 = zscore(log(volume+1), 20); define ExhaustionScore_5_20 = I(streak_length_5==5)*SIGN(sum(return over last 5d))*RANK(TR_z20)*RANK(ABS(CLV))*RANK(-VOL_z20), where higher score predicts negative next-3/5d return in the streak direction (reversal), and test the contrast set where TR_z20 is low and ABS(CLV) is low for weaker reversal/possible continuation.\n                ",
        "initial_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "planning_direction": "Residual mean-reversion vs breakout: Use RESI5 as deviation-from-trend and interact with RSQR10; hypothesize that extreme |RESI5| predicts next-3/5d reversal when RSQR10 is low (unstable trend), but predicts continuation/breakout when RSQR10 is high (stable trend).",
        "created_at": "2026-01-22T08:57:49.843798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0968333873527188,
        "ICIR": 0.0376780199854975,
        "1day.excess_return_without_cost.std": 0.0041849215471846,
        "1day.excess_return_with_cost.annualized_return": 0.0410710034128783,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003717542057139,
        "1day.excess_return_without_cost.annualized_return": 0.0884775009599302,
        "1day.excess_return_with_cost.std": 0.004186772394951,
        "Rank IC": 0.0217072263204846,
        "IC": 0.0052058079282313,
        "1day.excess_return_without_cost.max_drawdown": -0.0873329609293837,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3704306024900246,
        "1day.pa": 0.0,
        "l2.valid": 0.9961150853999317,
        "Rank ICIR": 0.1588763689571593,
        "l2.train": 0.9929814709139256,
        "1day.excess_return_with_cost.information_ratio": 0.6358687511734816,
        "1day.excess_return_with_cost.mean": 0.0001725672412305
      },
      "feedback": {
        "observations": "The combined run improves portfolio-level performance materially versus SOTA on risk-adjusted return (information_ratio 1.370 vs 0.973) and absolute return (annualized_return 0.0885 vs 0.0520), but worsens downside tail behavior and pointwise predictive correlation (max_drawdown -0.0873 vs -0.0726; IC 0.00521 vs 0.00580). This pattern is consistent with a signal that is useful when translated into a trading/portfolio rule (e.g., via nonlinear model or ranking/selection), but whose linear cross-sectional correlation (IC) is weaker and/or whose exposure occasionally loads into drawdown-prone regimes.",
        "hypothesis_evaluation": "Overall, the results are supportive-but-not-clean for the ‘streak exhaustion reversal’ hypothesis.\n\nSupport:\n- The large improvement in annualized return and information ratio suggests the factors are extracting economically meaningful structure consistent with reversal/continuation conditioning after 5-day same-sign streaks.\n- The contrast construction (exhaustion reversal vs no-exhaustion continuation) is conceptually aligned with the hypothesis and likely helps the model form a regime-dependent mapping.\n\nCaveats / partial refutation signals:\n- IC deteriorated vs SOTA, implying the cross-sectional monotonic relationship between factor score and next-day return is weaker than before. This can happen if (a) the effect is horizon-specific (3–5D) but you are being judged largely through 1D/next-day labels or trading mechanics, (b) the signal is highly conditional and sparse (only active on 5D streak days), or (c) the rank-product structure creates extreme/nonlinear outputs that help portfolio selection but reduce linear correlation.\n- Max drawdown is worse, suggesting the reversal logic may fail in strong trend regimes (where streaks continue despite “exhaustion-like” prints), or that the gating is too permissive and triggers contrarian bets into momentum markets.\n\nHyperparameters explicitly present in this framework (critical for next iteration sweeps; each setting should be a separate static factor definition):\n- Streak lookback: 5 days (hard gate: last 5 returns same sign)\n- Streak direction aggregator: TS_SUM(return, 5) then SIGN\n- Volatility/range normalization window: 20D z-score (TR’ z20; range z20)\n- Volume normalization window: 20D z-score in two factors; 5D z-score in the variant\n- Volume transform: LOG(volume+1)\n- CLV transform: ABS(CLV) (i.e., ignores whether close pinned to high vs low)\n- True range proxy: TR’ = MAX(high-low, |close - DELAY(close,1)|)\n- Cross-sectional transform: RANK(.) then multiplicative combination (rank-product)\n\nNet: the hypothesis is directionally supported (portfolio metrics up), but the weaker IC + worse drawdown indicate the exhaustion conditions and/or gating need refinement to improve robustness and generalization.",
        "decision": true,
        "reason": "1) Signed vs absolute CLV: Using |CLV| treats closes pinned to highs and lows as equivalent, but reversal should depend on whether the close is pinned to the extreme in the streak direction (e.g., after an up-streak, CLV near +1 is more relevant than CLV near -1). Switching to direction-consistent CLV (e.g., CLV * sign(streak)) should reduce false positives and may improve IC and drawdown.\n\n2) Streak intensity normalization: A simple 5-day same-sign gate can trigger on weak drifts; adding a magnitude condition like TS_SUM(return,5) / TS_STD(return,20) (or z-scoring the 5D return) targets true “extended” moves, likely reducing noisy contrarian trades.\n\n3) Regime filter to address drawdown: Worse max drawdown vs SOTA strongly hints at failure during strong momentum regimes. Add a regime qualifier (within the same theoretical framework) such as: only take reversal signals when medium-horizon trend is flat (e.g., 20D momentum near 0) or when volatility is elevated relative to its own history.\n\n4) Sensitivity to windows: Current windows (z20 for TR/range, z20 or z5 for volume) are plausible but arbitrary. Because performance improved in IR/return but degraded in IC/drawdown, the next step is parameter sensitivity rather than changing the core idea.\n\nConcrete next-iteration suggestions (keep expressions simple; avoid extra raw features beyond high/low/close/volume):\n- Define separate factors for each window choice:\n  - Streak length L ∈ {3, 4, 5, 7}\n  - TR/range z-score window Wtr ∈ {10, 20, 40}\n  - Volume z-score window Wv ∈ {5, 10, 20}\n- Replace ABS(CLV) with direction-consistent pinning:\n  - pin_t = CLV_t * SIGN(TS_SUM(r,5)) (then rank of pin_t, not |CLV|)\n  - or pin_t = -CLV_t * SIGN(TS_SUM(r,5)) depending on convention; test both as distinct factors\n- Add streak magnitude conditioning as a separate factor variant:\n  - gate = 1[COUNT(r>0,5)=5 or COUNT(r<0,5)=5] * RANK( TS_SUM(r,5) / (TS_STD(r,20)+1e-8) )\n  - then multiply exhaustion components by gate (but keep it minimal to control complexity)\n- Reduce drawdown via a simple regime filter variant:\n  - e.g., only activate reversal when 20D momentum rank is low/neutral (define as separate factor)\n\nComplexity control note:\n- Your current formulations are not obviously over-complex (mostly a few rolling ops + ranks). Keep it that way. The biggest robustness gains here likely come from (a) signed CLV alignment and (b) window/streak sensitivity sweeps, not from adding more terms."
      }
    },
    "e896142e448899d1": {
      "factor_id": "e896142e448899d1",
      "factor_name": "GapFade_Intensity_10D_RangeZ20_CLVMid",
      "factor_expression": "RANK(TS_MEAN((-LOG($open/DELAY($close,1))*LOG($close/$open))*TS_ZSCORE((($high-$low)/($close+1e-8)),20)*(1-ABS((2*$close-$high-$low)/(($high-$low)+1e-8))),10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((-LOG($open/DELAY($close,1))*LOG($close/$open))*TS_ZSCORE((($high-$low)/($close+1e-8)),20)*(1-ABS((2*$close-$high-$low)/(($high-$low)+1e-8))),10))\" # Your output factor expression will be filled in here\n    name = \"GapFade_Intensity_10D_RangeZ20_CLVMid\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Continuous gap-and-fade reversal intensity: rewards opposite-signed overnight vs intraday log-returns (negative product), amplified when intraday normalized range is high (20D TS_ZSCORE) and the close is near the middle of the day's range (1-|CLV|). Averaged over 10 days and cross-sectionally ranked.",
      "factor_formulation": "F_t=\\operatorname{RANK}\\left(\\operatorname{TS\\_MEAN}\\left( -r_{on,t}r_{id,t}\\cdot Z_{20}(\\tfrac{H_t-L_t}{C_t})\\cdot (1-|CLV_t|),10\\right)\\right),\\; r_{on,t}=\\log(\\tfrac{O_t}{C_{t-1}}),\\; r_{id,t}=\\log(\\tfrac{C_t}{O_t}),\\; CLV_t=\\tfrac{2C_t-H_t-L_t}{H_t-L_t}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "e522727249a0",
        "parent_trajectory_ids": [
          "483a296a51b6"
        ],
        "hypothesis": "Hypothesis: Stocks exhibiting persistent “gap-and-fade” intraday reversal—where the overnight return (close[t-1]→open[t]) is systematically offset by an opposite-signed intraday return (open[t]→close[t]) under elevated intraday range and weak close-location—will mean-revert over the next 2–15 trading days (i.e., predict opposite-signed forward returns), consistent with transient liquidity/auction price-pressure rather than information-driven trend.\n                Concise Observation: With only daily OHLCV available, the cleanest orthogonal microstructure proxy to breakout/continuation is the decomposition of daily return into overnight (C[t-1]→O[t]) and intraday (O[t]→C[t]) components plus geometry features (range and close-location) that distinguish ‘failed follow-through’ from trend confirmation.\n                Concise Justification: A repeated negative interaction between overnight and intraday returns (gap-and-fade) indicates that opening price pressure is being reversed by same-day liquidity provision; when accompanied by high (H−L) and a close away from extremes, it implies transient impact rather than a directional breakout, so subsequent returns should revert as the imbalance dissipates.\n                Concise Knowledge: If price changes are dominated by short-lived liquidity imbalance (e.g., opening gap caused by temporary order-flow) rather than information, then an opposite-signed intraday move that “fades” the gap—especially when the day’s range is large but the close is not near extremes—should signal temporary impact and predict subsequent mean-reversion over the next few to ~15 sessions.\n                concise Specification: Define overnight log-return r_on[t]=log(O[t]/C[t-1]) and intraday log-return r_id[t]=log(C[t]/O[t]); construct a reversal-intensity signal over a fixed window N=10 as: mean( I(sign(r_on)≠sign(r_id)) * |r_on*r_id| ) scaled by a volatility/geometry gate requiring (H−L)/C to be above its 20D median and close-location-in-range CLV=(2C−H−L)/(H−L+1e-8) to satisfy |CLV|<0.3; test that higher signal predicts opposite-signed next-k returns for k∈{2,5,10,15} cross-sectionally, with all hyperparameters fixed (N=10, range window=20, CLV threshold=0.3).\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-22T09:06:56.815564"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1018234285646253,
        "ICIR": 0.0351908079579382,
        "1day.excess_return_without_cost.std": 0.0041211581398113,
        "1day.excess_return_with_cost.annualized_return": 0.0109147056460296,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002431614078343,
        "1day.excess_return_without_cost.annualized_return": 0.057872415064584,
        "1day.excess_return_with_cost.std": 0.0041229693819873,
        "Rank IC": 0.0206259736117666,
        "IC": 0.0047401467585865,
        "1day.excess_return_without_cost.max_drawdown": -0.0945484494299648,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.910256623579539,
        "1day.pa": 0.0,
        "l2.valid": 0.996728223789114,
        "Rank ICIR": 0.1582835725768729,
        "l2.train": 0.9943039415778804,
        "1day.excess_return_with_cost.information_ratio": 0.1715984812339775,
        "1day.excess_return_with_cost.mean": 4.5860107756426894e-05
      },
      "feedback": {
        "observations": "Only the two implemented factors (GapFade_Intensity_10D_RangeZ20_CLVMid, GapFade_DaysCount_10D_RangeMed20_CLV03) were tested. The combined portfolio shows higher annualized return than SOTA (0.0579 vs 0.0520), but worse risk-adjusted and signal-quality metrics: information ratio is lower (0.910 vs 0.973), IC is lower (0.00474 vs 0.00580), and max drawdown is worse (0.0945 vs 0.0726; smaller is better). Net: the new construction likely increased raw return via higher risk/vol exposure rather than improving the true predictive signal.",
        "hypothesis_evaluation": "Partial/weak support at best. The hypothesis claims a robust mean-reversion signal over the next 2–15 trading days driven by persistent gap-and-fade under high range and weak close-location. However:\n1) The measured IC is positive but very small, and it deteriorated vs SOTA, suggesting the implemented versions did not strengthen the intended predictive relationship.\n2) Your reported evaluation metrics are explicitly for a 1-day excess-return portfolio. This is misaligned with the stated 2–15 day mean-reversion horizon; a real effect at 2–15D can look weak/noisy at 1D. You should re-run with labels/holding periods matching 2D, 5D, 10D, 15D forward returns (and check whether IC increases with horizon).\n3) The worse drawdown + worse IR indicates the current factor combination may be loading on volatility/range regimes (risk-on/risk-off) rather than isolating “auction pressure then fade” as an alpha.\nConclusion: the current results do not refute the hypothesis, but they do not convincingly confirm it either given (a) horizon mismatch and (b) deterioration in IC/IR vs SOTA.",
        "decision": false,
        "reason": "Your multipliers (range z-score / range median filter and mid-range close weighting) can inadvertently proxy for volatility regimes. That can raise raw returns while worsening drawdown/IR and depressing IC. Adding a participation/liquidity condition (e.g., relative volume/turnover) and aligning the evaluation horizon with the hypothesized 2–15D window should better isolate transient price-pressure reversals from information-driven moves.\n\nConcrete iteration directions (keep factors simple; define each hyperparameter explicitly as separate factors):\n1) Horizon alignment tests (critical):\n- Evaluate factor IC and portfolio metrics on forward returns of 2D/5D/10D/15D. If the hypothesis is correct, IC should increase with horizon up to a point.\n\n2) Implement the missing persistence-coupling factor (already proposed):\n- GapFade_NegCorr_10D_RangeRank20_CLVMid (hyperparams: corr window=10, range rank window=20). This directly targets “persistent offset” rather than single-day product noise.\n\n3) Reduce volatility contamination / improve robustness:\n- Try a normalized core signal: S_t = -(r_on * r_id) / (TS_STD(r_on,20)*TS_STD(r_id,20)) with the same CLV and range gates. (Hyperparams: std window=20, mean window=10). This aims to remove ‘just high vol’ effects.\n- Alternatively, drop one multiplier at a time to see which is hurting generalization:\n  a) Intensity_10D with CLV only (remove range zscore)\n  b) Intensity_10D with range only (remove CLV)\n  c) Pure gap-fade intensity without both (baseline)\n\n4) Parameter sweeps (each is a distinct factor by your rule):\n- Lookback aggregation: TS_MEAN window ∈ {5, 10, 20}\n- Range normalization window ∈ {10, 20, 60}\n- CLV mid-band: |CLV| threshold ∈ {0.2, 0.3, 0.4} (for the discrete version) and mid-weighting forms: (1-|CLV|) vs (1-CLV^2)\n- Discrete persistence: use FRACTION instead of COUNT to stabilize across missing days: COUNT(condition,10)/10 (hyperparams: 10)\n\n5) Participation/liquidity conditioning (still same framework; minimal extra feature):\n- Add relative volume gate: volume / TS_MEAN(volume,20) < 1 (or TS_ZSCORE(volume,20) < 0) to focus on low-participation gaps more likely to revert. (Hyperparams: 20)\n- Keep it as a separate factor or a separate gate variant to avoid over-engineering.\n\n6) Cross-sectional treatment:\n- RANK can discard magnitude information that may matter. Test CS_ZSCORE instead of RANK (one new factor variant) or do rank within industry/sector if available (if not, skip).\n\n7) Directionality sanity check:\n- The hypothesis implies “predict opposite-signed forward returns.” Ensure the factor sign is aligned with the model target (you may need to multiply by -1 depending on whether high factor corresponds to stronger future reversal or continuation in your current implementation)."
      }
    },
    "c3ab721846e2a981": {
      "factor_id": "c3ab721846e2a981",
      "factor_name": "GapFade_DaysCount_10D_RangeMed20_CLV03",
      "factor_expression": "COUNT((LOG($open/DELAY($close,1))*LOG($close/$open)<0)&&(ABS((2*$close-$high-$low)/(($high-$low)+1e-8))<0.3)&&(($high-$low)>TS_MEDIAN($high-$low,20)),10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"COUNT((LOG($open/DELAY($close,1))*LOG($close/$open)<0)&&(ABS((2*$close-$high-$low)/(($high-$low)+1e-8))<0.3)&&(($high-$low)>TS_MEDIAN($high-$low,20)),10)\" # Your output factor expression will be filled in here\n    name = \"GapFade_DaysCount_10D_RangeMed20_CLV03\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Discrete persistence measure: counts the number of days in the past 10 where overnight and intraday log-returns have opposite signs (product<0), the intraday range is above its 20D median, and close-location-in-range is not near extremes (|CLV|<0.3). Higher count indicates more persistent gap-and-fade behavior.",
      "factor_formulation": "F_t=\\operatorname{COUNT}\\Big( (r_{on,t}r_{id,t}<0)\\land (|CLV_t|<0.3)\\land (Range_t>\\operatorname{TS\\_MEDIAN}(Range,20)),10\\Big),\\; Range_t=H_t-L_t",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "e522727249a0",
        "parent_trajectory_ids": [
          "483a296a51b6"
        ],
        "hypothesis": "Hypothesis: Stocks exhibiting persistent “gap-and-fade” intraday reversal—where the overnight return (close[t-1]→open[t]) is systematically offset by an opposite-signed intraday return (open[t]→close[t]) under elevated intraday range and weak close-location—will mean-revert over the next 2–15 trading days (i.e., predict opposite-signed forward returns), consistent with transient liquidity/auction price-pressure rather than information-driven trend.\n                Concise Observation: With only daily OHLCV available, the cleanest orthogonal microstructure proxy to breakout/continuation is the decomposition of daily return into overnight (C[t-1]→O[t]) and intraday (O[t]→C[t]) components plus geometry features (range and close-location) that distinguish ‘failed follow-through’ from trend confirmation.\n                Concise Justification: A repeated negative interaction between overnight and intraday returns (gap-and-fade) indicates that opening price pressure is being reversed by same-day liquidity provision; when accompanied by high (H−L) and a close away from extremes, it implies transient impact rather than a directional breakout, so subsequent returns should revert as the imbalance dissipates.\n                Concise Knowledge: If price changes are dominated by short-lived liquidity imbalance (e.g., opening gap caused by temporary order-flow) rather than information, then an opposite-signed intraday move that “fades” the gap—especially when the day’s range is large but the close is not near extremes—should signal temporary impact and predict subsequent mean-reversion over the next few to ~15 sessions.\n                concise Specification: Define overnight log-return r_on[t]=log(O[t]/C[t-1]) and intraday log-return r_id[t]=log(C[t]/O[t]); construct a reversal-intensity signal over a fixed window N=10 as: mean( I(sign(r_on)≠sign(r_id)) * |r_on*r_id| ) scaled by a volatility/geometry gate requiring (H−L)/C to be above its 20D median and close-location-in-range CLV=(2C−H−L)/(H−L+1e-8) to satisfy |CLV|<0.3; test that higher signal predicts opposite-signed next-k returns for k∈{2,5,10,15} cross-sectionally, with all hyperparameters fixed (N=10, range window=20, CLV threshold=0.3).\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-22T09:06:56.815564"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1018234285646253,
        "ICIR": 0.0351908079579382,
        "1day.excess_return_without_cost.std": 0.0041211581398113,
        "1day.excess_return_with_cost.annualized_return": 0.0109147056460296,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002431614078343,
        "1day.excess_return_without_cost.annualized_return": 0.057872415064584,
        "1day.excess_return_with_cost.std": 0.0041229693819873,
        "Rank IC": 0.0206259736117666,
        "IC": 0.0047401467585865,
        "1day.excess_return_without_cost.max_drawdown": -0.0945484494299648,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.910256623579539,
        "1day.pa": 0.0,
        "l2.valid": 0.996728223789114,
        "Rank ICIR": 0.1582835725768729,
        "l2.train": 0.9943039415778804,
        "1day.excess_return_with_cost.information_ratio": 0.1715984812339775,
        "1day.excess_return_with_cost.mean": 4.5860107756426894e-05
      },
      "feedback": {
        "observations": "Only the two implemented factors (GapFade_Intensity_10D_RangeZ20_CLVMid, GapFade_DaysCount_10D_RangeMed20_CLV03) were tested. The combined portfolio shows higher annualized return than SOTA (0.0579 vs 0.0520), but worse risk-adjusted and signal-quality metrics: information ratio is lower (0.910 vs 0.973), IC is lower (0.00474 vs 0.00580), and max drawdown is worse (0.0945 vs 0.0726; smaller is better). Net: the new construction likely increased raw return via higher risk/vol exposure rather than improving the true predictive signal.",
        "hypothesis_evaluation": "Partial/weak support at best. The hypothesis claims a robust mean-reversion signal over the next 2–15 trading days driven by persistent gap-and-fade under high range and weak close-location. However:\n1) The measured IC is positive but very small, and it deteriorated vs SOTA, suggesting the implemented versions did not strengthen the intended predictive relationship.\n2) Your reported evaluation metrics are explicitly for a 1-day excess-return portfolio. This is misaligned with the stated 2–15 day mean-reversion horizon; a real effect at 2–15D can look weak/noisy at 1D. You should re-run with labels/holding periods matching 2D, 5D, 10D, 15D forward returns (and check whether IC increases with horizon).\n3) The worse drawdown + worse IR indicates the current factor combination may be loading on volatility/range regimes (risk-on/risk-off) rather than isolating “auction pressure then fade” as an alpha.\nConclusion: the current results do not refute the hypothesis, but they do not convincingly confirm it either given (a) horizon mismatch and (b) deterioration in IC/IR vs SOTA.",
        "decision": false,
        "reason": "Your multipliers (range z-score / range median filter and mid-range close weighting) can inadvertently proxy for volatility regimes. That can raise raw returns while worsening drawdown/IR and depressing IC. Adding a participation/liquidity condition (e.g., relative volume/turnover) and aligning the evaluation horizon with the hypothesized 2–15D window should better isolate transient price-pressure reversals from information-driven moves.\n\nConcrete iteration directions (keep factors simple; define each hyperparameter explicitly as separate factors):\n1) Horizon alignment tests (critical):\n- Evaluate factor IC and portfolio metrics on forward returns of 2D/5D/10D/15D. If the hypothesis is correct, IC should increase with horizon up to a point.\n\n2) Implement the missing persistence-coupling factor (already proposed):\n- GapFade_NegCorr_10D_RangeRank20_CLVMid (hyperparams: corr window=10, range rank window=20). This directly targets “persistent offset” rather than single-day product noise.\n\n3) Reduce volatility contamination / improve robustness:\n- Try a normalized core signal: S_t = -(r_on * r_id) / (TS_STD(r_on,20)*TS_STD(r_id,20)) with the same CLV and range gates. (Hyperparams: std window=20, mean window=10). This aims to remove ‘just high vol’ effects.\n- Alternatively, drop one multiplier at a time to see which is hurting generalization:\n  a) Intensity_10D with CLV only (remove range zscore)\n  b) Intensity_10D with range only (remove CLV)\n  c) Pure gap-fade intensity without both (baseline)\n\n4) Parameter sweeps (each is a distinct factor by your rule):\n- Lookback aggregation: TS_MEAN window ∈ {5, 10, 20}\n- Range normalization window ∈ {10, 20, 60}\n- CLV mid-band: |CLV| threshold ∈ {0.2, 0.3, 0.4} (for the discrete version) and mid-weighting forms: (1-|CLV|) vs (1-CLV^2)\n- Discrete persistence: use FRACTION instead of COUNT to stabilize across missing days: COUNT(condition,10)/10 (hyperparams: 10)\n\n5) Participation/liquidity conditioning (still same framework; minimal extra feature):\n- Add relative volume gate: volume / TS_MEAN(volume,20) < 1 (or TS_ZSCORE(volume,20) < 0) to focus on low-participation gaps more likely to revert. (Hyperparams: 20)\n- Keep it as a separate factor or a separate gate variant to avoid over-engineering.\n\n6) Cross-sectional treatment:\n- RANK can discard magnitude information that may matter. Test CS_ZSCORE instead of RANK (one new factor variant) or do rank within industry/sector if available (if not, skip).\n\n7) Directionality sanity check:\n- The hypothesis implies “predict opposite-signed forward returns.” Ensure the factor sign is aligned with the model target (you may need to multiply by -1 depending on whether high factor corresponds to stronger future reversal or continuation in your current implementation)."
      }
    },
    "805cb45af4bdd50a": {
      "factor_id": "805cb45af4bdd50a",
      "factor_name": "GapFade_NegCorr_10D_RangeRank20_CLVMid",
      "factor_expression": "(-TS_CORR(LOG($open/DELAY($close,1)),LOG($close/$open),10))*(TS_RANK($high-$low,20)/20)*(1-ABS((2*$close-$high-$low)/(($high-$low)+1e-8)))",
      "factor_implementation_code": "",
      "factor_description": "Persistence via negative coupling: uses the negative 10D rolling correlation between overnight and intraday log-returns (more positive when they are consistently opposite). Scales by elevated recent range (20D TS_RANK) and by mid-range closing (1-|CLV|).",
      "factor_formulation": "F_t=\\big(-\\operatorname{TS\\_CORR}(r_{on},r_{id},10)\\big)\\cdot \\frac{\\operatorname{TS\\_RANK}(H-L,20)}{20}\\cdot (1-|CLV_t|)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-23-45-603859",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "e522727249a0",
        "parent_trajectory_ids": [
          "483a296a51b6"
        ],
        "hypothesis": "Hypothesis: Stocks exhibiting persistent “gap-and-fade” intraday reversal—where the overnight return (close[t-1]→open[t]) is systematically offset by an opposite-signed intraday return (open[t]→close[t]) under elevated intraday range and weak close-location—will mean-revert over the next 2–15 trading days (i.e., predict opposite-signed forward returns), consistent with transient liquidity/auction price-pressure rather than information-driven trend.\n                Concise Observation: With only daily OHLCV available, the cleanest orthogonal microstructure proxy to breakout/continuation is the decomposition of daily return into overnight (C[t-1]→O[t]) and intraday (O[t]→C[t]) components plus geometry features (range and close-location) that distinguish ‘failed follow-through’ from trend confirmation.\n                Concise Justification: A repeated negative interaction between overnight and intraday returns (gap-and-fade) indicates that opening price pressure is being reversed by same-day liquidity provision; when accompanied by high (H−L) and a close away from extremes, it implies transient impact rather than a directional breakout, so subsequent returns should revert as the imbalance dissipates.\n                Concise Knowledge: If price changes are dominated by short-lived liquidity imbalance (e.g., opening gap caused by temporary order-flow) rather than information, then an opposite-signed intraday move that “fades” the gap—especially when the day’s range is large but the close is not near extremes—should signal temporary impact and predict subsequent mean-reversion over the next few to ~15 sessions.\n                concise Specification: Define overnight log-return r_on[t]=log(O[t]/C[t-1]) and intraday log-return r_id[t]=log(C[t]/O[t]); construct a reversal-intensity signal over a fixed window N=10 as: mean( I(sign(r_on)≠sign(r_id)) * |r_on*r_id| ) scaled by a volatility/geometry gate requiring (H−L)/C to be above its 20D median and close-location-in-range CLV=(2C−H−L)/(H−L+1e-8) to satisfy |CLV|<0.3; test that higher signal predicts opposite-signed next-k returns for k∈{2,5,10,15} cross-sectionally, with all hyperparameters fixed (N=10, range window=20, CLV threshold=0.3).\n                ",
        "initial_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "planning_direction": "Intraday support strength as a predictive microstructure signal: Form a factor based on KLOW normalized by KLEN (lower-shadow share) and condition on STD5; hypothesize that high lower-shadow share (buy-the-dip) predicts positive next-1/3d returns especially when STD5 is elevated (volatile regimes).",
        "created_at": "2026-01-22T09:06:56.815564"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1018234285646253,
        "ICIR": 0.0351908079579382,
        "1day.excess_return_without_cost.std": 0.0041211581398113,
        "1day.excess_return_with_cost.annualized_return": 0.0109147056460296,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002431614078343,
        "1day.excess_return_without_cost.annualized_return": 0.057872415064584,
        "1day.excess_return_with_cost.std": 0.0041229693819873,
        "Rank IC": 0.0206259736117666,
        "IC": 0.0047401467585865,
        "1day.excess_return_without_cost.max_drawdown": -0.0945484494299648,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.910256623579539,
        "1day.pa": 0.0,
        "l2.valid": 0.996728223789114,
        "Rank ICIR": 0.1582835725768729,
        "l2.train": 0.9943039415778804,
        "1day.excess_return_with_cost.information_ratio": 0.1715984812339775,
        "1day.excess_return_with_cost.mean": 4.5860107756426894e-05
      },
      "feedback": {
        "observations": "Only the two implemented factors (GapFade_Intensity_10D_RangeZ20_CLVMid, GapFade_DaysCount_10D_RangeMed20_CLV03) were tested. The combined portfolio shows higher annualized return than SOTA (0.0579 vs 0.0520), but worse risk-adjusted and signal-quality metrics: information ratio is lower (0.910 vs 0.973), IC is lower (0.00474 vs 0.00580), and max drawdown is worse (0.0945 vs 0.0726; smaller is better). Net: the new construction likely increased raw return via higher risk/vol exposure rather than improving the true predictive signal.",
        "hypothesis_evaluation": "Partial/weak support at best. The hypothesis claims a robust mean-reversion signal over the next 2–15 trading days driven by persistent gap-and-fade under high range and weak close-location. However:\n1) The measured IC is positive but very small, and it deteriorated vs SOTA, suggesting the implemented versions did not strengthen the intended predictive relationship.\n2) Your reported evaluation metrics are explicitly for a 1-day excess-return portfolio. This is misaligned with the stated 2–15 day mean-reversion horizon; a real effect at 2–15D can look weak/noisy at 1D. You should re-run with labels/holding periods matching 2D, 5D, 10D, 15D forward returns (and check whether IC increases with horizon).\n3) The worse drawdown + worse IR indicates the current factor combination may be loading on volatility/range regimes (risk-on/risk-off) rather than isolating “auction pressure then fade” as an alpha.\nConclusion: the current results do not refute the hypothesis, but they do not convincingly confirm it either given (a) horizon mismatch and (b) deterioration in IC/IR vs SOTA.",
        "decision": false,
        "reason": "Your multipliers (range z-score / range median filter and mid-range close weighting) can inadvertently proxy for volatility regimes. That can raise raw returns while worsening drawdown/IR and depressing IC. Adding a participation/liquidity condition (e.g., relative volume/turnover) and aligning the evaluation horizon with the hypothesized 2–15D window should better isolate transient price-pressure reversals from information-driven moves.\n\nConcrete iteration directions (keep factors simple; define each hyperparameter explicitly as separate factors):\n1) Horizon alignment tests (critical):\n- Evaluate factor IC and portfolio metrics on forward returns of 2D/5D/10D/15D. If the hypothesis is correct, IC should increase with horizon up to a point.\n\n2) Implement the missing persistence-coupling factor (already proposed):\n- GapFade_NegCorr_10D_RangeRank20_CLVMid (hyperparams: corr window=10, range rank window=20). This directly targets “persistent offset” rather than single-day product noise.\n\n3) Reduce volatility contamination / improve robustness:\n- Try a normalized core signal: S_t = -(r_on * r_id) / (TS_STD(r_on,20)*TS_STD(r_id,20)) with the same CLV and range gates. (Hyperparams: std window=20, mean window=10). This aims to remove ‘just high vol’ effects.\n- Alternatively, drop one multiplier at a time to see which is hurting generalization:\n  a) Intensity_10D with CLV only (remove range zscore)\n  b) Intensity_10D with range only (remove CLV)\n  c) Pure gap-fade intensity without both (baseline)\n\n4) Parameter sweeps (each is a distinct factor by your rule):\n- Lookback aggregation: TS_MEAN window ∈ {5, 10, 20}\n- Range normalization window ∈ {10, 20, 60}\n- CLV mid-band: |CLV| threshold ∈ {0.2, 0.3, 0.4} (for the discrete version) and mid-weighting forms: (1-|CLV|) vs (1-CLV^2)\n- Discrete persistence: use FRACTION instead of COUNT to stabilize across missing days: COUNT(condition,10)/10 (hyperparams: 10)\n\n5) Participation/liquidity conditioning (still same framework; minimal extra feature):\n- Add relative volume gate: volume / TS_MEAN(volume,20) < 1 (or TS_ZSCORE(volume,20) < 0) to focus on low-participation gaps more likely to revert. (Hyperparams: 20)\n- Keep it as a separate factor or a separate gate variant to avoid over-engineering.\n\n6) Cross-sectional treatment:\n- RANK can discard magnitude information that may matter. Test CS_ZSCORE instead of RANK (one new factor variant) or do rank within industry/sector if available (if not, skip).\n\n7) Directionality sanity check:\n- The hypothesis implies “predict opposite-signed forward returns.” Ensure the factor sign is aligned with the model target (you may need to multiply by -1 depending on whether high factor corresponds to stronger future reversal or continuation in your current implementation)."
      }
    }
  }
}