#!/usr/bin/env python3
"""
å›æµ‹æ‰§è¡Œå™¨ - ä½¿ç”¨ Qlib è¿›è¡Œå®Œæ•´å›æµ‹

åŠŸèƒ½:
1. åŠ è½½å› å­ï¼ˆå®˜æ–¹/è‡ªå®šä¹‰ï¼‰
2. è®¡ç®—è‡ªå®šä¹‰å› å­å€¼
3. è®­ç»ƒæ¨¡å‹
4. æ‰§è¡Œå›æµ‹
5. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
"""

import json
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple

import numpy as np
import pandas as pd
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)


class BacktestRunner:
    """å›æµ‹æ‰§è¡Œå™¨"""
    
    def __init__(self, config_path: str):
        """
        åˆå§‹åŒ–å›æµ‹æ‰§è¡Œå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self._qlib_initialized = False
        
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"âœ“ åŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
        return config
    
    def _init_qlib(self):
        """åˆå§‹åŒ– Qlib"""
        if self._qlib_initialized:
            return
            
        import qlib
        
        provider_uri = self.config['data']['provider_uri']
        qlib.init(provider_uri=provider_uri, region='cn')
        self._qlib_initialized = True
        logger.info(f"âœ“ Qlib åˆå§‹åŒ–å®Œæˆ: {provider_uri}")
    
    def run(self, 
            factor_source: Optional[str] = None,
            factor_json: Optional[List[str]] = None,
            experiment_name: Optional[str] = None) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´å›æµ‹æµç¨‹
        
        Args:
            factor_source: å› å­æºç±»å‹ (è¦†ç›–é…ç½®æ–‡ä»¶)
            factor_json: è‡ªå®šä¹‰å› å­ JSON æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (è¦†ç›–é…ç½®æ–‡ä»¶)
            experiment_name: å®éªŒåç§° (è¦†ç›–é…ç½®æ–‡ä»¶)
            
        Returns:
            Dict: å›æµ‹ç»“æœæŒ‡æ ‡
        """
        start_time_total = time.time()
        
        # åˆå§‹åŒ– Qlib
        self._init_qlib()
        
        # æ›´æ–°é…ç½®
        if factor_source:
            self.config['factor_source']['type'] = factor_source
        if factor_json:
            self.config['factor_source']['custom']['json_files'] = factor_json
        
        exp_name = experiment_name or self.config['experiment']['name']
        rec_name = self.config['experiment']['recorder']
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ å¼€å§‹å›æµ‹: {exp_name}")
        print(f"{'='*70}\n")
        
        # 1. åŠ è½½å› å­
        print("ğŸ“Š ç¬¬ä¸€æ­¥ï¼šåŠ è½½å› å­...")
        factor_expressions, custom_factors = self._load_factors()
        print(f"  âœ“ Qlib å…¼å®¹å› å­: {len(factor_expressions)} ä¸ª")
        print(f"  âœ“ éœ€è¦è®¡ç®—çš„è‡ªå®šä¹‰å› å­: {len(custom_factors)} ä¸ª")
        
        # 2. è®¡ç®—è‡ªå®šä¹‰å› å­ï¼ˆå¦‚æœæœ‰ï¼‰
        computed_factors = None
        if custom_factors:
            print("\nğŸ”§ ç¬¬äºŒæ­¥ï¼šè®¡ç®—è‡ªå®šä¹‰å› å­...")
            computed_factors = self._compute_custom_factors(custom_factors)
            if computed_factors is not None and not computed_factors.empty:
                print(f"  âœ“ æˆåŠŸè®¡ç®— {len(computed_factors.columns)} ä¸ªå› å­")
        
        # 3. åˆ›å»ºæ•°æ®é›†
        print("\nğŸ“ˆ ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ•°æ®é›†...")
        dataset = self._create_dataset(factor_expressions, computed_factors)
        
        # 4. è®­ç»ƒæ¨¡å‹å¹¶å›æµ‹
        print("\nğŸ¤– ç¬¬å››æ­¥ï¼šè®­ç»ƒæ¨¡å‹å¹¶æ‰§è¡Œå›æµ‹...")
        metrics = self._train_and_backtest(dataset, exp_name, rec_name)
        
        # 5. è¾“å‡ºç»“æœ
        total_time = time.time() - start_time_total
        self._print_results(metrics, total_time)
        
        # 6. ä¿å­˜ç»“æœ
        self._save_results(metrics, exp_name, factor_source or self.config['factor_source']['type'], 
                          len(factor_expressions) + len(custom_factors), total_time)
        
        return metrics
    
    def _load_factors(self) -> Tuple[Dict[str, str], List[Dict]]:
        """åŠ è½½å› å­"""
        from .factor_loader import FactorLoader
        
        loader = FactorLoader(self.config)
        return loader.load_factors()
    
    def _compute_custom_factors(self, factors: List[Dict]) -> Optional[pd.DataFrame]:
        """è®¡ç®—è‡ªå®šä¹‰å› å­"""
        from .factor_calculator import FactorCalculator, QlibDataProvider
        
        # è·å–æ•°æ®
        data_provider = QlibDataProvider(self.config)
        data_df = data_provider.get_stock_data()
        
        # è®¡ç®—å› å­
        calculator = FactorCalculator(self.config, data_df)
        return calculator.calculate_factors(factors)
    
    def _create_dataset(self, 
                       factor_expressions: Dict[str, str],
                       computed_factors: Optional[pd.DataFrame] = None):
        """åˆ›å»º Qlib æ•°æ®é›†"""
        from qlib.data.dataset import DatasetH
        from qlib.data.dataset.handler import DataHandlerLP
        
        data_config = self.config['data']
        dataset_config = self.config['dataset']
        
        # å‡†å¤‡å› å­è¡¨è¾¾å¼åˆ—è¡¨
        expressions = list(factor_expressions.values())
        names = list(factor_expressions.keys())
        
        handler_config = {
            'start_time': data_config['start_time'],
            'end_time': data_config['end_time'],
            'instruments': data_config['market'],
            'data_loader': {
                'class': 'QlibDataLoader',
                'module_path': 'qlib.contrib.data.loader',
                'kwargs': {
                    'config': {
                        'feature': (expressions, names),
                        'label': ([dataset_config['label']], ['LABEL0'])
                    }
                }
            },
            'learn_processors': dataset_config['learn_processors'],
            'infer_processors': dataset_config['infer_processors']
        }
        
        dataset = DatasetH(
            handler=DataHandlerLP(**handler_config),
            segments=dataset_config['segments']
        )
        
        print(f"  è®­ç»ƒé›†: {dataset_config['segments']['train']}")
        print(f"  éªŒè¯é›†: {dataset_config['segments']['valid']}")
        print(f"  æµ‹è¯•é›†: {dataset_config['segments']['test']}")
        
        return dataset
    
    def _train_and_backtest(self, dataset, exp_name: str, rec_name: str) -> Dict:
        """è®­ç»ƒæ¨¡å‹å¹¶æ‰§è¡Œå›æµ‹"""
        from qlib.contrib.model.gbdt import LGBModel
        from qlib.data import D
        from qlib.workflow import R
        from qlib.workflow.record_temp import SignalRecord, SigAnaRecord
        from qlib.backtest import backtest as qlib_backtest
        from qlib.contrib.evaluate import risk_analysis
        
        model_config = self.config['model']
        backtest_config = self.config['backtest']['backtest']
        strategy_config = self.config['backtest']['strategy']
        
        metrics = {}
        
        with R.start(experiment_name=exp_name, recorder_name=rec_name):
            # è®­ç»ƒæ¨¡å‹
            print("  è®­ç»ƒ LightGBM æ¨¡å‹...")
            train_start = time.time()
            
            if model_config['type'] == 'lgb':
                model = LGBModel(**model_config['params'])
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_config['type']}")
            
            model.fit(dataset)
            print(f"  âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ (è€—æ—¶: {time.time()-train_start:.2f}ç§’)")
            
            # ç”Ÿæˆé¢„æµ‹
            print("  ç”Ÿæˆé¢„æµ‹...")
            pred = model.predict(dataset)
            print(f"  âœ“ é¢„æµ‹æ•°æ®å½¢çŠ¶: {pred.shape}")
            
            # ä¿å­˜é¢„æµ‹
            sr = SignalRecord(recorder=R.get_recorder(), model=model, dataset=dataset)
            sr.generate()
            
            # è®¡ç®— IC æŒ‡æ ‡
            print("  è®¡ç®— IC æŒ‡æ ‡...")
            try:
                sar = SigAnaRecord(recorder=R.get_recorder(), ana_long_short=False, ann_scaler=252)
                sar.generate()
                
                recorder = R.get_recorder()
                try:
                    ic_series = recorder.load_object("sig_analysis/ic.pkl")
                    ric_series = recorder.load_object("sig_analysis/ric.pkl")
                    
                    if isinstance(ic_series, pd.Series) and len(ic_series) > 0:
                        metrics['IC'] = float(ic_series.mean())
                        metrics['ICIR'] = float(ic_series.mean() / ic_series.std()) if ic_series.std() > 0 else 0.0
                    
                    if isinstance(ric_series, pd.Series) and len(ric_series) > 0:
                        metrics['Rank IC'] = float(ric_series.mean())
                        metrics['Rank ICIR'] = float(ric_series.mean() / ric_series.std()) if ric_series.std() > 0 else 0.0
                    
                    print(f"  âœ“ IC={metrics.get('IC', 0):.6f}, ICIR={metrics.get('ICIR', 0):.6f}")
                    print(f"  âœ“ Rank IC={metrics.get('Rank IC', 0):.6f}, Rank ICIR={metrics.get('Rank ICIR', 0):.6f}")
                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å– IC ç»“æœ: {e}")
            except Exception as e:
                logger.warning(f"IC åˆ†æå¤±è´¥: {e}")
            
            # æ‰§è¡Œç»„åˆå›æµ‹
            print("  æ‰§è¡Œç»„åˆå›æµ‹...")
            try:
                bt_start = time.time()
                
                market = self.config['data']['market']
                instruments = D.instruments(market)
                stock_list = D.list_instruments(
                    instruments,
                    start_time=backtest_config['start_time'],
                    end_time=backtest_config['end_time'],
                    as_list=True
                )
                print(f"  âœ“ è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
                
                if len(stock_list) < 10:
                    logger.warning(f"âš ï¸  è­¦å‘Š: è‚¡ç¥¨æ± è¿‡å° ({len(stock_list)} åªè‚¡ç¥¨)ï¼Œå›æµ‹ç»“æœå¯èƒ½ä¸å¯ä¿¡ï¼")
                
                # è¿‡æ»¤ä»·æ ¼å¼‚å¸¸çš„è‚¡ç¥¨ä¿¡å·
                print("  æ£€æŸ¥å¹¶è¿‡æ»¤ä»·æ ¼å¼‚å¸¸æ•°æ®...")
                try:
                    price_data = D.features(
                        stock_list,
                        ['$close'],
                        start_time=backtest_config['start_time'],
                        end_time=backtest_config['end_time'],
                        freq='day'
                    )
                    invalid_mask = (price_data['$close'] == 0) | (price_data['$close'].isna())
                    invalid_count = invalid_mask.sum()
                    
                    if invalid_count > 0:
                        print(f"  âš ï¸ å‘ç° {invalid_count} æ¡ä»·æ ¼ä¸º0/NaNçš„è®°å½•")
                        if isinstance(pred, pd.Series):
                            invalid_indices = invalid_mask[invalid_mask].index
                            invalid_set = set()
                            for idx in invalid_indices:
                                instrument, datetime = idx
                                invalid_set.add((datetime, instrument))
                            
                            filtered_count = 0
                            for idx in pred.index:
                                if idx in invalid_set:
                                    pred.loc[idx] = np.nan
                                    filtered_count += 1
                            
                            if filtered_count > 0:
                                print(f"  âœ“ å·²å°† {filtered_count} æ¡ä»·æ ¼å¼‚å¸¸çš„é¢„æµ‹ä¿¡å·è®¾ä¸ºNaN")
                except Exception as filter_err:
                    logger.warning(f"ä»·æ ¼è¿‡æ»¤å¤±è´¥: {filter_err}")
                
                portfolio_metric_dict, indicator_dict = qlib_backtest(
                    executor={
                        "class": "SimulatorExecutor",
                        "module_path": "qlib.backtest.executor",
                        "kwargs": {
                            "time_per_step": "day",
                            "generate_portfolio_metrics": True,
                            "verbose": False,
                            "indicator_config": {"show_indicator": False}
                        }
                    },
                    strategy={
                        "class": strategy_config['class'],
                        "module_path": strategy_config['module_path'],
                        "kwargs": {
                            "signal": pred,
                            "topk": strategy_config['kwargs']['topk'],
                            "n_drop": strategy_config['kwargs']['n_drop']
                        }
                    },
                    start_time=backtest_config['start_time'],
                    end_time=backtest_config['end_time'],
                    account=backtest_config['account'],
                    benchmark=backtest_config['benchmark'],
                    exchange_kwargs={
                        "codes": stock_list,
                        **backtest_config['exchange_kwargs']
                    }
                )
                
                print(f"  âœ“ ç»„åˆå›æµ‹å®Œæˆ (è€—æ—¶: {time.time()-bt_start:.2f}ç§’)")
                
                # æå–ç»„åˆæŒ‡æ ‡
                if portfolio_metric_dict and "1day" in portfolio_metric_dict:
                    report_df, positions_df = portfolio_metric_dict["1day"]
                    
                    if isinstance(report_df, pd.DataFrame) and 'return' in report_df.columns:
                        portfolio_return = report_df['return'].replace([np.inf, -np.inf], np.nan).fillna(0)
                        bench_return = report_df['bench'].replace([np.inf, -np.inf], np.nan).fillna(0) if 'bench' in report_df.columns else 0
                        cost = report_df['cost'].replace([np.inf, -np.inf], np.nan).fillna(0) if 'cost' in report_df.columns else 0
                        
                        excess_return_with_cost = portfolio_return - bench_return - cost
                        excess_return_with_cost = excess_return_with_cost.dropna()
                        
                        if len(excess_return_with_cost) > 0:
                            analysis = risk_analysis(excess_return_with_cost)
                            
                            if isinstance(analysis, pd.DataFrame):
                                analysis = analysis['risk'] if 'risk' in analysis.columns else analysis.iloc[:, 0]
                            
                            ann_ret = float(analysis.get('annualized_return', 0))
                            info_ratio = float(analysis.get('information_ratio', 0))
                            max_dd = float(analysis.get('max_drawdown', 0))
                            
                            if not np.isnan(ann_ret) and not np.isinf(ann_ret):
                                metrics['annualized_return'] = ann_ret
                            if not np.isnan(info_ratio) and not np.isinf(info_ratio):
                                metrics['information_ratio'] = info_ratio
                            if not np.isnan(max_dd) and not np.isinf(max_dd):
                                metrics['max_drawdown'] = max_dd
                            
                            if max_dd != 0 and not np.isnan(ann_ret) and not np.isinf(ann_ret):
                                calmar = ann_ret / abs(max_dd)
                                if not np.isnan(calmar) and not np.isinf(calmar):
                                    metrics['calmar_ratio'] = calmar
                            
                            print(f"  âœ“ æå–äº†ç»„åˆç­–ç•¥æŒ‡æ ‡")
                            
            except Exception as e:
                logger.warning(f"ç»„åˆå›æµ‹å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        return metrics
    
    def _print_results(self, metrics: Dict, total_time: float):
        """æ‰“å°ç»“æœ"""
        print(f"\n{'='*70}")
        print("ğŸ“ˆ å›æµ‹ç»“æœ:")
        print(f"{'='*70}")
        
        print("\nã€IC æŒ‡æ ‡ã€‘")
        print(f"  IC:               {metrics.get('IC', 'N/A'):.6f}" if isinstance(metrics.get('IC'), float) else f"  IC:               {metrics.get('IC', 'N/A')}")
        print(f"  ICIR:             {metrics.get('ICIR', 'N/A'):.6f}" if isinstance(metrics.get('ICIR'), float) else f"  ICIR:             {metrics.get('ICIR', 'N/A')}")
        print(f"  Rank IC:          {metrics.get('Rank IC', 'N/A'):.6f}" if isinstance(metrics.get('Rank IC'), float) else f"  Rank IC:          {metrics.get('Rank IC', 'N/A')}")
        print(f"  Rank ICIR:        {metrics.get('Rank ICIR', 'N/A'):.6f}" if isinstance(metrics.get('Rank ICIR'), float) else f"  Rank ICIR:        {metrics.get('Rank ICIR', 'N/A')}")
        
        print("\nã€ç­–ç•¥æŒ‡æ ‡ã€‘")
        print(f"  å¹´åŒ–æ”¶ç›Š:         {metrics.get('annualized_return', 'N/A'):.4f}" if isinstance(metrics.get('annualized_return'), float) else f"  å¹´åŒ–æ”¶ç›Š:         {metrics.get('annualized_return', 'N/A')}")
        print(f"  ä¿¡æ¯æ¯”ç‡:         {metrics.get('information_ratio', 'N/A'):.4f}" if isinstance(metrics.get('information_ratio'), float) else f"  ä¿¡æ¯æ¯”ç‡:         {metrics.get('information_ratio', 'N/A')}")
        print(f"  æœ€å¤§å›æ’¤:         {metrics.get('max_drawdown', 'N/A'):.4f}" if isinstance(metrics.get('max_drawdown'), float) else f"  æœ€å¤§å›æ’¤:         {metrics.get('max_drawdown', 'N/A')}")
        print(f"  å¡å°”ç›æ¯”ç‡:       {metrics.get('calmar_ratio', 'N/A'):.4f}" if isinstance(metrics.get('calmar_ratio'), float) else f"  å¡å°”ç›æ¯”ç‡:       {metrics.get('calmar_ratio', 'N/A')}")
        
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"{'='*70}\n")
    
    def _save_results(self, metrics: Dict, exp_name: str, 
                     factor_source: str, num_factors: int, elapsed: float):
        """ä¿å­˜ç»“æœ"""
        output_dir = Path(self.config['experiment'].get('output_dir', './backtest_v2_results'))
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = self.config['experiment']['output_metrics_file']
        output_path = output_dir / output_file
        
        result_data = {
            "experiment_name": exp_name,
            "factor_source": factor_source,
            "num_factors": num_factors,
            "metrics": metrics,
            "config": {
                "data_range": f"{self.config['data']['start_time']} ~ {self.config['data']['end_time']}",
                "test_range": f"{self.config['dataset']['segments']['test'][0]} ~ {self.config['dataset']['segments']['test'][1]}",
                "backtest_range": f"{self.config['backtest']['backtest']['start_time']} ~ {self.config['backtest']['backtest']['end_time']}",
                "market": self.config['data']['market'],
                "benchmark": self.config['backtest']['backtest']['benchmark']
            },
            "elapsed_seconds": elapsed
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}\n")
