{
  "metadata": {
    "created_at": "2026-01-17T12:00:22.246171",
    "last_updated": "2026-01-17T12:00:22.246177",
    "total_factors": 185,
    "version": "1.0",
    "source": "all_factors_library_10_10_10_best1_组合123_QA.json",
    "note": "evolution_phase为mutation的所有因子，保持原始顺序"
  },
  "factors": {
    "7e3f80ee8d36b54f": {
      "factor_id": "7e3f80ee8d36b54f",
      "factor_name": "Trend_Fragility_Index_20D",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies imminent regime shifts by measuring the volatility of trend linearity. It calculates the R-squared of the close price against a time index over a 10-day window to assess trend quality, then computes the 20-day rolling standard deviation of these R-squared values. High values indicate that the trend's stability is fluctuating, signaling a potential transition from stable momentum to chaotic price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.501939",
      "updated_at": "2026-01-17T06:03:35.808848"
    },
    "837d323fefb53783": {
      "factor_id": "837d323fefb53783",
      "factor_name": "VPBD_Volatility_Adjusted_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VPBD_Volatility_Adjusted_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the 5-day VWAP to the 5-day TWAP, normalized by the price volatility. A value greater than 1 suggests volume is concentrated at higher prices relative to the time-average, indicating aggressive institutional accumulation during low-volatility 'stealth' phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.747135",
      "updated_at": "2026-01-17T02:09:58.747143"
    },
    "0a76cc8f99c5c7e6": {
      "factor_id": "0a76cc8f99c5c7e6",
      "factor_name": "Stealth_Accumulation_ZScore_10D",
      "factor_expression": "RANK((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5)) * (1 - RANK(TS_STD($return, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5)) * (1 - RANK(TS_STD(TS_PCTCHANGE($close, 1), 10))))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of the VWAP-TWAP divergence during periods of compressed volatility. It identifies assets where buyers are paying a premium (VWAP > TWAP) while price action remains quiet, a hallmark of institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.759289",
      "updated_at": "2026-01-17T02:09:58.759295"
    },
    "a886230cf326bdc7": {
      "factor_id": "a886230cf326bdc7",
      "factor_name": "VWAP_TWAP_Convexity_5D",
      "factor_expression": "((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) - TS_MEAN($close, 5)) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) - TS_MEAN($close, 5)) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWAP_TWAP_Convexity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the intensity of volume-weighted price premiums relative to time-weighted prices, specifically targeting low-volatility regimes. High values indicate that volume is heavily skewed toward the upper end of the 5-day price range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.771189",
      "updated_at": "2026-01-17T02:09:58.771195"
    },
    "d4d86729fd6774d5": {
      "factor_id": "d4d86729fd6774d5",
      "factor_name": "Price_Convexity_Volume_Exhaustion_3D",
      "factor_expression": "DELTA(TS_PCTCHANGE($close, 1), 1) * (($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA(TS_PCTCHANGE($close, 1), 1) * (($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Convexity_Volume_Exhaustion_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion opportunities by detecting price acceleration (convexity) decoupled from volume support. It calculates the change in price returns (acceleration) and multiplies it by the intraday range-to-volume ratio to pinpoint retail-driven liquidity exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.523033",
      "updated_at": "2026-01-17T02:16:08.523040"
    },
    "02847e8e88449175": {
      "factor_id": "02847e8e88449175",
      "factor_name": "Ranked_Convexity_Efficiency_5D",
      "factor_expression": "RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Convexity_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the convexity hypothesis. It ranks the acceleration of price changes over the last 2 days and multiplies it by the rank of the price range per unit of volume. High values indicate stocks where price is 'blowing off' with low volume efficiency relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.535713",
      "updated_at": "2026-01-17T02:16:08.535720"
    },
    "82602f3ec66b4e93": {
      "factor_id": "82602f3ec66b4e93",
      "factor_name": "ZScored_Acceleration_Volume_Ratio_10D",
      "factor_expression": "TS_ZSCORE(DELTA(TS_PCTCHANGE($close, 1), 1), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(DELTA(TS_PCTCHANGE($close, 1), 1), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Acceleration_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the price acceleration and volume efficiency using time-series Z-scores over a 10-day window. It targets extreme deviations in price convexity that are not supported by proportional volume, signaling unsustainable moves.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.549256",
      "updated_at": "2026-01-17T02:16:08.549262"
    },
    "b3cd9d1f66a40514": {
      "factor_id": "b3cd9d1f66a40514",
      "factor_name": "Exhaustion_Gap_Reversal_5D",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Gap_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion gaps by calculating the ratio of the overnight gap to the 5-day average volume. It assumes that large gaps on low relative volume are unsustainable and likely to mean-revert. The factor is cross-sectionally ranked to identify the most extreme exhaustion candidates.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.874619",
      "updated_at": "2026-01-17T02:16:09.874626"
    },
    "34be0ab703c37f6b": {
      "factor_id": "34be0ab703c37f6b",
      "factor_name": "Gap_Intraday_Efficiency_Ratio",
      "factor_expression": "(ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * INV(TS_ZSCORE($volume, 10) + 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * INV(ABS(TS_ZSCORE($volume, 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Intraday_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 'efficiency' of a gap by comparing the overnight gap magnitude to the subsequent intraday range, normalized by volume intensity. If the gap is large but the intraday range is small relative to volume, it suggests a lack of follow-through and a high probability of reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.887332",
      "updated_at": "2026-01-17T02:16:09.887338"
    },
    "34fcf06e06ae043f": {
      "factor_id": "34fcf06e06ae043f",
      "factor_name": "Liquidity_Imbalance_Gap_Factor",
      "factor_expression": "SIGN($open - DELAY($close, 1)) * ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open - DELAY($close, 1)) * ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Imbalance_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Targets gaps driven by liquidity imbalances. It calculates the overnight gap and penalizes it if the intraday volume is significantly lower than the recent average, suggesting the gap was a 'low-conviction' move prone to filling.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.899914",
      "updated_at": "2026-01-17T02:16:09.899920"
    },
    "ab596c4b1cce2d5e": {
      "factor_id": "ab596c4b1cce2d5e",
      "factor_name": "Overnight_Gap_Volume_Intensity_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Volume_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Gap' by calculating the ratio of the overnight return to the 5-day average trading volume. A high overnight return relative to low volume suggests that the price shock hasn't been fully absorbed by the market, potentially leading to a post-announcement drift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.757718",
      "updated_at": "2026-01-17T02:18:50.757725"
    },
    "b6a2b87926f3b41e": {
      "factor_id": "b6a2b87926f3b41e",
      "factor_name": "Ranked_Gap_to_Volume_Ratio_10D",
      "factor_expression": "RANK((($open - DELAY($close, 1)) / DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open - DELAY($close, 1)) / DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_to_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the gap-to-volume ratio, normalized by the 10-day volume trend. It identifies stocks where the overnight price jump is most extreme relative to its recent liquidity context, signaling potential trend continuation due to incomplete information absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.774939",
      "updated_at": "2026-01-17T02:18:50.774945"
    },
    "73054cc654b85f9d": {
      "factor_id": "73054cc654b85f9d",
      "factor_name": "Gap_Liquidity_Divergence_ZScore",
      "factor_expression": "TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Liquidity_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the overnight price shock and recent volume intensity using a Z-score. It targets the hypothesis that significant gaps on low relative volume lead to multi-day drifts because institutional order imbalances are not cleared immediately.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.787763",
      "updated_at": "2026-01-17T02:18:50.787769"
    },
    "d99c0a2786538e10": {
      "factor_id": "d99c0a2786538e10",
      "factor_name": "Liquidity_Absorption_Efficiency_20D",
      "factor_expression": "RANK(TS_MEAN($volume, 20) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Absorption_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high institutional accumulation by calculating the ratio of average volume to price volatility. High volume combined with low volatility suggests that large orders are being absorbed without significant price impact, often preceding a breakout. The factor is cross-sectionally ranked for comparability.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.461197",
      "updated_at": "2026-01-17T02:19:32.461203"
    },
    "7ea821869b791a04": {
      "factor_id": "7ea821869b791a04",
      "factor_name": "Tight_Consolidation_Volume_Ratio_10D",
      "factor_expression": "RANK(TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Tight_Consolidation_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity absorption hypothesis focusing on a shorter 10-day window. It measures the intensity of volume relative to the true range of the price, identifying 'tight' price action under heavy accumulation. It uses the high-low range as a proxy for intraday volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.474462",
      "updated_at": "2026-01-17T02:19:32.474468"
    },
    "8ef60a16ce69bd4d": {
      "factor_id": "8ef60a16ce69bd4d",
      "factor_name": "ZScored_Absorption_Intensity_20D",
      "factor_expression": "TS_ZSCORE($volume, 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume, 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Absorption_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the liquidity absorption concept by using Z-scores to identify extreme outliers where volume is significantly higher than its own history while volatility remains suppressed. This highlights the 'coiled spring' effect more precisely.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.488899",
      "updated_at": "2026-01-17T02:19:32.488906"
    },
    "72899da06635a7c9": {
      "factor_id": "72899da06635a7c9",
      "factor_name": "Overnight_Liquidity_Exhaustion_Factor",
      "factor_expression": "RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Liquidity_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean reversion by calculating the ratio of the overnight gap to the average intraday range, conditioned on a negative correlation between price changes and volume. A high value suggests price dislocation due to liquidity exhaustion rather than fundamental conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.227209",
      "updated_at": "2026-01-17T02:25:06.227216"
    },
    "d8c3febdd45c3cc5": {
      "factor_id": "d8c3febdd45c3cc5",
      "factor_name": "Price_Volume_Divergence_Reversion",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($open, 1) / (TS_STD($high - $low, 5) + 1e-8)) * SIGN(-1 * TS_CORR($close - $open, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($open, 1) / (TS_STD($high - $low, 5) + 1e-8)) * SIGN(-1 * TS_CORR($close - $open, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Divergence_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Targets short-term reversals by capturing instances where the overnight return is disproportionately large compared to the recent volatility (intraday range), specifically when price and volume move in opposite directions (negative correlation), signaling weak conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.240378",
      "updated_at": "2026-01-17T02:25:06.240384"
    },
    "52db75a891a36d98": {
      "factor_id": "52db75a891a36d98",
      "factor_name": "Liquidity_Imbalance_Index",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 5) + 1e-8)) * (1 - TS_CORR(($close / $open - 1), LOG($volume + 1), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 5) + 1e-8)) * (1 - TS_CORR(($close / $open - 1), LOG($volume + 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Imbalance_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of price-volume decoupling. It normalizes the overnight gap by the 5-day median intraday range and scales it by the inverse of the price-volume correlation to highlight liquidity-driven gaps likely to reverse.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.253319",
      "updated_at": "2026-01-17T02:25:06.253325"
    },
    "d422b0c3436a867b": {
      "factor_id": "d422b0c3436a867b",
      "factor_name": "PVDP_Exhaustion_Ratio_10D",
      "factor_expression": "TS_CORR($return, TS_PCTCHANGE($volume, 1), 10) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 0.00001))\" # Your output factor expression will be filled in here\n    name = \"PVDP_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by measuring the divergence between price returns and volume changes, scaled by the ratio of overnight gaps to intraday ranges. A low correlation between returns and volume growth, coupled with a high gap-to-range ratio, suggests institutional withdrawal and potential mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.395591",
      "updated_at": "2026-01-17T02:26:06.395598"
    },
    "84d5431c1331477c": {
      "factor_id": "84d5431c1331477c",
      "factor_name": "Institutional_Exhaustion_Index_V1",
      "factor_expression": "RANK(TS_CORR($return, $volume, 10)) * RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10)) * RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 0.0001))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Index_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'quiet' exhaustion phase where price continues to drift on weakening volume support. It uses the rank-transformed correlation of price-volume and compares the magnitude of the opening jump to the subsequent intraday volatility. High values indicate the trend is driven by inertia rather than conviction.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.409041",
      "updated_at": "2026-01-17T02:26:06.409047"
    },
    "380a7d7077fba3ab": {
      "factor_id": "380a7d7077fba3ab",
      "factor_name": "Gap_Range_Divergence_ZScore",
      "factor_expression": "TS_CORR($return, $volume, 10) * TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10) * TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Gap_Range_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Normalizes the divergence between the overnight gap and intraday range using Z-scores, then interacts it with the price-volume correlation. This highlights periods where price movements are dominated by overnight sentiment but lack intraday follow-through and volume confirmation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.426924",
      "updated_at": "2026-01-17T02:26:06.426931"
    },
    "b288c17cf78e5e8a": {
      "factor_id": "b288c17cf78e5e8a",
      "factor_name": "Volatility_Exhaustion_Reversal_5D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * (($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * (($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean reversion opportunities by detecting 'volatility exhaustion'. It calculates the ratio of the current daily range to its 20-day average and scales it by the relative position of the close within that range. High values indicate the price has stretched to an extreme and closed near that extreme, suggesting a high probability of a 5-day reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.934535",
      "updated_at": "2026-01-17T02:29:19.934542"
    },
    "f31f3f1925246a8d": {
      "factor_id": "f31f3f1925246a8d",
      "factor_name": "Intraday_Skew_Exhaustion_Factor",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 20)) * SIGN($close - 0.5 * ($high + $low))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 20)) * SIGN($close - 0.5 * ($high + $low))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Skew_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures liquidity exhaustion by measuring the daily range expansion relative to historical volatility, specifically when the close is significantly skewed toward the high or low. It targets short-term mean reversion by identifying emotional overshoots in price action.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.948118",
      "updated_at": "2026-01-17T02:29:19.948124"
    },
    "f181f52bc7dfdd49": {
      "factor_id": "f181f52bc7dfdd49",
      "factor_name": "Range_Stretch_Median_Reversion",
      "factor_expression": "ZSCORE(($high - $low) / (TS_MEDIAN($high - $low, 20) + 1e-8)) * ((2 * $close - ($high + $low)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / (TS_MEDIAN($high - $low, 20) + 1e-8)) * ((2 * $close - ($high + $low)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Range_Stretch_Median_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 'stretch' of the current daily range against the 20-day median range. It combines this with the intraday price location to signal exhaustion. It uses TS_MEDIAN for robustness against outliers in historical volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.961533",
      "updated_at": "2026-01-17T02:29:19.961539"
    },
    "714bd241d9bef45d": {
      "factor_id": "714bd241d9bef45d",
      "factor_name": "VW_Price_Efficiency_Regime_5D",
      "factor_expression": "((DELTA($close, 5) * $volume / (TS_MEAN($volume, 20) + 1e-8)) * (ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8))) * ((TS_STD($close, 5) > TS_STD($close, 20)) && ($volume > 1.5 * TS_MEAN($volume, 20)) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((DELTA($close, 5) * $volume / (TS_MEAN($volume, 20) + 1e-8)) * (ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8))) * ((TS_STD($close, 5) > TS_STD($close, 20)) && ($volume > 1.5 * TS_MEAN($volume, 20)) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Efficiency_Regime_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by combining volume-weighted momentum with price discovery efficiency. It focuses on regimes where short-term volatility (5-day) exceeds long-term volatility (20-day) and volume is significantly higher than its 20-day average. Efficiency is defined as the ratio of absolute displacement to the total price range covered.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.291253",
      "updated_at": "2026-01-17T02:30:45.291261"
    },
    "d330a6dddbc6bd32": {
      "factor_id": "d330a6dddbc6bd32",
      "factor_name": "Efficiency_Adjusted_Force_Index_10D",
      "factor_expression": "RANK(TS_SUM($return * $volume, 10)) * RANK(ABS(DELTA($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) * $volume, 10)) * RANK(ABS(DELTA($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Force_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the regime-shift hypothesis focusing on the 'Force Index' (volume-weighted return) adjusted by price discovery efficiency over a 10-day window. It uses RANK to normalize the interaction between volume surges and directional persistence, identifying institutional accumulation or distribution.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.307816",
      "updated_at": "2026-01-17T02:30:45.307822"
    },
    "29c4edd238c78731": {
      "factor_id": "29c4edd238c78731",
      "factor_name": "Vol_Expansion_Trend_Persistence_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Expansion_Trend_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of a trend during volatility expansion. It calculates the product of the 5-day return and the ratio of displacement to volatility, specifically when the short-term volatility is rising relative to its medium-term benchmark, signaling a potential structural regime shift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.323029",
      "updated_at": "2026-01-17T02:30:45.323034"
    },
    "8a6eb155a91d9ffb": {
      "factor_id": "8a6eb155a91d9ffb",
      "factor_name": "Stealth_Accumulation_Decoupling_20D",
      "factor_expression": "-1 * RANK(TS_CORR($high - $low, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_CORR($high - $low, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Decoupling_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the decoupling between the daily price range (high - low) and daily trading volume over a 20-day period. A lower correlation suggests that price movements are occurring without significant liquidity shocks, indicating informed institutional accumulation with minimal market impact.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.582971",
      "updated_at": "2026-01-17T02:33:31.582977"
    },
    "2288ed9bab90400e": {
      "factor_id": "2288ed9bab90400e",
      "factor_name": "Informed_Range_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Informed_Range_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'stealth' price discovery by calculating the ratio of the price range to the volume, smoothed over 15 days. High values indicate high range efficiency where price moves significantly on relatively low volume, suggesting institutional positioning rather than retail-driven volume spikes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.600892",
      "updated_at": "2026-01-17T02:33:31.600899"
    },
    "973adedc0202ee0d": {
      "factor_id": "973adedc0202ee0d",
      "factor_name": "Stealth_Drift_Persistence_10D",
      "factor_expression": "RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price volatility and volume intensity. It uses the difference between the rank of the price range and the rank of volume over a 10-day window. Positive values indicate price volatility is higher than volume intensity, a hallmark of stealth accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.616048",
      "updated_at": "2026-01-17T02:33:31.616054"
    },
    "ea9e5ed667e7ed94": {
      "factor_id": "ea9e5ed667e7ed94",
      "factor_name": "Quiet_Accumulation_Gap_Factor_20D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * RANK(1 / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * RANK(INV(TS_STD(($close / DELAY($close, 1)) - 1, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Gap_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional accumulation by identifying overnight price gaps that occur during low-volatility consolidation phases. It multiplies the overnight return by the volume surprise (current volume relative to its 20-day mean) and applies a penalty to stocks with high historical volatility to isolate 'quiet' zones.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.490809",
      "updated_at": "2026-01-17T02:34:54.490816"
    },
    "889acbc204290131": {
      "factor_id": "889acbc204290131",
      "factor_name": "Low_Vol_Volume_Surprise_Momentum",
      "factor_expression": "(RANK(TS_STD($return, 20)) < 0.3) ? ((($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_STD(TS_PCTCHANGE($close, 1), 20)) < 0.3) ? ((($open / DELAY($close, 1)) - 1) * ($volume / TS_MEAN($volume, 20))) : 0\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Volume_Surprise_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price movements during low-volatility regimes. It calculates the product of the overnight gap and the volume ratio, specifically filtering for stocks in the bottom 30% of 20-day volatility to target institutional 'quiet' accumulation before a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.504977",
      "updated_at": "2026-01-17T02:34:54.504983"
    },
    "11aa0f7100914260": {
      "factor_id": "11aa0f7100914260",
      "factor_name": "Institutional_Gap_Signal_ZScore",
      "factor_expression": "TS_ZSCORE((($open / DELAY($close, 1)) - 1) * $volume, 20) * (1 - RANK(TS_STD($return, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((($open / DELAY($close, 1)) - 1) * $volume, 20) * (1 - RANK(TS_STD(($close / DELAY($close, 1) - 1), 20)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Signal_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the quiet accumulation hypothesis. It measures the Z-score of the volume-weighted overnight gap, scaled by the inverse of volatility rank to prioritize signals originating from stable price bases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.518903",
      "updated_at": "2026-01-17T02:34:54.518909"
    },
    "2490e493b70901a7": {
      "factor_id": "2490e493b70901a7",
      "factor_name": "Liquidity_Depletion_Reversal_3D",
      "factor_expression": "-1 * RANK(TS_MEAN($volume, 3) / (TS_MEDIAN($volume, 20) + 1e-8) + TS_MEAN($high - $low, 3) / (TS_MEAN($close, 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($volume, 3) / (TS_MEDIAN($volume, 20) + 1e-8) + TS_MEAN($high - $low, 3) / (TS_MEAN($close, 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Depletion_Reversal_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with extreme volume depletion and price range compression over a 3-day window relative to their 20-day baseline. According to the Liquidity Provision Reversal hypothesis, such 'quiet' states represent a liquidity vacuum that precedes a mean-reversion when market makers return.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.318051",
      "updated_at": "2026-01-17T02:37:14.318057"
    },
    "eb86cf43cd13021e": {
      "factor_id": "eb86cf43cd13021e",
      "factor_name": "Price_Efficiency_Vacuum_Factor",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 3) / (TS_SUM($volume, 3) + 1e-8)) * ZSCORE(TS_SUM($volume, 3) / (TS_SUM($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 3) / (TS_SUM($volume, 3) + 1e-8)) * ZSCORE(TS_SUM($volume, 3) / (TS_SUM($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Vacuum_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures 'price efficiency' during low-volume periods. It targets stocks where the price movement per unit of volume is minimal over a short window (3 days) compared to the long-term average, indicating a lack of conviction and a high probability of reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.332468",
      "updated_at": "2026-01-17T02:37:14.332474"
    },
    "9ad4ed63e0efd34f": {
      "factor_id": "9ad4ed63e0efd34f",
      "factor_name": "Quiet_Regime_Mean_Reversion",
      "factor_expression": "-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD($return, 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 3))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines volume depletion (3-day mean vs 20-day mean) with price stability (3-day volatility). Low values in both suggest a 'quiet' regime susceptible to liquidity-driven reversals. The factor is negated to reflect the expected mean-reversion return.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.346788",
      "updated_at": "2026-01-17T02:37:14.346794"
    },
    "a5ce5e3f851fd4d1": {
      "factor_id": "a5ce5e3f851fd4d1",
      "factor_name": "Overnight_Conviction_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Conviction_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of absolute overnight returns to the intraday price range, averaged over 5 days. It identifies high-conviction institutional positioning by highlighting periods where price movement occurs primarily during non-trading hours relative to intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.221118",
      "updated_at": "2026-01-17T02:37:58.221125"
    },
    "82ece24226c9cbeb": {
      "factor_id": "82ece24226c9cbeb",
      "factor_name": "Low_Noise_Institutional_Gap_Factor",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_STD($close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_STD($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Low_Noise_Institutional_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the overnight return magnitude with a penalty for intraday price volatility. It scales the 5-day average overnight return by the inverse of the 5-day price standard deviation, rewarding stable, low-noise price action that suggests institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.235425",
      "updated_at": "2026-01-17T02:37:58.235431"
    },
    "3d503a5431bacb0d": {
      "factor_id": "3d503a5431bacb0d",
      "factor_name": "Ranked_Conviction_Persistence_Index",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($return, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Persistence_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction index. It compares the relative strength of the overnight-to-range ratio against the relative stability of the stock, identifying assets with the highest institutional signal-to-noise ratio.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.251412",
      "updated_at": "2026-01-17T02:37:58.251418"
    },
    "e55f48a58d8cef9e": {
      "factor_id": "e55f48a58d8cef9e",
      "factor_name": "Inst_Liquidity_Exhaustion_5D",
      "factor_expression": "TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Inst_Liquidity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional liquidity exhaustion by measuring the divergence between the closing price and the daily average price (HLC/3), normalized by the daily range. A high positive value suggests a late-day markup without broad support, predicting a potential reversal. The value is smoothed over 5 days to capture persistent imbalances.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.369398",
      "updated_at": "2026-01-17T02:40:14.369405"
    },
    "99189547d9fa4c68": {
      "factor_id": "99189547d9fa4c68",
      "factor_name": "Relative_Closing_Imbalance_Rank_10D",
      "factor_expression": "TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Closing_Imbalance_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the relative position of the close within the daily range compared to the average price. By applying a cross-sectional rank to the exhaustion signal and smoothing it, it identifies stocks with the most extreme liquidity traps relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.384880",
      "updated_at": "2026-01-17T02:40:14.384886"
    },
    "066c4742ee84bfb7": {
      "factor_id": "066c4742ee84bfb7",
      "factor_name": "Liquidity_Trap_ZScore_20D",
      "factor_expression": "TS_ZSCORE(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Trap_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the statistical significance of the price-discovery divergence by calculating the time-series Z-score of the daily close-to-average-price distance. High Z-scores indicate abnormal late-session price behavior that is likely to mean-revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.399185",
      "updated_at": "2026-01-17T02:40:14.399192"
    },
    "fffb5eb9485c4f77": {
      "factor_id": "fffb5eb9485c4f77",
      "factor_name": "Amihud_Reversion_5D",
      "factor_expression": "TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (1 - $close / $open)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (1 - $close / ($open + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion candidates by multiplying the 5-day average Amihud illiquidity ratio (absolute return divided by volume) with the negative intraday return. High illiquidity during a price move suggests a transient shock likely to reverse.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.179048",
      "updated_at": "2026-01-17T02:41:08.179055"
    },
    "5ae2eca4ab56957e": {
      "factor_id": "5ae2eca4ab56957e",
      "factor_name": "Illiquidity_Shock_ZScore_Reversal",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($volume + 1e-8), 20) * ($open - $close) / ($open + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 20) * ($open - $close) / ($open + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Illiquidity_Shock_ZScore_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between normalized illiquidity shocks and intraday price direction. It uses the Z-score of the Amihud ratio over 20 days to identify extreme liquidity-driven moves and bets on the reversal of the intraday trend.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.194184",
      "updated_at": "2026-01-17T02:41:08.194191"
    },
    "bbae81fc535fa2c3": {
      "factor_id": "bbae81fc535fa2c3",
      "factor_name": "Ranked_Amihud_Intraday_Reversal",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 10)) * SIGN($open - $close)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(($close - $open) / $open) / ($volume + 1e-8), 10)) * SIGN($open - $close)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Amihud_Intraday_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the illiquidity-reversion hypothesis. It ranks the 10-day average price impact per unit volume and multiplies it by the negative sign of the intraday return to target stocks where illiquid moves are most likely to exhaust.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.209027",
      "updated_at": "2026-01-17T02:41:08.209034"
    },
    "1aa53be0817ae109": {
      "factor_id": "1aa53be0817ae109",
      "factor_name": "IPVE_Fragility_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"IPVE_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the Intraday Price-Volume Efficiency (IPVE) by taking the ratio of the daily price range to the trading volume. It identifies 'fragile' price movements where high volatility occurs on low liquidity. A 5-day simple moving average is applied to smooth idiosyncratic noise, and the result is cross-sectionally ranked to identify stocks prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.001869",
      "updated_at": "2026-01-17T02:43:26.001876"
    },
    "4a8501762c4a0bae": {
      "factor_id": "4a8501762c4a0bae",
      "factor_name": "Normalized_IPVE_ZScore_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Normalized_IPVE_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "An alternative measure of price-volume efficiency that normalizes the price range by the 10-day average volume to isolate volume shocks. It uses a Z-score to identify extreme price-impact days relative to the stock's recent history, highlighting liquidity exhaustion points before mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.016885",
      "updated_at": "2026-01-17T02:43:26.016891"
    },
    "93f99fe635358d30": {
      "factor_id": "93f99fe635358d30",
      "factor_name": "Relative_Range_Volume_Efficiency_20D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement relative to volume by comparing the current range-to-volume ratio against its 20-day median. It targets stocks where the current price movement is significantly more 'expensive' in terms of liquidity than usual, indicating a high probability of a fragile trend.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.031536",
      "updated_at": "2026-01-17T02:43:26.031542"
    },
    "893f367c987d653e": {
      "factor_id": "893f367c987d653e",
      "factor_name": "Gap_Stability_Ratio_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS($open / DELAY($close, 1) - 1) / (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Stability_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of the overnight gap to the intraday price range. A high value indicates that the price movement occurred primarily during non-trading hours and was maintained throughout the day with little intraday volatility, suggesting institutional conviction. It is normalized by the 10-day average intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.660769",
      "updated_at": "2026-01-17T02:46:39.660776"
    },
    "753627a010696eb7": {
      "factor_id": "753627a010696eb7",
      "factor_name": "Institutional_Gap_Persistence",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * (1 - ($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * (1 - ($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies days where the overnight gap is significant relative to historical intraday volatility, and the intraday range remains compressed. It uses a conditional logic to highlight 'gap and hold' patterns where the gap is at least 1.5 times the 5-day average intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.677132",
      "updated_at": "2026-01-17T02:46:39.677139"
    },
    "372da11902cb84e1": {
      "factor_id": "372da11902cb84e1",
      "factor_name": "Normalized_Overnight_Dominance",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Overnight_Dominance\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the dominance of the overnight return relative to the total daily range. It is cross-sectionally ranked to identify assets where the 'information gap' is the primary driver of the price trend compared to intraday noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.694076",
      "updated_at": "2026-01-17T02:46:39.694082"
    },
    "79ca87965d5ce3c0": {
      "factor_id": "79ca87965d5ce3c0",
      "factor_name": "Amihud_Fragility_5D",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures short-term price fragility using the Amihud Illiquidity ratio (absolute return divided by volume), smoothed over a 5-day window. High values indicate price movements driven by low liquidity, which are expected to mean-revert.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.169842",
      "updated_at": "2026-01-17T02:46:43.169848"
    },
    "db3bb63c885516b0": {
      "factor_id": "db3bb63c885516b0",
      "factor_name": "Relative_Illiquidity_Shock_10D",
      "factor_expression": "ZSCORE((ABS($return) / ($volume + 1e-8)) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8) / TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Illiquidity_Shock_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the intensity of a liquidity shock by comparing the current daily price impact (absolute return/volume) to its 10-day historical average. A high ratio suggests an unsustainable price extension due to liquidity bottlenecks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.186993",
      "updated_at": "2026-01-17T02:46:43.186999"
    },
    "f2b1e3a9b86377a0": {
      "factor_id": "f2b1e3a9b86377a0",
      "factor_name": "Fragility_Momentum_Divergence_10D",
      "factor_expression": "RANK(TS_SUM($return, 10) * TS_RANK(ABS($return) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1), 10) * TS_RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Fragility_Momentum_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies cases where price trends are 'fragile' by multiplying the 10-day return by the time-series rank of the Amihud illiquidity ratio. High fragility during a price move signals a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.202044",
      "updated_at": "2026-01-17T02:46:43.202051"
    },
    "831b0bb79204fd79": {
      "factor_id": "831b0bb79204fd79",
      "factor_name": "Intraday_Efficiency_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Efficiency_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement over a 5-day window. It calculates the ratio of the absolute net intraday change to the total intraday range. A high ratio suggests that price movement is driven by persistent institutional flow rather than volatile noise, indicating a stronger likelihood of trend continuation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.532447",
      "updated_at": "2026-01-17T03:54:30.979215"
    },
    "8afb1882b81bac5e": {
      "factor_id": "8afb1882b81bac5e",
      "factor_name": "Efficiency_Adjusted_Momentum_10D",
      "factor_expression": "TS_MEAN(RANK(SIGN($close - $open) * (ABS($close - $open) / ($high - $low + 1e-8))), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK(SIGN($close - $open) * (ABS($close - $open) / ($high - $low + 1e-8))), 10)\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the intraday price efficiency with the direction of the price move. By multiplying the sign of the daily return by the efficiency ratio, it identifies days where price moved decisively in one direction. It is then cross-sectionally ranked and smoothed over 10 days to identify stocks with consistent institutional accumulation or distribution.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price Range Efficiency factor, defined as the ratio of the daily price displacement (Close - Open) to the total daily price range (High - Low), predicts short-term trend persistence by distinguishing between directed institutional flows and high-entropy retail noise.\n                Concise Observation: Daily volume volatility metrics capture liquidity shocks but ignore the 'shape' of price action; often, stocks with similar daily returns exhibit vastly different intraday volatility profiles (efficiency vs. noise).\n                Concise Justification: A high displacement-to-range ratio indicates strong conviction and low resistance in price movement, suggesting institutional accumulation, whereas a low ratio indicates high-frequency 'churn' and lack of directional consensus.\n                Concise Knowledge: If the price displacement is a large fraction of the total daily range, the market is processing information efficiently in a single direction; when the range is large but the net displacement is small, the price path is inefficient and prone to reversal.\n                concise Specification: The factor is calculated as (ABS($close - $open) / ($high - $low + 1e-8)) smoothed over a 5-day window to capture persistent intraday efficiency trends, expected to correlate positively with next-day returns.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "c682652a1743",
      "parent_trajectory_ids": [
        "dcffecfc2bac"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050534531140359,
        "ICIR": 0.0346235292495759,
        "RankIC": 0.0221182072026201,
        "RankICIR": 0.1519411893480342,
        "annualized_return": 0.0355549437763706,
        "information_ratio": 0.525952478763076,
        "max_drawdown": -0.1038771064595254
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.558100",
      "updated_at": "2026-01-17T02:49:18.558108"
    },
    "2a583ee1ec243c76": {
      "factor_id": "2a583ee1ec243c76",
      "factor_name": "Relative_Efficiency_Volatility_ZScore",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Relative_Efficiency_Volatility_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the current intraday efficiency relative to its own history using a Z-score. It identifies periods where the price action becomes significantly more 'efficient' (directional) than usual, which often precedes a breakout. A high Z-score suggests a sudden shift from retail noise to institutional conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price Range Efficiency factor, defined as the ratio of the daily price displacement (Close - Open) to the total daily price range (High - Low), predicts short-term trend persistence by distinguishing between directed institutional flows and high-entropy retail noise.\n                Concise Observation: Daily volume volatility metrics capture liquidity shocks but ignore the 'shape' of price action; often, stocks with similar daily returns exhibit vastly different intraday volatility profiles (efficiency vs. noise).\n                Concise Justification: A high displacement-to-range ratio indicates strong conviction and low resistance in price movement, suggesting institutional accumulation, whereas a low ratio indicates high-frequency 'churn' and lack of directional consensus.\n                Concise Knowledge: If the price displacement is a large fraction of the total daily range, the market is processing information efficiently in a single direction; when the range is large but the net displacement is small, the price path is inefficient and prone to reversal.\n                concise Specification: The factor is calculated as (ABS($close - $open) / ($high - $low + 1e-8)) smoothed over a 5-day window to capture persistent intraday efficiency trends, expected to correlate positively with next-day returns.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "c682652a1743",
      "parent_trajectory_ids": [
        "dcffecfc2bac"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050534531140359,
        "ICIR": 0.0346235292495759,
        "RankIC": 0.0221182072026201,
        "RankICIR": 0.1519411893480342,
        "annualized_return": 0.0355549437763706,
        "information_ratio": 0.525952478763076,
        "max_drawdown": -0.1038771064595254
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.581565",
      "updated_at": "2026-01-17T02:49:18.581571"
    },
    "7edeac1299d5ec7a": {
      "factor_id": "7edeac1299d5ec7a",
      "factor_name": "Price_Efficiency_Ratio_10D",
      "factor_expression": "ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates Kaufman's Efficiency Ratio over a 10-day window. It measures the net price change relative to the total path traveled (sum of absolute daily returns). Low values indicate high noise and potential for mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.094020",
      "updated_at": "2026-01-17T02:52:25.094027"
    },
    "6f61aa0cb607231a": {
      "factor_id": "6f61aa0cb607231a",
      "factor_name": "Efficiency_Adjusted_Volatility_Rank",
      "factor_expression": "RANK(TS_SUM(ABS(DELTA($close, 1)), 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS(DELTA($close, 1)), 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Volatility_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the Efficiency Ratio with cross-sectional ranking to identify assets that are moving significantly but with high 'noise' (low efficiency). It ranks the inverse of the 10-day Efficiency Ratio to highlight mean-reversion candidates.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.110271",
      "updated_at": "2026-01-17T02:52:25.110276"
    },
    "a68abefcaf887ab0": {
      "factor_id": "a68abefcaf887ab0",
      "factor_name": "Noise_Filtered_Return_Reversion",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Noise_Filtered_Return_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that identifies stocks with high daily variance (high-low range) but low net directional movement over 10 days. It uses the ratio of 10-day range sum to net displacement, standardized by Z-score.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.127010",
      "updated_at": "2026-01-17T02:52:25.127016"
    },
    "525b9fd9ff076a5a": {
      "factor_id": "525b9fd9ff076a5a",
      "factor_name": "Liquidity_Exhaustion_Reversion_20D",
      "factor_expression": "(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 20-day abnormal turnover ratio. A high positive value indicates a 'blow-off top' where prices are pushed significantly above the average intraday cost on high volume, suggesting liquidity exhaustion and a likely downward reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.768309",
      "updated_at": "2026-01-17T03:37:08.768316"
    },
    "78b1d1c3e8ceffa4": {
      "factor_id": "78b1d1c3e8ceffa4",
      "factor_name": "Ranked_Intraday_Exhaustion_10D",
      "factor_expression": "RANK(($close - ($high + $low) / 2) / (($high + $low) / 2 + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - ($high + $low) / 2) / (($high + $low) / 2 + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Intraday_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the liquidity exhaustion hypothesis. It measures the divergence of the close from the intraday mid-point, scaled by the relative volume intensity over 10 days. By using RANK, it focuses on the stocks with the most extreme exhaustion signals relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.787163",
      "updated_at": "2026-01-17T03:37:08.787169"
    },
    "7147211d46e7ca79": {
      "factor_id": "7147211d46e7ca79",
      "factor_name": "ZScored_Liquidity_Divergence_15D",
      "factor_expression": "TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Liquidity_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the price-VWAP deviation and the Z-score of volume to identify statistical outliers in liquidity consumption. It captures periods where the price is at a multi-standard deviation distance from the daily average price on significantly higher-than-normal volume.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.805539",
      "updated_at": "2026-01-17T03:37:08.805545"
    },
    "5223064962986e06": {
      "factor_id": "5223064962986e06",
      "factor_name": "Micro_Stability_Absorption_3D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 3)) * -1",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 3)) * -1\" # Your output factor expression will be filled in here\n    name = \"Micro_Stability_Absorption_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional price absorption by measuring the 3-day average of the ratio between intraday price range and volume. A lower ratio indicates high volume with low price volatility, suggesting hidden liquidity is clearing orders without slippage. The factor is cross-sectionally ranked to identify stocks with the highest micro-structure stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.416884",
      "updated_at": "2026-01-17T03:39:34.416891"
    },
    "c3c1d58825d6e03f": {
      "factor_id": "c3c1d58825d6e03f",
      "factor_name": "Absorption_Breakout_Proximity_3D",
      "factor_expression": "($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Absorption_Breakout_Proximity_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the micro-structure stability (low range-to-volume ratio) with the proximity of the current price to the 3-day high. It targets breakout continuation by identifying stocks where absorption is occurring near resistance levels. The stability component is inverted so that higher values represent more stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.435984",
      "updated_at": "2026-01-17T03:39:34.435990"
    },
    "643d95ac0e36ae82": {
      "factor_id": "643d95ac0e36ae82",
      "factor_name": "Relative_Absorption_Intensity_5D",
      "factor_expression": "1 - TS_RANK(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"1 - TS_RANK(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Relative_Absorption_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of price absorption by comparing the current range-to-volume ratio to its 5-day historical distribution using TS_RANK. A low time-series rank of the ratio indicates a significant increase in micro-structure stability relative to the stock's own recent history, signaling institutional clearing.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.454766",
      "updated_at": "2026-01-17T03:39:34.454771"
    },
    "464853529eb9b105": {
      "factor_id": "464853529eb9b105",
      "factor_name": "Delta_RESI5_Convexity",
      "factor_expression": "DELTA($close - TS_MEAN($close, 5), 5) / (TS_STD($close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA($close - TS_MEAN($close, 5), 5) / (TS_STD($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Delta_RESI5_Convexity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day rate of change in the price residual (current price minus its 5-day mean), normalized by the 5-day price volatility. A sharp increase in this residual velocity indicates price acceleration away from the mean, suggesting trend exhaustion and potential mean-reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.105605",
      "updated_at": "2026-01-17T03:43:00.105611"
    },
    "ac2e9b90c0052852": {
      "factor_id": "ac2e9b90c0052852",
      "factor_name": "ZScore_Residual_Velocity_5D",
      "factor_expression": "RANK(DELTA(TS_ZSCORE($close, 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_ZSCORE($close, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Residual_Velocity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the residual convexity hypothesis that uses the 5-day change in the Z-scored price deviation. By calculating the change in how many standard deviations the price is from its mean over a 5-day window, it identifies accelerating speculative climaxes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.125338",
      "updated_at": "2026-01-17T03:43:00.125344"
    },
    "ada1d67af3c47fe6": {
      "factor_id": "ada1d67af3c47fe6",
      "factor_name": "Normalized_Exhaustion_Index_5D",
      "factor_expression": "(($close - TS_MEAN($close, 5)) - DELAY($close - TS_MEAN($close, 5), 5)) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - TS_MEAN($close, 5)) - DELAY($close - TS_MEAN($close, 5), 5)) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the second-order momentum of price residuals. It calculates the difference between the current residual and its 5-day lag, scaled by the 20-day volatility to provide a more stable normalization against long-term regime changes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.144818",
      "updated_at": "2026-01-17T03:43:00.144824"
    },
    "be6b50ad31dd469e": {
      "factor_id": "be6b50ad31dd469e",
      "factor_name": "CSVD_Volatility_Convexity_Ratio",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / TS_MEAN($high - $low, 20)) / STD($close / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"CSVD_Volatility_Convexity_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of short-term (5-day) price range to medium-term (20-day) price range, normalized by the cross-sectional standard deviation of returns. It identifies stocks where idiosyncratic price-range expansion or contraction decouples from market-wide return dispersion, signaling potential alpha from stock-specific re-pricing.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.169035",
      "updated_at": "2026-01-17T03:46:21.169042"
    },
    "016dc251bf05446e": {
      "factor_id": "016dc251bf05446e",
      "factor_name": "Idiosyncratic_Range_Decoupling_Rank",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD(TS_PCTCHANGE($close, 1)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Range_Decoupling_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Volatility Convexity' of a stock relative to the cross-sectional market dispersion. It uses RANK to normalize the ratio of current range volatility against its historical mean, then scales it by the inverse of market-wide return dispersion to isolate assets undergoing unique fundamental adjustments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.188725",
      "updated_at": "2026-01-17T03:46:21.188731"
    },
    "6cf31eb6d71efdc1": {
      "factor_id": "6cf31eb6d71efdc1",
      "factor_name": "ZScore_Range_Dispersion_Alpha",
      "factor_expression": "ZSCORE(TS_MEAN($high - $low, 5) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($high - $low, 5) / TS_MEAN($high - $low, 20)) / (STD(TS_PCTCHANGE($close, 1)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Range_Dispersion_Alpha\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the CSVD hypothesis. It calculates the Z-score of the 5-day range relative to its 20-day baseline and divides it by the cross-sectional volatility of returns. This highlights stocks with extreme idiosyncratic volatility shifts relative to the broader market noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.207951",
      "updated_at": "2026-01-17T03:46:21.207957"
    },
    "9724358e7953d565": {
      "factor_id": "9724358e7953d565",
      "factor_name": "Overnight_Sentiment_Volatility_Ratio_20D",
      "factor_expression": "($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_STD(($close / (DELAY($close, 1) + 1e-8)) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by measuring the overnight price gap relative to historical volatility. A large gap compared to the 20-day standard deviation of returns suggests a potential emotional overreaction that is likely to revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.407397",
      "updated_at": "2026-01-17T03:49:20.407403"
    },
    "181ee1d93dac7aac": {
      "factor_id": "181ee1d93dac7aac",
      "factor_name": "Hollow_Gap_Liquidity_Divergence_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Gap_Liquidity_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'hollow' gaps where the overnight price jump is unsupported by volume trends. It scales the overnight return by the ratio of current volume to its 20-day average, identifying gaps that lack structural capital commitment.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.427009",
      "updated_at": "2026-01-17T03:49:20.427015"
    },
    "22af8b8c6538acb9": {
      "factor_id": "22af8b8c6538acb9",
      "factor_name": "Ranked_Overnight_Mean_Reversion_Signal",
      "factor_expression": "RANK(($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_STD(($close / (DELAY($close, 1) + 1e-8)) - 1, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Overnight_Mean_Reversion_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the overnight sentiment divergence. It measures the intensity of the overnight gap relative to the 20-day return volatility, normalized across the universe to identify the most extreme sentiment shifts.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.446277",
      "updated_at": "2026-01-17T03:49:20.446283"
    },
    "1b1fa0567b320f2c": {
      "factor_id": "1b1fa0567b320f2c",
      "factor_name": "Overnight_Sentiment_Persistence_5D",
      "factor_expression": "TS_MEAN(($open / DELAY($close, 1) - 1) / (TS_STD($close / $open - 1, 5) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open / DELAY($close, 1) - 1) / (TS_STD($close / $open - 1, 5) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional sentiment by calculating the 5-day moving average of overnight returns normalized by intraday volatility. High values suggest persistent institutional accumulation during non-trading hours relative to noisy intraday price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.932942",
      "updated_at": "2026-01-17T03:49:44.932949"
    },
    "27d0dacce74686ae": {
      "factor_id": "27d0dacce74686ae",
      "factor_name": "Z_Overnight_Sentiment_Efficiency",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Z_Overnight_Sentiment_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the overnight sentiment factor, measuring the efficiency of overnight price discovery. It uses the ratio of overnight return to the 10-day intraday range to identify stocks where news is being priced in cleanly at the open.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.953263",
      "updated_at": "2026-01-17T03:49:44.953269"
    },
    "ed7666f723507327": {
      "factor_id": "ed7666f723507327",
      "factor_name": "Overnight_Relative_Strength_Persistence",
      "factor_expression": "TS_SUM($open / DELAY($close, 1) - 1, 10) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM(($open / DELAY($close, 1) - 1), 10) / (TS_STD(($close / DELAY($close, 1) - 1), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Relative_Strength_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of overnight returns relative to the total daily return volatility. By focusing on the 10-day sum of overnight gaps divided by the 10-day standard deviation of daily returns, it highlights stocks with consistent institutional directionality.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.972983",
      "updated_at": "2026-01-17T03:49:44.972989"
    },
    "dbfd1381630af6e3": {
      "factor_id": "dbfd1381630af6e3",
      "factor_name": "Liquidity_Exhaustion_Reversal_5D",
      "factor_expression": "(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by measuring the relative closing position within the daily range, weighted by volume intensity relative to 5-day price volatility. A high value indicates the price closed near the high despite high volume, suggesting exhaustion of buying pressure and potential mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.284646",
      "updated_at": "2026-01-17T03:51:37.284654"
    },
    "b1eb4e19eecaf117": {
      "factor_id": "b1eb4e19eecaf117",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "ZSCORE(($close - $low) / ($high - $low + 1e-8)) * ZSCORE($volume / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - $low) / ($high - $low + 1e-8)) * ZSCORE($volume / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the liquidity exhaustion hypothesis. It ranks the intensity of volume-weighted price overextension. By using Z-scored volume-to-volatility ratios, it identifies stocks where liquidity consumption is statistically extreme relative to the cross-section, signaling a higher probability of a 1-3 day reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.305370",
      "updated_at": "2026-01-17T03:51:37.305377"
    },
    "69b9b972e8d4304f": {
      "factor_id": "69b9b972e8d4304f",
      "factor_name": "Smoothed_Liquidity_Pressure_3D",
      "factor_expression": "SMA((($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8)), 3, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SMA((($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8)), 3, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Liquidity_Pressure_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistent state of liquidity exhaustion by applying a 3-day simple moving average to the exhaustion ratio. It filters out single-day noise to identify sustained periods where prices are failing to hold extremes despite high volume-to-volatility ratios.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.325947",
      "updated_at": "2026-01-17T03:51:37.325954"
    },
    "1121ca9a99cc49c9": {
      "factor_id": "1121ca9a99cc49c9",
      "factor_name": "LAE_Liquidity_Fragility_10D",
      "factor_expression": "RANK((($high - $low) / $close) / (TS_STD($volume, 10) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / $close) / (TS_STD($volume, 10) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LAE_Liquidity_Fragility_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity Absorption Efficiency (LAE) factor identifies structural exhaustion by measuring the ratio of the volume-weighted price range to volume volatility. High values indicate that price movements require extreme volume consistency, while a spike in volume volatility relative to range suggests a liquidity vacuum and potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.617057",
      "updated_at": "2026-01-17T03:52:20.617064"
    },
    "1f99d421bb121b0f": {
      "factor_id": "1f99d421bb121b0f",
      "factor_name": "Liquidity_Elasticity_Index_10D",
      "factor_expression": "ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Elasticity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the elasticity of liquidity by comparing the price range to the standardized volume turnover. It targets regimes where price trends become fragile due to surging execution costs (proxied by volume volatility), signaling an impending mean-reversion event.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.637184",
      "updated_at": "2026-01-17T03:52:20.637190"
    },
    "56c76c86b6cae379": {
      "factor_id": "56c76c86b6cae379",
      "factor_name": "Volume_Price_Coupling_Exhaustion",
      "factor_expression": "TS_MEAN(($high - $low) / $close, 10) / (TS_STD($volume / (MEDIAN($volume) + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / $close, 10) / (TS_STD($volume / (MEDIAN($volume) + 1e-8), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Coupling_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'Liquidity Fragility' by identifying when the volume required to move the price a single unit becomes unstable. It uses the ratio of the 10-day average price range to the 10-day volume volatility, normalized by cross-sectional median volume to ensure comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.656874",
      "updated_at": "2026-01-17T03:52:20.656880"
    },
    "91a4c2e2fc281a70": {
      "factor_id": "91a4c2e2fc281a70",
      "factor_name": "IVCS_Exhaustion_5D",
      "factor_expression": "TS_MEAN(($close - ($high + $low) / 2) * $volume / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($high + $low) / 2) * $volume / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"IVCS_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the Intraday Volume Concentration Skew (IVCS) over a 5-day window. It calculates the distance of the closing price from the daily midpoint, weighted by volume relative to the daily range. High values indicate volume concentration at price extremes without significant range expansion, signaling potential liquidity exhaustion and mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.362465",
      "updated_at": "2026-01-17T03:53:53.362472"
    },
    "243c743e2fe55295": {
      "factor_id": "243c743e2fe55295",
      "factor_name": "Relative_Extreme_Volume_Skew_10D",
      "factor_expression": "RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Extreme_Volume_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 10-day average of volume-weighted price skewness. It normalizes the intraday position of the close relative to the high-low range and scales it by volume. By applying a cross-sectional RANK, it identifies stocks where volume is most heavily concentrated at price extremes relative to the peer group, suggesting trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.382751",
      "updated_at": "2026-01-17T03:53:53.382758"
    },
    "27a0fd17ace83e7b": {
      "factor_id": "27a0fd17ace83e7b",
      "factor_name": "Volume_Price_Divergence_ZScore_5D",
      "factor_expression": "TS_ZSCORE(($close - $open) / ($high - $low + 1e-8) * $volume, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - $open) / ($high - $low + 1e-8) * $volume, 5)\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Divergence_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies exhaustion by measuring the time-series Z-score of the volume-weighted price displacement. A high Z-score indicates that the current day's volume concentration at a price extreme is statistically significant compared to the last 5 days, increasing the probability of a reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.402782",
      "updated_at": "2026-01-17T03:53:53.402788"
    },
    "f2e8b0bf5cbd2fa2": {
      "factor_id": "f2e8b0bf5cbd2fa2",
      "factor_name": "Intraday_Efficiency_Ratio_20D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Efficiency_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures long-term institutional positioning by measuring the average intraday efficiency over a 20-day window. It identifies stocks where price appreciation is achieved with low path-volatility relative to the daily range, filtering out high-frequency noise and retail-driven shocks.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.001994",
      "updated_at": "2026-01-17T03:54:31.002003"
    },
    "b1a1d0ebf13c8116": {
      "factor_id": "b1a1d0ebf13c8116",
      "factor_name": "ZScore_IER_Trend_10D",
      "factor_expression": "ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"ZScore_IER_Trend_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the Intraday Efficiency Ratio (IER) cross-sectionally to identify stocks with the most efficient price trends relative to the market. It uses a 10-day moving average of the ratio to ensure stability and then applies a Z-score for cross-sectional comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.038363",
      "updated_at": "2026-01-17T03:54:31.038371"
    },
    "b1435518c0e34cff": {
      "factor_id": "b1435518c0e34cff",
      "factor_name": "Liquidity_Exhaustion_Ratio_1D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price exhaustion by measuring the ratio of the daily price range to the trading volume, normalized by the relative position of the close. High values indicate 'thin' price moves where price discovery occurs on low volume intensity, signaling a likely mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.927814",
      "updated_at": "2026-01-17T03:57:08.927821"
    },
    "65d79c435508c9e4": {
      "factor_id": "65d79c435508c9e4",
      "factor_name": "Relative_Volume_Intensity_Reversal_5D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Intensity_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the exhaustion of momentum by comparing the current day's price range per unit of volume against its 5-day historical average. It highlights days where price moves are disproportionately large relative to the liquidity provided, suggesting a structural void.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.948630",
      "updated_at": "2026-01-17T03:57:08.948636"
    },
    "e6aa23f628500dca": {
      "factor_id": "e6aa23f628500dca",
      "factor_name": "Extreme_Price_Liquidity_Trap",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Extreme_Price_Liquidity_Trap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies liquidity traps by detecting daily price extremes (high or low) that occur on significantly lower volume than the recent average. It uses the inverse of volume intensity to signal that the trend is unsustainable.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.968980",
      "updated_at": "2026-01-17T03:57:08.968986"
    },
    "95b87a37f6256346": {
      "factor_id": "95b87a37f6256346",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price-volume divergence by calculating the ratio of the 5-day price change to the 5-day average volume-weighted price velocity. A high ratio indicates that price is moving significantly on relatively low volume intensity, suggesting a liquidity vacuum prone to mean-reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.518658",
      "updated_at": "2026-01-17T03:57:26.518666"
    },
    "a1ce18ab8bc5af65": {
      "factor_id": "a1ce18ab8bc5af65",
      "factor_name": "Thin_Market_Reversal_Signal",
      "factor_expression": "RANK(ABS($return)) * (1.0 - TS_RANK($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($close / DELAY($close, 1) - 1)) * (1.0 - TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Thin_Market_Reversal_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures mean-reversion opportunities by identifying days with high return magnitude but significantly low relative volume. It uses the ratio of absolute return to the 20-day volume rank to highlight 'thin' price moves.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.541106",
      "updated_at": "2026-01-17T03:57:26.541113"
    },
    "e67723e910000cb7": {
      "factor_id": "e67723e910000cb7",
      "factor_name": "Price_Volume_Fragility_Index",
      "factor_expression": "(DELTA($close, 5) / ($close + 1e-8)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / DELAY($close, 5)) / (TS_MEAN($volume, 5) / TS_MEAN($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Fragility_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the fragility of the current price trend by comparing the 5-day price momentum against the volume-weighted participation. It identifies exhaustion when price momentum is high but volume-weighted intensity is declining relative to its 20-day average.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.563108",
      "updated_at": "2026-01-17T03:57:26.563114"
    },
    "ca9b0af6a43479c3": {
      "factor_id": "ca9b0af6a43479c3",
      "factor_name": "Gap_Diffusion_Lag_Factor_5D",
      "factor_expression": "TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Gap_Diffusion_Lag_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Lag' by measuring the interaction between the average overnight gap and volume volatility. It identifies stocks where price discovery is delayed, specifically when the intraday return is lower than the overnight impulse, suggesting a potential catch-up effect in high-volatility regimes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.742894",
      "updated_at": "2026-01-17T03:58:17.742900"
    },
    "bb952250c0b75dda": {
      "factor_id": "bb952250c0b75dda",
      "factor_name": "Frictional_Price_Discovery_Rank",
      "factor_expression": "RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD(($close / DELAY($close, 1) - 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Frictional_Price_Discovery_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on the cross-sectional lag by identifying stocks with high idiosyncratic volatility relative to their overnight gap. It uses the ratio of intraday range to the overnight gap, scaled by volume stability, to predict short-term momentum laggards.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.766747",
      "updated_at": "2026-01-17T03:58:17.766753"
    },
    "13a64ce6d82bff1b": {
      "factor_id": "13a64ce6d82bff1b",
      "factor_name": "Institutional_Gap_Laggard_Signal",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Laggard_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the discrepancy between overnight institutional positioning (gap) and retail-driven intraday volatility. It targets stocks where the overnight gap is significant but the intraday movement is muted, suggesting a delayed reaction to market-wide information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.787462",
      "updated_at": "2026-01-17T03:58:17.787468"
    },
    "d31b51f2cd614148": {
      "factor_id": "d31b51f2cd614148",
      "factor_name": "Volume_Vol_Overnight_Gap_Reversion_5D",
      "factor_expression": "-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))\" # Your output factor expression will be filled in here\n    name = \"Volume_Vol_Overnight_Gap_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the mean-reversion effect of overnight price gaps when accompanied by high volume volatility at the previous day's close. High volume volatility suggests dealer inventory stress, making the opening gap likely to revert. The factor is negated to align with a long-short prediction of the reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.080482",
      "updated_at": "2026-01-17T03:59:50.080490"
    },
    "eb89102aa260b117": {
      "factor_id": "eb89102aa260b117",
      "factor_name": "Liquidity_Stress_Gap_Reversal_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Stress_Gap_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity-driven reversion factor that uses the Z-score of volume volatility to identify extreme inventory imbalances. It focuses on the interaction between standardized volume dispersion and the overnight return, predicting that extreme imbalances lead to gap dissipation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.102507",
      "updated_at": "2026-01-17T03:59:50.102513"
    },
    "ccda060b09b8cfce": {
      "factor_id": "ccda060b09b8cfce",
      "factor_name": "Relative_Volume_Dispersion_Gap_Factor",
      "factor_expression": "-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Dispersion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between the overnight gap and the relative intensity of volume volatility. By using TS_RANK of volume volatility, it identifies periods where liquidity-driven distortions are historically high for the specific asset, signaling a higher probability of opening gap mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.123301",
      "updated_at": "2026-01-17T03:59:50.123307"
    },
    "667c8534e6e3442b": {
      "factor_id": "667c8534e6e3442b",
      "factor_name": "Informed_Liquidity_Accumulation_10D",
      "factor_expression": "TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Liquidity_Accumulation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend breakouts by detecting periods of high volume density within narrow price ranges. It calculates the 10-day average of the ratio between volume and the high-low range, scaled by the inverse of price volatility to isolate 'quiet' institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.815968",
      "updated_at": "2026-01-17T04:00:06.815975"
    },
    "2aba12657a8d146a": {
      "factor_id": "2aba12657a8d146a",
      "factor_name": "Volume_Density_Compression_ZScore_10D",
      "factor_expression": "TS_ZSCORE($volume / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Density_Compression_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of volume relative to price movement, standardized against its 10-day history. A high value suggests that volume is clustering within a tight price range, indicating institutional absorption before a volatility expansion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.837299",
      "updated_at": "2026-01-17T04:00:06.837305"
    },
    "9ff730c073fc8d6a": {
      "factor_id": "9ff730c073fc8d6a",
      "factor_name": "Accumulation_Coil_Factor_15D",
      "factor_expression": "RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Coil_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies a 'coiled' market state where price dispersion is at a minimum relative to volume intensity. It uses the ratio of the 15-day average volume to the 15-day price range, cross-sectionally ranked to find the most compressed instruments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.858139",
      "updated_at": "2026-01-17T04:00:06.858145"
    },
    "2eb4cc9253e7aff3": {
      "factor_id": "2eb4cc9253e7aff3",
      "factor_name": "Liquidity_Exhaustion_Reversal_10D",
      "factor_expression": "TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in volume. It calculates the difference between the time-series Z-score of the intraday range and the time-series Z-score of volume over a 10-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.759885",
      "updated_at": "2026-01-17T04:01:01.759892"
    },
    "10a3628cfd4ea100": {
      "factor_id": "10a3628cfd4ea100",
      "factor_name": "Cross_Sectional_Liquidity_Vacuum_20D",
      "factor_expression": "RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Vacuum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the relative liquidity exhaustion across the market. It ranks the ratio of a smoothed price range to smoothed volume, highlighting stocks where price volatility is disproportionately high compared to trading activity, adjusted for a 20-day lookback.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.781726",
      "updated_at": "2026-01-17T04:01:01.781732"
    },
    "cd30d6c8ccbc13e8": {
      "factor_id": "cd30d6c8ccbc13e8",
      "factor_name": "Range_Volume_Divergence_ZScore_5D",
      "factor_expression": "ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))\" # Your output factor expression will be filled in here\n    name = \"Range_Volume_Divergence_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on short-term liquidity gaps by measuring the divergence between price range and volume growth. It uses a 5-day window to capture rapid 'overshooting' events where the range expands while volume stays low or decreases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.802827",
      "updated_at": "2026-01-17T04:01:01.802833"
    },
    "ee5011636f3af683": {
      "factor_id": "ee5011636f3af683",
      "factor_name": "Stealth_Liquidity_Absorption_20D",
      "factor_expression": "($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Liquidity_Absorption_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of trading volume to the squared intraday price range. A high ratio indicates high turnover within a narrow price band, suggesting 'stealth' liquidity absorption. The value is normalized by its 20-day moving average to identify abnormal accumulation phases.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.920019",
      "updated_at": "2026-01-17T04:02:51.920027"
    },
    "f31a3d208db11e89": {
      "factor_id": "f31a3d208db11e89",
      "factor_name": "Relative_Volume_Density_Rank_10D",
      "factor_expression": "RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Density_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of volume density (volume per unit of price range) relative to its recent time-series distribution. It targets stocks where the current volume-to-range ratio is at a historical peak, signaling potential exhaustion of sellers and a forthcoming breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.950367",
      "updated_at": "2026-01-17T04:02:51.950373"
    },
    "64b2836e01ce5097": {
      "factor_id": "64b2836e01ce5097",
      "factor_name": "ZScore_Accumulation_Density_15D",
      "factor_expression": "TS_ZSCORE($volume / (ABS($high - $low) + 1e-8), 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 15)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Accumulation_Density_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the time-series Z-score of the volume-to-range ratio over a 15-day window. By using Z-score, it identifies statistically significant 'quiet' accumulation periods where volume density exceeds the normal distribution of the specific instrument's trading activity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.971394",
      "updated_at": "2026-01-17T04:02:51.971400"
    },
    "3030871e1ca545c4": {
      "factor_id": "3030871e1ca545c4",
      "factor_name": "IIA_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies Institutional Inventory Absorption (IIA) by calculating the ratio of the 20-day average volume to the 20-day price volatility. High values indicate 'Quiet Accumulation' where high volume is absorbed with minimal price movement, signaling a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.319517",
      "updated_at": "2026-01-17T04:03:00.319524"
    },
    "d17fc8759133d362": {
      "factor_id": "d17fc8759133d362",
      "factor_name": "IIA_Rank_Tightness_20D",
      "factor_expression": "RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))\" # Your output factor expression will be filled in here\n    name = \"IIA_Rank_Tightness_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiled spring' effect by cross-sectionally ranking volume and price stability. It identifies stocks in the top decile of volume and bottom decile of volatility by subtracting the volatility rank from the volume rank.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.341262",
      "updated_at": "2026-01-17T04:03:00.341269"
    },
    "b1e96ffb77a4c8bb": {
      "factor_id": "b1e96ffb77a4c8bb",
      "factor_name": "IIA_Relative_Efficiency_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Relative_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of volume in moving prices. It uses the inverse of the 20-day price range normalized by volume. A high value suggests that large volumes are being traded within a very narrow price range, indicating institutional absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.363832",
      "updated_at": "2026-01-17T04:03:00.363839"
    },
    "c092235ba2e172e2": {
      "factor_id": "c092235ba2e172e2",
      "factor_name": "Overnight_Intraday_Asymmetry_Ratio",
      "factor_expression": "RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Intraday_Asymmetry_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the ratio of the overnight gap return to the intraday price range, weighted by the current volume relative to its 5-day average. High values indicate a significant overnight gap followed by low-volatility intraday consolidation, suggesting institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.785370",
      "updated_at": "2026-01-17T04:05:47.785376"
    },
    "b829d8b82d07f289": {
      "factor_id": "b829d8b82d07f289",
      "factor_name": "Gap_Consolidation_Efficiency_5D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)) / (($high - $low) + 0.0001), 5)\" # Your output factor expression will be filled in here\n    name = \"Gap_Consolidation_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of price discovery by comparing the magnitude of overnight gaps to the intraday volatility over a 5-day period. It uses Z-scores to normalize the gap-to-range ratio, identifying days where the gap dominates the daily price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.807039",
      "updated_at": "2026-01-17T04:05:47.807045"
    },
    "13a0cd3f1b427b42": {
      "factor_id": "13a0cd3f1b427b42",
      "factor_name": "Institutional_Stealth_Accumulation",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Stealth_Accumulation\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies potential institutional accumulation by looking for days with a positive overnight gap but a narrow intraday range relative to the 10-day average range, further filtered by volume strength.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.828509",
      "updated_at": "2026-01-17T04:05:47.828514"
    },
    "b543bbfaef7ecdae": {
      "factor_id": "b543bbfaef7ecdae",
      "factor_name": "Liquidity_Drift_Persistence_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'liquidity-driven drifting' by measuring the autocorrelation of returns during periods of low trading volume. High price persistence on low volume suggests a lack of institutional liquidity, which often leads to mean-reversion when volume returns. The factor targets regimes where volume is in the bottom 30th percentile and return autocorrelation is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.731871",
      "updated_at": "2026-01-17T04:12:15.731878"
    },
    "e99dc8eb50384b19": {
      "factor_id": "e99dc8eb50384b19",
      "factor_name": "Hollow_Trend_Reversal_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELAY($return, 1), 10)) * (1.0 - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10)) * (1.0 - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Trend_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trends that lack structural support by multiplying the 10-day return autocorrelation with a volume-based penalty. It uses the inverse of the volume rank to amplify signals where price persistence is high but market participation is low, indicating a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.754210",
      "updated_at": "2026-01-17T04:12:15.754216"
    },
    "c194349585ccf845": {
      "factor_id": "c194349585ccf845",
      "factor_name": "Low_Volume_Autocorr_ZScore",
      "factor_expression": "TS_ZSCORE(TS_CORR($return, DELAY($return, 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Low_Volume_Autocorr_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the return autocorrelation and filters for low-volume environments. It identifies assets where the current 10-day price persistence is significantly higher than its own history while the volume remains below its 20-day median, signaling an overextended move likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.776481",
      "updated_at": "2026-01-17T04:12:15.776488"
    },
    "85c86e3efae357d7": {
      "factor_id": "85c86e3efae357d7",
      "factor_name": "Institutional_Absorption_Ratio_5D",
      "factor_expression": "(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of price range to volume-weighted impact. A low value suggests 'quiet' accumulation where high volume turnover occurs within a tight price range, indicating institutional absorption before a potential breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.310621",
      "updated_at": "2026-01-17T04:16:58.310627"
    },
    "d51246ff8f20a25c": {
      "factor_id": "d51246ff8f20a25c",
      "factor_name": "Compressed_Range_Volume_Efficiency",
      "factor_expression": "RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Range_Volume_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of volume in moving price. It targets assets where the 5-day price range is compressed relative to the volume-to-price ratio, normalized by the stability of volume (inverse of 10-day volume volatility) to detect non-volatile institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.333594",
      "updated_at": "2026-01-17T04:16:58.333600"
    },
    "68f8b445de3c1f81": {
      "factor_id": "68f8b445de3c1f81",
      "factor_name": "Accumulation_Spring_Factor",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Spring_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the divergence between price volatility and volume intensity. It specifically looks for periods where the price range (high-low) is small compared to the dollar volume, weighted by the inverse of volume variance to highlight 'stable' high-liquidity zones.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.355989",
      "updated_at": "2026-01-17T04:16:58.355995"
    },
    "4b7ce1906bab598a": {
      "factor_id": "4b7ce1906bab598a",
      "factor_name": "Stealth_Momentum_Ratio_3D",
      "factor_expression": "TS_SUM($return, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Momentum_Ratio_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'stealth' institutional accumulation by calculating the ratio of the 3-day price return to the average volume-volatility product. High values suggest price discovery is occurring with minimal market impact and retail noise, indicating a high-conviction trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.871702",
      "updated_at": "2026-01-17T04:20:15.871709"
    },
    "505941f44d7074fe": {
      "factor_id": "505941f44d7074fe",
      "factor_name": "Clean_Breakout_Efficiency_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Breakout_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the stealth momentum hypothesis focusing on price efficiency over a slightly longer window (5 days). It uses the Z-score of the return divided by the volume-volatility product to identify outliers where price moves significantly despite low 'noise' (volume and volatility).",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.895356",
      "updated_at": "2026-01-17T04:20:15.895362"
    },
    "5d4a5307ed5d0e9c": {
      "factor_id": "5d4a5307ed5d0e9c",
      "factor_name": "Relative_Stealth_Intensity_10D",
      "factor_expression": "TS_RANK($return / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(TS_PCTCHANGE($close, 1) / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Stealth_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of stealth momentum by comparing the current return-to-volatility-volume ratio against its own 10-day history using TS_RANK. This identifies moments where the 'cleanliness' of the price move is at a local peak.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.917949",
      "updated_at": "2026-01-17T04:20:15.917955"
    },
    "a189234f57dc4140": {
      "factor_id": "a189234f57dc4140",
      "factor_name": "IAP_Factor_10D",
      "factor_expression": "(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IAP_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Information Asymmetry Persistence (IAP) factor: It calculates the ratio of the volume coefficient of variation to the price return volatility over a 10-day window. High values identify stocks with significant volume dispersion during price consolidation, signaling institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.946476",
      "updated_at": "2026-01-17T04:43:37.946483"
    },
    "54f8a6f63ea313e6": {
      "factor_id": "54f8a6f63ea313e6",
      "factor_name": "Z_IAP_Divergence_15D",
      "factor_expression": "ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 1e-8)) / (TS_STD($return, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 0.000001)) / (TS_STD(TS_PCTCHANGE($close, 1), 15) + 0.000001))\" # Your output factor expression will be filled in here\n    name = \"Z_IAP_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the Information Asymmetry Persistence hypothesis using a 15-day window. It measures the relative intensity of volume-price divergence compared to other stocks, highlighting extreme institutional accumulation phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.970699",
      "updated_at": "2026-01-17T04:43:37.970705"
    },
    "fc91fb2a85d935be": {
      "factor_id": "fc91fb2a85d935be",
      "factor_name": "IAP_Rank_Trend_20D",
      "factor_expression": "TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"IAP_Rank_Trend_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of information asymmetry by taking the 20-day time-series rank of the IAP ratio. A high rank suggests that the current 'quiet' accumulation phase is at its most intense relative to the past month.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.994614",
      "updated_at": "2026-01-17T04:43:37.994620"
    },
    "a4c66b2dd186bd3f": {
      "factor_id": "a4c66b2dd186bd3f",
      "factor_name": "Informed_Flow_Persistence_5D",
      "factor_expression": "TS_ZSCORE(SKEW($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SKEW(TS_PCTCHANGE($close, 1), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Flow_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend continuation by measuring the ratio of 5-day return skewness to the 5-day standard deviation of the overnight gap. High positive values suggest 'quiet' institutional accumulation characterized by smooth, positively skewed intraday discovery with minimal overnight volatility shocks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.654977",
      "updated_at": "2026-01-17T05:02:29.654984"
    },
    "54a8292e9cd61523": {
      "factor_id": "54a8292e9cd61523",
      "factor_name": "Smooth_Discovery_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smooth_Discovery_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of price trends by comparing the magnitude of daily returns to the volatility of overnight gaps. It targets regimes where price discovery is 'smooth' and driven by continuous intraday flow rather than discrete overnight jumps.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.679452",
      "updated_at": "2026-01-17T05:02:29.679458"
    },
    "835a287e74598f97": {
      "factor_id": "835a287e74598f97",
      "factor_name": "Intraday_Skew_Gap_Stability_5D",
      "factor_expression": "RANK(SKEW($return)) - RANK(TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SKEW(($close - $open) / $open, 5)) - RANK(TS_STD(($open / DELAY($close, 1)) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Skew_Gap_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked factor that rewards stocks with high intraday return skewness relative to their overnight gap risk. This aligns with the hypothesis that institutional accumulation creates positive skewness without triggering high-volatility gap events.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.703585",
      "updated_at": "2026-01-17T05:02:29.703590"
    },
    "411d946cbcb95d0b": {
      "factor_id": "411d946cbcb95d0b",
      "factor_name": "Institutional_Commitment_Persistence_Ratio_20D",
      "factor_expression": "RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Commitment_Persistence_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable trends by calculating the ratio of the Coefficient of Variation (CV) of the price range to the CV of volume over a 20-day window. A lower ratio indicates that volume is more stable relative to price volatility, suggesting 'quiet' institutional accumulation. CV is calculated as the standard deviation divided by the mean.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.092594",
      "updated_at": "2026-01-17T05:49:14.092601"
    },
    "d256ede617306ae6": {
      "factor_id": "d256ede617306ae6",
      "factor_name": "Institutional_Accumulation_Stability_20D",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 20), 20) + TS_ZSCORE(TS_STD(ABS($close - $open), 20), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the stability of institutional commitment by comparing the rolling 20-day volatility of volume against the rolling 20-day volatility of intraday returns. It targets periods where price movement is orderly (low range volatility) and volume is consistent, which is characteristic of algorithmic execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.117822",
      "updated_at": "2026-01-17T05:49:14.117828"
    },
    "b15a9e66a9933ad3": {
      "factor_id": "b15a9e66a9933ad3",
      "factor_name": "Volume_Consistency_Trend_Filter_20D",
      "factor_expression": "((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Consistency_Trend_Filter_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of institutional activity by measuring the inverse of volume dispersion relative to price range dispersion. It uses the ratio of 20-day Mean Absolute Deviation (MAD) of volume to the 20-day range to filter out speculative spikes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.142727",
      "updated_at": "2026-01-17T05:49:14.142732"
    },
    "f31d8c4ef20d75c6": {
      "factor_id": "f31d8c4ef20d75c6",
      "factor_name": "Linear_Trend_Decay_ZScore",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Decay_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that focuses on the standardized deviation of trend linearity. It uses the Z-score of the 10-day R-squared over a 20-day period to detect extreme departures from the recent trend stability regime, helping to identify points where the 'quality' of the price movement is breaking down.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.834190",
      "updated_at": "2026-01-17T06:03:35.834196"
    },
    "373b3a86b027bfcc": {
      "factor_id": "373b3a86b027bfcc",
      "factor_name": "Relative_Trend_Instability",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Trend_Instability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the instability of price trends by comparing the current trend's R-squared to its 20-day moving average, normalized by its volatility. It captures the 'fragility' of the trend by highlighting periods where the goodness-of-fit of the linear price-time relationship is significantly more volatile than its recent history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.859234",
      "updated_at": "2026-01-17T06:03:35.859239"
    },
    "1be142da9be01930": {
      "factor_id": "1be142da9be01930",
      "factor_name": "Overnight_Informed_Gap_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Informed_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies informed price discovery by multiplying the overnight return (gap) with the relative trading volume of the current day. High volume during the gap's subsequent session suggests institutional validation of the price shock, while low volume suggests retail noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.778853",
      "updated_at": "2026-01-17T06:06:12.778860"
    },
    "5f27b35f17420f9d": {
      "factor_id": "5f27b35f17420f9d",
      "factor_name": "ZScore_Overnight_Volume_Shock",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Volume_Shock\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the overnight sentiment gap that uses Z-score normalization for the volume component and cross-sectional ranking for the gap, ensuring the factor is robust to different market regimes and stock scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.804532",
      "updated_at": "2026-01-17T06:06:12.804538"
    },
    "a38885cb88142b61": {
      "factor_id": "a38885cb88142b61",
      "factor_name": "Informed_Gap_Momentum_Filter",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Informed_Gap_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the overnight gap by applying a sign-based volume weight. It captures the conviction of the overnight move by scaling the gap magnitude by the 5-day relative volume, specifically focusing on cases where volume exceeds the recent median to filter out low-conviction noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.831460",
      "updated_at": "2026-01-17T06:06:12.831466"
    },
    "97893b031c147033": {
      "factor_id": "97893b031c147033",
      "factor_name": "Intraday_VWAP_Midpoint_Deviation_5D",
      "factor_expression": "TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_VWAP_Midpoint_Deviation_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of the approximated Volume-Weighted Average Price (VWAP) from the daily price midpoint, normalized by the daily range. A high deviation indicates that volume is concentrated at one extreme of the price range, suggesting liquidity exhaustion and potential mean-reversion. It is smoothed over a 5-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.432281",
      "updated_at": "2026-01-17T06:08:21.432288"
    },
    "298e0ab6776e2256": {
      "factor_id": "298e0ab6776e2256",
      "factor_name": "Hollow_Price_Extreme_Reversal_5D",
      "factor_expression": "TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Price_Extreme_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'hollow' price moves by calculating the distance between the daily close and the approximated VWAP relative to the daily range. If the close is far from where the volume was executed (VWAP), the price level is considered low-conviction. The factor uses a 5-day moving average to signal mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.458630",
      "updated_at": "2026-01-17T06:08:21.458636"
    },
    "ad0df9d76562d7e7": {
      "factor_id": "ad0df9d76562d7e7",
      "factor_name": "Volume_Weighted_Position_ZScore_5D",
      "factor_expression": "ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the position of the VWAP within the daily range using a cross-sectional Z-score to identify assets where price extremes are most disconnected from volume centers across the universe, targeting mean-reversion over a 5-day lookback.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.484297",
      "updated_at": "2026-01-17T06:08:21.484303"
    },
    "ed8a5a26050ad169": {
      "factor_id": "ed8a5a26050ad169",
      "factor_name": "Trend_Acceleration_Decay_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Decay_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term and long-term price linearity. It calculates the difference between the 5-day R-squared and the 20-day R-squared of closing prices against time. A high value indicates a speculative blow-off where short-term linearity far exceeds long-term structural stability, while a low value suggests a breakdown of a previously stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.069444",
      "updated_at": "2026-01-17T06:38:46.069451"
    },
    "1d239eda75962a9c": {
      "factor_id": "1d239eda75962a9c",
      "factor_name": "ZScore_Trend_Linearity_Divergence",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Trend_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the trend acceleration decay. It identifies assets where the short-term (5-day) trend linearity is an outlier relative to its long-term (20-day) historical linearity, highlighting potential mean-reversion candidates in the broader market context.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.096980",
      "updated_at": "2026-01-17T06:38:46.096986"
    },
    "3469c1a0a46fd14e": {
      "factor_id": "3469c1a0a46fd14e",
      "factor_name": "Relative_Linearity_Efficiency_Ratio",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)\" # Your output factor expression will be filled in here\n    name = \"Relative_Linearity_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the efficiency of trend acceleration by scaling the linearity difference by the long-term linearity baseline. It highlights cases where a stable trend (high 20-day R-squared) is suddenly disrupted or exponentially accelerated, providing a normalized measure of structural decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.122928",
      "updated_at": "2026-01-17T06:38:46.122933"
    },
    "f463f63909a625be": {
      "factor_id": "f463f63909a625be",
      "factor_name": "Intraday_Exhaustion_ATR_Normalized_20D",
      "factor_expression": "TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies overextended emotional positioning by calculating the 20-day average of the ratio between the daily high-low range and the absolute open-close body, normalized by the 20-day Average True Range (ATR). High values indicate failed price discovery and potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.738933",
      "updated_at": "2026-01-17T06:42:00.738939"
    },
    "99540186c19ce407": {
      "factor_id": "99540186c19ce407",
      "factor_name": "Shadow_to_Body_Efficiency_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Shadow_to_Body_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified measure of the 'hollow' price move hypothesis. It calculates the 20-day average of the ratio of the total intraday range to the price displacement (body), cross-sectionally ranked to identify stocks with the most extreme 'exhaustion' patterns relative to the market.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.765086",
      "updated_at": "2026-01-17T06:42:00.765091"
    },
    "f3aada6b8df9d2b5": {
      "factor_id": "f3aada6b8df9d2b5",
      "factor_name": "Relative_Intraday_Volatility_Skew_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (ABS($close - $open) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (MAX(ABS($close - $open), 0.001 * $close)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Volatility_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between total intraday movement and net progress by comparing the current shadow-to-body ratio against its 10-day historical standard deviation, identifying statistical instability in price discovery.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.790636",
      "updated_at": "2026-01-17T06:42:00.790641"
    },
    "d339476e2577b31e": {
      "factor_id": "d339476e2577b31e",
      "factor_name": "Overnight_Sentiment_Exhaustion_5D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential short-term mean reversion by calculating the ratio of the overnight price gap to the average volume-weighted intraday range over the last 5 days. A high value suggests an emotional overnight overextension on low relative liquidity density, which is likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.308356",
      "updated_at": "2026-01-17T06:44:28.308362"
    },
    "924aeaafa3d5d17d": {
      "factor_id": "924aeaafa3d5d17d",
      "factor_name": "Ranked_Gap_to_Liquidity_Density_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_to_Liquidity_Density_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized version of the sentiment exhaustion hypothesis. It compares the current overnight gap against the average intraday price movement per unit of volume over 10 days, applying cross-sectional ranking to identify the most overextended stocks relative to their recent liquidity profile.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.334292",
      "updated_at": "2026-01-17T06:44:28.334298"
    },
    "858f84aee06050b8": {
      "factor_id": "858f84aee06050b8",
      "factor_name": "Volatility_Adjusted_Overnight_Gap_3D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Overnight_Gap_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the 3-day average intraday range, excluding volume to focus purely on price-action exhaustion. It targets stocks where the overnight move is disproportionately large compared to recent daily price volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.359855",
      "updated_at": "2026-01-17T06:44:28.359861"
    },
    "2a7824bde358fdcf": {
      "factor_id": "2a7824bde358fdcf",
      "factor_name": "WV_Trend_Linearity_Ratio_5_10",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WV_Trend_Linearity_Ratio_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio between the 5-day volume-weighted price range and the 10-day R-squared of price against a time index. It identifies trend exhaustion by detecting when the 'energy' (volume-weighted volatility) spikes while the 'order' (linear trend persistence) begins to plateau or decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:09.983407",
      "updated_at": "2026-01-17T06:59:09.983414"
    },
    "1b788843ad56ac76": {
      "factor_id": "1b788843ad56ac76",
      "factor_name": "Vol_Weighted_Volatility_ZScore_Trend_Decay",
      "factor_expression": "TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Volatility_ZScore_Trend_Decay\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between standardized volume-weighted volatility and trend persistence. It targets the lead-lag relationship where a surge in volatility (Z-score of WV) relative to the trend stability (R-squared) signals an imminent regime shift or trend breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.009807",
      "updated_at": "2026-01-17T06:59:10.009813"
    },
    "97f062d37da14737": {
      "factor_id": "97f062d37da14737",
      "factor_name": "Institutional_Distribution_Energy_Factor",
      "factor_expression": "RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Distribution_Energy_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis focusing on the ratio of short-term volume-weighted price movement to the persistence of the trend. High values suggest that price movement is becoming erratic and volume-heavy, indicating potential institutional distribution before a trend reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.035784",
      "updated_at": "2026-01-17T06:59:10.035789"
    },
    "628b34f333f9c1b3": {
      "factor_id": "628b34f333f9c1b3",
      "factor_name": "Stealth_Accumulation_Efficiency_20D",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 20)) / (TS_SUM(ABS(DELTA($close, 1)), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining price path efficiency with a volume-weighted positioning metric, filtered for low-volatility 'quiet' regimes. High efficiency (net move vs total move) and volume concentrated near the high during low turnover-to-volatility periods signal sustainable stealth trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.576468",
      "updated_at": "2026-01-17T06:59:34.576476"
    },
    "775ac856b5e37fdc": {
      "factor_id": "775ac856b5e37fdc",
      "factor_name": "Quiet_Regime_Path_Linearity_10D",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(TS_STD($return, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 0.00000001)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 10) / (TS_MEAN($volume, 10) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Path_Linearity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stealth accumulation hypothesis focusing on the linearity of price movement (Efficiency Ratio) normalized by the relative volatility-to-turnover ratio. It targets stocks moving steadily with low market noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.603817",
      "updated_at": "2026-01-17T06:59:34.603823"
    },
    "3d7dd83af034db9d": {
      "factor_id": "3d7dd83af034db9d",
      "factor_name": "Volume_Skew_Efficiency_Combined",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($close - DELAY($close, 1)), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Volume_Skew_Efficiency_Combined\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the synergy between price efficiency and the intraday volume-weighted close position. It uses the 20-day efficiency ratio and weights it by the 5-day average of where the close sits relative to the daily range, emphasizing 'quiet' accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.630010",
      "updated_at": "2026-01-17T06:59:34.630016"
    },
    "47ab5689d1d20430": {
      "factor_id": "47ab5689d1d20430",
      "factor_name": "Liquidity_Drift_Efficiency_20D",
      "factor_expression": "TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistent drift of price relative to the proxy VWAP (average of OHLC), normalized by price volatility. It identifies sustainable trends by calculating the 20-day moving average of this normalized distance, capturing high-conviction liquidity-taking phases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.104134",
      "updated_at": "2026-01-17T07:02:02.104141"
    },
    "612c20e61471a5fb": {
      "factor_id": "612c20e61471a5fb",
      "factor_name": "Stable_Trend_Consensus_Factor",
      "factor_expression": "RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Stable_Trend_Consensus_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend stability by combining the price-VWAP distance with its cross-sectional rank. It targets assets where the price is consistently re-rated relative to the average cost basis, avoiding temporary spikes by using a smoothed 20-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.131054",
      "updated_at": "2026-01-17T07:02:02.131060"
    },
    "01c133f13ad1a4f7": {
      "factor_id": "01c133f13ad1a4f7",
      "factor_name": "VWAP_Distance_ZScore_20D",
      "factor_expression": "TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Distance_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized measure of the price's deviation from the proxy VWAP, expressed as a time-series Z-score over 20 days. This captures the statistical significance of the price drift relative to its own historical volatility to signal trend continuation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.157264",
      "updated_at": "2026-01-17T07:02:02.157270"
    },
    "f6b570215828664b": {
      "factor_id": "f6b570215828664b",
      "factor_name": "Institutional_Accumulation_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($close - $open) / ($high - $low + 1e-8)) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($close / DELAY($close, 1) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring 'price efficiency' (the ratio of net price movement to total intraday range) scaled by volume density. It targets steady price appreciation accompanied by high relative volume and low volatility, which suggests structural absorption of supply.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.446055",
      "updated_at": "2026-01-17T07:02:26.446062"
    },
    "3972ceec7e301721": {
      "factor_id": "3972ceec7e301721",
      "factor_name": "Low_Vol_Volume_Density_Rank_15D",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($return, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 15))\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Volume_Density_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-quality momentum by ranking stocks that exhibit a high ratio of volume to intraday range (volume density) while maintaining low return volatility. High volume density indicates that large orders are being filled within a tight price range, a hallmark of institutional execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.472976",
      "updated_at": "2026-01-17T07:02:26.472982"
    },
    "60d07cdfa713d25a": {
      "factor_id": "60d07cdfa713d25a",
      "factor_name": "Structural_Liquidity_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Liquidity_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the persistence of price trends by evaluating the consistency of positive returns relative to the intraday range, weighted by the 20-day time-series rank of volume. It identifies 'quiet' trends where volume is high relative to historical norms but price volatility remains suppressed.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.499248",
      "updated_at": "2026-01-17T07:02:26.499253"
    },
    "c3727aed18a981b4": {
      "factor_id": "c3727aed18a981b4",
      "factor_name": "Intraday_Conviction_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Conviction_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional trend conviction by measuring the alignment between price direction and intraday range, weighted by volume intensity and penalized by volume instability. It calculates the 5-day average price efficiency (body-to-range ratio) multiplied by the 5-day average volume, normalized by the 20-day volume standard deviation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.499804",
      "updated_at": "2026-01-17T07:04:53.499811"
    },
    "b35305f10d1e3564": {
      "factor_id": "b35305f10d1e3564",
      "factor_name": "Cross_Sectional_Institutional_Flow_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Institutional_Flow_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction hypothesis that focuses on the relative strength of price-volume synchronization. It uses the ratio of price efficiency to volume volatility over a 10-day window to identify stocks with the most stable institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.526663",
      "updated_at": "2026-01-17T07:04:53.526669"
    },
    "67c375461e7ad2ef": {
      "factor_id": "67c375461e7ad2ef",
      "factor_name": "Conviction_Momentum_ZScore_20D",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Momentum_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of price moves by standardizing the price efficiency ratio against its own history and scaling it by the relative volume level. It highlights periods where price movement is unusually 'clean' relative to the intraday noise, supported by high relative volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.552981",
      "updated_at": "2026-01-17T07:04:53.552987"
    },
    "461bb144da4b724a": {
      "factor_id": "461bb144da4b724a",
      "factor_name": "Inst_Trend_Stability_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Stability_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the stability of volume relative to price range. A low ratio of price range to volume volatility, smoothed over 20 days and normalized by 60-day momentum, suggests a steady, low-impact trend characteristic of institutional buying.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.610923",
      "updated_at": "2026-01-17T07:08:38.610930"
    },
    "c5e624a879656b21": {
      "factor_id": "c5e624a879656b21",
      "factor_name": "Smooth_Volume_Efficiency_20D",
      "factor_expression": "ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN($return, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"Smooth_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price efficiency by comparing the daily price range to volume dispersion. It targets regimes where price moves are achieved with consistent volume rather than spikes, indicating sustainable trend persistence. It uses Z-score for cross-sectional normalization.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.637858",
      "updated_at": "2026-01-17T07:08:38.637863"
    },
    "629b1b2a695e6c1d": {
      "factor_id": "629b1b2a695e6c1d",
      "factor_name": "Institutional_Accumulation_Proxy",
      "factor_expression": "TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Proxy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined measure of institutional trend persistence. It calculates the ratio of price range to volume volatility, then applies a time-series rank to ensure the indicator is robust to outliers before multiplying by the long-term trend direction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.666387",
      "updated_at": "2026-01-17T07:08:38.666393"
    },
    "837f1167178d649c": {
      "factor_id": "837f1167178d649c",
      "factor_name": "IAG_Factor_5D",
      "factor_expression": "RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"IAG_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's closing position relative to its daily range. High values suggest informed institutional positioning with low retail resistance.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.531668",
      "updated_at": "2026-01-17T07:09:48.531675"
    },
    "395e6e416c3c22cc": {
      "factor_id": "395e6e416c3c22cc",
      "factor_name": "Institutional_Gap_Persistence_10D",
      "factor_expression": "ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of information-driven gaps by scaling the overnight return by the 10-day volatility of intraday returns, further filtered by the intraday price location to confirm trend strength. It targets 'quiet' trend initiations where institutional consensus is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.562432",
      "updated_at": "2026-01-17T07:09:48.562439"
    },
    "36354e062634e726": {
      "factor_id": "36354e062634e726",
      "factor_name": "Quiet_Trend_Initiation_Index",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Initiation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the ratio of the overnight return to the trailing 5-day median absolute deviation of intraday returns. It uses TS_MAD for robustness against outliers and scales by the intraday range ratio to identify high-conviction institutional moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.590704",
      "updated_at": "2026-01-17T07:09:48.590711"
    },
    "f6f5d9c29160fdcf": {
      "factor_id": "f6f5d9c29160fdcf",
      "factor_name": "Overnight_Gap_ATR_Normalized_20D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the overnight price gap (current open minus previous close) and normalizes it by the 20-day Average True Range (ATR). It identifies institutional information shocks where the overnight surprise significantly exceeds typical daily volatility, signaling a momentum breakout.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.322229",
      "updated_at": "2026-01-17T07:11:55.322236"
    },
    "33dde5198bb9a733": {
      "factor_id": "33dde5198bb9a733",
      "factor_name": "ZScore_Overnight_Shock_20D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Shock_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the cross-sectional strength of the overnight gap relative to its historical volatility. By applying a Z-score to the ATR-normalized gap, it highlights stocks experiencing the most significant idiosyncratic information shocks relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.350013",
      "updated_at": "2026-01-17T07:11:55.350019"
    },
    "5d7b0005e2695a36": {
      "factor_id": "5d7b0005e2695a36",
      "factor_name": "Ranked_Information_Shock_Persistence",
      "factor_expression": "RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Information_Shock_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the ATR-normalized overnight gap with its time-series rank over the last 10 days. It aims to identify 'breakout' days where the overnight shock is not only large relative to volatility but also represents a recent peak in surprise intensity.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.377120",
      "updated_at": "2026-01-17T07:11:55.377126"
    },
    "beceb91b44bbc95e": {
      "factor_id": "beceb91b44bbc95e",
      "factor_name": "MRLV_Liquidity_Vacuum_5D_20D",
      "factor_expression": "TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"MRLV_Liquidity_Vacuum_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Mean-Reverting Liquidity Vacuum (MRLV) factor identifies price exhaustion by calculating the ratio of short-term price range volatility to long-term average volume. High values indicate 'hollow' price movements driven by liquidity gaps rather than institutional conviction, signaling a likely reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.831791",
      "updated_at": "2026-01-17T07:15:34.831797"
    },
    "ab092a4ed20eeabf": {
      "factor_id": "ab092a4ed20eeabf",
      "factor_name": "Hollow_Volatility_Reversal_Factor",
      "factor_expression": "RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($return, $volume, 10) < 0 ? 1 : 0.5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($close / DELAY($close, 1) - 1, $volume, 10) < 0 ? 1 : 0.5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Volatility_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets assets where price range expansion is decoupled from volume support. It uses the ratio of the 5-day range standard deviation to the 20-day volume mean, cross-sectionally ranked and filtered for low price-volume correlation to isolate non-institutional noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.861060",
      "updated_at": "2026-01-17T07:15:34.861066"
    },
    "b9875be6ef7bd575": {
      "factor_id": "b9875be6ef7bd575",
      "factor_name": "ZScore_Range_Volume_Imbalance",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Range_Volume_Imbalance\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the standardized imbalance between price range volatility and volume. By using TS_ZSCORE, it identifies extreme 'liquidity vacuum' events relative to the asset's own history, which are historically prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.889105",
      "updated_at": "2026-01-17T07:15:34.889111"
    },
    "bc5cd0033670fd71": {
      "factor_id": "bc5cd0033670fd71",
      "factor_name": "TED_Linearity_Volume_Divergence_10D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"TED_Linearity_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies unsustainable price trends by multiplying the trend linearity (R-squared of price over time) by the negative correlation between price and volume. High linearity combined with price-volume divergence (negative correlation) suggests trend exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.951902",
      "updated_at": "2026-01-17T08:22:54.951909"
    },
    "1b9594382311ea4a": {
      "factor_id": "1b9594382311ea4a",
      "factor_name": "Trend_Fragility_Index_10D",
      "factor_expression": "RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Trend Exhaustion Divergence hypothesis. It uses the time-series rank of price linearity and combines it with the cross-sectional rank of the negative price-volume correlation to find stocks where the trend is most 'crowded' yet unsupported by volume.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.982889",
      "updated_at": "2026-01-17T08:22:54.982895"
    },
    "d8bcc7cc594a12bc": {
      "factor_id": "d8bcc7cc594a12bc",
      "factor_name": "Exhaustion_Volume_Decay_10D",
      "factor_expression": "TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Volume_Decay_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by looking at the interaction between price momentum and the decline in volume support. It uses the R-squared of the price trend scaled by the inverse of the price-volume correlation, focusing on cases where price moves linearly but volume participation is fading.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:55.013504",
      "updated_at": "2026-01-17T08:22:55.013510"
    },
    "164030fafe4ad9c9": {
      "factor_id": "164030fafe4ad9c9",
      "factor_name": "Institutional_Flow_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Flow_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional conviction by measuring the average intraday price positioning (Close-Open relative to High-Low) weighted by the 5-day volume trend, identifying persistent directional flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.945249",
      "updated_at": "2026-01-17T08:41:46.945258"
    },
    "e8edb408831788e7": {
      "factor_id": "e8edb408831788e7",
      "factor_name": "Aggressive_Skew_Momentum_10D",
      "factor_expression": "RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($return))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($close / DELAY($close, 1) - 1))\" # Your output factor expression will be filled in here\n    name = \"Aggressive_Skew_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies aggressive trend-following behavior by combining cross-sectional return skewness with the consistency of price relative to its recent range, signaling institutional dominance.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.977170",
      "updated_at": "2026-01-17T08:41:46.977177"
    },
    "39784a9223d662b5": {
      "factor_id": "39784a9223d662b5",
      "factor_name": "Volume_Weighted_Position_Consistency",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_Consistency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the consistency of informed accumulation by evaluating the rank of price positioning relative to the volume-weighted trend, emphasizing stocks with stable institutional footprints.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:47.007667",
      "updated_at": "2026-01-17T08:41:47.007673"
    }
  }
}