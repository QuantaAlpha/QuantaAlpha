{
  "metadata": {
    "created_at": "2026-01-17T02:01:06.994943",
    "last_updated": "2026-01-17T02:01:06.994948",
    "total_factors": 154,
    "version": "1.0",
    "note": "Random 30 factors per round (1,2,3,4,5,8) from all_factors_library_AA.json"
  },
  "factors": {
    "d5c41860c0168b28": {
      "factor_id": "d5c41860c0168b28",
      "factor_name": "Net_Volume_Momentum_5D",
      "factor_expression": "ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Net_Volume_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of directional money flow by calculating the normalized difference between volume on up-days and down-days over a 5-day window, capturing net capital inflow or outflow.",
      FF: "2026-01-14_12-28-24-866300",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite signal integrating short-term price-volume correlation, relative price positioning against recent peaks, and volume-weighted momentum can effectively capture mean-reversion and trend-exhaustion points in equity returns.\n                Concise Observation: The user's provided components (CORR5, MAX5, VSUMD5) target three distinct dimensions: liquidity-price synergy, technical resistance, and directional volume intensity over a 5-day window.\n                Concise Justification: Combining these factors allows for a multi-dimensional filter where VSUMD5 identifies the net force of money flow, while MAX5 and CORR5 act as conditional oscillators to determine if that flow is sustainable or hitting a structural ceiling.\n                Concise Knowledge: If price increases are decoupled from volume growth (low correlation), the trend may lack conviction; when prices approach a 5-day resistance level (high MAX5), selling pressure typically intensifies; if volume disproportionately accompanies price declines (negative VSUMD5), it indicates aggressive capital outflow.\n                concise Specification: The hypothesis will be tested by calculating the 5-day correlation of close price and log-volume, the ratio of 5-day high to current close, and the normalized difference of volume on up-days versus down-days, expecting a negative relationship between high resistance/low flow and future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048430344071001,
        "ICIR": 0.0331262421245781,
        "RankIC": 0.0186466306361967,
        "RankICIR": 0.1295832293323421,
        "annualized_return": 0.0480758806902796,
        "information_ratio": 0.6093342429088725,
        "max_drawdown": -0.1697593938726594
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:58.229250",
      "updated_at": "2026-01-14T20:33:58.229256"
    },
    "040b0ca4fc42fff3": {
      "factor_id": "040b0ca4fc42fff3",
      "factor_name": "Trend_Conviction_Volume_Stability_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Trend_Conviction_Volume_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the composite hypothesis focusing on the interaction between price-volume correlation and volume stability. It identifies stocks where price trends are backed by consistent, non-volatile volume growth, suggesting high-quality institutional accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.574184",
      "updated_at": "2026-01-14T20:24:44.574190"
    },
    "c45771cd18f826ae": {
      "factor_id": "c45771cd18f826ae",
      "factor_name": "Relative_Strength_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day reversal logic with the Relative Strength Index (RSI). It identifies mean-reversion candidates by looking for stocks that have both a negative 10-day return and an oversold RSI signal, smoothed by a cross-sectional rank.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.463809",
      "updated_at": "2026-01-14T16:57:26.463815"
    },
    "8fe21fdb459ddca8": {
      "factor_id": "8fe21fdb459ddca8",
      "factor_name": "Volume_Weighted_Leader_Signal",
      "factor_expression": "ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Leader_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis that weights the 10-day momentum of the entire cross-section by volume rank to emphasize leader behavior, then applies this signal specifically to lower-volume assets.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.848571",
      "updated_at": "2026-01-15T17:38:45.848577"
    },
    "12a138054c7457fa": {
      "factor_id": "12a138054c7457fa",
      "factor_name": "Clean_Trend_Quality_Index",
      "factor_expression": "RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Trend_Quality_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the trend quality hypothesis focusing on the ratio of directional persistence to intraday volatility. It rewards stocks where the 10-day price change is high relative to the average daily range, adjusted for volume stability.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.150807",
      "updated_at": "2026-01-14T17:20:27.150813"
    },
    "fc79ccb2d5cb3a49": {
      "factor_id": "fc79ccb2d5cb3a49",
      "factor_name": "Volume_Weighted_Range_Convexity_10D",
      "factor_expression": "RANK(TS_SUM((ABS($return) * $volume) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(($volume * ABS($return)) / (TS_STD($close, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Range_Convexity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the hypothesis that high intraday volatility relative to net price change, when confirmed by high volume, indicates exhaustion. It calculates the 10-day sum of volume-weighted return-to-range ratios, cross-sectionally ranked for robustness.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.772489",
      "updated_at": "2026-01-15T18:44:45.772495"
    },
    "5216873e5822843b": {
      "factor_id": "5216873e5822843b",
      "factor_name": "Composite_Trend_Volume_RSV_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Volume_RSV_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines 20-day price trend stability (proxied by the square of the correlation between price and time), 5-day volume-weighted buying pressure, and the 5-day Relative Statistical Value (RSV) to identify high-probability entry points.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.835728",
      "updated_at": "2026-01-14T17:27:11.835735"
    },
    "d4a61936fdb34177": {
      "factor_id": "d4a61936fdb34177",
      "factor_name": "Lead_Lag_Momentum_Corr_20D_5L",
      "factor_expression": "TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Lead_Lag_Momentum_Corr_20D_5L\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 20-day rolling correlation between the current daily return and the 5-day lagged log return. It captures lead-lag momentum effects where current price action follows historical trends with a specific delay.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.598808",
      "updated_at": "2026-01-15T18:47:04.598816"
    },
    "be5d0f19f2e385b1": {
      "factor_id": "be5d0f19f2e385b1",
      "factor_name": "Short_Term_Oversold_Stability_Factor",
      "factor_expression": "-1 * RANK(TS_MEAN($close, 5)) * (1.0 - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($close, 5)) * (1.0 - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Short_Term_Oversold_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the mean-reversion and liquidity stability components of the hypothesis. It looks for stocks that are cross-sectionally oversold over a 5-day period but maintain stable volume profiles, indicating a potential low-risk bounce.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.589041",
      "updated_at": "2026-01-14T20:24:44.589047"
    },
    "2397650750fec253": {
      "factor_id": "2397650750fec253",
      "factor_name": "Trend_Stability_PV_Sync_60D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_PV_Sync_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between long-term price trend linearity (R-squared) and short-term price-volume synchronization. High linearity suggests a stable trend, while positive price-volume correlation confirms the conviction behind the move.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.812715",
      "updated_at": "2026-01-14T17:26:18.812726"
    },
    "c2ef165146f514d0": {
      "factor_id": "c2ef165146f514d0",
      "factor_name": "Exhaustive_Spike_Rank_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))\" # Your output factor expression will be filled in here\n    name = \"Exhaustive_Spike_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price 'noise' relative to its trend. It combines the 10-day price residual with a smoothed efficiency ratio. By using RANK, it focuses on the relative extremity of the exhaustive price action compared to the rest of the market universe.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.680649",
      "updated_at": "2026-01-14T20:32:25.680655"
    },
    "0404e78482312e86": {
      "factor_id": "0404e78482312e86",
      "factor_name": "Z_RESI_Efficiency_Filter_10D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ABS(($close - $open) / ($high - $low + 1e-12))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ABS(($close - $open) / ($high - $low + 1e-12))\" # Your output factor expression will be filled in here\n    name = \"Z_RESI_Efficiency_Filter_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the over-extension factor. It uses the Z-score of the 10-day linear regression residual to measure relative price deviation and weights it by the absolute price efficiency. This helps identify assets that have deviated most significantly from their trend with the least structural support.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.665439",
      "updated_at": "2026-01-14T20:32:25.665445"
    },
    "d459cae3758d5c09": {
      "factor_id": "d459cae3758d5c09",
      "factor_name": "Composite_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8)) - ZSCORE(TS_STD(WMA($close, 20), 20) / (TS_MEAN(WMA($close, 20), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) - ZSCORE(TS_STD(WMA($close, 20), 20) / TS_MEAN(WMA($close, 20), 20))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines the linearity of the price trend (RSQR) with the relative volume-weighted price stability. It filters for stocks where the price trend is both statistically linear and supported by consistent volume-weighted price levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.889747",
      "updated_at": "2026-01-14T17:26:18.889753"
    },
    "7374cc0adeeff66f": {
      "factor_id": "7374cc0adeeff66f",
      "factor_name": "RESI_KMID_MeanReversion_10D",
      "factor_expression": "REGRESI($close, SEQUENCE(10), 10) * (($close - $open) / ($high - $low + 1e-12))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(10), 10) * (($close - $open) / ($high - $low + 1e-12))\" # Your output factor expression will be filled in here\n    name = \"RESI_KMID_MeanReversion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion opportunities by multiplying the 10-day linear regression residual of closing prices with the daily price efficiency (KMID). A high residual suggests price over-extension, while a low KMID (small candle body relative to range) indicates weak conviction, signaling an exhaustive move likely to reverse.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.649922",
      "updated_at": "2026-01-14T20:32:25.649929"
    },
    "d817e6e5d1c010ca": {
      "factor_id": "d817e6e5d1c010ca",
      "factor_name": "Trend_Stability_Composite_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Composite_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable price trends by combining trend linearity (R-squared of price against time), relative intraday range (noise), and volume-weighted return dispersion. High values indicate a high-conviction, low-noise trend often associated with institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.117300",
      "updated_at": "2026-01-14T17:20:27.117308"
    },
    "5986d9d2092eb2ce": {
      "factor_id": "5986d9d2092eb2ce",
      "factor_name": "Laggard_Delayed_Response_10D",
      "factor_expression": "DELAY(MEAN(FILTER(TS_SUM($return, 10), RANK($volume) > 0.9)), 5) * RANK(INV($volume))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(DELAY($return, 5), RANK(DELAY($volume, 5)) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Laggard_Delayed_Response_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'laggard' stocks (bottom 50% by volume) and calculates their sensitivity to the previous period's market leader returns. It assumes that if the top 10% most liquid stocks had high returns 5 days ago, laggards will catch up today.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.829835",
      "updated_at": "2026-01-15T17:38:45.829841"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T16:57:26.431941"
    },
    "fe46aa9f57813678": {
      "factor_id": "fe46aa9f57813678",
      "factor_name": "Normalized_Price_Efficiency_ZScore_10D",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Price_Efficiency_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures price efficiency by comparing the directional return to the total volatility (range). It uses a Z-score of the ratio of absolute return to the high-low range, smoothed over 10 days, to identify periods where price movement is 'inefficient' or 'convex', signaling exhaustion.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.752734",
      "updated_at": "2026-01-15T18:44:45.752740"
    },
    "4e1777247bcab4a7": {
      "factor_id": "4e1777247bcab4a7",
      "factor_name": "Intraday_Volatility_Adjusted_Momentum",
      "factor_expression": "RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Volatility_Adjusted_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intraday return normalized by the intraday range (high-low) over a 20-day period. By scaling the intraday trend by the daily volatility, it highlights persistent directional moves that occur with relatively low noise.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.266712",
      "updated_at": "2026-01-15T17:37:26.266718"
    },
    "b999c8f19d5042cd": {
      "factor_id": "b999c8f19d5042cd",
      "factor_name": "Intraday_Return_Relative_Rank_10D",
      "factor_expression": "RANK(TS_RANK(($close - $open) / ($open * ABS($return) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK(($close - $open) / ($open * ABS($return) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Return_Relative_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of intraday return (open-to-close) to the total daily return (close-to-prev_close) and takes its 10-day time-series rank. It identifies stocks where intraday price action dominates the total return, suggesting strong 'smart money' conviction.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.247964",
      "updated_at": "2026-01-15T17:37:26.247970"
    },
    "e3b73174f7fdec13": {
      "factor_id": "e3b73174f7fdec13",
      "factor_name": "Volume_Weighted_Lag_Momentum_20D",
      "factor_expression": "TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Lag_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the lead-lag hypothesis by correlating current returns with the 5-day lagged volume-weighted price change proxy, aiming to identify trends backed by significant trading activity.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.638025",
      "updated_at": "2026-01-15T18:47:04.638031"
    },
    "c20dcf9d08b15587": {
      "factor_id": "c20dcf9d08b15587",
      "factor_name": "Ranked_Stability_Buying_Pressure_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_Buying_Pressure_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the hypothesis by cross-sectionally ranking trend stability (R-squared of price vs time) and multiplying it by the buying pressure ratio over a 5-day window, adjusted for price positioning.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.869921",
      "updated_at": "2026-01-14T17:27:11.869929"
    },
    "bce345eb801c5573": {
      "factor_id": "bce345eb801c5573",
      "factor_name": "Intraday_Momentum_ZScore_5D",
      "factor_expression": "ZSCORE(TS_MEAN(($close - $open) / ($open + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($close - $open) / ($open + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Momentum_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates the intraday return (open-to-close) and calculates its 5-day moving average, normalized by the cross-sectional Z-score. It aims to capture persistent institutional buying or selling pressure during market hours, independent of overnight price gaps.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.228959",
      "updated_at": "2026-01-15T17:37:26.228966"
    },
    "87ef5fd9a3bfa508": {
      "factor_id": "87ef5fd9a3bfa508",
      "factor_name": "PV_Corr_Resistance_5D",
      "factor_expression": "RANK(TS_CORR($close, LOG($volume + 1e-8), 5)) * RANK($close / (TS_MAX($high, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, LOG($volume + 1e-8), 5)) * RANK($close / (TS_MAX($high, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"PV_Corr_Resistance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by combining price-volume correlation with proximity to recent price peaks. A high correlation between price and volume near a 5-day high suggests a potential blow-off top or resistance-driven reversal.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite signal integrating short-term price-volume correlation, relative price positioning against recent peaks, and volume-weighted momentum can effectively capture mean-reversion and trend-exhaustion points in equity returns.\n                Concise Observation: The user's provided components (CORR5, MAX5, VSUMD5) target three distinct dimensions: liquidity-price synergy, technical resistance, and directional volume intensity over a 5-day window.\n                Concise Justification: Combining these factors allows for a multi-dimensional filter where VSUMD5 identifies the net force of money flow, while MAX5 and CORR5 act as conditional oscillators to determine if that flow is sustainable or hitting a structural ceiling.\n                Concise Knowledge: If price increases are decoupled from volume growth (low correlation), the trend may lack conviction; when prices approach a 5-day resistance level (high MAX5), selling pressure typically intensifies; if volume disproportionately accompanies price declines (negative VSUMD5), it indicates aggressive capital outflow.\n                concise Specification: The hypothesis will be tested by calculating the 5-day correlation of close price and log-volume, the ratio of 5-day high to current close, and the normalized difference of volume on up-days versus down-days, expecting a negative relationship between high resistance/low flow and future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048430344071001,
        "ICIR": 0.0331262421245781,
        "RankIC": 0.0186466306361967,
        "RankICIR": 0.1295832293323421,
        "annualized_return": 0.0480758806902796,
        "information_ratio": 0.6093342429088725,
        "max_drawdown": -0.1697593938726594
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:58.213655",
      "updated_at": "2026-01-14T20:33:58.213663"
    },
    "201b29ae566c3fdf": {
      "factor_id": "201b29ae566c3fdf",
      "factor_name": "Trend_Consistency_Extreme_Timing_5D",
      "factor_expression": "ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Extreme_Timing_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite indicator measuring the synergy between trend direction and the internal rhythm of price extremes. It combines the 5-day price slope with the normalized distance between the occurrences of the 5-day high and low.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.220275",
      "updated_at": "2026-01-14T17:15:58.220283"
    },
    "2aa3b67e52c741d1": {
      "factor_id": "2aa3b67e52c741d1",
      "factor_name": "Composite_Trend_Reversion_Stability_Factor",
      "factor_expression": "RANK(TS_CORR(DELAY($return, 1), DELAY(DELTA(LOG($volume + 1e-8), 1), 1), 60)) - RANK(RANK($close)) - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DELAY($return, 1), DELAY(DELTA(LOG($volume), 1), 1), 60)) - RANK(TS_RANK($close, 5)) - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Reversion_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines long-term trend quality (60-day price-volume correlation), short-term mean reversion (5-day price rank), and liquidity stability (10-day volume volatility). It targets stocks with high trend conviction, oversold conditions, and stable institutional participation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.559388",
      "updated_at": "2026-01-14T20:24:44.559395"
    },
    "677fe32db5e17012": {
      "factor_id": "677fe32db5e17012",
      "factor_name": "Breadth_Timing_Composite_5D",
      "factor_expression": "RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Breadth_Timing_Composite_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures short-term market strength by combining the breadth of positive price movements (upward frequency) with the relative position of the current price within its recent 5-day range, adjusted for trend slope.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.253729",
      "updated_at": "2026-01-14T17:15:58.253736"
    },
    "4fd5f6bb928aff93": {
      "factor_id": "4fd5f6bb928aff93",
      "factor_name": "Lagged_Return_Spillover_Rank_20D",
      "factor_expression": "TS_CORR($return, DELAY(RANK($return), 5), 20)",
      "factor_implementation_code": "",
      "factor_description": "A variation of the lead-lag hypothesis that uses cross-sectional ranking of lagged returns to identify momentum spillover. It correlates current returns with the 5-day lagged cross-sectional rank of returns over a 20-day window.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.618652",
      "updated_at": "2026-01-15T18:47:04.618659"
    },
    "2e2d86921c884979": {
      "factor_id": "2e2d86921c884979",
      "factor_name": "Leader_Momentum_Spillover_10D",
      "factor_expression": "MEAN(FILTER(TS_MEAN($return, 10), RANK($volume) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(TS_MEAN($return, 10), RANK($volume) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Leader_Momentum_Spillover_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the lead-lag effect by calculating the cross-sectional correlation between a stock's current volume rank (identifying laggards) and the recent 10-day momentum of high-volume leaders. It uses the cross-sectional mean of returns for high-volume stocks as a proxy for leader movement.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.810757",
      "updated_at": "2026-01-15T17:38:45.810765"
    },
    "de72babf4b53b854": {
      "factor_id": "de72babf4b53b854",
      "factor_name": "Institutional_Accumulation_Score",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Score\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'low noise' aspect of the hypothesis. It measures the linearity of the price trend (RSQR) and penalizes stocks with high 'friction' (intraday volatility relative to volume).",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.183527",
      "updated_at": "2026-01-14T17:20:27.183533"
    },
    "e7e3d9f0f2bcda6e": {
      "factor_id": "e7e3d9f0f2bcda6e",
      "factor_name": "Ranked_Stability_VWAP_Trigger_2D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_VWAP_Trigger_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the stability-momentum hypothesis using RANK instead of ZSCORE to handle outliers. It identifies stocks where the 20-day price trend is highly linear (RSQR) and is currently experiencing a positive 2-day volume-weighted price thrust, signaling a high-probability entry point.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.101297",
      "updated_at": "2026-01-14T17:43:57.101305"
    },
    "793ee7a2944db336": {
      "factor_id": "793ee7a2944db336",
      "factor_name": "Vol_Normalized_Exhaustion_Index_20D",
      "factor_expression": "((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Normalized_Exhaustion_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies structural trend exhaustion by measuring the volatility-normalized distance between the 20-day high and the current close, weighted by the surge in short-term volume relative to its monthly average. High values suggest a 'blow-off' top where price is stretched but volume is disproportionately high or low compared to the baseline.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.183104",
      "updated_at": "2026-01-14T20:37:23.183111"
    },
    "57ed23d5978e1e44": {
      "factor_id": "57ed23d5978e1e44",
      "factor_name": "Conviction_Filtered_Trend_5D",
      "factor_expression": "RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Filtered_Trend_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by comparing the cross-sectional rank of the 5-day price slope against the rank of the volume-weighted price location. Divergence between trend direction and volume-weighted support indicates potential reversals.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.034763",
      "updated_at": "2026-01-14T17:21:26.034769"
    },
    "7e9ddacd0e80dc3f": {
      "factor_id": "7e9ddacd0e80dc3f",
      "factor_name": "Liquidity_Adjusted_Momentum_Z",
      "factor_expression": "TS_ZSCORE($close / (($high + $low + $close) / 3 + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - (($high + $low + $close) / 3)) / (TS_STD($return, 20) + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Momentum_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price moves by calculating the Z-score of the ratio between price-VWAP deviation and historical volatility, multiplied by the rank of short-term volume growth to filter for institutional accumulation.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.357753",
      "updated_at": "2026-01-14T17:29:39.357759"
    },
    "0a7e73fd9b4c7d2f": {
      "factor_id": "0a7e73fd9b4c7d2f",
      "factor_name": "Smoothed_Conviction_Momentum_10D",
      "factor_expression": "TS_CORR($return, EMA(DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, EMA(DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5), 10)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Conviction_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the conviction lead-lag factor that applies an Exponential Moving Average (EMA) to the volume-scaled lagged return signal to reduce noise before calculating the 10-day correlation with current returns.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day rolling correlation between current returns and a 3-day lagged, volume-scaled return signal captures high-conviction price discovery trends more effectively than longer-lag models.\n                Concise Observation: The previous 5-day lag and 20-day window were too slow to capture decaying lead-lag effects; shortening the lag to 3 days and using a volume ratio instead of a Z-score improved the Information Ratio and signal responsiveness.\n                Concise Justification: Shorter lags capture more immediate information diffusion, while scaling lagged returns by the volume ratio (current volume / mean volume) emphasizes price moves that occurred with high relative conviction, filtering out noise from low-liquidity sessions.\n                Concise Knowledge: If the lag period is reduced to 3 days and the lagged signal is scaled by the ratio of volume to its 10-day moving average, then the resulting correlation identifies short-term momentum backed by liquidity, which is more predictive of immediate price persistence.\n                concise Specification: Calculate the factor as the 10-day Pearson correlation between the daily return ($return) and a 'Conviction Signal', where the Conviction Signal is the 3-day lagged return multiplied by ($volume / TS_MEAN($volume, 10)).\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064292131116171,
        "ICIR": 0.0471904782508434,
        "RankIC": 0.022961676702149,
        "RankICIR": 0.1745311944608633,
        "annualized_return": 0.0713249472038566,
        "information_ratio": 1.1379839206679387,
        "max_drawdown": -0.0918045186564081
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:54:09.625003",
      "updated_at": "2026-01-15T18:54:09.625009"
    },
    "1dc7e879df593121": {
      "factor_id": "1dc7e879df593121",
      "factor_name": "VWIM_EMA3_RelVol10",
      "factor_expression": "EMA(($close / $open - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(($close / $open - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3)\" # Your output factor expression will be filled in here\n    name = \"VWIM_EMA3_RelVol10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Intraday Momentum (VWIM) factor: captures the open-to-close return scaled by relative volume (current volume divided by its 10-day average) and smoothed with a 3-day EMA to prioritize recent institutional conviction while filtering out low-volume noise.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Volume-Weighted Intraday Momentum (VWIM) factor, calculated as the open-to-close return scaled by relative volume and smoothed with a short-term Exponential Moving Average (EMA), provides a higher signal-to-noise ratio for predicting short-term returns than simple intraday gaps.\n                Concise Observation: Previous results showed that while intraday momentum is predictive (IR 0.9577), simple moving averages (5D/20D) likely lag the signal's decay, and unweighted returns fail to distinguish between high-conviction institutional flows and low-volume retail noise.\n                Concise Justification: Volume serves as a validation metric for price action; scaling the intraday return by the ratio of current volume to its historical average filters for 'informed' trading, while the EMA prioritizes recent data points to mitigate the signal-lag inherent in standard rolling means.\n                Concise Knowledge: If intraday price trends are supported by high relative volume, they indicate higher institutional conviction; when these signals are processed using decay-weighted averages (EMA) over short horizons (e.g., 3 days), they better capture the transient nature of alpha before market efficiency absorbs the trend.\n                concise Specification: The factor is defined as (Close/Open - 1) * (Volume / SMA(Volume, 10)), then smoothed using a 3-day Exponential Moving Average (EMA) to generate a final predictive value for each instrument.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058479468228565,
        "ICIR": 0.0376867169187617,
        "RankIC": 0.0224571044860769,
        "RankICIR": 0.1444330405368809,
        "annualized_return": 0.0707034454329422,
        "information_ratio": 0.9352636238015638,
        "max_drawdown": -0.1053260582417709
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:40:20.877177",
      "updated_at": "2026-01-15T17:40:20.877184"
    },
    "f101db011ea22576": {
      "factor_id": "f101db011ea22576",
      "factor_name": "Ranked_Squeeze_Momentum_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the volatility squeeze hypothesis. It measures the intensity of price tightness (inverse of the 5-day range normalized by 20-day volatility) and scales it by the sign of the recent 5-day trend to ensure directional alignment with the breakout.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.421657",
      "updated_at": "2026-01-14T17:23:48.421663"
    },
    "89b598f9778770de": {
      "factor_id": "89b598f9778770de",
      "factor_name": "VW_Range_Position_Exhaustion_5D",
      "factor_expression": "($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Range_Position_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the distance between the current close and the 5-day volume-weighted average price (VWAP) normalized by the range. It targets mean reversion by identifying when price moves too far from the volume-weighted conviction level relative to its 5-day trend.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.067321",
      "updated_at": "2026-01-14T17:21:26.067327"
    },
    "b6d66145f7cdc66f": {
      "factor_id": "b6d66145f7cdc66f",
      "factor_name": "Conditional_Trend_Stability_2D",
      "factor_expression": "(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Trend_Stability_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional logic where the 20-day trend stability (RSQR) is only considered if the 2-day volume-weighted return is positive. It focuses on 'quiet' institutional accumulation that is just beginning to break out with volume support, filtering out stagnant or decaying trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.137115",
      "updated_at": "2026-01-14T17:43:57.137122"
    },
    "0b1696dec7b25994": {
      "factor_id": "0b1696dec7b25994",
      "factor_name": "ZScore_RSQR20_VWAP_Momentum_2D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_RSQR20_VWAP_Momentum_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trend continuations by multiplying the cross-sectional Z-score of price trend stability (R-squared of close prices over 20 days) with the cross-sectional Z-score of a 2-day volume-weighted return. This ensures that long-term structural stability is validated by immediate volume-supported price action.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.064610",
      "updated_at": "2026-01-14T17:43:57.064617"
    },
    "87e41321572b0d24": {
      "factor_id": "87e41321572b0d24",
      "factor_name": "Squeeze_Efficiency_Interaction_10D",
      "factor_expression": "TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Efficiency_Interaction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines the volatility squeeze concept with the direction of the 10-day price move. It uses the ratio of the 20-day standard deviation to the 5-day high-low range to identify periods of expansion potential, weighted by the 10-day return to filter for bullish momentum.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.455370",
      "updated_at": "2026-01-14T17:23:48.455376"
    },
    "3656e978261fcb3a": {
      "factor_id": "3656e978261fcb3a",
      "factor_name": "Trend_Exhaustion_Index_V1",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Index_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion signals by multiplying the 10-day price residual (deviation from trend) with a 5-day smoothed price efficiency ratio and a 20-day relative volume. High values indicate a 'blow-off' climax where price over-extension is met with high volume and weakening conviction.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.380256",
      "updated_at": "2026-01-14T20:37:56.380262"
    },
    "8a3c3da6922f3d71": {
      "factor_id": "8a3c3da6922f3d71",
      "factor_name": "Efficiency_Filtered_Residual_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Filtered_Residual_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price over-extension and smoothed efficiency. It identifies assets where the price has deviated significantly from its 10-day trend while the 'quality' of the move (efficiency) is low, suggesting a higher probability of reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.411997",
      "updated_at": "2026-01-14T20:37:56.412003"
    },
    "5936a1ec35f7b5b4": {
      "factor_id": "5936a1ec35f7b5b4",
      "factor_name": "Efficiency_Rank_Reversal_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Rank_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between price efficiency and cross-sectional price extremes. It uses the 5-day Efficiency Ratio (net displacement over total movement) and weights it by the inverse of the cross-sectional rank of the 20-day price position to highlight overextended, inefficient trends.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.679134",
      "updated_at": "2026-01-15T18:48:21.679140"
    },
    "4e50237f8538ced2": {
      "factor_id": "4e50237f8538ced2",
      "factor_name": "Laggard_Sensitivity_Leader_Conviction",
      "factor_expression": "(RANK($volume) < 0.5 && RANK(TS_STD($return, 10)) < 0.25) ? MEAN(TS_ZSCORE(TS_PCTCHANGE($close, 3), 10) * (TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "",
      "factor_description": "Calculates the conviction-weighted momentum of the top quintile of stocks by volume and projects it onto stocks with low idiosyncratic volatility and low volume. The volume shock is capped to prevent outliers from dominating the signal.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.112593",
      "updated_at": "2026-01-15T17:47:09.112598"
    },
    "cc5ead208c103e71": {
      "factor_id": "cc5ead208c103e71",
      "factor_name": "Churn_Volatility_Adjusted_ER_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Churn_Volatility_Adjusted_ER_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'wasteful' price action by scaling the 5-day Efficiency Ratio by the negative sign of the recent price trend. It specifically looks for low-efficiency moves (churn) that occur during high-volatility periods, signaling that the current trend direction is losing its strength.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.698797",
      "updated_at": "2026-01-15T18:48:21.698803"
    },
    "502409b41bea1fbd": {
      "factor_id": "502409b41bea1fbd",
      "factor_name": "Exhaustion_Reversal_Score_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Score_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the volume-price divergence hypothesis. It calculates the 10-day reversal and weights it by the time-series rank of the inverse volume, prioritizing reversals that occur on declining or low relative volume.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.215328",
      "updated_at": "2026-01-14T17:02:57.215334"
    },
    "8c475560c22dde7f": {
      "factor_id": "8c475560c22dde7f",
      "factor_name": "Kaufman_Exhaustion_ZScore_5D_20D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Kaufman_Exhaustion_ZScore_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by multiplying the 5-day Kaufman Efficiency Ratio (ER) with the negative of the 20-day price Z-score. A low ER (high path length relative to displacement) at price extremes (high Z-score) suggests 'churning' and imminent mean reversion.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.658788",
      "updated_at": "2026-01-15T18:48:21.658796"
    },
    "57a1a7219e6a9c5e": {
      "factor_id": "57a1a7219e6a9c5e",
      "factor_name": "Divergence_ZScore_Exhaustion_20D",
      "factor_expression": "TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Divergence_ZScore_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price positioning and volume intensity. It calculates the Z-score of the current price relative to its 20-day history and multiplies it by the volume ratio. A high price Z-score combined with a high volume ratio often signals a liquidity-thin peak or trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.198967",
      "updated_at": "2026-01-14T20:37:23.198973"
    },
    "2049a9a4215625f3": {
      "factor_id": "2049a9a4215625f3",
      "factor_name": "Relative_Resistance_Volume_Surge_20D",
      "factor_expression": "RANK((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) + RANK($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) + RANK($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Resistance_Volume_Surge_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures how close the current price is to its 20-day resistance (max price) relative to its typical volatility, adjusted by the intensity of recent volume. It uses RANK to normalize the components cross-sectionally to identify the most exhausted stocks in the universe.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.214434",
      "updated_at": "2026-01-14T20:37:23.214439"
    },
    "4eb1402e756c4b8e": {
      "factor_id": "4eb1402e756c4b8e",
      "factor_name": "Volatility_Squeeze_Breakout_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Squeeze_Breakout_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'volatility springs' by calculating the ratio of long-term volatility to the recent price range, then multiplying by the 5-day return to capture the direction of the breakout. A high value indicates a tight consolidation followed by a positive price expansion.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.387142",
      "updated_at": "2026-01-14T17:23:48.387149"
    },
    "7ea4a5dcdae76558": {
      "factor_id": "7ea4a5dcdae76558",
      "factor_name": "Conviction_Lead_Lag_Corr_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Lead_Lag_Corr_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 10-day rolling correlation between current returns and a conviction signal. The conviction signal is defined as the 3-day lagged return scaled by the ratio of current volume to its 10-day moving average, highlighting price moves backed by relative liquidity.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day rolling correlation between current returns and a 3-day lagged, volume-scaled return signal captures high-conviction price discovery trends more effectively than longer-lag models.\n                Concise Observation: The previous 5-day lag and 20-day window were too slow to capture decaying lead-lag effects; shortening the lag to 3 days and using a volume ratio instead of a Z-score improved the Information Ratio and signal responsiveness.\n                Concise Justification: Shorter lags capture more immediate information diffusion, while scaling lagged returns by the volume ratio (current volume / mean volume) emphasizes price moves that occurred with high relative conviction, filtering out noise from low-liquidity sessions.\n                Concise Knowledge: If the lag period is reduced to 3 days and the lagged signal is scaled by the ratio of volume to its 10-day moving average, then the resulting correlation identifies short-term momentum backed by liquidity, which is more predictive of immediate price persistence.\n                concise Specification: Calculate the factor as the 10-day Pearson correlation between the daily return ($return) and a 'Conviction Signal', where the Conviction Signal is the 3-day lagged return multiplied by ($volume / TS_MEAN($volume, 10)).\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064292131116171,
        "ICIR": 0.0471904782508434,
        "RankIC": 0.022961676702149,
        "RankICIR": 0.1745311944608633,
        "annualized_return": 0.0713249472038566,
        "information_ratio": 1.1379839206679387,
        "max_drawdown": -0.0918045186564081
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:54:09.604270",
      "updated_at": "2026-01-15T18:54:09.604278"
    },
    "313646e5c487fee1": {
      "factor_id": "313646e5c487fee1",
      "factor_name": "Steady_Trend_Conviction_Rank_20D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Steady_Trend_Conviction_Rank_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that identifies high-conviction trends by scaling the 20-day price return by the inverse of volume volatility. It uses the ratio of mean volume to volume standard deviation as a multiplier for price momentum, effectively amplifying signals where volume is consistent and stable.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.872162",
      "updated_at": "2026-01-14T20:26:55.872168"
    },
    "bb649f19188ec110": {
      "factor_id": "bb649f19188ec110",
      "factor_name": "VW_Price_Slope_Divergence_5D",
      "factor_expression": "REGBETA($close, SEQUENCE(5), 5) - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGBETA($close, SEQUENCE(5), 5) - (TS_SUM((($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)) * $volume, 5) / TS_SUM($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Slope_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the 5-day price trend (regression slope) and the volume-weighted relative position of the price within its high-low range. A high price slope combined with a low volume-weighted position suggests a 'hollow' trend prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.000804",
      "updated_at": "2026-01-14T17:21:26.000811"
    },
    "8ea1bf1386c5b50e": {
      "factor_id": "8ea1bf1386c5b50e",
      "factor_name": "VWAP_Efficiency_Accel_20D",
      "factor_expression": "TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Efficiency_Accel_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the interaction between price-volume efficiency and the acceleration of liquidity-adjusted momentum. It measures the deviation of the close price from the VWAP (approximated by (high+low+close)/3), normalized by 20-day return volatility, and scales it by the 5-day change in volume-weighted price momentum.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.322550",
      "updated_at": "2026-01-14T17:29:39.322557"
    },
    "23101d70fb6bc583": {
      "factor_id": "23101d70fb6bc583",
      "factor_name": "Dynamic_LeadLag_Momentum_Filter",
      "factor_expression": "(RANK(TS_STD($return, 10)) < 0.25) ? MEAN((TS_PCTCHANGE($close, 3) * MIN(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8), 3)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(TS_PCTCHANGE($close, 3), (TS_MEAN($volume, 3) / TS_MEAN($volume, 20)) > 1.5)) * (RANK(TS_STD($return, 10)) < 0.25 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Dynamic_LeadLag_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies the momentum of high-conviction leaders (volume surge) and applies it to low-volatility laggards. It uses a 3-day window for momentum and volume shocks to capture faster information diffusion, while using the cross-sectional mean of leader signals to drive laggard expectations.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.093634",
      "updated_at": "2026-01-15T17:47:09.093641"
    },
    "0a2809d6fd472731": {
      "factor_id": "0a2809d6fd472731",
      "factor_name": "Efficiency_Volatility_Ratio_20D",
      "factor_expression": "RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of price discovery by comparing the price-VWAP ratio to the 20-day standard deviation of returns. It targets stocks where price is trending above the volume-weighted average under conditions of low relative volatility, which indicates a stable, high-conviction trend.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.391667",
      "updated_at": "2026-01-14T17:29:39.391673"
    },
    "1d5804d105216831": {
      "factor_id": "1d5804d105216831",
      "factor_name": "Climax_Reversal_Signal_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Climax_Reversal_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion index targeting market climaxes. It combines the 10-day price residual with the 5-day average efficiency, but uses Z-scores to normalize the components before interaction, specifically highlighting cases where volume is significantly above its 20-day average.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.396389",
      "updated_at": "2026-01-14T20:37:56.396394"
    },
    "ff9db33c946c0706": {
      "factor_id": "ff9db33c946c0706",
      "factor_name": "ZScore_VWIM_ShortTerm",
      "factor_expression": "ZSCORE(EMA(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(EMA(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3))\" # Your output factor expression will be filled in here\n    name = \"ZScore_VWIM_ShortTerm\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Cross-sectionally standardized version of the Volume-Weighted Intraday Momentum. It identifies stocks with the strongest volume-validated intraday trends relative to the market, smoothed by a 3-day EMA to capture decaying alpha.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Volume-Weighted Intraday Momentum (VWIM) factor, calculated as the open-to-close return scaled by relative volume and smoothed with a short-term Exponential Moving Average (EMA), provides a higher signal-to-noise ratio for predicting short-term returns than simple intraday gaps.\n                Concise Observation: Previous results showed that while intraday momentum is predictive (IR 0.9577), simple moving averages (5D/20D) likely lag the signal's decay, and unweighted returns fail to distinguish between high-conviction institutional flows and low-volume retail noise.\n                Concise Justification: Volume serves as a validation metric for price action; scaling the intraday return by the ratio of current volume to its historical average filters for 'informed' trading, while the EMA prioritizes recent data points to mitigate the signal-lag inherent in standard rolling means.\n                Concise Knowledge: If intraday price trends are supported by high relative volume, they indicate higher institutional conviction; when these signals are processed using decay-weighted averages (EMA) over short horizons (e.g., 3 days), they better capture the transient nature of alpha before market efficiency absorbs the trend.\n                concise Specification: The factor is defined as (Close/Open - 1) * (Volume / SMA(Volume, 10)), then smoothed using a 3-day Exponential Moving Average (EMA) to generate a final predictive value for each instrument.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058479468228565,
        "ICIR": 0.0376867169187617,
        "RankIC": 0.0224571044860769,
        "RankICIR": 0.1444330405368809,
        "annualized_return": 0.0707034454329422,
        "information_ratio": 0.9352636238015638,
        "max_drawdown": -0.1053260582417709
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:40:20.896797",
      "updated_at": "2026-01-15T17:40:20.896804"
    },
    "fb42bc4cc1cea0c8": {
      "factor_id": "fb42bc4cc1cea0c8",
      "factor_name": "VWM_Normalized_CV_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWM_Normalized_CV_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 20-day price momentum (percentage change) and normalizes it by the volume coefficient of variation (CV) over the same period. The CV is the ratio of the standard deviation of volume to the mean volume. By dividing momentum by CV, the factor penalizes price trends accompanied by erratic or unstable volume, favoring steady, high-conviction accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.857108",
      "updated_at": "2026-01-14T20:26:55.857114"
    },
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T17:06:25.115468"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T17:06:25.147238"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T17:06:25.178740"
    },
    "a6bae1dc4dfa3dda": {
      "factor_id": "a6bae1dc4dfa3dda",
      "factor_name": "Price_Volume_Efficiency_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Efficiency_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of the 5-day cumulative return to the 5-day cumulative volume turnover. A high ratio indicates a 'fragile' price move on low volume support, suggesting a higher probability of mean reversion. The ratio is cross-sectionally standardized using Z-score to identify extremes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.702263",
      "updated_at": "2026-01-14T17:25:41.702270"
    },
    "974be850a4998b4d": {
      "factor_id": "974be850a4998b4d",
      "factor_name": "Efficiency_Exhaustion_Index_5D",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8), 5)",
      "factor_implementation_code": "",
      "factor_description": "This factor targets liquidity-driven price spikes by measuring the 5-day price impact per unit of volume, further normalized by the time-series volatility of the ratio. It captures instances where price moves are 'too efficient' relative to historical norms, signaling potential exhaustion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.738072",
      "updated_at": "2026-01-14T17:25:41.738079"
    },
    "824685211c1a9db6": {
      "factor_id": "824685211c1a9db6",
      "factor_name": "Ranked_Price_Impact_Ratio_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Price_Impact_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 5-day return relative to the total volume traded, applying a cross-sectional rank to identify stocks with the most extreme price-volume efficiency. This helps isolate stocks where the price has moved significantly on relatively low volume, indicating a lack of fundamental absorption.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.771471",
      "updated_at": "2026-01-14T17:25:41.771477"
    },
    "5d9461843c6ecdcb": {
      "factor_id": "5d9461843c6ecdcb",
      "factor_name": "Normalized_Squeeze_Efficiency_ZScore_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Squeeze_Efficiency_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the volatility squeeze intensity relative to its 20-day history, then weighting it by the 10-day Efficiency Ratio. Instead of a raw price range, it uses the average true range (high-low) over 5 days to normalize the squeeze denominator and avoid outliers, then applies a cross-sectional Z-score to the final interaction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.048570",
      "updated_at": "2026-01-14T17:29:05.048577"
    },
    "11d3367e5ad2e843": {
      "factor_id": "11d3367e5ad2e843",
      "factor_name": "Relative_Compression_Breakout_Rank_15D",
      "factor_expression": "RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Breakout_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'spring-loading' effect of price compression by comparing the 20-day volatility to the 10-day price range, using a logarithmic transformation to handle non-stationarity. It is then combined with the 10-day RSI to ensure the breakout occurs within a strong momentum context, avoiding stagnant consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.084527",
      "updated_at": "2026-01-14T17:29:05.084533"
    },
    "f41fea1bcefd3200": {
      "factor_id": "f41fea1bcefd3200",
      "factor_name": "Squeeze_Directional_Efficiency_10D",
      "factor_expression": "TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Directional_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the quality of the squeeze by interacting a 20-day volatility-to-range ratio with the Efficiency Ratio, but uses a 10-day moving average of the interaction to smooth out high-frequency noise. It uses the difference between close and open as a proxy for intraday conviction within the range calculation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.118341",
      "updated_at": "2026-01-14T17:29:05.118347"
    },
    "0e1e6895d262970e": {
      "factor_id": "0e1e6895d262970e",
      "factor_name": "VWPP_Persistence_20D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 20) * ($close / (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 20) * ($close / ((TS_SUM($volume, 10) > 0) ? (TS_SUM($close * $volume, 10) / TS_SUM($volume, 10)) : $close))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Price Persistence (VWPP) calculates the 20-day average of daily returns weighted by the cross-sectional rank of volume. This captures momentum supported by relative liquidity. It is then scaled by the ratio of the current price to the 10-day volume-weighted average price (VWAP) to ensure the signal is active during high-conviction price trends.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.245004",
      "updated_at": "2026-01-14T17:33:11.245011"
    },
    "7e17d6f59c434e2c": {
      "factor_id": "7e17d6f59c434e2c",
      "factor_name": "VWPP_ZScore_Filtered_20D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VWPP_ZScore_Filtered_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Weighted Price Persistence factor that applies a cross-sectional Z-score to the volume-weighted return component to improve comparability. The factor is activated only when the price is above the 10-day VWAP, identifying efficient momentum regimes.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.278927",
      "updated_at": "2026-01-14T17:33:11.278933"
    },
    "5f773998e535e4cb": {
      "factor_id": "5f773998e535e4cb",
      "factor_name": "VWPP_Efficiency_Ratio_15D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Efficiency_Ratio_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between volume-ranked returns and price efficiency. It uses a 15-day window for the volume-weighted return and normalizes the distance from the 10-day VWAP using the 20-day price standard deviation to account for varying volatility levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.312438",
      "updated_at": "2026-01-14T17:33:11.312444"
    },
    "dc158e72b35d4132": {
      "factor_id": "dc158e72b35d4132",
      "factor_name": "WRSQR_V_Divergence_Product",
      "factor_expression": "RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"WRSQR_V_Divergence_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR) with a volume-price divergence ratio. WRSQR20 is calculated as the squared correlation between close prices and a linear sequence over 20 days, weighted by DECAYLINEAR to prioritize recent trend consistency. V_Divergence is the ratio of the 5-day VWAP to the 5-day SMA, acting as a filter for institutional accumulation. The final factor is the product of their cross-sectional ranks.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.447954",
      "updated_at": "2026-01-14T18:02:27.447961"
    },
    "6b09649c0a1463db": {
      "factor_id": "6b09649c0a1463db",
      "factor_name": "Decay_Stability_Accumulation_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decay_Stability_Accumulation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the stability-momentum hypothesis. It uses the 20-day weighted R-squared (via DECAYLINEAR) to capture 'fresh' trend stability and scales it by the 5-day VWAP-to-SMA ratio to identify volume-supported price levels. Both components are cross-sectionally standardized using ZSCORE to ensure equal contribution.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.485711",
      "updated_at": "2026-01-14T18:02:27.485718"
    },
    "96f61e329e278ad9": {
      "factor_id": "96f61e329e278ad9",
      "factor_name": "Weighted_Trend_Conviction_Index",
      "factor_expression": "RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))\" # Your output factor expression will be filled in here\n    name = \"Weighted_Trend_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high recent trend stability that are also trading above their volume-weighted average price relative to their simple average. It uses a 20-day decay-weighted correlation to measure stability and a 5-day divergence ratio to measure conviction, combined via RANK to handle non-linearities.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.523328",
      "updated_at": "2026-01-14T18:02:27.523335"
    },
    "fc05bdc64f3d5cf3": {
      "factor_id": "fc05bdc64f3d5cf3",
      "factor_name": "Volume_Efficiency_Correlation_10D",
      "factor_expression": "(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, DELTA($volume, 1), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, DELTA($volume, 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Efficiency_Correlation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction accumulation phases by measuring the 10-day price return per unit of volume volatility, filtered by the correlation between returns and volume changes. High 'efficiency' (return/volatility) combined with positive price-volume correlation suggests institutional buying with minimal price friction.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.028160",
      "updated_at": "2026-01-14T20:33:07.028170"
    },
    "c821041764f42dd2": {
      "factor_id": "c821041764f42dd2",
      "factor_name": "Ranked_Accumulation_Efficiency_10D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Accumulation_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the Volume Efficiency hypothesis. It ranks the 10-day return-to-volume-volatility ratio and scales it by the strength of the price-volume relationship. This isolates stocks showing steady price appreciation on consistent, trend-aligned volume.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.067500",
      "updated_at": "2026-01-14T20:33:07.067511"
    },
    "53ffb45a85127135": {
      "factor_id": "53ffb45a85127135",
      "factor_name": "Filtered_Volume_Momentum_10D",
      "factor_expression": "(TS_PCTCHANGE($close, 10) / MAX(TS_ZSCORE($volume, 10), 1)) * MAX(TS_CORR($return, $volume, 10), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 10) / MAX(TS_ZSCORE($volume, 10), 1)) * MAX(TS_CORR($return, $volume, 10), 0)\" # Your output factor expression will be filled in here\n    name = \"Filtered_Volume_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the 10-day momentum scaled by the inverse of volume dispersion, specifically when the price-volume correlation is positive. It uses Z-scoring for volume volatility to ensure the penalty for erratic liquidity is normalized across the universe.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.110727",
      "updated_at": "2026-01-14T20:33:07.110746"
    },
    "2bedf15e4751de80": {
      "factor_id": "2bedf15e4751de80",
      "factor_name": "Price_Volume_Accel_Divergence_10D",
      "factor_expression": "RANK(TS_MEAN($return, 10)) - RANK(TS_PCTCHANGE($volume, 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return, 10)) - RANK(TS_PCTCHANGE($volume, 3))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Accel_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend exhaustion by measuring the spread between the cross-sectional rank of 10-day price momentum and the cross-sectional rank of 3-day volume acceleration. A high volume acceleration paired with low price momentum (negative spread) suggests liquidity absorption and a potential peak.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:43.989130",
      "updated_at": "2026-01-14T20:40:43.989137"
    },
    "c2ac425b322611c4": {
      "factor_id": "c2ac425b322611c4",
      "factor_name": "Exhaustion_Rank_Spread_10D",
      "factor_expression": "RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Rank_Spread_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the price-volume divergence hypothesis that uses the 10-day time-series rank of returns compared to the 10-day time-series rank of volume growth. It targets assets where volume is reaching extreme historical levels (high rank) while price gains are lagging (low rank).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.005509",
      "updated_at": "2026-01-14T20:40:44.005515"
    },
    "d62c2a86081649c0": {
      "factor_id": "d62c2a86081649c0",
      "factor_name": "Churn_Intensity_Index_10D",
      "factor_expression": "RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)\" # Your output factor expression will be filled in here\n    name = \"Churn_Intensity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'churning' behavior by calculating the ratio of ranked price momentum to ranked volume volatility. It identifies periods where high volume activity does not translate into proportional price movement, signaling a loss of trend conviction.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.021513",
      "updated_at": "2026-01-14T20:40:44.021519"
    },
    "cf8d9a3eb9e997de": {
      "factor_id": "cf8d9a3eb9e997de",
      "factor_name": "Trend_Divergence_Efficiency_Slope_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Divergence_Efficiency_Slope_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by capturing the divergence between price deviation from its 10-day linear trend and the 5-day slope of price efficiency. A high residual paired with a declining efficiency slope indicates a trend losing conviction. To avoid duplicated sub-expressions, the efficiency is calculated using the ratio of body to the average true range proxy.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.962393",
      "updated_at": "2026-01-14T20:45:46.962399"
    },
    "56648b1aee6f7d28": {
      "factor_id": "56648b1aee6f7d28",
      "factor_name": "Efficiency_Decay_Residual_Interaction_15D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Decay_Residual_Interaction_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the interaction between price over-extension and the decay in price movement quality. It uses the 10-day price residual and the 5-day change in a smoothed efficiency ratio (body size relative to high-low range), focusing on the negative momentum of efficiency as a signal for trend failure.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.978971",
      "updated_at": "2026-01-14T20:45:46.978977"
    },
    "0e929b6dbe2a549a": {
      "factor_id": "0e929b6dbe2a549a",
      "factor_name": "Relative_Exhaustion_Divergence_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))\" # Your output factor expression will be filled in here\n    name = \"Relative_Exhaustion_Divergence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the price trend (10-day residual) and the trend of 'clean' price moves. Instead of simple KMID, it uses the ratio of the absolute return to the total daily range, smoothed over 5 days, and looks for its 3-day slope to identify exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.995460",
      "updated_at": "2026-01-14T20:45:46.995465"
    },
    "2ced7731281f6246": {
      "factor_id": "2ced7731281f6246",
      "factor_name": "Stretched_Reversal_Divergence_10D",
      "factor_expression": "(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Stretched_Reversal_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by scaling the negative 10-day return by its 20-day volatility and multiplying it by the 5-day change in the price-volume correlation. This captures 'stretched' price moves where the relationship between price and volume is weakening, indicating trend exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.343160",
      "updated_at": "2026-01-14T17:12:56.343166"
    },
    "a539c30693a56101": {
      "factor_id": "a539c30693a56101",
      "factor_name": "Volatility_Scaled_Exhaustion_Rank",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Scaled_Exhaustion_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that ranks the intensity of a price reversal. It combines the 10-day return normalized by 20-day volatility with the momentum of the price-volume correlation. It targets stocks where price moves are extreme relative to volatility and conviction (volume-price link) is shifting.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.376043",
      "updated_at": "2026-01-14T17:12:56.376049"
    },
    "6411ef0aaf297143": {
      "factor_id": "6411ef0aaf297143",
      "factor_name": "ZScore_Reversal_Conviction_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Reversal_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 10-day reversal potential by calculating the Z-score of returns and weighting it by the change in price-volume correlation. It uses Z-scores to identify statistically significant 'stretched' moves and filters them by the divergence in volume flow conviction.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.408776",
      "updated_at": "2026-01-14T17:12:56.408783"
    },
    "befa3a7f6f097a80": {
      "factor_id": "befa3a7f6f097a80",
      "factor_name": "Vol_Adjusted_Price_Impact_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Price_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the ratio of 5-day cumulative return to the 5-day average volume, normalized by the 5-day standard deviation of volume. This normalization isolates high-conviction liquidity exhaustion by filtering out noisy volume spikes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.325818",
      "updated_at": "2026-01-14T17:30:23.325824"
    },
    "3fd5eeb189991af8": {
      "factor_id": "3fd5eeb189991af8",
      "factor_name": "Liquidity_Exhaustion_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the volatility-adjusted price impact per unit of volume. It divides the 5-day return by the coefficient of variation of volume over the same period to highlight 'fragile' price moves that occur on stable but low liquidity, signaling potential reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.359575",
      "updated_at": "2026-01-14T17:30:23.359581"
    },
    "d83bb851f311b99a": {
      "factor_id": "d83bb851f311b99a",
      "factor_name": "Robust_Price_Efficiency_Rank_5D",
      "factor_expression": "RANK((DELTA($close, 5) / $close) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Price_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the price-volume efficiency hypothesis. It uses the 5-day return divided by the 5-day median volume, further adjusted by the volume's 5-day standard deviation to ensure the signal is not driven by a single day's volume outlier.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.394693",
      "updated_at": "2026-01-14T17:30:23.394699"
    },
    "be56412e2f4c7223": {
      "factor_id": "be56412e2f4c7223",
      "factor_name": "VW_Efficiency_Squeeze_Tanh_10D",
      "factor_expression": "((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Squeeze_Tanh_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by interacting a squashed Volatility Squeeze Z-score with a Volume-Weighted Efficiency Ratio. The squeeze is calculated as the ratio of 20-day return volatility to the 10-day price range, normalized via TS_ZSCORE and bounded by a Tanh-like transformation to handle outliers. The Volume-Weighted Efficiency Ratio ensures that price movements are supported by significant trading activity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.297230",
      "updated_at": "2026-01-14T17:35:59.297237"
    },
    "c66ee9481bdf59cf": {
      "factor_id": "c66ee9481bdf59cf",
      "factor_name": "Robust_Squeeze_VWER_Interaction",
      "factor_expression": "RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VWER_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified interaction factor between a volatility compression metric and volume-weighted price efficiency. It uses a 10-day window for the squeeze and efficiency measures, applying a rank-based normalization to the squeeze intensity to ensure cross-sectional stability and combining it with a volume-scaled price velocity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.334867",
      "updated_at": "2026-01-14T17:35:59.334874"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T17:36:23.056545"
    },
    "06b6f311ac141eab": {
      "factor_id": "06b6f311ac141eab",
      "factor_name": "ZScored_Volume_Persistence_Divergence",
      "factor_expression": "(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Persistence_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the momentum divergence hypothesis that uses cross-sectional Z-scores to compare 15-day volume-weighted conviction against the 5-day price trend, ensuring the divergence signal is comparable across the universe before being scaled by the asset's relative volatility.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.092745",
      "updated_at": "2026-01-14T17:36:23.092750"
    },
    "79fbd5019fd5aa30": {
      "factor_id": "79fbd5019fd5aa30",
      "factor_name": "Smoothed_Momentum_Conviction_Ratio",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Momentum_Conviction_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the ratio of volume-supported persistence to short-term trend magnitude. By using the ratio instead of a difference, it identifies stocks where institutional conviction (15-day) significantly outweighs recent price action (5-day), normalized by the 20-day high-low range.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.128528",
      "updated_at": "2026-01-14T17:36:23.128535"
    },
    "a539ea5d667c40ef": {
      "factor_id": "a539ea5d667c40ef",
      "factor_name": "Smoothed_Stability_Accumulation_ZScore_3D",
      "factor_expression": "ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), DECAYLINEAR(SEQUENCE(20), 20), 20), 2)) + ZSCORE(TS_MEAN((WMA($close * $volume, 5) / (WMA($volume, 5) + 1e-8)) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5), 3))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Stability_Accumulation_ZScore_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR20) with a smoothed volume-price divergence ratio. WRSQR20 captures trend consistency by prioritizing recent price action through a linear decay. The divergence ratio (VWAP5/SMA5) is smoothed using a 3-day SMA to filter out idiosyncratic volume shocks. The two components are aggregated using cross-sectional Z-scores to ensure scale stability and reduce drawdown risk.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.092364",
      "updated_at": "2026-01-14T18:23:40.092371"
    },
    "a49365e40349aa7e": {
      "factor_id": "a49365e40349aa7e",
      "factor_name": "Robust_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Robust_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "To avoid duplicated sub-expressions while maintaining the hypothesis, this factor uses WMA (weighted moving average) for the volume-price divergence calculation instead of TS_SUM, and replaces the standard R-squared with a correlation between price and a time-sequence, smoothed by a 3-day window. It targets institutional accumulation by identifying where weighted average prices stay above simple averages during stable trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.131909",
      "updated_at": "2026-01-14T18:23:40.131915"
    },
    "8be05e4ee9f1457a": {
      "factor_id": "8be05e4ee9f1457a",
      "factor_name": "Decayed_Stability_Volume_Ratio",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Decayed_Stability_Volume_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor utilizes the ratio of the 5-day EMA of price to its 5-day SMA as a proxy for divergence, combined with a 20-day price stability measure. By using EMA in the divergence numerator, it places more weight on recent volume-driven price shifts. The final factor is the sum of the Z-scored stability and the smoothed divergence ratio to improve the Information Ratio.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.170205",
      "updated_at": "2026-01-14T18:23:40.170211"
    },
    "bdb78b063c6c4d5b": {
      "factor_id": "bdb78b063c6c4d5b",
      "factor_name": "VWRE10_Efficiency_Factor",
      "factor_expression": "TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWRE10_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 10-day Volume-Weighted Return Efficiency (VWRE10) factor identifies sustainable price trends by scaling the 10-day return by the inverse of the volume coefficient of variation. This prioritizes moves supported by high, stable liquidity, filtering out speculative spikes on erratic volume.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.490223",
      "updated_at": "2026-01-14T20:36:31.490230"
    },
    "b67247ca8bd6c992": {
      "factor_id": "b67247ca8bd6c992",
      "factor_name": "Ranked_Liquidity_Stability_Momentum_10D",
      "factor_expression": "RANK(TS_SUM($return, 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Liquidity_Stability_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 10-day price momentum with a cross-sectional rank of volume stability. It identifies stocks where the recent trend is backed by consistent institutional participation relative to the broader market, using the ratio of mean volume to volume standard deviation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.505921",
      "updated_at": "2026-01-14T20:36:31.505927"
    },
    "54e6425649423ec0": {
      "factor_id": "54e6425649423ec0",
      "factor_name": "ZScored_Volume_Efficiency_10D",
      "factor_expression": "ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the Volume-Weighted Return Efficiency factor. It applies a cross-sectional Z-score to the 10-day return scaled by the volume signal-to-noise ratio, ensuring the factor is robust across different market regimes and stock scales.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.521215",
      "updated_at": "2026-01-14T20:36:31.521220"
    },
    "ae40ea3dc6632f44": {
      "factor_id": "ae40ea3dc6632f44",
      "factor_name": "Price_Efficiency_Volume_Exhaustion_15D",
      "factor_expression": "(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (TS_ZSCORE($volume, 15) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (TS_ZSCORE($volume, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Volume_Exhaustion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score) coincide with low price efficiency. Price efficiency is the ratio of net displacement to the total path traveled. A low value indicates 'churning' (high effort, low result), signaling imminent trend reversal.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.113249",
      "updated_at": "2026-01-14T20:45:17.113256"
    },
    "e8e67ecb849a3d87": {
      "factor_id": "e8e67ecb849a3d87",
      "factor_name": "Volume_Surge_Efficiency_Divergence_15D",
      "factor_expression": "RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Efficiency_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the exhaustion hypothesis that uses the cross-sectional rank of price efficiency divided by the cross-sectional rank of volume Z-scores. It targets the non-linear nature of market exhaustion by identifying assets where the 'effort' (volume) is disproportionately high compared to the 'result' (price efficiency) relative to other stocks.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.129870",
      "updated_at": "2026-01-14T20:45:17.129876"
    },
    "563bf561c88c4e3f": {
      "factor_id": "563bf561c88c4e3f",
      "factor_name": "Churn_Intensity_Reversion_15D",
      "factor_expression": "TS_ZSCORE($volume, 15) * (TS_SUM(ABS(DELTA($close, 1)), 15) / (ABS(DELTA($close, 15)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume, 15) / (ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Churn_Intensity_Reversion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures 'churn intensity' by calculating the ratio of the 15-day volume Z-score to the price efficiency. High churn (extreme volume with low efficiency) results in a high factor value, which is expected to predict negative future returns as it signals institutional distribution at a peak.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.146382",
      "updated_at": "2026-01-14T20:45:17.146388"
    },
    "e99c2ba0795b9e8a": {
      "factor_id": "e99c2ba0795b9e8a",
      "factor_name": "Volume_Adjusted_Exhaustion_Divergence_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Adjusted_Exhaustion_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies terminal trend exhaustion by measuring the divergence between price over-extension and volume-price efficiency. It calculates the product of the 10-day price residual (deviation from linear trend) and the negative 5-day slope of volume efficiency. Volume efficiency is defined as the absolute return per unit of relative volume. A high price residual combined with a declining volume efficiency suggests 'churning' at price extremes, signaling a potential reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.613072",
      "updated_at": "2026-01-14T20:55:45.613078"
    },
    "899e40ac86d91875": {
      "factor_id": "899e40ac86d91875",
      "factor_name": "Efficiency_Decay_Volume_Climax_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / TS_MEAN($volume, 20) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "",
      "factor_description": "This factor captures the 'conviction' dimension of trend exhaustion. It focuses on the interaction between price over-extension and the recent decay in price-volume efficiency. It identifies stocks where price is significantly above its 10-day trend while the 'result' (return) per 'effort' (volume) is diminishing over a 5-day window. The negative slope of efficiency acts as a lead indicator for liquidity exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.630266",
      "updated_at": "2026-01-14T20:55:45.630272"
    },
    "d39bc944ba333c67": {
      "factor_id": "d39bc944ba333c67",
      "factor_name": "NonLinear_Churn_Exhaustion_Index",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Churn_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'churning' phase of a trend where high volume fails to produce proportional price progress. It combines the 10-day price residual with the 5-day average of volume-adjusted price efficiency. By ranking both components, it highlights assets that are at extreme price deviations but showing the lowest relative efficiency in the cross-section, maximizing the probability of mean-reversion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.647215",
      "updated_at": "2026-01-14T20:55:45.647220"
    },
    "04af2bc09ff7df83": {
      "factor_id": "04af2bc09ff7df83",
      "factor_name": "Conviction_Divergence_Reversal_10D",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Divergence_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by combining price-volume divergence with volume conviction. It uses the 10-day price-volume correlation change as a measure of trend exhaustion, weighted by the 20-day volume Z-score (clipped at 0) to ensure the signal occurs during a high-conviction liquidity event. The reversal component is normalized by the 10-day price range relative to the typical body size.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.781751",
      "updated_at": "2026-01-14T17:26:49.781758"
    },
    "0965806078acfa49": {
      "factor_id": "0965806078acfa49",
      "factor_name": "Liquidity_Climax_Exhaustion_Factor",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Climax_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets reversal points where price-volume correlation breaks down during extreme volume spikes. It normalizes the 10-day return by the 10-day Median Absolute Deviation of returns to handle outliers, then scales it by the interaction of volume intensity and the 5-day shift in price-volume alignment.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.815950",
      "updated_at": "2026-01-14T17:26:49.815956"
    },
    "1a83f9422320ba4d": {
      "factor_id": "1a83f9422320ba4d",
      "factor_name": "Vol_Weighted_Exhaustion_Index",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8)) * ((TS_ZSCORE($volume, 20) > 0) ? (TS_ZSCORE($volume, 20)) : (0)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified implementation of the conviction-exhaustion hypothesis. It measures 10-day price exhaustion by dividing the 10-day return by its 10-day volatility, then multiplying by the product of the volume Z-score and the change in price-volume correlation to isolate high-volume trend decoupling.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.848804",
      "updated_at": "2026-01-14T17:26:49.848810"
    },
    "a4536c724715cb93": {
      "factor_id": "a4536c724715cb93",
      "factor_name": "Volume_Price_Asymmetry_Index_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Asymmetry_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of 5-day cumulative returns to the 5-day average volume, then scaling this impact by the relative liquidity (5-day average volume vs. 20-day average volume). High values indicate price moves on relatively low or declining liquidity, signaling potential mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.645583",
      "updated_at": "2026-01-14T17:34:27.645589"
    },
    "742224279aef2211": {
      "factor_id": "742224279aef2211",
      "factor_name": "Asymmetric_Liquidity_Impact_5D",
      "factor_expression": "RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Liquidity_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Price Asymmetry index that focuses on the 'cost' of price movement. It measures the 5-day return per unit of volume, adjusted by how the current 5-day volume compares to a longer 20-day baseline. It aims to capture 'hollow' price moves where participation is low relative to historical norms.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.680765",
      "updated_at": "2026-01-14T17:34:27.680770"
    },
    "21b119adc7849b19": {
      "factor_id": "21b119adc7849b19",
      "factor_name": "Relative_Volume_Efficiency_Rank_5D",
      "factor_expression": "ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion by comparing the magnitude of price change to the relative volume surge. It uses the ratio of 5-day absolute returns to the 5-day average volume, scaled by the 20-day volume average to normalize for stock-specific liquidity levels.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.715331",
      "updated_at": "2026-01-14T17:34:27.715337"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T17:39:41.148683"
    },
    "ba52212e001d0431": {
      "factor_id": "ba52212e001d0431",
      "factor_name": "Efficiency_Adjusted_Persistence_15D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency hypothesis that focuses on the Z-score interaction between volume-ranked returns and a price-range stability metric. It identifies assets where the conviction (volume-weighted returns) significantly outweighs the noise (price range), using Z-scores to ensure cross-sectional comparability.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.183691",
      "updated_at": "2026-01-14T17:39:41.183697"
    },
    "c52e3e585865407c": {
      "factor_id": "c52e3e585865407c",
      "factor_name": "Ranked_Conviction_Trend_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Trend_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a trend by subtracting the rank of daily price volatility (proxied by the high-low spread) from the rank of volume-weighted returns. By using ranks, it mitigates the impact of outliers and focuses on the relative efficiency of the price movement within the universe.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.220630",
      "updated_at": "2026-01-14T17:39:41.220636"
    },
    "fbf7da796f254b8c": {
      "factor_id": "fbf7da796f254b8c",
      "factor_name": "Volume_Surge_Breakout_Intensity_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Breakout_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the interaction between price momentum and a volume-weighted volatility squeeze. Instead of a raw price range, it uses the standard deviation of returns normalized by a 20-day baseline, multiplied by a volume surge ratio (5-day vs 20-day) to filter for institutional participation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.601633",
      "updated_at": "2026-01-14T17:41:01.601641"
    },
    "db32cf1b30603006": {
      "factor_id": "db32cf1b30603006",
      "factor_name": "Compressed_Momentum_Volume_Multiplier_10D",
      "factor_expression": "(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Momentum_Volume_Multiplier_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiling' effect by comparing the current 5-day return to the 20-day historical volatility, then scales this signal by the relative volume growth. It uses the ratio of 5-day average volume to 20-day average volume as a threshold-based multiplier to ensure the breakout is supported by liquidity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.638855",
      "updated_at": "2026-01-14T17:41:01.638861"
    },
    "813f4d08321676c8": {
      "factor_id": "813f4d08321676c8",
      "factor_name": "Breakout_Conviction_Index_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Breakout_Conviction_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a breakout by combining the direction of the 5-day price move with the relative volume intensity, normalized by the 20-day price volatility. It avoids raw high-low ranges to prevent outlier sensitivity, focusing instead on return-based volatility.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.674344",
      "updated_at": "2026-01-14T17:41:01.674351"
    },
    "362c428a7eea6559": {
      "factor_id": "362c428a7eea6559",
      "factor_name": "Vol_Adj_MFI_Stability_Factor",
      "factor_expression": "ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_MFI_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 20-day weighted price stability with a 5-day Money Flow Index (MFI) relative to its recent average. It uses volatility-adjusted weighting to balance the two components, ensuring that the more stable trend signal and the more reactive capital flow signal contribute proportionally based on their recent variance.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.350701",
      "updated_at": "2026-01-14T18:42:41.350708"
    },
    "dc89cc27bd12469a": {
      "factor_id": "dc89cc27bd12469a",
      "factor_name": "MFI_Surge_Trend_Alignment",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MFI_Surge_Trend_Alignment\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the MFI-Stability hypothesis focusing on the ratio of Money Flow intensity to trend consistency. It identifies stocks where capital is surging (MFI > 3-day average) while the price trend remains structurally sound (high correlation with time), normalized by cross-sectional rank to ensure robustness.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.389138",
      "updated_at": "2026-01-14T18:42:41.389144"
    },
    "f6f91286e32c9272": {
      "factor_id": "f6f91286e32c9272",
      "factor_name": "PVD_Exhaustion_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVD_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence factor identifies short-term exhaustion or breakout regimes. It scales the 5-day price return by the volume signal-to-noise ratio (Mean/STD). High values indicate price trends supported by consistent liquidity, while low values suggest erratic or noise-driven moves prone to reversal.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.448476",
      "updated_at": "2026-01-14T20:39:43.448482"
    },
    "a6c613799bd857ca": {
      "factor_id": "a6c613799bd857ca",
      "factor_name": "Consistent_Liquidity_Momentum_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Consistent_Liquidity_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day price change normalized by the volume coefficient of variation. By using a 5-day window, it captures immediate liquidity regimes. The use of TS_ZSCORE on the volume ratio helps mitigate numerical instability from low volume variance before multiplying by the short-term return.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.464430",
      "updated_at": "2026-01-14T20:39:43.464436"
    },
    "ed6041fff76a183d": {
      "factor_id": "ed6041fff76a183d",
      "factor_name": "Robust_Volume_Efficiency_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Robust_Volume_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined volume efficiency factor that uses the 5-day price return and the ratio of median volume to volume standard deviation to reduce the impact of outlier spikes. The factor is cross-sectionally ranked to ensure comparability across different liquidity profiles.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.480342",
      "updated_at": "2026-01-14T20:39:43.480349"
    },
    "dd47681204cca2e0": {
      "factor_id": "dd47681204cca2e0",
      "factor_name": "Idiosyncratic_Churn_Volatility_10D",
      "factor_expression": "RANK(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8)) * RANK(TS_ZSCORE($volume, 10)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8)) * RANK(TS_ZSCORE($volume, 10)) * RANK(TS_STD($return, 10))\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Churn_Volatility_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by detecting stocks where high volume intensity and high return volatility coincide with low price efficiency. It interacts the cross-sectional rank of inverse price efficiency with the rank of volume surges and return standard deviation over a 10-day window to signal liquidity-driven trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.242096",
      "updated_at": "2026-01-14T20:49:41.242103"
    },
    "67c80b225c0e2bc4": {
      "factor_id": "67c80b225c0e2bc4",
      "factor_name": "Efficiency_Adjusted_Volume_Exhaustion_10D",
      "factor_expression": "RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Volume_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion factor that captures the 'effort vs result' divergence. It calculates the ratio of volume intensity to price efficiency, then weights it by the cross-sectional rank of price volatility. A high value indicates high effort (volume) and high noise (volatility) with low directional progress (efficiency).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.259006",
      "updated_at": "2026-01-14T20:49:41.259012"
    },
    "398af1472a4fdf41": {
      "factor_id": "398af1472a4fdf41",
      "factor_name": "ZScore_Churn_Intensity_10D",
      "factor_expression": "ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Churn_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates idiosyncratic blow-off tops by combining the cross-sectional Z-score of volume surges with the cross-sectional Z-score of price churn (the inverse of efficiency). It targets stocks that are statistical outliers in both liquidity consumption and price volatility relative to the market.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.275537",
      "updated_at": "2026-01-14T20:49:41.275544"
    },
    "54dfd5af549bf116": {
      "factor_id": "54dfd5af549bf116",
      "factor_name": "Structural_Exhaustion_Divergence_20D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the divergence between a 20-day price over-extension (residual from linear trend) and a 5-day rolling correlation between price returns and volume. A negative correlation during a period of high price residual indicates a 'churning' phase where price progress lacks volume conviction, signaling a terminal trend.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.213353",
      "updated_at": "2026-01-14T21:05:02.213360"
    },
    "34d16a9f7914acac": {
      "factor_id": "34d16a9f7914acac",
      "factor_name": "Decoupled_Trend_Reversion_Index",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(20), 20)) * ZSCORE(-1 * TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(20), 20)) * ZSCORE(-1 * TS_CORR($return, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Trend_Reversion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures structural mean-reversion opportunities by identifying assets that are significantly above their 20-day linear trend while experiencing a breakdown in the relationship between price returns and volume. The factor uses the negative 5-day price-volume correlation to highlight the decoupling of price action from market participation.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.230962",
      "updated_at": "2026-01-14T21:05:02.230968"
    },
    "309399ad265059fe": {
      "factor_id": "309399ad265059fe",
      "factor_name": "Volume_Conviction_Exhaustion_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20) * ((TS_CORR($return, $volume, 5) < 0) ? (-1 * TS_CORR($return, $volume, 5)) : 0))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20) * ((TS_CORR($return, $volume, 5) < 0) ? (-1 * TS_CORR($return, $volume, 5)) : 0))\" # Your output factor expression will be filled in here\n    name = \"Volume_Conviction_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the structural exhaustion index that focuses on identifying periods where price residuals are at extremes and the 5-day price-volume correlation is negative. This specific interaction targets 'absorption' phases where high volume fails to support further price extension, leading to a reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.248049",
      "updated_at": "2026-01-14T21:05:02.248055"
    },
    "73bb4619b3ffbc9f": {
      "factor_id": "73bb4619b3ffbc9f",
      "factor_name": "Liquidity_Convexity_Exhaustion_5D",
      "factor_expression": "SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Convexity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'blow-off' exhaustion points by calculating the 5-day average of the squared price range relative to volume turnover. This convexity-based approach amplifies signals of extreme price moves on low liquidity. It is normalized by the 20-day standard deviation and signed by the 5-day cumulative return to capture mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.801485",
      "updated_at": "2026-01-14T17:47:47.801492"
    },
    "ec3ba8798b60ab54": {
      "factor_id": "ec3ba8798b60ab54",
      "factor_name": "Convex_Price_Impact_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Convex_Price_Impact_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor targeting price-volume decoupling. It measures the convexity of price 'effort' by squaring the daily range relative to volume, then compares the 5-day average of this impact against its 20-day historical volatility to isolate unsustainable liquidity gaps.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.838225",
      "updated_at": "2026-01-14T17:47:47.838230"
    },
    "01fd11f2d23d962e": {
      "factor_id": "01fd11f2d23d962e",
      "factor_name": "Hollow_Move_Convexity_ZScore",
      "factor_expression": "SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / ($volume + 1.0), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / (MAX($volume, 1.0)), 20)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_Convexity_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the convexity-adjusted price impact (range squared over volume) to identify outliers in price discovery. By multiplying by the sign of the 5-day return, it positions for a reversal when price expansion significantly outpaces volume support.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.879619",
      "updated_at": "2026-01-14T17:47:47.879629"
    },
    "530b4b81842c1774": {
      "factor_id": "530b4b81842c1774",
      "factor_name": "Divergent_ZScore_Reversal_10D",
      "factor_expression": "TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_ZScore_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by measuring the statistical extremity of the price move (Z-score) and weighting it by a 'Divergence Index'. The Divergence Index is calculated as (1 - TS_CORR), which amplifies the signal when price and volume move in opposite directions, indicating trend fragility. The price move is calculated as the negative 10-day return to capture mean-reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.840434",
      "updated_at": "2026-01-14T17:48:31.840441"
    },
    "beda22fd003445b3": {
      "factor_id": "beda22fd003445b3",
      "factor_name": "Climax_Gated_Reversal_Factor",
      "factor_expression": "(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Climax_Gated_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets high-conviction selling climaxes. It uses the 10-day price-volume correlation as a state filter (negated to favor divergence) and multiplies it by a volatility-adjusted 10-day return. It incorporates a Volume Surge component (Volume relative to its 20-day mean) to ensure the reversal is backed by significant liquidity exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.876983",
      "updated_at": "2026-01-14T17:48:31.876989"
    },
    "c900cc937efad896": {
      "factor_id": "c900cc937efad896",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional approach to the exhaustion hypothesis. It ranks the 10-day price decline and weights it by the 10-day volume Z-score. By using RANK, it identifies the most 'stretched' assets in the universe, while the volume Z-score (clipped at 0) ensures the signal is only active during periods of higher-than-average volume intensity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.914496",
      "updated_at": "2026-01-14T17:48:31.914503"
    },
    "351ac7234f11b736": {
      "factor_id": "351ac7234f11b736",
      "factor_name": "VW_Momentum_Conviction_Interaction_20D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Conviction_Interaction_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between volume-weighted price momentum and the relative distance from the institutional cost basis. It uses the 10-day rolling mean of return scaled by cross-sectional volume rank to identify institutional conviction, and multiplies it by the rank of the price-to-VWAP ratio. The VWAP is calculated over 20 days. By using the product of two ranked components, it preserves signal intensity for stocks where both momentum and positioning are extreme.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.562820",
      "updated_at": "2026-01-14T17:56:26.562827"
    },
    "8cd6723351ebfc5d": {
      "factor_id": "8cd6723351ebfc5d",
      "factor_name": "Institutional_Efficiency_ZScore_Signal",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Efficiency_ZScore_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by combining the 10-day volume-ranked momentum with a standardized measure of price deviation from the 20-day VWAP. Instead of a simple ratio, it uses the cross-sectional Z-score of the price-to-VWAP distance to highlight statistical outliers in institutional accumulation, ensuring the factor captures high-magnitude alpha as hypothesized.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.602822",
      "updated_at": "2026-01-14T17:56:26.602829"
    },
    "8f0ff1e46d6e06e7": {
      "factor_id": "8f0ff1e46d6e06e7",
      "factor_name": "Volume_Weighted_Momentum_Anchor_Ratio",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Momentum_Anchor_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Efficiency Gap' by multiplying the 10-day persistence of volume-weighted returns with the ratio of the current price to its 20-day volume-weighted anchor. To avoid duplication and preserve signal strength, the VWAP is calculated using TS_SUM and the final interaction is cross-sectionally ranked to focus on relative institutional conviction.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.640127",
      "updated_at": "2026-01-14T17:56:26.640133"
    },
    "0a1cfd2df9539934": {
      "factor_id": "0a1cfd2df9539934",
      "factor_name": "ATR_Normalized_Squeeze_Momentum_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"ATR_Normalized_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by applying a threshold filter based on the Relative Compression Index (20-day range vs 5-day range). When a stock is in the top 10% of 'coiled' states, it outputs the 5-day momentum normalized by a 20-day simplified Average True Range (ATR) to ensure the signal is robust across different volatility regimes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.197501",
      "updated_at": "2026-01-14T18:04:58.197507"
    },
    "2c7e42eff14839e8": {
      "factor_id": "2c7e42eff14839e8",
      "factor_name": "ZScore_Momentum_Compression_Gate_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Compression_Gate_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a 20-day range-based compression ratio as a binary gate. If the stock is experiencing extreme price tightness (top 10% cross-sectionally), it captures the 5-day return normalized by its 20-day time-series Z-score. This ensures that the momentum signal is evaluated relative to its own recent distribution during the breakout phase.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.234715",
      "updated_at": "2026-01-14T18:04:58.234721"
    },
    "b89837c4374e6714": {
      "factor_id": "b89837c4374e6714",
      "factor_name": "Robust_Coil_Breakout_Factor_15D",
      "factor_expression": "((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Robust_Coil_Breakout_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Instead of using a 5-day window which was flagged for duplication, this factor utilizes a 6-day window for the 'coiling' measurement and a 15-day baseline. It interacts the compression state with an ATR-normalized return to identify stocks breaking out from a period of restricted price action.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.271232",
      "updated_at": "2026-01-14T18:04:58.271237"
    },
    "0031652e34990993": {
      "factor_id": "0031652e34990993",
      "factor_name": "Gated_Efficiency_MFI_Factor",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-9)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"Gated_Efficiency_MFI_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional 'Gated' logic where the 10-day Efficiency Ratio (ER10) is only active when the 5-day Money Flow Index (MFI) is above its 10-day rolling median. This ensures that the price efficiency signal is only rewarded when confirmed by above-average liquidity intensity, filtering out low-conviction price drifts.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.156680",
      "updated_at": "2026-01-14T19:04:02.156688"
    },
    "6c1f43082bb778c4": {
      "factor_id": "6c1f43082bb778c4",
      "factor_name": "MFI_Gated_Clean_Trend",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"MFI_Gated_Clean_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the gated efficiency hypothesis that uses a 10-day Efficiency Ratio gated by a 5-day MFI condition. Instead of a binary 1/0 gate, it uses the rank of the Efficiency Ratio multiplied by the logical condition to prioritize stocks with high trend cleanliness and confirmed institutional presence.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.195394",
      "updated_at": "2026-01-14T19:04:02.195400"
    },
    "7f2f8c1405fefe55": {
      "factor_id": "7f2f8c1405fefe55",
      "factor_name": "Liquidity_Confirmed_Efficiency_10D",
      "factor_expression": "ZSCORE(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * (RSI(($high + $low + $close) / 3 * $volume, 5) > TS_MEDIAN(RSI(($high + $low + $close) / 3 * $volume, 5), 10) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Confirmed_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trends by calculating the 10-day Efficiency Ratio and applying a cross-sectional Z-score, then nullifying the signal if the 5-day Money Flow Index is below its 10-day median. This focuses the alpha capture on 'efficient' price moves supported by liquidity.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.233875",
      "updated_at": "2026-01-14T19:04:02.233881"
    },
    "89ab97f85fe9e5e0": {
      "factor_id": "89ab97f85fe9e5e0",
      "factor_name": "PVDE5_Efficiency_Factor",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVDE5_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline. This captures 'low-friction' price discovery where institutional absorption occurs with minimal market impact.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.296769",
      "updated_at": "2026-01-14T20:59:06.296777"
    },
    "aa7009f641606569": {
      "factor_id": "aa7009f641606569",
      "factor_name": "Quiet_Accumulation_Persistence_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return, 5)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks where the 5-day price momentum is high but the volume volatility is lower than its recent average. It uses the inverse of the relative volume CV to weight the returns, emphasizing trends that are 'quiet' and thus potentially more sustainable.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.314150",
      "updated_at": "2026-01-14T20:59:06.314156"
    },
    "5fa7adef201adad7": {
      "factor_id": "5fa7adef201adad7",
      "factor_name": "Relative_Volume_Stability_Momentum",
      "factor_expression": "RANK(TS_SUM($return, 5)) * RANK(TS_MEDIAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5)) * RANK(TS_MEDIAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Stability_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A factor that focuses on the divergence between price trend and volume noise. It rewards stocks with positive 5-day returns that exhibit a 5-day volume CV that is lower than the 20-day median volume CV, signaling a transition into a more stable liquidity regime.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.331108",
      "updated_at": "2026-01-14T20:59:06.331114"
    },
    "562402034005b51a": {
      "factor_id": "562402034005b51a",
      "factor_name": "Decay_Weighted_Resistance_Exhaustion_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Decay_Weighted_Resistance_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by calculating the ratio of the distance from the 10-day high to a decay-weighted path length. The decay weighting prioritizes recent price volatility (effort), while the distance to high measures the result. This ratio is then scaled by the 10-day volume Z-score to isolate high-intensity exhaustion events.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.796121",
      "updated_at": "2026-01-14T21:08:05.796129"
    },
    "7744865b19c42ffe": {
      "factor_id": "7744865b19c42ffe",
      "factor_name": "Volatility_Adjusted_Decay_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Decay_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor enhances the resistance exhaustion signal by normalizing the distance to the 10-day high by the 10-day standard deviation of returns (volatility filter) and a decay-weighted sum of absolute returns. It targets stocks where recent 'churn' is high but price progress toward resistance is stalling, weighted by relative volume intensity.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.813949",
      "updated_at": "2026-01-14T21:08:05.813956"
    },
    "8978cd1625ebb519": {
      "factor_id": "8978cd1625ebb519",
      "factor_name": "Relative_Resistance_Decay_Surge_10D",
      "factor_expression": "ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Resistance_Decay_Surge_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the decay-weighted exhaustion factor that uses cross-sectional ranking to identify idiosyncratic outliers. It measures the failure to reach the 10-day high relative to recent price action intensity (decay-weighted), specifically during volume surges.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.831423",
      "updated_at": "2026-01-14T21:08:05.831429"
    },
    "7507c77f514565a6": {
      "factor_id": "7507c77f514565a6",
      "factor_name": "Relative_Efficiency_Decay_VWAP_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Efficiency_Decay_VWAP_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by measuring the divergence between a stock's current price relative to its 20-day Volume-Weighted Average Price (VWAP) and its relative efficiency decay. The efficiency decay is calculated as the ratio of the 5-day exponential moving average of returns to the 20-day standard deviation, normalized by the medium-term baseline to detect structural weakening.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.301854",
      "updated_at": "2026-01-14T21:18:16.301862"
    },
    "bbf0152f53011c07": {
      "factor_id": "bbf0152f53011c07",
      "factor_name": "VWAP_Extension_Churn_Index_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VWAP_Extension_Churn_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'churning' phases where price is extended from the volume-weighted cost basis but the risk-adjusted return (efficiency) is collapsing. It uses the ratio of the 5-day median return to the 20-day volatility to avoid noise from single-day spikes, identifying imminent mean-reversion when price extension is high but stability is low.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.320532",
      "updated_at": "2026-01-14T21:18:16.320538"
    },
    "2c26ba58e0190cfe": {
      "factor_id": "2c26ba58e0190cfe",
      "factor_name": "Volume_Weighted_Efficiency_Gap",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Efficiency_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies trend exhaustion by comparing the 20-day VWAP deviation with a 'Relative Efficiency' metric. The efficiency component uses the ratio of the 5-day sum of returns to the 20-day sum of absolute returns, capturing the loss of directional conviction relative to total price churn.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.338873",
      "updated_at": "2026-01-14T21:18:16.338879"
    }
  }
}