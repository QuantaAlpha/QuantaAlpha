{
  "metadata": {
    "created_at": "2026-01-17T12:00:22.272640",
    "last_updated": "2026-01-17T12:00:22.272647",
    "total_factors": 150,
    "version": "1.0",
    "source": "all_factors_library_10_10_10_best1_组合123_QA.json",
    "note": "随机抽取的150个因子(seed=42)，保持原始顺序"
  },
  "factors": {
    "552fa3c9d347569e": {
      "factor_id": "552fa3c9d347569e",
      "factor_name": "Vol_Adjusted_Residual_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Residual_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day price residual from a linear regression against time, normalized by the 5-day rolling standard deviation of daily returns. This normalization identifies overextended price movements relative to the asset's current volatility regime.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.383540",
      "updated_at": "2026-01-17T01:31:14.383548"
    },
    "f099da69a9738d69": {
      "factor_id": "f099da69a9738d69",
      "factor_name": "Delta_RESI_5D_Acceleration",
      "factor_expression": "DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Delta_RESI_5D_Acceleration\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day difference of the Relative Strength Intensity (RESI), where RESI is the ratio of the 5-day price range (highest high to lowest low) to the absolute 5-day price change. A sharp increase in this ratio indicates that price volatility is expanding much faster than directional displacement, signaling potential trend exhaustion and mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.915433",
      "updated_at": "2026-01-17T01:38:33.915439"
    },
    "731124529417b326": {
      "factor_id": "731124529417b326",
      "factor_name": "Ranked_RESI_Volatility_Exhaustion",
      "factor_expression": "RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_RESI_Volatility_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Delta-RESI factor. It identifies stocks experiencing the most extreme acceleration in price range relative to net displacement. High values suggest 'blow-off' phases where price movement becomes inefficient, increasing the probability of a short-term reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.924868",
      "updated_at": "2026-01-17T01:38:33.924874"
    },
    "6cbededfd2d1673b": {
      "factor_id": "6cbededfd2d1673b",
      "factor_name": "Risk_Adj_Momentum_Vol_Stab_60D",
      "factor_expression": "(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) * INV(TS_STD($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 60) / TS_STD(TS_PCTCHANGE($close, 1), 20)) * INV(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Risk_Adj_Momentum_Vol_Stab_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the risk-adjusted momentum (60-day price change divided by 20-day return volatility) and scales it by the inverse of short-term volume volatility. High values indicate a strong, stable price trend accompanied by consistent trading volume, suggesting institutional quality trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.797529",
      "updated_at": "2026-01-17T01:38:36.797535"
    },
    "4954e8114853e7d1": {
      "factor_id": "4954e8114853e7d1",
      "factor_name": "Ranked_Quality_Momentum_Volume_Stability",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Quality_Momentum_Volume_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the risk-adjusted momentum hypothesis. It combines the rank of 60-day momentum normalized by 20-day volatility with the rank of the inverse 5-day volume volatility to identify assets with the most 'orderly' uptrends relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.807169",
      "updated_at": "2026-01-17T01:38:36.807175"
    },
    "7bcced8c81d75b33": {
      "factor_id": "7bcced8c81d75b33",
      "factor_name": "Trend_Exhaustion_Signal_20D",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(20), 20), 2) * TS_VAR(SEQUENCE(20), 20) / (TS_VAR($close, 20) + 1e-8)) * SIGN(-1 * TS_CORR($return, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * SIGN(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the trend exhaustion hypothesis using a 20-day window. It captures the interaction between price trend stability and the decoupling of volume, where a negative correlation between volume and price changes indicates a lack of conviction in the prevailing trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.367826",
      "updated_at": "2026-01-17T01:43:23.367834"
    },
    "ee1e2d324e285027": {
      "factor_id": "ee1e2d324e285027",
      "factor_name": "Cross_Sectional_Divergence_Rank_15D",
      "factor_expression": "RANK(POW(REGBETA($close, SEQUENCE(15), 15), 2) * TS_VAR(SEQUENCE(15), 15) / (TS_VAR($close, 15) + 1e-8)) * RANK(-1 * TS_CORR($return, $volume, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(15), 15), 2)) * RANK(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Divergence_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price-volume divergence relative to the market, weighted by the linearity of the 15-day price trend. It highlights stocks where the trend is most likely to reverse due to a significant drop in volume support during price moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.396155",
      "updated_at": "2026-01-17T01:43:23.396163"
    },
    "b63263adb82f671c": {
      "factor_id": "b63263adb82f671c",
      "factor_name": "VWAP_Volume_Corr_20D",
      "factor_expression": "TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Volume_Corr_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the 20-day Pearson correlation between the daily Volume-Weighted Average Price (approximated by the average of OHLC) and daily trading volume. High positive correlation suggests institutional accumulation during high-liquidity periods.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.506484",
      "updated_at": "2026-01-17T01:45:05.506490"
    },
    "9583a1d6192db0b5": {
      "factor_id": "9583a1d6192db0b5",
      "factor_name": "Ranked_Stable_Mean_Reversion_5D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stable_Mean_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the short-term residual factor, conditioned on a low-volatility ratio. It uses the ratio of 5-day to 20-day volatility as a weight for the 5-day price residual, emphasizing mean reversion in stocks with the most 'quiet' price action relative to their historical norm.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.669801",
      "updated_at": "2026-01-17T01:46:16.669808"
    },
    "2b13a01bedaeed68": {
      "factor_id": "2b13a01bedaeed68",
      "factor_name": "ZScore_MSLVR_Inversion_Factor",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8), 20) * TS_PCTCHANGE($close, 60)",
      "factor_implementation_code": "",
      "factor_description": "This factor uses the Z-score of the volume volatility ratio to identify extreme liquidity shifts. It assumes that when the 5-day volume volatility is extremely high relative to its 60-day history, the 60-day momentum is likely to mean-revert or stall.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.371604",
      "updated_at": "2026-01-17T01:49:23.371611"
    },
    "8dfd2563d1c47f9f": {
      "factor_id": "8dfd2563d1c47f9f",
      "factor_name": "Asymmetric_Shadow_Volatility_Regime_5D",
      "factor_expression": "(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Shadow_Volatility_Regime_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by calculating the ratio of the lower shadow length to the total daily range, specifically during periods of high 5-day price volatility. A high ratio in a high-volatility environment suggests exhaustive selling pressure and intraday price rejection.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.387299",
      "updated_at": "2026-01-17T01:49:29.387306"
    },
    "5024667fb96dc362": {
      "factor_id": "5024667fb96dc362",
      "factor_name": "Shadow_Exhaustion_Intensity_5D",
      "factor_expression": "(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Shadow_Exhaustion_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of the lower shadow relative to the candle body, conditioned on the stock being in a high-volatility state. It focuses on the 'Hammer' strength by comparing the lower shadow to the absolute price movement between open and close.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.408278",
      "updated_at": "2026-01-17T01:49:29.408284"
    },
    "02c7c583868e4030": {
      "factor_id": "02c7c583868e4030",
      "factor_name": "Price_Volume_Trend_Divergence_10D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Trend_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price momentum and volume-weighted momentum over a 10-day period. It calculates the difference between the cross-sectional rank of the 10-day price change and the cross-sectional rank of the 10-day RSI (Relative Strength Index). A high divergence suggests the price trend is exhausted and likely to undergo mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.133648",
      "updated_at": "2026-01-17T01:52:41.133655"
    },
    "cd7ac8d6736c5188": {
      "factor_id": "cd7ac8d6736c5188",
      "factor_name": "Normalized_PV_Synchrony_Intensity",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_PV_Synchrony_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume synchrony hypothesis that normalizes volume volatility by its 20-day average to capture relative intensity. It scales the 20-day price-volume correlation by the ratio of short-term volume volatility to long-term volume volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.985842",
      "updated_at": "2026-01-17T01:54:48.985848"
    },
    "8080ce5352833969": {
      "factor_id": "8080ce5352833969",
      "factor_name": "Smoothed_Gap_To_Shadow_Efficiency",
      "factor_expression": "TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Gap_To_Shadow_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A smoothed version of the gap-to-lower-shadow ratio using a 5-day moving average. It filters out daily noise to identify stocks where overnight gaps consistently show high intraday support (minimal lower shadows).",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.408199",
      "updated_at": "2026-01-17T01:55:36.408206"
    },
    "8336f343c9f54590": {
      "factor_id": "8336f343c9f54590",
      "factor_name": "ZScore_Decay_Momentum_60D",
      "factor_expression": "ZSCORE(EMA($return, 19))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(EMA(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Decay_Momentum_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the exponentially weighted 60-day momentum by its cross-sectional volatility. By applying ZSCORE to the EMA of returns, it identifies stocks with the strongest recent momentum relative to the market, adjusted for the decay of older price information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.689291",
      "updated_at": "2026-01-17T01:58:21.689297"
    },
    "30f6c97b79f08892": {
      "factor_id": "30f6c97b79f08892",
      "factor_name": "Decay_Momentum_Volatility_Ratio",
      "factor_expression": "EMA($return, 19) / (TS_STD($return, 60) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(TS_PCTCHANGE($close, 1), 19) / (TS_STD(TS_PCTCHANGE($close, 1), 60) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Decay_Momentum_Volatility_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of exponentially decayed momentum to the 60-day price volatility. It aims to capture risk-adjusted recent momentum, ensuring that the trend acceleration is not merely a result of high idiosyncratic volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.700299",
      "updated_at": "2026-01-17T01:58:21.700304"
    },
    "2974bff508b08b79": {
      "factor_id": "2974bff508b08b79",
      "factor_name": "ZScored_Idiosyncratic_Shock_5D",
      "factor_expression": "RANK(TS_SUM(ZSCORE($return), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM(ZSCORE(TS_PCTCHANGE($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Idiosyncratic_Shock_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the intensity of stock-specific price movements relative to the market by calculating the 5-day sum of cross-sectionally standardized return residuals. It helps identify assets experiencing extreme idiosyncratic shocks that are likely to mean-revert or trend independently.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.674794",
      "updated_at": "2026-01-17T02:01:26.674800"
    },
    "798c3c97bde13834": {
      "factor_id": "798c3c97bde13834",
      "factor_name": "ROC60_PV_CORR20_Rank_Product",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ROC60_PV_CORR20_Rank_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies assets with both strong long-term momentum and high price-volume synchronization. It calculates the 60-day rate of change and the 20-day correlation between price and volume, then combines their cross-sectional ranks to isolate high-conviction recovery trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.970694",
      "updated_at": "2026-01-17T02:03:45.970701"
    },
    "347805446ee512ab": {
      "factor_id": "347805446ee512ab",
      "factor_name": "Clean_Momentum_Recovery_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($return, DELTA($volume, 1), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Clean_Momentum_Recovery_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume interaction hypothesis that focuses on the stability of returns relative to volume. It uses the 60-day price change and the 20-day correlation between daily returns and volume changes to filter for assets where price appreciation is consistently supported by volume flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.982125",
      "updated_at": "2026-01-17T02:03:45.982131"
    },
    "e8b47be6a786d40e": {
      "factor_id": "e8b47be6a786d40e",
      "factor_name": "Price_Range_Quantile_Support",
      "factor_expression": "RANK($low - $open) * (1 - TS_RANK($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($low - $open) * (1 - TS_RANK($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Range_Quantile_Support\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the coiled spring hypothesis that uses the 20-day range quantile to identify periods of low volatility (compression) and combines it with the intraday low's position relative to the open price.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.730918",
      "updated_at": "2026-01-17T02:04:05.730924"
    },
    "f7a2decd56930628": {
      "factor_id": "f7a2decd56930628",
      "factor_name": "Neutralized_Volume_Stability_5D",
      "factor_expression": "TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Neutralized_Volume_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day rolling standard deviation of volume to measure liquidity volatility, then subtracts the cross-sectional median to isolate idiosyncratic liquidity stability from market-wide noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.533818",
      "updated_at": "2026-01-17T02:06:12.533825"
    },
    "837d323fefb53783": {
      "factor_id": "837d323fefb53783",
      "factor_name": "VPBD_Volatility_Adjusted_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VPBD_Volatility_Adjusted_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the 5-day VWAP to the 5-day TWAP, normalized by the price volatility. A value greater than 1 suggests volume is concentrated at higher prices relative to the time-average, indicating aggressive institutional accumulation during low-volatility 'stealth' phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.747135",
      "updated_at": "2026-01-17T02:09:58.747143"
    },
    "3a3929d58669dc91": {
      "factor_id": "3a3929d58669dc91",
      "factor_name": "Volatility_Weighted_PV_Divergence",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Weighted_PV_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the regime hypothesis that weights the 20-day price-volume correlation by the 14-day price volatility (standard deviation) normalized by price. It emphasizes price-volume signals during periods of high relative volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.961311",
      "updated_at": "2026-01-17T02:12:37.961317"
    },
    "66f572336e2eb2b4": {
      "factor_id": "66f572336e2eb2b4",
      "factor_name": "Regime_Filtered_PV_Momentum",
      "factor_expression": "TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Regime_Filtered_PV_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the 14-day ATR-to-price ratio as a regime filter. It amplifies the 20-day price-volume correlation when the current volatility is higher than its 60-day median, targeting periods of market stress or significant movement.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.973445",
      "updated_at": "2026-01-17T02:12:37.973451"
    },
    "02847e8e88449175": {
      "factor_id": "02847e8e88449175",
      "factor_name": "Ranked_Convexity_Efficiency_5D",
      "factor_expression": "RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Convexity_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the convexity hypothesis. It ranks the acceleration of price changes over the last 2 days and multiplies it by the rank of the price range per unit of volume. High values indicate stocks where price is 'blowing off' with low volume efficiency relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.535713",
      "updated_at": "2026-01-17T02:16:08.535720"
    },
    "ff213d9fa8bc5bb6": {
      "factor_id": "ff213d9fa8bc5bb6",
      "factor_name": "Vol_Adj_WVMA_Momentum_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_WVMA_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 5-day Volume Weighted Moving Average (WVMA) and transforms it using a volatility-adjusted momentum ratio. It aims to identify high-conviction trends by scaling the volume-weighted price by the ratio of 5-day returns to 5-day price volatility, effectively filtering out noise in high-variance regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.632203",
      "updated_at": "2026-01-17T02:17:56.632212"
    },
    "f07da216a4b9559c": {
      "factor_id": "f07da216a4b9559c",
      "factor_name": "Regime_Scaled_WVMA_5D",
      "factor_expression": "RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE($return, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE(TS_PCTCHANGE($close, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"Regime_Scaled_WVMA_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A non-linear transformation of the 5-day WVMA that uses the Z-score of returns relative to volatility. This factor distinguishes between institutional accumulation (low volatility, rising price) and distribution (high volatility, falling price) by multiplying the volume-weighted price level by the 5-day return Z-score.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.645835",
      "updated_at": "2026-01-17T02:17:56.645842"
    },
    "ab596c4b1cce2d5e": {
      "factor_id": "ab596c4b1cce2d5e",
      "factor_name": "Overnight_Gap_Volume_Intensity_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Volume_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Gap' by calculating the ratio of the overnight return to the 5-day average trading volume. A high overnight return relative to low volume suggests that the price shock hasn't been fully absorbed by the market, potentially leading to a post-announcement drift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.757718",
      "updated_at": "2026-01-17T02:18:50.757725"
    },
    "73054cc654b85f9d": {
      "factor_id": "73054cc654b85f9d",
      "factor_name": "Gap_Liquidity_Divergence_ZScore",
      "factor_expression": "TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Liquidity_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the overnight price shock and recent volume intensity using a Z-score. It targets the hypothesis that significant gaps on low relative volume lead to multi-day drifts because institutional order imbalances are not cleared immediately.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.787763",
      "updated_at": "2026-01-17T02:18:50.787769"
    },
    "72899da06635a7c9": {
      "factor_id": "72899da06635a7c9",
      "factor_name": "Overnight_Liquidity_Exhaustion_Factor",
      "factor_expression": "RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Liquidity_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean reversion by calculating the ratio of the overnight gap to the average intraday range, conditioned on a negative correlation between price changes and volume. A high value suggests price dislocation due to liquidity exhaustion rather than fundamental conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.227209",
      "updated_at": "2026-01-17T02:25:06.227216"
    },
    "29c4edd238c78731": {
      "factor_id": "29c4edd238c78731",
      "factor_name": "Vol_Expansion_Trend_Persistence_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Expansion_Trend_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of a trend during volatility expansion. It calculates the product of the 5-day return and the ratio of displacement to volatility, specifically when the short-term volatility is rising relative to its medium-term benchmark, signaling a potential structural regime shift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.323029",
      "updated_at": "2026-01-17T02:30:45.323034"
    },
    "973adedc0202ee0d": {
      "factor_id": "973adedc0202ee0d",
      "factor_name": "Stealth_Drift_Persistence_10D",
      "factor_expression": "RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price volatility and volume intensity. It uses the difference between the rank of the price range and the rank of volume over a 10-day window. Positive values indicate price volatility is higher than volume intensity, a hallmark of stealth accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.616048",
      "updated_at": "2026-01-17T02:33:31.616054"
    },
    "9ad4ed63e0efd34f": {
      "factor_id": "9ad4ed63e0efd34f",
      "factor_name": "Quiet_Regime_Mean_Reversion",
      "factor_expression": "-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD($return, 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 3))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines volume depletion (3-day mean vs 20-day mean) with price stability (3-day volatility). Low values in both suggest a 'quiet' regime susceptible to liquidity-driven reversals. The factor is negated to reflect the expected mean-reversion return.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.346788",
      "updated_at": "2026-01-17T02:37:14.346794"
    },
    "a5ce5e3f851fd4d1": {
      "factor_id": "a5ce5e3f851fd4d1",
      "factor_name": "Overnight_Conviction_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Conviction_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of absolute overnight returns to the intraday price range, averaged over 5 days. It identifies high-conviction institutional positioning by highlighting periods where price movement occurs primarily during non-trading hours relative to intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.221118",
      "updated_at": "2026-01-17T02:37:58.221125"
    },
    "3d503a5431bacb0d": {
      "factor_id": "3d503a5431bacb0d",
      "factor_name": "Ranked_Conviction_Persistence_Index",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($return, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Persistence_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction index. It compares the relative strength of the overnight-to-range ratio against the relative stability of the stock, identifying assets with the highest institutional signal-to-noise ratio.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.251412",
      "updated_at": "2026-01-17T02:37:58.251418"
    },
    "e55f48a58d8cef9e": {
      "factor_id": "e55f48a58d8cef9e",
      "factor_name": "Inst_Liquidity_Exhaustion_5D",
      "factor_expression": "TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Inst_Liquidity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional liquidity exhaustion by measuring the divergence between the closing price and the daily average price (HLC/3), normalized by the daily range. A high positive value suggests a late-day markup without broad support, predicting a potential reversal. The value is smoothed over 5 days to capture persistent imbalances.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.369398",
      "updated_at": "2026-01-17T02:40:14.369405"
    },
    "99189547d9fa4c68": {
      "factor_id": "99189547d9fa4c68",
      "factor_name": "Relative_Closing_Imbalance_Rank_10D",
      "factor_expression": "TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Closing_Imbalance_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the relative position of the close within the daily range compared to the average price. By applying a cross-sectional rank to the exhaustion signal and smoothing it, it identifies stocks with the most extreme liquidity traps relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.384880",
      "updated_at": "2026-01-17T02:40:14.384886"
    },
    "fffb5eb9485c4f77": {
      "factor_id": "fffb5eb9485c4f77",
      "factor_name": "Amihud_Reversion_5D",
      "factor_expression": "TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (1 - $close / $open)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (1 - $close / ($open + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion candidates by multiplying the 5-day average Amihud illiquidity ratio (absolute return divided by volume) with the negative intraday return. High illiquidity during a price move suggests a transient shock likely to reverse.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.179048",
      "updated_at": "2026-01-17T02:41:08.179055"
    },
    "bbae81fc535fa2c3": {
      "factor_id": "bbae81fc535fa2c3",
      "factor_name": "Ranked_Amihud_Intraday_Reversal",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 10)) * SIGN($open - $close)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(($close - $open) / $open) / ($volume + 1e-8), 10)) * SIGN($open - $close)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Amihud_Intraday_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the illiquidity-reversion hypothesis. It ranks the 10-day average price impact per unit volume and multiplies it by the negative sign of the intraday return to target stocks where illiquid moves are most likely to exhaust.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.209027",
      "updated_at": "2026-01-17T02:41:08.209034"
    },
    "1aa53be0817ae109": {
      "factor_id": "1aa53be0817ae109",
      "factor_name": "IPVE_Fragility_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"IPVE_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the Intraday Price-Volume Efficiency (IPVE) by taking the ratio of the daily price range to the trading volume. It identifies 'fragile' price movements where high volatility occurs on low liquidity. A 5-day simple moving average is applied to smooth idiosyncratic noise, and the result is cross-sectionally ranked to identify stocks prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.001869",
      "updated_at": "2026-01-17T02:43:26.001876"
    },
    "93f99fe635358d30": {
      "factor_id": "93f99fe635358d30",
      "factor_name": "Relative_Range_Volume_Efficiency_20D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement relative to volume by comparing the current range-to-volume ratio against its 20-day median. It targets stocks where the current price movement is significantly more 'expensive' in terms of liquidity than usual, indicating a high probability of a fragile trend.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.031536",
      "updated_at": "2026-01-17T02:43:26.031542"
    },
    "f2b1e3a9b86377a0": {
      "factor_id": "f2b1e3a9b86377a0",
      "factor_name": "Fragility_Momentum_Divergence_10D",
      "factor_expression": "RANK(TS_SUM($return, 10) * TS_RANK(ABS($return) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1), 10) * TS_RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Fragility_Momentum_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies cases where price trends are 'fragile' by multiplying the 10-day return by the time-series rank of the Amihud illiquidity ratio. High fragility during a price move signals a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.202044",
      "updated_at": "2026-01-17T02:46:43.202051"
    },
    "9238283d9d0fe1b6": {
      "factor_id": "9238283d9d0fe1b6",
      "factor_name": "Trend_Acceleration_Divergence_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Divergence_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term (5-day) and long-term (20-day) trend quality. It uses the square of the correlation between price and a time sequence (R-squared) to identify parabolic acceleration or trend exhaustion. A high positive value suggests recent linear intensification, while a sharp drop suggests structural breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.832266",
      "updated_at": "2026-01-17T02:49:16.832272"
    },
    "5d04ffa211d8c42c": {
      "factor_id": "5d04ffa211d8c42c",
      "factor_name": "Trend_Consistency_Decay_Rate",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Decay_Rate\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the decay in trend consistency by comparing the current 5-day R-squared to its 10-day moving average, normalized by the 20-day R-squared. This identifies assets where the 'linear consistency' is failing faster than the long-term trend would suggest, signaling potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.862200",
      "updated_at": "2026-01-17T02:49:16.862206"
    },
    "3167fd05ab02177c": {
      "factor_id": "3167fd05ab02177c",
      "factor_name": "ZScore_Gap_Support_Interaction",
      "factor_expression": "ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Gap_Support_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a Z-score to the overnight gap and the intraday support ratio independently before multiplication. This ensures that the two components have equal weight in the final signal, identifying stocks where both the overnight reaction and intraday price action are statistically significant relative to the cross-section.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of the volatility-normalized overnight gap and the 5-day moving average of the ratio between the daily low and the daily range (high-low) identifies high-conviction institutional trends where overnight information is validated by intraday structural support.\n                Concise Observation: Parent 1 showed that intraday support (low/range) has predictive power (RankIC 0.0256), while Parent 2 showed that normalized overnight gaps capture information asymmetry (RankIC 0.0303); however, each alone may capture noise or temporary spikes without cross-temporal confirmation.\n                Concise Justification: The overnight gap represents the market's reaction to new information, while the relative position of the daily low represents the persistence of buying pressure throughout the session; multiplying these ensures that only gaps with sustained intraday support are signaled as high-quality entries.\n                Concise Knowledge: If an overnight price gap is followed by a high relative daily low (low price near the high price relative to the range), it indicates institutional floor-setting; when these two signals are combined multiplicatively, they filter for high-conviction momentum and reduce the risk of exhaustion gaps.\n                concise Specification: The factor is defined as ((Open_t - Close_{t-1}) / StdDev(Returns, 20)) * SMA((Low_t - Low_t) / (High_t - Low_t + epsilon), 5), where the first term captures the normalized gap and the second term captures the 5-day smoothed intraday support persistence.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "59eff6c582b9",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042283937066098,
        "ICIR": 0.0313094228775075,
        "RankIC": 0.0181419910093354,
        "RankICIR": 0.1348464607506115,
        "annualized_return": 0.0839854243634816,
        "information_ratio": 1.1324999228391175,
        "max_drawdown": -0.0954403690053182
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:51:24.873746",
      "updated_at": "2026-01-17T02:51:24.873753"
    },
    "3cd6d15d89224ff5": {
      "factor_id": "3cd6d15d89224ff5",
      "factor_name": "Relative_Intraday_Intensity_20D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the current day's price range to the 20-day Average True Range (ATR). It identifies stocks with abnormal intraday volatility relative to their historical baseline, normalized for cross-sectional comparison.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:07.993363",
      "updated_at": "2026-01-17T02:52:07.993370"
    },
    "366a311d0a63e223": {
      "factor_id": "366a311d0a63e223",
      "factor_name": "Volatility_Adjusted_Range_Shock_10D",
      "factor_expression": "RANK((($high - $low) / $close) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / $close) / TS_STD(TS_PCTCHANGE($close, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Range_Shock_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the intraday intensity factor that uses a 10-day rolling standard deviation of returns to normalize the daily range-to-price ratio, highlighting price shocks relative to recent volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.010514",
      "updated_at": "2026-01-17T02:52:08.010520"
    },
    "9a62de12186c88c7": {
      "factor_id": "9a62de12186c88c7",
      "factor_name": "Relative_Range_ZScore_20D",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the time-series Z-score of the daily price range over a 20-day window. It identifies how many standard deviations the current day's range is from its recent mean, providing a unit-less measure of trading intensity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.026105",
      "updated_at": "2026-01-17T02:52:08.026110"
    },
    "7edeac1299d5ec7a": {
      "factor_id": "7edeac1299d5ec7a",
      "factor_name": "Price_Efficiency_Ratio_10D",
      "factor_expression": "ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates Kaufman's Efficiency Ratio over a 10-day window. It measures the net price change relative to the total path traveled (sum of absolute daily returns). Low values indicate high noise and potential for mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.094020",
      "updated_at": "2026-01-17T02:52:25.094027"
    },
    "a68abefcaf887ab0": {
      "factor_id": "a68abefcaf887ab0",
      "factor_name": "Noise_Filtered_Return_Reversion",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Noise_Filtered_Return_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that identifies stocks with high daily variance (high-low range) but low net directional movement over 10 days. It uses the ratio of 10-day range sum to net displacement, standardized by Z-score.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.127010",
      "updated_at": "2026-01-17T02:52:25.127016"
    },
    "8f46483ca3e55e78": {
      "factor_id": "8f46483ca3e55e78",
      "factor_name": "Path_Efficiency_Liquidity_Rank_5D",
      "factor_expression": "RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Path_Efficiency_Liquidity_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency ratio that focuses on the cross-sectional rank of path efficiency (displacement over total range) adjusted by the rank of volume intensity. It identifies assets where price moves are 'efficient' relative to the liquidity provided, targeting mean-reversion when efficiency is extreme.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.153925",
      "updated_at": "2026-01-17T02:55:13.153932"
    },
    "bd57f3aa96b263e1": {
      "factor_id": "bd57f3aa96b263e1",
      "factor_name": "Stealth_Accumulation_ZScore_60D",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) * SIGN(TS_CORR($close, $volume, 20)) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) * SIGN(TS_CORR($close, $volume, 20)) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_ZScore_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis that focuses on the Z-score of range efficiency during price-volume divergence. It targets assets where the current range-to-volume ratio is significantly lower than its 20-day average, conditioned on being in a 60-day oversold state.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The fusion of medium-term price exhaustion and micro-structural stealth accumulation, measured by the interaction of a 20-day negative price-volume correlation and a 10-day range-to-volume efficiency ratio within a 60-day downward momentum regime, predicts superior mean-reversal returns.\n                Concise Observation: Parent 1 successfully identified oversold regimes (RankIC 0.029) while Parent 2 captured subtle institutional footprints (RankIC 0.026); however, both likely suffer from false signals during continuous liquidations or low-volatility drifts.\n                Concise Justification: Combining macro-regime filters with micro-execution metrics ensures that mean-reversion trades are only entered when 'stealth' buying behavior stabilizes the price range, filtering out falling knives that lack institutional support.\n                Concise Knowledge: If an asset exhibits negative price-volume correlation during a significant downtrend, it indicates selling exhaustion; when this coincides with a decreasing ratio of daily price range to volume, it signals institutional absorption of liquidity and an imminent trend reversal.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation (Price, Volume) and the 10-day average of (High-Low)/Volume, conditioned on the 60-day price change being in the bottom quintile of the cross-section.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5e5e3ce55591",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0027254100469313,
        "ICIR": 0.0196622782725537,
        "RankIC": 0.0181251384351378,
        "RankICIR": 0.1276285485652918,
        "annualized_return": 0.0496725864195166,
        "information_ratio": 0.6727011235559099,
        "max_drawdown": -0.139122733193392
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:58:02.149372",
      "updated_at": "2026-01-17T02:58:02.149378"
    },
    "c2e2a187a71a6e4a": {
      "factor_id": "c2e2a187a71a6e4a",
      "factor_name": "Volatility_Adjusted_Gap_Reversion_5D",
      "factor_expression": "($close - TS_MEAN($close, 5)) / (TS_STD($return, 5) + 1e-8) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - TS_MEAN($close, 5)) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by scaling price residuals by volatility and weighting them with the inverse of the overnight-to-intraday gap ratio. A high gap ratio suggests institutional conviction, which filters out trend breakouts, while a low gap ratio identifies noise-driven deviations prone to reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 5-day volatility-adjusted price residual (RESI5/STD5) and the 5-day average overnight-to-intraday gap ratio (GAP_RATIO) identifies high-probability mean-reversion entries by filtering out institutional-driven breakouts.\n                Concise Observation: Parent 1 (RankIC=0.0228) struggles with 'value traps' during strong trends, while Parent 2 (RankIC=0.0303) effectively distinguishes between institutional conviction and retail noise through overnight price gaps.\n                Concise Justification: By conditioning the mean-reversion signal (RESI5/STD5) on a measure of institutional conviction (Overnight Gap / Daily Range), we can isolate mean-reversion opportunities to environments where price extremes lack structural support.\n                Concise Knowledge: If a short-term price deviation is accompanied by low overnight gap persistence, it is likely noise-driven and prone to mean reversion; conversely, if the deviation is supported by high overnight conviction, it signals a structural trend breakout.\n                concise Specification: Define RESI5 as (Close - Mean(Close, 5)), STD5 as the 5-day daily return standard deviation, and GAP_RATIO as the 5-day average of (abs(Open - PrevClose) / (High - Low)). The final factor is RESI5 / STD5 * (1 - GAP_RATIO).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "cff31d942462",
      "parent_trajectory_ids": [
        "534d813fed12",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038223203757825,
        "ICIR": 0.0265310893241041,
        "RankIC": 0.0198615195554917,
        "RankICIR": 0.1406405073269134,
        "annualized_return": 0.0572091069734403,
        "information_ratio": 0.7586299454893467,
        "max_drawdown": -0.1096029180672807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:01:26.247687",
      "updated_at": "2026-01-17T03:01:26.247699"
    },
    "d5d5ad13fcc99509": {
      "factor_id": "d5d5ad13fcc99509",
      "factor_name": "Ranked_Support_Integrity_5D",
      "factor_expression": "RANK(TS_MEAN(($close - $low) / (($high - $low) / ($volume + 1e-8) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $low) / (($high - $low) / ($volume + 1e-8) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Support_Integrity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the structural integrity of price floors by ranking the interaction between price support and volume-to-range efficiency. It identifies stocks where the price is supported near the low on high relative liquidity, avoiding 'hollow' price levels characterized by large ranges on low volume.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Support Persistence (LVSP) factor, calculated as the 5-day average of the ratio between intraday support strength (low relative to range) and intraday price-volume exhaustion (range relative to volume), identifies high-conviction accumulation by filtering out fragile price floors formed on low liquidity.\n                Concise Observation: Parent 1 showed that intraday support persistence (RankIC 0.0256) is a valid signal, while Parent 2 demonstrated that price-volume efficiency (RankIC 0.0265) captures exhaustion; however, neither accounts for the interaction where volume validates the structural integrity of the support level.\n                Concise Justification: By dividing the support metric by the exhaustion metric, we amplify signals where price floors are 'dense' (high volume, small range) and penalize 'hollow' support levels, creating a synergistic factor that captures the quality of buying pressure rather than just its presence.\n                Concise Knowledge: If intraday price support (low price near high) is accompanied by high volume relative to the price range, it signifies institutional accumulation; conversely, if support occurs with high price-volume exhaustion (large range on low volume), the price level is likely a liquidity gap prone to reversal.\n                concise Specification: The factor is defined as the 5-day rolling mean of [(($high - $low) / ($volume + 1)) / (($high - $low) / ($close - $low + 1e-6))], simplified to the 5-day average of (($close - $low) * $volume) / (($high - $low)^2 + 1e-6) to represent volume-weighted support density.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5dece64bed8e",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030132636768753,
        "ICIR": 0.0215194480321322,
        "RankIC": 0.018658191678368,
        "RankICIR": 0.1376405485497886,
        "annualized_return": 0.0415392551290103,
        "information_ratio": 0.67615156428944,
        "max_drawdown": -0.1046921246221175
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:11.857423",
      "updated_at": "2026-01-17T03:10:11.857429"
    },
    "cecbeb683ba33bd9": {
      "factor_id": "cecbeb683ba33bd9",
      "factor_name": "Structural_Decay_Shock_Factor",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(ABS($return) / ($volume + 1e-8)) * (TS_PCTCHANGE($close, 60) < 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8)) * (TS_PCTCHANGE($close, 60) < 0 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Structural_Decay_Shock_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the liquidity exhaustion hypothesis that uses the rank of price-volume decoupling and the rank of illiquidity spikes to identify fragile market structures in a downtrend.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Exhaustion Divergence' factor identifies mean-reversion by multiplying the 20-day negative price-volume correlation (Parent 1) with the 5-day Amihud Illiquidity Z-score (Parent 2) within a 60-day momentum context.\n                Concise Observation: Parent 1 captures structural trend decay (RankIC 0.029) while Parent 2 captures immediate execution stress (RankIC 0.023); however, each alone may trigger premature entries in trending or flat markets respectively.\n                Concise Justification: Combining the 20-day price-volume decoupling with a 5-day illiquidity spike ensures that the mean-reversion signal is only generated when the macro-trend has lost volume support and the micro-structure is fragile enough to snap back.\n                Concise Knowledge: If a medium-term price trend exhibits decoupling (negative price-volume correlation) and is simultaneously hit by a short-term liquidity shock (high Amihud ratio), then the probability of a sharp mean-reversion increases due to exhaustion of the dominant market participants.\n                concise Specification: Define the factor as the product of TS_CORR($close, $volume, 20) and a 5-day Z-score of ($abs(return)/$volume), filtered by a negative 60-day cumulative return to isolate oversold recovery opportunities.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "0d28bc31ac05",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "696eecf82dbb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.009537074802855,
        "ICIR": 0.0664693296707091,
        "RankIC": 0.0265548610396828,
        "RankICIR": 0.1853266300679249,
        "annualized_return": 0.077722993371773,
        "information_ratio": 1.1414703919871785,
        "max_drawdown": -0.1191262636734705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:11:27.325238",
      "updated_at": "2026-01-17T03:11:27.325243"
    },
    "1a11d5bfc97b9bc3": {
      "factor_id": "1a11d5bfc97b9bc3",
      "factor_name": "Volatility_Liquidity_Efficiency_Ratio",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) / (RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) / (RANK(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Liquidity_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the liquidity-regime hypothesis focusing on the ratio of price-volume trend strength to illiquidity. It uses the 20-day price-volume correlation as a proxy for trend conviction and divides it by the short-term price impact (Amihud Illiquidity) to identify efficient price discovery.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation and the 14-day ATR, when normalized by the 5-day Amihud Illiquidity, identifies high-conviction regime shifts by filtering out low-volume 'liquidity traps' that lead to false trend signals.\n                Concise Observation: Parent 1 captures volatility-adjusted regimes (RankIC 0.029) and Parent 2 captures liquidity-driven reversals (RankIC 0.023), but neither distinguishes if a volatile trend is supported by sufficient depth.\n                Concise Justification: By dividing the regime signal (CORR * ATR) by a short-term illiquidity measure, we amplify signals where price discovery is efficient (low illiquidity) and dampen or reverse signals where price moves are disproportionate to volume.\n                Concise Knowledge: If a price-volume trend is accompanied by high volatility but low liquidity (high Amihud), it is likely a mean-reverting fragility event; whereas high liquidity validates the regime's persistence.\n                concise Specification: The factor is defined as (Corr(Close, Volume, 20) * ATR(14) / Close) / (Mean(Abs(Return/Volume), 5)), where all components are z-scored cross-sectionally to ensure scale compatibility before interaction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "62c64bb3c0a6",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "696eecf82dbb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074053998988955,
        "ICIR": 0.0455593270860017,
        "RankIC": 0.0255328451637223,
        "RankICIR": 0.1593400656595424,
        "annualized_return": 0.0475535713674498,
        "information_ratio": 0.5902989201047026,
        "max_drawdown": -0.1281671761192537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:17:55.463968",
      "updated_at": "2026-01-17T03:17:55.463974"
    },
    "d822cde10d1bc54f": {
      "factor_id": "d822cde10d1bc54f",
      "factor_name": "Overnight_Gap_Lower_Shadow_Interaction_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Lower_Shadow_Interaction_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional accumulation by multiplying the normalized overnight gap with the relative lower shadow length. A positive gap followed by price rejection at the lows (long lower shadow) suggests 'Smart Money' is defending the position. The gap is normalized by the 5-day price volatility to account for varying market regimes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and intraday support—measured as the product of the normalized overnight gap and the lower shadow length relative to the volume-weighted price deviation—identifies institutional accumulation and trend continuation.\n                Concise Observation: Parent strategies show that overnight gaps capture information asymmetry (RankIC 0.030) and lower shadows indicate price rejection (RankIC 0.021), suggesting that their intersection reveals high-conviction 'breakaway' moves rather than exhaustion.\n                Concise Justification: Institutional 'Smart Money' often positions overnight, and their continued support during intraday dips (lower shadows) confirms the validity of the initial gap, filtering out noise from retail-driven volatility.\n                Concise Knowledge: If an overnight price gap is sustained and subsequently defended by intraday buying pressure (long lower shadows), it indicates institutional conviction; when this recovery is high relative to the volume-weighted average price, the signal for future positive returns is strengthened.\n                concise Specification: The factor is defined as (Gap / Daily_Volatility) * (Lower_Shadow / (High - Low)) * (VWAP / Close), where Gap is (Open - Prev_Close) and the window for volatility and VWAP is 1 day, targeting a multi-day return prediction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4d83ddf20a43",
      "parent_trajectory_ids": [
        "2e043cd85785",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051819354837216,
        "ICIR": 0.0400666235467534,
        "RankIC": 0.0223888233115769,
        "RankICIR": 0.1731252769066772,
        "annualized_return": 0.0800904971652552,
        "information_ratio": 1.1991589482185585,
        "max_drawdown": -0.0851840722238418
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:18:02.149526",
      "updated_at": "2026-01-17T03:18:02.149533"
    },
    "e96740b7992d2742": {
      "factor_id": "e96740b7992d2742",
      "factor_name": "Gap_Continuation_ZScore_20D",
      "factor_expression": "TS_ZSCORE($open - DELAY($close, 1), 20) * (($open - $low) / (ABS($close - $open) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($open - DELAY($close, 1), 20) * (($open - $low) / (ABS($close - $open) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Continuation_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the conviction of an overnight gap by evaluating if the intraday low stays significantly above the previous day's close, weighted by the relative size of the lower shadow. This version uses Z-scoring to normalize the gap magnitude over a 20-day window.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and intraday support—measured as the product of the normalized overnight gap and the lower shadow length relative to the volume-weighted price deviation—identifies institutional accumulation and trend continuation.\n                Concise Observation: Parent strategies show that overnight gaps capture information asymmetry (RankIC 0.030) and lower shadows indicate price rejection (RankIC 0.021), suggesting that their intersection reveals high-conviction 'breakaway' moves rather than exhaustion.\n                Concise Justification: Institutional 'Smart Money' often positions overnight, and their continued support during intraday dips (lower shadows) confirms the validity of the initial gap, filtering out noise from retail-driven volatility.\n                Concise Knowledge: If an overnight price gap is sustained and subsequently defended by intraday buying pressure (long lower shadows), it indicates institutional conviction; when this recovery is high relative to the volume-weighted average price, the signal for future positive returns is strengthened.\n                concise Specification: The factor is defined as (Gap / Daily_Volatility) * (Lower_Shadow / (High - Low)) * (VWAP / Close), where Gap is (Open - Prev_Close) and the window for volatility and VWAP is 1 day, targeting a multi-day return prediction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4d83ddf20a43",
      "parent_trajectory_ids": [
        "2e043cd85785",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051819354837216,
        "ICIR": 0.0400666235467534,
        "RankIC": 0.0223888233115769,
        "RankICIR": 0.1731252769066772,
        "annualized_return": 0.0800904971652552,
        "information_ratio": 1.1991589482185585,
        "max_drawdown": -0.0851840722238418
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:18:02.184667",
      "updated_at": "2026-01-17T03:18:02.184673"
    },
    "9693654b8d3f4aea": {
      "factor_id": "9693654b8d3f4aea",
      "factor_name": "Structural_Tactical_Convergence_Factor",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Tactical_Convergence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis focusing on the convergence of structural price-volume decoupling and short-term range expansion. It uses the rank of the product of volume-price divergence and volatility-normalized range to identify high-probability reversal zones.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The High-Conviction Exhaustion Factor combines a 20-day price-volume correlation regime filter with a 5-day volatility-normalized range stretch and intraday price skew to identify high-probability mean-reversion points.\n                Concise Observation: Parent 1 (RankIC 0.029) identifies structural trend weakness via price-volume divergence, while Parent 2 (RankIC 0.023) captures tactical exhaustion; combining them reduces the 'falling knife' risk of pure volatility triggers.\n                Concise Justification: Market reversals are most robust when structural exhaustion (20-day volume divergence) aligns with tactical capitulation (5-day range stretch), as the lack of volume support at price extremes suggests an imminent liquidity vacuum and trend flip.\n                Concise Knowledge: If medium-term price-volume decoupling (negative correlation) signals a loss of trend conviction, then short-term volatility spikes (High-Low range expansion) followed by extreme intraday price positioning (Close relative to Range) act as high-probability triggers for mean reversion.\n                concise Specification: The factor is defined as the product of the 20-day rank-correlation of price and volume, the 5-day Z-score of the (High-Low)/Close range, and the intraday skew ((Close-Low)/(High-Low) - 0.5), filtered by a 60-day price momentum threshold.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2f675cfa4c94",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054294617308086,
        "ICIR": 0.0403817037639643,
        "RankIC": 0.0201054522477108,
        "RankICIR": 0.1507632154211738,
        "annualized_return": 0.0591266192987523,
        "information_ratio": 0.8377864499731825,
        "max_drawdown": -0.1556919240039379
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:41.266101",
      "updated_at": "2026-01-17T03:23:41.266108"
    },
    "5f3f4b1b8c689ea1": {
      "factor_id": "5f3f4b1b8c689ea1",
      "factor_name": "Exhaustion_Stability_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Stability_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by calculating the 5-day average of the ratio between the candle body and the total daily range, weighted by the 10-day R-squared of the price trend. A low body-to-range ratio combined with high trend linearity (R-squared) suggests a potential reversal after a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.722344",
      "updated_at": "2026-01-17T03:25:33.722351"
    },
    "acd93be4bfe19b46": {
      "factor_id": "acd93be4bfe19b46",
      "factor_name": "Trend_Stability_Rejection_Ratio",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Rejection_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price linearity and intraday rejection. It uses the 10-day R-squared as a filter for trend maturity and measures the relative size of the candle body. Lower values indicate higher reversal probability at the end of a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.758911",
      "updated_at": "2026-01-17T03:25:33.758916"
    },
    "ab48d0b9b27ffa64": {
      "factor_id": "ab48d0b9b27ffa64",
      "factor_name": "Exhaustion_Flow_Divergence_20D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Flow_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price exhaustion by multiplying the normalized intraday range (volatility spike) with the price-volume correlation. A high range relative to its 20-day average combined with a low or negative price-volume correlation suggests a 'blow-off top' or retail exhaustion, signaling a potential reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid factor 'Exhaustion_Flow_Divergence' is calculated by multiplying the 5-day intraday range normalized by its 20-day ATR with the 20-day rolling correlation between price and volume, capturing high-conviction reversals when volatility spikes are unsupported by volume flow.\n                Concise Observation: Parent 1 (PV correlation) captures trend quality (RankIC 0.029) and Parent 2 (Range expansion) captures volatility extremes (RankIC 0.023), but neither distinguishes between a 'breakout' and a 'blow-off top' in isolation.\n                Concise Justification: By interacting the short-term range stretch with medium-term PV correlation, we create a non-linear filter where the signal strength is amplified only when price urgency (volatility) and flow conviction (correlation) diverge.\n                Concise Knowledge: If a volatility spike (High-Low) occurs with declining price-volume correlation, it indicates a retail-driven exhaustion climax likely to reverse; whereas high correlation during spikes suggests institutional trend confirmation.\n                concise Specification: The factor is defined as ( (High - Low) / SMA(High - Low, 20) ) * Correlation(Close, Volume, 20). A high positive value suggests trend continuation, while a high value with a sign flip in correlation indicates a mean-reversion opportunity.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "993b2c78a85b",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059925956114096,
        "ICIR": 0.0438085618038032,
        "RankIC": 0.021177103155139,
        "RankICIR": 0.1596705791765874,
        "annualized_return": 0.062064173995162,
        "information_ratio": 0.8276913265386626,
        "max_drawdown": -0.1271856852731376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:28:58.715046",
      "updated_at": "2026-01-17T03:28:58.715053"
    },
    "4834dbee6b9fd7f3": {
      "factor_id": "4834dbee6b9fd7f3",
      "factor_name": "MDEC_Exhaustion_Reversal_10D",
      "factor_expression": "(RANK(TS_RANK($return, 10)) - RANK(TS_RANK($return * $volume, 10))) * INV(1 + ABS(TS_CORR($return, $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_RANK(TS_PCTCHANGE($close, 1), 10)) - RANK(TS_RANK(TS_PCTCHANGE($close, 1) * $volume, 10))) * INV(1 + ABS(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 0.00001))\" # Your output factor expression will be filled in here\n    name = \"MDEC_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price reversals by detecting momentum-volume divergence. It calculates the difference between price return rank and volume-weighted momentum rank, scaled by the inverse of return-volume correlation and the ratio of overnight gaps to intraday volatility. High values signal 'hollow' price moves likely to mean-revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Dimensional Exhaustion Convergence (MDEC) factor predicts short-term reversals by identifying 10-day price-volume momentum divergences that are validated by a decay in return-volume correlation and an increase in the ratio of overnight gaps to intraday volatility.\n                Concise Observation: Parent 1 (RankIC 0.0239) identifies simple momentum-volume divergence, while Parent 2 (RankIC 0.0271) captures structural decay in volume support; combining these filters reduces false positives in trend-following by isolating 'hollow' price moves.\n                Concise Justification: A price trend lacking volume correlation indicates diminishing liquidity support, and a high overnight-to-intraday range ratio suggests that price discovery is shifting away from active trading sessions, both of which are hallmarks of trend exhaustion.\n                Concise Knowledge: If price momentum diverges from volume-weighted momentum while the rolling correlation between returns and volume decreases, the trend is likely driven by low-conviction flows; when this coincides with expanding overnight gaps relative to intraday ranges, it signals institutional exhaustion and an impending mean reversion.\n                concise Specification: Calculate the difference between 10-day price return percentile and 10-day VWAP momentum percentile; multiply this by the inverse of the 10-day rolling correlation between daily returns and volume, and scale by the ratio of the absolute overnight gap (abs(open - prev_close)) to the 10-day average intraday range (high - low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "977c8dae85e8",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "17cebd62c163"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:31:51.502092",
      "updated_at": "2026-01-17T03:31:51.502099"
    },
    "29de2f90c029124e": {
      "factor_id": "29de2f90c029124e",
      "factor_name": "LAME_ZScore_Efficiency_Trend",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 10) - TS_PCTCHANGE($close * $volume, 10)) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 10) - TS_PCTCHANGE($close * $volume, 10)) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"LAME_ZScore_Efficiency_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the LAME hypothesis focusing on the z-score of price-volume divergence relative to the efficiency of price discovery. It captures the degree to which price is overextending relative to the liquidity required to move it.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Momentum Exhaustion (LAME) factor, calculated as the product of the 10-day price-volume trend divergence and the 5-day average intraday price-volume efficiency, identifies fragile price trends prone to mean reversion.\n                Concise Observation: Parent strategies show that price-volume divergence (RankIC 0.0239) and intraday efficiency (RankIC 0.0265) both capture exhaustion, but individual signals often fail during high-liquidity trend continuations.\n                Concise Justification: Combining divergence with efficiency filters for 'expensive' price movements; a trend that requires high volatility on low relative volume to sustain itself is fundamentally unstable compared to one backed by dense liquidity.\n                Concise Knowledge: If a stock exhibits high price momentum relative to its volume-weighted momentum while simultaneously showing high intraday range per unit volume, then the trend is likely liquidity-constrained and prone to reversal.\n                concise Specification: Define Divergence as the difference between 10-day price change percentile and 10-day VWAP momentum percentile; define IPVE as (High-Low)/Volume; the factor is the product of Divergence and the 5-day moving average of IPVE.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a685230d9429",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:34:38.146402",
      "updated_at": "2026-01-17T03:34:38.146408"
    },
    "40f08d46d096ced8": {
      "factor_id": "40f08d46d096ced8",
      "factor_name": "LAME_Rank_Efficiency_Product",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"LAME_Rank_Efficiency_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the LAME hypothesis by using the cross-sectional rank of the intraday price-volume efficiency multiplied by the momentum divergence. This ensures the factor is robust to outliers in volume and price range across different stocks.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Momentum Exhaustion (LAME) factor, calculated as the product of the 10-day price-volume trend divergence and the 5-day average intraday price-volume efficiency, identifies fragile price trends prone to mean reversion.\n                Concise Observation: Parent strategies show that price-volume divergence (RankIC 0.0239) and intraday efficiency (RankIC 0.0265) both capture exhaustion, but individual signals often fail during high-liquidity trend continuations.\n                Concise Justification: Combining divergence with efficiency filters for 'expensive' price movements; a trend that requires high volatility on low relative volume to sustain itself is fundamentally unstable compared to one backed by dense liquidity.\n                Concise Knowledge: If a stock exhibits high price momentum relative to its volume-weighted momentum while simultaneously showing high intraday range per unit volume, then the trend is likely liquidity-constrained and prone to reversal.\n                concise Specification: Define Divergence as the difference between 10-day price change percentile and 10-day VWAP momentum percentile; define IPVE as (High-Low)/Volume; the factor is the product of Divergence and the 5-day moving average of IPVE.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a685230d9429",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:34:38.164585",
      "updated_at": "2026-01-17T03:34:38.164590"
    },
    "525b9fd9ff076a5a": {
      "factor_id": "525b9fd9ff076a5a",
      "factor_name": "Liquidity_Exhaustion_Reversion_20D",
      "factor_expression": "(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 20-day abnormal turnover ratio. A high positive value indicates a 'blow-off top' where prices are pushed significantly above the average intraday cost on high volume, suggesting liquidity exhaustion and a likely downward reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.768309",
      "updated_at": "2026-01-17T03:37:08.768316"
    },
    "7147211d46e7ca79": {
      "factor_id": "7147211d46e7ca79",
      "factor_name": "ZScored_Liquidity_Divergence_15D",
      "factor_expression": "TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Liquidity_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the price-VWAP deviation and the Z-score of volume to identify statistical outliers in liquidity consumption. It captures periods where the price is at a multi-standard deviation distance from the daily average price on significantly higher-than-normal volume.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.805539",
      "updated_at": "2026-01-17T03:37:08.805545"
    },
    "c3c1d58825d6e03f": {
      "factor_id": "c3c1d58825d6e03f",
      "factor_name": "Absorption_Breakout_Proximity_3D",
      "factor_expression": "($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Absorption_Breakout_Proximity_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the micro-structure stability (low range-to-volume ratio) with the proximity of the current price to the 3-day high. It targets breakout continuation by identifying stocks where absorption is occurring near resistance levels. The stability component is inverted so that higher values represent more stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.435984",
      "updated_at": "2026-01-17T03:39:34.435990"
    },
    "2cd7851c51b79b5a": {
      "factor_id": "2cd7851c51b79b5a",
      "factor_name": "Stability_Reversion_RSQR_WVMA_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stability_Reversion_RSQR_WVMA_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by multiplying the trend stability (R-squared of price against time) with the price deviation from a Volume Weighted Moving Average. High R-squared indicates a consensus-driven trend, while a large deviation from WVMA suggests exhaustion. The factor uses TS_CORR squared to represent R-squared and a volume-weighted price proxy.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.879266",
      "updated_at": "2026-01-17T03:40:59.879273"
    },
    "ec7e0fd06961de67": {
      "factor_id": "ec7e0fd06961de67",
      "factor_name": "Trend_Exhaustion_Linearity_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Linearity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stability-reversion hypothesis focusing on a shorter 5-day window. It captures the interaction between the linearity of the price trend (R-squared) and the standardized distance from the volume-weighted average price to detect speculative blow-off points.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.899548",
      "updated_at": "2026-01-17T03:40:59.899554"
    },
    "016dc251bf05446e": {
      "factor_id": "016dc251bf05446e",
      "factor_name": "Idiosyncratic_Range_Decoupling_Rank",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD(TS_PCTCHANGE($close, 1)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Range_Decoupling_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Volatility Convexity' of a stock relative to the cross-sectional market dispersion. It uses RANK to normalize the ratio of current range volatility against its historical mean, then scales it by the inverse of market-wide return dispersion to isolate assets undergoing unique fundamental adjustments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.188725",
      "updated_at": "2026-01-17T03:46:21.188731"
    },
    "9724358e7953d565": {
      "factor_id": "9724358e7953d565",
      "factor_name": "Overnight_Sentiment_Volatility_Ratio_20D",
      "factor_expression": "($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_STD(($close / (DELAY($close, 1) + 1e-8)) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by measuring the overnight price gap relative to historical volatility. A large gap compared to the 20-day standard deviation of returns suggests a potential emotional overreaction that is likely to revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.407397",
      "updated_at": "2026-01-17T03:49:20.407403"
    },
    "d8f036d6e6b62e0a": {
      "factor_id": "d8f036d6e6b62e0a",
      "factor_name": "Mean_Reversion_Efficiency_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * TS_PCTCHANGE($close, 60) * TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * TS_PCTCHANGE($close, 60) * TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Mean_Reversion_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion entries by combining negative price-volume correlation (indicating selling exhaustion) with medium-term price momentum and a short-term intraday efficiency ratio. High values suggest that a downward trend is losing steam and showing signs of high-conviction intraday buying.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative price-volume correlation and a 60-day price momentum, when filtered by a 5-day average intraday price efficiency ratio (Close-Open)/(High-Low), identifies high-conviction mean-reversion entries by distinguishing institutional accumulation from retail noise.\n                Concise Observation: Parent 1 identifies mean-reversion regimes but suffers from 'falling knives' due to lack of timing; Parent 2 identifies intraday conviction but lacks trend context; combining them targets assets where price drift has exhausted and new directional conviction is emerging.\n                Concise Justification: Negative price-volume correlation indicates a lack of selling pressure at lower prices (exhaustion), while a high ratio of (Close-Open) to (High-Low) indicates that intraday price movement is efficient and dominated by directional flow rather than random noise.\n                Concise Knowledge: If a medium-term price decline is accompanied by decoupling volume (exhaustion) and high intraday displacement efficiency (conviction), then the probability of a persistent trend reversal is higher than in cases with high intraday volatility but low net displacement.\n                concise Specification: Define Factor as the product of: (1) 20-day Spearman correlation of $close and $volume, (2) 60-day price return, and (3) 5-day moving average of abs($close - $open) / ($high - $low + epsilon), focusing on the intersection of low momentum and high efficiency.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a765057e4a75",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "677bfa9f37b3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059444334061954,
        "ICIR": 0.0415344081304131,
        "RankIC": 0.0231783460341772,
        "RankICIR": 0.1675708044085009,
        "annualized_return": 0.0496824335896681,
        "information_ratio": 0.7773368973755901,
        "max_drawdown": -0.0585744017921535
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:41.513713",
      "updated_at": "2026-01-17T03:49:41.513720"
    },
    "1f99d421bb121b0f": {
      "factor_id": "1f99d421bb121b0f",
      "factor_name": "Liquidity_Elasticity_Index_10D",
      "factor_expression": "ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Elasticity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the elasticity of liquidity by comparing the price range to the standardized volume turnover. It targets regimes where price trends become fragile due to surging execution costs (proxied by volume volatility), signaling an impending mean-reversion event.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.637184",
      "updated_at": "2026-01-17T03:52:20.637190"
    },
    "243c743e2fe55295": {
      "factor_id": "243c743e2fe55295",
      "factor_name": "Relative_Extreme_Volume_Skew_10D",
      "factor_expression": "RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Extreme_Volume_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 10-day average of volume-weighted price skewness. It normalizes the intraday position of the close relative to the high-low range and scales it by volume. By applying a cross-sectional RANK, it identifies stocks where volume is most heavily concentrated at price extremes relative to the peer group, suggesting trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.382751",
      "updated_at": "2026-01-17T03:53:53.382758"
    },
    "f2e8b0bf5cbd2fa2": {
      "factor_id": "f2e8b0bf5cbd2fa2",
      "factor_name": "Intraday_Efficiency_Ratio_20D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Efficiency_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures long-term institutional positioning by measuring the average intraday efficiency over a 20-day window. It identifies stocks where price appreciation is achieved with low path-volatility relative to the daily range, filtering out high-frequency noise and retail-driven shocks.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.001994",
      "updated_at": "2026-01-17T03:54:31.002003"
    },
    "b1a1d0ebf13c8116": {
      "factor_id": "b1a1d0ebf13c8116",
      "factor_name": "ZScore_IER_Trend_10D",
      "factor_expression": "ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"ZScore_IER_Trend_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the Intraday Efficiency Ratio (IER) cross-sectionally to identify stocks with the most efficient price trends relative to the market. It uses a 10-day moving average of the ratio to ensure stability and then applies a Z-score for cross-sectional comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.038363",
      "updated_at": "2026-01-17T03:54:31.038371"
    },
    "ffa41311903d2f78": {
      "factor_id": "ffa41311903d2f78",
      "factor_name": "ICD_Factor_20D_5D",
      "factor_expression": "TS_MEAN(TS_CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), 5)\" # Your output factor expression will be filled in here\n    name = \"ICD_Factor_20D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Institutional Conviction Divergence (ICD) factor identifies high-conviction institutional trends in low-impact accumulation phases. It combines price-volume correlation (conviction) with a range-to-volume efficiency ratio (stealth), smoothed to reduce noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Conviction Divergence (ICD) factor, defined as the product of the 20-day price-volume correlation and the 5-day range-to-volume efficiency ratio, identifies high-conviction institutional trends that are currently in a low-impact accumulation phase.\n                Concise Observation: Parent 1 showed that price-volume synchrony (RankIC 0.025) captures momentum conviction, while Parent 2 showed that decoupling price range from volume intensity (RankIC 0.026) identifies stealth institutional activity.\n                Concise Justification: By multiplying the conviction metric (CORR) with the efficiency metric (Range/Volume), we amplify signals where the market agrees on direction but the execution remains 'stealthy' and efficient, filtering out high-friction retail exhaustion phases.\n                Concise Knowledge: If a strong positive correlation between price and volume is accompanied by a high price-range-to-volume ratio, it indicates efficient institutional accumulation; when these two signals converge, the resulting momentum is more sustainable than volume-heavy retail-driven moves.\n                concise Specification: The factor is calculated as CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), smoothed by a 5-day moving average to ensure signal stability and reduce noise from daily liquidity fluctuations.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "27a5787f65fc",
      "parent_trajectory_ids": [
        "c4016b5d2dfb",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058738787037622,
        "ICIR": 0.0409147214264877,
        "RankIC": 0.0237358595926097,
        "RankICIR": 0.1682903117923777,
        "annualized_return": 0.0450439052909164,
        "information_ratio": 0.6313711650225228,
        "max_drawdown": -0.1046087378096799
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:55:10.915099",
      "updated_at": "2026-01-17T03:55:10.915106"
    },
    "b1435518c0e34cff": {
      "factor_id": "b1435518c0e34cff",
      "factor_name": "Liquidity_Exhaustion_Ratio_1D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price exhaustion by measuring the ratio of the daily price range to the trading volume, normalized by the relative position of the close. High values indicate 'thin' price moves where price discovery occurs on low volume intensity, signaling a likely mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.927814",
      "updated_at": "2026-01-17T03:57:08.927821"
    },
    "2aba12657a8d146a": {
      "factor_id": "2aba12657a8d146a",
      "factor_name": "Volume_Density_Compression_ZScore_10D",
      "factor_expression": "TS_ZSCORE($volume / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Density_Compression_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of volume relative to price movement, standardized against its 10-day history. A high value suggests that volume is clustering within a tight price range, indicating institutional absorption before a volatility expansion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.837299",
      "updated_at": "2026-01-17T04:00:06.837305"
    },
    "10a3628cfd4ea100": {
      "factor_id": "10a3628cfd4ea100",
      "factor_name": "Cross_Sectional_Liquidity_Vacuum_20D",
      "factor_expression": "RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Vacuum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the relative liquidity exhaustion across the market. It ranks the ratio of a smoothed price range to smoothed volume, highlighting stocks where price volatility is disproportionately high compared to trading activity, adjusted for a 20-day lookback.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.781726",
      "updated_at": "2026-01-17T04:01:01.781732"
    },
    "f31a3d208db11e89": {
      "factor_id": "f31a3d208db11e89",
      "factor_name": "Relative_Volume_Density_Rank_10D",
      "factor_expression": "RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Density_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of volume density (volume per unit of price range) relative to its recent time-series distribution. It targets stocks where the current volume-to-range ratio is at a historical peak, signaling potential exhaustion of sellers and a forthcoming breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.950367",
      "updated_at": "2026-01-17T04:02:51.950373"
    },
    "3030871e1ca545c4": {
      "factor_id": "3030871e1ca545c4",
      "factor_name": "IIA_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies Institutional Inventory Absorption (IIA) by calculating the ratio of the 20-day average volume to the 20-day price volatility. High values indicate 'Quiet Accumulation' where high volume is absorbed with minimal price movement, signaling a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.319517",
      "updated_at": "2026-01-17T04:03:00.319524"
    },
    "e99dc8eb50384b19": {
      "factor_id": "e99dc8eb50384b19",
      "factor_name": "Hollow_Trend_Reversal_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELAY($return, 1), 10)) * (1.0 - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10)) * (1.0 - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Trend_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trends that lack structural support by multiplying the 10-day return autocorrelation with a volume-based penalty. It uses the inverse of the volume rank to amplify signals where price persistence is high but market participation is low, indicating a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.754210",
      "updated_at": "2026-01-17T04:12:15.754216"
    },
    "14ab16974a927eb5": {
      "factor_id": "14ab16974a927eb5",
      "factor_name": "Retail_Exhaustion_Institutional_Floor_5D",
      "factor_expression": "RANK(TS_ZSCORE($return, 5)) * RANK(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_PCTCHANGE($close, 1), 5)) * RANK(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Retail_Exhaustion_Institutional_Floor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the LIFA hypothesis focusing on the interaction between retail-driven price spikes (Z-score of returns) and the failure of institutional support levels (Low-to-Range ratio). It uses RANK to normalize the components cross-sectionally for better stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Institutional Flow Asymmetry (LIFA) factor predicts price reversals by identifying scenarios where retail-driven liquidity exhaustion (high late-session price-VWAP divergence) occurs simultaneously with a breakdown in institutional support (low 3-day Low-to-Range ratio) and is confirmed by a decoupling of price-volume correlation.\n                Concise Observation: Parent 1 (RankIC=0.0248) successfully captures retail over-extension via VWAP divergence, while Parent 2 (RankIC=0.0265) identifies institutional price floors; combining these reveals that price extremes are most mean-reverting when the structural support levels and volume-driven momentum disagree.\n                Concise Justification: Retail exhaustion often marks the end of a price move, but without checking institutional support levels (Low-to-Range), it is difficult to distinguish between a temporary pullback and a trend exhaustion. Integrating both ensures the factor captures both the intensity of the move and its structural location.\n                Concise Knowledge: If high turnover and late-session price-VWAP divergence (retail exhaustion) coincide with a price position near the bottom of the recent range (institutional floor failure), then the probability of a sharp mean reversion increases; this signal is more robust when price-volume correlation is low, indicating a lack of trend conviction.\n                concise Specification: The factor is calculated as the product of the 5-day Z-score of (Close - VWAP) and the 3-day mean of ((Low - Min(Low, 5)) / (Max(High, 5) - Min(Low, 5))), further scaled by the inverse of the 10-day price-volume correlation.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "86305af25597",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0089195923003938,
        "ICIR": 0.0709347875880521,
        "RankIC": 0.0222380896811452,
        "RankICIR": 0.1868603002457731,
        "annualized_return": 0.077421642056292,
        "information_ratio": 1.2212093417608447,
        "max_drawdown": -0.0728690176970663
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:13:23.785027",
      "updated_at": "2026-01-17T04:13:23.785033"
    },
    "44974a2d1e0f693f": {
      "factor_id": "44974a2d1e0f693f",
      "factor_name": "Decoupled_Liquidity_Asymmetry_15D",
      "factor_expression": "TS_RANK($close, 10) * (1 - ABS(TS_CORR($close, $volume, 15)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK($close, 10) * (1 - ABS(TS_CORR($close, $volume, 15)))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Liquidity_Asymmetry_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'decoupling' aspect of the LIFA hypothesis. It measures the divergence between price action and volume conviction, specifically looking for instances where price is at an extreme relative to its 10-day range but volume correlation is collapsing, suggesting a lack of institutional follow-through.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Institutional Flow Asymmetry (LIFA) factor predicts price reversals by identifying scenarios where retail-driven liquidity exhaustion (high late-session price-VWAP divergence) occurs simultaneously with a breakdown in institutional support (low 3-day Low-to-Range ratio) and is confirmed by a decoupling of price-volume correlation.\n                Concise Observation: Parent 1 (RankIC=0.0248) successfully captures retail over-extension via VWAP divergence, while Parent 2 (RankIC=0.0265) identifies institutional price floors; combining these reveals that price extremes are most mean-reverting when the structural support levels and volume-driven momentum disagree.\n                Concise Justification: Retail exhaustion often marks the end of a price move, but without checking institutional support levels (Low-to-Range), it is difficult to distinguish between a temporary pullback and a trend exhaustion. Integrating both ensures the factor captures both the intensity of the move and its structural location.\n                Concise Knowledge: If high turnover and late-session price-VWAP divergence (retail exhaustion) coincide with a price position near the bottom of the recent range (institutional floor failure), then the probability of a sharp mean reversion increases; this signal is more robust when price-volume correlation is low, indicating a lack of trend conviction.\n                concise Specification: The factor is calculated as the product of the 5-day Z-score of (Close - VWAP) and the 3-day mean of ((Low - Min(Low, 5)) / (Max(High, 5) - Min(Low, 5))), further scaled by the inverse of the 10-day price-volume correlation.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "86305af25597",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0089195923003938,
        "ICIR": 0.0709347875880521,
        "RankIC": 0.0222380896811452,
        "RankICIR": 0.1868603002457731,
        "annualized_return": 0.077421642056292,
        "information_ratio": 1.2212093417608447,
        "max_drawdown": -0.0728690176970663
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:13:23.807451",
      "updated_at": "2026-01-17T04:13:23.807457"
    },
    "85c86e3efae357d7": {
      "factor_id": "85c86e3efae357d7",
      "factor_name": "Institutional_Absorption_Ratio_5D",
      "factor_expression": "(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of price range to volume-weighted impact. A low value suggests 'quiet' accumulation where high volume turnover occurs within a tight price range, indicating institutional absorption before a potential breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.310621",
      "updated_at": "2026-01-17T04:16:58.310627"
    },
    "6676834534de5750": {
      "factor_id": "6676834534de5750",
      "factor_name": "Z_Conviction_Gap_Dispersion_10D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) * (TS_MEAN(STD($return), 10) + 1e-8)))",
      "factor_implementation_code": "",
      "factor_description": "A cross-sectionally standardized version of the conviction divergence. It measures the overnight gap relative to the recent cross-sectional dispersion of returns, then applies a Z-score to ensure the signal is comparable across different market regimes. This highlights idiosyncratic moves that deviate most from the current market noise level.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Idiosyncratic Conviction Divergence' factor, calculated as the ratio of the overnight gap to the 10-day cross-sectional volatility dispersion, identifies alpha by isolating high-conviction institutional re-pricing that occurs independently of systemic market noise.\n                Concise Observation: Parent strategies show that both intraday volatility dispersion (RankIC 0.026) and institutional gap signals (RankIC 0.025) provide predictive power, but they often struggle to distinguish between broad market beta spikes and stock-specific information events.\n                Concise Justification: By normalizing the overnight gap (a proxy for institutional conviction) by the cross-sectional volatility dispersion (a proxy for market noise), we create a signal-to-noise ratio that highlights 'clean' price discoveries likely to persist.\n                Concise Knowledge: If an overnight price gap is large relative to the current cross-sectional dispersion of returns, it indicates idiosyncratic institutional conviction; when such moves occur during periods of low market-wide dispersion, they are more likely to represent sustainable momentum rather than systemic noise.\n                concise Specification: The factor is defined as (Open_t / Close_{t-1} - 1) divided by the standard deviation of all stock returns in the cross-section over the previous 10 days, capturing the purity of the price move relative to the market environment.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a981c8bd8bfe",
      "parent_trajectory_ids": [
        "7513729d3145",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063446725914684,
        "ICIR": 0.0473629018593917,
        "RankIC": 0.0238336727388599,
        "RankICIR": 0.1805527973251633,
        "annualized_return": 0.0883968772409901,
        "information_ratio": 1.3528728247110378,
        "max_drawdown": -0.0963561551508521
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:18:29.819030",
      "updated_at": "2026-01-17T04:18:29.819036"
    },
    "505941f44d7074fe": {
      "factor_id": "505941f44d7074fe",
      "factor_name": "Clean_Breakout_Efficiency_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Breakout_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the stealth momentum hypothesis focusing on price efficiency over a slightly longer window (5 days). It uses the Z-score of the return divided by the volume-volatility product to identify outliers where price moves significantly despite low 'noise' (volume and volatility).",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.895356",
      "updated_at": "2026-01-17T04:20:15.895362"
    },
    "bcd1c01af077b394": {
      "factor_id": "bcd1c01af077b394",
      "factor_name": "Z_LVIG_Momentum_Refined",
      "factor_expression": "ZSCORE((($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Z_LVIG_Momentum_Refined\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the LVIG factor. It captures the relative strength of institutional gap conviction across the market. By using ZSCORE, it identifies stocks with the most significant liquidity-validated breakaway moves relative to the universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Institutional Gap (LVIG) factor predicts returns by multiplying the overnight gap (normalized by 20-day volatility) with an 'Institutional Conviction' ratio (gap size relative to intraday range), further scaled by a volume-based liquidity multiplier to distinguish between sustainable breakaway moves and mean-reverting exhaustion.\n                Concise Observation: Parent strategies showed that overnight gaps have predictive power (RankIC ~0.025), but their effectiveness is limited by failing to distinguish between high-conviction institutional moves and low-liquidity noise that tends to mean-revert.\n                Concise Justification: Combining the overnight gap with intraday price structure (shadows and range) and volume validation creates a regime-switching mechanism that captures momentum when price action is 'solid' and mean-reversion when price action is 'hollow'.\n                Concise Knowledge: If an overnight price gap is accompanied by a small intraday range (high conviction) and high relative volume, it indicates institutional trend continuation; conversely, if the gap is large but followed by high intraday volatility or low volume, it signals a mean-reverting exhaustion gap.\n                concise Specification: The factor is calculated as (Gap / 20-day Volatility) * (Gap / (High - Low + 1e-6)) * (Volume / 10-day Moving Average Volume), where Gap is (Open - Previous Close).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "758c1d6f5792",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056646558545069,
        "ICIR": 0.0409743114100333,
        "RankIC": 0.0231878175384502,
        "RankICIR": 0.1667542903070123,
        "annualized_return": 0.0974907403790993,
        "information_ratio": 1.4980137589442482,
        "max_drawdown": -0.0892909265930361
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:21:36.519526",
      "updated_at": "2026-01-17T04:21:36.519532"
    },
    "baba2b3086bea1bd": {
      "factor_id": "baba2b3086bea1bd",
      "factor_name": "Hollow_Move_ZScore_10D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)) / ($volume / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)) / ($volume / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the VVDE hypothesis focusing on the cross-sectional rank of the ratio between price volatility and volume. It identifies stocks where the intraday range is disproportionately large compared to the recent volume trend, signaling exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Volume Divergence Efficiency (VVDE) factor, calculated as the ratio of the ATR-normalized intraday price range to the 5-day relative volume intensity, predicts future returns by identifying 'hollow' price expansions prone to mean reversion.\n                Concise Observation: Parent strategies showed that while ATR-normalized ranges (RankIC 0.029) and volume exhaustion (RankIC 0.027) are individually predictive, price shocks without volume support often represent unsustainable 'hollow' moves.\n                Concise Justification: By dividing the Relative Intraday Intensity by Relative Volume Intensity, we isolate stocks where the 'cost' of moving price in terms of volume is abnormally high, signaling a lack of liquidity depth and impending trend exhaustion.\n                Concise Knowledge: If intraday price volatility expands significantly while volume remains low relative to its recent average, the price move is likely driven by liquidity voids rather than institutional conviction, leading to a higher probability of reversal.\n                concise Specification: Define VVDE as [(High - Low) / ATR(20)] / [Volume / Mean(Volume, 5)]; high values indicate volatility-volume divergence; expect a negative correlation with next-day returns as these 'hollow' moves mean-revert.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "02ca504bc6bd",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "3806921571eb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078726148102835,
        "ICIR": 0.0524784406475679,
        "RankIC": 0.0298113390161144,
        "RankICIR": 0.1971814056117819,
        "annualized_return": 0.1149124625429248,
        "information_ratio": 1.6386987543596918,
        "max_drawdown": -0.116216639948346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:23:23.038627",
      "updated_at": "2026-01-17T04:23:23.038634"
    },
    "c0c266cb2a021cb5": {
      "factor_id": "c0c266cb2a021cb5",
      "factor_name": "CLC_Ranked_Convergence_V2",
      "factor_expression": "RANK(DELTA(TS_ZSCORE($close, 20), 5)) + RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_ZSCORE($close, 20), 5)) + RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"CLC_Ranked_Convergence_V2\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the CLC factor. It ranks the 5-day momentum of price residuals and the 3-day average of the low-to-range ratio independently before combining them, ensuring the factor is less sensitive to outliers and market regimes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Convexity-Liquidity Convergence (CLC) factor, defined as the product of the 5-day change in volatility-normalized price residuals and the 3-day mean of the Low-to-Range ratio, identifies superior alpha by distinguishing between exhaustion-driven reversals and institutional-backed trend accelerations.\n                Concise Observation: Parent 1 (RankIC 0.0237) captures price exhaustion via residuals, while Parent 2 (RankIC 0.0265) captures liquidity support; combining them addresses the false signals generated when price momentum lacks volume/support confirmation.\n                Concise Justification: Price residuals represent the 'unexplained' component of returns; when their velocity (convexity) peaks, it indicates a potential limit to current price action, which becomes a high-conviction signal when filtered by the physical support levels of daily price ranges.\n                Concise Knowledge: If price residual acceleration (convexity) is high while institutional support (Low-to-Range ratio) is low, a mean-reversion is likely; if both are high, the trend is likely to persist; normalizing residuals by rolling volatility ensures signal stability across regimes.\n                concise Specification: The factor calculates the 5-day difference of (Close - 20-day Mean Close) / 20-day StdDev, then multiplies this by the 3-day rolling average of (Low - Open) / (High - Low), using daily_pv.h5 data.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ced5b34d842b",
      "parent_trajectory_ids": [
        "c7199504b485",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071058661397089,
        "ICIR": 0.0533324050492334,
        "RankIC": 0.0215694843177437,
        "RankICIR": 0.1663182255077696,
        "annualized_return": 0.0583205464909847,
        "information_ratio": 0.921718266716346,
        "max_drawdown": -0.1056371884367749
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:24:41.781397",
      "updated_at": "2026-01-17T04:24:41.781403"
    },
    "f8d517c6f31a9154": {
      "factor_id": "f8d517c6f31a9154",
      "factor_name": "Institutional_Conviction_Liquidity_Ratio",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-6)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-6)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Liquidity_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover. It identifies sustainable price movements by rewarding high institutional conviction (gap) that is not yet undermined by retail-driven liquidity exhaustion (abnormal turnover).",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Liquidity Equilibrium' factor, calculated as the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover, identifies sustainable price movements by rewarding high institutional conviction that is not yet undermined by retail-driven liquidity exhaustion.\n                Concise Observation: Parent 1's liquidity exhaustion (RankIC 0.0248) and Parent 2's institutional conviction (RankIC 0.0252) both capture distinct alpha sources, but individually fail to distinguish between trend persistence and trend exhaustion during high-volatility events.\n                Concise Justification: Institutional investors typically express conviction through overnight gaps, while retail investors often drive late-stage volume surges; a factor that scales the strength of the gap by the inverse of recent volume intensity captures the 'purity' of the institutional signal.\n                Concise Knowledge: If institutional conviction (overnight gap) is high while retail participation (abnormal turnover) remains moderate, the price trend is more likely to persist; conversely, when high conviction is accompanied by extreme turnover, the probability of a mean-reversion event increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as ( (Open - Close_prev) / (High - Low + 1e-6) ) / ( (Volume_5d_mean / Volume_20d_mean) + 1e-6 ), where the numerator represents the conviction gap and the denominator represents the 5-day abnormal turnover ratio as a proxy for liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "fd2838afc896",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059976693228329,
        "ICIR": 0.0442200815507922,
        "RankIC": 0.0227144863478864,
        "RankICIR": 0.1738311683058916,
        "annualized_return": 0.0701262051024463,
        "information_ratio": 1.0822167722531244,
        "max_drawdown": -0.1238228584092356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:27:51.109291",
      "updated_at": "2026-01-17T04:27:51.109297"
    },
    "c02477aa5a4b255b": {
      "factor_id": "c02477aa5a4b255b",
      "factor_name": "ISB_Coil_Support_Gap_10D",
      "factor_expression": "(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * TS_MEAN(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8), 5) * SIGN($open - DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * TS_MEAN(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8), 5) * SIGN($open - DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"ISB_Coil_Support_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Informed Structural Breakout factor identifies sustainable price moves by multiplying a 10-day volume density (Coil) with a 5-day institutional support score and the sign of the overnight price gap. High volume in a narrow range signifies accumulation, which, when combined with price support and a positive gap, indicates a high-conviction breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Structural Breakout (ISB) factor identifies sustainable price moves by multiplying a 10-day volatility-normalized volume density (representing 'coiled' liquidity) with a 5-day institutional support persistence score and the sign of the overnight price gap.\n                Concise Observation: Parent 1 (RankIC=0.0234) successfully captures volume concentration but lacks directional conviction, while Parent 2 (RankIC=0.0265) identifies support levels but misses the explosive potential of low-volatility 'coils'.\n                Concise Justification: Multiplying volume density by a support metric creates a non-linear filter that prioritizes assets where liquidity is being actively absorbed at established price floors, while the overnight gap provides a high-conviction directional trigger.\n                Concise Knowledge: If high volume density occurs within a narrow price range (compression), it signifies accumulation; when this state is combined with institutional price support and confirmed by overnight sentiment, the subsequent breakout is more likely to be persistent.\n                concise Specification: Define 'Coil' as the 10-day sum of volume divided by the 10-day price range; define 'Support' as the 5-day average of (Low - Close.min) / (High - Low); the final factor is Coil * Support * sign(Open - Close_prev).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "8a6e9fe51078",
      "parent_trajectory_ids": [
        "2e3d00378ae9",
        "d75e00a65fc2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029805922840875,
        "ICIR": 0.0220525340961762,
        "RankIC": 0.0180366356582126,
        "RankICIR": 0.1365198838404512,
        "annualized_return": 0.0320310098625329,
        "information_ratio": 0.4775910895196999,
        "max_drawdown": -0.1228907016328854
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:30:31.004543",
      "updated_at": "2026-01-17T04:30:31.004550"
    },
    "b5d213c5e57ba216": {
      "factor_id": "b5d213c5e57ba216",
      "factor_name": "Z_Informed_Breakout_Ranked",
      "factor_expression": "RANK(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * RANK(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * RANK(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"Z_Informed_Breakout_Ranked\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Informed Structural Breakout hypothesis. It normalizes the 'Coil' (volume/range ratio) and 'Support' (relative low position) components to ensure the factor is robust across different market regimes and asset scales before applying the overnight gap trigger.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Structural Breakout (ISB) factor identifies sustainable price moves by multiplying a 10-day volatility-normalized volume density (representing 'coiled' liquidity) with a 5-day institutional support persistence score and the sign of the overnight price gap.\n                Concise Observation: Parent 1 (RankIC=0.0234) successfully captures volume concentration but lacks directional conviction, while Parent 2 (RankIC=0.0265) identifies support levels but misses the explosive potential of low-volatility 'coils'.\n                Concise Justification: Multiplying volume density by a support metric creates a non-linear filter that prioritizes assets where liquidity is being actively absorbed at established price floors, while the overnight gap provides a high-conviction directional trigger.\n                Concise Knowledge: If high volume density occurs within a narrow price range (compression), it signifies accumulation; when this state is combined with institutional price support and confirmed by overnight sentiment, the subsequent breakout is more likely to be persistent.\n                concise Specification: Define 'Coil' as the 10-day sum of volume divided by the 10-day price range; define 'Support' as the 5-day average of (Low - Close.min) / (High - Low); the final factor is Coil * Support * sign(Open - Close_prev).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "8a6e9fe51078",
      "parent_trajectory_ids": [
        "2e3d00378ae9",
        "d75e00a65fc2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029805922840875,
        "ICIR": 0.0220525340961762,
        "RankIC": 0.0180366356582126,
        "RankICIR": 0.1365198838404512,
        "annualized_return": 0.0320310098625329,
        "information_ratio": 0.4775910895196999,
        "max_drawdown": -0.1228907016328854
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:30:31.028117",
      "updated_at": "2026-01-17T04:30:31.028123"
    },
    "c8fbcdcf82df067d": {
      "factor_id": "c8fbcdcf82df067d",
      "factor_name": "Ranked_LASC_Institutional_Accumulation",
      "factor_expression": "SIGN($open - DELAY($close, 1)) * RANK(TS_MEAN($volume / ($high - $low + 1e-6), 3)) * RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open - DELAY($close, 1)) * RANK(TS_MEAN($volume / ($high - $low + 1e-6), 3)) * RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_LASC_Institutional_Accumulation\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the LASC factor. It focuses on the relative strength of liquidity absorption and support persistence across the universe, smoothing the components to ensure robustness against outliers in volume and range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Absorption & Support Convergence (LASC) factor, calculated as the product of a 3-day price absorption ratio (volume divided by high-low range) and a 5-day support persistence metric (mean of low-to-range ratio), identifies high-quality institutional accumulation when adjusted by the sign of the overnight gap.\n                Concise Observation: Parent 1 showed that intraday stability (low range per volume) captures institutional activity (RankIC=0.0229), while Parent 2 demonstrated that support levels and overnight gaps predict reversals (RankIC=0.0265); combining these filters reduces noise from low-volatility drift.\n                Concise Justification: Institutional buyers often hide their tracks by absorbing liquidity within tight price bands; by multiplying the absorption efficiency with a support-based persistence measure, we isolate periods where price floors are actively defended by large-scale limit orders.\n                Concise Knowledge: If high volume occurs within a narrow price range (absorption) while prices consistently hold near the daily lows (support persistence), then the underlying asset is likely experiencing institutional accumulation; this signal is more reliable when confirmed by overnight sentiment (gap direction).\n                concise Specification: Define Absorption as $volume / ($high - $low + 1e-6) over 3 days; define Support as ($low - $open) / ($high - $low + 1e-6) over 5 days; the final factor is the product of these two, multiplied by the sign of ($open_t - $close_{t-1}) to align with short-term sentiment bias.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f2aa418d8203",
      "parent_trajectory_ids": [
        "09b9e0babff9",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045555821708553,
        "ICIR": 0.034049696424528,
        "RankIC": 0.0188423534034833,
        "RankICIR": 0.1444675523442208,
        "annualized_return": 0.0612561414231417,
        "information_ratio": 0.9483138314734816,
        "max_drawdown": -0.0778155499757223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:32:47.884159",
      "updated_at": "2026-01-17T04:32:47.884165"
    },
    "850138de110e25e1": {
      "factor_id": "850138de110e25e1",
      "factor_name": "Institutional_Absorption_Exhaustion_10D",
      "factor_expression": "TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 10) * (1 - POW(TS_CORR($close, SEQUENCE(10), 10), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 10) * (1 - POW(TS_CORR($close, SEQUENCE(10), 10), 2))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend reversals by combining volume density (absorption) with trend linearity decay. It calculates the product of the average volume-to-squared-range ratio and the degree of non-linearity (1 - RSQR) over a 10-day period. High values suggest institutional absorption during a maturing trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption-Exhaustion' factor, defined as the product of the 10-day Volume-to-Squared-Range ratio and the 10-day Price Trend Non-Linearity (1 - RSQR), identifies high-probability reversals by detecting institutional liquidity absorption at the climax of rigid price trends.\n                Concise Observation: Parent 1 showed that trend linearity (RSQR) effectively identifies trend maturity, while Parent 2 demonstrated that volume density relative to squared price range captures stealth institutional activity; combining them addresses the weakness of each acting in isolation.\n                Concise Justification: Institutional investors often accumulate or distribute large positions near trend exhaustion points without causing large price swings (stealth); by weighting this 'absorption' by the decay in trend linearity, we isolate the specific moment where smart money overcomes the prevailing trend's inertia.\n                Concise Knowledge: If high volume occurs within a narrow price range (high absorption density) while a previously linear price trend loses its structural rigidity (low RSQR), then a trend reversal or high-quality breakout is imminent; institutional positioning is most effective when it disrupts established retail momentum.\n                concise Specification: Calculate the 10-day rolling RSQR of daily close prices and the 10-day rolling average of (Volume / (High - Low)^2); the final factor is the product of the average volume density and (1 - RSQR), targeting assets with high consolidation density and low trend fit.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "574cd1e862c0",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047167361451284,
        "ICIR": 0.0364844064841437,
        "RankIC": 0.0191266897767354,
        "RankICIR": 0.1502700646302422,
        "annualized_return": 0.0513879652748899,
        "information_ratio": 0.8647905410225525,
        "max_drawdown": -0.0999122671344044
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:35:28.438738",
      "updated_at": "2026-01-17T04:35:28.438750"
    },
    "6c85d665d5418c64": {
      "factor_id": "6c85d665d5418c64",
      "factor_name": "Inst_Exhaustion_Reversal_10D",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-8) / (TS_STD($close, 10) + 1e-8)) * (1 / (1 + ABS(DELTA(REGRESI($close, SEQUENCE(5), 5), 1))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-8) / (TS_STD($close, 10) + 1e-8)) * (1 / (1 + ABS(DELTA(REGRESI($close, SEQUENCE(5), 5), 1))))\" # Your output factor expression will be filled in here\n    name = \"Inst_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price exhaustion by interacting the institutional conviction gap (overnight gap relative to range) with the 5-day change in price residual convexity. It aims to capture 'blow-off' tops or bottoms where high institutional activity meets decelerating price energy.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Momentum-Exhaustion' factor, calculated as the 10-day volatility-normalized Institutional Conviction Gap multiplied by the negative 5-day change in price-residual convexity, identifies high-probability reversals and sustainable trends by filtering institutional signals through a lens of price exhaustion.\n                Concise Observation: Parent 1's residual convexity (RankIC 0.0237) and Parent 2's conviction gap (RankIC 0.0252) both capture price-volume anomalies, but they fail to distinguish between the start of a trend and its final exhaustion phase.\n                Concise Justification: By interacting the conviction gap with the inverse of residual velocity, we isolate 'clean' smart-money entries that have not yet depleted their price energy, thereby reducing the risk of buying into a climax.\n                Concise Knowledge: If institutional conviction (overnight gap relative to range) is high while price residual acceleration (convexity) is low or negative, the trend is likely sustainable; when high conviction coincides with extreme residual acceleration, it signals a 'blow-off' exhaustion point.\n                concise Specification: The factor is defined as (Gap_Ratio / TS_STD($close, 10)) * (1 / (1 + ABS(Delta_RESI5))), where Gap_Ratio is ($open - $close.shift(1)) / (($high - $low) + ($low - $close.shift(1))), and Delta_RESI5 is the 5-day difference of the residual of $close regressed against time.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "75821eb5ffff",
      "parent_trajectory_ids": [
        "c7199504b485",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048621246374715,
        "ICIR": 0.0383360805784428,
        "RankIC": 0.0191808615256612,
        "RankICIR": 0.1535564180682635,
        "annualized_return": 0.0663555207704074,
        "information_ratio": 1.0807202666469589,
        "max_drawdown": -0.0762739481620921
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:37:30.357928",
      "updated_at": "2026-01-17T04:37:30.357936"
    },
    "2ca3a9a4260666f5": {
      "factor_id": "2ca3a9a4260666f5",
      "factor_name": "Gap_Efficiency_Ratio_20D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Gap_Efficiency_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the absolute overnight gap to the intraday range, smoothed over 20 days. A high ratio suggests that price discovery is occurring primarily through overnight information shocks rather than intraday noise, indicating high-conviction institutional movement.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Gap Efficiency factor, calculated as the ratio of the absolute overnight gap to the 20-day ATR-normalized intraday range, predicts future returns by identifying high-conviction information shocks that occur without excessive intraday exhaustion.\n                Concise Observation: Parent 1 showed that ATR-normalized ranges capture volatility regimes (RankIC 0.029), while Parent 2 highlighted that overnight gaps contain unique information (RankIC 0.024); however, both struggle when high volatility is purely noise-driven.\n                Concise Justification: By using the 20-day ATR to scale the intraday range, we create a 'noise' baseline that allows the overnight 'signal' (the gap) to be evaluated for efficiency, where a high ratio signifies a clean price discovery process.\n                Concise Knowledge: If a significant overnight price gap is followed by a narrow, ATR-normalized intraday range, it indicates institutional conviction; conversely, wide intraday ranges relative to historical volatility suggest speculative exhaustion and noise.\n                concise Specification: The factor is defined as (abs(Open_t - Close_{t-1}) / ATR(20)_t) / ((High_t - Low_t) / ATR(20)_t), which simplifies to abs(Open_t - Close_{t-1}) / (High_t - Low_t), where ATR(20) provides the context for 'normal' movement.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b94108e85f56",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "a79c88fcd924"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049839754120521,
        "ICIR": 0.0347786556387274,
        "RankIC": 0.0221394957570045,
        "RankICIR": 0.1582793905217302,
        "annualized_return": 0.0745694145530136,
        "information_ratio": 1.1045058007815225,
        "max_drawdown": -0.0884942850477227
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:38:49.382244",
      "updated_at": "2026-01-17T04:38:49.382252"
    },
    "55d6f7c75c8976f9": {
      "factor_id": "55d6f7c75c8976f9",
      "factor_name": "Volatility_Adjusted_Gap_Conviction",
      "factor_expression": "ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, ABS($high - DELAY($close, 1))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8)) / (($high - $low) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Conviction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the 20-day average true range (ATR) divided by the intraday range relative to the same ATR. It identifies days where the gap is significant but the subsequent intraday volatility is suppressed, signifying efficient price adjustment.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Gap Efficiency factor, calculated as the ratio of the absolute overnight gap to the 20-day ATR-normalized intraday range, predicts future returns by identifying high-conviction information shocks that occur without excessive intraday exhaustion.\n                Concise Observation: Parent 1 showed that ATR-normalized ranges capture volatility regimes (RankIC 0.029), while Parent 2 highlighted that overnight gaps contain unique information (RankIC 0.024); however, both struggle when high volatility is purely noise-driven.\n                Concise Justification: By using the 20-day ATR to scale the intraday range, we create a 'noise' baseline that allows the overnight 'signal' (the gap) to be evaluated for efficiency, where a high ratio signifies a clean price discovery process.\n                Concise Knowledge: If a significant overnight price gap is followed by a narrow, ATR-normalized intraday range, it indicates institutional conviction; conversely, wide intraday ranges relative to historical volatility suggest speculative exhaustion and noise.\n                concise Specification: The factor is defined as (abs(Open_t - Close_{t-1}) / ATR(20)_t) / ((High_t - Low_t) / ATR(20)_t), which simplifies to abs(Open_t - Close_{t-1}) / (High_t - Low_t), where ATR(20) provides the context for 'normal' movement.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b94108e85f56",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "a79c88fcd924"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049839754120521,
        "ICIR": 0.0347786556387274,
        "RankIC": 0.0221394957570045,
        "RankICIR": 0.1582793905217302,
        "annualized_return": 0.0745694145530136,
        "information_ratio": 1.1045058007815225,
        "max_drawdown": -0.0884942850477227
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:38:49.407431",
      "updated_at": "2026-01-17T04:38:49.407437"
    },
    "5495e194e6b567f6": {
      "factor_id": "5495e194e6b567f6",
      "factor_name": "Idio_Vol_Exhaustion_V1",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($close + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN($return * $volume, 10))) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($close + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN(TS_PCTCHANGE($close, 1) * $volume, 10))) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Idio_Vol_Exhaustion_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by combining idiosyncratic volatility dispersion with price-volume divergence. It calculates the 10-day TS_ZSCORE of the intraday range, multiplies it by the rank difference between 10-day price momentum and volume-weighted returns, and scales it by the ratio of overnight volatility to intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Idiosyncratic Volatility-Volume Exhaustion factor, defined by the product of 10-day Cross-Sectional Volatility Dispersion (CSVD) and the rank-difference between price momentum and volume-weighted returns, identifies high-conviction reversals when filtered by the overnight-to-intraday volatility ratio.\n                Concise Observation: Parent 1 (CSVD) captures alpha from volatility dispersion (RankIC 0.026), while Parent 2 identifies institutional reversals through price-volume divergence (RankIC 0.022); combining them addresses the noise inherent in individual volatility spikes.\n                Concise Justification: CSVD identifies assets undergoing unique re-pricing, but requires a conviction filter (price-volume rank difference) and a volatility regime check (overnight gap ratio) to distinguish between sustainable trends and mean-reverting exhaustion points.\n                Concise Knowledge: If a stock's idiosyncratic range volatility expands while its price-volume trend diverges, it indicates institutional exhaustion; when this occurs alongside high overnight-to-intraday volatility, the likelihood of a price reversal increases due to liquidity-driven overextension.\n                concise Specification: Calculate CSVD as the 10-day rolling Z-score of (High-Low)/Close; multiply by the difference between 10-day price change rank and 10-day volume-weighted return rank; then scale by the ratio of the 5-day average overnight gap to intraday range.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a5cc0d100065",
      "parent_trajectory_ids": [
        "7513729d3145",
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:40:09.105511",
      "updated_at": "2026-01-17T04:40:09.105517"
    },
    "1a592c4b2c507dc2": {
      "factor_id": "1a592c4b2c507dc2",
      "factor_name": "Inst_Absorp_Exhaustion_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close / (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) - 1) * TS_ZSCORE($volume / (POW($high - $low, 2) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close / (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) - 1) * TS_ZSCORE($volume / (MAX(POW($high - $low, 2), 1e-4)), 10)\" # Your output factor expression will be filled in here\n    name = \"Inst_Absorp_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction reversal points by combining trend linearity (R-squared), VWMA price deviation, and liquidity density. High R-squared indicates a stable trend, while a high volume-to-squared-range ratio suggests institutional accumulation. A subsequent deviation from the VWMA signals exhaustion of that institutional regime.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption Exhaustion' factor, defined as the product of the 10-day price-time R-squared and the 5-day VWMA price deviation, scaled by the 10-day Z-score of the volume-to-squared-range ratio, identifies high-conviction reversal points following institutional liquidity accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies trend stability but lacks volume context, while Parent 2 (RankIC 0.0303) identifies institutional presence but lacks trend directionality; combining them targets the 'maturation' phase of a move.\n                Concise Justification: High volume within narrow price ranges (Stealth Liquidity) creates a 'coiled spring' effect; when this occurs within a stable linear trend, the eventual deviation from the VWMA indicates a structural breakdown of the institutional accumulation/distribution regime.\n                Concise Knowledge: If a security exhibits high trend linearity (R-squared) alongside high liquidity density (Volume/Range^2), then subsequent deviations from the volume-weighted average price (VWMA) signify exhaustion of institutional support rather than random noise.\n                concise Specification: Calculate the 10-day R-squared of $close vs. time; calculate the 5-day VWMA deviation ($close / VWMA - 1); calculate the 10-day Z-score of ($volume / ($high - $low + epsilon)^2); the final factor is the product of these three components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "eaa213f8926b",
      "parent_trajectory_ids": [
        "6c7b79d75672",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035798662382449,
        "ICIR": 0.0243715991744727,
        "RankIC": 0.0170600930317845,
        "RankICIR": 0.1177336289915161,
        "annualized_return": 0.0067228323166186,
        "information_ratio": 0.089167333949632,
        "max_drawdown": -0.1571893892605717
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:54:32.127741",
      "updated_at": "2026-01-17T04:54:32.127747"
    },
    "14f311511630f9db": {
      "factor_id": "14f311511630f9db",
      "factor_name": "Cross_Sectional_Absorption_Strength",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) * (($volume / ($high - $low + 1e-8)) / (ABS($close - $open) / ($high - $low + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) * (($volume / ($high - $low + 1e-8)) / (ABS($close - $open) / ($high - $low + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Absorption_Strength\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the absorption signal across the market. It calculates the density of volume relative to the price range and divides it by the relative candle body size, then scales this by the cross-sectional rank of the 10-day price momentum to find the strongest accumulation in the most stable trends.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Inertial Compression-Absorption' factor, defined as the product of the 10-day price trend R-squared and the ratio of 5-day average volume-to-range density to the 5-day average body-to-range ratio, identifies high-conviction institutional accumulation phases that precede trend-following breakouts.\n                Concise Observation: Parent 1 successfully used price body ratios to find exhaustion, while Parent 2 used volume-to-range squared to find stealth liquidity; however, both lacked a filter for trend stability, often leading to false signals in mean-reverting or chaotic regimes.\n                Concise Justification: High volume within narrow price bands suggests institutional absorption (liquidity drain), and when this occurs alongside a high R-squared (trend stability) and small price bodies (indecision), it indicates a temporary pause for accumulation before the next leg of the trend.\n                Concise Knowledge: If a market exhibits high structural persistence (R-squared) while volume is concentrated in narrow price ranges (high volume/range) and price bodies are small relative to total range (low body/range), then the resulting 'compressed absorption' signals a high-probability continuation of the existing trend.\n                concise Specification: The factor is calculated as (10-day R-squared of $close) * (SMA(Volume / (High - Low + epsilon), 5) / SMA(abs(Close - Open) / (High - Low + epsilon), 5)), where epsilon is a small constant to prevent division by zero.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d6415d4aa6f7",
      "parent_trajectory_ids": [
        "00a6075cc504",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026012431262506,
        "ICIR": 0.0192586554014756,
        "RankIC": 0.0179616309709079,
        "RankICIR": 0.1329784901916024,
        "annualized_return": 0.0073720711364907,
        "information_ratio": 0.1072068122868142,
        "max_drawdown": -0.1169963401656844
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:01:17.306832",
      "updated_at": "2026-01-17T05:01:17.306838"
    },
    "05a42dacbddf8ae7": {
      "factor_id": "05a42dacbddf8ae7",
      "factor_name": "Inst_Trend_Integrity_20D",
      "factor_expression": "TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Integrity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining volume density (volume relative to price range) with trend stability. High volume density suggests liquidity absorption within narrow price bands, while low volatility in the R-squared of price regression indicates a consistent, non-erratic trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Trend Integrity' factor, defined as the 20-day rolling average of the (Volume / (High - Low + epsilon)^2) ratio scaled by the inverse of the 20-day standard deviation of the 10-day price regression R-squared, predicts superior forward returns by identifying stable institutional accumulation.\n                Concise Observation: Parent 1 showed that trend fragility (R-squared volatility) captures regime shifts (RankIC 0.0216), while Parent 2 demonstrated that volume-to-price-range ratios identify institutional footprints (RankIC 0.0303), suggesting a synergistic link between volume density and trend consistency.\n                Concise Justification: Institutional investors often execute large orders within narrow price bands to minimize impact, creating high volume density; when this behavior is paired with a stable, non-erratic linear trend, it signals a high-conviction regime shift that the market has yet to fully price in.\n                Concise Knowledge: If high volume density (liquidity absorption) coincides with low volatility in trend goodness-of-fit (trend stability), then the underlying price movement is likely driven by institutional accumulation rather than retail noise; such moves are more persistent and less prone to immediate reversal.\n                concise Specification: Calculate the daily ratio of volume to the square of the daily range; compute its 20-day mean; calculate the 20-day standard deviation of the R-squared from a 10-day linear regression of close prices; the final factor is the ratio of the 20-day mean volume density to the 20-day R-squared volatility.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2406a677c638",
      "parent_trajectory_ids": [
        "fe2976b173a7",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048202276785119,
        "ICIR": 0.0360916624363226,
        "RankIC": 0.0218515919024348,
        "RankICIR": 0.1686860189406379,
        "annualized_return": 0.0474429812813558,
        "information_ratio": 0.810910955831541,
        "max_drawdown": -0.1034097001433274
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:13:50.502117",
      "updated_at": "2026-01-17T05:13:50.502124"
    },
    "892928c119672f0a": {
      "factor_id": "892928c119672f0a",
      "factor_name": "Trend_Efficiency_Volume_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN($volume / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN($volume / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Trend_Efficiency_Volume_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement relative to volume. It uses the 10-day price regression R-squared as a proxy for trend integrity and scales it by the 20-day moving average of volume density, rewarding stocks with high volume absorption and linear price paths.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Trend Integrity' factor, defined as the 20-day rolling average of the (Volume / (High - Low + epsilon)^2) ratio scaled by the inverse of the 20-day standard deviation of the 10-day price regression R-squared, predicts superior forward returns by identifying stable institutional accumulation.\n                Concise Observation: Parent 1 showed that trend fragility (R-squared volatility) captures regime shifts (RankIC 0.0216), while Parent 2 demonstrated that volume-to-price-range ratios identify institutional footprints (RankIC 0.0303), suggesting a synergistic link between volume density and trend consistency.\n                Concise Justification: Institutional investors often execute large orders within narrow price bands to minimize impact, creating high volume density; when this behavior is paired with a stable, non-erratic linear trend, it signals a high-conviction regime shift that the market has yet to fully price in.\n                Concise Knowledge: If high volume density (liquidity absorption) coincides with low volatility in trend goodness-of-fit (trend stability), then the underlying price movement is likely driven by institutional accumulation rather than retail noise; such moves are more persistent and less prone to immediate reversal.\n                concise Specification: Calculate the daily ratio of volume to the square of the daily range; compute its 20-day mean; calculate the 20-day standard deviation of the R-squared from a 10-day linear regression of close prices; the final factor is the ratio of the 20-day mean volume density to the 20-day R-squared volatility.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2406a677c638",
      "parent_trajectory_ids": [
        "fe2976b173a7",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048202276785119,
        "ICIR": 0.0360916624363226,
        "RankIC": 0.0218515919024348,
        "RankICIR": 0.1686860189406379,
        "annualized_return": 0.0474429812813558,
        "information_ratio": 0.810910955831541,
        "max_drawdown": -0.1034097001433274
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:13:50.551002",
      "updated_at": "2026-01-17T05:13:50.551008"
    },
    "17dc6ce14c0fa34f": {
      "factor_id": "17dc6ce14c0fa34f",
      "factor_name": "Liquidity_Exhaustion_Gap_Factor",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_RANK(($high - $low) / (TS_STD($close, 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_RANK(($high - $low) / (TS_STD($close, 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the intensity-adjusted gap reversal. It uses the cross-sectional rank of the overnight gap and the time-series rank of the intraday range relative to volume-weighted volatility to find high-conviction reversal points.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Intensity-Adjusted Gap Reversal' factor, calculated as the product of the overnight price gap and the 20-day Z-score of the (High-Low)/ATR20 ratio, identifies high-conviction mean-reversion signals by isolating liquidity-driven exhaustion points.\n                Concise Observation: Parent 1 showed that normalized intraday intensity (Range/ATR) captures price exhaustion (RankIC 0.029), while Parent 2 demonstrated that overnight gaps coupled with volume dispersion signal reversals (RankIC 0.022); combining these filters out 'noisy' gaps that lack the volatility confirmation needed for high-conviction trades.\n                Concise Justification: By scaling the overnight gap by the relative intraday intensity, we weight the signal toward 'over-extended' states where the price has moved significantly beyond its typical volatility envelope, suggesting a higher likelihood of inventory-driven correction.\n                Concise Knowledge: If an overnight price gap occurs in conjunction with extreme intraday price range expansion relative to its historical ATR, the price movement is more likely driven by temporary liquidity imbalances rather than fundamental shifts; when volume volatility is also high, the probability of a mean-reversion reversal increases.\n                concise Specification: The factor is defined as: Gap * TS_ZScore((High - Low) / ATR(20), 20), where Gap is (Open - Prev_Close) / Prev_Close and ATR(20) is the 20-day Average True Range; a high positive value suggests a gap-up with extreme intensity (sell signal), and a low negative value suggests a gap-down with extreme intensity (buy signal).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67a65f59ba9a",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "ccbd1a1bc892"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074614630650547,
        "ICIR": 0.0552835729971314,
        "RankIC": 0.0252842146188579,
        "RankICIR": 0.1900184381652116,
        "annualized_return": 0.070876744457745,
        "information_ratio": 1.0589173674031032,
        "max_drawdown": -0.0948577377005152
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:17:13.649487",
      "updated_at": "2026-01-17T05:17:13.649493"
    },
    "4c772ab65d1c8aef": {
      "factor_id": "4c772ab65d1c8aef",
      "factor_name": "LGGRF_Gap_Intensity_10D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"LGGRF_Gap_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Gated Gap Reversion Factor (LGGRF) identifies potential mean reversion by combining overnight price shocks with intraday price expansion on low volume. It calculates the product of the 10-day time-series Z-score of the overnight gap and the 10-day time-series Z-score of intraday intensity (range divided by volume). High values suggest the price movement is overextended and lacks institutional liquidity support.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Gated Gap Reversion Factor (LGGRF) predicts short-term price reversals by identifying large overnight price gaps that are subsequently accompanied by intraday price expansion on declining volume intensity, signaling a lack of institutional support for the gap's direction.\n                Concise Observation: Parent 1 showed that overnight gaps (RankIC 0.0245) have mean-reversion potential, while Parent 2 showed that intraday price extremes on low volume (RankIC 0.0269) signal exhaustion; combining them addresses the weakness of trading gaps that are actually supported by strong intraday flow.\n                Concise Justification: Overnight gaps represent information shocks, but their sustainability depends on intraday follow-through; a 'liquidity trap' occurs when price continues to move in the gap direction but volume fades, suggesting the initial shock has overextended beyond the market's current clearing capacity.\n                Concise Knowledge: If an overnight price gap is followed by intraday price extremes reached with lower-than-average volume, the price movement is likely exhaustive; when high overnight volatility meets low intraday liquidity, mean reversion is more probable than trend continuation.\n                concise Specification: Define Gap as abs(Open - Close[1]); define Intraday Intensity as (High - Low) / Volume; the factor is the product of the 10-day Z-score of the Gap and the 10-day Z-score of the Intraday Intensity, where a high value indicates a volatile gap followed by exhaustive intraday price action.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "61b88053c4c0",
      "parent_trajectory_ids": [
        "5482374782e1",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043323998793942,
        "ICIR": 0.0323540901856198,
        "RankIC": 0.0212825093775084,
        "RankICIR": 0.1617653671916123,
        "annualized_return": 0.0502685120758134,
        "information_ratio": 0.8333518050177452,
        "max_drawdown": -0.074595041048191
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:20:12.919859",
      "updated_at": "2026-01-17T05:20:12.919865"
    },
    "80430b43effd83e0": {
      "factor_id": "80430b43effd83e0",
      "factor_name": "Liquidity_Trap_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE(ABS($open - DELAY($close, 1)), 20)) + RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(ABS($open - DELAY($close, 1)), 20)) + RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Trap_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'liquidity traps' where overnight gaps are followed by low-volume intraday price ranges. It uses a 20-day window to normalize the gap and intensity, then applies a cross-sectional rank to identify stocks with the most exhaustive price action relative to their peers. High ranks indicate a higher probability of short-term reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Gated Gap Reversion Factor (LGGRF) predicts short-term price reversals by identifying large overnight price gaps that are subsequently accompanied by intraday price expansion on declining volume intensity, signaling a lack of institutional support for the gap's direction.\n                Concise Observation: Parent 1 showed that overnight gaps (RankIC 0.0245) have mean-reversion potential, while Parent 2 showed that intraday price extremes on low volume (RankIC 0.0269) signal exhaustion; combining them addresses the weakness of trading gaps that are actually supported by strong intraday flow.\n                Concise Justification: Overnight gaps represent information shocks, but their sustainability depends on intraday follow-through; a 'liquidity trap' occurs when price continues to move in the gap direction but volume fades, suggesting the initial shock has overextended beyond the market's current clearing capacity.\n                Concise Knowledge: If an overnight price gap is followed by intraday price extremes reached with lower-than-average volume, the price movement is likely exhaustive; when high overnight volatility meets low intraday liquidity, mean reversion is more probable than trend continuation.\n                concise Specification: Define Gap as abs(Open - Close[1]); define Intraday Intensity as (High - Low) / Volume; the factor is the product of the 10-day Z-score of the Gap and the 10-day Z-score of the Intraday Intensity, where a high value indicates a volatile gap followed by exhaustive intraday price action.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "61b88053c4c0",
      "parent_trajectory_ids": [
        "5482374782e1",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043323998793942,
        "ICIR": 0.0323540901856198,
        "RankIC": 0.0212825093775084,
        "RankICIR": 0.1617653671916123,
        "annualized_return": 0.0502685120758134,
        "information_ratio": 0.8333518050177452,
        "max_drawdown": -0.074595041048191
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:20:12.944776",
      "updated_at": "2026-01-17T05:20:12.944781"
    },
    "cda1b49df004b2e6": {
      "factor_id": "cda1b49df004b2e6",
      "factor_name": "SEMS_Zscore_Exhaustion_15D",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(15), 15), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(15), 15), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"SEMS_Zscore_Exhaustion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This variation uses a 15-day window for trend linearity and a 5-day window for liquidity exhaustion, standardized using TS_ZSCORE to identify extreme exhaustion events relative to the asset's own history before a reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Multi-Scale (SEMS) factor identifies price reversals by multiplying the 10-day price trend linearity (RSQR) with the 5-day average ratio of price range to volume intensity, capturing the convergence of macro-trend maturity and micro-liquidity collapse.\n                Concise Observation: Parent 1 (RSQR10) captures medium-term trend persistence (RankIC 0.0243), while Parent 2 (ILEF) captures short-term liquidity traps (RankIC 0.0270); combining them addresses the weakness of entering reversals too early in strong linear trends.\n                Concise Justification: Linear trends (high RSQR) are sustainable only if supported by efficient liquidity; a rising price-to-volume ratio (range/volume) at the end of such a trend indicates 'thin' trading and a liquidity void, signaling an imminent structural breakdown.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but is accompanied by a decreasing ratio of price movement per unit of volume, then the trend is likely driven by retail exhaustion rather than institutional conviction; when these multi-scale signals align, the probability of mean reversion increases.\n                concise Specification: Calculate RSQR of close prices over 10 days; calculate the daily Liquidity Intensity as (High - Low) / Volume; compute the 5-day moving average of this intensity; the final factor is the product of RSQR and the 5-day intensity average, targeting assets with high linearity and high liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a34c9bb86b45",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038162505599264,
        "ICIR": 0.0278069908189633,
        "RankIC": 0.0196482391902487,
        "RankICIR": 0.1453964088361926,
        "annualized_return": 0.0303750622438065,
        "information_ratio": 0.4422539176493897,
        "max_drawdown": -0.101040702168971
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:34:45.816466",
      "updated_at": "2026-01-17T05:34:45.816471"
    },
    "d256ede617306ae6": {
      "factor_id": "d256ede617306ae6",
      "factor_name": "Institutional_Accumulation_Stability_20D",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 20), 20) + TS_ZSCORE(TS_STD(ABS($close - $open), 20), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the stability of institutional commitment by comparing the rolling 20-day volatility of volume against the rolling 20-day volatility of intraday returns. It targets periods where price movement is orderly (low range volatility) and volume is consistent, which is characteristic of algorithmic execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.117822",
      "updated_at": "2026-01-17T05:49:14.117828"
    },
    "f31d8c4ef20d75c6": {
      "factor_id": "f31d8c4ef20d75c6",
      "factor_name": "Linear_Trend_Decay_ZScore",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Decay_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that focuses on the standardized deviation of trend linearity. It uses the Z-score of the 10-day R-squared over a 20-day period to detect extreme departures from the recent trend stability regime, helping to identify points where the 'quality' of the price movement is breaking down.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.834190",
      "updated_at": "2026-01-17T06:03:35.834196"
    },
    "5f27b35f17420f9d": {
      "factor_id": "5f27b35f17420f9d",
      "factor_name": "ZScore_Overnight_Volume_Shock",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Volume_Shock\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the overnight sentiment gap that uses Z-score normalization for the volume component and cross-sectional ranking for the gap, ensuring the factor is robust to different market regimes and stock scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.804532",
      "updated_at": "2026-01-17T06:06:12.804538"
    },
    "97893b031c147033": {
      "factor_id": "97893b031c147033",
      "factor_name": "Intraday_VWAP_Midpoint_Deviation_5D",
      "factor_expression": "TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_VWAP_Midpoint_Deviation_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of the approximated Volume-Weighted Average Price (VWAP) from the daily price midpoint, normalized by the daily range. A high deviation indicates that volume is concentrated at one extreme of the price range, suggesting liquidity exhaustion and potential mean-reversion. It is smoothed over a 5-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.432281",
      "updated_at": "2026-01-17T06:08:21.432288"
    },
    "298e0ab6776e2256": {
      "factor_id": "298e0ab6776e2256",
      "factor_name": "Hollow_Price_Extreme_Reversal_5D",
      "factor_expression": "TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Price_Extreme_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'hollow' price moves by calculating the distance between the daily close and the approximated VWAP relative to the daily range. If the close is far from where the volume was executed (VWAP), the price level is considered low-conviction. The factor uses a 5-day moving average to signal mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.458630",
      "updated_at": "2026-01-17T06:08:21.458636"
    },
    "1d239eda75962a9c": {
      "factor_id": "1d239eda75962a9c",
      "factor_name": "ZScore_Trend_Linearity_Divergence",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Trend_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the trend acceleration decay. It identifies assets where the short-term (5-day) trend linearity is an outlier relative to its long-term (20-day) historical linearity, highlighting potential mean-reversion candidates in the broader market context.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.096980",
      "updated_at": "2026-01-17T06:38:46.096986"
    },
    "2a7824bde358fdcf": {
      "factor_id": "2a7824bde358fdcf",
      "factor_name": "WV_Trend_Linearity_Ratio_5_10",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WV_Trend_Linearity_Ratio_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio between the 5-day volume-weighted price range and the 10-day R-squared of price against a time index. It identifies trend exhaustion by detecting when the 'energy' (volume-weighted volatility) spikes while the 'order' (linear trend persistence) begins to plateau or decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:09.983407",
      "updated_at": "2026-01-17T06:59:09.983414"
    },
    "97f062d37da14737": {
      "factor_id": "97f062d37da14737",
      "factor_name": "Institutional_Distribution_Energy_Factor",
      "factor_expression": "RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Distribution_Energy_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis focusing on the ratio of short-term volume-weighted price movement to the persistence of the trend. High values suggest that price movement is becoming erratic and volume-heavy, indicating potential institutional distribution before a trend reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.035784",
      "updated_at": "2026-01-17T06:59:10.035789"
    },
    "628b34f333f9c1b3": {
      "factor_id": "628b34f333f9c1b3",
      "factor_name": "Stealth_Accumulation_Efficiency_20D",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 20)) / (TS_SUM(ABS(DELTA($close, 1)), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining price path efficiency with a volume-weighted positioning metric, filtered for low-volatility 'quiet' regimes. High efficiency (net move vs total move) and volume concentrated near the high during low turnover-to-volatility periods signal sustainable stealth trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.576468",
      "updated_at": "2026-01-17T06:59:34.576476"
    },
    "f6b570215828664b": {
      "factor_id": "f6b570215828664b",
      "factor_name": "Institutional_Accumulation_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($close - $open) / ($high - $low + 1e-8)) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($close / DELAY($close, 1) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring 'price efficiency' (the ratio of net price movement to total intraday range) scaled by volume density. It targets steady price appreciation accompanied by high relative volume and low volatility, which suggests structural absorption of supply.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.446055",
      "updated_at": "2026-01-17T07:02:26.446062"
    },
    "60d07cdfa713d25a": {
      "factor_id": "60d07cdfa713d25a",
      "factor_name": "Structural_Liquidity_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Liquidity_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the persistence of price trends by evaluating the consistency of positive returns relative to the intraday range, weighted by the 20-day time-series rank of volume. It identifies 'quiet' trends where volume is high relative to historical norms but price volatility remains suppressed.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.499248",
      "updated_at": "2026-01-17T07:02:26.499253"
    },
    "67c375461e7ad2ef": {
      "factor_id": "67c375461e7ad2ef",
      "factor_name": "Conviction_Momentum_ZScore_20D",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Momentum_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of price moves by standardizing the price efficiency ratio against its own history and scaling it by the relative volume level. It highlights periods where price movement is unusually 'clean' relative to the intraday noise, supported by high relative volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.552981",
      "updated_at": "2026-01-17T07:04:53.552987"
    },
    "c5e624a879656b21": {
      "factor_id": "c5e624a879656b21",
      "factor_name": "Smooth_Volume_Efficiency_20D",
      "factor_expression": "ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN($return, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"Smooth_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price efficiency by comparing the daily price range to volume dispersion. It targets regimes where price moves are achieved with consistent volume rather than spikes, indicating sustainable trend persistence. It uses Z-score for cross-sectional normalization.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.637858",
      "updated_at": "2026-01-17T07:08:38.637863"
    },
    "36354e062634e726": {
      "factor_id": "36354e062634e726",
      "factor_name": "Quiet_Trend_Initiation_Index",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Initiation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the ratio of the overnight return to the trailing 5-day median absolute deviation of intraday returns. It uses TS_MAD for robustness against outliers and scales by the intraday range ratio to identify high-conviction institutional moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.590704",
      "updated_at": "2026-01-17T07:09:48.590711"
    },
    "33dde5198bb9a733": {
      "factor_id": "33dde5198bb9a733",
      "factor_name": "ZScore_Overnight_Shock_20D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Shock_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the cross-sectional strength of the overnight gap relative to its historical volatility. By applying a Z-score to the ATR-normalized gap, it highlights stocks experiencing the most significant idiosyncratic information shocks relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.350013",
      "updated_at": "2026-01-17T07:11:55.350019"
    },
    "c077f13bd7bec6f8": {
      "factor_id": "c077f13bd7bec6f8",
      "factor_name": "Smoothed_ILVG_Validation_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) * TS_MEAN(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) * TS_MEAN(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_ILVG_Validation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A smoothed version of the Informed Liquidity-Validation Gap that uses a 10-day moving average of the validation component (Volume/Range) to identify persistent institutional support for overnight moves rather than single-day noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity-Validation Gap (ILVG) factor, defined as the overnight return divided by the ratio of intraday price range (High-Low) to relative volume intensity over a 5-day window, predicts positive returns when gaps are efficiently supported by volume and negative returns when gaps are 'hollow' expansions.\n                Concise Observation: Parent 1 showed that overnight gaps carry sentiment (RankIC 0.0216), while Parent 2 demonstrated that the ratio of price range to volume intensity (VVDE) identifies price efficiency (RankIC 0.0298).\n                Concise Justification: By scaling the overnight sentiment signal by the inverse of the 'cost of price movement' (VVDE), we filter out gaps that lack liquidity validation, thereby isolating high-conviction institutional flows from retail-driven exhaustion gaps.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday volatility but low relative volume, the price move is likely noise-driven and prone to mean reversion; conversely, when high volume supports a narrow intraday range following a gap, the price discovery is efficient and momentum-persistent.\n                concise Specification: The ILVG factor is calculated as (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / Close_t / (Volume_t / Mean(Volume_{t-1...t-5}))). The look-back period for volume normalization is 5 days, and the intraday range is normalized by the current close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "21809a7d6aca",
      "parent_trajectory_ids": [
        "c45ed08a92fb",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0065254216645761,
        "ICIR": 0.0472355092847189,
        "RankIC": 0.0270520258483099,
        "RankICIR": 0.2024824929100111,
        "annualized_return": 0.0821097882309767,
        "information_ratio": 1.2176888122530412,
        "max_drawdown": -0.098122127271157
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:12:54.366828",
      "updated_at": "2026-01-17T07:12:54.366834"
    },
    "722b01272514c293": {
      "factor_id": "722b01272514c293",
      "factor_name": "LRRF_Gap_Volatility_Reversal_14D",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LRRF_Gap_Volatility_Reversal_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the validation of reversal signals using overnight gaps relative to historical volatility. It identifies regimes where the overnight price jump is large compared to the 14-day ATR, suggesting a liquidity vacuum that is likely to revert when combined with high intraday price dispersion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Regime Reversal Factor (LRRF) identifies high-conviction mean-reversion points by combining ATR-normalized intraday price dispersion with a volume-exhaustion filter, weighted by the 20-day price-volume correlation and validated by the ratio of overnight gaps to previous day volatility.\n                Concise Observation: Parent 1 successfully used High-Low/Volume for mean reversion (RankIC 0.026), while Parent 2 showed that price-volume correlation and overnight gaps (RankIC 0.031) provide strong regime filters, suggesting a synergistic effect if combined.\n                Concise Justification: Liquidity exhaustion is most predictive of reversal when it represents a 'failed' price discovery process (low correlation) rather than a trending move, and scaling by ATR ensures that the dispersion signal is statistically significant relative to the asset's historical noise.\n                Concise Knowledge: If extreme price dispersion occurs on declining volume while price-volume correlation is low, a liquidity vacuum is likely; when these signals are normalized by ATR and confirmed by overnight gaps, the resulting reversal signal is more robust across different volatility regimes.\n                concise Specification: Calculate the ratio of (High-Low)/ATR(14) divided by Volume(5-day mean), multiply by the absolute difference of 1 and the 20-day Spearman correlation of price and volume, then scale by the ratio of the absolute overnight gap to the 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "32d8562e2ac5",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004582143450058,
        "ICIR": 0.0323815285094316,
        "RankIC": 0.0206565794098764,
        "RankICIR": 0.1499498185884695,
        "annualized_return": 0.032041373972513,
        "information_ratio": 0.4373950925488938,
        "max_drawdown": -0.120092798839113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:20:03.609356",
      "updated_at": "2026-01-17T07:20:03.609362"
    },
    "885d228959d7ac35": {
      "factor_id": "885d228959d7ac35",
      "factor_name": "Structural_Exhaustion_Factor_V1",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) * (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) * (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Factor_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by multiplying the instability of the price-time linear fit (20-day volatility of 10-day R-squared) with price-volume divergence (ATR to relative volume ratio). High values indicate a 'hollow' trend where price linearity is breaking down while liquidity support is diminishing.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Factor' (SEF) predicts asset returns by identifying periods where high Trend Fragility (20-day volatility of 10-day price-time R-squared) coincides with high Price-Volume Divergence (5-day ATR divided by relative volume), signaling a breakdown in trend integrity.\n                Concise Observation: Parent 1 identifies regime shifts through R-squared volatility (RankIC 0.0215), while Parent 2 captures efficiency via ATR/Volume (RankIC 0.0298); combining them targets the specific failure mode where statistical linearity and volume support diverge.\n                Concise Justification: Trends often collapse when they become 'hollow'—maintaining price movement through low liquidity rather than conviction; by weighting price-volume efficiency by the instability of the trend's linear fit, we isolate high-conviction exhaustion signals.\n                Concise Knowledge: If a price trend exhibits high volatility in its linear consistency while price ranges expand on diminishing volume, then the trend is structurally exhausted; such conditions typically precede mean reversion as the 'brittle' momentum lacks liquidity support.\n                concise Specification: Calculate SEF as the product of the 20-day standard deviation of the 10-day price-time R-squared and the ratio of the 5-day ATR to the 5-day average volume normalized by its 20-day mean; high values indicate imminent reversal.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "c83bda189fad",
      "parent_trajectory_ids": [
        "d28523b947b5",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029310941342914,
        "ICIR": 0.0228851278151406,
        "RankIC": 0.0172368444764199,
        "RankICIR": 0.1323453288932452,
        "annualized_return": 0.0279175594805435,
        "information_ratio": 0.4815084563662187,
        "max_drawdown": -0.1050173850263145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:21:03.208677",
      "updated_at": "2026-01-17T07:21:03.208685"
    },
    "817200c44756edcb": {
      "factor_id": "817200c44756edcb",
      "factor_name": "Normalized_Exhaustion_Intensity_5D",
      "factor_expression": "(MAX($high, DELAY($close, 1)) - MIN($low, DELAY($close, 1))) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MAX($high, DELAY($close, 1)) - MIN($low, DELAY($close, 1))) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the LVSE hypothesis by calculating the ratio of the total daily price range (including the gap) to the relative volume intensity. High values indicate price 'sprinting' on thin liquidity, which is a precursor to mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Exhaustion (LVSE) factor, defined as the product of the overnight gap normalized by the 5-day average volume and the intraday range normalized by the 5-day relative volume intensity, identifies mean-reverting price moves driven by institutional liquidity vacuums.\n                Concise Observation: Parent strategies show that overnight gaps and intraday volatility-volume divergences independently predict returns (RankIC 0.021 and 0.029), but they often suffer from false positives when institutional participation is actually high during one of the sessions.\n                Concise Justification: By multiplying the overnight exhaustion signal with the intraday efficiency signal, the factor isolates periods where price discovery is inefficient across the entire trading cycle, specifically targeting retail-driven 'liquidity vacuums' that lack the capital depth to sustain the new price level.\n                Concise Knowledge: If a significant overnight price gap is followed by a high-volatility intraday session on low relative volume, then the price move lacks institutional conviction and is likely to mean-revert; When price moves are decoupled from volume across both overnight and intraday sessions, the resulting 'hollow' expansion indicates sentiment exhaustion.\n                concise Specification: Calculate the overnight gap as (Open - Previous Close) / Previous Close; normalize this by the 5-day moving average of volume; multiply this by the ratio of the intraday range (High - Low) to the 5-day relative volume (Current Volume / 5-day Avg Volume); use a 5-day lookback for all moving averages.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67f2bb4e6644",
      "parent_trajectory_ids": [
        "7be123f3452d",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0062924490755552,
        "ICIR": 0.0488930632043071,
        "RankIC": 0.0219184141665883,
        "RankICIR": 0.1712070931153219,
        "annualized_return": 0.0505599073713051,
        "information_ratio": 0.9402729093250598,
        "max_drawdown": -0.0542230106351212
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:24:16.681094",
      "updated_at": "2026-01-17T07:24:16.681099"
    },
    "2231f6a60e698a66": {
      "factor_id": "2231f6a60e698a66",
      "factor_name": "Ranked_ISA_Efficiency_15D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 15)) * RANK($volume / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 15)) * RANK($volume / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_ISA_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the ISA hypothesis using a 15-day window to capture more stable institutional trends. It measures the efficiency of price discovery by comparing price-volume synchronicity against the standardized price range per unit of volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Stealth Absorption (ISA) factor, calculated as the 10-day correlation between price and volume divided by the 10-day ratio of high-low range to volume, identifies superior returns by isolating high-conviction directional moves that occur with minimal price dispersion.\n                Concise Observation: Parent strategies showed that while price-volume correlation (RankIC 0.028) and liquidity vacuum ratios (RankIC 0.026) are independently predictive, their intersection captures 'efficient' price discovery that avoids the mean-reversion traps of high-volatility exhaustion.\n                Concise Justification: Institutional buyers seek to minimize market impact, leading to high directional conviction (correlation) with compressed intra-day ranges relative to the volume traded (absorption), whereas retail-driven moves typically exhibit high range volatility and 'hollow' liquidity.\n                Concise Knowledge: If price-volume correlation is high while price-range volatility per unit of volume is low, then the asset is likely undergoing institutional accumulation; when these conditions diverge, price moves are often driven by retail noise or liquidity exhaustion.\n                concise Specification: The factor is defined as TS_CORR($close, $volume, 10) / (($high - $low) / $volume). It expects a positive relationship with future returns, where higher values indicate 'stealth' accumulation and lower values indicate either lack of conviction or volatile price exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b0acffbb7c07",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068294348773451,
        "ICIR": 0.0468938169997795,
        "RankIC": 0.0234412453878346,
        "RankICIR": 0.1634847987247056,
        "annualized_return": 0.0335898031429351,
        "information_ratio": 0.4671604333292865,
        "max_drawdown": -0.1349401268889269
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:30:01.114625",
      "updated_at": "2026-01-17T07:30:01.114632"
    },
    "114d105f79e6f1b9": {
      "factor_id": "114d105f79e6f1b9",
      "factor_name": "Standardized_Structural_Fragility_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Standardized_Structural_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the Structural Exhaustion signal by applying a Z-score to the price-range-to-volume ratio before multiplying by the trend linearity. This ensures that the 'hollow' price acceleration is measured relative to the asset's own recent liquidity history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the product of the 5-day price-time R-squared and the 5-day ATR-to-Volume ratio, identifies high-conviction trend reversals by detecting 'hollow' price accelerations that lack liquidity support.\n                Concise Observation: Parent 1 showed that short-term price linearity decay precedes reversals (RankIC 0.020), and Parent 2 demonstrated that high price range relative to volume signals efficiency exhaustion (RankIC 0.030).\n                Concise Justification: Combining these captures 'Structural Fragility': the R-squared component ensures the trend is technically 'stretched' and linear, while the ATR/Volume ratio confirms the move is 'expensive' and unsupported by deep liquidity, creating a synergistic signal for trend exhaustion.\n                Concise Knowledge: If a price trend exhibits high short-term linearity (R-squared) but requires increasing price volatility per unit of volume (ATR/Volume), it indicates a liquidity-driven 'blow-off' phase likely to reverse; whereas high linearity with low relative volatility suggests a sustainable, fundamentally backed trend.\n                concise Specification: Calculate the 5-day rolling R-squared of $close against a time index; calculate the 5-day average of ($high-$low)/$volume; the SEE factor is the product of these two metrics, where high values signal imminent exhaustion and low values signal structural stability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d025bb6b3900",
      "parent_trajectory_ids": [
        "d7555a47a787",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049294871514049,
        "ICIR": 0.0369113585360031,
        "RankIC": 0.0224614532776789,
        "RankICIR": 0.1688719622945828,
        "annualized_return": 0.0374867846205408,
        "information_ratio": 0.5864814292730505,
        "max_drawdown": -0.1089300550887258
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:39:22.216542",
      "updated_at": "2026-01-17T07:39:22.216548"
    },
    "9de952d54942159e": {
      "factor_id": "9de952d54942159e",
      "factor_name": "Institutional_Accumulation_Density_10D",
      "factor_expression": "RANK($volume / ($high - $low + 1e-8)) * RANK(INV(TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($volume / ($high - $low + 1e-8)) * RANK(INV(TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Density_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the absorption hypothesis focusing on the cross-sectional rank of volume density relative to price volatility. It captures periods where price moves are supported by heavy volume relative to the realized range, normalized by the 10-day volatility to ensure the trend is structural rather than speculative.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Absorption Efficiency Index (IAEI) predicts asset returns by identifying periods where high volume-to-price-range density (Institutional Accumulation) is paired with low volatility-normalized price efficiency, filtering out low-conviction breakouts.\n                Concise Observation: Parent 1 (IAPF) captures trend persistence through volume concentration (RankIC 0.020), while Parent 2 (VVDE) captures price efficiency (RankIC 0.029); combining them addresses the weakness of buying into low-liquidity volatility spikes.\n                Concise Justification: Institutional players accumulate positions over time to minimize market impact, leading to high volume per unit of price range; by weighting volume density with the inverse of volatility-normalized range, we isolate high-conviction structural trends.\n                Concise Knowledge: If price appreciation occurs with high volume density and low relative volatility, it indicates institutional absorption; when price moves are 'hollow' (high volatility, low volume), they are prone to mean reversion.\n                concise Specification: Define IAEI as the product of a 5-day rolling average of (Volume / (High - Low)) and the 5-day inverse of (ATR / Relative Volume), ensuring both volume support and price efficiency are maximized simultaneously.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "949f65a01ea5",
      "parent_trajectory_ids": [
        "acb39605a28d",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037083274031751,
        "ICIR": 0.0276066445176113,
        "RankIC": 0.0194354575836202,
        "RankICIR": 0.1489870304438573,
        "annualized_return": 0.0179828042632012,
        "information_ratio": 0.2936536264072802,
        "max_drawdown": -0.122562838916295
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:42:11.750856",
      "updated_at": "2026-01-17T07:42:11.750862"
    },
    "3e35e902f32a93e8": {
      "factor_id": "3e35e902f32a93e8",
      "factor_name": "Structural_Exhaustion_Efficiency_20D",
      "factor_expression": "TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8) / ($volume / (TS_MEAN($volume, 5) + 1e-8)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8) / ($volume / (TS_MEAN($volume, 5) + 1e-8)), 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The SEE factor identifies mean-reversion opportunities by calculating the ratio of intraday price travel (range) to net movement (body), normalized by relative volume. High values indicate 'hollow' volatility where price expands on low conviction, signaling potential exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the 20-day average of the ratio between intraday range-to-body asymmetry and 5-day relative volume intensity, identifies mean-reversion opportunities where price expansion is decoupled from liquidity support.\n                Concise Observation: Parent 1 (RankIC 0.0196) captures price-action indecision, while Parent 2 (RankIC 0.0298) identifies volume-price divergence; combining them targets 'hollow' volatility where high range occurs on low conviction.\n                Concise Justification: By dividing the intraday range-to-body ratio by the relative volume, we isolate periods where price 'travel' is high but 'efficiency' is low, signaling that the current trend is unsustainable due to a lack of volume-weighted cost basis.\n                Concise Knowledge: If a stock exhibits high intraday price volatility relative to its net open-to-close movement (asymmetry) while simultaneously experiencing low relative volume (hollow liquidity), then the price movement is likely driven by retail exhaustion rather than institutional conviction, leading to predictable reversals.\n                concise Specification: The SEE factor is calculated as (High-Low)/(abs(Close-Open) + epsilon) divided by (Volume / Rolling_Mean(Volume, 5)), smoothed over a 20-day window to capture persistent structural exhaustion while filtering for high-ATR regimes.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "54bba1c4e2b3",
      "parent_trajectory_ids": [
        "f0c2093c047e",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048152811794458,
        "ICIR": 0.0373798278647546,
        "RankIC": 0.0208149822955344,
        "RankICIR": 0.1635624640411027,
        "annualized_return": 0.0399757029352592,
        "information_ratio": 0.6571625664999783,
        "max_drawdown": -0.0882684243465727
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:45:37.553954",
      "updated_at": "2026-01-17T07:45:37.553960"
    },
    "56b4c928d1cab681": {
      "factor_id": "56b4c928d1cab681",
      "factor_name": "Relative_Range_Efficiency_Rank",
      "factor_expression": "RANK(TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Efficiency_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the exhaustion principle, focusing on the divergence between price range and volume intensity. It identifies stocks with the most disproportionate price travel relative to their liquidity support over a 10-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the 20-day average of the ratio between intraday range-to-body asymmetry and 5-day relative volume intensity, identifies mean-reversion opportunities where price expansion is decoupled from liquidity support.\n                Concise Observation: Parent 1 (RankIC 0.0196) captures price-action indecision, while Parent 2 (RankIC 0.0298) identifies volume-price divergence; combining them targets 'hollow' volatility where high range occurs on low conviction.\n                Concise Justification: By dividing the intraday range-to-body ratio by the relative volume, we isolate periods where price 'travel' is high but 'efficiency' is low, signaling that the current trend is unsustainable due to a lack of volume-weighted cost basis.\n                Concise Knowledge: If a stock exhibits high intraday price volatility relative to its net open-to-close movement (asymmetry) while simultaneously experiencing low relative volume (hollow liquidity), then the price movement is likely driven by retail exhaustion rather than institutional conviction, leading to predictable reversals.\n                concise Specification: The SEE factor is calculated as (High-Low)/(abs(Close-Open) + epsilon) divided by (Volume / Rolling_Mean(Volume, 5)), smoothed over a 20-day window to capture persistent structural exhaustion while filtering for high-ATR regimes.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "54bba1c4e2b3",
      "parent_trajectory_ids": [
        "f0c2093c047e",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048152811794458,
        "ICIR": 0.0373798278647546,
        "RankIC": 0.0208149822955344,
        "RankICIR": 0.1635624640411027,
        "annualized_return": 0.0399757029352592,
        "information_ratio": 0.6571625664999783,
        "max_drawdown": -0.0882684243465727
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:45:37.583024",
      "updated_at": "2026-01-17T07:45:37.583030"
    },
    "c91c0cc9e19b6247": {
      "factor_id": "c91c0cc9e19b6247",
      "factor_name": "Informed_Liquidity_Absorption_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) / (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) / (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Liquidity_Absorption_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional trends by calculating the ratio of the overnight gap (normalized by historical volatility) to the intraday price discovery efficiency. A high gap validated by low price-to-volume divergence suggests institutional absorption and trend persistence.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Absorption (ILA) factor, defined as the product of the overnight gap (normalized by 5-day intraday volatility) and the inverse of the 5-day Volatility-Volume Divergence Efficiency, identifies high-conviction institutional trends by rewarding gaps that are sustained by efficient, high-volume intraday price discovery.\n                Concise Observation: Parent 1 (IAG) captures pre-market intent but lacks intraday validation, while Parent 2 (VVDE) measures execution efficiency but ignores the signaling power of overnight positioning; combining them addresses the 'hollow move' problem in gap trading.\n                Concise Justification: Institutional players often express conviction through overnight positioning, but the sustainability of the resulting trend depends on whether intraday liquidity is sufficient to absorb the move without excessive volatility, a state captured by the ratio of gap magnitude to intraday efficiency.\n                Concise Knowledge: If an overnight price gap is validated by high volume relative to price range (low VVDE), it indicates institutional absorption and trend persistence; if a gap occurs with wide price swings on low volume (high VVDE), it indicates liquidity exhaustion and likely mean reversion.\n                concise Specification: The factor is calculated as (Gap / ATR_5) / (Range_5 / Volume_Rel_5), where Gap is (Open - Prev_Close), ATR_5 is the 5-day average true range, Range_5 is the 5-day average (High - Low), and Volume_Rel_5 is the 5-day average volume; a higher value predicts positive future returns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "df7dfd9db5e1",
      "parent_trajectory_ids": [
        "2c2098e706e5",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063747927182966,
        "ICIR": 0.0474726293488803,
        "RankIC": 0.0218360517214985,
        "RankICIR": 0.1675279251410049,
        "annualized_return": 0.0553551326154067,
        "information_ratio": 0.8556669485594854,
        "max_drawdown": -0.0968061621215196
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:48:28.530475",
      "updated_at": "2026-01-17T07:48:28.530481"
    },
    "70e549c8cea3371f": {
      "factor_id": "70e549c8cea3371f",
      "factor_name": "Institutional_Gap_Efficiency_Rank_10D",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Efficiency_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Informed Liquidity Absorption hypothesis. It measures the strength of the overnight gap relative to the 10-day volatility, divided by the efficiency of intraday price movement (range per unit of volume). Higher values indicate gaps that are more likely to be sustained by institutional liquidity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Absorption (ILA) factor, defined as the product of the overnight gap (normalized by 5-day intraday volatility) and the inverse of the 5-day Volatility-Volume Divergence Efficiency, identifies high-conviction institutional trends by rewarding gaps that are sustained by efficient, high-volume intraday price discovery.\n                Concise Observation: Parent 1 (IAG) captures pre-market intent but lacks intraday validation, while Parent 2 (VVDE) measures execution efficiency but ignores the signaling power of overnight positioning; combining them addresses the 'hollow move' problem in gap trading.\n                Concise Justification: Institutional players often express conviction through overnight positioning, but the sustainability of the resulting trend depends on whether intraday liquidity is sufficient to absorb the move without excessive volatility, a state captured by the ratio of gap magnitude to intraday efficiency.\n                Concise Knowledge: If an overnight price gap is validated by high volume relative to price range (low VVDE), it indicates institutional absorption and trend persistence; if a gap occurs with wide price swings on low volume (high VVDE), it indicates liquidity exhaustion and likely mean reversion.\n                concise Specification: The factor is calculated as (Gap / ATR_5) / (Range_5 / Volume_Rel_5), where Gap is (Open - Prev_Close), ATR_5 is the 5-day average true range, Range_5 is the 5-day average (High - Low), and Volume_Rel_5 is the 5-day average volume; a higher value predicts positive future returns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "df7dfd9db5e1",
      "parent_trajectory_ids": [
        "2c2098e706e5",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063747927182966,
        "ICIR": 0.0474726293488803,
        "RankIC": 0.0218360517214985,
        "RankICIR": 0.1675279251410049,
        "annualized_return": 0.0553551326154067,
        "information_ratio": 0.8556669485594854,
        "max_drawdown": -0.0968061621215196
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:48:28.559726",
      "updated_at": "2026-01-17T07:48:28.559731"
    },
    "af25db02d368cf6f": {
      "factor_id": "af25db02d368cf6f",
      "factor_name": "Structural_Exhaustion_Index_5D",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($volume + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the LAVPE hypothesis focusing on the 'Effort-vs-Result' principle. It identifies 'hollow expansions' where price range is high relative to the volume-weighted energy, normalized by the cross-sectional rank of trend linearity to focus on the most stable regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Linearity-Adjusted Volume-Price Efficiency' (LAVPE) factor, defined as the ratio of 5-day ATR-normalized price range to 5-day volume-weighted volatility, scaled by the 10-day price-time R-squared, predicts mean reversion by identifying structural exhaustion in linear trends.\n                Concise Observation: Parent 1's trend linearity (RSQR10) identifies stable regimes, while Parent 2's efficiency ratio (VVDE) flags price-volume decoupling; combining them addresses the 'hollow expansion' observed when price moves exceed institutional backing.\n                Concise Justification: The 'Effort-vs-Result' principle suggests that price moves requiring disproportionately low or erratic volume-weighted energy are unsustainable; weighting this efficiency by trend linearity filters out noise and focuses on structural breakdown points.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) but low volume-weighted efficiency (range/volume-volatility), it is likely a liquidity-driven exhaustion point; When volume-weighted energy fails to support price expansion, the trend's structural integrity is compromised.\n                concise Specification: Calculate the 5-day average of (High-Low)/Close as price range, divide by the 5-day average of ($volume * (High-Low)/Close) for volume-weighted energy, and multiply by the 10-day R-squared of $close against a time index.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6d40bf7cdeda",
      "parent_trajectory_ids": [
        "b3f61a773f43",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030771522236266,
        "ICIR": 0.0227185928599906,
        "RankIC": 0.0192694488128021,
        "RankICIR": 0.1455545567998845,
        "annualized_return": 0.0327616494366824,
        "information_ratio": 0.4481053444880533,
        "max_drawdown": -0.0983948914523569
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:04:01.641847",
      "updated_at": "2026-01-17T08:04:01.641853"
    },
    "8cee304738fda193": {
      "factor_id": "8cee304738fda193",
      "factor_name": "ZScore_VWAP_Deviation_Range_10D",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 10)) * RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 10)) * RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_VWAP_Deviation_Range_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the hollow expansion hypothesis that uses cross-sectional ranking to identify stocks where the intraday price range is large relative to its recent history, and the price has closed far from the intraday mid-point, signaling potential exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Hollow Expansion Index (LAHEI), defined as the product of the ATR-normalized intraday range and the distance between the daily close and the Volume-Weighted Average Price (VWAP), identifies price 'hollows' that predict short-term mean reversion.\n                Concise Observation: Parent strategies showed that intraday price positioning relative to volume (RankIC 0.018) and volatility-normalized volume divergence (RankIC 0.030) are both predictive; combining them addresses the weakness of volume-only or price-only exhaustion signals.\n                Concise Justification: By multiplying the range-based volatility (from Parent 2) with the VWAP-to-Close deviation (from Parent 1), we isolate instances where price moved significantly but the 'center of gravity' of trading volume failed to follow, indicating a lack of structural support.\n                Concise Knowledge: If a large price expansion occurs with a significant gap between the closing price and the volume-weighted average price, the move is likely driven by liquidity voids rather than institutional conviction; when such 'hollow' moves occur, they tend to revert as liquidity stabilizes.\n                concise Specification: The factor is calculated as [(High - Low) / ATR(5)] * [(Close - VWAP) / (High - Low)], where VWAP is approximated as (Open+Close+High+Low)/4, focusing on the 5-day lookback period for volatility normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ab0815655d5d",
      "parent_trajectory_ids": [
        "94f4a684161a",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049273018425848,
        "ICIR": 0.0332149350767551,
        "RankIC": 0.020188325843943,
        "RankICIR": 0.1407029517125129,
        "annualized_return": 0.0657937117078128,
        "information_ratio": 0.9010570874521956,
        "max_drawdown": -0.0985490242912436
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:06:48.396749",
      "updated_at": "2026-01-17T08:06:48.396755"
    },
    "234ecf17f52471e1": {
      "factor_id": "234ecf17f52471e1",
      "factor_name": "Inst_Gap_Persistence_V1",
      "factor_expression": "(TS_ZSCORE(($close-$open)/$open, 5) / (TS_STD($open - DELAY($close, 1), 5) + 1e-8)) * TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SKEW(($close - $open) / $open, 5) / (TS_STD(($open - DELAY($close, 1)) / DELAY($close, 1), 5) + 1e-8)) * TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / $close)\" # Your output factor expression will be filled in here\n    name = \"Inst_Gap_Persistence_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining intraday return skewness relative to overnight volatility with price-volume correlation. Low skewness relative to gap volatility suggests 'quiet' informed flow, while high price-volume correlation confirms structural trend conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Gap-Persistence' factor identifies sustainable price movements by multiplying the 5-day ratio of intraday return skewness to overnight volatility with the 20-day price-volume correlation, scaled by the 14-day price range, to distinguish institutional accumulation from noise.\n                Concise Observation: Parent 1 (RankIC 0.022) captures short-term informed flow via distribution shapes, while Parent 2 (RankIC 0.031) captures medium-term structural liquidity; combining them addresses the noise inherent in overnight gaps by filtering them through intraday persistence metrics.\n                Concise Justification: Institutional investors often hide their trades intraday (low skewness) while their impact is felt in overnight gaps and volume-price alignment; multiplying these cross-dimensional metrics creates a regime-adaptive signal that rewards consistency across multiple time horizons.\n                Concise Knowledge: If short-term intraday skewness is low relative to overnight volatility, it indicates institutional 'quiet' accumulation; when this aligns with a strong 20-day price-volume correlation, the resulting signal identifies high-conviction structural trends rather than temporary liquidity traps.\n                concise Specification: The factor is defined as (5-day Intraday Skew / 5-day StdDev of (Open - PrevClose)) * (20-day Correlation of Close and Volume) * (14-day ATR / Close), where ATR is the 14-day average of (High - Low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "94e2b000cf8b",
      "parent_trajectory_ids": [
        "8b13845457df",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.006797536530237,
        "ICIR": 0.0514909043766003,
        "RankIC": 0.0213743344969453,
        "RankICIR": 0.1644779678783632,
        "annualized_return": 0.0541896324471593,
        "information_ratio": 0.7837050863467108,
        "max_drawdown": -0.1641871046121855
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:08:12.502814",
      "updated_at": "2026-01-17T08:08:12.502821"
    },
    "3162184d49f077b4": {
      "factor_id": "3162184d49f077b4",
      "factor_name": "Gap_Trend_Alignment_14D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close - $open, $volume, 14)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close - $open, $volume, 14)\" # Your output factor expression will be filled in here\n    name = \"Gap_Trend_Alignment_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the alignment between overnight price gaps and the subsequent intraday range, scaled by volume conviction. It targets stocks where the gap is supported by consistent price-volume behavior rather than speculative noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Gap-Persistence' factor identifies sustainable price movements by multiplying the 5-day ratio of intraday return skewness to overnight volatility with the 20-day price-volume correlation, scaled by the 14-day price range, to distinguish institutional accumulation from noise.\n                Concise Observation: Parent 1 (RankIC 0.022) captures short-term informed flow via distribution shapes, while Parent 2 (RankIC 0.031) captures medium-term structural liquidity; combining them addresses the noise inherent in overnight gaps by filtering them through intraday persistence metrics.\n                Concise Justification: Institutional investors often hide their trades intraday (low skewness) while their impact is felt in overnight gaps and volume-price alignment; multiplying these cross-dimensional metrics creates a regime-adaptive signal that rewards consistency across multiple time horizons.\n                Concise Knowledge: If short-term intraday skewness is low relative to overnight volatility, it indicates institutional 'quiet' accumulation; when this aligns with a strong 20-day price-volume correlation, the resulting signal identifies high-conviction structural trends rather than temporary liquidity traps.\n                concise Specification: The factor is defined as (5-day Intraday Skew / 5-day StdDev of (Open - PrevClose)) * (20-day Correlation of Close and Volume) * (14-day ATR / Close), where ATR is the 14-day average of (High - Low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "94e2b000cf8b",
      "parent_trajectory_ids": [
        "8b13845457df",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.006797536530237,
        "ICIR": 0.0514909043766003,
        "RankIC": 0.0213743344969453,
        "RankICIR": 0.1644779678783632,
        "annualized_return": 0.0541896324471593,
        "information_ratio": 0.7837050863467108,
        "max_drawdown": -0.1641871046121855
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:08:12.562042",
      "updated_at": "2026-01-17T08:08:12.562048"
    },
    "b9a08347802a4c0a": {
      "factor_id": "b9a08347802a4c0a",
      "factor_name": "SLVR_Structural_Exhaustion_5D",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-5)) * RANK(TS_CORR($close, $volume, 20)) * ZSCORE(ABS($return) / ($volume + 1e-5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-9), 5)) * RANK(TS_CORR($close, $volume, 20)) * ZSCORE(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-9), 5))\" # Your output factor expression will be filled in here\n    name = \"SLVR_Structural_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by combining intraday price dispersion, price-volume correlation decay, and illiquidity. This version focuses on the 5-day interaction between range-to-volume and Amihud illiquidity, moderated by the 20-day price-volume correlation to identify unsustainable exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by multiplying the 5-day intraday price dispersion (High-Low range normalized by Volume) with the 20-day negative price-volume correlation, further scaled by a 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1 successfully captured intraday exhaustion (RankIC 0.0268) and Parent 2 captured structural decay (RankIC 0.0266), but both suffer from false positives during high-volume trend breakouts where price-volume synergy remains intact.\n                Concise Justification: Fusing these metrics ensures that high volatility is only traded as a reversal if it lacks structural support (negative correlation) and occurs in a high-impact environment (Amihud), filtering out healthy trend continuations.\n                Concise Knowledge: If extreme intraday price volatility occurs while price-volume synergy is decaying and illiquidity is peaking, then the price movement is likely a 'liquidity vacuum' spike prone to reversal; When high range-to-volume ratios coincide with negative price-volume correlation, market participants are exhausted.\n                concise Specification: The factor is defined as: Rank((High-Low)/(Volume+1e-5), 5) * Rank(Correlation(Close, Volume, 20), 20) * ZScore((Abs(Return)/Volume), 5). It expects a negative relationship with future returns as high values indicate unsustainable exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ef9400abf2",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "8b31cd9afab3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067035766755135,
        "ICIR": 0.0465146591916888,
        "RankIC": 0.0229687226052108,
        "RankICIR": 0.1598980304505583,
        "annualized_return": 0.006762518040761,
        "information_ratio": 0.0919589333845521,
        "max_drawdown": -0.1258508606308615
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:15:46.032114",
      "updated_at": "2026-01-17T08:15:46.032121"
    },
    "adb04d205aaddcce": {
      "factor_id": "adb04d205aaddcce",
      "factor_name": "Amihud_Exhaustion_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE(ABS($return) / ($volume + 1e-5), 5)) * RANK(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-5), 5)) * RANK(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Exhaustion_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Illiquidity Z-score' component of the SLVR hypothesis. It identifies stocks where the current return-to-volume ratio (Amihud Illiquidity) is an outlier relative to its own history, filtered by the 20-day price-volume trend to catch reversal points.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by multiplying the 5-day intraday price dispersion (High-Low range normalized by Volume) with the 20-day negative price-volume correlation, further scaled by a 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1 successfully captured intraday exhaustion (RankIC 0.0268) and Parent 2 captured structural decay (RankIC 0.0266), but both suffer from false positives during high-volume trend breakouts where price-volume synergy remains intact.\n                Concise Justification: Fusing these metrics ensures that high volatility is only traded as a reversal if it lacks structural support (negative correlation) and occurs in a high-impact environment (Amihud), filtering out healthy trend continuations.\n                Concise Knowledge: If extreme intraday price volatility occurs while price-volume synergy is decaying and illiquidity is peaking, then the price movement is likely a 'liquidity vacuum' spike prone to reversal; When high range-to-volume ratios coincide with negative price-volume correlation, market participants are exhausted.\n                concise Specification: The factor is defined as: Rank((High-Low)/(Volume+1e-5), 5) * Rank(Correlation(Close, Volume, 20), 20) * ZScore((Abs(Return)/Volume), 5). It expects a negative relationship with future returns as high values indicate unsustainable exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ef9400abf2",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "8b31cd9afab3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067035766755135,
        "ICIR": 0.0465146591916888,
        "RankIC": 0.0229687226052108,
        "RankICIR": 0.1598980304505583,
        "annualized_return": 0.006762518040761,
        "information_ratio": 0.0919589333845521,
        "max_drawdown": -0.1258508606308615
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:15:46.091344",
      "updated_at": "2026-01-17T08:15:46.091350"
    },
    "348629c09066e01e": {
      "factor_id": "348629c09066e01e",
      "factor_name": "MRLV_Exhaustion_Trigger",
      "factor_expression": "RANK(($high - $low) / $close) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / $close) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MRLV_Exhaustion_Trigger\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Mean-Reverting Liquidity Vacuum (MRLV) focusing on micro-exhaustion. It measures price range expansion relative to normalized volume, identifying instances where price moves are 'thin' and likely to reverse due to lack of liquidity depth.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Retail Structural Friction' (IRSF) factor identifies high-probability reversals by multiplying the 5-day Mean-Reverting Liquidity Vacuum (MRLV) with the 20-day negative price-volume correlation, weighted by the 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1's MRLV (RankIC 0.0262) captures micro-exhaustion, while Parent 2's divergence (RankIC 0.0266) captures structural decay; combining them targets 'hollow' volatility spikes in thin markets where price discovery is inefficient.\n                Concise Justification: The MRLV identifies the 'exhaustion' trigger, while the negative price-volume correlation ensures the move is a 'divergence' from fundamental accumulation, and the Amihud Z-score scales the signal by the difficulty of price maintenance in low-liquidity environments.\n                Concise Knowledge: If short-term price range expansion occurs on declining relative volume (Liquidity Vacuum) while the medium-term trend shows negative price-volume correlation, the price move is likely retail-driven and prone to reversal; when these conditions coincide with high illiquidity, the mean-reversion effect is amplified due to the lack of institutional support.\n                concise Specification: Define MRLV as (High-Low)/Close divided by (Volume/SMA(Volume,20)) over 5 days; calculate the 20-day correlation between daily returns and volume changes; multiply the Z-scored MRLV by the negative correlation and the 5-day Amihud Illiquidity ratio (abs(return)/volume).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b7098cdae6bc",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073375787075466,
        "ICIR": 0.0532128482617706,
        "RankIC": 0.024067797281387,
        "RankICIR": 0.1764820283550209,
        "annualized_return": 0.078373715075335,
        "information_ratio": 1.099977462153051,
        "max_drawdown": -0.1230286729484408
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:28.195795",
      "updated_at": "2026-01-17T08:22:28.195801"
    },
    "935737e4c24adabd": {
      "factor_id": "935737e4c24adabd",
      "factor_name": "Amihud_Divergence_Reversal",
      "factor_expression": "(-1 * TS_CORR($return, DELTA($volume, 1), 20)) * RANK(ABS($return) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20)) * RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Divergence_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures structural decay by multiplying the negative correlation between returns and volume changes with the cross-sectional rank of the Amihud illiquidity ratio. It highlights assets where price trends are diverging from volume support in illiquid conditions.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Retail Structural Friction' (IRSF) factor identifies high-probability reversals by multiplying the 5-day Mean-Reverting Liquidity Vacuum (MRLV) with the 20-day negative price-volume correlation, weighted by the 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1's MRLV (RankIC 0.0262) captures micro-exhaustion, while Parent 2's divergence (RankIC 0.0266) captures structural decay; combining them targets 'hollow' volatility spikes in thin markets where price discovery is inefficient.\n                Concise Justification: The MRLV identifies the 'exhaustion' trigger, while the negative price-volume correlation ensures the move is a 'divergence' from fundamental accumulation, and the Amihud Z-score scales the signal by the difficulty of price maintenance in low-liquidity environments.\n                Concise Knowledge: If short-term price range expansion occurs on declining relative volume (Liquidity Vacuum) while the medium-term trend shows negative price-volume correlation, the price move is likely retail-driven and prone to reversal; when these conditions coincide with high illiquidity, the mean-reversion effect is amplified due to the lack of institutional support.\n                concise Specification: Define MRLV as (High-Low)/Close divided by (Volume/SMA(Volume,20)) over 5 days; calculate the 20-day correlation between daily returns and volume changes; multiply the Z-scored MRLV by the negative correlation and the 5-day Amihud Illiquidity ratio (abs(return)/volume).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b7098cdae6bc",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073375787075466,
        "ICIR": 0.0532128482617706,
        "RankIC": 0.024067797281387,
        "RankICIR": 0.1764820283550209,
        "annualized_return": 0.078373715075335,
        "information_ratio": 1.099977462153051,
        "max_drawdown": -0.1230286729484408
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:28.225565",
      "updated_at": "2026-01-17T08:22:28.225571"
    },
    "d8bcc7cc594a12bc": {
      "factor_id": "d8bcc7cc594a12bc",
      "factor_name": "Exhaustion_Volume_Decay_10D",
      "factor_expression": "TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Volume_Decay_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by looking at the interaction between price momentum and the decline in volume support. It uses the R-squared of the price trend scaled by the inverse of the price-volume correlation, focusing on cases where price moves linearly but volume participation is fading.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:55.013504",
      "updated_at": "2026-01-17T08:22:55.013510"
    },
    "fe64b5e15c32e0b9": {
      "factor_id": "fe64b5e15c32e0b9",
      "factor_name": "Consensus_Drift_Volatility_Ratio_20D",
      "factor_expression": "($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8) * ABS($open / DELAY($close, 1) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8) * ABS($open / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"Consensus_Drift_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price discovery by comparing the distance of the current price from its 20-day mean to the overnight volatility shock. High values suggest price is overextending relative to consensus, especially when triggered by overnight gaps.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Adaptive_Consensus_Exhaustion' factor, calculated as the 20-day Z-score of the price-to-VWAP distance multiplied by the 20-day price-volume correlation and adjusted by the ratio of overnight returns to the 14-day ATR, identifies trend continuation when consensus drift is stable and reversals when liquidity shocks occur at extreme valuations.\n                Concise Observation: Parent 1 shows that normalized VWAP distance captures consensus efficiency (RankIC 0.021), while Parent 2 demonstrates that overnight returns relative to volatility identify conviction (RankIC 0.031); however, neither accounts for the transition between trend stability and exhaustion.\n                Concise Justification: Fusing long-term consensus drift with short-term liquidity shocks allows the factor to distinguish between 'healthy' price appreciation supported by volume and 'exhausted' price spikes caused by overnight liquidity gaps, leading to more robust predictive power across different market regimes.\n                Concise Knowledge: If price-to-VWAP distance is normalized by volatility, it represents valuation drift; when this drift is accompanied by high price-volume correlation, the trend is reinforced, but if coupled with high overnight return shocks (liquidity gaps), the probability of mean-reversion increases.\n                concise Specification: The factor uses a 20-day window for VWAP and price-volume correlation to establish the trend anchor, a 14-day ATR for volatility normalization, and a 1-day overnight return (Open/PrevClose - 1) as the exhaustion trigger, targeting a non-linear combination of trend strength and reversal probability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6ab1bd4c02a3",
      "parent_trajectory_ids": [
        "a52ba1223e8c",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073779907857329,
        "ICIR": 0.0523821340778484,
        "RankIC": 0.0217374772276411,
        "RankICIR": 0.1617357917821639,
        "annualized_return": 0.0626651264624249,
        "information_ratio": 0.8305351420356816,
        "max_drawdown": -0.1069402707821122
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:27:09.463318",
      "updated_at": "2026-01-17T08:27:09.463324"
    },
    "5981b3cc0eeb6c45": {
      "factor_id": "5981b3cc0eeb6c45",
      "factor_name": "Ranked_Friction_Discovery_14D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 14)) * RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 14)) * RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Friction_Discovery_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the friction-adjusted discovery factor. It evaluates the relative intensity of overnight information shocks against liquidity (proxied by price-volume correlation) and volatility (ATR). High values indicate high-conviction diffusion, while low values suggest frictional discovery prone to reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Friction-Adjusted Discovery' factor, calculated as the product of the 20-day price-volume correlation and the ratio of the absolute overnight gap to the 14-day Average True Range, identifies assets where overnight information is inefficiently integrated into intraday liquidity, predicting short-term price reversals or continuations based on the magnitude of this friction.\n                Concise Observation: Parent 1 showed that overnight gaps relative to intraday volatility capture diffusion lags (RankIC 0.021), while Parent 2 demonstrated that price-volume correlation scaled by ATR identifies high-conviction liquidity states (RankIC 0.031).\n                Concise Justification: The fusion leverages price-volume correlation as a proxy for structural liquidity and ATR as a volatility normalizer, ensuring that the overnight 'information shock' is measured against the asset's current capacity to process information without excessive slippage or exhaustion.\n                Concise Knowledge: If a significant overnight price gap is not supported by a corresponding intraday price-volume correlation relative to historical volatility (ATR), the price discovery is considered incomplete or 'frictional'; when this friction is high, the asset is prone to mean-reversion as liquidity eventually absorbs the information shock.\n                concise Specification: The factor is defined as (Correlation($close, $volume, 20) * (Abs($open / Delay($close, 1) - 1) / ATR(14))), where ATR is the 14-day rolling average of (High - Low); a high value indicates high-conviction information diffusion, while a low value suggests a lack of liquidity support for the price move.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "16f63ed20036",
      "parent_trajectory_ids": [
        "ddd892827174",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068032163816015,
        "ICIR": 0.0463246430445467,
        "RankIC": 0.0236913075245471,
        "RankICIR": 0.1659601070478587,
        "annualized_return": 0.0230248837679552,
        "information_ratio": 0.3111210249824456,
        "max_drawdown": -0.179194916529402
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:33:02.149668",
      "updated_at": "2026-01-17T08:33:02.149674"
    },
    "136f1dd35e873a74": {
      "factor_id": "136f1dd35e873a74",
      "factor_name": "LSDI_Structural_Reversal_5D",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 5) * (1 - TS_CORR($return, $volume, 20)) * TS_MEAN(ABS($return) / ($volume * $close + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 5) * (1 - TS_CORR($close / DELAY($close, 1) - 1, $volume, 20)) * TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume * $close + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"LSDI_Structural_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Liquidity-Structural Divergence Index: Identifies mean-reversion candidates by combining high intraday price dispersion relative to volume (liquidity exhaustion), low price-volume correlation (structural weakness), and rising illiquidity (Amihud).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Structural Divergence Index' (LSDI) predicts reversals by identifying assets where the 5-day Z-score of the (High-Low)/Volume ratio is high, while the 20-day price-volume correlation is low and the 5-day Amihud Illiquidity is rising.\n                Concise Observation: Parent 1 successfully captured mean-reversion via intraday range/volume (RankIC 0.0268), while Parent 2 identified regime shifts via price-volume correlation and Amihud illiquidity (RankIC 0.0255); however, both suffer from noise during trending markets with low-quality volume.\n                Concise Justification: Fusing these identifies 'Liquidity Vacuums' where price moves are 'expensive' (high Amihud) and 'disorganized' (low PV correlation), ensuring that the exhaustion signal from Parent 1 is validated by the structural weakness identified in Parent 2.\n                Concise Knowledge: If extreme intraday price dispersion occurs without a corresponding increase in price-volume reflexivity, the price move is likely a liquidity-driven exhaustion rather than a sustainable trend; when high illiquidity coincides with low correlation, the market is in a 'regime trap' prone to mean reversion.\n                concise Specification: The factor is defined as the product of the 5-day Z-score of (High-Low)/Volume and the inverse of the 20-day rolling correlation between price changes and volume, scaled by the 5-day average of absolute return divided by dollar volume (Amihud).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2978591db7ac",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "3c37422cea0a"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046096241986078,
        "ICIR": 0.032824358114378,
        "RankIC": 0.021486235632396,
        "RankICIR": 0.1551139432987301,
        "annualized_return": 0.0164555744396186,
        "information_ratio": 0.2351988131090285,
        "max_drawdown": -0.1148980339497351
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:38:04.473403",
      "updated_at": "2026-01-17T08:38:04.473410"
    },
    "d1c4f598a5239432": {
      "factor_id": "d1c4f598a5239432",
      "factor_name": "Amihud_Regime_Trap_Index",
      "factor_expression": "RANK(ABS($return) / ($volume * $close + 1e-8)) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume * $close + 1e-8)) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Regime_Trap_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies 'Regime Traps' where illiquidity is high but price movement lacks volume confirmation. It measures the cross-sectional rank of Amihud illiquidity multiplied by the divergence of current volume from its 20-day mean.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Structural Divergence Index' (LSDI) predicts reversals by identifying assets where the 5-day Z-score of the (High-Low)/Volume ratio is high, while the 20-day price-volume correlation is low and the 5-day Amihud Illiquidity is rising.\n                Concise Observation: Parent 1 successfully captured mean-reversion via intraday range/volume (RankIC 0.0268), while Parent 2 identified regime shifts via price-volume correlation and Amihud illiquidity (RankIC 0.0255); however, both suffer from noise during trending markets with low-quality volume.\n                Concise Justification: Fusing these identifies 'Liquidity Vacuums' where price moves are 'expensive' (high Amihud) and 'disorganized' (low PV correlation), ensuring that the exhaustion signal from Parent 1 is validated by the structural weakness identified in Parent 2.\n                Concise Knowledge: If extreme intraday price dispersion occurs without a corresponding increase in price-volume reflexivity, the price move is likely a liquidity-driven exhaustion rather than a sustainable trend; when high illiquidity coincides with low correlation, the market is in a 'regime trap' prone to mean reversion.\n                concise Specification: The factor is defined as the product of the 5-day Z-score of (High-Low)/Volume and the inverse of the 20-day rolling correlation between price changes and volume, scaled by the 5-day average of absolute return divided by dollar volume (Amihud).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2978591db7ac",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "3c37422cea0a"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046096241986078,
        "ICIR": 0.032824358114378,
        "RankIC": 0.021486235632396,
        "RankICIR": 0.1551139432987301,
        "annualized_return": 0.0164555744396186,
        "information_ratio": 0.2351988131090285,
        "max_drawdown": -0.1148980339497351
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:38:04.535079",
      "updated_at": "2026-01-17T08:38:04.535085"
    },
    "39784a9223d662b5": {
      "factor_id": "39784a9223d662b5",
      "factor_name": "Volume_Weighted_Position_Consistency",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_Consistency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the consistency of informed accumulation by evaluating the rank of price positioning relative to the volume-weighted trend, emphasizing stocks with stable institutional footprints.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:47.007667",
      "updated_at": "2026-01-17T08:41:47.007673"
    }
  }
}