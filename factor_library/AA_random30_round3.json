{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.673860",
    "last_updated": "2026-01-17T02:02:58.673864",
    "total_factors": 24,
    "version": "1.0",
    "note": "Random 30 factors from round 3 (from all_factors_library_AA.json)"
  },
  "factors": {
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T17:06:25.115468"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T17:06:25.147238"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T17:06:25.178740"
    },
    "a6bae1dc4dfa3dda": {
      "factor_id": "a6bae1dc4dfa3dda",
      "factor_name": "Price_Volume_Efficiency_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Efficiency_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of the 5-day cumulative return to the 5-day cumulative volume turnover. A high ratio indicates a 'fragile' price move on low volume support, suggesting a higher probability of mean reversion. The ratio is cross-sectionally standardized using Z-score to identify extremes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.702263",
      "updated_at": "2026-01-14T17:25:41.702270"
    },
    "974be850a4998b4d": {
      "factor_id": "974be850a4998b4d",
      "factor_name": "Efficiency_Exhaustion_Index_5D",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8), 5)",
      "factor_implementation_code": "",
      "factor_description": "This factor targets liquidity-driven price spikes by measuring the 5-day price impact per unit of volume, further normalized by the time-series volatility of the ratio. It captures instances where price moves are 'too efficient' relative to historical norms, signaling potential exhaustion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.738072",
      "updated_at": "2026-01-14T17:25:41.738079"
    },
    "824685211c1a9db6": {
      "factor_id": "824685211c1a9db6",
      "factor_name": "Ranked_Price_Impact_Ratio_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Price_Impact_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 5-day return relative to the total volume traded, applying a cross-sectional rank to identify stocks with the most extreme price-volume efficiency. This helps isolate stocks where the price has moved significantly on relatively low volume, indicating a lack of fundamental absorption.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.771471",
      "updated_at": "2026-01-14T17:25:41.771477"
    },
    "5d9461843c6ecdcb": {
      "factor_id": "5d9461843c6ecdcb",
      "factor_name": "Normalized_Squeeze_Efficiency_ZScore_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Squeeze_Efficiency_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the volatility squeeze intensity relative to its 20-day history, then weighting it by the 10-day Efficiency Ratio. Instead of a raw price range, it uses the average true range (high-low) over 5 days to normalize the squeeze denominator and avoid outliers, then applies a cross-sectional Z-score to the final interaction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.048570",
      "updated_at": "2026-01-14T17:29:05.048577"
    },
    "11d3367e5ad2e843": {
      "factor_id": "11d3367e5ad2e843",
      "factor_name": "Relative_Compression_Breakout_Rank_15D",
      "factor_expression": "RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Breakout_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'spring-loading' effect of price compression by comparing the 20-day volatility to the 10-day price range, using a logarithmic transformation to handle non-stationarity. It is then combined with the 10-day RSI to ensure the breakout occurs within a strong momentum context, avoiding stagnant consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.084527",
      "updated_at": "2026-01-14T17:29:05.084533"
    },
    "f41fea1bcefd3200": {
      "factor_id": "f41fea1bcefd3200",
      "factor_name": "Squeeze_Directional_Efficiency_10D",
      "factor_expression": "TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Directional_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the quality of the squeeze by interacting a 20-day volatility-to-range ratio with the Efficiency Ratio, but uses a 10-day moving average of the interaction to smooth out high-frequency noise. It uses the difference between close and open as a proxy for intraday conviction within the range calculation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.118341",
      "updated_at": "2026-01-14T17:29:05.118347"
    },
    "0e1e6895d262970e": {
      "factor_id": "0e1e6895d262970e",
      "factor_name": "VWPP_Persistence_20D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 20) * ($close / (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 20) * ($close / ((TS_SUM($volume, 10) > 0) ? (TS_SUM($close * $volume, 10) / TS_SUM($volume, 10)) : $close))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Price Persistence (VWPP) calculates the 20-day average of daily returns weighted by the cross-sectional rank of volume. This captures momentum supported by relative liquidity. It is then scaled by the ratio of the current price to the 10-day volume-weighted average price (VWAP) to ensure the signal is active during high-conviction price trends.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.245004",
      "updated_at": "2026-01-14T17:33:11.245011"
    },
    "7e17d6f59c434e2c": {
      "factor_id": "7e17d6f59c434e2c",
      "factor_name": "VWPP_ZScore_Filtered_20D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VWPP_ZScore_Filtered_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Weighted Price Persistence factor that applies a cross-sectional Z-score to the volume-weighted return component to improve comparability. The factor is activated only when the price is above the 10-day VWAP, identifying efficient momentum regimes.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.278927",
      "updated_at": "2026-01-14T17:33:11.278933"
    },
    "5f773998e535e4cb": {
      "factor_id": "5f773998e535e4cb",
      "factor_name": "VWPP_Efficiency_Ratio_15D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Efficiency_Ratio_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between volume-ranked returns and price efficiency. It uses a 15-day window for the volume-weighted return and normalizes the distance from the 10-day VWAP using the 20-day price standard deviation to account for varying volatility levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.312438",
      "updated_at": "2026-01-14T17:33:11.312444"
    },
    "dc158e72b35d4132": {
      "factor_id": "dc158e72b35d4132",
      "factor_name": "WRSQR_V_Divergence_Product",
      "factor_expression": "RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"WRSQR_V_Divergence_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR) with a volume-price divergence ratio. WRSQR20 is calculated as the squared correlation between close prices and a linear sequence over 20 days, weighted by DECAYLINEAR to prioritize recent trend consistency. V_Divergence is the ratio of the 5-day VWAP to the 5-day SMA, acting as a filter for institutional accumulation. The final factor is the product of their cross-sectional ranks.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.447954",
      "updated_at": "2026-01-14T18:02:27.447961"
    },
    "6b09649c0a1463db": {
      "factor_id": "6b09649c0a1463db",
      "factor_name": "Decay_Stability_Accumulation_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decay_Stability_Accumulation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the stability-momentum hypothesis. It uses the 20-day weighted R-squared (via DECAYLINEAR) to capture 'fresh' trend stability and scales it by the 5-day VWAP-to-SMA ratio to identify volume-supported price levels. Both components are cross-sectionally standardized using ZSCORE to ensure equal contribution.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.485711",
      "updated_at": "2026-01-14T18:02:27.485718"
    },
    "96f61e329e278ad9": {
      "factor_id": "96f61e329e278ad9",
      "factor_name": "Weighted_Trend_Conviction_Index",
      "factor_expression": "RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))\" # Your output factor expression will be filled in here\n    name = \"Weighted_Trend_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high recent trend stability that are also trading above their volume-weighted average price relative to their simple average. It uses a 20-day decay-weighted correlation to measure stability and a 5-day divergence ratio to measure conviction, combined via RANK to handle non-linearities.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.523328",
      "updated_at": "2026-01-14T18:02:27.523335"
    },
    "fc05bdc64f3d5cf3": {
      "factor_id": "fc05bdc64f3d5cf3",
      "factor_name": "Volume_Efficiency_Correlation_10D",
      "factor_expression": "(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, DELTA($volume, 1), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, DELTA($volume, 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Efficiency_Correlation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction accumulation phases by measuring the 10-day price return per unit of volume volatility, filtered by the correlation between returns and volume changes. High 'efficiency' (return/volatility) combined with positive price-volume correlation suggests institutional buying with minimal price friction.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.028160",
      "updated_at": "2026-01-14T20:33:07.028170"
    },
    "c821041764f42dd2": {
      "factor_id": "c821041764f42dd2",
      "factor_name": "Ranked_Accumulation_Efficiency_10D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10) / (TS_STD($volume, 10) + 1e-8)) * TS_CORR($return, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Accumulation_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the Volume Efficiency hypothesis. It ranks the 10-day return-to-volume-volatility ratio and scales it by the strength of the price-volume relationship. This isolates stocks showing steady price appreciation on consistent, trend-aligned volume.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.067500",
      "updated_at": "2026-01-14T20:33:07.067511"
    },
    "53ffb45a85127135": {
      "factor_id": "53ffb45a85127135",
      "factor_name": "Filtered_Volume_Momentum_10D",
      "factor_expression": "(TS_PCTCHANGE($close, 10) / MAX(TS_ZSCORE($volume, 10), 1)) * MAX(TS_CORR($return, $volume, 10), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 10) / MAX(TS_ZSCORE($volume, 10), 1)) * MAX(TS_CORR($return, $volume, 10), 0)\" # Your output factor expression will be filled in here\n    name = \"Filtered_Volume_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the 10-day momentum scaled by the inverse of volume dispersion, specifically when the price-volume correlation is positive. It uses Z-scoring for volume volatility to ensure the penalty for erratic liquidity is normalized across the universe.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day Volume Efficiency Factor, defined as the 10-day return divided by the 10-day volume standard deviation and multiplied by the 10-day price-volume correlation, identifies high-conviction accumulation phases by capturing high returns per unit of liquidity risk.\n                Concise Observation: Previous 20-day windows smoothed out volume signals too much, and simple normalization by the coefficient of variation failed to distinguish between accumulation and distribution, whereas a 10-day window with a correlation filter successfully improved IC.\n                Concise Justification: Shortening the window to 10 days captures immediate regime shifts, while the price-volume correlation ensures that the volume volatility being measured is associated with price increases (accumulation) rather than price-agnostic noise or distribution.\n                Concise Knowledge: If price momentum is scaled by the inverse of volume volatility and conditioned on positive price-volume correlation, it isolates institutional accumulation; in short-term windows, 'efficient' price movement (high return with low volume variance) indicates less friction and higher trend persistence.\n                concise Specification: The factor is calculated as: (10-day price return / 10-day rolling standard deviation of volume) * (10-day rolling correlation between daily returns and daily volume changes). All windows are fixed at 10 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069929480190521,
        "ICIR": 0.0463340700899272,
        "RankIC": 0.0237122492718362,
        "RankICIR": 0.1644686736188316,
        "annualized_return": 0.0277787233934552,
        "information_ratio": 0.3933719788893416,
        "max_drawdown": -0.1163474550030895
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:07.110727",
      "updated_at": "2026-01-14T20:33:07.110746"
    },
    "2bedf15e4751de80": {
      "factor_id": "2bedf15e4751de80",
      "factor_name": "Price_Volume_Accel_Divergence_10D",
      "factor_expression": "RANK(TS_MEAN($return, 10)) - RANK(TS_PCTCHANGE($volume, 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return, 10)) - RANK(TS_PCTCHANGE($volume, 3))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Accel_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend exhaustion by measuring the spread between the cross-sectional rank of 10-day price momentum and the cross-sectional rank of 3-day volume acceleration. A high volume acceleration paired with low price momentum (negative spread) suggests liquidity absorption and a potential peak.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:43.989130",
      "updated_at": "2026-01-14T20:40:43.989137"
    },
    "c2ac425b322611c4": {
      "factor_id": "c2ac425b322611c4",
      "factor_name": "Exhaustion_Rank_Spread_10D",
      "factor_expression": "RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Rank_Spread_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the price-volume divergence hypothesis that uses the 10-day time-series rank of returns compared to the 10-day time-series rank of volume growth. It targets assets where volume is reaching extreme historical levels (high rank) while price gains are lagging (low rank).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.005509",
      "updated_at": "2026-01-14T20:40:44.005515"
    },
    "d62c2a86081649c0": {
      "factor_id": "d62c2a86081649c0",
      "factor_name": "Churn_Intensity_Index_10D",
      "factor_expression": "RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)\" # Your output factor expression will be filled in here\n    name = \"Churn_Intensity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'churning' behavior by calculating the ratio of ranked price momentum to ranked volume volatility. It identifies periods where high volume activity does not translate into proportional price movement, signaling a loss of trend conviction.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.021513",
      "updated_at": "2026-01-14T20:40:44.021519"
    },
    "cf8d9a3eb9e997de": {
      "factor_id": "cf8d9a3eb9e997de",
      "factor_name": "Trend_Divergence_Efficiency_Slope_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Divergence_Efficiency_Slope_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by capturing the divergence between price deviation from its 10-day linear trend and the 5-day slope of price efficiency. A high residual paired with a declining efficiency slope indicates a trend losing conviction. To avoid duplicated sub-expressions, the efficiency is calculated using the ratio of body to the average true range proxy.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.962393",
      "updated_at": "2026-01-14T20:45:46.962399"
    },
    "56648b1aee6f7d28": {
      "factor_id": "56648b1aee6f7d28",
      "factor_name": "Efficiency_Decay_Residual_Interaction_15D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Decay_Residual_Interaction_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the interaction between price over-extension and the decay in price movement quality. It uses the 10-day price residual and the 5-day change in a smoothed efficiency ratio (body size relative to high-low range), focusing on the negative momentum of efficiency as a signal for trend failure.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.978971",
      "updated_at": "2026-01-14T20:45:46.978977"
    },
    "0e929b6dbe2a549a": {
      "factor_id": "0e929b6dbe2a549a",
      "factor_name": "Relative_Exhaustion_Divergence_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))\" # Your output factor expression will be filled in here\n    name = \"Relative_Exhaustion_Divergence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the price trend (10-day residual) and the trend of 'clean' price moves. Instead of simple KMID, it uses the ratio of the absolute return to the total daily range, smoothed over 5 days, and looks for its 3-day slope to identify exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.995460",
      "updated_at": "2026-01-14T20:45:46.995465"
    }
  }
}