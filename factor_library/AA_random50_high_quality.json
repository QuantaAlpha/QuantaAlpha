{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.668990",
    "last_updated": "2026-01-17T02:02:58.668998",
    "total_factors": 50,
    "version": "1.0",
    "note": "Random 50 high_quality factors from all_factors_library_AA.json"
  },
  "factors": {
    "e8e67ecb849a3d87": {
      "factor_id": "e8e67ecb849a3d87",
      "factor_name": "Volume_Surge_Efficiency_Divergence_15D",
      "factor_expression": "RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Efficiency_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the exhaustion hypothesis that uses the cross-sectional rank of price efficiency divided by the cross-sectional rank of volume Z-scores. It targets the non-linear nature of market exhaustion by identifying assets where the 'effort' (volume) is disproportionately high compared to the 'result' (price efficiency) relative to other stocks.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.129870",
      "updated_at": "2026-01-14T20:45:17.129876"
    },
    "4d5727c8cc0353a3": {
      "factor_id": "4d5727c8cc0353a3",
      "factor_name": "Volume_Weighted_Volatility_Dispersion_60D",
      "factor_expression": "TS_STD(WMA($close, 60), 60) / (TS_MEAN(WMA($close, 60), 60) + 1e-8)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the volume-weighted volatility coefficient. It normalizes price volatility by volume to identify phases of stable accumulation or distribution. Lower values indicate more efficient price discovery with less noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.855502",
      "updated_at": "2026-01-14T17:26:18.855509"
    },
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T17:06:25.115468"
    },
    "1fcafa6be21caa92": {
      "factor_id": "1fcafa6be21caa92",
      "factor_name": "Efficient_Acceleration_Rank_10D",
      "factor_expression": "RANK(TS_DELTA($return, 5)) * RANK(INV(TS_MEAN($volume / $close, 10) / (TS_MEAN($volume / $close, 40) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($return, 5)) * RANK(INV(TS_MEAN($volume / $close, 10) / TS_MEAN($volume / $close, 40)))\" # Your output factor expression will be filled in here\n    name = \"Efficient_Acceleration_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Volume-Weighted Price Acceleration hypothesis that focuses on the ratio of price acceleration to the stability of volume turnover. It uses cross-sectional ranking to isolate stocks where the rate of return is increasing most efficiently per unit of relative turnover.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Price Acceleration (VWPA10) factor identifies high-conviction momentum by measuring the change in price per unit of volume turnover, specifically targeting stocks where price increases are accelerating while volume remains stable relative to a 40-day baseline.\n                Concise Observation: Previous attempts (PVDE5, VSAM) focused on volume volatility ratios but failed to capture alpha, likely because they ignored price acceleration and used simple returns which don't distinguish between steady trends and stalling ones.\n                Concise Justification: By using the second derivative of price (acceleration) and normalizing it by the volume-to-price-level ratio (turnover proxy), we isolate 'low-resistance' breakouts. A 40-day baseline for volume provides a more stable regime filter than the previously failed 20-day baseline, reducing noise in the denominator.\n                Concise Knowledge: If price acceleration (change in returns) is positive while volume turnover is stable, the trend is driven by institutional supply absorption; in quantitative equity, 'efficient' price moves (high price change per unit of volume) are more persistent than 'exhaustion' moves (high volume with stalling price).\n                concise Specification: The factor is defined as: (TS_DELTA($return, 5)) / (TS_MEAN($volume / $close, 10) / TS_MEAN($volume / $close, 40) + 1e-6). The numerator captures 5-day return acceleration, while the denominator captures the 10-day relative volume turnover intensity. The final output is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030212066706805,
        "ICIR": 0.0232092608321908,
        "RankIC": 0.0159233410322443,
        "RankICIR": 0.1242213933556221,
        "annualized_return": 0.0365031995359191,
        "information_ratio": 0.5346727284719999,
        "max_drawdown": -0.0953123150204958
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:32.015332",
      "updated_at": "2026-01-14T21:08:32.015339"
    },
    "813f4d08321676c8": {
      "factor_id": "813f4d08321676c8",
      "factor_name": "Breakout_Conviction_Index_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Breakout_Conviction_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a breakout by combining the direction of the 5-day price move with the relative volume intensity, normalized by the 20-day price volatility. It avoids raw high-low ranges to prevent outlier sensitivity, focusing instead on return-based volatility.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.674344",
      "updated_at": "2026-01-14T17:41:01.674351"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T17:39:41.148683"
    },
    "06b6f311ac141eab": {
      "factor_id": "06b6f311ac141eab",
      "factor_name": "ZScored_Volume_Persistence_Divergence",
      "factor_expression": "(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Persistence_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the momentum divergence hypothesis that uses cross-sectional Z-scores to compare 15-day volume-weighted conviction against the 5-day price trend, ensuring the divergence signal is comparable across the universe before being scaled by the asset's relative volatility.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.092745",
      "updated_at": "2026-01-14T17:36:23.092750"
    },
    "5d54c018fc9beb9d": {
      "factor_id": "5d54c018fc9beb9d",
      "factor_name": "Trend_Volume_Confirmation_ZScore",
      "factor_expression": "ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Volume_Confirmation_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the hypothesis focusing on the convergence of price stability and volume intensity. It uses Z-scores to ensure the components are on the same scale before combination.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.904259",
      "updated_at": "2026-01-14T17:27:11.904265"
    },
    "76ac3aa3a2819795": {
      "factor_id": "76ac3aa3a2819795",
      "factor_name": "VWPA10_Momentum_Acceleration_Factor",
      "factor_expression": "RANK(TS_DELTA($return, 5) / (TS_MEAN($volume / $close, 10) / (TS_MEAN($volume / $close, 40) + 1e-8) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($return, 5) / (TS_MEAN($volume / $close, 10) / (TS_MEAN($volume / $close, 40) + 1e-8) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VWPA10_Momentum_Acceleration_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction momentum by measuring 5-day price acceleration normalized by the relative volume turnover intensity. It targets 'low-resistance' breakouts where price increases are accelerating while volume remains stable relative to a 40-day baseline, avoiding exhaustion moves.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Price Acceleration (VWPA10) factor identifies high-conviction momentum by measuring the change in price per unit of volume turnover, specifically targeting stocks where price increases are accelerating while volume remains stable relative to a 40-day baseline.\n                Concise Observation: Previous attempts (PVDE5, VSAM) focused on volume volatility ratios but failed to capture alpha, likely because they ignored price acceleration and used simple returns which don't distinguish between steady trends and stalling ones.\n                Concise Justification: By using the second derivative of price (acceleration) and normalizing it by the volume-to-price-level ratio (turnover proxy), we isolate 'low-resistance' breakouts. A 40-day baseline for volume provides a more stable regime filter than the previously failed 20-day baseline, reducing noise in the denominator.\n                Concise Knowledge: If price acceleration (change in returns) is positive while volume turnover is stable, the trend is driven by institutional supply absorption; in quantitative equity, 'efficient' price moves (high price change per unit of volume) are more persistent than 'exhaustion' moves (high volume with stalling price).\n                concise Specification: The factor is defined as: (TS_DELTA($return, 5)) / (TS_MEAN($volume / $close, 10) / TS_MEAN($volume / $close, 40) + 1e-6). The numerator captures 5-day return acceleration, while the denominator captures the 10-day relative volume turnover intensity. The final output is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030212066706805,
        "ICIR": 0.0232092608321908,
        "RankIC": 0.0159233410322443,
        "RankICIR": 0.1242213933556221,
        "annualized_return": 0.0365031995359191,
        "information_ratio": 0.5346727284719999,
        "max_drawdown": -0.0953123150204958
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:31.996374",
      "updated_at": "2026-01-14T21:08:31.996381"
    },
    "824685211c1a9db6": {
      "factor_id": "824685211c1a9db6",
      "factor_name": "Ranked_Price_Impact_Ratio_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Price_Impact_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 5-day return relative to the total volume traded, applying a cross-sectional rank to identify stocks with the most extreme price-volume efficiency. This helps isolate stocks where the price has moved significantly on relatively low volume, indicating a lack of fundamental absorption.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.771471",
      "updated_at": "2026-01-14T17:25:41.771477"
    },
    "a3d913ea532ba19a": {
      "factor_id": "a3d913ea532ba19a",
      "factor_name": "Low_Friction_Trend_Factor_10D",
      "factor_expression": "TS_SUM($return, 10) * TS_STD($volume / ($close + 1e-8), 10) / (TS_STD($return, 10) + 1e-6)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($return, 10) * TS_STD($volume / ($close + 1e-8), 10) / (TS_STD($return, 10) + 1e-6)\" # Your output factor expression will be filled in here\n    name = \"Low_Friction_Trend_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of price movement by calculating the 10-day return per unit of 'Relative Volatility'. It uses the standard deviation of the volume-to-price ratio to capture regime stability, rewarding stocks that move significantly with stable volume-price interaction.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day Volatility-Adjusted Price-Volume Efficiency (VAPVE10) factor, which scales the 10-day price return by the ratio of 10-day price volatility to 10-day volume volatility, identifies high-conviction trends by isolating price movements that require minimal 'liquidity effort' relative to their volatility.\n                Concise Observation: Previous iterations (Hypothesis 5 & 6) showed that while volume stability (Mean/STD) reduces drawdown, it dilutes alpha when used as a simple multiplier because it doesn't account for the intrinsic price volatility (ATR/STD) of the asset.\n                Concise Justification: By comparing price volatility (TS_STD of returns) to volume volatility (TS_STD of volume), we create a 'Relative Volatility Efficiency' metric. A high return achieved with low volume volatility relative to price volatility suggests institutional conviction and a lack of retail-driven noise, addressing the 'signal-to-noise' issues seen in previous failures.\n                Concise Knowledge: If price returns are high while the ratio of price volatility to volume volatility is also high, it indicates a 'low-friction' regime where price moves efficiently without erratic volume spikes; in daily equity data, this 'quiet' efficiency is more predictive of trend persistence than high-volume breakouts which often signal exhaustion.\n                concise Specification: The factor is defined as: (TS_SUM($return, 10)) / ((TS_STD($return, 10) + 1e-6) / (TS_STD($volume / TS_MEAN($volume, 10), 10) + 1e-6)). The volume standard deviation is calculated on volume normalized by its 10-day mean to ensure scale-invariance across instruments. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0004467851129522,
        "ICIR": 0.0032835220956772,
        "RankIC": 0.0144502668176974,
        "RankICIR": 0.1098915545166409,
        "annualized_return": 0.0208351558182856,
        "information_ratio": 0.3093396996618583,
        "max_drawdown": -0.1555657185981356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:54:33.625854",
      "updated_at": "2026-01-14T20:54:33.625859"
    },
    "cc5ead208c103e71": {
      "factor_id": "cc5ead208c103e71",
      "factor_name": "Churn_Volatility_Adjusted_ER_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Churn_Volatility_Adjusted_ER_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'wasteful' price action by scaling the 5-day Efficiency Ratio by the negative sign of the recent price trend. It specifically looks for low-efficiency moves (churn) that occur during high-volatility periods, signaling that the current trend direction is losing its strength.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.698797",
      "updated_at": "2026-01-15T18:48:21.698803"
    },
    "fb42bc4cc1cea0c8": {
      "factor_id": "fb42bc4cc1cea0c8",
      "factor_name": "VWM_Normalized_CV_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWM_Normalized_CV_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 20-day price momentum (percentage change) and normalizes it by the volume coefficient of variation (CV) over the same period. The CV is the ratio of the standard deviation of volume to the mean volume. By dividing momentum by CV, the factor penalizes price trends accompanied by erratic or unstable volume, favoring steady, high-conviction accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.857108",
      "updated_at": "2026-01-14T20:26:55.857114"
    },
    "f101db011ea22576": {
      "factor_id": "f101db011ea22576",
      "factor_name": "Ranked_Squeeze_Momentum_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the volatility squeeze hypothesis. It measures the intensity of price tightness (inverse of the 5-day range normalized by 20-day volatility) and scales it by the sign of the recent 5-day trend to ensure directional alignment with the breakout.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.421657",
      "updated_at": "2026-01-14T17:23:48.421663"
    },
    "1d5804d105216831": {
      "factor_id": "1d5804d105216831",
      "factor_name": "Climax_Reversal_Signal_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Climax_Reversal_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion index targeting market climaxes. It combines the 10-day price residual with the 5-day average efficiency, but uses Z-scores to normalize the components before interaction, specifically highlighting cases where volume is significantly above its 20-day average.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.396389",
      "updated_at": "2026-01-14T20:37:56.396394"
    },
    "96f61e329e278ad9": {
      "factor_id": "96f61e329e278ad9",
      "factor_name": "Weighted_Trend_Conviction_Index",
      "factor_expression": "RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))\" # Your output factor expression will be filled in here\n    name = \"Weighted_Trend_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high recent trend stability that are also trading above their volume-weighted average price relative to their simple average. It uses a 20-day decay-weighted correlation to measure stability and a 5-day divergence ratio to measure conviction, combined via RANK to handle non-linearities.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.523328",
      "updated_at": "2026-01-14T18:02:27.523335"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T17:06:25.178740"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T17:06:25.147238"
    },
    "87e41321572b0d24": {
      "factor_id": "87e41321572b0d24",
      "factor_name": "Squeeze_Efficiency_Interaction_10D",
      "factor_expression": "TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Efficiency_Interaction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines the volatility squeeze concept with the direction of the 10-day price move. It uses the ratio of the 20-day standard deviation to the 5-day high-low range to identify periods of expansion potential, weighted by the 10-day return to filter for bullish momentum.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.455370",
      "updated_at": "2026-01-14T17:23:48.455376"
    },
    "c66ee9481bdf59cf": {
      "factor_id": "c66ee9481bdf59cf",
      "factor_name": "Robust_Squeeze_VWER_Interaction",
      "factor_expression": "RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VWER_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified interaction factor between a volatility compression metric and volume-weighted price efficiency. It uses a 10-day window for the squeeze and efficiency measures, applying a rank-based normalization to the squeeze intensity to ensure cross-sectional stability and combining it with a volume-scaled price velocity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.334867",
      "updated_at": "2026-01-14T17:35:59.334874"
    },
    "4ef43361520c1374": {
      "factor_id": "4ef43361520c1374",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by measuring the 'Price Impact' (5-day average high-low range divided by volume) normalized by the 20-day historical volatility. High values indicate price expansion on low volume relative to the stock's typical risk profile, suggesting a liquidity-driven spike prone to reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.121526",
      "updated_at": "2026-01-14T17:37:25.121533"
    },
    "d2bf005770af6309": {
      "factor_id": "d2bf005770af6309",
      "factor_name": "Efficiency_Adjusted_Money_Flow_Rank",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI($close * $volume, 5) / (TS_MEAN(RSI($close * $volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI($close * $volume, 5) / (TS_MEAN(RSI($close * $volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Money_Flow_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by multiplying the rank of the 10-day Efficiency Ratio with the rank of the 5-day MFI surge. It targets stocks that have moved significantly with minimal retracement (high ER) while experiencing a surge in money flow intensity relative to the last 3 days.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 6,
      "hypothesis": "Hypothesis: A factor that combines the 10-day price-volume Efficiency Ratio (ER10) with a 5-day Money Flow Index (MFI5) surge, using cross-sectional rank multiplication, will improve alpha capture and IC by identifying high-conviction, low-friction price movements.\n                Concise Observation: Previous iterations using 20-day stability (WRSQR20) optimized the Information Ratio (0.880) but suffered from a drop in IC and absolute return, suggesting the 20-day window is too lagging to pair effectively with the 5-day MFI signal.\n                Concise Justification: The Efficiency Ratio (ER) measures the 'cleanliness' of a trend by comparing net displacement to total volatility; when high ER is validated by an MFI surge (MFI relative to its 3-day average), it filters for stocks that are moving with low resistance and high institutional support, leading to higher predictive accuracy (IC).\n                Concise Knowledge: If a stock's price path is 'efficient' (minimal retracement relative to total movement) and accompanied by a positive surge in money flow, it indicates a high-conviction trend; in the context of daily price-volume data, shortening the stability window from 20 to 10 days reduces signal lag while maintaining structural integrity.\n                concise Specification: 1. Calculate ER10: Abs(Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Surge: MFI5 / SMA(MFI5, 3). 4. Apply cross-sectional Rank to ER10 and MFI_Surge. 5. Factor = Rank(ER10) * Rank(MFI_Surge).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061301747193448,
        "ICIR": 0.0454594371348165,
        "RankIC": 0.0225599092501203,
        "RankICIR": 0.1715580178527048,
        "annualized_return": 0.0620265606196682,
        "information_ratio": 0.956932954991831,
        "max_drawdown": -0.0799597137888558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:49:04.003390",
      "updated_at": "2026-01-14T18:49:04.003396"
    },
    "a6c613799bd857ca": {
      "factor_id": "a6c613799bd857ca",
      "factor_name": "Consistent_Liquidity_Momentum_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Consistent_Liquidity_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day price change normalized by the volume coefficient of variation. By using a 5-day window, it captures immediate liquidity regimes. The use of TS_ZSCORE on the volume ratio helps mitigate numerical instability from low volume variance before multiplying by the short-term return.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.464430",
      "updated_at": "2026-01-14T20:39:43.464436"
    },
    "7ea4a5dcdae76558": {
      "factor_id": "7ea4a5dcdae76558",
      "factor_name": "Conviction_Lead_Lag_Corr_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Lead_Lag_Corr_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 10-day rolling correlation between current returns and a conviction signal. The conviction signal is defined as the 3-day lagged return scaled by the ratio of current volume to its 10-day moving average, highlighting price moves backed by relative liquidity.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day rolling correlation between current returns and a 3-day lagged, volume-scaled return signal captures high-conviction price discovery trends more effectively than longer-lag models.\n                Concise Observation: The previous 5-day lag and 20-day window were too slow to capture decaying lead-lag effects; shortening the lag to 3 days and using a volume ratio instead of a Z-score improved the Information Ratio and signal responsiveness.\n                Concise Justification: Shorter lags capture more immediate information diffusion, while scaling lagged returns by the volume ratio (current volume / mean volume) emphasizes price moves that occurred with high relative conviction, filtering out noise from low-liquidity sessions.\n                Concise Knowledge: If the lag period is reduced to 3 days and the lagged signal is scaled by the ratio of volume to its 10-day moving average, then the resulting correlation identifies short-term momentum backed by liquidity, which is more predictive of immediate price persistence.\n                concise Specification: Calculate the factor as the 10-day Pearson correlation between the daily return ($return) and a 'Conviction Signal', where the Conviction Signal is the 3-day lagged return multiplied by ($volume / TS_MEAN($volume, 10)).\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064292131116171,
        "ICIR": 0.0471904782508434,
        "RankIC": 0.022961676702149,
        "RankICIR": 0.1745311944608633,
        "annualized_return": 0.0713249472038566,
        "information_ratio": 1.1379839206679387,
        "max_drawdown": -0.0918045186564081
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:54:09.604270",
      "updated_at": "2026-01-15T18:54:09.604278"
    },
    "c2ef165146f514d0": {
      "factor_id": "c2ef165146f514d0",
      "factor_name": "Exhaustive_Spike_Rank_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))\" # Your output factor expression will be filled in here\n    name = \"Exhaustive_Spike_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price 'noise' relative to its trend. It combines the 10-day price residual with a smoothed efficiency ratio. By using RANK, it focuses on the relative extremity of the exhaustive price action compared to the rest of the market universe.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.680649",
      "updated_at": "2026-01-14T20:32:25.680655"
    },
    "21b119adc7849b19": {
      "factor_id": "21b119adc7849b19",
      "factor_name": "Relative_Volume_Efficiency_Rank_5D",
      "factor_expression": "ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion by comparing the magnitude of price change to the relative volume surge. It uses the ratio of 5-day absolute returns to the 5-day average volume, scaled by the 20-day volume average to normalize for stock-specific liquidity levels.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.715331",
      "updated_at": "2026-01-14T17:34:27.715337"
    },
    "edc1843ea9fd697f": {
      "factor_id": "edc1843ea9fd697f",
      "factor_name": "Ranked_Resistance_Volume_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * RANK(TS_MEAN($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * RANK(TS_MEAN($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Resistance_Volume_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the resistance efficiency hypothesis that uses cross-sectional ranking. It interacts the rank of 'Resistance Distance' (distance from 10-day high normalized by path length) with the rank of volume intensity. High values target stocks with high effort (volume) but low results (failure to close near the 10-day high).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.068913",
      "updated_at": "2026-01-14T21:02:22.068919"
    },
    "56648b1aee6f7d28": {
      "factor_id": "56648b1aee6f7d28",
      "factor_name": "Efficiency_Decay_Residual_Interaction_15D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Decay_Residual_Interaction_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the interaction between price over-extension and the decay in price movement quality. It uses the 10-day price residual and the 5-day change in a smoothed efficiency ratio (body size relative to high-low range), focusing on the negative momentum of efficiency as a signal for trend failure.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.978971",
      "updated_at": "2026-01-14T20:45:46.978977"
    },
    "89ab97f85fe9e5e0": {
      "factor_id": "89ab97f85fe9e5e0",
      "factor_name": "PVDE5_Efficiency_Factor",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVDE5_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline. This captures 'low-friction' price discovery where institutional absorption occurs with minimal market impact.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.296769",
      "updated_at": "2026-01-14T20:59:06.296777"
    },
    "4e50237f8538ced2": {
      "factor_id": "4e50237f8538ced2",
      "factor_name": "Laggard_Sensitivity_Leader_Conviction",
      "factor_expression": "(RANK($volume) < 0.5 && RANK(TS_STD($return, 10)) < 0.25) ? MEAN(TS_ZSCORE(TS_PCTCHANGE($close, 3), 10) * (TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "",
      "factor_description": "Calculates the conviction-weighted momentum of the top quintile of stocks by volume and projects it onto stocks with low idiosyncratic volatility and low volume. The volume shock is capped to prevent outliers from dominating the signal.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.112593",
      "updated_at": "2026-01-15T17:47:09.112598"
    },
    "6b09649c0a1463db": {
      "factor_id": "6b09649c0a1463db",
      "factor_name": "Decay_Stability_Accumulation_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decay_Stability_Accumulation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the stability-momentum hypothesis. It uses the 20-day weighted R-squared (via DECAYLINEAR) to capture 'fresh' trend stability and scales it by the 5-day VWAP-to-SMA ratio to identify volume-supported price levels. Both components are cross-sectionally standardized using ZSCORE to ensure equal contribution.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.485711",
      "updated_at": "2026-01-14T18:02:27.485718"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T17:36:23.056545"
    },
    "6ebedce912a42e84": {
      "factor_id": "6ebedce912a42e84",
      "factor_name": "Net_Conviction_VWAP_Filter",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Net_Conviction_VWAP_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 'net conviction' score by subtracting 10-day volatility from volume-weighted momentum. It then applies a non-linear filter based on the distance from the 20-day VWAP (proxied by TS_SUM of price-volume) to identify stocks with strong support.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 9,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Divergence from Volatility', where alpha is maximized by the difference between 10-day volume-weighted return persistence and 10-day price volatility, filtered by the asset's position relative to its 20-day VWAP.\n                Concise Observation: Previous attempts using multiplicative interactions or simple rank-subtractions failed because they either amplified noise or over-smoothed the signal; however, the SOTA (Hypothesis 3) and high-IC versions (Hypothesis 6/7) consistently utilized VWAP as a 'location' filter and volume-ranked returns for conviction.\n                Concise Justification: By subtracting the 10-day volatility (standard deviation) from the 10-day volume-weighted return persistence, we create a 'net conviction' score. Filtering this by the 20-day VWAP ensures we avoid 'overheated' stocks where price has already moved too far from the average cost basis, addressing the 'late-stage trend' failure of Hypothesis 8.\n                Concise Knowledge: In quant equity, if an asset's volume-weighted momentum significantly exceeds its realized volatility (high return-to-risk persistence), it indicates institutional accumulation; when this occurs while the price is near or below the 20-day VWAP, it identifies a low-risk entry point for trend continuation rather than an exhausted spike.\n                concise Specification: The factor 'VW_Momentum_Vol_Divergence' is defined as: (ts_mean($return * rank($volume), 10) - ts_std($return, 10)) * ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041107781040163,
        "ICIR": 0.0266018454123839,
        "RankIC": 0.0186597296899252,
        "RankICIR": 0.1218079143956096,
        "annualized_return": 0.0312271284971009,
        "information_ratio": 0.3824112733783517,
        "max_drawdown": -0.172297884389554
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:06:51.101247",
      "updated_at": "2026-01-14T18:06:51.101253"
    },
    "3656e978261fcb3a": {
      "factor_id": "3656e978261fcb3a",
      "factor_name": "Trend_Exhaustion_Index_V1",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Index_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion signals by multiplying the 10-day price residual (deviation from trend) with a 5-day smoothed price efficiency ratio and a 20-day relative volume. High values indicate a 'blow-off' climax where price over-extension is met with high volume and weakening conviction.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.380256",
      "updated_at": "2026-01-14T20:37:56.380262"
    },
    "074aeb1bdfd6f8e3": {
      "factor_id": "074aeb1bdfd6f8e3",
      "factor_name": "Climax_Reversal_Volume_Momentum_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close, 10) + 1e-8)) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close, 10) + 1e-8)) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Climax_Reversal_Volume_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction price reversals by combining the 10-day price drawdown (normalized by its 10-day standard deviation) with a 5-day volume momentum filter. It targets 'selling climax' events where sharp price declines are met with increasing volume participation, suggesting a potential trend exhaustion and subsequent bounce.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day price reversal is most potent when a significant price drawdown is accompanied by positive volume momentum, where the signal is enhanced by cross-sectionally ranking the return relative to its volatility to isolate high-conviction climax events.\n                Concise Observation: Previous iterations using 10-day price-volume correlation (1-CORR) successfully reduced drawdown but diluted the IC (0.0063 down to lower levels), suggesting that the 'state' of correlation is too slow compared to the 'momentum' of volume during a capitulation event.\n                Concise Justification: Market microstructure suggests that the most profitable reversals occur after a 'blow-off' or 'selling climax,' characterized by price and volume moving aggressively in the same direction (positive volume momentum) before a snap-back. Cross-sectional ranking of the return ensures that we target assets with the most extreme 'stretch' relative to the market, improving the signal-to-noise ratio.\n                Concise Knowledge: If a short-term price trend accelerates while volume momentum is positive, it indicates a 'climax' phase; when the 10-day return is cross-sectionally ranked and multiplied by volume momentum, the resulting factor identifies high-conviction turning points more effectively than linear correlation-based filters.\n                concise Specification: The factor is defined as: CS_Rank(-1 * 10-day return / 10-day price standard deviation) * CS_Rank(5-day volume momentum). Volume momentum is defined as the ratio of the 5-day average volume to the 20-day average volume. All variables are sourced from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0021517511318312,
        "ICIR": 0.0152943302107834,
        "RankIC": 0.0164866647542131,
        "RankICIR": 0.1207719729597577,
        "annualized_return": 0.0469881451941539,
        "information_ratio": 0.6718395658582001,
        "max_drawdown": -0.1029565810443816
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:42:22.746761",
      "updated_at": "2026-01-14T17:42:22.746768"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T16:57:26.431941"
    },
    "28c761af988bbc9d": {
      "factor_id": "28c761af988bbc9d",
      "factor_name": "Resistance_Volume_Divergence_20D",
      "factor_expression": "RANK((TS_MAX($high, 20) - $close) / (TS_STD($close, 20) + 1e-8) + RANK($volume / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - $close) / (TS_STD($close, 20) + 1e-8) + RANK($volume / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Resistance_Volume_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by interacting the price distance from the 20-day high with the cross-sectional rank of recent 5-day volume surges. It targets stocks where extreme turnover fails to overcome structural peaks, signaling exhaustion. The distance is normalized by the 20-day standard deviation to account for volatility.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 9,
      "hypothesis": "Hypothesis: A 20-day 'Resistance-Volume Divergence' factor identifies mean-reversion by interacting the 20-day price distance from resistance with the cross-sectional rank of 5-day volume surges, specifically targeting stocks where short-term extreme turnover fails to overcome monthly structural peaks.\n                Concise Observation: Previous successes (IR 1.15) used a 10-day window for both resistance and volume, but the most recent attempt at decay-weighting (Hypothesis 8) improved the IC (0.0052) while losing IR, suggesting that while recent volatility is important, the resistance level itself needs a more stable (longer) lookback to filter out noise.\n                Concise Justification: Using a 20-day window for the 'Distance to High' provides a more robust structural resistance level, while a 5-day volume surge captures the immediate 'blow-off' intensity. Combining these via cross-sectional ranks instead of raw Z-scores or complex decay functions prevents outlier distortion and focuses on idiosyncratic exhaustion.\n                Concise Knowledge: If a short-term volume surge (5-day) fails to push the price toward a medium-term resistance (20-day high), the liquidity is being absorbed by sellers; When high-intensity turnover occurs at a significant price distance from recent peaks, it indicates 'churning' rather than a breakout.\n                concise Specification: The factor calculates the 20-day Distance from High (ts_max(high, 20) - close) / ts_std(close, 20). This is then added to the cross-sectional rank of the 5-day volume surge (volume / ts_mean(volume, 20)). The final output is the cross-sectional rank of this sum to predict positive future returns (as high distance + high volume surge = high exhaustion/reversion potential).\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050588825246269,
        "ICIR": 0.0367420663658229,
        "RankIC": 0.0217995635837097,
        "RankICIR": 0.1656796713947607,
        "annualized_return": 0.0795477822592887,
        "information_ratio": 1.2282168943232237,
        "max_drawdown": -0.0916984352237093
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:11:14.800679",
      "updated_at": "2026-01-14T21:11:14.800686"
    },
    "7e9ddacd0e80dc3f": {
      "factor_id": "7e9ddacd0e80dc3f",
      "factor_name": "Liquidity_Adjusted_Momentum_Z",
      "factor_expression": "TS_ZSCORE($close / (($high + $low + $close) / 3 + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - (($high + $low + $close) / 3)) / (TS_STD($return, 20) + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Momentum_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price moves by calculating the Z-score of the ratio between price-VWAP deviation and historical volatility, multiplied by the rank of short-term volume growth to filter for institutional accumulation.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.357753",
      "updated_at": "2026-01-14T17:29:39.357759"
    },
    "d39bc944ba333c67": {
      "factor_id": "d39bc944ba333c67",
      "factor_name": "NonLinear_Churn_Exhaustion_Index",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Churn_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'churning' phase of a trend where high volume fails to produce proportional price progress. It combines the 10-day price residual with the 5-day average of volume-adjusted price efficiency. By ranking both components, it highlights assets that are at extreme price deviations but showing the lowest relative efficiency in the cross-section, maximizing the probability of mean-reversion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.647215",
      "updated_at": "2026-01-14T20:55:45.647220"
    },
    "afb58b5af7742904": {
      "factor_id": "afb58b5af7742904",
      "factor_name": "VWIM_Rank_Decay_5D",
      "factor_expression": "DECAYLINEAR(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DECAYLINEAR(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"VWIM_Rank_Decay_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the VWIM factor that applies a 5-day linear decay (DECAYLINEAR) to the volume-weighted intraday return. This reduces the impact of outliers and focuses on the persistence of volume-backed price action over a one-week horizon.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Volume-Weighted Intraday Momentum (VWIM) factor, calculated as the open-to-close return scaled by relative volume and smoothed with a short-term Exponential Moving Average (EMA), provides a higher signal-to-noise ratio for predicting short-term returns than simple intraday gaps.\n                Concise Observation: Previous results showed that while intraday momentum is predictive (IR 0.9577), simple moving averages (5D/20D) likely lag the signal's decay, and unweighted returns fail to distinguish between high-conviction institutional flows and low-volume retail noise.\n                Concise Justification: Volume serves as a validation metric for price action; scaling the intraday return by the ratio of current volume to its historical average filters for 'informed' trading, while the EMA prioritizes recent data points to mitigate the signal-lag inherent in standard rolling means.\n                Concise Knowledge: If intraday price trends are supported by high relative volume, they indicate higher institutional conviction; when these signals are processed using decay-weighted averages (EMA) over short horizons (e.g., 3 days), they better capture the transient nature of alpha before market efficiency absorbs the trend.\n                concise Specification: The factor is defined as (Close/Open - 1) * (Volume / SMA(Volume, 10)), then smoothed using a 3-day Exponential Moving Average (EMA) to generate a final predictive value for each instrument.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058479468228565,
        "ICIR": 0.0376867169187617,
        "RankIC": 0.0224571044860769,
        "RankICIR": 0.1444330405368809,
        "annualized_return": 0.0707034454329422,
        "information_ratio": 0.9352636238015638,
        "max_drawdown": -0.1053260582417709
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:40:20.920479",
      "updated_at": "2026-01-15T17:40:20.920489"
    },
    "beda22fd003445b3": {
      "factor_id": "beda22fd003445b3",
      "factor_name": "Climax_Gated_Reversal_Factor",
      "factor_expression": "(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Climax_Gated_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets high-conviction selling climaxes. It uses the 10-day price-volume correlation as a state filter (negated to favor divergence) and multiplies it by a volatility-adjusted 10-day return. It incorporates a Volume Surge component (Volume relative to its 20-day mean) to ensure the reversal is backed by significant liquidity exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.876983",
      "updated_at": "2026-01-14T17:48:31.876989"
    },
    "c9317ae43f557284": {
      "factor_id": "c9317ae43f557284",
      "factor_name": "Momentum_Quality_Divergence_Index_20D",
      "factor_expression": "RANK($close / TS_MEAN($close, 20) - 1) * RANK(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / TS_MEAN($close, 20) - 1) * RANK(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Quality_Divergence_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the breakdown in price progress per unit of volatility during 20-day price over-extensions. It multiplies the rank of price deviation from its 20-day mean by the rank of the negative 5-day price quality (mean return divided by standard deviation of returns).",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 'Momentum-Quality Divergence Index' identifies trend reversals by detecting the breakdown in price progress per unit of volatility (Sharpe-like efficiency) during 20-day price over-extensions.\n                Concise Observation: Previous attempts using 'Volume Efficiency' (Range/Volume) were too noisy and sensitive to outliers, while the most successful iteration (Hypothesis 3, IR 1.13) relied on price efficiency (KMID); however, KMID ignores the volatility-adjusted stability of the trend progress.\n                Concise Justification: A sustainable trend requires price to move with consistent, low-volatility progress. By measuring the 'Price Quality' as the 5-day average return divided by the 5-day standard deviation of returns, we isolate periods where price movement becomes erratic or 'noisy' at the peak of a 20-day extension. This divergence indicates that the trend is no longer supported by steady institutional accumulation but by volatile retail speculation.\n                Concise Knowledge: In this quant scenario, if a stock's price deviates significantly from its 20-day mean while its risk-adjusted price progress (mean return divided by volatility) over the last 5 days collapses, the trend is likely entering an unstable, speculative phase; when price extension grows but 'quality' (return/std) decays, the probability of a sharp mean-reversion increases.\n                concise Specification: The factor is defined as the product of: 1. The Rank of the 20-day price deviation (Close / TS_MEAN(Close, 20) - 1), and 2. The Rank of the negative 5-day 'Price Quality' (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)). The 20-day window captures medium-term over-extension, while the 5-day window captures the immediate decay in trend quality. Both components are cross-sectionally ranked before multiplication.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050482736677071,
        "ICIR": 0.0376898899710857,
        "RankIC": 0.0197474945716331,
        "RankICIR": 0.1546038489613508,
        "annualized_return": 0.0714561174132213,
        "information_ratio": 1.0586574991150286,
        "max_drawdown": -0.133435429109272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:13:24.402247",
      "updated_at": "2026-01-14T21:13:24.402254"
    },
    "8ea1bf1386c5b50e": {
      "factor_id": "8ea1bf1386c5b50e",
      "factor_name": "VWAP_Efficiency_Accel_20D",
      "factor_expression": "TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Efficiency_Accel_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the interaction between price-volume efficiency and the acceleration of liquidity-adjusted momentum. It measures the deviation of the close price from the VWAP (approximated by (high+low+close)/3), normalized by 20-day return volatility, and scales it by the 5-day change in volume-weighted price momentum.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.322550",
      "updated_at": "2026-01-14T17:29:39.322557"
    },
    "5986d9d2092eb2ce": {
      "factor_id": "5986d9d2092eb2ce",
      "factor_name": "Laggard_Delayed_Response_10D",
      "factor_expression": "DELAY(MEAN(FILTER(TS_SUM($return, 10), RANK($volume) > 0.9)), 5) * RANK(INV($volume))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(DELAY($return, 5), RANK(DELAY($volume, 5)) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Laggard_Delayed_Response_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'laggard' stocks (bottom 50% by volume) and calculates their sensitivity to the previous period's market leader returns. It assumes that if the top 10% most liquid stocks had high returns 5 days ago, laggards will catch up today.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.829835",
      "updated_at": "2026-01-15T17:38:45.829841"
    },
    "530b4b81842c1774": {
      "factor_id": "530b4b81842c1774",
      "factor_name": "Divergent_ZScore_Reversal_10D",
      "factor_expression": "TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_ZScore_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by measuring the statistical extremity of the price move (Z-score) and weighting it by a 'Divergence Index'. The Divergence Index is calculated as (1 - TS_CORR), which amplifies the signal when price and volume move in opposite directions, indicating trend fragility. The price move is calculated as the negative 10-day return to capture mean-reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.840434",
      "updated_at": "2026-01-14T17:48:31.840441"
    },
    "fc79ccb2d5cb3a49": {
      "factor_id": "fc79ccb2d5cb3a49",
      "factor_name": "Volume_Weighted_Range_Convexity_10D",
      "factor_expression": "RANK(TS_SUM((ABS($return) * $volume) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(($volume * ABS($return)) / (TS_STD($close, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Range_Convexity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the hypothesis that high intraday volatility relative to net price change, when confirmed by high volume, indicates exhaustion. It calculates the 10-day sum of volume-weighted return-to-range ratios, cross-sectionally ranked for robustness.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.772489",
      "updated_at": "2026-01-15T18:44:45.772495"
    },
    "8fe21fdb459ddca8": {
      "factor_id": "8fe21fdb459ddca8",
      "factor_name": "Volume_Weighted_Leader_Signal",
      "factor_expression": "ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Leader_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis that weights the 10-day momentum of the entire cross-section by volume rank to emphasize leader behavior, then applies this signal specifically to lower-volume assets.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.848571",
      "updated_at": "2026-01-15T17:38:45.848577"
    },
    "02cbecb3e4566b4d": {
      "factor_id": "02cbecb3e4566b4d",
      "factor_name": "Relative_Compression_Ranked_Momentum_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Ranked_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies volatility squeezes by calculating the ratio of the 20-day price range to the 5-day price range, using this to weight a cross-sectionally ranked 5-day momentum signal. To isolate high-conviction breakouts and avoid crowded trades, it is neutralized by the 20-day average volume, targeting quiet consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.232562",
      "updated_at": "2026-01-14T17:54:15.232569"
    },
    "a6bae1dc4dfa3dda": {
      "factor_id": "a6bae1dc4dfa3dda",
      "factor_name": "Price_Volume_Efficiency_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Efficiency_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of the 5-day cumulative return to the 5-day cumulative volume turnover. A high ratio indicates a 'fragile' price move on low volume support, suggesting a higher probability of mean reversion. The ratio is cross-sectionally standardized using Z-score to identify extremes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.702263",
      "updated_at": "2026-01-14T17:25:41.702270"
    },
    "899eb901a112f8b8": {
      "factor_id": "899eb901a112f8b8",
      "factor_name": "Log_Efficiency_Volume_Momentum",
      "factor_expression": "TS_MEAN($return * RANK($volume), 10) * LOG($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 10) * LOG($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Log_Efficiency_Volume_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a logarithmic transformation of the price-to-VWAP ratio to dampen the impact of price spikes, combined with the 10-day volume-ranked momentum. It aims to capture institutional accumulation trends with a more symmetric distribution.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 7,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Efficiency Gap', where alpha is maximized by the interaction between the 10-day volume-ranked momentum and the price's deviation from its 20-day volume-weighted average price, normalized by the 20-day rolling price range.\n                Concise Observation: Previous iterations (Hypothesis 6) achieved a high IC (0.0038) by using volume-weighted returns and VWAP filters, but failed on IR/Returns due to the 'convexity' (10d-20d) term being too noisy and the 5-day VWAP being too reactive.\n                Concise Justification: A 20-day VWAP provides a more stable institutional cost-basis anchor than a 5-day window. By replacing the 'acceleration' subtraction with a direct persistence measure and normalizing by a robust volatility proxy (High-Low range), we aim to retain the high IC while improving the signal-to-noise ratio for better risk-adjusted returns.\n                Concise Knowledge: If volume-weighted momentum is high while the price remains close to or slightly above its 20-day VWAP, the asset is in an efficient accumulation phase; when this signal is scaled by the high-low range, it accounts for asset-specific volatility without the instability of standard deviation.\n                concise Specification: The factor 'VW_Efficiency_Gap_20D' is calculated as the 10-day rolling mean of ($return * rank($volume)) multiplied by the ratio ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))), all divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00310286363765,
        "ICIR": 0.0239724348684757,
        "RankIC": 0.0184843273960079,
        "RankICIR": 0.1457955762559876,
        "annualized_return": 0.0261503792401489,
        "information_ratio": 0.43320028836764,
        "max_drawdown": -0.0934994899682903
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:50:57.559059",
      "updated_at": "2026-01-14T17:50:57.559065"
    }
  }
}