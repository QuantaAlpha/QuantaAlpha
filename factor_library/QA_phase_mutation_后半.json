{
  "metadata": {
    "created_at": "2026-01-17T12:00:22.263368",
    "last_updated": "2026-01-17T12:00:22.263374",
    "total_factors": 93,
    "version": "1.0",
    "source": "all_factors_library_10_10_10_best1_组合123_QA.json",
    "note": "evolution_phase为mutation的后半部分因子，保持原始顺序"
  },
  "factors": {
    "e6aa23f628500dca": {
      "factor_id": "e6aa23f628500dca",
      "factor_name": "Extreme_Price_Liquidity_Trap",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Extreme_Price_Liquidity_Trap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies liquidity traps by detecting daily price extremes (high or low) that occur on significantly lower volume than the recent average. It uses the inverse of volume intensity to signal that the trend is unsustainable.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.968980",
      "updated_at": "2026-01-17T03:57:08.968986"
    },
    "95b87a37f6256346": {
      "factor_id": "95b87a37f6256346",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price-volume divergence by calculating the ratio of the 5-day price change to the 5-day average volume-weighted price velocity. A high ratio indicates that price is moving significantly on relatively low volume intensity, suggesting a liquidity vacuum prone to mean-reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.518658",
      "updated_at": "2026-01-17T03:57:26.518666"
    },
    "a1ce18ab8bc5af65": {
      "factor_id": "a1ce18ab8bc5af65",
      "factor_name": "Thin_Market_Reversal_Signal",
      "factor_expression": "RANK(ABS($return)) * (1.0 - TS_RANK($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($close / DELAY($close, 1) - 1)) * (1.0 - TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Thin_Market_Reversal_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures mean-reversion opportunities by identifying days with high return magnitude but significantly low relative volume. It uses the ratio of absolute return to the 20-day volume rank to highlight 'thin' price moves.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.541106",
      "updated_at": "2026-01-17T03:57:26.541113"
    },
    "e67723e910000cb7": {
      "factor_id": "e67723e910000cb7",
      "factor_name": "Price_Volume_Fragility_Index",
      "factor_expression": "(DELTA($close, 5) / ($close + 1e-8)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / DELAY($close, 5)) / (TS_MEAN($volume, 5) / TS_MEAN($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Fragility_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the fragility of the current price trend by comparing the 5-day price momentum against the volume-weighted participation. It identifies exhaustion when price momentum is high but volume-weighted intensity is declining relative to its 20-day average.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.563108",
      "updated_at": "2026-01-17T03:57:26.563114"
    },
    "ca9b0af6a43479c3": {
      "factor_id": "ca9b0af6a43479c3",
      "factor_name": "Gap_Diffusion_Lag_Factor_5D",
      "factor_expression": "TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Gap_Diffusion_Lag_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Lag' by measuring the interaction between the average overnight gap and volume volatility. It identifies stocks where price discovery is delayed, specifically when the intraday return is lower than the overnight impulse, suggesting a potential catch-up effect in high-volatility regimes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.742894",
      "updated_at": "2026-01-17T03:58:17.742900"
    },
    "bb952250c0b75dda": {
      "factor_id": "bb952250c0b75dda",
      "factor_name": "Frictional_Price_Discovery_Rank",
      "factor_expression": "RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD(($close / DELAY($close, 1) - 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Frictional_Price_Discovery_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on the cross-sectional lag by identifying stocks with high idiosyncratic volatility relative to their overnight gap. It uses the ratio of intraday range to the overnight gap, scaled by volume stability, to predict short-term momentum laggards.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.766747",
      "updated_at": "2026-01-17T03:58:17.766753"
    },
    "13a64ce6d82bff1b": {
      "factor_id": "13a64ce6d82bff1b",
      "factor_name": "Institutional_Gap_Laggard_Signal",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Laggard_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the discrepancy between overnight institutional positioning (gap) and retail-driven intraday volatility. It targets stocks where the overnight gap is significant but the intraday movement is muted, suggesting a delayed reaction to market-wide information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.787462",
      "updated_at": "2026-01-17T03:58:17.787468"
    },
    "d31b51f2cd614148": {
      "factor_id": "d31b51f2cd614148",
      "factor_name": "Volume_Vol_Overnight_Gap_Reversion_5D",
      "factor_expression": "-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))\" # Your output factor expression will be filled in here\n    name = \"Volume_Vol_Overnight_Gap_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the mean-reversion effect of overnight price gaps when accompanied by high volume volatility at the previous day's close. High volume volatility suggests dealer inventory stress, making the opening gap likely to revert. The factor is negated to align with a long-short prediction of the reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.080482",
      "updated_at": "2026-01-17T03:59:50.080490"
    },
    "eb89102aa260b117": {
      "factor_id": "eb89102aa260b117",
      "factor_name": "Liquidity_Stress_Gap_Reversal_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Stress_Gap_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity-driven reversion factor that uses the Z-score of volume volatility to identify extreme inventory imbalances. It focuses on the interaction between standardized volume dispersion and the overnight return, predicting that extreme imbalances lead to gap dissipation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.102507",
      "updated_at": "2026-01-17T03:59:50.102513"
    },
    "ccda060b09b8cfce": {
      "factor_id": "ccda060b09b8cfce",
      "factor_name": "Relative_Volume_Dispersion_Gap_Factor",
      "factor_expression": "-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Dispersion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between the overnight gap and the relative intensity of volume volatility. By using TS_RANK of volume volatility, it identifies periods where liquidity-driven distortions are historically high for the specific asset, signaling a higher probability of opening gap mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.123301",
      "updated_at": "2026-01-17T03:59:50.123307"
    },
    "667c8534e6e3442b": {
      "factor_id": "667c8534e6e3442b",
      "factor_name": "Informed_Liquidity_Accumulation_10D",
      "factor_expression": "TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Liquidity_Accumulation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend breakouts by detecting periods of high volume density within narrow price ranges. It calculates the 10-day average of the ratio between volume and the high-low range, scaled by the inverse of price volatility to isolate 'quiet' institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.815968",
      "updated_at": "2026-01-17T04:00:06.815975"
    },
    "2aba12657a8d146a": {
      "factor_id": "2aba12657a8d146a",
      "factor_name": "Volume_Density_Compression_ZScore_10D",
      "factor_expression": "TS_ZSCORE($volume / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Density_Compression_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of volume relative to price movement, standardized against its 10-day history. A high value suggests that volume is clustering within a tight price range, indicating institutional absorption before a volatility expansion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.837299",
      "updated_at": "2026-01-17T04:00:06.837305"
    },
    "9ff730c073fc8d6a": {
      "factor_id": "9ff730c073fc8d6a",
      "factor_name": "Accumulation_Coil_Factor_15D",
      "factor_expression": "RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Coil_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies a 'coiled' market state where price dispersion is at a minimum relative to volume intensity. It uses the ratio of the 15-day average volume to the 15-day price range, cross-sectionally ranked to find the most compressed instruments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.858139",
      "updated_at": "2026-01-17T04:00:06.858145"
    },
    "2eb4cc9253e7aff3": {
      "factor_id": "2eb4cc9253e7aff3",
      "factor_name": "Liquidity_Exhaustion_Reversal_10D",
      "factor_expression": "TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in volume. It calculates the difference between the time-series Z-score of the intraday range and the time-series Z-score of volume over a 10-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.759885",
      "updated_at": "2026-01-17T04:01:01.759892"
    },
    "10a3628cfd4ea100": {
      "factor_id": "10a3628cfd4ea100",
      "factor_name": "Cross_Sectional_Liquidity_Vacuum_20D",
      "factor_expression": "RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Vacuum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the relative liquidity exhaustion across the market. It ranks the ratio of a smoothed price range to smoothed volume, highlighting stocks where price volatility is disproportionately high compared to trading activity, adjusted for a 20-day lookback.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.781726",
      "updated_at": "2026-01-17T04:01:01.781732"
    },
    "cd30d6c8ccbc13e8": {
      "factor_id": "cd30d6c8ccbc13e8",
      "factor_name": "Range_Volume_Divergence_ZScore_5D",
      "factor_expression": "ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))\" # Your output factor expression will be filled in here\n    name = \"Range_Volume_Divergence_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on short-term liquidity gaps by measuring the divergence between price range and volume growth. It uses a 5-day window to capture rapid 'overshooting' events where the range expands while volume stays low or decreases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.802827",
      "updated_at": "2026-01-17T04:01:01.802833"
    },
    "ee5011636f3af683": {
      "factor_id": "ee5011636f3af683",
      "factor_name": "Stealth_Liquidity_Absorption_20D",
      "factor_expression": "($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Liquidity_Absorption_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of trading volume to the squared intraday price range. A high ratio indicates high turnover within a narrow price band, suggesting 'stealth' liquidity absorption. The value is normalized by its 20-day moving average to identify abnormal accumulation phases.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.920019",
      "updated_at": "2026-01-17T04:02:51.920027"
    },
    "f31a3d208db11e89": {
      "factor_id": "f31a3d208db11e89",
      "factor_name": "Relative_Volume_Density_Rank_10D",
      "factor_expression": "RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Density_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of volume density (volume per unit of price range) relative to its recent time-series distribution. It targets stocks where the current volume-to-range ratio is at a historical peak, signaling potential exhaustion of sellers and a forthcoming breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.950367",
      "updated_at": "2026-01-17T04:02:51.950373"
    },
    "64b2836e01ce5097": {
      "factor_id": "64b2836e01ce5097",
      "factor_name": "ZScore_Accumulation_Density_15D",
      "factor_expression": "TS_ZSCORE($volume / (ABS($high - $low) + 1e-8), 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 15)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Accumulation_Density_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the time-series Z-score of the volume-to-range ratio over a 15-day window. By using Z-score, it identifies statistically significant 'quiet' accumulation periods where volume density exceeds the normal distribution of the specific instrument's trading activity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.971394",
      "updated_at": "2026-01-17T04:02:51.971400"
    },
    "3030871e1ca545c4": {
      "factor_id": "3030871e1ca545c4",
      "factor_name": "IIA_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies Institutional Inventory Absorption (IIA) by calculating the ratio of the 20-day average volume to the 20-day price volatility. High values indicate 'Quiet Accumulation' where high volume is absorbed with minimal price movement, signaling a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.319517",
      "updated_at": "2026-01-17T04:03:00.319524"
    },
    "d17fc8759133d362": {
      "factor_id": "d17fc8759133d362",
      "factor_name": "IIA_Rank_Tightness_20D",
      "factor_expression": "RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))\" # Your output factor expression will be filled in here\n    name = \"IIA_Rank_Tightness_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiled spring' effect by cross-sectionally ranking volume and price stability. It identifies stocks in the top decile of volume and bottom decile of volatility by subtracting the volatility rank from the volume rank.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.341262",
      "updated_at": "2026-01-17T04:03:00.341269"
    },
    "b1e96ffb77a4c8bb": {
      "factor_id": "b1e96ffb77a4c8bb",
      "factor_name": "IIA_Relative_Efficiency_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Relative_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of volume in moving prices. It uses the inverse of the 20-day price range normalized by volume. A high value suggests that large volumes are being traded within a very narrow price range, indicating institutional absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.363832",
      "updated_at": "2026-01-17T04:03:00.363839"
    },
    "c092235ba2e172e2": {
      "factor_id": "c092235ba2e172e2",
      "factor_name": "Overnight_Intraday_Asymmetry_Ratio",
      "factor_expression": "RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Intraday_Asymmetry_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the ratio of the overnight gap return to the intraday price range, weighted by the current volume relative to its 5-day average. High values indicate a significant overnight gap followed by low-volatility intraday consolidation, suggesting institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.785370",
      "updated_at": "2026-01-17T04:05:47.785376"
    },
    "b829d8b82d07f289": {
      "factor_id": "b829d8b82d07f289",
      "factor_name": "Gap_Consolidation_Efficiency_5D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)) / (($high - $low) + 0.0001), 5)\" # Your output factor expression will be filled in here\n    name = \"Gap_Consolidation_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of price discovery by comparing the magnitude of overnight gaps to the intraday volatility over a 5-day period. It uses Z-scores to normalize the gap-to-range ratio, identifying days where the gap dominates the daily price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.807039",
      "updated_at": "2026-01-17T04:05:47.807045"
    },
    "13a0cd3f1b427b42": {
      "factor_id": "13a0cd3f1b427b42",
      "factor_name": "Institutional_Stealth_Accumulation",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Stealth_Accumulation\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies potential institutional accumulation by looking for days with a positive overnight gap but a narrow intraday range relative to the 10-day average range, further filtered by volume strength.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.828509",
      "updated_at": "2026-01-17T04:05:47.828514"
    },
    "b543bbfaef7ecdae": {
      "factor_id": "b543bbfaef7ecdae",
      "factor_name": "Liquidity_Drift_Persistence_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'liquidity-driven drifting' by measuring the autocorrelation of returns during periods of low trading volume. High price persistence on low volume suggests a lack of institutional liquidity, which often leads to mean-reversion when volume returns. The factor targets regimes where volume is in the bottom 30th percentile and return autocorrelation is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.731871",
      "updated_at": "2026-01-17T04:12:15.731878"
    },
    "e99dc8eb50384b19": {
      "factor_id": "e99dc8eb50384b19",
      "factor_name": "Hollow_Trend_Reversal_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELAY($return, 1), 10)) * (1.0 - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10)) * (1.0 - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Trend_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trends that lack structural support by multiplying the 10-day return autocorrelation with a volume-based penalty. It uses the inverse of the volume rank to amplify signals where price persistence is high but market participation is low, indicating a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.754210",
      "updated_at": "2026-01-17T04:12:15.754216"
    },
    "c194349585ccf845": {
      "factor_id": "c194349585ccf845",
      "factor_name": "Low_Volume_Autocorr_ZScore",
      "factor_expression": "TS_ZSCORE(TS_CORR($return, DELAY($return, 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Low_Volume_Autocorr_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the return autocorrelation and filters for low-volume environments. It identifies assets where the current 10-day price persistence is significantly higher than its own history while the volume remains below its 20-day median, signaling an overextended move likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.776481",
      "updated_at": "2026-01-17T04:12:15.776488"
    },
    "85c86e3efae357d7": {
      "factor_id": "85c86e3efae357d7",
      "factor_name": "Institutional_Absorption_Ratio_5D",
      "factor_expression": "(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of price range to volume-weighted impact. A low value suggests 'quiet' accumulation where high volume turnover occurs within a tight price range, indicating institutional absorption before a potential breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.310621",
      "updated_at": "2026-01-17T04:16:58.310627"
    },
    "d51246ff8f20a25c": {
      "factor_id": "d51246ff8f20a25c",
      "factor_name": "Compressed_Range_Volume_Efficiency",
      "factor_expression": "RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Range_Volume_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of volume in moving price. It targets assets where the 5-day price range is compressed relative to the volume-to-price ratio, normalized by the stability of volume (inverse of 10-day volume volatility) to detect non-volatile institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.333594",
      "updated_at": "2026-01-17T04:16:58.333600"
    },
    "68f8b445de3c1f81": {
      "factor_id": "68f8b445de3c1f81",
      "factor_name": "Accumulation_Spring_Factor",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Spring_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the divergence between price volatility and volume intensity. It specifically looks for periods where the price range (high-low) is small compared to the dollar volume, weighted by the inverse of volume variance to highlight 'stable' high-liquidity zones.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.355989",
      "updated_at": "2026-01-17T04:16:58.355995"
    },
    "4b7ce1906bab598a": {
      "factor_id": "4b7ce1906bab598a",
      "factor_name": "Stealth_Momentum_Ratio_3D",
      "factor_expression": "TS_SUM($return, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Momentum_Ratio_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'stealth' institutional accumulation by calculating the ratio of the 3-day price return to the average volume-volatility product. High values suggest price discovery is occurring with minimal market impact and retail noise, indicating a high-conviction trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.871702",
      "updated_at": "2026-01-17T04:20:15.871709"
    },
    "505941f44d7074fe": {
      "factor_id": "505941f44d7074fe",
      "factor_name": "Clean_Breakout_Efficiency_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Breakout_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the stealth momentum hypothesis focusing on price efficiency over a slightly longer window (5 days). It uses the Z-score of the return divided by the volume-volatility product to identify outliers where price moves significantly despite low 'noise' (volume and volatility).",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.895356",
      "updated_at": "2026-01-17T04:20:15.895362"
    },
    "5d4a5307ed5d0e9c": {
      "factor_id": "5d4a5307ed5d0e9c",
      "factor_name": "Relative_Stealth_Intensity_10D",
      "factor_expression": "TS_RANK($return / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(TS_PCTCHANGE($close, 1) / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Stealth_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of stealth momentum by comparing the current return-to-volatility-volume ratio against its own 10-day history using TS_RANK. This identifies moments where the 'cleanliness' of the price move is at a local peak.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.917949",
      "updated_at": "2026-01-17T04:20:15.917955"
    },
    "a189234f57dc4140": {
      "factor_id": "a189234f57dc4140",
      "factor_name": "IAP_Factor_10D",
      "factor_expression": "(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IAP_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Information Asymmetry Persistence (IAP) factor: It calculates the ratio of the volume coefficient of variation to the price return volatility over a 10-day window. High values identify stocks with significant volume dispersion during price consolidation, signaling institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.946476",
      "updated_at": "2026-01-17T04:43:37.946483"
    },
    "54f8a6f63ea313e6": {
      "factor_id": "54f8a6f63ea313e6",
      "factor_name": "Z_IAP_Divergence_15D",
      "factor_expression": "ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 1e-8)) / (TS_STD($return, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 0.000001)) / (TS_STD(TS_PCTCHANGE($close, 1), 15) + 0.000001))\" # Your output factor expression will be filled in here\n    name = \"Z_IAP_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the Information Asymmetry Persistence hypothesis using a 15-day window. It measures the relative intensity of volume-price divergence compared to other stocks, highlighting extreme institutional accumulation phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.970699",
      "updated_at": "2026-01-17T04:43:37.970705"
    },
    "fc91fb2a85d935be": {
      "factor_id": "fc91fb2a85d935be",
      "factor_name": "IAP_Rank_Trend_20D",
      "factor_expression": "TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"IAP_Rank_Trend_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of information asymmetry by taking the 20-day time-series rank of the IAP ratio. A high rank suggests that the current 'quiet' accumulation phase is at its most intense relative to the past month.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.994614",
      "updated_at": "2026-01-17T04:43:37.994620"
    },
    "a4c66b2dd186bd3f": {
      "factor_id": "a4c66b2dd186bd3f",
      "factor_name": "Informed_Flow_Persistence_5D",
      "factor_expression": "TS_ZSCORE(SKEW($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SKEW(TS_PCTCHANGE($close, 1), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Flow_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend continuation by measuring the ratio of 5-day return skewness to the 5-day standard deviation of the overnight gap. High positive values suggest 'quiet' institutional accumulation characterized by smooth, positively skewed intraday discovery with minimal overnight volatility shocks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.654977",
      "updated_at": "2026-01-17T05:02:29.654984"
    },
    "54a8292e9cd61523": {
      "factor_id": "54a8292e9cd61523",
      "factor_name": "Smooth_Discovery_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smooth_Discovery_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of price trends by comparing the magnitude of daily returns to the volatility of overnight gaps. It targets regimes where price discovery is 'smooth' and driven by continuous intraday flow rather than discrete overnight jumps.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.679452",
      "updated_at": "2026-01-17T05:02:29.679458"
    },
    "835a287e74598f97": {
      "factor_id": "835a287e74598f97",
      "factor_name": "Intraday_Skew_Gap_Stability_5D",
      "factor_expression": "RANK(SKEW($return)) - RANK(TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SKEW(($close - $open) / $open, 5)) - RANK(TS_STD(($open / DELAY($close, 1)) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Skew_Gap_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked factor that rewards stocks with high intraday return skewness relative to their overnight gap risk. This aligns with the hypothesis that institutional accumulation creates positive skewness without triggering high-volatility gap events.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.703585",
      "updated_at": "2026-01-17T05:02:29.703590"
    },
    "411d946cbcb95d0b": {
      "factor_id": "411d946cbcb95d0b",
      "factor_name": "Institutional_Commitment_Persistence_Ratio_20D",
      "factor_expression": "RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Commitment_Persistence_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable trends by calculating the ratio of the Coefficient of Variation (CV) of the price range to the CV of volume over a 20-day window. A lower ratio indicates that volume is more stable relative to price volatility, suggesting 'quiet' institutional accumulation. CV is calculated as the standard deviation divided by the mean.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.092594",
      "updated_at": "2026-01-17T05:49:14.092601"
    },
    "d256ede617306ae6": {
      "factor_id": "d256ede617306ae6",
      "factor_name": "Institutional_Accumulation_Stability_20D",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 20), 20) + TS_ZSCORE(TS_STD(ABS($close - $open), 20), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the stability of institutional commitment by comparing the rolling 20-day volatility of volume against the rolling 20-day volatility of intraday returns. It targets periods where price movement is orderly (low range volatility) and volume is consistent, which is characteristic of algorithmic execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.117822",
      "updated_at": "2026-01-17T05:49:14.117828"
    },
    "b15a9e66a9933ad3": {
      "factor_id": "b15a9e66a9933ad3",
      "factor_name": "Volume_Consistency_Trend_Filter_20D",
      "factor_expression": "((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Consistency_Trend_Filter_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of institutional activity by measuring the inverse of volume dispersion relative to price range dispersion. It uses the ratio of 20-day Mean Absolute Deviation (MAD) of volume to the 20-day range to filter out speculative spikes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.142727",
      "updated_at": "2026-01-17T05:49:14.142732"
    },
    "f31d8c4ef20d75c6": {
      "factor_id": "f31d8c4ef20d75c6",
      "factor_name": "Linear_Trend_Decay_ZScore",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Decay_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that focuses on the standardized deviation of trend linearity. It uses the Z-score of the 10-day R-squared over a 20-day period to detect extreme departures from the recent trend stability regime, helping to identify points where the 'quality' of the price movement is breaking down.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.834190",
      "updated_at": "2026-01-17T06:03:35.834196"
    },
    "373b3a86b027bfcc": {
      "factor_id": "373b3a86b027bfcc",
      "factor_name": "Relative_Trend_Instability",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Trend_Instability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the instability of price trends by comparing the current trend's R-squared to its 20-day moving average, normalized by its volatility. It captures the 'fragility' of the trend by highlighting periods where the goodness-of-fit of the linear price-time relationship is significantly more volatile than its recent history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.859234",
      "updated_at": "2026-01-17T06:03:35.859239"
    },
    "1be142da9be01930": {
      "factor_id": "1be142da9be01930",
      "factor_name": "Overnight_Informed_Gap_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Informed_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies informed price discovery by multiplying the overnight return (gap) with the relative trading volume of the current day. High volume during the gap's subsequent session suggests institutional validation of the price shock, while low volume suggests retail noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.778853",
      "updated_at": "2026-01-17T06:06:12.778860"
    },
    "5f27b35f17420f9d": {
      "factor_id": "5f27b35f17420f9d",
      "factor_name": "ZScore_Overnight_Volume_Shock",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Volume_Shock\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the overnight sentiment gap that uses Z-score normalization for the volume component and cross-sectional ranking for the gap, ensuring the factor is robust to different market regimes and stock scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.804532",
      "updated_at": "2026-01-17T06:06:12.804538"
    },
    "a38885cb88142b61": {
      "factor_id": "a38885cb88142b61",
      "factor_name": "Informed_Gap_Momentum_Filter",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Informed_Gap_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the overnight gap by applying a sign-based volume weight. It captures the conviction of the overnight move by scaling the gap magnitude by the 5-day relative volume, specifically focusing on cases where volume exceeds the recent median to filter out low-conviction noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.831460",
      "updated_at": "2026-01-17T06:06:12.831466"
    },
    "97893b031c147033": {
      "factor_id": "97893b031c147033",
      "factor_name": "Intraday_VWAP_Midpoint_Deviation_5D",
      "factor_expression": "TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_VWAP_Midpoint_Deviation_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of the approximated Volume-Weighted Average Price (VWAP) from the daily price midpoint, normalized by the daily range. A high deviation indicates that volume is concentrated at one extreme of the price range, suggesting liquidity exhaustion and potential mean-reversion. It is smoothed over a 5-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.432281",
      "updated_at": "2026-01-17T06:08:21.432288"
    },
    "298e0ab6776e2256": {
      "factor_id": "298e0ab6776e2256",
      "factor_name": "Hollow_Price_Extreme_Reversal_5D",
      "factor_expression": "TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Price_Extreme_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'hollow' price moves by calculating the distance between the daily close and the approximated VWAP relative to the daily range. If the close is far from where the volume was executed (VWAP), the price level is considered low-conviction. The factor uses a 5-day moving average to signal mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.458630",
      "updated_at": "2026-01-17T06:08:21.458636"
    },
    "ad0df9d76562d7e7": {
      "factor_id": "ad0df9d76562d7e7",
      "factor_name": "Volume_Weighted_Position_ZScore_5D",
      "factor_expression": "ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the position of the VWAP within the daily range using a cross-sectional Z-score to identify assets where price extremes are most disconnected from volume centers across the universe, targeting mean-reversion over a 5-day lookback.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.484297",
      "updated_at": "2026-01-17T06:08:21.484303"
    },
    "ed8a5a26050ad169": {
      "factor_id": "ed8a5a26050ad169",
      "factor_name": "Trend_Acceleration_Decay_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Decay_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term and long-term price linearity. It calculates the difference between the 5-day R-squared and the 20-day R-squared of closing prices against time. A high value indicates a speculative blow-off where short-term linearity far exceeds long-term structural stability, while a low value suggests a breakdown of a previously stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.069444",
      "updated_at": "2026-01-17T06:38:46.069451"
    },
    "1d239eda75962a9c": {
      "factor_id": "1d239eda75962a9c",
      "factor_name": "ZScore_Trend_Linearity_Divergence",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Trend_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the trend acceleration decay. It identifies assets where the short-term (5-day) trend linearity is an outlier relative to its long-term (20-day) historical linearity, highlighting potential mean-reversion candidates in the broader market context.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.096980",
      "updated_at": "2026-01-17T06:38:46.096986"
    },
    "3469c1a0a46fd14e": {
      "factor_id": "3469c1a0a46fd14e",
      "factor_name": "Relative_Linearity_Efficiency_Ratio",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)\" # Your output factor expression will be filled in here\n    name = \"Relative_Linearity_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the efficiency of trend acceleration by scaling the linearity difference by the long-term linearity baseline. It highlights cases where a stable trend (high 20-day R-squared) is suddenly disrupted or exponentially accelerated, providing a normalized measure of structural decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.122928",
      "updated_at": "2026-01-17T06:38:46.122933"
    },
    "f463f63909a625be": {
      "factor_id": "f463f63909a625be",
      "factor_name": "Intraday_Exhaustion_ATR_Normalized_20D",
      "factor_expression": "TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies overextended emotional positioning by calculating the 20-day average of the ratio between the daily high-low range and the absolute open-close body, normalized by the 20-day Average True Range (ATR). High values indicate failed price discovery and potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.738933",
      "updated_at": "2026-01-17T06:42:00.738939"
    },
    "99540186c19ce407": {
      "factor_id": "99540186c19ce407",
      "factor_name": "Shadow_to_Body_Efficiency_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Shadow_to_Body_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified measure of the 'hollow' price move hypothesis. It calculates the 20-day average of the ratio of the total intraday range to the price displacement (body), cross-sectionally ranked to identify stocks with the most extreme 'exhaustion' patterns relative to the market.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.765086",
      "updated_at": "2026-01-17T06:42:00.765091"
    },
    "f3aada6b8df9d2b5": {
      "factor_id": "f3aada6b8df9d2b5",
      "factor_name": "Relative_Intraday_Volatility_Skew_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (ABS($close - $open) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (MAX(ABS($close - $open), 0.001 * $close)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Volatility_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between total intraday movement and net progress by comparing the current shadow-to-body ratio against its 10-day historical standard deviation, identifying statistical instability in price discovery.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.790636",
      "updated_at": "2026-01-17T06:42:00.790641"
    },
    "d339476e2577b31e": {
      "factor_id": "d339476e2577b31e",
      "factor_name": "Overnight_Sentiment_Exhaustion_5D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential short-term mean reversion by calculating the ratio of the overnight price gap to the average volume-weighted intraday range over the last 5 days. A high value suggests an emotional overnight overextension on low relative liquidity density, which is likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.308356",
      "updated_at": "2026-01-17T06:44:28.308362"
    },
    "924aeaafa3d5d17d": {
      "factor_id": "924aeaafa3d5d17d",
      "factor_name": "Ranked_Gap_to_Liquidity_Density_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_to_Liquidity_Density_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized version of the sentiment exhaustion hypothesis. It compares the current overnight gap against the average intraday price movement per unit of volume over 10 days, applying cross-sectional ranking to identify the most overextended stocks relative to their recent liquidity profile.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.334292",
      "updated_at": "2026-01-17T06:44:28.334298"
    },
    "858f84aee06050b8": {
      "factor_id": "858f84aee06050b8",
      "factor_name": "Volatility_Adjusted_Overnight_Gap_3D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Overnight_Gap_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the 3-day average intraday range, excluding volume to focus purely on price-action exhaustion. It targets stocks where the overnight move is disproportionately large compared to recent daily price volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.359855",
      "updated_at": "2026-01-17T06:44:28.359861"
    },
    "2a7824bde358fdcf": {
      "factor_id": "2a7824bde358fdcf",
      "factor_name": "WV_Trend_Linearity_Ratio_5_10",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WV_Trend_Linearity_Ratio_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio between the 5-day volume-weighted price range and the 10-day R-squared of price against a time index. It identifies trend exhaustion by detecting when the 'energy' (volume-weighted volatility) spikes while the 'order' (linear trend persistence) begins to plateau or decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:09.983407",
      "updated_at": "2026-01-17T06:59:09.983414"
    },
    "1b788843ad56ac76": {
      "factor_id": "1b788843ad56ac76",
      "factor_name": "Vol_Weighted_Volatility_ZScore_Trend_Decay",
      "factor_expression": "TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Volatility_ZScore_Trend_Decay\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between standardized volume-weighted volatility and trend persistence. It targets the lead-lag relationship where a surge in volatility (Z-score of WV) relative to the trend stability (R-squared) signals an imminent regime shift or trend breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.009807",
      "updated_at": "2026-01-17T06:59:10.009813"
    },
    "97f062d37da14737": {
      "factor_id": "97f062d37da14737",
      "factor_name": "Institutional_Distribution_Energy_Factor",
      "factor_expression": "RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Distribution_Energy_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis focusing on the ratio of short-term volume-weighted price movement to the persistence of the trend. High values suggest that price movement is becoming erratic and volume-heavy, indicating potential institutional distribution before a trend reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.035784",
      "updated_at": "2026-01-17T06:59:10.035789"
    },
    "628b34f333f9c1b3": {
      "factor_id": "628b34f333f9c1b3",
      "factor_name": "Stealth_Accumulation_Efficiency_20D",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 20)) / (TS_SUM(ABS(DELTA($close, 1)), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining price path efficiency with a volume-weighted positioning metric, filtered for low-volatility 'quiet' regimes. High efficiency (net move vs total move) and volume concentrated near the high during low turnover-to-volatility periods signal sustainable stealth trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.576468",
      "updated_at": "2026-01-17T06:59:34.576476"
    },
    "775ac856b5e37fdc": {
      "factor_id": "775ac856b5e37fdc",
      "factor_name": "Quiet_Regime_Path_Linearity_10D",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(TS_STD($return, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 0.00000001)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 10) / (TS_MEAN($volume, 10) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Path_Linearity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stealth accumulation hypothesis focusing on the linearity of price movement (Efficiency Ratio) normalized by the relative volatility-to-turnover ratio. It targets stocks moving steadily with low market noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.603817",
      "updated_at": "2026-01-17T06:59:34.603823"
    },
    "3d7dd83af034db9d": {
      "factor_id": "3d7dd83af034db9d",
      "factor_name": "Volume_Skew_Efficiency_Combined",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($close - DELAY($close, 1)), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Volume_Skew_Efficiency_Combined\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the synergy between price efficiency and the intraday volume-weighted close position. It uses the 20-day efficiency ratio and weights it by the 5-day average of where the close sits relative to the daily range, emphasizing 'quiet' accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.630010",
      "updated_at": "2026-01-17T06:59:34.630016"
    },
    "47ab5689d1d20430": {
      "factor_id": "47ab5689d1d20430",
      "factor_name": "Liquidity_Drift_Efficiency_20D",
      "factor_expression": "TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistent drift of price relative to the proxy VWAP (average of OHLC), normalized by price volatility. It identifies sustainable trends by calculating the 20-day moving average of this normalized distance, capturing high-conviction liquidity-taking phases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.104134",
      "updated_at": "2026-01-17T07:02:02.104141"
    },
    "612c20e61471a5fb": {
      "factor_id": "612c20e61471a5fb",
      "factor_name": "Stable_Trend_Consensus_Factor",
      "factor_expression": "RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Stable_Trend_Consensus_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend stability by combining the price-VWAP distance with its cross-sectional rank. It targets assets where the price is consistently re-rated relative to the average cost basis, avoiding temporary spikes by using a smoothed 20-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.131054",
      "updated_at": "2026-01-17T07:02:02.131060"
    },
    "01c133f13ad1a4f7": {
      "factor_id": "01c133f13ad1a4f7",
      "factor_name": "VWAP_Distance_ZScore_20D",
      "factor_expression": "TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Distance_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized measure of the price's deviation from the proxy VWAP, expressed as a time-series Z-score over 20 days. This captures the statistical significance of the price drift relative to its own historical volatility to signal trend continuation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.157264",
      "updated_at": "2026-01-17T07:02:02.157270"
    },
    "f6b570215828664b": {
      "factor_id": "f6b570215828664b",
      "factor_name": "Institutional_Accumulation_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($close - $open) / ($high - $low + 1e-8)) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($close / DELAY($close, 1) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring 'price efficiency' (the ratio of net price movement to total intraday range) scaled by volume density. It targets steady price appreciation accompanied by high relative volume and low volatility, which suggests structural absorption of supply.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.446055",
      "updated_at": "2026-01-17T07:02:26.446062"
    },
    "3972ceec7e301721": {
      "factor_id": "3972ceec7e301721",
      "factor_name": "Low_Vol_Volume_Density_Rank_15D",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($return, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 15))\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Volume_Density_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-quality momentum by ranking stocks that exhibit a high ratio of volume to intraday range (volume density) while maintaining low return volatility. High volume density indicates that large orders are being filled within a tight price range, a hallmark of institutional execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.472976",
      "updated_at": "2026-01-17T07:02:26.472982"
    },
    "60d07cdfa713d25a": {
      "factor_id": "60d07cdfa713d25a",
      "factor_name": "Structural_Liquidity_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Liquidity_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the persistence of price trends by evaluating the consistency of positive returns relative to the intraday range, weighted by the 20-day time-series rank of volume. It identifies 'quiet' trends where volume is high relative to historical norms but price volatility remains suppressed.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.499248",
      "updated_at": "2026-01-17T07:02:26.499253"
    },
    "c3727aed18a981b4": {
      "factor_id": "c3727aed18a981b4",
      "factor_name": "Intraday_Conviction_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Conviction_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional trend conviction by measuring the alignment between price direction and intraday range, weighted by volume intensity and penalized by volume instability. It calculates the 5-day average price efficiency (body-to-range ratio) multiplied by the 5-day average volume, normalized by the 20-day volume standard deviation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.499804",
      "updated_at": "2026-01-17T07:04:53.499811"
    },
    "b35305f10d1e3564": {
      "factor_id": "b35305f10d1e3564",
      "factor_name": "Cross_Sectional_Institutional_Flow_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Institutional_Flow_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction hypothesis that focuses on the relative strength of price-volume synchronization. It uses the ratio of price efficiency to volume volatility over a 10-day window to identify stocks with the most stable institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.526663",
      "updated_at": "2026-01-17T07:04:53.526669"
    },
    "67c375461e7ad2ef": {
      "factor_id": "67c375461e7ad2ef",
      "factor_name": "Conviction_Momentum_ZScore_20D",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Momentum_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of price moves by standardizing the price efficiency ratio against its own history and scaling it by the relative volume level. It highlights periods where price movement is unusually 'clean' relative to the intraday noise, supported by high relative volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.552981",
      "updated_at": "2026-01-17T07:04:53.552987"
    },
    "461bb144da4b724a": {
      "factor_id": "461bb144da4b724a",
      "factor_name": "Inst_Trend_Stability_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Stability_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the stability of volume relative to price range. A low ratio of price range to volume volatility, smoothed over 20 days and normalized by 60-day momentum, suggests a steady, low-impact trend characteristic of institutional buying.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.610923",
      "updated_at": "2026-01-17T07:08:38.610930"
    },
    "c5e624a879656b21": {
      "factor_id": "c5e624a879656b21",
      "factor_name": "Smooth_Volume_Efficiency_20D",
      "factor_expression": "ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN($return, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"Smooth_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price efficiency by comparing the daily price range to volume dispersion. It targets regimes where price moves are achieved with consistent volume rather than spikes, indicating sustainable trend persistence. It uses Z-score for cross-sectional normalization.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.637858",
      "updated_at": "2026-01-17T07:08:38.637863"
    },
    "629b1b2a695e6c1d": {
      "factor_id": "629b1b2a695e6c1d",
      "factor_name": "Institutional_Accumulation_Proxy",
      "factor_expression": "TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Proxy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined measure of institutional trend persistence. It calculates the ratio of price range to volume volatility, then applies a time-series rank to ensure the indicator is robust to outliers before multiplying by the long-term trend direction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.666387",
      "updated_at": "2026-01-17T07:08:38.666393"
    },
    "837f1167178d649c": {
      "factor_id": "837f1167178d649c",
      "factor_name": "IAG_Factor_5D",
      "factor_expression": "RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"IAG_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's closing position relative to its daily range. High values suggest informed institutional positioning with low retail resistance.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.531668",
      "updated_at": "2026-01-17T07:09:48.531675"
    },
    "395e6e416c3c22cc": {
      "factor_id": "395e6e416c3c22cc",
      "factor_name": "Institutional_Gap_Persistence_10D",
      "factor_expression": "ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of information-driven gaps by scaling the overnight return by the 10-day volatility of intraday returns, further filtered by the intraday price location to confirm trend strength. It targets 'quiet' trend initiations where institutional consensus is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.562432",
      "updated_at": "2026-01-17T07:09:48.562439"
    },
    "36354e062634e726": {
      "factor_id": "36354e062634e726",
      "factor_name": "Quiet_Trend_Initiation_Index",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Initiation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the ratio of the overnight return to the trailing 5-day median absolute deviation of intraday returns. It uses TS_MAD for robustness against outliers and scales by the intraday range ratio to identify high-conviction institutional moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.590704",
      "updated_at": "2026-01-17T07:09:48.590711"
    },
    "f6f5d9c29160fdcf": {
      "factor_id": "f6f5d9c29160fdcf",
      "factor_name": "Overnight_Gap_ATR_Normalized_20D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the overnight price gap (current open minus previous close) and normalizes it by the 20-day Average True Range (ATR). It identifies institutional information shocks where the overnight surprise significantly exceeds typical daily volatility, signaling a momentum breakout.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.322229",
      "updated_at": "2026-01-17T07:11:55.322236"
    },
    "33dde5198bb9a733": {
      "factor_id": "33dde5198bb9a733",
      "factor_name": "ZScore_Overnight_Shock_20D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Shock_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the cross-sectional strength of the overnight gap relative to its historical volatility. By applying a Z-score to the ATR-normalized gap, it highlights stocks experiencing the most significant idiosyncratic information shocks relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.350013",
      "updated_at": "2026-01-17T07:11:55.350019"
    },
    "5d7b0005e2695a36": {
      "factor_id": "5d7b0005e2695a36",
      "factor_name": "Ranked_Information_Shock_Persistence",
      "factor_expression": "RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Information_Shock_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the ATR-normalized overnight gap with its time-series rank over the last 10 days. It aims to identify 'breakout' days where the overnight shock is not only large relative to volatility but also represents a recent peak in surprise intensity.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.377120",
      "updated_at": "2026-01-17T07:11:55.377126"
    },
    "beceb91b44bbc95e": {
      "factor_id": "beceb91b44bbc95e",
      "factor_name": "MRLV_Liquidity_Vacuum_5D_20D",
      "factor_expression": "TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"MRLV_Liquidity_Vacuum_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Mean-Reverting Liquidity Vacuum (MRLV) factor identifies price exhaustion by calculating the ratio of short-term price range volatility to long-term average volume. High values indicate 'hollow' price movements driven by liquidity gaps rather than institutional conviction, signaling a likely reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.831791",
      "updated_at": "2026-01-17T07:15:34.831797"
    },
    "ab092a4ed20eeabf": {
      "factor_id": "ab092a4ed20eeabf",
      "factor_name": "Hollow_Volatility_Reversal_Factor",
      "factor_expression": "RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($return, $volume, 10) < 0 ? 1 : 0.5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($close / DELAY($close, 1) - 1, $volume, 10) < 0 ? 1 : 0.5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Volatility_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets assets where price range expansion is decoupled from volume support. It uses the ratio of the 5-day range standard deviation to the 20-day volume mean, cross-sectionally ranked and filtered for low price-volume correlation to isolate non-institutional noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.861060",
      "updated_at": "2026-01-17T07:15:34.861066"
    },
    "b9875be6ef7bd575": {
      "factor_id": "b9875be6ef7bd575",
      "factor_name": "ZScore_Range_Volume_Imbalance",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Range_Volume_Imbalance\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the standardized imbalance between price range volatility and volume. By using TS_ZSCORE, it identifies extreme 'liquidity vacuum' events relative to the asset's own history, which are historically prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.889105",
      "updated_at": "2026-01-17T07:15:34.889111"
    },
    "bc5cd0033670fd71": {
      "factor_id": "bc5cd0033670fd71",
      "factor_name": "TED_Linearity_Volume_Divergence_10D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"TED_Linearity_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies unsustainable price trends by multiplying the trend linearity (R-squared of price over time) by the negative correlation between price and volume. High linearity combined with price-volume divergence (negative correlation) suggests trend exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.951902",
      "updated_at": "2026-01-17T08:22:54.951909"
    },
    "1b9594382311ea4a": {
      "factor_id": "1b9594382311ea4a",
      "factor_name": "Trend_Fragility_Index_10D",
      "factor_expression": "RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Trend Exhaustion Divergence hypothesis. It uses the time-series rank of price linearity and combines it with the cross-sectional rank of the negative price-volume correlation to find stocks where the trend is most 'crowded' yet unsupported by volume.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.982889",
      "updated_at": "2026-01-17T08:22:54.982895"
    },
    "d8bcc7cc594a12bc": {
      "factor_id": "d8bcc7cc594a12bc",
      "factor_name": "Exhaustion_Volume_Decay_10D",
      "factor_expression": "TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Volume_Decay_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by looking at the interaction between price momentum and the decline in volume support. It uses the R-squared of the price trend scaled by the inverse of the price-volume correlation, focusing on cases where price moves linearly but volume participation is fading.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:55.013504",
      "updated_at": "2026-01-17T08:22:55.013510"
    },
    "164030fafe4ad9c9": {
      "factor_id": "164030fafe4ad9c9",
      "factor_name": "Institutional_Flow_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Flow_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional conviction by measuring the average intraday price positioning (Close-Open relative to High-Low) weighted by the 5-day volume trend, identifying persistent directional flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.945249",
      "updated_at": "2026-01-17T08:41:46.945258"
    },
    "e8edb408831788e7": {
      "factor_id": "e8edb408831788e7",
      "factor_name": "Aggressive_Skew_Momentum_10D",
      "factor_expression": "RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($return))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($close / DELAY($close, 1) - 1))\" # Your output factor expression will be filled in here\n    name = \"Aggressive_Skew_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies aggressive trend-following behavior by combining cross-sectional return skewness with the consistency of price relative to its recent range, signaling institutional dominance.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.977170",
      "updated_at": "2026-01-17T08:41:46.977177"
    },
    "39784a9223d662b5": {
      "factor_id": "39784a9223d662b5",
      "factor_name": "Volume_Weighted_Position_Consistency",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) + RANK(TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_Consistency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the consistency of informed accumulation by evaluating the rank of price positioning relative to the volume-weighted trend, emphasizing stocks with stable institutional footprints.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:47.007667",
      "updated_at": "2026-01-17T08:41:47.007673"
    }
  }
}