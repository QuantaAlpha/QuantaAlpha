{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.671297",
    "last_updated": "2026-01-17T02:02:58.671303",
    "total_factors": 30,
    "version": "1.0",
    "note": "Random 30 factors from round 1 (from all_factors_library_AA.json)"
  },
  "factors": {
    "d5c41860c0168b28": {
      "factor_id": "d5c41860c0168b28",
      "factor_name": "Net_Volume_Momentum_5D",
      "factor_expression": "ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Net_Volume_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of directional money flow by calculating the normalized difference between volume on up-days and down-days over a 5-day window, capturing net capital inflow or outflow.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite signal integrating short-term price-volume correlation, relative price positioning against recent peaks, and volume-weighted momentum can effectively capture mean-reversion and trend-exhaustion points in equity returns.\n                Concise Observation: The user's provided components (CORR5, MAX5, VSUMD5) target three distinct dimensions: liquidity-price synergy, technical resistance, and directional volume intensity over a 5-day window.\n                Concise Justification: Combining these factors allows for a multi-dimensional filter where VSUMD5 identifies the net force of money flow, while MAX5 and CORR5 act as conditional oscillators to determine if that flow is sustainable or hitting a structural ceiling.\n                Concise Knowledge: If price increases are decoupled from volume growth (low correlation), the trend may lack conviction; when prices approach a 5-day resistance level (high MAX5), selling pressure typically intensifies; if volume disproportionately accompanies price declines (negative VSUMD5), it indicates aggressive capital outflow.\n                concise Specification: The hypothesis will be tested by calculating the 5-day correlation of close price and log-volume, the ratio of 5-day high to current close, and the normalized difference of volume on up-days versus down-days, expecting a negative relationship between high resistance/low flow and future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048430344071001,
        "ICIR": 0.0331262421245781,
        "RankIC": 0.0186466306361967,
        "RankICIR": 0.1295832293323421,
        "annualized_return": 0.0480758806902796,
        "information_ratio": 0.6093342429088725,
        "max_drawdown": -0.1697593938726594
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:58.229250",
      "updated_at": "2026-01-14T20:33:58.229256"
    },
    "040b0ca4fc42fff3": {
      "factor_id": "040b0ca4fc42fff3",
      "factor_name": "Trend_Conviction_Volume_Stability_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Trend_Conviction_Volume_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the composite hypothesis focusing on the interaction between price-volume correlation and volume stability. It identifies stocks where price trends are backed by consistent, non-volatile volume growth, suggesting high-quality institutional accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.574184",
      "updated_at": "2026-01-14T20:24:44.574190"
    },
    "c45771cd18f826ae": {
      "factor_id": "c45771cd18f826ae",
      "factor_name": "Relative_Strength_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day reversal logic with the Relative Strength Index (RSI). It identifies mean-reversion candidates by looking for stocks that have both a negative 10-day return and an oversold RSI signal, smoothed by a cross-sectional rank.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.463809",
      "updated_at": "2026-01-14T16:57:26.463815"
    },
    "8fe21fdb459ddca8": {
      "factor_id": "8fe21fdb459ddca8",
      "factor_name": "Volume_Weighted_Leader_Signal",
      "factor_expression": "ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Leader_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis that weights the 10-day momentum of the entire cross-section by volume rank to emphasize leader behavior, then applies this signal specifically to lower-volume assets.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.848571",
      "updated_at": "2026-01-15T17:38:45.848577"
    },
    "12a138054c7457fa": {
      "factor_id": "12a138054c7457fa",
      "factor_name": "Clean_Trend_Quality_Index",
      "factor_expression": "RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Trend_Quality_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the trend quality hypothesis focusing on the ratio of directional persistence to intraday volatility. It rewards stocks where the 10-day price change is high relative to the average daily range, adjusted for volume stability.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.150807",
      "updated_at": "2026-01-14T17:20:27.150813"
    },
    "fc79ccb2d5cb3a49": {
      "factor_id": "fc79ccb2d5cb3a49",
      "factor_name": "Volume_Weighted_Range_Convexity_10D",
      "factor_expression": "RANK(TS_SUM((ABS($return) * $volume) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(($volume * ABS($return)) / (TS_STD($close, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Range_Convexity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the hypothesis that high intraday volatility relative to net price change, when confirmed by high volume, indicates exhaustion. It calculates the 10-day sum of volume-weighted return-to-range ratios, cross-sectionally ranked for robustness.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.772489",
      "updated_at": "2026-01-15T18:44:45.772495"
    },
    "5216873e5822843b": {
      "factor_id": "5216873e5822843b",
      "factor_name": "Composite_Trend_Volume_RSV_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Volume_RSV_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines 20-day price trend stability (proxied by the square of the correlation between price and time), 5-day volume-weighted buying pressure, and the 5-day Relative Statistical Value (RSV) to identify high-probability entry points.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.835728",
      "updated_at": "2026-01-14T17:27:11.835735"
    },
    "d4a61936fdb34177": {
      "factor_id": "d4a61936fdb34177",
      "factor_name": "Lead_Lag_Momentum_Corr_20D_5L",
      "factor_expression": "TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Lead_Lag_Momentum_Corr_20D_5L\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 20-day rolling correlation between the current daily return and the 5-day lagged log return. It captures lead-lag momentum effects where current price action follows historical trends with a specific delay.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.598808",
      "updated_at": "2026-01-15T18:47:04.598816"
    },
    "be5d0f19f2e385b1": {
      "factor_id": "be5d0f19f2e385b1",
      "factor_name": "Short_Term_Oversold_Stability_Factor",
      "factor_expression": "-1 * RANK(TS_MEAN($close, 5)) * (1.0 - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($close, 5)) * (1.0 - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Short_Term_Oversold_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the mean-reversion and liquidity stability components of the hypothesis. It looks for stocks that are cross-sectionally oversold over a 5-day period but maintain stable volume profiles, indicating a potential low-risk bounce.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.589041",
      "updated_at": "2026-01-14T20:24:44.589047"
    },
    "2397650750fec253": {
      "factor_id": "2397650750fec253",
      "factor_name": "Trend_Stability_PV_Sync_60D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_PV_Sync_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between long-term price trend linearity (R-squared) and short-term price-volume synchronization. High linearity suggests a stable trend, while positive price-volume correlation confirms the conviction behind the move.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.812715",
      "updated_at": "2026-01-14T17:26:18.812726"
    },
    "c2ef165146f514d0": {
      "factor_id": "c2ef165146f514d0",
      "factor_name": "Exhaustive_Spike_Rank_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-12), 3))\" # Your output factor expression will be filled in here\n    name = \"Exhaustive_Spike_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price 'noise' relative to its trend. It combines the 10-day price residual with a smoothed efficiency ratio. By using RANK, it focuses on the relative extremity of the exhaustive price action compared to the rest of the market universe.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.680649",
      "updated_at": "2026-01-14T20:32:25.680655"
    },
    "0404e78482312e86": {
      "factor_id": "0404e78482312e86",
      "factor_name": "Z_RESI_Efficiency_Filter_10D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ABS(($close - $open) / ($high - $low + 1e-12))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ABS(($close - $open) / ($high - $low + 1e-12))\" # Your output factor expression will be filled in here\n    name = \"Z_RESI_Efficiency_Filter_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the over-extension factor. It uses the Z-score of the 10-day linear regression residual to measure relative price deviation and weights it by the absolute price efficiency. This helps identify assets that have deviated most significantly from their trend with the least structural support.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.665439",
      "updated_at": "2026-01-14T20:32:25.665445"
    },
    "d459cae3758d5c09": {
      "factor_id": "d459cae3758d5c09",
      "factor_name": "Composite_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8)) - ZSCORE(TS_STD(WMA($close, 20), 20) / (TS_MEAN(WMA($close, 20), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) - ZSCORE(TS_STD(WMA($close, 20), 20) / TS_MEAN(WMA($close, 20), 20))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines the linearity of the price trend (RSQR) with the relative volume-weighted price stability. It filters for stocks where the price trend is both statistically linear and supported by consistent volume-weighted price levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.889747",
      "updated_at": "2026-01-14T17:26:18.889753"
    },
    "7374cc0adeeff66f": {
      "factor_id": "7374cc0adeeff66f",
      "factor_name": "RESI_KMID_MeanReversion_10D",
      "factor_expression": "REGRESI($close, SEQUENCE(10), 10) * (($close - $open) / ($high - $low + 1e-12))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(10), 10) * (($close - $open) / ($high - $low + 1e-12))\" # Your output factor expression will be filled in here\n    name = \"RESI_KMID_MeanReversion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion opportunities by multiplying the 10-day linear regression residual of closing prices with the daily price efficiency (KMID). A high residual suggests price over-extension, while a low KMID (small candle body relative to range) indicates weak conviction, signaling an exhaustive move likely to reverse.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 10-day linear regression residual (RESI10) with the daily price efficiency (KMID2) can identify mean-reversion opportunities where high price deviation is confirmed by low-quality price movement.\n                Concise Observation: Market participants often overreact to short-term trends, creating residuals from the linear growth path; however, the 'quality' of the daily price action (open-close vs high-low) distinguishes between strong trend continuation and weak speculative spikes.\n                Concise Justification: Linear regression residuals measure the magnitude of price 'noise' or over-extension, while the ratio of the candle body to the total range (KMID) serves as a proxy for conviction; combining these filters out 'fake' breakouts and identifies overextended assets ready for correction.\n                Concise Knowledge: If a stock's price significantly deviates from its 10-day linear trend (RESI) while the daily candle body is small relative to its range (KMID), the price movement is likely exhaustive; when high relative price levels (QTLU) coincide with decreasing volume-price efficiency, a reversal is more probable.\n                concise Specification: The factor will be calculated as the product of the 10-day price residual from a linear trend and the daily KMID ratio, specifically: RESI10 = (Close - Linear_Trend(Close, 10)) and KMID2 = (Close - Open) / (High - Low + 1e-12), tested for its predictive power on 5-day forward returns.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033079696497917,
        "ICIR": 0.0247080342750833,
        "RankIC": 0.0175189843254098,
        "RankICIR": 0.1293448982407331,
        "annualized_return": 0.0366541206676843,
        "information_ratio": 0.5932339188890233,
        "max_drawdown": -0.1772475370397973
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:32:25.649922",
      "updated_at": "2026-01-14T20:32:25.649929"
    },
    "d817e6e5d1c010ca": {
      "factor_id": "d817e6e5d1c010ca",
      "factor_name": "Trend_Stability_Composite_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Composite_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable price trends by combining trend linearity (R-squared of price against time), relative intraday range (noise), and volume-weighted return dispersion. High values indicate a high-conviction, low-noise trend often associated with institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.117300",
      "updated_at": "2026-01-14T17:20:27.117308"
    },
    "5986d9d2092eb2ce": {
      "factor_id": "5986d9d2092eb2ce",
      "factor_name": "Laggard_Delayed_Response_10D",
      "factor_expression": "DELAY(MEAN(FILTER(TS_SUM($return, 10), RANK($volume) > 0.9)), 5) * RANK(INV($volume))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(DELAY($return, 5), RANK(DELAY($volume, 5)) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Laggard_Delayed_Response_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'laggard' stocks (bottom 50% by volume) and calculates their sensitivity to the previous period's market leader returns. It assumes that if the top 10% most liquid stocks had high returns 5 days ago, laggards will catch up today.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.829835",
      "updated_at": "2026-01-15T17:38:45.829841"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T16:57:26.431941"
    },
    "fe46aa9f57813678": {
      "factor_id": "fe46aa9f57813678",
      "factor_name": "Normalized_Price_Efficiency_ZScore_10D",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Price_Efficiency_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures price efficiency by comparing the directional return to the total volatility (range). It uses a Z-score of the ratio of absolute return to the high-low range, smoothed over 10 days, to identify periods where price movement is 'inefficient' or 'convex', signaling exhaustion.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.752734",
      "updated_at": "2026-01-15T18:44:45.752740"
    },
    "4e1777247bcab4a7": {
      "factor_id": "4e1777247bcab4a7",
      "factor_name": "Intraday_Volatility_Adjusted_Momentum",
      "factor_expression": "RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Volatility_Adjusted_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intraday return normalized by the intraday range (high-low) over a 20-day period. By scaling the intraday trend by the daily volatility, it highlights persistent directional moves that occur with relatively low noise.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.266712",
      "updated_at": "2026-01-15T17:37:26.266718"
    },
    "b999c8f19d5042cd": {
      "factor_id": "b999c8f19d5042cd",
      "factor_name": "Intraday_Return_Relative_Rank_10D",
      "factor_expression": "RANK(TS_RANK(($close - $open) / ($open * ABS($return) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK(($close - $open) / ($open * ABS($return) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Return_Relative_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of intraday return (open-to-close) to the total daily return (close-to-prev_close) and takes its 10-day time-series rank. It identifies stocks where intraday price action dominates the total return, suggesting strong 'smart money' conviction.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.247964",
      "updated_at": "2026-01-15T17:37:26.247970"
    },
    "e3b73174f7fdec13": {
      "factor_id": "e3b73174f7fdec13",
      "factor_name": "Volume_Weighted_Lag_Momentum_20D",
      "factor_expression": "TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Lag_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the lead-lag hypothesis by correlating current returns with the 5-day lagged volume-weighted price change proxy, aiming to identify trends backed by significant trading activity.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.638025",
      "updated_at": "2026-01-15T18:47:04.638031"
    },
    "c20dcf9d08b15587": {
      "factor_id": "c20dcf9d08b15587",
      "factor_name": "Ranked_Stability_Buying_Pressure_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_Buying_Pressure_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the hypothesis by cross-sectionally ranking trend stability (R-squared of price vs time) and multiplying it by the buying pressure ratio over a 5-day window, adjusted for price positioning.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.869921",
      "updated_at": "2026-01-14T17:27:11.869929"
    },
    "bce345eb801c5573": {
      "factor_id": "bce345eb801c5573",
      "factor_name": "Intraday_Momentum_ZScore_5D",
      "factor_expression": "ZSCORE(TS_MEAN(($close - $open) / ($open + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($close - $open) / ($open + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Momentum_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates the intraday return (open-to-close) and calculates its 5-day moving average, normalized by the cross-sectional Z-score. It aims to capture persistent institutional buying or selling pressure during market hours, independent of overnight price gaps.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Return Gap, defined as the difference between the daily total return and the overnight return, serves as a proxy for continuous intraday momentum and exhibits stronger predictive persistence for future returns than total daily returns.\n                Concise Observation: Daily returns often conflate overnight price gaps with intraday trends, potentially masking the distinct behavioral drivers of institutional trading that occur while the market is open.\n                Concise Justification: Institutional investors typically execute large orders during market hours to manage liquidity, creating autocorrelation in intraday price movements that is distinct from the jump-diffusion process of overnight gaps.\n                Concise Knowledge: If overnight returns represent reaction to public news and intraday returns reflect institutional flow, then isolating the intraday component should provide a cleaner signal of persistent 'smart money' positioning.\n                concise Specification: The factor is calculated as the daily close-to-open return ratio subtracted from the daily close-to-close return ratio, effectively isolating the open-to-close price movement as a predictor for next-day returns.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0086617941034014,
        "ICIR": 0.0551441560733923,
        "RankIC": 0.0254576486879335,
        "RankICIR": 0.1659860943621308,
        "annualized_return": 0.0705929095177307,
        "information_ratio": 0.9576916981655668,
        "max_drawdown": -0.1499371335219279
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:37:26.228959",
      "updated_at": "2026-01-15T17:37:26.228966"
    },
    "87ef5fd9a3bfa508": {
      "factor_id": "87ef5fd9a3bfa508",
      "factor_name": "PV_Corr_Resistance_5D",
      "factor_expression": "RANK(TS_CORR($close, LOG($volume + 1e-8), 5)) * RANK($close / (TS_MAX($high, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, LOG($volume + 1e-8), 5)) * RANK($close / (TS_MAX($high, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"PV_Corr_Resistance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by combining price-volume correlation with proximity to recent price peaks. A high correlation between price and volume near a 5-day high suggests a potential blow-off top or resistance-driven reversal.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite signal integrating short-term price-volume correlation, relative price positioning against recent peaks, and volume-weighted momentum can effectively capture mean-reversion and trend-exhaustion points in equity returns.\n                Concise Observation: The user's provided components (CORR5, MAX5, VSUMD5) target three distinct dimensions: liquidity-price synergy, technical resistance, and directional volume intensity over a 5-day window.\n                Concise Justification: Combining these factors allows for a multi-dimensional filter where VSUMD5 identifies the net force of money flow, while MAX5 and CORR5 act as conditional oscillators to determine if that flow is sustainable or hitting a structural ceiling.\n                Concise Knowledge: If price increases are decoupled from volume growth (low correlation), the trend may lack conviction; when prices approach a 5-day resistance level (high MAX5), selling pressure typically intensifies; if volume disproportionately accompanies price declines (negative VSUMD5), it indicates aggressive capital outflow.\n                concise Specification: The hypothesis will be tested by calculating the 5-day correlation of close price and log-volume, the ratio of 5-day high to current close, and the normalized difference of volume on up-days versus down-days, expecting a negative relationship between high resistance/low flow and future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048430344071001,
        "ICIR": 0.0331262421245781,
        "RankIC": 0.0186466306361967,
        "RankICIR": 0.1295832293323421,
        "annualized_return": 0.0480758806902796,
        "information_ratio": 0.6093342429088725,
        "max_drawdown": -0.1697593938726594
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:58.213655",
      "updated_at": "2026-01-14T20:33:58.213663"
    },
    "201b29ae566c3fdf": {
      "factor_id": "201b29ae566c3fdf",
      "factor_name": "Trend_Consistency_Extreme_Timing_5D",
      "factor_expression": "ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Extreme_Timing_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite indicator measuring the synergy between trend direction and the internal rhythm of price extremes. It combines the 5-day price slope with the normalized distance between the occurrences of the 5-day high and low.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.220275",
      "updated_at": "2026-01-14T17:15:58.220283"
    },
    "2aa3b67e52c741d1": {
      "factor_id": "2aa3b67e52c741d1",
      "factor_name": "Composite_Trend_Reversion_Stability_Factor",
      "factor_expression": "RANK(TS_CORR(DELAY($return, 1), DELAY(DELTA(LOG($volume + 1e-8), 1), 1), 60)) - RANK(RANK($close)) - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DELAY($return, 1), DELAY(DELTA(LOG($volume), 1), 1), 60)) - RANK(TS_RANK($close, 5)) - RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Reversion_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines long-term trend quality (60-day price-volume correlation), short-term mean reversion (5-day price rank), and liquidity stability (10-day volume volatility). It targets stocks with high trend conviction, oversold conditions, and stable institutional participation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.559388",
      "updated_at": "2026-01-14T20:24:44.559395"
    },
    "677fe32db5e17012": {
      "factor_id": "677fe32db5e17012",
      "factor_name": "Breadth_Timing_Composite_5D",
      "factor_expression": "RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Breadth_Timing_Composite_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures short-term market strength by combining the breadth of positive price movements (upward frequency) with the relative position of the current price within its recent 5-day range, adjusted for trend slope.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.253729",
      "updated_at": "2026-01-14T17:15:58.253736"
    },
    "4fd5f6bb928aff93": {
      "factor_id": "4fd5f6bb928aff93",
      "factor_name": "Lagged_Return_Spillover_Rank_20D",
      "factor_expression": "TS_CORR($return, DELAY(RANK($return), 5), 20)",
      "factor_implementation_code": "",
      "factor_description": "A variation of the lead-lag hypothesis that uses cross-sectional ranking of lagged returns to identify momentum spillover. It correlates current returns with the 5-day lagged cross-sectional rank of returns over a 20-day window.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.618652",
      "updated_at": "2026-01-15T18:47:04.618659"
    },
    "2e2d86921c884979": {
      "factor_id": "2e2d86921c884979",
      "factor_name": "Leader_Momentum_Spillover_10D",
      "factor_expression": "MEAN(FILTER(TS_MEAN($return, 10), RANK($volume) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(TS_MEAN($return, 10), RANK($volume) > 0.9)) * (RANK($volume) < 0.5 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Leader_Momentum_Spillover_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the lead-lag effect by calculating the cross-sectional correlation between a stock's current volume rank (identifying laggards) and the recent 10-day momentum of high-volume leaders. It uses the cross-sectional mean of returns for high-volume stocks as a proxy for leader movement.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.810757",
      "updated_at": "2026-01-15T17:38:45.810765"
    },
    "de72babf4b53b854": {
      "factor_id": "de72babf4b53b854",
      "factor_name": "Institutional_Accumulation_Score",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Score\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'low noise' aspect of the hypothesis. It measures the linearity of the price trend (RSQR) and penalizes stocks with high 'friction' (intraday volatility relative to volume).",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.183527",
      "updated_at": "2026-01-14T17:20:27.183533"
    }
  }
}