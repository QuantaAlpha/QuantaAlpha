{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.676880",
    "last_updated": "2026-01-17T02:02:58.676883",
    "total_factors": 24,
    "version": "1.0",
    "note": "Random 30 factors from round 8 (from all_factors_library_AA.json)"
  },
  "factors": {
    "73bb4619b3ffbc9f": {
      "factor_id": "73bb4619b3ffbc9f",
      "factor_name": "Liquidity_Convexity_Exhaustion_5D",
      "factor_expression": "SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Convexity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'blow-off' exhaustion points by calculating the 5-day average of the squared price range relative to volume turnover. This convexity-based approach amplifies signals of extreme price moves on low liquidity. It is normalized by the 20-day standard deviation and signed by the 5-day cumulative return to capture mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.801485",
      "updated_at": "2026-01-14T17:47:47.801492"
    },
    "ec3ba8798b60ab54": {
      "factor_id": "ec3ba8798b60ab54",
      "factor_name": "Convex_Price_Impact_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Convex_Price_Impact_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor targeting price-volume decoupling. It measures the convexity of price 'effort' by squaring the daily range relative to volume, then compares the 5-day average of this impact against its 20-day historical volatility to isolate unsustainable liquidity gaps.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.838225",
      "updated_at": "2026-01-14T17:47:47.838230"
    },
    "01fd11f2d23d962e": {
      "factor_id": "01fd11f2d23d962e",
      "factor_name": "Hollow_Move_Convexity_ZScore",
      "factor_expression": "SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / ($volume + 1.0), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / (MAX($volume, 1.0)), 20)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_Convexity_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the convexity-adjusted price impact (range squared over volume) to identify outliers in price discovery. By multiplying by the sign of the 5-day return, it positions for a reversal when price expansion significantly outpaces volume support.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.879619",
      "updated_at": "2026-01-14T17:47:47.879629"
    },
    "530b4b81842c1774": {
      "factor_id": "530b4b81842c1774",
      "factor_name": "Divergent_ZScore_Reversal_10D",
      "factor_expression": "TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_ZScore_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by measuring the statistical extremity of the price move (Z-score) and weighting it by a 'Divergence Index'. The Divergence Index is calculated as (1 - TS_CORR), which amplifies the signal when price and volume move in opposite directions, indicating trend fragility. The price move is calculated as the negative 10-day return to capture mean-reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.840434",
      "updated_at": "2026-01-14T17:48:31.840441"
    },
    "beda22fd003445b3": {
      "factor_id": "beda22fd003445b3",
      "factor_name": "Climax_Gated_Reversal_Factor",
      "factor_expression": "(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Climax_Gated_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets high-conviction selling climaxes. It uses the 10-day price-volume correlation as a state filter (negated to favor divergence) and multiplies it by a volatility-adjusted 10-day return. It incorporates a Volume Surge component (Volume relative to its 20-day mean) to ensure the reversal is backed by significant liquidity exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.876983",
      "updated_at": "2026-01-14T17:48:31.876989"
    },
    "c900cc937efad896": {
      "factor_id": "c900cc937efad896",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional approach to the exhaustion hypothesis. It ranks the 10-day price decline and weights it by the 10-day volume Z-score. By using RANK, it identifies the most 'stretched' assets in the universe, while the volume Z-score (clipped at 0) ensures the signal is only active during periods of higher-than-average volume intensity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.914496",
      "updated_at": "2026-01-14T17:48:31.914503"
    },
    "351ac7234f11b736": {
      "factor_id": "351ac7234f11b736",
      "factor_name": "VW_Momentum_Conviction_Interaction_20D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Conviction_Interaction_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between volume-weighted price momentum and the relative distance from the institutional cost basis. It uses the 10-day rolling mean of return scaled by cross-sectional volume rank to identify institutional conviction, and multiplies it by the rank of the price-to-VWAP ratio. The VWAP is calculated over 20 days. By using the product of two ranked components, it preserves signal intensity for stocks where both momentum and positioning are extreme.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.562820",
      "updated_at": "2026-01-14T17:56:26.562827"
    },
    "8cd6723351ebfc5d": {
      "factor_id": "8cd6723351ebfc5d",
      "factor_name": "Institutional_Efficiency_ZScore_Signal",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Efficiency_ZScore_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by combining the 10-day volume-ranked momentum with a standardized measure of price deviation from the 20-day VWAP. Instead of a simple ratio, it uses the cross-sectional Z-score of the price-to-VWAP distance to highlight statistical outliers in institutional accumulation, ensuring the factor captures high-magnitude alpha as hypothesized.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.602822",
      "updated_at": "2026-01-14T17:56:26.602829"
    },
    "8f0ff1e46d6e06e7": {
      "factor_id": "8f0ff1e46d6e06e7",
      "factor_name": "Volume_Weighted_Momentum_Anchor_Ratio",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Momentum_Anchor_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Efficiency Gap' by multiplying the 10-day persistence of volume-weighted returns with the ratio of the current price to its 20-day volume-weighted anchor. To avoid duplication and preserve signal strength, the VWAP is calculated using TS_SUM and the final interaction is cross-sectionally ranked to focus on relative institutional conviction.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.640127",
      "updated_at": "2026-01-14T17:56:26.640133"
    },
    "0a1cfd2df9539934": {
      "factor_id": "0a1cfd2df9539934",
      "factor_name": "ATR_Normalized_Squeeze_Momentum_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"ATR_Normalized_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by applying a threshold filter based on the Relative Compression Index (20-day range vs 5-day range). When a stock is in the top 10% of 'coiled' states, it outputs the 5-day momentum normalized by a 20-day simplified Average True Range (ATR) to ensure the signal is robust across different volatility regimes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.197501",
      "updated_at": "2026-01-14T18:04:58.197507"
    },
    "2c7e42eff14839e8": {
      "factor_id": "2c7e42eff14839e8",
      "factor_name": "ZScore_Momentum_Compression_Gate_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Compression_Gate_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a 20-day range-based compression ratio as a binary gate. If the stock is experiencing extreme price tightness (top 10% cross-sectionally), it captures the 5-day return normalized by its 20-day time-series Z-score. This ensures that the momentum signal is evaluated relative to its own recent distribution during the breakout phase.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.234715",
      "updated_at": "2026-01-14T18:04:58.234721"
    },
    "b89837c4374e6714": {
      "factor_id": "b89837c4374e6714",
      "factor_name": "Robust_Coil_Breakout_Factor_15D",
      "factor_expression": "((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Robust_Coil_Breakout_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Instead of using a 5-day window which was flagged for duplication, this factor utilizes a 6-day window for the 'coiling' measurement and a 15-day baseline. It interacts the compression state with an ATR-normalized return to identify stocks breaking out from a period of restricted price action.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.271232",
      "updated_at": "2026-01-14T18:04:58.271237"
    },
    "0031652e34990993": {
      "factor_id": "0031652e34990993",
      "factor_name": "Gated_Efficiency_MFI_Factor",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-9)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"Gated_Efficiency_MFI_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional 'Gated' logic where the 10-day Efficiency Ratio (ER10) is only active when the 5-day Money Flow Index (MFI) is above its 10-day rolling median. This ensures that the price efficiency signal is only rewarded when confirmed by above-average liquidity intensity, filtering out low-conviction price drifts.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.156680",
      "updated_at": "2026-01-14T19:04:02.156688"
    },
    "6c1f43082bb778c4": {
      "factor_id": "6c1f43082bb778c4",
      "factor_name": "MFI_Gated_Clean_Trend",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"MFI_Gated_Clean_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the gated efficiency hypothesis that uses a 10-day Efficiency Ratio gated by a 5-day MFI condition. Instead of a binary 1/0 gate, it uses the rank of the Efficiency Ratio multiplied by the logical condition to prioritize stocks with high trend cleanliness and confirmed institutional presence.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.195394",
      "updated_at": "2026-01-14T19:04:02.195400"
    },
    "7f2f8c1405fefe55": {
      "factor_id": "7f2f8c1405fefe55",
      "factor_name": "Liquidity_Confirmed_Efficiency_10D",
      "factor_expression": "ZSCORE(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * (RSI(($high + $low + $close) / 3 * $volume, 5) > TS_MEDIAN(RSI(($high + $low + $close) / 3 * $volume, 5), 10) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Confirmed_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trends by calculating the 10-day Efficiency Ratio and applying a cross-sectional Z-score, then nullifying the signal if the 5-day Money Flow Index is below its 10-day median. This focuses the alpha capture on 'efficient' price moves supported by liquidity.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.233875",
      "updated_at": "2026-01-14T19:04:02.233881"
    },
    "89ab97f85fe9e5e0": {
      "factor_id": "89ab97f85fe9e5e0",
      "factor_name": "PVDE5_Efficiency_Factor",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVDE5_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline. This captures 'low-friction' price discovery where institutional absorption occurs with minimal market impact.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.296769",
      "updated_at": "2026-01-14T20:59:06.296777"
    },
    "aa7009f641606569": {
      "factor_id": "aa7009f641606569",
      "factor_name": "Quiet_Accumulation_Persistence_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return, 5)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks where the 5-day price momentum is high but the volume volatility is lower than its recent average. It uses the inverse of the relative volume CV to weight the returns, emphasizing trends that are 'quiet' and thus potentially more sustainable.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.314150",
      "updated_at": "2026-01-14T20:59:06.314156"
    },
    "5fa7adef201adad7": {
      "factor_id": "5fa7adef201adad7",
      "factor_name": "Relative_Volume_Stability_Momentum",
      "factor_expression": "RANK(TS_SUM($return, 5)) * RANK(TS_MEDIAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5)) * RANK(TS_MEDIAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Stability_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A factor that focuses on the divergence between price trend and volume noise. It rewards stocks with positive 5-day returns that exhibit a 5-day volume CV that is lower than the 20-day median volume CV, signaling a transition into a more stable liquidity regime.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.331108",
      "updated_at": "2026-01-14T20:59:06.331114"
    },
    "562402034005b51a": {
      "factor_id": "562402034005b51a",
      "factor_name": "Decay_Weighted_Resistance_Exhaustion_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Decay_Weighted_Resistance_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by calculating the ratio of the distance from the 10-day high to a decay-weighted path length. The decay weighting prioritizes recent price volatility (effort), while the distance to high measures the result. This ratio is then scaled by the 10-day volume Z-score to isolate high-intensity exhaustion events.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.796121",
      "updated_at": "2026-01-14T21:08:05.796129"
    },
    "7744865b19c42ffe": {
      "factor_id": "7744865b19c42ffe",
      "factor_name": "Volatility_Adjusted_Decay_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Decay_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor enhances the resistance exhaustion signal by normalizing the distance to the 10-day high by the 10-day standard deviation of returns (volatility filter) and a decay-weighted sum of absolute returns. It targets stocks where recent 'churn' is high but price progress toward resistance is stalling, weighted by relative volume intensity.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.813949",
      "updated_at": "2026-01-14T21:08:05.813956"
    },
    "8978cd1625ebb519": {
      "factor_id": "8978cd1625ebb519",
      "factor_name": "Relative_Resistance_Decay_Surge_10D",
      "factor_expression": "ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Resistance_Decay_Surge_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the decay-weighted exhaustion factor that uses cross-sectional ranking to identify idiosyncratic outliers. It measures the failure to reach the 10-day high relative to recent price action intensity (decay-weighted), specifically during volume surges.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.831423",
      "updated_at": "2026-01-14T21:08:05.831429"
    },
    "7507c77f514565a6": {
      "factor_id": "7507c77f514565a6",
      "factor_name": "Relative_Efficiency_Decay_VWAP_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Efficiency_Decay_VWAP_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by measuring the divergence between a stock's current price relative to its 20-day Volume-Weighted Average Price (VWAP) and its relative efficiency decay. The efficiency decay is calculated as the ratio of the 5-day exponential moving average of returns to the 20-day standard deviation, normalized by the medium-term baseline to detect structural weakening.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.301854",
      "updated_at": "2026-01-14T21:18:16.301862"
    },
    "bbf0152f53011c07": {
      "factor_id": "bbf0152f53011c07",
      "factor_name": "VWAP_Extension_Churn_Index_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VWAP_Extension_Churn_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'churning' phases where price is extended from the volume-weighted cost basis but the risk-adjusted return (efficiency) is collapsing. It uses the ratio of the 5-day median return to the 20-day volatility to avoid noise from single-day spikes, identifying imminent mean-reversion when price extension is high but stability is low.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.320532",
      "updated_at": "2026-01-14T21:18:16.320538"
    },
    "2c26ba58e0190cfe": {
      "factor_id": "2c26ba58e0190cfe",
      "factor_name": "Volume_Weighted_Efficiency_Gap",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Efficiency_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies trend exhaustion by comparing the 20-day VWAP deviation with a 'Relative Efficiency' metric. The efficiency component uses the ratio of the 5-day sum of returns to the 20-day sum of absolute returns, capturing the loss of directional conviction relative to total price churn.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.338873",
      "updated_at": "2026-01-14T21:18:16.338879"
    }
  }
}