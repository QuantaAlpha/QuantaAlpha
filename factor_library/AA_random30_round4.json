{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.674906",
    "last_updated": "2026-01-17T02:02:58.674910",
    "total_factors": 23,
    "version": "1.0",
    "note": "Random 30 factors from round 4 (from all_factors_library_AA.json)"
  },
  "factors": {
    "2ced7731281f6246": {
      "factor_id": "2ced7731281f6246",
      "factor_name": "Stretched_Reversal_Divergence_10D",
      "factor_expression": "(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Stretched_Reversal_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by scaling the negative 10-day return by its 20-day volatility and multiplying it by the 5-day change in the price-volume correlation. This captures 'stretched' price moves where the relationship between price and volume is weakening, indicating trend exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.343160",
      "updated_at": "2026-01-14T17:12:56.343166"
    },
    "a539c30693a56101": {
      "factor_id": "a539c30693a56101",
      "factor_name": "Volatility_Scaled_Exhaustion_Rank",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Scaled_Exhaustion_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that ranks the intensity of a price reversal. It combines the 10-day return normalized by 20-day volatility with the momentum of the price-volume correlation. It targets stocks where price moves are extreme relative to volatility and conviction (volume-price link) is shifting.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.376043",
      "updated_at": "2026-01-14T17:12:56.376049"
    },
    "6411ef0aaf297143": {
      "factor_id": "6411ef0aaf297143",
      "factor_name": "ZScore_Reversal_Conviction_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Reversal_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 10-day reversal potential by calculating the Z-score of returns and weighting it by the change in price-volume correlation. It uses Z-scores to identify statistically significant 'stretched' moves and filters them by the divergence in volume flow conviction.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.408776",
      "updated_at": "2026-01-14T17:12:56.408783"
    },
    "befa3a7f6f097a80": {
      "factor_id": "befa3a7f6f097a80",
      "factor_name": "Vol_Adjusted_Price_Impact_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Price_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the ratio of 5-day cumulative return to the 5-day average volume, normalized by the 5-day standard deviation of volume. This normalization isolates high-conviction liquidity exhaustion by filtering out noisy volume spikes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.325818",
      "updated_at": "2026-01-14T17:30:23.325824"
    },
    "3fd5eeb189991af8": {
      "factor_id": "3fd5eeb189991af8",
      "factor_name": "Liquidity_Exhaustion_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the volatility-adjusted price impact per unit of volume. It divides the 5-day return by the coefficient of variation of volume over the same period to highlight 'fragile' price moves that occur on stable but low liquidity, signaling potential reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.359575",
      "updated_at": "2026-01-14T17:30:23.359581"
    },
    "d83bb851f311b99a": {
      "factor_id": "d83bb851f311b99a",
      "factor_name": "Robust_Price_Efficiency_Rank_5D",
      "factor_expression": "RANK((DELTA($close, 5) / $close) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Price_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the price-volume efficiency hypothesis. It uses the 5-day return divided by the 5-day median volume, further adjusted by the volume's 5-day standard deviation to ensure the signal is not driven by a single day's volume outlier.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.394693",
      "updated_at": "2026-01-14T17:30:23.394699"
    },
    "be56412e2f4c7223": {
      "factor_id": "be56412e2f4c7223",
      "factor_name": "VW_Efficiency_Squeeze_Tanh_10D",
      "factor_expression": "((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Squeeze_Tanh_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by interacting a squashed Volatility Squeeze Z-score with a Volume-Weighted Efficiency Ratio. The squeeze is calculated as the ratio of 20-day return volatility to the 10-day price range, normalized via TS_ZSCORE and bounded by a Tanh-like transformation to handle outliers. The Volume-Weighted Efficiency Ratio ensures that price movements are supported by significant trading activity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.297230",
      "updated_at": "2026-01-14T17:35:59.297237"
    },
    "c66ee9481bdf59cf": {
      "factor_id": "c66ee9481bdf59cf",
      "factor_name": "Robust_Squeeze_VWER_Interaction",
      "factor_expression": "RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VWER_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified interaction factor between a volatility compression metric and volume-weighted price efficiency. It uses a 10-day window for the squeeze and efficiency measures, applying a rank-based normalization to the squeeze intensity to ensure cross-sectional stability and combining it with a volume-scaled price velocity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.334867",
      "updated_at": "2026-01-14T17:35:59.334874"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T17:36:23.056545"
    },
    "06b6f311ac141eab": {
      "factor_id": "06b6f311ac141eab",
      "factor_name": "ZScored_Volume_Persistence_Divergence",
      "factor_expression": "(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Persistence_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the momentum divergence hypothesis that uses cross-sectional Z-scores to compare 15-day volume-weighted conviction against the 5-day price trend, ensuring the divergence signal is comparable across the universe before being scaled by the asset's relative volatility.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.092745",
      "updated_at": "2026-01-14T17:36:23.092750"
    },
    "79fbd5019fd5aa30": {
      "factor_id": "79fbd5019fd5aa30",
      "factor_name": "Smoothed_Momentum_Conviction_Ratio",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Momentum_Conviction_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the ratio of volume-supported persistence to short-term trend magnitude. By using the ratio instead of a difference, it identifies stocks where institutional conviction (15-day) significantly outweighs recent price action (5-day), normalized by the 20-day high-low range.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.128528",
      "updated_at": "2026-01-14T17:36:23.128535"
    },
    "a539ea5d667c40ef": {
      "factor_id": "a539ea5d667c40ef",
      "factor_name": "Smoothed_Stability_Accumulation_ZScore_3D",
      "factor_expression": "ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), DECAYLINEAR(SEQUENCE(20), 20), 20), 2)) + ZSCORE(TS_MEAN((WMA($close * $volume, 5) / (WMA($volume, 5) + 1e-8)) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5), 3))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Stability_Accumulation_ZScore_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR20) with a smoothed volume-price divergence ratio. WRSQR20 captures trend consistency by prioritizing recent price action through a linear decay. The divergence ratio (VWAP5/SMA5) is smoothed using a 3-day SMA to filter out idiosyncratic volume shocks. The two components are aggregated using cross-sectional Z-scores to ensure scale stability and reduce drawdown risk.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.092364",
      "updated_at": "2026-01-14T18:23:40.092371"
    },
    "a49365e40349aa7e": {
      "factor_id": "a49365e40349aa7e",
      "factor_name": "Robust_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Robust_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "To avoid duplicated sub-expressions while maintaining the hypothesis, this factor uses WMA (weighted moving average) for the volume-price divergence calculation instead of TS_SUM, and replaces the standard R-squared with a correlation between price and a time-sequence, smoothed by a 3-day window. It targets institutional accumulation by identifying where weighted average prices stay above simple averages during stable trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.131909",
      "updated_at": "2026-01-14T18:23:40.131915"
    },
    "8be05e4ee9f1457a": {
      "factor_id": "8be05e4ee9f1457a",
      "factor_name": "Decayed_Stability_Volume_Ratio",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Decayed_Stability_Volume_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor utilizes the ratio of the 5-day EMA of price to its 5-day SMA as a proxy for divergence, combined with a 20-day price stability measure. By using EMA in the divergence numerator, it places more weight on recent volume-driven price shifts. The final factor is the sum of the Z-scored stability and the smoothed divergence ratio to improve the Information Ratio.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.170205",
      "updated_at": "2026-01-14T18:23:40.170211"
    },
    "bdb78b063c6c4d5b": {
      "factor_id": "bdb78b063c6c4d5b",
      "factor_name": "VWRE10_Efficiency_Factor",
      "factor_expression": "TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWRE10_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 10-day Volume-Weighted Return Efficiency (VWRE10) factor identifies sustainable price trends by scaling the 10-day return by the inverse of the volume coefficient of variation. This prioritizes moves supported by high, stable liquidity, filtering out speculative spikes on erratic volume.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.490223",
      "updated_at": "2026-01-14T20:36:31.490230"
    },
    "b67247ca8bd6c992": {
      "factor_id": "b67247ca8bd6c992",
      "factor_name": "Ranked_Liquidity_Stability_Momentum_10D",
      "factor_expression": "RANK(TS_SUM($return, 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Liquidity_Stability_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 10-day price momentum with a cross-sectional rank of volume stability. It identifies stocks where the recent trend is backed by consistent institutional participation relative to the broader market, using the ratio of mean volume to volume standard deviation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.505921",
      "updated_at": "2026-01-14T20:36:31.505927"
    },
    "54e6425649423ec0": {
      "factor_id": "54e6425649423ec0",
      "factor_name": "ZScored_Volume_Efficiency_10D",
      "factor_expression": "ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the Volume-Weighted Return Efficiency factor. It applies a cross-sectional Z-score to the 10-day return scaled by the volume signal-to-noise ratio, ensuring the factor is robust across different market regimes and stock scales.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.521215",
      "updated_at": "2026-01-14T20:36:31.521220"
    },
    "ae40ea3dc6632f44": {
      "factor_id": "ae40ea3dc6632f44",
      "factor_name": "Price_Efficiency_Volume_Exhaustion_15D",
      "factor_expression": "(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (TS_ZSCORE($volume, 15) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (TS_ZSCORE($volume, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Volume_Exhaustion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score) coincide with low price efficiency. Price efficiency is the ratio of net displacement to the total path traveled. A low value indicates 'churning' (high effort, low result), signaling imminent trend reversal.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.113249",
      "updated_at": "2026-01-14T20:45:17.113256"
    },
    "e8e67ecb849a3d87": {
      "factor_id": "e8e67ecb849a3d87",
      "factor_name": "Volume_Surge_Efficiency_Divergence_15D",
      "factor_expression": "RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8)) / (RANK(TS_ZSCORE($volume, 15)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Efficiency_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the exhaustion hypothesis that uses the cross-sectional rank of price efficiency divided by the cross-sectional rank of volume Z-scores. It targets the non-linear nature of market exhaustion by identifying assets where the 'effort' (volume) is disproportionately high compared to the 'result' (price efficiency) relative to other stocks.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.129870",
      "updated_at": "2026-01-14T20:45:17.129876"
    },
    "563bf561c88c4e3f": {
      "factor_id": "563bf561c88c4e3f",
      "factor_name": "Churn_Intensity_Reversion_15D",
      "factor_expression": "TS_ZSCORE($volume, 15) * (TS_SUM(ABS(DELTA($close, 1)), 15) / (ABS(DELTA($close, 15)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume, 15) / (ABS(DELTA($close, 15)) / (TS_SUM(ABS(DELTA($close, 1)), 15) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Churn_Intensity_Reversion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures 'churn intensity' by calculating the ratio of the 15-day volume Z-score to the price efficiency. High churn (extreme volume with low efficiency) results in a high factor value, which is expected to predict negative future returns as it signals institutional distribution at a peak.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 15-day 'Price Efficiency-Volume Surge Divergence' factor identifies mean-reversion by detecting periods where extreme volume surges (Z-score > 2) coincide with low price efficiency (minimal net displacement relative to total path travel).\n                Concise Observation: Previous rank-based and linear models smoothed out the 'tail events' of market exhaustion; the 10-day window was slightly too short for stable trends, while 20-day metrics faced calculation robustness issues.\n                Concise Justification: Price Efficiency (Net Change / Sum of Absolute Changes) captures the 'quality' of a trend, while Volume Z-scores isolate the 'blow-off' intensity. Their interaction specifically targets the non-linear nature of exhaustion that simple rank spreads missed.\n                Concise Knowledge: If high volume (effort) fails to translate into significant price movement (result), the market is in a 'churning' phase; when volume Z-scores are extreme while price efficiency is low, it indicates institutional distribution and imminent trend reversal.\n                concise Specification: The factor calculates the 15-day Price Efficiency (abs(close - close_15) / sum(abs(return)_15)) divided by the 15-day Volume Z-Score ((volume - mean_volume_15) / std_volume_15). A low value (high volume surge + low efficiency) is expected to predict negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031638094667417,
        "ICIR": 0.0237305690647047,
        "RankIC": 0.0185437222759957,
        "RankICIR": 0.1439845771941868,
        "annualized_return": 0.0559620279033136,
        "information_ratio": 0.8752041657480297,
        "max_drawdown": -0.0985639764791649
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:17.146382",
      "updated_at": "2026-01-14T20:45:17.146388"
    },
    "e99c2ba0795b9e8a": {
      "factor_id": "e99c2ba0795b9e8a",
      "factor_name": "Volume_Adjusted_Exhaustion_Divergence_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Adjusted_Exhaustion_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies terminal trend exhaustion by measuring the divergence between price over-extension and volume-price efficiency. It calculates the product of the 10-day price residual (deviation from linear trend) and the negative 5-day slope of volume efficiency. Volume efficiency is defined as the absolute return per unit of relative volume. A high price residual combined with a declining volume efficiency suggests 'churning' at price extremes, signaling a potential reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.613072",
      "updated_at": "2026-01-14T20:55:45.613078"
    },
    "899e40ac86d91875": {
      "factor_id": "899e40ac86d91875",
      "factor_name": "Efficiency_Decay_Volume_Climax_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / TS_MEAN($volume, 20) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "",
      "factor_description": "This factor captures the 'conviction' dimension of trend exhaustion. It focuses on the interaction between price over-extension and the recent decay in price-volume efficiency. It identifies stocks where price is significantly above its 10-day trend while the 'result' (return) per 'effort' (volume) is diminishing over a 5-day window. The negative slope of efficiency acts as a lead indicator for liquidity exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.630266",
      "updated_at": "2026-01-14T20:55:45.630272"
    },
    "d39bc944ba333c67": {
      "factor_id": "d39bc944ba333c67",
      "factor_name": "NonLinear_Churn_Exhaustion_Index",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Churn_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'churning' phase of a trend where high volume fails to produce proportional price progress. It combines the 10-day price residual with the 5-day average of volume-adjusted price efficiency. By ranking both components, it highlights assets that are at extreme price deviations but showing the lowest relative efficiency in the cross-section, maximizing the probability of mean-reversion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.647215",
      "updated_at": "2026-01-14T20:55:45.647220"
    }
  }
}