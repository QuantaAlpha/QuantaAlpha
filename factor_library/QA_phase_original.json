{
  "metadata": {
    "created_at": "2026-01-17T12:00:22.241987",
    "last_updated": "2026-01-17T12:00:22.241994",
    "total_factors": 89,
    "version": "1.0",
    "source": "all_factors_library_10_10_10_best1_组合123_QA.json",
    "note": "evolution_phase为original的所有因子，保持原始顺序"
  },
  "factors": {
    "fdee666a2ba26e1d": {
      "factor_id": "fdee666a2ba26e1d",
      "factor_name": "ROC60_Low_Vol_Stability_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ROC60_Low_Vol_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by weighting the 60-day rate of change (ROC) by the inverse of the 5-day volume volatility. High ROC accompanied by low volume standard deviation suggests 'quiet' institutional exhaustion, increasing the probability of a reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.759435",
      "updated_at": "2026-01-17T01:28:06.759443"
    },
    "fe31eaba3ed86e19": {
      "factor_id": "fe31eaba3ed86e19",
      "factor_name": "Institutional_Accumulation_Reversal_5D",
      "factor_expression": "TS_PCTCHANGE($close, 60) * (1 - TS_ZSCORE(TS_STD($volume, 5), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 60) * (1 - TS_ZSCORE(TS_STD($volume, 5), 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction price trends by multiplying the 60-day price momentum with a stability filter. The filter uses the Z-score of the 5-day volume volatility to overweight stocks with steady (low-volatility) volume patterns, indicating institutional positioning.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.768275",
      "updated_at": "2026-01-17T01:28:06.768282"
    },
    "f167722533e1adb7": {
      "factor_id": "f167722533e1adb7",
      "factor_name": "Quiet_Trend_Exhaustion_Factor",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 60) / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 60) / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally normalized factor that targets stocks where the 60-day price momentum is extreme but the short-term volume volatility is minimal. It uses the ratio of momentum to volume volatility to highlight structural trends prone to mean-reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.777107",
      "updated_at": "2026-01-17T01:28:06.777114"
    },
    "552fa3c9d347569e": {
      "factor_id": "552fa3c9d347569e",
      "factor_name": "Vol_Adjusted_Residual_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Residual_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day price residual from a linear regression against time, normalized by the 5-day rolling standard deviation of daily returns. This normalization identifies overextended price movements relative to the asset's current volatility regime.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.383540",
      "updated_at": "2026-01-17T01:31:14.383548"
    },
    "ff0456dd0f1e862c": {
      "factor_id": "ff0456dd0f1e862c",
      "factor_name": "ZScore_Residual_Momentum_10D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Residual_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the volatility-adjusted residual using a 10-day window and cross-sectional Z-scoring. It measures how many standard deviations the current price deviates from its local trend, relative to other stocks in the universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.392740",
      "updated_at": "2026-01-17T01:31:14.392747"
    },
    "d3e961cf16cfa600": {
      "factor_id": "d3e961cf16cfa600",
      "factor_name": "Ranked_Vol_Residual_Ratio_20D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Vol_Residual_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a longer 20-day lookback for the trend residual and normalizes it by the 20-day volatility. The final value is cross-sectionally ranked to provide a robust signal for mean reversion that is less sensitive to extreme outliers in high-volatility environments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.401839",
      "updated_at": "2026-01-17T01:31:14.401845"
    },
    "e8c8d125e900c078": {
      "factor_id": "e8c8d125e900c078",
      "factor_name": "Price_Volume_Divergence_Momentum_Filter",
      "factor_expression": "TS_CORR($close, $volume, 20) * (($close / (DELAY($close, 60) + 1e-8)) > 1.2 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (($close / (DELAY($close, 60) + 1e-8)) > 1.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Divergence_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures mean-reversion opportunities by identifying assets where price and volume are negatively correlated over a 20-day window, filtered by a 60-day price momentum threshold. A negative correlation in a downtrend suggests selling exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.414416",
      "updated_at": "2026-01-17T01:33:55.414423"
    },
    "361cf565a18c2fb8": {
      "factor_id": "361cf565a18c2fb8",
      "factor_name": "Exhaustion_Regime_Indicator_20_60",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * TS_PCTCHANGE($close, 60)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * TS_PCTCHANGE($close, 60)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Regime_Indicator_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies a specific market regime where price trend lacks volume support. It uses the rank of the 20-day price-volume correlation and scales it by a long-term 60-day relative price change to highlight potential reversal points in overextended or distressed assets.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.423623",
      "updated_at": "2026-01-17T01:33:55.423629"
    },
    "62b2bd1a32c42d0d": {
      "factor_id": "62b2bd1a32c42d0d",
      "factor_name": "Volume_Decoupled_Mean_Reversion",
      "factor_expression": "TS_ZSCORE(TS_CORR($close, $volume, 20), 60)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR($close, $volume, 20), 60) * ((TS_MAX($high, 60) - TS_MIN($low, 60)) / (TS_MEAN($close, 60) + 1e-8) > 0.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Volume_Decoupled_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the decoupling of price and volume. It calculates the 20-day correlation between price and volume and applies a conditional check on the 60-day price range. It aims to detect when a price move is losing liquidity support, signaling a potential trend shift.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.432925",
      "updated_at": "2026-01-17T01:33:55.432932"
    },
    "1ef674e9335a5506": {
      "factor_id": "1ef674e9335a5506",
      "factor_name": "Intraday_Support_Persistence_3D",
      "factor_expression": "RANK(TS_MEAN($low / ($high + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($low / ($high + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Support_Persistence_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of intraday support by calculating the 3-day average of the ratio between the daily low and the daily high. A higher ratio indicates that the daily price floor is consistently near the daily ceiling, suggesting strong structural buying pressure and shallow retracements.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:31.996149",
      "updated_at": "2026-01-17T01:35:31.996156"
    },
    "aff3a44a82d9f6c2": {
      "factor_id": "aff3a44a82d9f6c2",
      "factor_name": "Relative_Low_Position_Stability_5D",
      "factor_expression": "RANK(TS_MEAN(($low - $low + 0.01) / (($high - $low) / $open + 0.01), 5))",
      "factor_implementation_code": "",
      "factor_description": "This factor captures the stability of the price floor by measuring the 5-day average of the low price's position relative to the daily range (high - low). It uses a slightly longer window than the 3-day version to capture more robust structural support while normalizing by the intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:32.005454",
      "updated_at": "2026-01-17T01:35:32.005459"
    },
    "dbdfe2963b41ca0d": {
      "factor_id": "dbdfe2963b41ca0d",
      "factor_name": "Support_Level_ZScore_3D",
      "factor_expression": "ZSCORE(TS_MEAN($low / ($high + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($low / ($high + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Support_Level_ZScore_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks where the current intraday low is significantly higher than its historical average relative to the high, normalized by the cross-sectional distribution. It highlights abnormal strength in the price floor.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:32.014723",
      "updated_at": "2026-01-17T01:35:32.014729"
    },
    "f099da69a9738d69": {
      "factor_id": "f099da69a9738d69",
      "factor_name": "Delta_RESI_5D_Acceleration",
      "factor_expression": "DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Delta_RESI_5D_Acceleration\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day difference of the Relative Strength Intensity (RESI), where RESI is the ratio of the 5-day price range (highest high to lowest low) to the absolute 5-day price change. A sharp increase in this ratio indicates that price volatility is expanding much faster than directional displacement, signaling potential trend exhaustion and mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.915433",
      "updated_at": "2026-01-17T01:38:33.915439"
    },
    "731124529417b326": {
      "factor_id": "731124529417b326",
      "factor_name": "Ranked_RESI_Volatility_Exhaustion",
      "factor_expression": "RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_RESI_Volatility_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Delta-RESI factor. It identifies stocks experiencing the most extreme acceleration in price range relative to net displacement. High values suggest 'blow-off' phases where price movement becomes inefficient, increasing the probability of a short-term reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.924868",
      "updated_at": "2026-01-17T01:38:33.924874"
    },
    "0ac2b03eccbd1e52": {
      "factor_id": "0ac2b03eccbd1e52",
      "factor_name": "Smoothed_RESI_Efficiency_Gap",
      "factor_expression": "SMA(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5), 3, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SMA(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5), 3, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_RESI_Efficiency_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a simple moving average to the Delta-RESI calculation to filter out daily noise and isolate sustained acceleration in volatility extremes. It focuses on the inefficiency of price movement over a short window to predict mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.934465",
      "updated_at": "2026-01-17T01:38:33.934470"
    },
    "6cbededfd2d1673b": {
      "factor_id": "6cbededfd2d1673b",
      "factor_name": "Risk_Adj_Momentum_Vol_Stab_60D",
      "factor_expression": "(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) * INV(TS_STD($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 60) / TS_STD(TS_PCTCHANGE($close, 1), 20)) * INV(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Risk_Adj_Momentum_Vol_Stab_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the risk-adjusted momentum (60-day price change divided by 20-day return volatility) and scales it by the inverse of short-term volume volatility. High values indicate a strong, stable price trend accompanied by consistent trading volume, suggesting institutional quality trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.797529",
      "updated_at": "2026-01-17T01:38:36.797535"
    },
    "4954e8114853e7d1": {
      "factor_id": "4954e8114853e7d1",
      "factor_name": "Ranked_Quality_Momentum_Volume_Stability",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Quality_Momentum_Volume_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the risk-adjusted momentum hypothesis. It combines the rank of 60-day momentum normalized by 20-day volatility with the rank of the inverse 5-day volume volatility to identify assets with the most 'orderly' uptrends relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.807169",
      "updated_at": "2026-01-17T01:38:36.807175"
    },
    "5e44428625b9cb8c": {
      "factor_id": "5e44428625b9cb8c",
      "factor_name": "Zscored_Trend_Persistence_Factor",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 60), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "",
      "factor_description": "This factor applies a Z-score to the 60-day return and divides it by the 20-day return standard deviation, then filters the result by the stability of volume. It aims to isolate high-conviction trends where price growth is statistically significant and volume noise is minimal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.816637",
      "updated_at": "2026-01-17T01:38:36.816643"
    },
    "85da7ff1dec67c97": {
      "factor_id": "85da7ff1dec67c97",
      "factor_name": "Lower_Shadow_Vwap_Reversal_1D",
      "factor_expression": "((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ((($open + $high + $low + $close) / 4) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ((($open + $high + $low + $close) / 4) / ($close + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Lower_Shadow_Vwap_Reversal_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by combining the relative length of the lower shadow with a volume-weighted price deviation. A long lower shadow (KLOW) indicates intraday price rejection, and when combined with a VWAP that is higher than the close price, it suggests institutional support at lower levels.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.760937",
      "updated_at": "2026-01-17T01:40:44.760945"
    },
    "93c985c2b203733a": {
      "factor_id": "93c985c2b203733a",
      "factor_name": "High_Conviction_Support_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 5))\" # Your output factor expression will be filled in here\n    name = \"High_Conviction_Support_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor smooths the intraday support signal over a 5-day window and applies a cross-sectional rank. It captures stocks consistently showing strong price rejection at lows relative to their volume-weighted average price, indicating high-conviction accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.771080",
      "updated_at": "2026-01-17T01:40:44.771088"
    },
    "85a9f9a96cbf1421": {
      "factor_id": "85a9f9a96cbf1421",
      "factor_name": "Volume_Weighted_Shadow_ZScore_10D",
      "factor_expression": "TS_ZSCORE(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Shadow_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the lower shadow conviction signal using a 10-day time-series Z-score. It highlights days where the intraday price rejection and VWAP-to-Close ratio are significantly higher than their recent historical norm, signaling an exhaustion of selling pressure.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.782036",
      "updated_at": "2026-01-17T01:40:44.782044"
    },
    "9490425d06133280": {
      "factor_id": "9490425d06133280",
      "factor_name": "Linear_Trend_Volume_Divergence_10D",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8)) * (-1 * TS_CORR($return, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend exhaustion by multiplying the linearity of the price trend (RSQR) with the negative correlation between returns and volume. High linearity combined with volume-price divergence suggests the trend is losing structural support.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.339434",
      "updated_at": "2026-01-17T01:43:23.339444"
    },
    "7bcced8c81d75b33": {
      "factor_id": "7bcced8c81d75b33",
      "factor_name": "Trend_Exhaustion_Signal_20D",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(20), 20), 2) * TS_VAR(SEQUENCE(20), 20) / (TS_VAR($close, 20) + 1e-8)) * SIGN(-1 * TS_CORR($return, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * SIGN(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the trend exhaustion hypothesis using a 20-day window. It captures the interaction between price trend stability and the decoupling of volume, where a negative correlation between volume and price changes indicates a lack of conviction in the prevailing trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.367826",
      "updated_at": "2026-01-17T01:43:23.367834"
    },
    "ee1e2d324e285027": {
      "factor_id": "ee1e2d324e285027",
      "factor_name": "Cross_Sectional_Divergence_Rank_15D",
      "factor_expression": "RANK(POW(REGBETA($close, SEQUENCE(15), 15), 2) * TS_VAR(SEQUENCE(15), 15) / (TS_VAR($close, 15) + 1e-8)) * RANK(-1 * TS_CORR($return, $volume, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(15), 15), 2)) * RANK(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Divergence_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price-volume divergence relative to the market, weighted by the linearity of the 15-day price trend. It highlights stocks where the trend is most likely to reverse due to a significant drop in volume support during price moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.396155",
      "updated_at": "2026-01-17T01:43:23.396163"
    },
    "b63263adb82f671c": {
      "factor_id": "b63263adb82f671c",
      "factor_name": "VWAP_Volume_Corr_20D",
      "factor_expression": "TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Volume_Corr_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the 20-day Pearson correlation between the daily Volume-Weighted Average Price (approximated by the average of OHLC) and daily trading volume. High positive correlation suggests institutional accumulation during high-liquidity periods.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.506484",
      "updated_at": "2026-01-17T01:45:05.506490"
    },
    "6ad5cfcd459fa7af": {
      "factor_id": "6ad5cfcd459fa7af",
      "factor_name": "Ranked_VWAP_Volume_Conviction_10D",
      "factor_expression": "RANK(TS_CORR(($open + $high + $low + $close) / 4, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(($open + $high + $low + $close) / 4, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_VWAP_Volume_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of the correlation between the daily average price (VWAP proxy) and volume over a 10-day window. Ranking the correlation helps identify stocks with the strongest institutional conviction relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.516600",
      "updated_at": "2026-01-17T01:45:05.516605"
    },
    "3ec21ce3831ff95e": {
      "factor_id": "3ec21ce3831ff95e",
      "factor_name": "VWAP_Volume_Trend_ZScore_20D",
      "factor_expression": "TS_ZSCORE(TS_CORR(($open + $high + $low + $close) / 4, $volume, 20), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(($open + $high + $low + $close) / 4, $volume, 20), 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Volume_Trend_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Standardizes the 20-day VWAP-Volume correlation using a time-series Z-score. This identifies periods where the institutional accumulation signal is significantly stronger or weaker than its own historical average, providing a signal of trend acceleration.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.527381",
      "updated_at": "2026-01-17T01:45:05.527388"
    },
    "931b61570e9c62ec": {
      "factor_id": "931b61570e9c62ec",
      "factor_name": "Low_Vol_Regime_Residual_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) * (TS_STD($close, 5) < TS_STD($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) * (TS_STD($close, 5) < TS_STD($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Regime_Residual_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures mean reversion signals by calculating the 5-day price residual against a linear trend, specifically filtering for regimes where short-term volatility (5-day) is lower than long-term volatility (20-day). This identifies stable environments where price deviations are more likely to be temporary inefficiencies.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.658937",
      "updated_at": "2026-01-17T01:46:16.658944"
    },
    "9583a1d6192db0b5": {
      "factor_id": "9583a1d6192db0b5",
      "factor_name": "Ranked_Stable_Mean_Reversion_5D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stable_Mean_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the short-term residual factor, conditioned on a low-volatility ratio. It uses the ratio of 5-day to 20-day volatility as a weight for the 5-day price residual, emphasizing mean reversion in stocks with the most 'quiet' price action relative to their historical norm.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.669801",
      "updated_at": "2026-01-17T01:46:16.669808"
    },
    "9e4d99df124567c1": {
      "factor_id": "9e4d99df124567c1",
      "factor_name": "Conditional_Residual_ZScore_5D",
      "factor_expression": "(TS_STD($close, 5) < TS_STD($close, 20)) ? TS_ZSCORE(REGRESI($close, SEQUENCE(5), 5), 10) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($close, 5) < TS_STD($close, 20)) ? TS_ZSCORE(REGRESI($close, SEQUENCE(5), 5), 10) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Residual_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the 5-day price residual into a Z-score and applies a hard filter. If the short-term volatility is higher than the long-term volatility, the factor returns zero to avoid 'falling knife' scenarios; otherwise, it returns the standardized residual to signal mean reversion strength.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.680020",
      "updated_at": "2026-01-17T01:46:16.680026"
    },
    "517c0b2db1b4818e": {
      "factor_id": "517c0b2db1b4818e",
      "factor_name": "MSLVR_ROC_Interaction_60D",
      "factor_expression": "(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * ($close / (DELAY($close, 60) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * ($close / (DELAY($close, 60) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"MSLVR_ROC_Interaction_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the Multi-Scale Liquidity Volatility Ratio (MSLVR) to modulate the 60-day Rate of Change (ROC). It captures the hypothesis that medium-term momentum reliability decreases when short-term volume volatility (5-day) significantly deviates from long-term volume volatility (60-day).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.350423",
      "updated_at": "2026-01-17T01:49:23.350431"
    },
    "cc8f4864f664a886": {
      "factor_id": "cc8f4864f664a886",
      "factor_name": "Ranked_MSLVR_Momentum_Signal",
      "factor_expression": "RANK(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * RANK(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * RANK(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Ranked_MSLVR_Momentum_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the MSLVR-modulated momentum. By ranking the ratio and the price change separately before multiplication, the factor becomes more robust to outliers in volume spikes and price gaps while maintaining the regime-switching logic.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.361079",
      "updated_at": "2026-01-17T01:49:23.361085"
    },
    "2b13a01bedaeed68": {
      "factor_id": "2b13a01bedaeed68",
      "factor_name": "ZScore_MSLVR_Inversion_Factor",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8), 20) * TS_PCTCHANGE($close, 60)",
      "factor_implementation_code": "",
      "factor_description": "This factor uses the Z-score of the volume volatility ratio to identify extreme liquidity shifts. It assumes that when the 5-day volume volatility is extremely high relative to its 60-day history, the 60-day momentum is likely to mean-revert or stall.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.371604",
      "updated_at": "2026-01-17T01:49:23.371611"
    },
    "8dfd2563d1c47f9f": {
      "factor_id": "8dfd2563d1c47f9f",
      "factor_name": "Asymmetric_Shadow_Volatility_Regime_5D",
      "factor_expression": "(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Shadow_Volatility_Regime_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by calculating the ratio of the lower shadow length to the total daily range, specifically during periods of high 5-day price volatility. A high ratio in a high-volatility environment suggests exhaustive selling pressure and intraday price rejection.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.387299",
      "updated_at": "2026-01-17T01:49:29.387306"
    },
    "f55b990d4989ce20": {
      "factor_id": "f55b990d4989ce20",
      "factor_name": "Normalized_Lower_Shadow_Reversal_10D",
      "factor_expression": "ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ZSCORE(TS_STD($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ZSCORE(TS_STD($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Lower_Shadow_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the asymmetric shadow ratio that uses the 10-day rolling median of the shadow ratio to identify extreme intraday rejections relative to recent history, weighted by the cross-sectional rank of historical volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.397872",
      "updated_at": "2026-01-17T01:49:29.397878"
    },
    "5024667fb96dc362": {
      "factor_id": "5024667fb96dc362",
      "factor_name": "Shadow_Exhaustion_Intensity_5D",
      "factor_expression": "(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Shadow_Exhaustion_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of the lower shadow relative to the candle body, conditioned on the stock being in a high-volatility state. It focuses on the 'Hammer' strength by comparing the lower shadow to the absolute price movement between open and close.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.408278",
      "updated_at": "2026-01-17T01:49:29.408284"
    },
    "02c7c583868e4030": {
      "factor_id": "02c7c583868e4030",
      "factor_name": "Price_Volume_Trend_Divergence_10D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Trend_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price momentum and volume-weighted momentum over a 10-day period. It calculates the difference between the cross-sectional rank of the 10-day price change and the cross-sectional rank of the 10-day RSI (Relative Strength Index). A high divergence suggests the price trend is exhausted and likely to undergo mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.133648",
      "updated_at": "2026-01-17T01:52:41.133655"
    },
    "0d21fba9d1db2f28": {
      "factor_id": "0d21fba9d1db2f28",
      "factor_name": "VW_Momentum_Exhaustion_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE(TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE(TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price-volume exhaustion by comparing the 10-day price return rank against the rank of the 10-day volume-weighted average price (VWAP) momentum. It uses the residual of price changes not explained by volume trends to signal potential reversals.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.144355",
      "updated_at": "2026-01-17T01:52:41.144361"
    },
    "d227acabb1805dc1": {
      "factor_id": "d227acabb1805dc1",
      "factor_name": "Relative_Strength_Divergence_ZScore",
      "factor_expression": "ZSCORE(RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the standardized divergence between price returns and the Relative Strength Index (RSI). By taking the Z-score of the difference between price return ranks and RSI ranks over 10 days, it highlights extreme cases where price action is decoupled from technical strength, indicating high reversal probability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.154827",
      "updated_at": "2026-01-17T01:52:41.154832"
    },
    "f0ba63507298d9b8": {
      "factor_id": "f0ba63507298d9b8",
      "factor_name": "PV_Conviction_Momentum_20_5",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"PV_Conviction_Momentum_20_5\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction momentum by calculating the product of the 20-day price-volume correlation and the 5-day volume volatility. A positive correlation combined with high volume dispersion suggests that the price trend is supported by intense information arrival and strong market consensus.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.974850",
      "updated_at": "2026-01-17T01:54:48.974856"
    },
    "cd7ac8d6736c5188": {
      "factor_id": "cd7ac8d6736c5188",
      "factor_name": "Normalized_PV_Synchrony_Intensity",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_PV_Synchrony_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume synchrony hypothesis that normalizes volume volatility by its 20-day average to capture relative intensity. It scales the 20-day price-volume correlation by the ratio of short-term volume volatility to long-term volume volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.985842",
      "updated_at": "2026-01-17T01:54:48.985848"
    },
    "55fd720195d71924": {
      "factor_id": "55fd720195d71924",
      "factor_name": "ZScored_PV_Momentum_Signal",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"ZScored_PV_Momentum_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a cross-sectional Z-score to the price-volume correlation and volume volatility components independently before multiplication. This ensures that both the direction (correlation) and the intensity (volatility) contribute equally to the final high-conviction momentum signal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.997555",
      "updated_at": "2026-01-17T01:54:48.997561"
    },
    "74b6a7c467babff2": {
      "factor_id": "74b6a7c467babff2",
      "factor_name": "Gap_Support_Ratio_10D",
      "factor_expression": "($open - DELAY($close, 1)) / (ABS($low - $open) + 0.001 * TS_STD($close, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) / ((ABS($low - MIN($open, $close)) + 1e-8) / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Support_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the overnight gap to the lower shadow length, normalized by the 10-day price volatility. It aims to identify if an overnight shock is supported by intraday price action. A high ratio with a small lower shadow suggests strong conviction, while a large lower shadow suggests a lack of support.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.386343",
      "updated_at": "2026-01-17T01:55:36.386351"
    },
    "cc4e28bbaa236de6": {
      "factor_id": "cc4e28bbaa236de6",
      "factor_name": "Normalized_Overnight_Intraday_Support_Z",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Overnight_Intraday_Support_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the intraday lower shadow, cross-sectionally normalized. It captures the 'shock magnitude' vs 'support distance' hypothesis by comparing the jump from previous close to the subsequent intraday floor.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.397370",
      "updated_at": "2026-01-17T01:55:36.397376"
    },
    "8080ce5352833969": {
      "factor_id": "8080ce5352833969",
      "factor_name": "Smoothed_Gap_To_Shadow_Efficiency",
      "factor_expression": "TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Gap_To_Shadow_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A smoothed version of the gap-to-lower-shadow ratio using a 5-day moving average. It filters out daily noise to identify stocks where overnight gaps consistently show high intraday support (minimal lower shadows).",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.408199",
      "updated_at": "2026-01-17T01:55:36.408206"
    },
    "e67d674b23a7a53e": {
      "factor_id": "e67d674b23a7a53e",
      "factor_name": "Exp_Decay_Momentum_60D",
      "factor_expression": "EMA($return, 19)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(TS_PCTCHANGE($close, 1), 60)\" # Your output factor expression will be filled in here\n    name = \"Exp_Decay_Momentum_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A 60-day price momentum factor weighted by an exponential decay function. It uses the EMA function to approximate the weighted sum of returns, where more recent returns have a higher impact on the factor value, effectively capturing trend acceleration while filtering out older noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.677890",
      "updated_at": "2026-01-17T01:58:21.677903"
    },
    "8336f343c9f54590": {
      "factor_id": "8336f343c9f54590",
      "factor_name": "ZScore_Decay_Momentum_60D",
      "factor_expression": "ZSCORE(EMA($return, 19))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(EMA(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Decay_Momentum_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the exponentially weighted 60-day momentum by its cross-sectional volatility. By applying ZSCORE to the EMA of returns, it identifies stocks with the strongest recent momentum relative to the market, adjusted for the decay of older price information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.689291",
      "updated_at": "2026-01-17T01:58:21.689297"
    },
    "30f6c97b79f08892": {
      "factor_id": "30f6c97b79f08892",
      "factor_name": "Decay_Momentum_Volatility_Ratio",
      "factor_expression": "EMA($return, 19) / (TS_STD($return, 60) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(TS_PCTCHANGE($close, 1), 19) / (TS_STD(TS_PCTCHANGE($close, 1), 60) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Decay_Momentum_Volatility_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of exponentially decayed momentum to the 60-day price volatility. It aims to capture risk-adjusted recent momentum, ensuring that the trend acceleration is not merely a result of high idiosyncratic volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.700299",
      "updated_at": "2026-01-17T01:58:21.700304"
    },
    "8a4591d5ab6206a4": {
      "factor_id": "8a4591d5ab6206a4",
      "factor_name": "Cross_Sectional_Residual_Momentum_5D",
      "factor_expression": "RANK(TS_SUM($return - MEAN($return), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Residual_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day accumulated idiosyncratic return by subtracting the cross-sectional mean return (market proxy) from individual stock returns. The resulting residual is ranked cross-sectionally to identify stocks with significant firm-specific price dislocations.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.663430",
      "updated_at": "2026-01-17T02:01:26.663437"
    },
    "2974bff508b08b79": {
      "factor_id": "2974bff508b08b79",
      "factor_name": "ZScored_Idiosyncratic_Shock_5D",
      "factor_expression": "RANK(TS_SUM(ZSCORE($return), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM(ZSCORE(TS_PCTCHANGE($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Idiosyncratic_Shock_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the intensity of stock-specific price movements relative to the market by calculating the 5-day sum of cross-sectionally standardized return residuals. It helps identify assets experiencing extreme idiosyncratic shocks that are likely to mean-revert or trend independently.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.674794",
      "updated_at": "2026-01-17T02:01:26.674800"
    },
    "8e606b3d410c86e0": {
      "factor_id": "8e606b3d410c86e0",
      "factor_name": "Residual_Volatility_Adjusted_Momentum_5D",
      "factor_expression": "RANK(TS_SUM($return - MEAN($return), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 5) / TS_STD(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 20))\" # Your output factor expression will be filled in here\n    name = \"Residual_Volatility_Adjusted_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the idiosyncratic signal by dividing the 5-day sum of market-neutral residuals by their time-series standard deviation. This normalization ensures that the signal is not dominated by high-volatility stocks, focusing on consistent firm-specific trends.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.685880",
      "updated_at": "2026-01-17T02:01:26.685886"
    },
    "798c3c97bde13834": {
      "factor_id": "798c3c97bde13834",
      "factor_name": "ROC60_PV_CORR20_Rank_Product",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ROC60_PV_CORR20_Rank_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies assets with both strong long-term momentum and high price-volume synchronization. It calculates the 60-day rate of change and the 20-day correlation between price and volume, then combines their cross-sectional ranks to isolate high-conviction recovery trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.970694",
      "updated_at": "2026-01-17T02:03:45.970701"
    },
    "347805446ee512ab": {
      "factor_id": "347805446ee512ab",
      "factor_name": "Clean_Momentum_Recovery_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($return, DELTA($volume, 1), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Clean_Momentum_Recovery_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume interaction hypothesis that focuses on the stability of returns relative to volume. It uses the 60-day price change and the 20-day correlation between daily returns and volume changes to filter for assets where price appreciation is consistently supported by volume flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.982125",
      "updated_at": "2026-01-17T02:03:45.982131"
    },
    "b398c32f51f40314": {
      "factor_id": "b398c32f51f40314",
      "factor_name": "ZScore_Momentum_Volume_Stability",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 60)) + ZSCORE(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 60)) + ZSCORE(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Volume_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses cross-sectional Z-scores to combine long-term momentum (60 days) and short-term price-volume correlation (20 days). By summing the Z-scores, it identifies assets that are outliers in both momentum and trend 'cleanliness' simultaneously.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.993489",
      "updated_at": "2026-01-17T02:03:45.993494"
    },
    "58eded43038c1180": {
      "factor_id": "58eded43038c1180",
      "factor_name": "Coiled_Spring_Compression_5D",
      "factor_expression": "RANK(($low - $open) / ($high - $low + 1e-8) * (1 / (TS_MEAN($high - $low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($low - $open) / ($high - $low + 1e-8) * (1 / (TS_MEAN($high - $low, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Coiled_Spring_Compression_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'coiled' price action by measuring the relative position of the daily low within the price range, weighted by the inverse of the 5-day average range. A high value indicates that the low is near the open/close (support) while volatility is shrinking, suggesting potential energy accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.707923",
      "updated_at": "2026-01-17T02:04:05.707930"
    },
    "e0cbcb061fcab14f": {
      "factor_id": "e0cbcb061fcab14f",
      "factor_name": "Volatility_Adjusted_Low_Support_10D",
      "factor_expression": "ZSCORE(($low - $open) / ($close * TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($low - $open) / ($close * TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Low_Support_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price compression by dividing the intraday support level (distance of low from open) by the 10-day historical volatility. It targets stocks where downside movement is restricted relative to historical price swings, normalized by the close price for cross-sectional stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.719599",
      "updated_at": "2026-01-17T02:04:05.719604"
    },
    "e8b47be6a786d40e": {
      "factor_id": "e8b47be6a786d40e",
      "factor_name": "Price_Range_Quantile_Support",
      "factor_expression": "RANK($low - $open) * (1 - TS_RANK($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($low - $open) * (1 - TS_RANK($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Range_Quantile_Support\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the coiled spring hypothesis that uses the 20-day range quantile to identify periods of low volatility (compression) and combines it with the intraday low's position relative to the open price.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.730918",
      "updated_at": "2026-01-17T02:04:05.730924"
    },
    "f7a2decd56930628": {
      "factor_id": "f7a2decd56930628",
      "factor_name": "Neutralized_Volume_Stability_5D",
      "factor_expression": "TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Neutralized_Volume_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day rolling standard deviation of volume to measure liquidity volatility, then subtracts the cross-sectional median to isolate idiosyncratic liquidity stability from market-wide noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.533818",
      "updated_at": "2026-01-17T02:06:12.533825"
    },
    "8345b03447c1e9c8": {
      "factor_id": "8345b03447c1e9c8",
      "factor_name": "Ranked_Idiosyncratic_Volume_Volatility_5D",
      "factor_expression": "RANK(TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Idiosyncratic_Volume_Volatility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of volume stability that first normalizes volume by its 20-day mean to handle scale differences, then calculates the 5-day volatility and applies cross-sectional ranking to identify stocks with extreme idiosyncratic liquidity shifts.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.545813",
      "updated_at": "2026-01-17T02:06:12.545819"
    },
    "008c300685deb3c0": {
      "factor_id": "008c300685deb3c0",
      "factor_name": "Relative_Liquidity_Stability_ZScore",
      "factor_expression": "ZSCORE(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Relative_Liquidity_Stability_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of a stock's 5-day volume volatility from the cross-sectional average, normalized by the cross-sectional standard deviation (Z-score), to identify significant liquidity exhaustion or accumulation phases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.557741",
      "updated_at": "2026-01-17T02:06:12.557748"
    },
    "8a9467859f0082d5": {
      "factor_id": "8a9467859f0082d5",
      "factor_name": "Fragility_Adjusted_Momentum_15D",
      "factor_expression": "TS_PCTCHANGE($close, 10) / (TS_STD(TS_CORR($close, SEQUENCE(10), 10), 15) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) / (TS_STD(TS_CORR($close, SEQUENCE(10), 10), 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Fragility_Adjusted_Momentum_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that scales the 10-day price return by the inverse of the R-squared volatility. It penalizes returns that occur during periods of erratic trend fitting, highlighting more 'stable' and reliable price movements.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, defined as the rolling 20-day standard deviation of the R-squared of a 10-day price linear regression, identifies impending trend reversals or regime shifts by quantifying the instability of trend persistence.\n                Concise Observation: Stable trends exhibit consistently high RSQR values with low variance, whereas maturing or failing trends often show erratic shifts in their linear fit before a significant price correction occurs.\n                Concise Justification: High variance in the goodness-of-fit metric (RSQR) suggests that the market's consensus on a directional move is fracturing, making the current trend 'fragile' and susceptible to noise or reversal.\n                Concise Knowledge: If the explanatory power of a linear trend (RSQR) fluctuates significantly, the prevailing market regime is becoming unstable; when this volatility peaks, the probability of a price reversal or a transition to a chaotic state increases.\n                concise Specification: Calculate the R-squared of $close against a time index over a 10-day sliding window, then compute the standard deviation of these R-squared values over a subsequent 20-day rolling period to output a single fragility score per instrument.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "original",
      "trajectory_id": "a74fc4f80eac",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005018283953464,
        "ICIR": 0.0334861927387632,
        "RankIC": 0.0215933859933432,
        "RankICIR": 0.1469933123286931,
        "annualized_return": 0.0803909023026703,
        "information_ratio": 1.0205138841727537,
        "max_drawdown": -0.095441911859979
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.515364",
      "updated_at": "2026-01-17T02:08:33.515372"
    },
    "c51dd08ee3b5d8e1": {
      "factor_id": "c51dd08ee3b5d8e1",
      "factor_name": "Relative_Trend_Stability_Rank",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) - TS_MEDIAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2) - TS_MEDIAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Trend_Stability_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor compares the current goodness-of-fit (R-squared) of a 10-day trend against its 20-day historical median, normalized by its volatility. It identifies stocks where the trend is becoming significantly more or less stable relative to its own recent history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, defined as the rolling 20-day standard deviation of the R-squared of a 10-day price linear regression, identifies impending trend reversals or regime shifts by quantifying the instability of trend persistence.\n                Concise Observation: Stable trends exhibit consistently high RSQR values with low variance, whereas maturing or failing trends often show erratic shifts in their linear fit before a significant price correction occurs.\n                Concise Justification: High variance in the goodness-of-fit metric (RSQR) suggests that the market's consensus on a directional move is fracturing, making the current trend 'fragile' and susceptible to noise or reversal.\n                Concise Knowledge: If the explanatory power of a linear trend (RSQR) fluctuates significantly, the prevailing market regime is becoming unstable; when this volatility peaks, the probability of a price reversal or a transition to a chaotic state increases.\n                concise Specification: Calculate the R-squared of $close against a time index over a 10-day sliding window, then compute the standard deviation of these R-squared values over a subsequent 20-day rolling period to output a single fragility score per instrument.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "original",
      "trajectory_id": "a74fc4f80eac",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005018283953464,
        "ICIR": 0.0334861927387632,
        "RankIC": 0.0215933859933432,
        "RankICIR": 0.1469933123286931,
        "annualized_return": 0.0803909023026703,
        "information_ratio": 1.0205138841727537,
        "max_drawdown": -0.095441911859979
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.528412",
      "updated_at": "2026-01-17T02:08:33.528419"
    },
    "dab6d997ce232f8b": {
      "factor_id": "dab6d997ce232f8b",
      "factor_name": "Gap_Over_Intraday_Volatility_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($open / DELAY($close, 1) - 1), 5) / (TS_MEAN(($high - $low) / ($open + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open / DELAY($close, 1) - 1), 5) / (TS_MEAN(($high - $low) / ($open + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Over_Intraday_Volatility_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the relative intensity of the overnight gap volatility compared to intraday volatility. According to the hypothesis, high overnight gaps relative to intraday price action suggest liquidity-induced overreactions that are prone to mean-reversion. A higher ratio indicates a potential reversal in the next session.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.445671",
      "updated_at": "2026-01-17T02:11:31.445678"
    },
    "0ab014079f0136ed": {
      "factor_id": "0ab014079f0136ed",
      "factor_name": "ZScore_Gap_Mean_Reversion_3D",
      "factor_expression": "-1 * ZSCORE(TS_MEAN(ABS($open / DELAY($close, 1) - 1), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ZSCORE(TS_MEAN(ABS($open / DELAY($close, 1) - 1), 3))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Gap_Mean_Reversion_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the cross-sectional intensity of the overnight gap normalized by its recent volatility. It targets the hypothesis that extreme overnight shocks (gaps) represent noise and behavioral biases. By applying ZSCORE cross-sectionally, it identifies stocks with the most significant 'jumps' relative to the market, which are expected to revert.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.458990",
      "updated_at": "2026-01-17T02:11:31.458997"
    },
    "580dcd9321a74d53": {
      "factor_id": "580dcd9321a74d53",
      "factor_name": "Gap_Volatility_Dominance_Rank_10D",
      "factor_expression": "RANK(TS_SUM(ABS($open - DELAY($close, 1)), 10) / (TS_SUM(($high - $low) + ABS($open - DELAY($close, 1)), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS($open - DELAY($close, 1)), 10) / (TS_SUM(($high - $low) + ABS($open - DELAY($close, 1)), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Volatility_Dominance_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks stocks based on the dominance of overnight gap volatility over total daily volatility (gap + intraday). It follows the logic that when volatility is primarily driven by overnight shocks rather than continuous intraday price discovery, the price is more likely to exhibit mean-reverting behavior.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.471278",
      "updated_at": "2026-01-17T02:11:31.471284"
    },
    "b3321ede1dc55647": {
      "factor_id": "b3321ede1dc55647",
      "factor_name": "PV_Corr_ATR_Regime_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 14) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 14) / ($close + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"PV_Corr_ATR_Regime_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures regime-dependent alpha by interacting the 20-day price-volume correlation with the 14-day Average True Range (ATR) normalized by price. High ATR signifies high-volatility regimes where price-volume divergence or convergence signals are more reliable.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.949028",
      "updated_at": "2026-01-17T02:12:37.949035"
    },
    "3a3929d58669dc91": {
      "factor_id": "3a3929d58669dc91",
      "factor_name": "Volatility_Weighted_PV_Divergence",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Weighted_PV_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the regime hypothesis that weights the 20-day price-volume correlation by the 14-day price volatility (standard deviation) normalized by price. It emphasizes price-volume signals during periods of high relative volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.961311",
      "updated_at": "2026-01-17T02:12:37.961317"
    },
    "66f572336e2eb2b4": {
      "factor_id": "66f572336e2eb2b4",
      "factor_name": "Regime_Filtered_PV_Momentum",
      "factor_expression": "TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Regime_Filtered_PV_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the 14-day ATR-to-price ratio as a regime filter. It amplifies the 20-day price-volume correlation when the current volatility is higher than its 60-day median, targeting periods of market stress or significant movement.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.973445",
      "updated_at": "2026-01-17T02:12:37.973451"
    },
    "ff213d9fa8bc5bb6": {
      "factor_id": "ff213d9fa8bc5bb6",
      "factor_name": "Vol_Adj_WVMA_Momentum_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_WVMA_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 5-day Volume Weighted Moving Average (WVMA) and transforms it using a volatility-adjusted momentum ratio. It aims to identify high-conviction trends by scaling the volume-weighted price by the ratio of 5-day returns to 5-day price volatility, effectively filtering out noise in high-variance regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.632203",
      "updated_at": "2026-01-17T02:17:56.632212"
    },
    "f07da216a4b9559c": {
      "factor_id": "f07da216a4b9559c",
      "factor_name": "Regime_Scaled_WVMA_5D",
      "factor_expression": "RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE($return, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE(TS_PCTCHANGE($close, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"Regime_Scaled_WVMA_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A non-linear transformation of the 5-day WVMA that uses the Z-score of returns relative to volatility. This factor distinguishes between institutional accumulation (low volatility, rising price) and distribution (high volatility, falling price) by multiplying the volume-weighted price level by the 5-day return Z-score.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.645835",
      "updated_at": "2026-01-17T02:17:56.645842"
    },
    "9d12564761d0156b": {
      "factor_id": "9d12564761d0156b",
      "factor_name": "Conviction_Trend_Index_5D",
      "factor_expression": "(DELTA($close, 5) / (TS_MEAN($high - $low, 5) + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / (TS_MEAN($high - $low, 5) + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Trend_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of a trend by normalizing the 5-day price change by the 5-day price range (volatility proxy) and weighting it by the relative volume intensity. It captures the hypothesis that price moves with high volume and low relative volatility are more predictive.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.659177",
      "updated_at": "2026-01-17T02:17:56.659183"
    },
    "9238283d9d0fe1b6": {
      "factor_id": "9238283d9d0fe1b6",
      "factor_name": "Trend_Acceleration_Divergence_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Divergence_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term (5-day) and long-term (20-day) trend quality. It uses the square of the correlation between price and a time sequence (R-squared) to identify parabolic acceleration or trend exhaustion. A high positive value suggests recent linear intensification, while a sharp drop suggests structural breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.832266",
      "updated_at": "2026-01-17T02:49:16.832272"
    },
    "562897a0cf01e5f1": {
      "factor_id": "562897a0cf01e5f1",
      "factor_name": "ZScored_Linearity_Burst_5D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Linearity_Burst_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'linear burst' phenomenon by calculating the cross-sectional Z-score of the short-term (5-day) R-squared relative to its long-term (20-day) baseline. It highlights assets where the short-term trend consistency is significantly deviating from its historical linear stability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.847318",
      "updated_at": "2026-01-17T02:49:16.847323"
    },
    "5d04ffa211d8c42c": {
      "factor_id": "5d04ffa211d8c42c",
      "factor_name": "Trend_Consistency_Decay_Rate",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Decay_Rate\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the decay in trend consistency by comparing the current 5-day R-squared to its 10-day moving average, normalized by the 20-day R-squared. This identifies assets where the 'linear consistency' is failing faster than the long-term trend would suggest, signaling potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.862200",
      "updated_at": "2026-01-17T02:49:16.862206"
    },
    "3cd6d15d89224ff5": {
      "factor_id": "3cd6d15d89224ff5",
      "factor_name": "Relative_Intraday_Intensity_20D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the current day's price range to the 20-day Average True Range (ATR). It identifies stocks with abnormal intraday volatility relative to their historical baseline, normalized for cross-sectional comparison.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:07.993363",
      "updated_at": "2026-01-17T02:52:07.993370"
    },
    "366a311d0a63e223": {
      "factor_id": "366a311d0a63e223",
      "factor_name": "Volatility_Adjusted_Range_Shock_10D",
      "factor_expression": "RANK((($high - $low) / $close) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / $close) / TS_STD(TS_PCTCHANGE($close, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Range_Shock_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the intraday intensity factor that uses a 10-day rolling standard deviation of returns to normalize the daily range-to-price ratio, highlighting price shocks relative to recent volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.010514",
      "updated_at": "2026-01-17T02:52:08.010520"
    },
    "9a62de12186c88c7": {
      "factor_id": "9a62de12186c88c7",
      "factor_name": "Relative_Range_ZScore_20D",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the time-series Z-score of the daily price range over a 20-day window. It identifies how many standard deviations the current day's range is from its recent mean, providing a unit-less measure of trading intensity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.026105",
      "updated_at": "2026-01-17T02:52:08.026110"
    },
    "99c155b7b71f606d": {
      "factor_id": "99c155b7b71f606d",
      "factor_name": "VW_Efficiency_Ratio_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (TS_MEAN($volume * $close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (TS_MEAN($volume * $close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day Volume-Weighted Efficiency Ratio. It measures the directness of price movement (displacement divided by total path traveled) normalized by the 5-day volume-weighted average price. High efficiency with high volume suggests trend persistence, while low efficiency or low volume suggests potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.137121",
      "updated_at": "2026-01-17T02:55:13.137128"
    },
    "8f46483ca3e55e78": {
      "factor_id": "8f46483ca3e55e78",
      "factor_name": "Path_Efficiency_Liquidity_Rank_5D",
      "factor_expression": "RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Path_Efficiency_Liquidity_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency ratio that focuses on the cross-sectional rank of path efficiency (displacement over total range) adjusted by the rank of volume intensity. It identifies assets where price moves are 'efficient' relative to the liquidity provided, targeting mean-reversion when efficiency is extreme.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.153925",
      "updated_at": "2026-01-17T02:55:13.153932"
    },
    "0a7f905fc3df233d": {
      "factor_id": "0a7f905fc3df233d",
      "factor_name": "Efficiency_Volatility_Adj_5D",
      "factor_expression": "ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) * TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) * TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Adj_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day price displacement relative to the cumulative high-low range, further adjusted by the 5-day price volatility (Standard Deviation). It aims to isolate high-conviction trends from noisy, high-volatility price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.170470",
      "updated_at": "2026-01-17T02:55:13.170476"
    },
    "3cbef1cd6406bdd6": {
      "factor_id": "3cbef1cd6406bdd6",
      "factor_name": "WVMA_RSQR_Exhaustion_Ratio_10D",
      "factor_expression": "TS_MEAN(TS_STD($close, 5) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_STD($close, 5) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WVMA_RSQR_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by calculating the ratio of volume-weighted volatility to the linearity of the price trend. A high value suggests that price movements are becoming more volatile and high-conviction (volume-weighted) while the trend's structural linearity (R-squared) is breaking down, signaling a potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.126614",
      "updated_at": "2026-01-17T03:10:24.126622"
    },
    "cdc26453752ef13a": {
      "factor_id": "cdc26453752ef13a",
      "factor_name": "Trend_Instability_Index_5D",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(5), 5), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(5), 5), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Instability_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis focusing on the divergence between volume-weighted price spread and trend stability. It uses the ratio of rolling volume-weighted high-low range to the square of the price-time correlation. High values indicate chaotic price action with high participation, often seen at market tops or bottoms.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.147874",
      "updated_at": "2026-01-17T03:10:24.147880"
    },
    "807104440bd1d4bf": {
      "factor_id": "807104440bd1d4bf",
      "factor_name": "Normalized_Volatility_Linearity_Divergence",
      "factor_expression": "TS_ZSCORE(TS_STD($close, 5) * $volume, 20) - TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_STD($close, 5) * $volume, 20) - TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Volatility_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between standardized volume-weighted volatility and the linearity of the price trend. By using Z-scores, it identifies extreme periods where volatility conviction significantly outpaces the trend's consistency, indicating a regime shift.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.164853",
      "updated_at": "2026-01-17T03:10:24.164859"
    },
    "5f3f4b1b8c689ea1": {
      "factor_id": "5f3f4b1b8c689ea1",
      "factor_name": "Exhaustion_Stability_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Stability_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by calculating the 5-day average of the ratio between the candle body and the total daily range, weighted by the 10-day R-squared of the price trend. A low body-to-range ratio combined with high trend linearity (R-squared) suggests a potential reversal after a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.722344",
      "updated_at": "2026-01-17T03:25:33.722351"
    },
    "cad94aa0b8ce9de8": {
      "factor_id": "cad94aa0b8ce9de8",
      "factor_name": "Ranked_Exhaustion_Persistence_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the exhaustion hypothesis. It ranks the 5-day smoothed body-to-range ratio and multiplies it by the 10-day price trend persistence (R-squared). This helps identify stocks that are showing the most significant signs of trend exhaustion relative to the market universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.741138",
      "updated_at": "2026-01-17T03:25:33.741144"
    },
    "acd93be4bfe19b46": {
      "factor_id": "acd93be4bfe19b46",
      "factor_name": "Trend_Stability_Rejection_Ratio",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Rejection_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price linearity and intraday rejection. It uses the 10-day R-squared as a filter for trend maturity and measures the relative size of the candle body. Lower values indicate higher reversal probability at the end of a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.758911",
      "updated_at": "2026-01-17T03:25:33.758916"
    },
    "2cd7851c51b79b5a": {
      "factor_id": "2cd7851c51b79b5a",
      "factor_name": "Stability_Reversion_RSQR_WVMA_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stability_Reversion_RSQR_WVMA_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by multiplying the trend stability (R-squared of price against time) with the price deviation from a Volume Weighted Moving Average. High R-squared indicates a consensus-driven trend, while a large deviation from WVMA suggests exhaustion. The factor uses TS_CORR squared to represent R-squared and a volume-weighted price proxy.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.879266",
      "updated_at": "2026-01-17T03:40:59.879273"
    },
    "ec7e0fd06961de67": {
      "factor_id": "ec7e0fd06961de67",
      "factor_name": "Trend_Exhaustion_Linearity_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Linearity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stability-reversion hypothesis focusing on a shorter 5-day window. It captures the interaction between the linearity of the price trend (R-squared) and the standardized distance from the volume-weighted average price to detect speculative blow-off points.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.899548",
      "updated_at": "2026-01-17T03:40:59.899554"
    },
    "71202d9fd3bd3bce": {
      "factor_id": "71202d9fd3bd3bce",
      "factor_name": "Cross_Sectional_Stability_Reversion",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Stability_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies cross-sectional ranking to the stability-reversion logic. It ranks the trend linearity (R-squared) and the volume-weighted price residual separately before combining them, ensuring the factor is robust across different market regimes and asset scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.918294",
      "updated_at": "2026-01-17T03:40:59.918300"
    }
  }
}