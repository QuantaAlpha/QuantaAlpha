{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.672588",
    "last_updated": "2026-01-17T02:02:58.672593",
    "total_factors": 30,
    "version": "1.0",
    "note": "Random 30 factors from round 2 (from all_factors_library_AA.json)"
  },
  "factors": {
    "e7e3d9f0f2bcda6e": {
      "factor_id": "e7e3d9f0f2bcda6e",
      "factor_name": "Ranked_Stability_VWAP_Trigger_2D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_VWAP_Trigger_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the stability-momentum hypothesis using RANK instead of ZSCORE to handle outliers. It identifies stocks where the 20-day price trend is highly linear (RSQR) and is currently experiencing a positive 2-day volume-weighted price thrust, signaling a high-probability entry point.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.101297",
      "updated_at": "2026-01-14T17:43:57.101305"
    },
    "793ee7a2944db336": {
      "factor_id": "793ee7a2944db336",
      "factor_name": "Vol_Normalized_Exhaustion_Index_20D",
      "factor_expression": "((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Normalized_Exhaustion_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies structural trend exhaustion by measuring the volatility-normalized distance between the 20-day high and the current close, weighted by the surge in short-term volume relative to its monthly average. High values suggest a 'blow-off' top where price is stretched but volume is disproportionately high or low compared to the baseline.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.183104",
      "updated_at": "2026-01-14T20:37:23.183111"
    },
    "57ed23d5978e1e44": {
      "factor_id": "57ed23d5978e1e44",
      "factor_name": "Conviction_Filtered_Trend_5D",
      "factor_expression": "RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Filtered_Trend_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by comparing the cross-sectional rank of the 5-day price slope against the rank of the volume-weighted price location. Divergence between trend direction and volume-weighted support indicates potential reversals.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.034763",
      "updated_at": "2026-01-14T17:21:26.034769"
    },
    "7e9ddacd0e80dc3f": {
      "factor_id": "7e9ddacd0e80dc3f",
      "factor_name": "Liquidity_Adjusted_Momentum_Z",
      "factor_expression": "TS_ZSCORE($close / (($high + $low + $close) / 3 + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - (($high + $low + $close) / 3)) / (TS_STD($return, 20) + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Momentum_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price moves by calculating the Z-score of the ratio between price-VWAP deviation and historical volatility, multiplied by the rank of short-term volume growth to filter for institutional accumulation.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.357753",
      "updated_at": "2026-01-14T17:29:39.357759"
    },
    "0a7e73fd9b4c7d2f": {
      "factor_id": "0a7e73fd9b4c7d2f",
      "factor_name": "Smoothed_Conviction_Momentum_10D",
      "factor_expression": "TS_CORR($return, EMA(DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, EMA(DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 5), 10)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Conviction_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the conviction lead-lag factor that applies an Exponential Moving Average (EMA) to the volume-scaled lagged return signal to reduce noise before calculating the 10-day correlation with current returns.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day rolling correlation between current returns and a 3-day lagged, volume-scaled return signal captures high-conviction price discovery trends more effectively than longer-lag models.\n                Concise Observation: The previous 5-day lag and 20-day window were too slow to capture decaying lead-lag effects; shortening the lag to 3 days and using a volume ratio instead of a Z-score improved the Information Ratio and signal responsiveness.\n                Concise Justification: Shorter lags capture more immediate information diffusion, while scaling lagged returns by the volume ratio (current volume / mean volume) emphasizes price moves that occurred with high relative conviction, filtering out noise from low-liquidity sessions.\n                Concise Knowledge: If the lag period is reduced to 3 days and the lagged signal is scaled by the ratio of volume to its 10-day moving average, then the resulting correlation identifies short-term momentum backed by liquidity, which is more predictive of immediate price persistence.\n                concise Specification: Calculate the factor as the 10-day Pearson correlation between the daily return ($return) and a 'Conviction Signal', where the Conviction Signal is the 3-day lagged return multiplied by ($volume / TS_MEAN($volume, 10)).\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064292131116171,
        "ICIR": 0.0471904782508434,
        "RankIC": 0.022961676702149,
        "RankICIR": 0.1745311944608633,
        "annualized_return": 0.0713249472038566,
        "information_ratio": 1.1379839206679387,
        "max_drawdown": -0.0918045186564081
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:54:09.625003",
      "updated_at": "2026-01-15T18:54:09.625009"
    },
    "1dc7e879df593121": {
      "factor_id": "1dc7e879df593121",
      "factor_name": "VWIM_EMA3_RelVol10",
      "factor_expression": "EMA(($close / $open - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(($close / $open - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3)\" # Your output factor expression will be filled in here\n    name = \"VWIM_EMA3_RelVol10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Intraday Momentum (VWIM) factor: captures the open-to-close return scaled by relative volume (current volume divided by its 10-day average) and smoothed with a 3-day EMA to prioritize recent institutional conviction while filtering out low-volume noise.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Volume-Weighted Intraday Momentum (VWIM) factor, calculated as the open-to-close return scaled by relative volume and smoothed with a short-term Exponential Moving Average (EMA), provides a higher signal-to-noise ratio for predicting short-term returns than simple intraday gaps.\n                Concise Observation: Previous results showed that while intraday momentum is predictive (IR 0.9577), simple moving averages (5D/20D) likely lag the signal's decay, and unweighted returns fail to distinguish between high-conviction institutional flows and low-volume retail noise.\n                Concise Justification: Volume serves as a validation metric for price action; scaling the intraday return by the ratio of current volume to its historical average filters for 'informed' trading, while the EMA prioritizes recent data points to mitigate the signal-lag inherent in standard rolling means.\n                Concise Knowledge: If intraday price trends are supported by high relative volume, they indicate higher institutional conviction; when these signals are processed using decay-weighted averages (EMA) over short horizons (e.g., 3 days), they better capture the transient nature of alpha before market efficiency absorbs the trend.\n                concise Specification: The factor is defined as (Close/Open - 1) * (Volume / SMA(Volume, 10)), then smoothed using a 3-day Exponential Moving Average (EMA) to generate a final predictive value for each instrument.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058479468228565,
        "ICIR": 0.0376867169187617,
        "RankIC": 0.0224571044860769,
        "RankICIR": 0.1444330405368809,
        "annualized_return": 0.0707034454329422,
        "information_ratio": 0.9352636238015638,
        "max_drawdown": -0.1053260582417709
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:40:20.877177",
      "updated_at": "2026-01-15T17:40:20.877184"
    },
    "f101db011ea22576": {
      "factor_id": "f101db011ea22576",
      "factor_name": "Ranked_Squeeze_Momentum_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the volatility squeeze hypothesis. It measures the intensity of price tightness (inverse of the 5-day range normalized by 20-day volatility) and scales it by the sign of the recent 5-day trend to ensure directional alignment with the breakout.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.421657",
      "updated_at": "2026-01-14T17:23:48.421663"
    },
    "89b598f9778770de": {
      "factor_id": "89b598f9778770de",
      "factor_name": "VW_Range_Position_Exhaustion_5D",
      "factor_expression": "($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Range_Position_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the distance between the current close and the 5-day volume-weighted average price (VWAP) normalized by the range. It targets mean reversion by identifying when price moves too far from the volume-weighted conviction level relative to its 5-day trend.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.067321",
      "updated_at": "2026-01-14T17:21:26.067327"
    },
    "b6d66145f7cdc66f": {
      "factor_id": "b6d66145f7cdc66f",
      "factor_name": "Conditional_Trend_Stability_2D",
      "factor_expression": "(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Trend_Stability_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional logic where the 20-day trend stability (RSQR) is only considered if the 2-day volume-weighted return is positive. It focuses on 'quiet' institutional accumulation that is just beginning to break out with volume support, filtering out stagnant or decaying trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.137115",
      "updated_at": "2026-01-14T17:43:57.137122"
    },
    "0b1696dec7b25994": {
      "factor_id": "0b1696dec7b25994",
      "factor_name": "ZScore_RSQR20_VWAP_Momentum_2D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_RSQR20_VWAP_Momentum_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trend continuations by multiplying the cross-sectional Z-score of price trend stability (R-squared of close prices over 20 days) with the cross-sectional Z-score of a 2-day volume-weighted return. This ensures that long-term structural stability is validated by immediate volume-supported price action.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.064610",
      "updated_at": "2026-01-14T17:43:57.064617"
    },
    "87e41321572b0d24": {
      "factor_id": "87e41321572b0d24",
      "factor_name": "Squeeze_Efficiency_Interaction_10D",
      "factor_expression": "TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Efficiency_Interaction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines the volatility squeeze concept with the direction of the 10-day price move. It uses the ratio of the 20-day standard deviation to the 5-day high-low range to identify periods of expansion potential, weighted by the 10-day return to filter for bullish momentum.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.455370",
      "updated_at": "2026-01-14T17:23:48.455376"
    },
    "3656e978261fcb3a": {
      "factor_id": "3656e978261fcb3a",
      "factor_name": "Trend_Exhaustion_Index_V1",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5)) * RANK($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Index_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion signals by multiplying the 10-day price residual (deviation from trend) with a 5-day smoothed price efficiency ratio and a 20-day relative volume. High values indicate a 'blow-off' climax where price over-extension is met with high volume and weakening conviction.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.380256",
      "updated_at": "2026-01-14T20:37:56.380262"
    },
    "8a3c3da6922f3d71": {
      "factor_id": "8a3c3da6922f3d71",
      "factor_name": "Efficiency_Filtered_Residual_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Filtered_Residual_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price over-extension and smoothed efficiency. It identifies assets where the price has deviated significantly from its 10-day trend while the 'quality' of the move (efficiency) is low, suggesting a higher probability of reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.411997",
      "updated_at": "2026-01-14T20:37:56.412003"
    },
    "5936a1ec35f7b5b4": {
      "factor_id": "5936a1ec35f7b5b4",
      "factor_name": "Efficiency_Rank_Reversal_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Rank_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between price efficiency and cross-sectional price extremes. It uses the 5-day Efficiency Ratio (net displacement over total movement) and weights it by the inverse of the cross-sectional rank of the 20-day price position to highlight overextended, inefficient trends.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.679134",
      "updated_at": "2026-01-15T18:48:21.679140"
    },
    "4e50237f8538ced2": {
      "factor_id": "4e50237f8538ced2",
      "factor_name": "Laggard_Sensitivity_Leader_Conviction",
      "factor_expression": "(RANK($volume) < 0.5 && RANK(TS_STD($return, 10)) < 0.25) ? MEAN(TS_ZSCORE(TS_PCTCHANGE($close, 3), 10) * (TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "",
      "factor_description": "Calculates the conviction-weighted momentum of the top quintile of stocks by volume and projects it onto stocks with low idiosyncratic volatility and low volume. The volume shock is capped to prevent outliers from dominating the signal.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.112593",
      "updated_at": "2026-01-15T17:47:09.112598"
    },
    "cc5ead208c103e71": {
      "factor_id": "cc5ead208c103e71",
      "factor_name": "Churn_Volatility_Adjusted_ER_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * SIGN(DELTA($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Churn_Volatility_Adjusted_ER_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'wasteful' price action by scaling the 5-day Efficiency Ratio by the negative sign of the recent price trend. It specifically looks for low-efficiency moves (churn) that occur during high-volatility periods, signaling that the current trend direction is losing its strength.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.698797",
      "updated_at": "2026-01-15T18:48:21.698803"
    },
    "502409b41bea1fbd": {
      "factor_id": "502409b41bea1fbd",
      "factor_name": "Exhaustion_Reversal_Score_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Score_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the volume-price divergence hypothesis. It calculates the 10-day reversal and weights it by the time-series rank of the inverse volume, prioritizing reversals that occur on declining or low relative volume.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.215328",
      "updated_at": "2026-01-14T17:02:57.215334"
    },
    "8c475560c22dde7f": {
      "factor_id": "8c475560c22dde7f",
      "factor_name": "Kaufman_Exhaustion_ZScore_5D_20D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Kaufman_Exhaustion_ZScore_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by multiplying the 5-day Kaufman Efficiency Ratio (ER) with the negative of the 20-day price Z-score. A low ER (high path length relative to displacement) at price extremes (high Z-score) suggests 'churning' and imminent mean reversion.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.658788",
      "updated_at": "2026-01-15T18:48:21.658796"
    },
    "57a1a7219e6a9c5e": {
      "factor_id": "57a1a7219e6a9c5e",
      "factor_name": "Divergence_ZScore_Exhaustion_20D",
      "factor_expression": "TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Divergence_ZScore_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price positioning and volume intensity. It calculates the Z-score of the current price relative to its 20-day history and multiplies it by the volume ratio. A high price Z-score combined with a high volume ratio often signals a liquidity-thin peak or trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.198967",
      "updated_at": "2026-01-14T20:37:23.198973"
    },
    "2049a9a4215625f3": {
      "factor_id": "2049a9a4215625f3",
      "factor_name": "Relative_Resistance_Volume_Surge_20D",
      "factor_expression": "RANK((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) + RANK($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($close, 20) - $close) / (TS_STD($close, 20) + 1e-8)) + RANK($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Resistance_Volume_Surge_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures how close the current price is to its 20-day resistance (max price) relative to its typical volatility, adjusted by the intensity of recent volume. It uses RANK to normalize the components cross-sectionally to identify the most exhausted stocks in the universe.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.214434",
      "updated_at": "2026-01-14T20:37:23.214439"
    },
    "4eb1402e756c4b8e": {
      "factor_id": "4eb1402e756c4b8e",
      "factor_name": "Volatility_Squeeze_Breakout_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Squeeze_Breakout_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'volatility springs' by calculating the ratio of long-term volatility to the recent price range, then multiplying by the 5-day return to capture the direction of the breakout. A high value indicates a tight consolidation followed by a positive price expansion.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.387142",
      "updated_at": "2026-01-14T17:23:48.387149"
    },
    "7ea4a5dcdae76558": {
      "factor_id": "7ea4a5dcdae76558",
      "factor_name": "Conviction_Lead_Lag_Corr_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return, 3) * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Lead_Lag_Corr_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 10-day rolling correlation between current returns and a conviction signal. The conviction signal is defined as the 3-day lagged return scaled by the ratio of current volume to its 10-day moving average, highlighting price moves backed by relative liquidity.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day rolling correlation between current returns and a 3-day lagged, volume-scaled return signal captures high-conviction price discovery trends more effectively than longer-lag models.\n                Concise Observation: The previous 5-day lag and 20-day window were too slow to capture decaying lead-lag effects; shortening the lag to 3 days and using a volume ratio instead of a Z-score improved the Information Ratio and signal responsiveness.\n                Concise Justification: Shorter lags capture more immediate information diffusion, while scaling lagged returns by the volume ratio (current volume / mean volume) emphasizes price moves that occurred with high relative conviction, filtering out noise from low-liquidity sessions.\n                Concise Knowledge: If the lag period is reduced to 3 days and the lagged signal is scaled by the ratio of volume to its 10-day moving average, then the resulting correlation identifies short-term momentum backed by liquidity, which is more predictive of immediate price persistence.\n                concise Specification: Calculate the factor as the 10-day Pearson correlation between the daily return ($return) and a 'Conviction Signal', where the Conviction Signal is the 3-day lagged return multiplied by ($volume / TS_MEAN($volume, 10)).\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064292131116171,
        "ICIR": 0.0471904782508434,
        "RankIC": 0.022961676702149,
        "RankICIR": 0.1745311944608633,
        "annualized_return": 0.0713249472038566,
        "information_ratio": 1.1379839206679387,
        "max_drawdown": -0.0918045186564081
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:54:09.604270",
      "updated_at": "2026-01-15T18:54:09.604278"
    },
    "313646e5c487fee1": {
      "factor_id": "313646e5c487fee1",
      "factor_name": "Steady_Trend_Conviction_Rank_20D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Steady_Trend_Conviction_Rank_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that identifies high-conviction trends by scaling the 20-day price return by the inverse of volume volatility. It uses the ratio of mean volume to volume standard deviation as a multiplier for price momentum, effectively amplifying signals where volume is consistent and stable.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.872162",
      "updated_at": "2026-01-14T20:26:55.872168"
    },
    "bb649f19188ec110": {
      "factor_id": "bb649f19188ec110",
      "factor_name": "VW_Price_Slope_Divergence_5D",
      "factor_expression": "REGBETA($close, SEQUENCE(5), 5) - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGBETA($close, SEQUENCE(5), 5) - (TS_SUM((($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)) * $volume, 5) / TS_SUM($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Slope_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the 5-day price trend (regression slope) and the volume-weighted relative position of the price within its high-low range. A high price slope combined with a low volume-weighted position suggests a 'hollow' trend prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.000804",
      "updated_at": "2026-01-14T17:21:26.000811"
    },
    "8ea1bf1386c5b50e": {
      "factor_id": "8ea1bf1386c5b50e",
      "factor_name": "VWAP_Efficiency_Accel_20D",
      "factor_expression": "TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Efficiency_Accel_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the interaction between price-volume efficiency and the acceleration of liquidity-adjusted momentum. It measures the deviation of the close price from the VWAP (approximated by (high+low+close)/3), normalized by 20-day return volatility, and scales it by the 5-day change in volume-weighted price momentum.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.322550",
      "updated_at": "2026-01-14T17:29:39.322557"
    },
    "23101d70fb6bc583": {
      "factor_id": "23101d70fb6bc583",
      "factor_name": "Dynamic_LeadLag_Momentum_Filter",
      "factor_expression": "(RANK(TS_STD($return, 10)) < 0.25) ? MEAN((TS_PCTCHANGE($close, 3) * MIN(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8), 3)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"MEAN(FILTER(TS_PCTCHANGE($close, 3), (TS_MEAN($volume, 3) / TS_MEAN($volume, 20)) > 1.5)) * (RANK(TS_STD($return, 10)) < 0.25 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Dynamic_LeadLag_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies the momentum of high-conviction leaders (volume surge) and applies it to low-volatility laggards. It uses a 3-day window for momentum and volume shocks to capture faster information diffusion, while using the cross-sectional mean of leader signals to drive laggard expectations.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.093634",
      "updated_at": "2026-01-15T17:47:09.093641"
    },
    "0a2809d6fd472731": {
      "factor_id": "0a2809d6fd472731",
      "factor_name": "Efficiency_Volatility_Ratio_20D",
      "factor_expression": "RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of price discovery by comparing the price-VWAP ratio to the 20-day standard deviation of returns. It targets stocks where price is trending above the volume-weighted average under conditions of low relative volatility, which indicates a stable, high-conviction trend.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.391667",
      "updated_at": "2026-01-14T17:29:39.391673"
    },
    "1d5804d105216831": {
      "factor_id": "1d5804d105216831",
      "factor_name": "Climax_Reversal_Signal_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 20) * TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Climax_Reversal_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion index targeting market climaxes. It combines the 10-day price residual with the 5-day average efficiency, but uses Z-scores to normalize the components before interaction, specifically highlighting cases where volume is significantly above its 20-day average.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.396389",
      "updated_at": "2026-01-14T20:37:56.396394"
    },
    "ff9db33c946c0706": {
      "factor_id": "ff9db33c946c0706",
      "factor_name": "ZScore_VWIM_ShortTerm",
      "factor_expression": "ZSCORE(EMA(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(EMA(($close - $open) / $open * ($volume / (TS_MEAN($volume, 10) + 1e-8)), 3))\" # Your output factor expression will be filled in here\n    name = \"ZScore_VWIM_ShortTerm\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Cross-sectionally standardized version of the Volume-Weighted Intraday Momentum. It identifies stocks with the strongest volume-validated intraday trends relative to the market, smoothed by a 3-day EMA to capture decaying alpha.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Volume-Weighted Intraday Momentum (VWIM) factor, calculated as the open-to-close return scaled by relative volume and smoothed with a short-term Exponential Moving Average (EMA), provides a higher signal-to-noise ratio for predicting short-term returns than simple intraday gaps.\n                Concise Observation: Previous results showed that while intraday momentum is predictive (IR 0.9577), simple moving averages (5D/20D) likely lag the signal's decay, and unweighted returns fail to distinguish between high-conviction institutional flows and low-volume retail noise.\n                Concise Justification: Volume serves as a validation metric for price action; scaling the intraday return by the ratio of current volume to its historical average filters for 'informed' trading, while the EMA prioritizes recent data points to mitigate the signal-lag inherent in standard rolling means.\n                Concise Knowledge: If intraday price trends are supported by high relative volume, they indicate higher institutional conviction; when these signals are processed using decay-weighted averages (EMA) over short horizons (e.g., 3 days), they better capture the transient nature of alpha before market efficiency absorbs the trend.\n                concise Specification: The factor is defined as (Close/Open - 1) * (Volume / SMA(Volume, 10)), then smoothed using a 3-day Exponential Moving Average (EMA) to generate a final predictive value for each instrument.\n                ",
      "initial_direction": "Intraday Momentum Decomposition: Separate overnight returns from intraday continuous price action to test the hypothesis that institutional 'smart money' momentum primarily persists during the first and last 30 minutes of trading sessions.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058479468228565,
        "ICIR": 0.0376867169187617,
        "RankIC": 0.0224571044860769,
        "RankICIR": 0.1444330405368809,
        "annualized_return": 0.0707034454329422,
        "information_ratio": 0.9352636238015638,
        "max_drawdown": -0.1053260582417709
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:40:20.896797",
      "updated_at": "2026-01-15T17:40:20.896804"
    },
    "fb42bc4cc1cea0c8": {
      "factor_id": "fb42bc4cc1cea0c8",
      "factor_name": "VWM_Normalized_CV_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWM_Normalized_CV_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 20-day price momentum (percentage change) and normalizes it by the volume coefficient of variation (CV) over the same period. The CV is the ratio of the standard deviation of volume to the mean volume. By dividing momentum by CV, the factor penalizes price trends accompanied by erratic or unstable volume, favoring steady, high-conviction accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.857108",
      "updated_at": "2026-01-14T20:26:55.857114"
    }
  }
}