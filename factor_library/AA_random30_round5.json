{
  "metadata": {
    "created_at": "2026-01-17T02:02:58.675896",
    "last_updated": "2026-01-17T02:02:58.675900",
    "total_factors": 23,
    "version": "1.0",
    "note": "Random 30 factors from round 5 (from all_factors_library_AA.json)"
  },
  "factors": {
    "04af2bc09ff7df83": {
      "factor_id": "04af2bc09ff7df83",
      "factor_name": "Conviction_Divergence_Reversal_10D",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Divergence_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by combining price-volume divergence with volume conviction. It uses the 10-day price-volume correlation change as a measure of trend exhaustion, weighted by the 20-day volume Z-score (clipped at 0) to ensure the signal occurs during a high-conviction liquidity event. The reversal component is normalized by the 10-day price range relative to the typical body size.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.781751",
      "updated_at": "2026-01-14T17:26:49.781758"
    },
    "0965806078acfa49": {
      "factor_id": "0965806078acfa49",
      "factor_name": "Liquidity_Climax_Exhaustion_Factor",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Climax_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets reversal points where price-volume correlation breaks down during extreme volume spikes. It normalizes the 10-day return by the 10-day Median Absolute Deviation of returns to handle outliers, then scales it by the interaction of volume intensity and the 5-day shift in price-volume alignment.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.815950",
      "updated_at": "2026-01-14T17:26:49.815956"
    },
    "1a83f9422320ba4d": {
      "factor_id": "1a83f9422320ba4d",
      "factor_name": "Vol_Weighted_Exhaustion_Index",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8)) * ((TS_ZSCORE($volume, 20) > 0) ? (TS_ZSCORE($volume, 20)) : (0)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified implementation of the conviction-exhaustion hypothesis. It measures 10-day price exhaustion by dividing the 10-day return by its 10-day volatility, then multiplying by the product of the volume Z-score and the change in price-volume correlation to isolate high-volume trend decoupling.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.848804",
      "updated_at": "2026-01-14T17:26:49.848810"
    },
    "a4536c724715cb93": {
      "factor_id": "a4536c724715cb93",
      "factor_name": "Volume_Price_Asymmetry_Index_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Asymmetry_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of 5-day cumulative returns to the 5-day average volume, then scaling this impact by the relative liquidity (5-day average volume vs. 20-day average volume). High values indicate price moves on relatively low or declining liquidity, signaling potential mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.645583",
      "updated_at": "2026-01-14T17:34:27.645589"
    },
    "742224279aef2211": {
      "factor_id": "742224279aef2211",
      "factor_name": "Asymmetric_Liquidity_Impact_5D",
      "factor_expression": "RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Liquidity_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Price Asymmetry index that focuses on the 'cost' of price movement. It measures the 5-day return per unit of volume, adjusted by how the current 5-day volume compares to a longer 20-day baseline. It aims to capture 'hollow' price moves where participation is low relative to historical norms.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.680765",
      "updated_at": "2026-01-14T17:34:27.680770"
    },
    "21b119adc7849b19": {
      "factor_id": "21b119adc7849b19",
      "factor_name": "Relative_Volume_Efficiency_Rank_5D",
      "factor_expression": "ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion by comparing the magnitude of price change to the relative volume surge. It uses the ratio of 5-day absolute returns to the 5-day average volume, scaled by the 20-day volume average to normalize for stock-specific liquidity levels.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.715331",
      "updated_at": "2026-01-14T17:34:27.715337"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T17:39:41.148683"
    },
    "ba52212e001d0431": {
      "factor_id": "ba52212e001d0431",
      "factor_name": "Efficiency_Adjusted_Persistence_15D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency hypothesis that focuses on the Z-score interaction between volume-ranked returns and a price-range stability metric. It identifies assets where the conviction (volume-weighted returns) significantly outweighs the noise (price range), using Z-scores to ensure cross-sectional comparability.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.183691",
      "updated_at": "2026-01-14T17:39:41.183697"
    },
    "c52e3e585865407c": {
      "factor_id": "c52e3e585865407c",
      "factor_name": "Ranked_Conviction_Trend_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Trend_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a trend by subtracting the rank of daily price volatility (proxied by the high-low spread) from the rank of volume-weighted returns. By using ranks, it mitigates the impact of outliers and focuses on the relative efficiency of the price movement within the universe.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.220630",
      "updated_at": "2026-01-14T17:39:41.220636"
    },
    "fbf7da796f254b8c": {
      "factor_id": "fbf7da796f254b8c",
      "factor_name": "Volume_Surge_Breakout_Intensity_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Breakout_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the interaction between price momentum and a volume-weighted volatility squeeze. Instead of a raw price range, it uses the standard deviation of returns normalized by a 20-day baseline, multiplied by a volume surge ratio (5-day vs 20-day) to filter for institutional participation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.601633",
      "updated_at": "2026-01-14T17:41:01.601641"
    },
    "db32cf1b30603006": {
      "factor_id": "db32cf1b30603006",
      "factor_name": "Compressed_Momentum_Volume_Multiplier_10D",
      "factor_expression": "(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Momentum_Volume_Multiplier_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiling' effect by comparing the current 5-day return to the 20-day historical volatility, then scales this signal by the relative volume growth. It uses the ratio of 5-day average volume to 20-day average volume as a threshold-based multiplier to ensure the breakout is supported by liquidity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.638855",
      "updated_at": "2026-01-14T17:41:01.638861"
    },
    "813f4d08321676c8": {
      "factor_id": "813f4d08321676c8",
      "factor_name": "Breakout_Conviction_Index_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Breakout_Conviction_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a breakout by combining the direction of the 5-day price move with the relative volume intensity, normalized by the 20-day price volatility. It avoids raw high-low ranges to prevent outlier sensitivity, focusing instead on return-based volatility.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.674344",
      "updated_at": "2026-01-14T17:41:01.674351"
    },
    "362c428a7eea6559": {
      "factor_id": "362c428a7eea6559",
      "factor_name": "Vol_Adj_MFI_Stability_Factor",
      "factor_expression": "ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_MFI_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 20-day weighted price stability with a 5-day Money Flow Index (MFI) relative to its recent average. It uses volatility-adjusted weighting to balance the two components, ensuring that the more stable trend signal and the more reactive capital flow signal contribute proportionally based on their recent variance.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.350701",
      "updated_at": "2026-01-14T18:42:41.350708"
    },
    "dc89cc27bd12469a": {
      "factor_id": "dc89cc27bd12469a",
      "factor_name": "MFI_Surge_Trend_Alignment",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MFI_Surge_Trend_Alignment\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the MFI-Stability hypothesis focusing on the ratio of Money Flow intensity to trend consistency. It identifies stocks where capital is surging (MFI > 3-day average) while the price trend remains structurally sound (high correlation with time), normalized by cross-sectional rank to ensure robustness.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.389138",
      "updated_at": "2026-01-14T18:42:41.389144"
    },
    "f6f91286e32c9272": {
      "factor_id": "f6f91286e32c9272",
      "factor_name": "PVD_Exhaustion_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVD_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence factor identifies short-term exhaustion or breakout regimes. It scales the 5-day price return by the volume signal-to-noise ratio (Mean/STD). High values indicate price trends supported by consistent liquidity, while low values suggest erratic or noise-driven moves prone to reversal.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.448476",
      "updated_at": "2026-01-14T20:39:43.448482"
    },
    "a6c613799bd857ca": {
      "factor_id": "a6c613799bd857ca",
      "factor_name": "Consistent_Liquidity_Momentum_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5)) * ZSCORE(TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Consistent_Liquidity_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day price change normalized by the volume coefficient of variation. By using a 5-day window, it captures immediate liquidity regimes. The use of TS_ZSCORE on the volume ratio helps mitigate numerical instability from low volume variance before multiplying by the short-term return.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.464430",
      "updated_at": "2026-01-14T20:39:43.464436"
    },
    "ed6041fff76a183d": {
      "factor_id": "ed6041fff76a183d",
      "factor_name": "Robust_Volume_Efficiency_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Robust_Volume_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined volume efficiency factor that uses the 5-day price return and the ratio of median volume to volume standard deviation to reduce the impact of outlier spikes. The factor is cross-sectionally ranked to ensure comparability across different liquidity profiles.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.480342",
      "updated_at": "2026-01-14T20:39:43.480349"
    },
    "dd47681204cca2e0": {
      "factor_id": "dd47681204cca2e0",
      "factor_name": "Idiosyncratic_Churn_Volatility_10D",
      "factor_expression": "RANK(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8)) * RANK(TS_ZSCORE($volume, 10)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8)) * RANK(TS_ZSCORE($volume, 10)) * RANK(TS_STD($return, 10))\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Churn_Volatility_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by detecting stocks where high volume intensity and high return volatility coincide with low price efficiency. It interacts the cross-sectional rank of inverse price efficiency with the rank of volume surges and return standard deviation over a 10-day window to signal liquidity-driven trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.242096",
      "updated_at": "2026-01-14T20:49:41.242103"
    },
    "67c80b225c0e2bc4": {
      "factor_id": "67c80b225c0e2bc4",
      "factor_name": "Efficiency_Adjusted_Volume_Exhaustion_10D",
      "factor_expression": "RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Volume_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion factor that captures the 'effort vs result' divergence. It calculates the ratio of volume intensity to price efficiency, then weights it by the cross-sectional rank of price volatility. A high value indicates high effort (volume) and high noise (volatility) with low directional progress (efficiency).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.259006",
      "updated_at": "2026-01-14T20:49:41.259012"
    },
    "398af1472a4fdf41": {
      "factor_id": "398af1472a4fdf41",
      "factor_name": "ZScore_Churn_Intensity_10D",
      "factor_expression": "ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Churn_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates idiosyncratic blow-off tops by combining the cross-sectional Z-score of volume surges with the cross-sectional Z-score of price churn (the inverse of efficiency). It targets stocks that are statistical outliers in both liquidity consumption and price volatility relative to the market.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.275537",
      "updated_at": "2026-01-14T20:49:41.275544"
    },
    "54dfd5af549bf116": {
      "factor_id": "54dfd5af549bf116",
      "factor_name": "Structural_Exhaustion_Divergence_20D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the divergence between a 20-day price over-extension (residual from linear trend) and a 5-day rolling correlation between price returns and volume. A negative correlation during a period of high price residual indicates a 'churning' phase where price progress lacks volume conviction, signaling a terminal trend.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.213353",
      "updated_at": "2026-01-14T21:05:02.213360"
    },
    "34d16a9f7914acac": {
      "factor_id": "34d16a9f7914acac",
      "factor_name": "Decoupled_Trend_Reversion_Index",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(20), 20)) * ZSCORE(-1 * TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(20), 20)) * ZSCORE(-1 * TS_CORR($return, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Trend_Reversion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures structural mean-reversion opportunities by identifying assets that are significantly above their 20-day linear trend while experiencing a breakdown in the relationship between price returns and volume. The factor uses the negative 5-day price-volume correlation to highlight the decoupling of price action from market participation.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.230962",
      "updated_at": "2026-01-14T21:05:02.230968"
    },
    "309399ad265059fe": {
      "factor_id": "309399ad265059fe",
      "factor_name": "Volume_Conviction_Exhaustion_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20) * ((TS_CORR($return, $volume, 5) < 0) ? (-1 * TS_CORR($return, $volume, 5)) : 0))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20) * ((TS_CORR($return, $volume, 5) < 0) ? (-1 * TS_CORR($return, $volume, 5)) : 0))\" # Your output factor expression will be filled in here\n    name = \"Volume_Conviction_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the structural exhaustion index that focuses on identifying periods where price residuals are at extremes and the 5-day price-volume correlation is negative. This specific interaction targets 'absorption' phases where high volume fails to support further price extension, leading to a reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.248049",
      "updated_at": "2026-01-14T21:05:02.248055"
    }
  }
}