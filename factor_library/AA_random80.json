{
  "metadata": {
    "created_at": "2026-01-20T01:23:40.749871",
    "source": "all_factors_library_AA.json",
    "selection_method": "random_80",
    "random_seed": 42,
    "total_factors": 80
  },
  "factors": {
    "67c80b225c0e2bc4": {
      "factor_id": "67c80b225c0e2bc4",
      "factor_name": "Efficiency_Adjusted_Volume_Exhaustion_10D",
      "factor_expression": "RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($volume / (TS_MEAN($volume, 10) + 1e-8)) / (ABS(DELTA($close, 10)) / (TS_SUM(ABS($return), 10) + 1e-8) + 1e-8)) * RANK(TS_STD($return, 10))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Volume_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined exhaustion factor that captures the 'effort vs result' divergence. It calculates the ratio of volume intensity to price efficiency, then weights it by the cross-sectional rank of price volatility. A high value indicates high effort (volume) and high noise (volatility) with low directional progress (efficiency).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.259006",
      "updated_at": "2026-01-14T20:49:41.259012"
    },
    "c20dcf9d08b15587": {
      "factor_id": "c20dcf9d08b15587",
      "factor_name": "Ranked_Stability_Buying_Pressure_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_Buying_Pressure_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the hypothesis by cross-sectionally ranking trend stability (R-squared of price vs time) and multiplying it by the buying pressure ratio over a 5-day window, adjusted for price positioning.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.869921",
      "updated_at": "2026-01-14T17:27:11.869929"
    },
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T17:06:25.115468"
    },
    "cfc3e507d3af3de2": {
      "factor_id": "cfc3e507d3af3de2",
      "factor_name": "Volume_Efficiency_ZScore_Divergence",
      "factor_expression": "RANK(($close - TS_MEAN($close, 20)) / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_ZSCORE(($high - $low) / ($volume + 1e-12), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - TS_MEAN($close, 20)) / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_ZSCORE(($high - $low) / ($volume + 1e-12), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Efficiency_ZScore_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets terminal exhaustion by measuring the interaction between a 20-day price deviation and the 10-day time-series Z-score of volume efficiency. By using TS_ZSCORE, it highlights extreme 'churn' where price progress per unit of volume is significantly lower than its recent history, signaling a blow-off top or bottom.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 'Liquidity-Driven Exhaustion Factor' identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day trend of 'Volume Efficiency' (Price Range per unit of Volume).\n                Concise Observation: Previous attempts using linear regression residuals and price-volume correlations failed due to instability (NaNs) and noise; however, the 'Trend Divergence' hypothesis (Hypothesis 3) showed that efficiency decay is the most robust predictor of reversal when paired with price extension.\n                Concise Justification: Using a 20-day Moving Average for extension is more stable than regression residuals. By measuring 'Volume Efficiency' as (High-Low)/Volume, we capture the 'effort vs. result' relationship; a falling trend in this ratio during a price peak suggests that institutional liquidity is absorbing the move, leading to a blow-off top or bottom.\n                Concise Knowledge: If a stock's price is significantly extended from its 20-day mean while the 'Price Range per Volume' (efficiency) is declining, it indicates that increasing liquidity is required to move the price smaller distances; when this 'churn' occurs at price extremes, a mean-reversion is imminent.\n                concise Specification: The factor is calculated as: Rank(Close / TS_MEAN(Close, 20) - 1) * Rank(-1 * TS_SLOPE((High - Low) / (Volume + 1e-12), 10)). This targets the interaction between a 20-day price deviation and a 10-day decay in volume-driven price movement efficiency.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034841674078172,
        "ICIR": 0.0221572133423855,
        "RankIC": 0.0197789339949966,
        "RankICIR": 0.1233941161010065,
        "annualized_return": -0.0190783538830311,
        "information_ratio": -0.2253320618783825,
        "max_drawdown": -0.259735875124117
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:09:29.093047",
      "updated_at": "2026-01-14T21:09:29.093052"
    },
    "b6d66145f7cdc66f": {
      "factor_id": "b6d66145f7cdc66f",
      "factor_name": "Conditional_Trend_Stability_2D",
      "factor_expression": "(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Trend_Stability_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional logic where the 20-day trend stability (RSQR) is only considered if the 2-day volume-weighted return is positive. It focuses on 'quiet' institutional accumulation that is just beginning to break out with volume support, filtering out stagnant or decaying trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.137115",
      "updated_at": "2026-01-14T17:43:57.137122"
    },
    "fbf7da796f254b8c": {
      "factor_id": "fbf7da796f254b8c",
      "factor_name": "Volume_Surge_Breakout_Intensity_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Breakout_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the interaction between price momentum and a volume-weighted volatility squeeze. Instead of a raw price range, it uses the standard deviation of returns normalized by a 20-day baseline, multiplied by a volume surge ratio (5-day vs 20-day) to filter for institutional participation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.601633",
      "updated_at": "2026-01-14T17:41:01.601641"
    },
    "ba52212e001d0431": {
      "factor_id": "ba52212e001d0431",
      "factor_name": "Efficiency_Adjusted_Persistence_15D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency hypothesis that focuses on the Z-score interaction between volume-ranked returns and a price-range stability metric. It identifies assets where the conviction (volume-weighted returns) significantly outweighs the noise (price range), using Z-scores to ensure cross-sectional comparability.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.183691",
      "updated_at": "2026-01-14T17:39:41.183697"
    },
    "0a2809d6fd472731": {
      "factor_id": "0a2809d6fd472731",
      "factor_name": "Efficiency_Volatility_Ratio_20D",
      "factor_expression": "RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of price discovery by comparing the price-VWAP ratio to the 20-day standard deviation of returns. It targets stocks where price is trending above the volume-weighted average under conditions of low relative volatility, which indicates a stable, high-conviction trend.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.391667",
      "updated_at": "2026-01-14T17:29:39.391673"
    },
    "0a63c9f3468d0b56": {
      "factor_id": "0a63c9f3468d0b56",
      "factor_name": "Liquidity_Driven_Exhaustion_Factor_20D",
      "factor_expression": "RANK($close / (TS_MEAN($close, 20) + 1e-8) - 1) * RANK(-1 * REGBETA(($high - $low) / ($volume + 1e-12), SEQUENCE(10), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_MEAN($close, 20) + 1e-8) - 1) * RANK(-1 * REGBETA(($high - $low) / ($volume + 1e-12), SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Driven_Exhaustion_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day decay of 'Volume Efficiency'. It uses the distance from the 20-day moving average to measure extension and the slope of (High-Low)/Volume to measure the 'effort vs. result' relationship. A falling efficiency during a price peak suggests institutional absorption.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 'Liquidity-Driven Exhaustion Factor' identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day trend of 'Volume Efficiency' (Price Range per unit of Volume).\n                Concise Observation: Previous attempts using linear regression residuals and price-volume correlations failed due to instability (NaNs) and noise; however, the 'Trend Divergence' hypothesis (Hypothesis 3) showed that efficiency decay is the most robust predictor of reversal when paired with price extension.\n                Concise Justification: Using a 20-day Moving Average for extension is more stable than regression residuals. By measuring 'Volume Efficiency' as (High-Low)/Volume, we capture the 'effort vs. result' relationship; a falling trend in this ratio during a price peak suggests that institutional liquidity is absorbing the move, leading to a blow-off top or bottom.\n                Concise Knowledge: If a stock's price is significantly extended from its 20-day mean while the 'Price Range per Volume' (efficiency) is declining, it indicates that increasing liquidity is required to move the price smaller distances; when this 'churn' occurs at price extremes, a mean-reversion is imminent.\n                concise Specification: The factor is calculated as: Rank(Close / TS_MEAN(Close, 20) - 1) * Rank(-1 * TS_SLOPE((High - Low) / (Volume + 1e-12), 10)). This targets the interaction between a 20-day price deviation and a 10-day decay in volume-driven price movement efficiency.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034841674078172,
        "ICIR": 0.0221572133423855,
        "RankIC": 0.0197789339949966,
        "RankICIR": 0.1233941161010065,
        "annualized_return": -0.0190783538830311,
        "information_ratio": -0.2253320618783825,
        "max_drawdown": -0.259735875124117
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:09:29.075139",
      "updated_at": "2026-01-14T21:09:29.075146"
    },
    "1a83f9422320ba4d": {
      "factor_id": "1a83f9422320ba4d",
      "factor_name": "Vol_Weighted_Exhaustion_Index",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8)) * ((TS_ZSCORE($volume, 20) > 0) ? (TS_ZSCORE($volume, 20)) : (0)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified implementation of the conviction-exhaustion hypothesis. It measures 10-day price exhaustion by dividing the 10-day return by its 10-day volatility, then multiplying by the product of the volume Z-score and the change in price-volume correlation to isolate high-volume trend decoupling.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.848804",
      "updated_at": "2026-01-14T17:26:49.848810"
    },
    "89ab97f85fe9e5e0": {
      "factor_id": "89ab97f85fe9e5e0",
      "factor_name": "PVDE5_Efficiency_Factor",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEAN(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"PVDE5_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline. This captures 'low-friction' price discovery where institutional absorption occurs with minimal market impact.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Efficiency (PVDE5) factor identifies high-conviction trends by isolating positive price momentum that occurs alongside a declining 5-day rolling volume coefficient of variation relative to its 20-day baseline.\n                Concise Observation: Previous attempts using ratios of price-to-volume volatility (VAPVE10) or simple volume stability (IIE5) failed because they were either too noisy or over-penalized necessary volume participation; however, they consistently showed that volume stability helps in drawdown reduction.\n                Concise Justification: By measuring the 'divergence' where price moves up but volume volatility (CV) decreases, we isolate 'low-friction' price discovery. Using a 5-day window for recent dynamics and a 20-day window for the volume baseline ensures the factor captures a relative improvement in liquidity stability rather than just absolute low volume.\n                Concise Knowledge: In daily equity markets, a 'quiet' trend is more sustainable than a 'noisy' one; if price momentum is positive while volume volatility is contracting relative to its long-term average, it signals institutional absorption of supply with minimal market impact, leading to higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($return, 5)) * (TS_MEAN(TS_STD($volume, 5) / TS_MEAN($volume, 5), 20) / (TS_STD($volume, 5) / TS_MEAN($volume, 5) + 1e-6)). This multiplies 5-day momentum by the ratio of the 20-day average volume CV to the current 5-day volume CV. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042505116546111,
        "ICIR": 0.0343437633704383,
        "RankIC": 0.0190189933123043,
        "RankICIR": 0.1556622755870954,
        "annualized_return": 0.0285551835405233,
        "information_ratio": 0.5040700607358951,
        "max_drawdown": -0.083728627216693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:59:06.296769",
      "updated_at": "2026-01-14T20:59:06.296777"
    },
    "e3b73174f7fdec13": {
      "factor_id": "e3b73174f7fdec13",
      "factor_name": "Volume_Weighted_Lag_Momentum_20D",
      "factor_expression": "TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Lag_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the lead-lag hypothesis by correlating current returns with the 5-day lagged volume-weighted price change proxy, aiming to identify trends backed by significant trading activity.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.638025",
      "updated_at": "2026-01-15T18:47:04.638031"
    },
    "bdb78b063c6c4d5b": {
      "factor_id": "bdb78b063c6c4d5b",
      "factor_name": "VWRE10_Efficiency_Factor",
      "factor_expression": "TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWRE10_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The 10-day Volume-Weighted Return Efficiency (VWRE10) factor identifies sustainable price trends by scaling the 10-day return by the inverse of the volume coefficient of variation. This prioritizes moves supported by high, stable liquidity, filtering out speculative spikes on erratic volume.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.490223",
      "updated_at": "2026-01-14T20:36:31.490230"
    },
    "974be850a4998b4d": {
      "factor_id": "974be850a4998b4d",
      "factor_name": "Efficiency_Exhaustion_Index_5D",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8), 5)",
      "factor_implementation_code": "",
      "factor_description": "This factor targets liquidity-driven price spikes by measuring the 5-day price impact per unit of volume, further normalized by the time-series volatility of the ratio. It captures instances where price moves are 'too efficient' relative to historical norms, signaling potential exhaustion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.738072",
      "updated_at": "2026-01-14T17:25:41.738079"
    },
    "c2ac425b322611c4": {
      "factor_id": "c2ac425b322611c4",
      "factor_name": "Exhaustion_Rank_Spread_10D",
      "factor_expression": "RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Rank_Spread_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the price-volume divergence hypothesis that uses the 10-day time-series rank of returns compared to the 10-day time-series rank of volume growth. It targets assets where volume is reaching extreme historical levels (high rank) while price gains are lagging (low rank).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.005509",
      "updated_at": "2026-01-14T20:40:44.005515"
    },
    "a24b397b359720ef": {
      "factor_id": "a24b397b359720ef",
      "factor_name": "VW_Momentum_Stability_10D",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * (($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * (($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Stability_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the stability of volume-weighted returns over a 10-day period (mean/std) and scales it by the relative position of the current price within its 20-day high-low range. This identifies persistent institutional accumulation while filtering out exhausted trends where the price is near a 20-day peak.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 10,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Stability', where alpha is maximized by the interaction between the 10-day volume-ranked return and its 10-day standard deviation, filtered by the price's relative position within its 20-day high-low range.\n                Concise Observation: Previous attempts using subtraction (Momentum - Volatility) or simple VWAP ratios achieved high IC (0.0041) but low IR and high drawdown, suggesting the signal captures correlation but lacks the 'quality' or 'timing' needed for portfolio alpha.\n                Concise Justification: A 'Momentum Stability' ratio (Mean/Std) is more robust than subtraction because it normalizes the conviction by the risk taken to achieve it. Using a 20-day High-Low range position as a filter is more effective than a VWAP ratio for identifying 'room to grow' versus 'exhaustion' in a cross-sectional context.\n                Concise Knowledge: If volume-weighted momentum is divided by its own rolling volatility (stability), it identifies persistent institutional accumulation; when this stability is gated by a price-range position (e.g., price is not at a 20-day peak), it filters out exhausted trends in the daily price-volume data.\n                concise Specification: The factor 'VW_Momentum_Stability_10D' is calculated as the 10-day rolling mean of ($return * rank($volume)) divided by its 10-day rolling standard deviation. This ratio is then multiplied by the 'Range Position' defined as ($close - ts_min($low, 20)) / (ts_max($high, 20) - ts_min($low, 20) + 1e-6).\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039708830785583,
        "ICIR": 0.0294388017895317,
        "RankIC": 0.0194767156135878,
        "RankICIR": 0.1478709276916057,
        "annualized_return": 0.065756071935017,
        "information_ratio": 0.9962170733913044,
        "max_drawdown": -0.0882252406645723
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:31.737085",
      "updated_at": "2026-01-14T18:10:31.737092"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T17:06:25.178740"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T17:06:25.147238"
    },
    "824685211c1a9db6": {
      "factor_id": "824685211c1a9db6",
      "factor_name": "Ranked_Price_Impact_Ratio_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Price_Impact_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 5-day return relative to the total volume traded, applying a cross-sectional rank to identify stocks with the most extreme price-volume efficiency. This helps isolate stocks where the price has moved significantly on relatively low volume, indicating a lack of fundamental absorption.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.771471",
      "updated_at": "2026-01-14T17:25:41.771477"
    },
    "fc4601e963b9c4b1": {
      "factor_id": "fc4601e963b9c4b1",
      "factor_name": "Volatility_Scaled_Impact_Rank_5D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Scaled_Impact_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of price movement per unit of volume, normalized by the stock's 20-day return standard deviation. By applying a cross-sectional rank, it identifies stocks with the most extreme liquidity-induced price exhaustion relative to their historical volatility baseline.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.191520",
      "updated_at": "2026-01-14T17:37:25.191526"
    },
    "6e15d6b03df56549": {
      "factor_id": "6e15d6b03df56549",
      "factor_name": "Liquidity_Acceleration_Exhaustion_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Acceleration_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the 'acceleration' of price range relative to volume growth. A high ratio indicates that price volatility is expanding faster than liquidity support, signaling a 'hollow' move. This is weighted by the 5-day average position of the close within the high-low range to identify exhaustion patterns.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:57.989967",
      "updated_at": "2026-01-14T17:40:57.989974"
    },
    "040b0ca4fc42fff3": {
      "factor_id": "040b0ca4fc42fff3",
      "factor_name": "Trend_Conviction_Volume_Stability_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($return, DELTA($volume, 1), 60)) / (1.0 + RANK(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Trend_Conviction_Volume_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the composite hypothesis focusing on the interaction between price-volume correlation and volume stability. It identifies stocks where price trends are backed by consistent, non-volatile volume growth, suggesting high-quality institutional accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 60-day price-volume correlation (CORD60), the 5-day relative price rank (RANK5), and the 10-day volume volatility (VSTD10) can capture the interplay between long-term trend quality, short-term mean reversion, and liquidity stability to predict future returns.\n                Concise Observation: The provided components suggest that market efficiency can be exploited by combining long-term momentum quality (CORD60), short-term positioning (RANK5), and the stability of market participation (VSTD10).\n                Concise Justification: High price-volume correlation indicates strong conviction in a trend, while low volume standard deviation suggests institutional accumulation or distribution rather than erratic retail trading, and a low 5-day rank identifies potential oversold bounce opportunities.\n                Concise Knowledge: If price and volume changes are positively correlated over a long window, the trend is considered healthy; if short-term price rank is extreme, mean reversion is likely; and if volume volatility is low, the price movement is supported by stable capital flows.\n                concise Specification: The factor will be calculated as a linear or non-linear combination of: 1) 60-day correlation between 1-day lagged returns and 1-day lagged log volume changes; 2) 5-day cross-sectional rank of closing prices; 3) 10-day rolling standard deviation of volume normalized by its mean.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041774855935651,
        "ICIR": 0.0304178684647742,
        "RankIC": 0.0183805260950416,
        "RankICIR": 0.1331805502718588,
        "annualized_return": 0.0664537386745702,
        "information_ratio": 0.9211946263394244,
        "max_drawdown": -0.1174550153255256
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:24:44.574184",
      "updated_at": "2026-01-14T20:24:44.574190"
    },
    "04d981c8a3a16b84": {
      "factor_id": "04d981c8a3a16b84",
      "factor_name": "Intraday_Range_Efficiency_V20",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($close, 5) + 1e-8)) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-6) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / (TS_MEAN($close, 5) + 1e-8)) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-6) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Range_Efficiency_V20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price expansion intensity relative to long-term liquidity consistency. It uses the 5-day average intraday range normalized by the 20-day volume coefficient of variation. High values indicate price moves occurring within a stable, high-participation environment.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 5-day Intraday Intensity Efficiency (IIE5) factor, calculated as the 5-day sum of the intraday price range relative to the 20-day volume stability (Mean/STD), identifies high-conviction breakouts by isolating price expansion supported by institutional liquidity regimes.\n                Concise Observation: Previous attempts showed that 5-day windows provide excellent risk control (reduced drawdown) but weak alpha, while 20-day windows for volume better define the 'normal' liquidity regime; simple close-to-close returns failed to capture the 'effort' of price movement compared to intraday ranges.\n                Concise Justification: Using a 20-day window for the volume-to-volatility ratio establishes a robust baseline of liquidity consistency, while the 5-day intraday range (High-Low) captures the intensity of recent price action. Dividing the range by volume volatility (rather than just volume) filters for moves occurring within a stable participation environment, which historically leads to higher IC than raw momentum.\n                Concise Knowledge: If short-term intraday price expansion (High-Low) is scaled by a long-term volume stability metric (20-day Mean/STD), the signal distinguishes between 'low-friction' institutional breakouts and 'high-noise' retail spikes; in daily equity data, price moves that expand the high-low range while maintaining a stable liquidity baseline exhibit higher trend persistence.\n                concise Specification: The factor is calculated as: (TS_SUM($high - $low, 5) / TS_MEAN($close, 5)) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-6)). The intraday range is normalized by the 5-day mean price to ensure scale-invariance, and the final output is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0007015828137994,
        "ICIR": 0.0056922053075266,
        "RankIC": 0.0114665980311102,
        "RankICIR": 0.0896322677862204,
        "annualized_return": 0.0076338712959795,
        "information_ratio": 0.1210668798831529,
        "max_drawdown": -0.1752543301605067
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:43:35.223644",
      "updated_at": "2026-01-14T20:43:35.223655"
    },
    "8c475560c22dde7f": {
      "factor_id": "8c475560c22dde7f",
      "factor_name": "Kaufman_Exhaustion_ZScore_5D_20D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Kaufman_Exhaustion_ZScore_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by multiplying the 5-day Kaufman Efficiency Ratio (ER) with the negative of the 20-day price Z-score. A low ER (high path length relative to displacement) at price extremes (high Z-score) suggests 'churning' and imminent mean reversion.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.658788",
      "updated_at": "2026-01-15T18:48:21.658796"
    },
    "57a1a7219e6a9c5e": {
      "factor_id": "57a1a7219e6a9c5e",
      "factor_name": "Divergence_ZScore_Exhaustion_20D",
      "factor_expression": "TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close, 20) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Divergence_ZScore_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price positioning and volume intensity. It calculates the Z-score of the current price relative to its 20-day history and multiplies it by the volume ratio. A high price Z-score combined with a high volume ratio often signals a liquidity-thin peak or trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 2,
      "hypothesis": "Hypothesis: A 20-day 'Volume-Price Divergence Index' that combines volatility-normalized price distance from the monthly high with the ratio of short-term volume to its medium-term average can identify structural trend exhaustion more effectively than short-term raw correlations.\n                Concise Observation: The previous 5-day window was too sensitive to noise, resulting in a low IC and high drawdown; the feedback suggests that simple linear rank combinations of short-term price-volume metrics fail to account for the 'blow-off' nature of volume surges relative to a baseline.\n                Concise Justification: Extending the lookback to 20 days (one trading month) establishes a more stable resistance level, while normalizing the price distance by standard deviation (Z-score) accounts for varying asset volatility, and using a volume ratio (V/V_MA) highlights abnormal exhaustion activity.\n                Concise Knowledge: If a stock reaches a new 20-day high on declining relative volume while price volatility is expanding, it indicates a 'liquidity-thin' peak; when prices are significantly stretched above their 20-day mean but volume fails to exceed its 20-day moving average, the probability of a mean-reversion event increases.\n                concise Specification: The factor will calculate the 20-day maximum price relative to the current close normalized by the 20-day standard deviation, multiplied by the ratio of the 5-day average volume to the 20-day average volume, targeting a 20-day lookback period.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:23.198967",
      "updated_at": "2026-01-14T20:37:23.198973"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T17:36:23.056545"
    },
    "7744865b19c42ffe": {
      "factor_id": "7744865b19c42ffe",
      "factor_name": "Volatility_Adjusted_Decay_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Decay_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor enhances the resistance exhaustion signal by normalizing the distance to the 10-day high by the 10-day standard deviation of returns (volatility filter) and a decay-weighted sum of absolute returns. It targets stocks where recent 'churn' is high but price progress toward resistance is stalling, weighted by relative volume intensity.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.813949",
      "updated_at": "2026-01-14T21:08:05.813956"
    },
    "8f1ec6ae1129b7b7": {
      "factor_id": "8f1ec6ae1129b7b7",
      "factor_name": "Relative_Volatility_Conviction_10D",
      "factor_expression": "TS_MEAN($return, 10) * (TS_STD($volume / (TS_MEDIAN($volume, 10) + 1e-8), 10) / (TS_STD($return, 10) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return, 10) * (TS_STD($volume / (TS_MEDIAN($volume, 10) + 1e-8), 10) / (TS_STD($return, 10) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volatility_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends where price efficiency is high. It compares the 10-day price momentum to the ratio of price volatility (standard deviation of returns) and the volatility of volume turnover (proxied by volume divided by its 10-day median). It avoids previous duplicated sub-expressions by using TS_MEDIAN for normalization.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day Volatility-Adjusted Price-Volume Efficiency (VAPVE10) factor, which scales the 10-day price return by the ratio of 10-day price volatility to 10-day volume volatility, identifies high-conviction trends by isolating price movements that require minimal 'liquidity effort' relative to their volatility.\n                Concise Observation: Previous iterations (Hypothesis 5 & 6) showed that while volume stability (Mean/STD) reduces drawdown, it dilutes alpha when used as a simple multiplier because it doesn't account for the intrinsic price volatility (ATR/STD) of the asset.\n                Concise Justification: By comparing price volatility (TS_STD of returns) to volume volatility (TS_STD of volume), we create a 'Relative Volatility Efficiency' metric. A high return achieved with low volume volatility relative to price volatility suggests institutional conviction and a lack of retail-driven noise, addressing the 'signal-to-noise' issues seen in previous failures.\n                Concise Knowledge: If price returns are high while the ratio of price volatility to volume volatility is also high, it indicates a 'low-friction' regime where price moves efficiently without erratic volume spikes; in daily equity data, this 'quiet' efficiency is more predictive of trend persistence than high-volume breakouts which often signal exhaustion.\n                concise Specification: The factor is defined as: (TS_SUM($return, 10)) / ((TS_STD($return, 10) + 1e-6) / (TS_STD($volume / TS_MEAN($volume, 10), 10) + 1e-6)). The volume standard deviation is calculated on volume normalized by its 10-day mean to ensure scale-invariance across instruments. The final value is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0004467851129522,
        "ICIR": 0.0032835220956772,
        "RankIC": 0.0144502668176974,
        "RankICIR": 0.1098915545166409,
        "annualized_return": 0.0208351558182856,
        "information_ratio": 0.3093396996618583,
        "max_drawdown": -0.1555657185981356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:54:33.609421",
      "updated_at": "2026-01-14T20:54:33.609427"
    },
    "54dfd5af549bf116": {
      "factor_id": "54dfd5af549bf116",
      "factor_name": "Structural_Exhaustion_Divergence_20D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20)) * RANK(-1 * TS_CORR($return, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the divergence between a 20-day price over-extension (residual from linear trend) and a 5-day rolling correlation between price returns and volume. A negative correlation during a period of high price residual indicates a 'churning' phase where price progress lacks volume conviction, signaling a terminal trend.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Index' identifies trend reversals by detecting the divergence between a 20-day price over-extension and a 5-day rolling correlation between price returns and volume, specifically targeting periods where price and volume decouple.\n                Concise Observation: Previous attempts using linear multipliers or ranks of volume efficiency (Return/Volume) failed to beat the SOTA because they didn't account for the directionality of volume support; the 10-day residual was also noted as potentially too noisy for identifying established trend exhaustion.\n                Concise Justification: A healthy trend requires price and volume to move in tandem (positive correlation). A negative correlation between price returns and volume during a period of high price residual indicates that either price is rising on falling volume (lack of conviction) or price is stalling on high volume (absorption/distribution), both of which are terminal signals.\n                Concise Knowledge: If a medium-term trend (20-day residual) persists while the price-volume correlation (5-day window) turns negative, the trend is likely entering a 'churning' phase; when price progress becomes decoupled from volume support at extreme deviations, the probability of a structural mean-reversion increases.\n                concise Specification: The factor is defined as: Rank(Close - 20-day Linear Trend) * Rank(-1 * 5-day Rolling Correlation(Return, Volume)). The 20-day window provides a stable trend baseline, while the negative correlation captures the 'decoupling' of price and volume conviction. The final product is cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:05:02.213353",
      "updated_at": "2026-01-14T21:05:02.213360"
    },
    "8fe21fdb459ddca8": {
      "factor_id": "8fe21fdb459ddca8",
      "factor_name": "Volume_Weighted_Leader_Signal",
      "factor_expression": "ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(MEAN(TS_MEAN($return, 10) * RANK($volume))) / (RANK($volume) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Leader_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis that weights the 10-day momentum of the entire cross-section by volume rank to emphasize leader behavior, then applies this signal specifically to lower-volume assets.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price momentum of high-volume stocks (market leaders) within the same sector positively predicts the subsequent 5-day returns of lower-volume stocks (laggards) due to information diffusion delays.\n                Concise Observation: Market leaders often react instantaneously to macroeconomic shifts or sector news, while smaller or less liquid stocks frequently exhibit a delayed response in price discovery.\n                Concise Justification: Friction in information processing and liquidity constraints cause a lead-lag effect where the price action of dominant firms precedes the movement of the broader sector.\n                Concise Knowledge: If information flows sequentially from market leaders to laggards, then the lagged returns of high-liquidity assets will serve as a leading indicator for the future returns of low-liquidity assets within the same economic cluster.\n                concise Specification: Calculate the average 10-day return of the top 10% most liquid stocks as a proxy for leader momentum and use it to predict the cross-sectional returns of the remaining stocks over a 5-day forward window.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029869228032052,
        "ICIR": 0.0209942001856705,
        "RankIC": 0.0195450261616047,
        "RankICIR": 0.1434193126511699,
        "annualized_return": 0.0343406477070409,
        "information_ratio": 0.4681149415596617,
        "max_drawdown": -0.1059764271623404
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:38:45.848571",
      "updated_at": "2026-01-15T17:38:45.848577"
    },
    "6ebedce912a42e84": {
      "factor_id": "6ebedce912a42e84",
      "factor_name": "Net_Conviction_VWAP_Filter",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Net_Conviction_VWAP_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 'net conviction' score by subtracting 10-day volatility from volume-weighted momentum. It then applies a non-linear filter based on the distance from the 20-day VWAP (proxied by TS_SUM of price-volume) to identify stocks with strong support.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 9,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Divergence from Volatility', where alpha is maximized by the difference between 10-day volume-weighted return persistence and 10-day price volatility, filtered by the asset's position relative to its 20-day VWAP.\n                Concise Observation: Previous attempts using multiplicative interactions or simple rank-subtractions failed because they either amplified noise or over-smoothed the signal; however, the SOTA (Hypothesis 3) and high-IC versions (Hypothesis 6/7) consistently utilized VWAP as a 'location' filter and volume-ranked returns for conviction.\n                Concise Justification: By subtracting the 10-day volatility (standard deviation) from the 10-day volume-weighted return persistence, we create a 'net conviction' score. Filtering this by the 20-day VWAP ensures we avoid 'overheated' stocks where price has already moved too far from the average cost basis, addressing the 'late-stage trend' failure of Hypothesis 8.\n                Concise Knowledge: In quant equity, if an asset's volume-weighted momentum significantly exceeds its realized volatility (high return-to-risk persistence), it indicates institutional accumulation; when this occurs while the price is near or below the 20-day VWAP, it identifies a low-risk entry point for trend continuation rather than an exhausted spike.\n                concise Specification: The factor 'VW_Momentum_Vol_Divergence' is defined as: (ts_mean($return * rank($volume), 10) - ts_std($return, 10)) * ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0041107781040163,
        "ICIR": 0.0266018454123839,
        "RankIC": 0.0186597296899252,
        "RankICIR": 0.1218079143956096,
        "annualized_return": 0.0312271284971009,
        "information_ratio": 0.3824112733783517,
        "max_drawdown": -0.172297884389554
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:06:51.101247",
      "updated_at": "2026-01-14T18:06:51.101253"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T17:39:41.148683"
    },
    "68734068d9c35316": {
      "factor_id": "68734068d9c35316",
      "factor_name": "Efficiency_Adjusted_Compression_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Compression_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the quality of a volatility squeeze by interacting a 20-day compression ratio with a price-volume efficiency metric. It uses the ratio of 20-day price range to the 5-day average true range (simplified) and weights it by the 5-day price change normalized by volume volatility to capture institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 10,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day range-based 'Coiling Index' is interacted with a 'Price-Volume Efficiency' score that measures the consistency of price movement relative to volume dispersion, rather than simple volume ratios.\n                Concise Observation: Previous additive rank models (Hypothesis 9) improved IC and Max Drawdown but lost IR, suggesting that while the signal is robust, the volume-price component (VPD) is still too noisy and fails to capture the 'quality' of the accumulation phase.\n                Concise Justification: Replacing simple volume ratios with a 'Price-Volume Efficiency' metric (Price Delta / Volume StdDev) isolates trends where price moves with minimal volume-induced friction. Combining this with a range-based 'Coiling Index' (20D/5D Range) ensures we target stocks that are both tightly consolidated and efficiently accumulated.\n                Concise Knowledge: If a stock displays extreme price range contraction (coiling), the subsequent move is more sustainable when the preceding price action shows high 'efficiency' (low volume-weighted price variance), as this indicates controlled institutional absorption rather than erratic retail speculation.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(5)) / (Std($volume * $return, 5) + 1e-6)). This uses a 20/5 range compression rank and a 5-day price change normalized by the standard deviation of volume-weighted returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059719283971487,
        "ICIR": 0.0440422913021039,
        "RankIC": 0.0196755371698568,
        "RankICIR": 0.1547587243327648,
        "annualized_return": 0.0755824516069986,
        "information_ratio": 1.1644873779148774,
        "max_drawdown": -0.0928560916120309
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:15:32.202203",
      "updated_at": "2026-01-14T18:15:32.202209"
    },
    "ed6041fff76a183d": {
      "factor_id": "ed6041fff76a183d",
      "factor_name": "Robust_Volume_Efficiency_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($return, 5) * (TS_MEDIAN($volume, 5) / (TS_STD($volume, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Robust_Volume_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined volume efficiency factor that uses the 5-day price return and the ratio of median volume to volume standard deviation to reduce the impact of outlier spikes. The factor is cross-sectionally ranked to ensure comparability across different liquidity profiles.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 5-day Price-Volume Divergence Factor, calculated as the product of the 5-day price return and the 5-day volume-to-volatility ratio, identifies short-term exhaustion or breakout regimes by emphasizing consistent liquidity support over price magnitude.\n                Concise Observation: Previous attempts with 10-day and 20-day windows failed to capture alpha or resulted in signal dilution, while the 'NaN' results in Hypothesis 4 suggest numerical instability when volume standard deviation approaches zero in longer windows.\n                Concise Justification: Shortening the window to 5 days captures the immediate liquidity regime. Using the Volume-to-Volatility ratio (Mean/STD) instead of just Standard Deviation provides a dimensionless 'signal-to-noise' metric that identifies where volume is consistently high, reducing the impact of outlier spikes that often lead to false momentum signals.\n                Concise Knowledge: If a short-term price trend (5 days) is supported by a high Volume-to-Volatility ratio (Mean/STD), it indicates high-conviction institutional flow; conversely, price moves with low volume stability are likely noise-driven and prone to immediate reversal in the Qlib predictive framework.\n                concise Specification: The factor is defined as: (Return_5) * (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + EPS)), where EPS is a small constant (1e-6) to prevent division by zero. The final factor should be cross-sectionally ranked to ensure stability and comparability across instruments with different liquidity profiles.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045242241001771,
        "ICIR": 0.0367556521916585,
        "RankIC": 0.0193057331628799,
        "RankICIR": 0.1598757947299785,
        "annualized_return": 0.0261282657236021,
        "information_ratio": 0.4364552510934094,
        "max_drawdown": -0.0838641675298448
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:39:43.480342",
      "updated_at": "2026-01-14T20:39:43.480349"
    },
    "cb229012ab6ccba6": {
      "factor_id": "cb229012ab6ccba6",
      "factor_name": "VW_Momentum_Convexity_10_20",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Convexity_10_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the acceleration of volume-weighted momentum by subtracting the 20-day trend from the 10-day momentum, filtered by the price position relative to a 5-day VWAP proxy. This identifies high-conviction institutional accumulation when the price is efficiently positioned.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 6,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Convexity', where alpha is maximized by identifying assets where the 10-day volume-weighted momentum is accelerating relative to its 20-day trend, specifically when the price is trading below its 5-day high-volume price level (VWAP proxy).\n                Concise Observation: Previous attempts failed because rank-subtraction (Hypothesis 5) over-smoothed the signal and 15-day windows were too lagging; however, the successful SOTA (Hypothesis 3) utilized a price-to-VWAP ratio which provided a necessary 'location' filter that the subsequent failures lacked.\n                Concise Justification: Momentum 'acceleration' (10d vs 20d) captures the second derivative of price action which is more predictive of future returns than simple velocity. Re-introducing the VWAP-based 'location' filter (from Hypothesis 3) ensures that the momentum signal is only active when the price is efficiently positioned relative to recent volume-weighted costs.\n                Concise Knowledge: If the short-term (10-day) volume-weighted return exceeds the medium-term (20-day) baseline, it indicates a convexity in institutional accumulation; when this is combined with a price position near a short-term liquidity anchor (5-day VWAP), it identifies high-probability entry points for trend continuation.\n                concise Specification: The factor 'VW_Momentum_Convexity_10_20' is defined as the subtraction of the 20-day mean of ($return * rank($volume)) from the 10-day mean of ($return * rank($volume)), then multiplied by the ratio ($close / ts_mean($close * $volume, 5) / ts_mean($volume, 5)). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037946798042562,
        "ICIR": 0.0289506865260227,
        "RankIC": 0.0185580027774798,
        "RankICIR": 0.1416468970919491,
        "annualized_return": 0.0305367437495582,
        "information_ratio": 0.5025696895316144,
        "max_drawdown": -0.1023061839122148
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:21.596856",
      "updated_at": "2026-01-14T17:46:21.596864"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T16:57:26.431941"
    },
    "7e17d6f59c434e2c": {
      "factor_id": "7e17d6f59c434e2c",
      "factor_name": "VWPP_ZScore_Filtered_20D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VWPP_ZScore_Filtered_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Weighted Price Persistence factor that applies a cross-sectional Z-score to the volume-weighted return component to improve comparability. The factor is activated only when the price is above the 10-day VWAP, identifying efficient momentum regimes.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.278927",
      "updated_at": "2026-01-14T17:33:11.278933"
    },
    "c2157f4cefd0d4cf": {
      "factor_id": "c2157f4cefd0d4cf",
      "factor_name": "Volatility_Adjusted_Resistance_Gap_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + 1e-8)) * (1 + TS_PCTCHANGE($volume, 10))",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the gap between the 10-day high and the current close, normalized by the 10-day standard deviation of returns, and weighted by the 10-day volume trend. It specifically targets assets where price is lagging behind its resistance while volume is surging, indicating a distribution phase.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.086028",
      "updated_at": "2026-01-14T21:02:22.086034"
    },
    "2b68e51e20d01e99": {
      "factor_id": "2b68e51e20d01e99",
      "factor_name": "Volatility_Filtered_Resistance_Surge",
      "factor_expression": "ZSCORE((TS_MAX($high, 20) - $close) / (TS_STD($close, 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 5) * (TS_MEAN($high - $low, 10) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MAX($high, 20) - $close) / (TS_STD($close, 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 5) * (TS_MEAN($high - $low, 10) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Filtered_Resistance_Surge\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies exhaustion by looking for volume spikes that occur when the price is struggling to reach the 20-day high, specifically in regimes where the current price range is small relative to the average true range (compression).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 10,
      "hypothesis": "Hypothesis: A 20-day 'Resistance-Compression-Volume' factor identifies mean-reversion by detecting stocks where 5-day volume surges occur during 10-day price range compression (low efficiency) while the price remains significantly below the 20-day high.\n                Concise Observation: The previous SOTA (IR 1.23) successfully combined 20-day resistance with 5-day volume surges, but suffered from increased drawdown, likely due to misidentifying high-volatility breakouts as exhaustion.\n                Concise Justification: By adding a volatility-compression filter (Range/ATR), we isolate 'churning' (high volume, low range) from 'breakouts' (high volume, high range). This refinement targets the specific 'absorption' phase of market peaks, which should stabilize the signal and reduce the drawdown observed in the previous 20-day model.\n                Concise Knowledge: If extreme volume (effort) is injected into a stock characterized by tight price ranges (compression/low efficiency) near structural resistance, the probability of a trend reversal increases; When high turnover fails to expand the price range, it indicates institutional absorption of buying pressure.\n                concise Specification: The factor interacts the 20-day Distance to High (normalized by 20-day std) with the ratio of the 5-day volume surge (V/V_MA20) and the inverse of the 10-day Range Efficiency (10-day Range / 10-day ATR). The components are combined via cross-sectional ranks to ensure robustness and focus on idiosyncratic exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042780226830892,
        "ICIR": 0.0332719396992201,
        "RankIC": 0.0160093466381118,
        "RankICIR": 0.1272308128775134,
        "annualized_return": 0.054108548536107,
        "information_ratio": 0.8688660400759982,
        "max_drawdown": -0.0973765879901777
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:20:33.193402",
      "updated_at": "2026-01-14T21:20:33.193408"
    },
    "a7b2276045c16adc": {
      "factor_id": "a7b2276045c16adc",
      "factor_name": "Normalized_Exhaustion_Impact_20D",
      "factor_expression": "ZSCORE((TS_MEAN(($high - $low) / ($volume + 1), 5) / (TS_STD(($high - $low) / ($volume + 1), 20) + 1e-8)) * SIGN($close - TS_MEAN($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MEAN(($high - $low) / ($volume + 1), 5) / (TS_STD(($high - $low) / ($volume + 1), 20) + 1e-8)) * SIGN($close - TS_MEAN($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Impact_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the price-volume resistance by normalizing the 5-day average price impact (range/volume) by its 20-day historical volatility. This ensures that the exhaustion signal is relative to the stock's own liquidity regime, identifying true 'low-progress' anomalies.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.894568",
      "updated_at": "2026-01-14T17:51:58.894574"
    },
    "562402034005b51a": {
      "factor_id": "562402034005b51a",
      "factor_name": "Decay_Weighted_Resistance_Exhaustion_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Decay_Weighted_Resistance_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by calculating the ratio of the distance from the 10-day high to a decay-weighted path length. The decay weighting prioritizes recent price volatility (effort), while the distance to high measures the result. This ratio is then scaled by the 10-day volume Z-score to isolate high-intensity exhaustion events.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.796121",
      "updated_at": "2026-01-14T21:08:05.796129"
    },
    "0e1e6895d262970e": {
      "factor_id": "0e1e6895d262970e",
      "factor_name": "VWPP_Persistence_20D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 20) * ($close / (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 20) * ($close / ((TS_SUM($volume, 10) > 0) ? (TS_SUM($close * $volume, 10) / TS_SUM($volume, 10)) : $close))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Price Persistence (VWPP) calculates the 20-day average of daily returns weighted by the cross-sectional rank of volume. This captures momentum supported by relative liquidity. It is then scaled by the ratio of the current price to the 10-day volume-weighted average price (VWAP) to ensure the signal is active during high-conviction price trends.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.245004",
      "updated_at": "2026-01-14T17:33:11.245011"
    },
    "bbf0152f53011c07": {
      "factor_id": "bbf0152f53011c07",
      "factor_name": "VWAP_Extension_Churn_Index_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))) * RANK(TS_STD($return, 20) / (TS_MEDIAN($return, 5) + SIGN(TS_MEDIAN($return, 5)) * 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VWAP_Extension_Churn_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'churning' phases where price is extended from the volume-weighted cost basis but the risk-adjusted return (efficiency) is collapsing. It uses the ratio of the 5-day median return to the 20-day volatility to avoid noise from single-day spikes, identifying imminent mean-reversion when price extension is high but stability is low.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.320532",
      "updated_at": "2026-01-14T21:18:16.320538"
    },
    "c3831ffe9f1d8c8c": {
      "factor_id": "c3831ffe9f1d8c8c",
      "factor_name": "Volume_Price_Resistance_Efficiency_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1), 5) * (( $close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1), 5) * (( $close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Resistance_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term exhaustion by measuring the 'price impact per volume' (Resistance Efficiency) and weighting it by the price's distance from its 5-day mean. High resistance efficiency combined with an overextended price (high Z-score) suggests a 'hollow' move prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.856478",
      "updated_at": "2026-01-14T17:51:58.856486"
    },
    "4e50237f8538ced2": {
      "factor_id": "4e50237f8538ced2",
      "factor_name": "Laggard_Sensitivity_Leader_Conviction",
      "factor_expression": "(RANK($volume) < 0.5 && RANK(TS_STD($return, 10)) < 0.25) ? MEAN(TS_ZSCORE(TS_PCTCHANGE($close, 3), 10) * (TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * (RANK($volume) > 0.8 ? 1 : 0)) : 0",
      "factor_implementation_code": "",
      "factor_description": "Calculates the conviction-weighted momentum of the top quintile of stocks by volume and projects it onto stocks with low idiosyncratic volatility and low volume. The volume shock is capped to prevent outliers from dominating the signal.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 3-day momentum of market leaders, weighted by their 3-day volume surge (shock), predicts the next 2-day returns of low-volatility laggards more accurately than static volume-rank models.\n                Concise Observation: Previous lead-lag factors using a 5-day delay and static volume thresholds were too slow and noisy; the positive IC suggests a signal exists, but the high drawdown indicates the need for a more dynamic filter on both the leader's signal strength and the laggard's sensitivity.\n                Concise Justification: Volume shocks signify institucional conviction in the leader's price move, increasing the likelihood of a sector-wide trend, while low idiosyncratic volatility in laggards minimizes stock-specific noise that usually masks the diffusion effect.\n                Concise Knowledge: If a market leader experiences a volume shock, its price action becomes a high-confidence signal; when laggards are in low-volatility consolidation, they are more receptive to these external price signals for breakout direction.\n                concise Specification: Define leaders as top 20% by volume; calculate their 3-day momentum weighted by the ratio of current 3-day average volume to 20-day average volume; apply this signal only to laggards (bottom 50% volume) whose 10-day volatility is in the bottom quartile.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Analyze the predictive power of price trends in upstream/downstream commodity futures and sector-specific supply chain leaders to identify delayed momentum signals in laggard equities.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0012643846124157,
        "ICIR": 0.0099502932512903,
        "RankIC": 0.0160401417143159,
        "RankICIR": 0.1260374585134848,
        "annualized_return": 0.0747586551372068,
        "information_ratio": 1.1700215257909958,
        "max_drawdown": -0.1090330097866659
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T17:47:09.112593",
      "updated_at": "2026-01-15T17:47:09.112598"
    },
    "2c26ba58e0190cfe": {
      "factor_id": "2c26ba58e0190cfe",
      "factor_name": "Volume_Weighted_Efficiency_Gap",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (TS_SUM($return, 5) / (TS_SUM(ABS($return), 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Efficiency_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies trend exhaustion by comparing the 20-day VWAP deviation with a 'Relative Efficiency' metric. The efficiency component uses the ratio of the 5-day sum of returns to the 20-day sum of absolute returns, capturing the loss of directional conviction relative to total price churn.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.338873",
      "updated_at": "2026-01-14T21:18:16.338879"
    },
    "310db097c90e330a": {
      "factor_id": "310db097c90e330a",
      "factor_name": "Volume_Price_Flow_Divergence_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * TS_MEAN(1 / (ABS($close - ($volume * $close / ($volume + 1e-9))) + 1e-9), 5) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1), 5) * TS_MEAN(INV(ABS($close - (($open + $high + $low + $close) / 4)) + 1e-9), 5) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Flow_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by measuring the 5-day cumulative return weighted by the inverse of the price spread (Close vs VWAP proxy). It scales this by the ratio of short-term (5-day) to long-term (20-day) volume turnover to isolate liquidity-driven exhaustion where price moves on declining participation.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 10,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Flow Divergence', where the 5-day cumulative return is weighted by the inverse of the volume-weighted price spread (VWAP vs Close) and filtered by the 5-day volume turnover trend to isolate liquidity-driven exhaustion.\n                Concise Observation: Previous attempts using range-to-volume ratios (Hypothesis 9) failed because they were too sensitive to single-day volume outliers; however, the successful Hypothesis 6 and 7 showed that price-volume decoupling is a valid signal when properly normalized against a volatility baseline.\n                Concise Justification: Using the distance between Close and VWAP provides a more stable measure of 'price extension' than raw range, as it represents the deviation from the average cost of participants. Normalizing this by a volume turnover trend (rather than a static sum) allows the factor to identify the specific 'tipping point' where price continues to move but liquidity participation (the 'fuel') is withdrawing.\n                Concise Knowledge: If a price move occurs with a widening gap between the closing price and the volume-weighted average price (VWAP) while volume turnover is declining, the move is likely a liquidity-driven 'hollow' extension; When price is overextended but volume support (turnover) is high, the trend is more likely to persist rather than revert.\n                concise Specification: Calculate the 5-day cumulative return. Multiply this by the 5-day average of (1 / (abs($close - ($volume * $close / $volume)) + 1e-9)). Scale this product by the ratio of the 5-day average volume to the 20-day average volume to capture the 'volume decay'. Apply a cross-sectional rank to the final value over a 5-day window.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.340770",
      "updated_at": "2026-01-14T18:02:27.340777"
    },
    "04af2bc09ff7df83": {
      "factor_id": "04af2bc09ff7df83",
      "factor_name": "Conviction_Divergence_Reversal_10D",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Divergence_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by combining price-volume divergence with volume conviction. It uses the 10-day price-volume correlation change as a measure of trend exhaustion, weighted by the 20-day volume Z-score (clipped at 0) to ensure the signal occurs during a high-conviction liquidity event. The reversal component is normalized by the 10-day price range relative to the typical body size.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.781751",
      "updated_at": "2026-01-14T17:26:49.781758"
    },
    "02cbecb3e4566b4d": {
      "factor_id": "02cbecb3e4566b4d",
      "factor_name": "Relative_Compression_Ranked_Momentum_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Ranked_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies volatility squeezes by calculating the ratio of the 20-day price range to the 5-day price range, using this to weight a cross-sectionally ranked 5-day momentum signal. To isolate high-conviction breakouts and avoid crowded trades, it is neutralized by the 20-day average volume, targeting quiet consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.232562",
      "updated_at": "2026-01-14T17:54:15.232569"
    },
    "c633563812707c64": {
      "factor_id": "c633563812707c64",
      "factor_name": "Effort_Result_Divergence_5D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($volume, 5) + 1)) * RANK($close - TS_MEAN($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($volume, 5) + 1)) * RANK($close - TS_MEAN($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Effort_Result_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between price effort (volume turnover) and price result (range). It specifically targets points where the price is far from its 5-day VWAP-proxy (TS_MEAN) but the volume-normalized range is at an extreme, signaling a blow-off top or bottom.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.932099",
      "updated_at": "2026-01-14T17:51:58.932106"
    },
    "2aecca6da5acd4bc": {
      "factor_id": "2aecca6da5acd4bc",
      "factor_name": "Volatility_Adjusted_Extension_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE($close, 20)) * RANK(INV(TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($close, 20)) * RANK(INV(TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Extension_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between medium-term price extension and short-term trend stability. It targets stocks where price is significantly above its 20-day average but the risk-adjusted return (Sharpe-like ratio) over the last 5 days is collapsing, signaling speculative exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 'Momentum-Quality Divergence Index' identifies trend reversals by detecting the breakdown in price progress per unit of volatility (Sharpe-like efficiency) during 20-day price over-extensions.\n                Concise Observation: Previous attempts using 'Volume Efficiency' (Range/Volume) were too noisy and sensitive to outliers, while the most successful iteration (Hypothesis 3, IR 1.13) relied on price efficiency (KMID); however, KMID ignores the volatility-adjusted stability of the trend progress.\n                Concise Justification: A sustainable trend requires price to move with consistent, low-volatility progress. By measuring the 'Price Quality' as the 5-day average return divided by the 5-day standard deviation of returns, we isolate periods where price movement becomes erratic or 'noisy' at the peak of a 20-day extension. This divergence indicates that the trend is no longer supported by steady institutional accumulation but by volatile retail speculation.\n                Concise Knowledge: In this quant scenario, if a stock's price deviates significantly from its 20-day mean while its risk-adjusted price progress (mean return divided by volatility) over the last 5 days collapses, the trend is likely entering an unstable, speculative phase; when price extension grows but 'quality' (return/std) decays, the probability of a sharp mean-reversion increases.\n                concise Specification: The factor is defined as the product of: 1. The Rank of the 20-day price deviation (Close / TS_MEAN(Close, 20) - 1), and 2. The Rank of the negative 5-day 'Price Quality' (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)). The 20-day window captures medium-term over-extension, while the 5-day window captures the immediate decay in trend quality. Both components are cross-sectionally ranked before multiplication.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050482736677071,
        "ICIR": 0.0376898899710857,
        "RankIC": 0.0197474945716331,
        "RankICIR": 0.1546038489613508,
        "annualized_return": 0.0714561174132213,
        "information_ratio": 1.0586574991150286,
        "max_drawdown": -0.133435429109272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:13:24.420220",
      "updated_at": "2026-01-14T21:13:24.420226"
    },
    "94686d4d9a6a76ca": {
      "factor_id": "94686d4d9a6a76ca",
      "factor_name": "ZScored_Reversal_Volume_Intensity",
      "factor_expression": "RANK(-1 * TS_ZSCORE(TS_SUM($return, 10), 20)) * RANK(TS_RANK($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_ZSCORE(TS_SUM($return, 10), 20)) * RANK(TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Reversal_Volume_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates mean-reversion signals by cross-sectionally ranking the 10-day return Z-score and multiplying it by the rank of volume intensity. This approach ensures that the reversal signal is significant both in terms of its own history (time-series) and relative to the market (cross-section), while requiring high volume to confirm the climax.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day price reversal is most potent when a significant price drawdown is accompanied by positive volume momentum, where the signal is enhanced by cross-sectionally ranking the return relative to its volatility to isolate high-conviction climax events.\n                Concise Observation: Previous iterations using 10-day price-volume correlation (1-CORR) successfully reduced drawdown but diluted the IC (0.0063 down to lower levels), suggesting that the 'state' of correlation is too slow compared to the 'momentum' of volume during a capitulation event.\n                Concise Justification: Market microstructure suggests that the most profitable reversals occur after a 'blow-off' or 'selling climax,' characterized by price and volume moving aggressively in the same direction (positive volume momentum) before a snap-back. Cross-sectional ranking of the return ensures that we target assets with the most extreme 'stretch' relative to the market, improving the signal-to-noise ratio.\n                Concise Knowledge: If a short-term price trend accelerates while volume momentum is positive, it indicates a 'climax' phase; when the 10-day return is cross-sectionally ranked and multiplied by volume momentum, the resulting factor identifies high-conviction turning points more effectively than linear correlation-based filters.\n                concise Specification: The factor is defined as: CS_Rank(-1 * 10-day return / 10-day price standard deviation) * CS_Rank(5-day volume momentum). Volume momentum is defined as the ratio of the 5-day average volume to the 20-day average volume. All variables are sourced from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0021517511318312,
        "ICIR": 0.0152943302107834,
        "RankIC": 0.0164866647542131,
        "RankICIR": 0.1207719729597577,
        "annualized_return": 0.0469881451941539,
        "information_ratio": 0.6718395658582001,
        "max_drawdown": -0.1029565810443816
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:42:22.818539",
      "updated_at": "2026-01-14T17:42:22.818545"
    },
    "6411ef0aaf297143": {
      "factor_id": "6411ef0aaf297143",
      "factor_name": "ZScore_Reversal_Conviction_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Reversal_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 10-day reversal potential by calculating the Z-score of returns and weighting it by the change in price-volume correlation. It uses Z-scores to identify statistically significant 'stretched' moves and filters them by the divergence in volume flow conviction.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.408776",
      "updated_at": "2026-01-14T17:12:56.408783"
    },
    "834423060d8ce847": {
      "factor_id": "834423060d8ce847",
      "factor_name": "Fractal_Efficiency_MFI_ZScore_Factor",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 10) + 1e-8)) * RANK((MFI($close, $high, $low, $volume, 5) - TS_MEAN(MFI($close, $high, $low, $volume, 5), 10)) / (TS_STD(MFI($close, $high, $low, $volume, 5), 10) + 1e-8))",
      "factor_implementation_code": "",
      "factor_description": "This factor combines a 10-day Fractal Efficiency Ratio (FER10) with a 5-day Money Flow Index Z-score (MFI_Z5). FER10 uses the sum of True Range to normalize price displacement, accounting for overnight gaps and intraday volatility. MFI_Z5 measures the statistical significance of capital flow intensity relative to its 10-day history. The factor identifies high-conviction trends where price movement is efficient and supported by significant liquidity surges.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 7,
      "hypothesis": "Hypothesis: A factor that combines a 10-day Volatility-Adjusted Efficiency Ratio (VAER10) with a 5-day Money Flow Index Z-score (MFI_Z5) will improve the signal-to-noise ratio and risk-adjusted returns by normalizing trend quality and capital flow intensity across different volatility regimes.\n                Concise Observation: The previous ER10 and MFI-Surge combination achieved a high IR (0.957) and low drawdown (-0.079), but the feedback suggests that the simple sum of absolute changes in the ER denominator and the simple SMA in the MFI surge do not account for the varying 'noise floor' of different instruments.\n                Concise Justification: Using ATR in the Efficiency Ratio denominator (Fractal Efficiency) accounts for overnight gaps and intraday volatility that simple close-to-close changes miss. Replacing the MFI/SMA ratio with a Z-score (using a 10-day rolling window) ensures that a 'surge' is statistically significant relative to that specific stock's recent liquidity profile.\n                Concise Knowledge: If price efficiency is normalized by the Average True Range (ATR) and money flow surges are measured by their standard deviation (Z-score), the factor becomes invariant to market volatility; When price-volume signals are volatility-adjusted, they more accurately distinguish between structural institutional accumulation and random retail-driven noise.\n                concise Specification: 1. Calculate VAER10: (Close - Close[10]) / (10-day Sum of True Range). 2. Calculate 5-day MFI. 3. Calculate MFI_Z5: (MFI5 - Mean(MFI5, 10)) / Std(MFI5, 10). 4. Apply cross-sectional Rank to both VAER10 and MFI_Z5. 5. Factor = Rank(VAER10) * Rank(MFI_Z5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:56:33.410526",
      "updated_at": "2026-01-14T18:56:33.410533"
    },
    "d5c41860c0168b28": {
      "factor_id": "d5c41860c0168b28",
      "factor_name": "Net_Volume_Momentum_5D",
      "factor_expression": "ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((SUMIF($volume, 5, $return > 0) - SUMIF($volume, 5, $return < 0)) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Net_Volume_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of directional money flow by calculating the normalized difference between volume on up-days and down-days over a 5-day window, capturing net capital inflow or outflow.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite signal integrating short-term price-volume correlation, relative price positioning against recent peaks, and volume-weighted momentum can effectively capture mean-reversion and trend-exhaustion points in equity returns.\n                Concise Observation: The user's provided components (CORR5, MAX5, VSUMD5) target three distinct dimensions: liquidity-price synergy, technical resistance, and directional volume intensity over a 5-day window.\n                Concise Justification: Combining these factors allows for a multi-dimensional filter where VSUMD5 identifies the net force of money flow, while MAX5 and CORR5 act as conditional oscillators to determine if that flow is sustainable or hitting a structural ceiling.\n                Concise Knowledge: If price increases are decoupled from volume growth (low correlation), the trend may lack conviction; when prices approach a 5-day resistance level (high MAX5), selling pressure typically intensifies; if volume disproportionately accompanies price declines (negative VSUMD5), it indicates aggressive capital outflow.\n                concise Specification: The hypothesis will be tested by calculating the 5-day correlation of close price and log-volume, the ratio of 5-day high to current close, and the normalized difference of volume on up-days versus down-days, expecting a negative relationship between high resistance/low flow and future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048430344071001,
        "ICIR": 0.0331262421245781,
        "RankIC": 0.0186466306361967,
        "RankICIR": 0.1295832293323421,
        "annualized_return": 0.0480758806902796,
        "information_ratio": 0.6093342429088725,
        "max_drawdown": -0.1697593938726594
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:33:58.229250",
      "updated_at": "2026-01-14T20:33:58.229256"
    },
    "11d3367e5ad2e843": {
      "factor_id": "11d3367e5ad2e843",
      "factor_name": "Relative_Compression_Breakout_Rank_15D",
      "factor_expression": "RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Breakout_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'spring-loading' effect of price compression by comparing the 20-day volatility to the 10-day price range, using a logarithmic transformation to handle non-stationarity. It is then combined with the 10-day RSI to ensure the breakout occurs within a strong momentum context, avoiding stagnant consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.084527",
      "updated_at": "2026-01-14T17:29:05.084533"
    },
    "8f0ff1e46d6e06e7": {
      "factor_id": "8f0ff1e46d6e06e7",
      "factor_name": "Volume_Weighted_Momentum_Anchor_Ratio",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Momentum_Anchor_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Efficiency Gap' by multiplying the 10-day persistence of volume-weighted returns with the ratio of the current price to its 20-day volume-weighted anchor. To avoid duplication and preserve signal strength, the VWAP is calculated using TS_SUM and the final interaction is cross-sectionally ranked to focus on relative institutional conviction.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.640127",
      "updated_at": "2026-01-14T17:56:26.640133"
    },
    "89b598f9778770de": {
      "factor_id": "89b598f9778770de",
      "factor_name": "VW_Range_Position_Exhaustion_5D",
      "factor_expression": "($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Range_Position_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the distance between the current close and the 5-day volume-weighted average price (VWAP) normalized by the range. It targets mean reversion by identifying when price moves too far from the volume-weighted conviction level relative to its 5-day trend.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.067321",
      "updated_at": "2026-01-14T17:21:26.067327"
    },
    "54e6425649423ec0": {
      "factor_id": "54e6425649423ec0",
      "factor_name": "ZScored_Volume_Efficiency_10D",
      "factor_expression": "ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($return, 10) * (TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the Volume-Weighted Return Efficiency factor. It applies a cross-sectional Z-score to the 10-day return scaled by the volume signal-to-noise ratio, ensuring the factor is robust across different market regimes and stock scales.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 10-day Volume-Weighted Return Efficiency (VWRE10) factor, calculated as the 10-day price return multiplied by the 10-day average volume and divided by the 10-day volume standard deviation, identifies sustainable price trends by prioritizing high-liquidity moves with low-volatility participation.\n                Concise Observation: Previous attempts using price-volume correlation and raw volume volatility improved IC but suffered in IR and Annualized Return, likely because the correlation term was too noisy and the absolute standard deviation penalized high-volume stocks regardless of their baseline liquidity.\n                Concise Justification: Using the ratio of Mean Volume to Volume Standard Deviation (the inverse of the Coefficient of Variation) acts as a signal-to-noise filter that rewards stocks with consistent liquidity. Multiplying this by the return ensures that we are identifying efficient price discovery where the market consensus is stable rather than speculative.\n                Concise Knowledge: If price momentum is scaled by the inverse of the volume coefficient of variation (Mean/STD), it isolates 'quiet' institutional accumulation; in daily equity data, a high return accompanied by stable, high-volume participation suggests stronger trend persistence than price spikes on erratic or low volume.\n                concise Specification: The factor is defined as: (Return_10 / TS_STD($volume, 10)) * TS_MEAN($volume, 10). This is mathematically equivalent to Return_10 divided by the 10-day Volume Coefficient of Variation. The look-back window is fixed at 10 days for all components.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:36:31.521215",
      "updated_at": "2026-01-14T20:36:31.521220"
    },
    "f3d62b60ba880c34": {
      "factor_id": "f3d62b60ba880c34",
      "factor_name": "Ranked_Squeeze_Momentum_Conviction",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) + RANK(TS_PCTCHANGE($close, 5) / (TS_STD($return, 20) + 1e-7)) + RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) + RANK(TS_PCTCHANGE($close, 5) / (TS_STD($return, 20) + 1e-7)) + RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_Conviction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the squeeze hypothesis that uses cross-sectional ranking to normalize the components. It combines the rank of range compression (20d/5d), the rank of volatility-adjusted momentum, and the rank of volume surges to identify high-conviction breakouts.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 6,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is best captured by the interaction between a 'Relative Compression Index' (5-day range vs 20-day range) and a 'Volume-Weighted Momentum' signal, where the momentum is normalized by the 20-day standard deviation of returns to ensure cross-sectional stationarity.\n                Concise Observation: Previous iterations failed when using standard deviation in the denominator (creating outliers) or complex Tanh/Z-score transforms (over-parameterization). The most successful model (IR 1.03) used a 20-day lookback for squeeze intensity but lacked a robust volume component that didn't degrade the signal.\n                Concise Justification: Using the ratio of short-term range to medium-term range (Max-Min) provides a bounded, more stable measure of compression than using standard deviation. Normalizing the directional 5-day return by the 20-day volatility (Sharpe-like ratio) ensures that the momentum signal is adjusted for the asset's specific risk regime, while the volume multiplier acts as a conviction filter.\n                Concise Knowledge: If a stock's 5-day price range is significantly smaller than its 20-day price range, it indicates a 'coiling' phase; when this is combined with a volume-weighted 5-day return normalized by historical volatility, it identifies breakouts where price movement is disproportionate to recent noise and supported by liquidity.\n                concise Specification: The factor is defined as: ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) * (($close - $close.shift(5)) / (Std($return, 20) * $close.shift(5) + 1e-6)) * (Mean($volume, 5) / Mean($volume, 20)). This combines a 20/5 range compression ratio, a volatility-adjusted 5-day return, and a 5/20 volume surge ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058182922470469,
        "ICIR": 0.0359666134509271,
        "RankIC": 0.0190837142510583,
        "RankICIR": 0.1186662918811512,
        "annualized_return": 0.0384624667001231,
        "information_ratio": 0.4579454241354422,
        "max_drawdown": -0.1706529568579493
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:29.623713",
      "updated_at": "2026-01-14T17:46:29.623719"
    },
    "3eae7d08e007715b": {
      "factor_id": "3eae7d08e007715b",
      "factor_name": "Coiled_Momentum_Volume_Divergence_10D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-4)) * INV(TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-4)) * INV(TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Coiled_Momentum_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'coiling' effect of price by comparing the 20-day range to the 10-day range. This compression index weights the 5-day return. The result is divided by the 5-day volume mean to favor breakouts occurring on lower relative volume, which suggests institutional accumulation rather than retail climaxes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.268860",
      "updated_at": "2026-01-14T17:54:15.268866"
    },
    "8a3c3da6922f3d71": {
      "factor_id": "8a3c3da6922f3d71",
      "factor_name": "Efficiency_Filtered_Residual_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(INV(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Filtered_Residual_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price over-extension and smoothed efficiency. It identifies assets where the price has deviated significantly from its 10-day trend while the 'quality' of the move (efficiency) is low, suggesting a higher probability of reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 2,
      "hypothesis": "Hypothesis: The Trend_Exhaustion_Index, defined as the product of the 10-day price residual and the 5-day average price efficiency, scaled by the 20-day relative volume, identifies high-conviction mean-reversion signals during market climaxes.\n                Concise Observation: Previous results showed that daily efficiency (KMID) is too noisy, but smoothing it and focusing on the interaction between trend deviation and volume improves the Information Ratio and reduces drawdown.\n                Concise Justification: High volume at the end of a price extension often signals a 'blow-off top' or 'selling climax'; by smoothing the efficiency ratio over 5 days, we filter out intraday noise to capture the structural weakening of the trend conviction.\n                Concise Knowledge: If a price over-extension (RESI) is sustained by low efficiency (KMID) and high relative volume, it indicates a liquidity climax; when these three conditions align, the probability of a sharp mean-reversion increases as speculative energy is depleted.\n                concise Specification: The factor is calculated as: (Close - 10-day Linear Trend) * (5-day Mean of (Close-Open)/(High-Low)) * (Volume / 20-day Mean Volume). All components are calculated per instrument and then cross-sectionally ranked to ensure scale independence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.00328928946783,
        "ICIR": 0.0232221508629143,
        "RankIC": 0.016158991976058,
        "RankICIR": 0.1143467871645518,
        "annualized_return": 0.0239623429596809,
        "information_ratio": 0.3214576068824046,
        "max_drawdown": -0.154918395771664
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:37:56.411997",
      "updated_at": "2026-01-14T20:37:56.412003"
    },
    "c66ee9481bdf59cf": {
      "factor_id": "c66ee9481bdf59cf",
      "factor_name": "Robust_Squeeze_VWER_Interaction",
      "factor_expression": "RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VWER_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified interaction factor between a volatility compression metric and volume-weighted price efficiency. It uses a 10-day window for the squeeze and efficiency measures, applying a rank-based normalization to the squeeze intensity to ensure cross-sectional stability and combining it with a volume-scaled price velocity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.334867",
      "updated_at": "2026-01-14T17:35:59.334874"
    },
    "de72babf4b53b854": {
      "factor_id": "de72babf4b53b854",
      "factor_name": "Institutional_Accumulation_Score",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Score\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'low noise' aspect of the hypothesis. It measures the linearity of the price trend (RSQR) and penalizes stocks with high 'friction' (intraday volatility relative to volume).",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.183527",
      "updated_at": "2026-01-14T17:20:27.183533"
    },
    "398af1472a4fdf41": {
      "factor_id": "398af1472a4fdf41",
      "factor_name": "ZScore_Churn_Intensity_10D",
      "factor_expression": "ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($volume, 10)) + ZSCORE(TS_SUM(ABS($return), 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Churn_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates idiosyncratic blow-off tops by combining the cross-sectional Z-score of volume surges with the cross-sectional Z-score of price churn (the inverse of efficiency). It targets stocks that are statistical outliers in both liquidity consumption and price volatility relative to the market.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 5,
      "hypothesis": "Hypothesis: A 10-day 'Idiosyncratic Churn-Volatility Interaction' factor identifies mean-reversion by detecting stocks where high cross-sectional volume intensity and high return volatility coincide with low price efficiency, signaling a liquidity-driven peak.\n                Concise Observation: The 15-day window was slightly too long and diluted the reversion signal, but the 'Churn Intensity' (Volume/Efficiency) logic showed the highest IR (0.875) so far, suggesting that the interaction between effort and result is a valid alpha source.\n                Concise Justification: Shortening the window to 10 days increases responsiveness to sharp exhaustion events. Incorporating cross-sectional ranking of volatility ensures that the factor identifies 'noisy' churn rather than high-conviction breakouts, as true exhaustion is characterized by high variance but low directional progress.\n                Concise Knowledge: If high volume 'effort' occurs alongside high price volatility but low net displacement, the trend is likely exhausted; when this 'churn' is ranked cross-sectionally, it isolates idiosyncratic blow-off tops from market-wide volume spikes.\n                concise Specification: The factor calculates the 10-day Price Efficiency (abs(close - close_10) / sum(abs(daily_return), 10)). It then interacts the cross-sectional rank of (1/Efficiency) with the cross-sectional rank of 10-day volume Z-scores and the cross-sectional rank of 10-day return standard deviation.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037913340750813,
        "ICIR": 0.0281099680740613,
        "RankIC": 0.0185308999090783,
        "RankICIR": 0.14163299301192,
        "annualized_return": 0.0425082276559173,
        "information_ratio": 0.7157625237234718,
        "max_drawdown": -0.0949208044868297
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:49:41.275537",
      "updated_at": "2026-01-14T20:49:41.275544"
    },
    "c52e3e585865407c": {
      "factor_id": "c52e3e585865407c",
      "factor_name": "Ranked_Conviction_Trend_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Trend_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a trend by subtracting the rank of daily price volatility (proxied by the high-low spread) from the rank of volume-weighted returns. By using ranks, it mitigates the impact of outliers and focuses on the relative efficiency of the price movement within the universe.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.220630",
      "updated_at": "2026-01-14T17:39:41.220636"
    },
    "ea99a07e9b070392": {
      "factor_id": "ea99a07e9b070392",
      "factor_name": "Vol_Squeeze_Conviction_Ratio_20D",
      "factor_expression": "((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * (DELTA($close, 5) / (TS_STD($return, 20) * DELAY($close, 5) + 1e-7)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * (DELTA($close, 5) / (TS_STD($return, 20) * DELAY($close, 5) + 1e-7)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))\" # Your output factor expression will be filled in here\n    name = \"Vol_Squeeze_Conviction_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the volatility squeeze by comparing the 20-day high-low range to the 5-day high-low range, then weights this compression by a volatility-normalized 5-day return and a volume intensity ratio. It identifies 'coiling' stocks where price tightness is released with volume support.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 6,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is best captured by the interaction between a 'Relative Compression Index' (5-day range vs 20-day range) and a 'Volume-Weighted Momentum' signal, where the momentum is normalized by the 20-day standard deviation of returns to ensure cross-sectional stationarity.\n                Concise Observation: Previous iterations failed when using standard deviation in the denominator (creating outliers) or complex Tanh/Z-score transforms (over-parameterization). The most successful model (IR 1.03) used a 20-day lookback for squeeze intensity but lacked a robust volume component that didn't degrade the signal.\n                Concise Justification: Using the ratio of short-term range to medium-term range (Max-Min) provides a bounded, more stable measure of compression than using standard deviation. Normalizing the directional 5-day return by the 20-day volatility (Sharpe-like ratio) ensures that the momentum signal is adjusted for the asset's specific risk regime, while the volume multiplier acts as a conviction filter.\n                Concise Knowledge: If a stock's 5-day price range is significantly smaller than its 20-day price range, it indicates a 'coiling' phase; when this is combined with a volume-weighted 5-day return normalized by historical volatility, it identifies breakouts where price movement is disproportionate to recent noise and supported by liquidity.\n                concise Specification: The factor is defined as: ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) * (($close - $close.shift(5)) / (Std($return, 20) * $close.shift(5) + 1e-6)) * (Mean($volume, 5) / Mean($volume, 20)). This combines a 20/5 range compression ratio, a volatility-adjusted 5-day return, and a 5/20 volume surge ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058182922470469,
        "ICIR": 0.0359666134509271,
        "RankIC": 0.0190837142510583,
        "RankICIR": 0.1186662918811512,
        "annualized_return": 0.0384624667001231,
        "information_ratio": 0.4579454241354422,
        "max_drawdown": -0.1706529568579493
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:29.587156",
      "updated_at": "2026-01-14T17:46:29.587163"
    },
    "cf8d9a3eb9e997de": {
      "factor_id": "cf8d9a3eb9e997de",
      "factor_name": "Trend_Divergence_Efficiency_Slope_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Divergence_Efficiency_Slope_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by capturing the divergence between price deviation from its 10-day linear trend and the 5-day slope of price efficiency. A high residual paired with a declining efficiency slope indicates a trend losing conviction. To avoid duplicated sub-expressions, the efficiency is calculated using the ratio of body to the average true range proxy.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.962393",
      "updated_at": "2026-01-14T20:45:46.962399"
    },
    "7507c77f514565a6": {
      "factor_id": "7507c77f514565a6",
      "factor_name": "Relative_Efficiency_Decay_VWAP_20D",
      "factor_expression": "RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)) - 1) * RANK(-1 * (EMA($return, 5) / (TS_STD($return, 20) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Efficiency_Decay_VWAP_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by measuring the divergence between a stock's current price relative to its 20-day Volume-Weighted Average Price (VWAP) and its relative efficiency decay. The efficiency decay is calculated as the ratio of the 5-day exponential moving average of returns to the 20-day standard deviation, normalized by the medium-term baseline to detect structural weakening.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 'Relative Efficiency Decay Index' identifies trend exhaustion by detecting when the short-term (5-day) risk-adjusted return significantly underperforms the medium-term (20-day) baseline, specifically when the price is extended relative to its 20-day Volume-Weighted Average Price (VWAP).\n                Concise Observation: While Hypothesis 7 successfully increased annualized returns by using a Sharpe-like efficiency ratio, it suffered from high drawdown (-13.3%) because a static 5-day window is sensitive to noise; previous successful iterations (Hypothesis 3) suggest that 'decay' or 'divergence' works best when normalized against a trend's own history.\n                Concise Justification: Using a 'Relative Efficiency' (5D Sharpe / 20D Sharpe) captures the structural weakening of a trend relative to its own established pace, filtering out stocks that are naturally volatile. Replacing the 20-day Mean with a 20-day VWAP for the extension component ensures that the 'over-extension' is measured against the actual capital-weighted cost basis of market participants, providing a more robust resistance level.\n                Concise Knowledge: If a stock's short-term price efficiency (Return/Volatility) drops below its medium-term historical efficiency while the price is at a volume-weighted extreme, the trend is likely entering a 'churning' phase; when the price/VWAP ratio is high but relative efficiency is low, mean-reversion is imminent because the liquidity required to sustain the move is no longer generating stable returns.\n                concise Specification: The factor is defined as: Rank(Close / (TS_SUM(Close * Volume, 20) / TS_SUM(Volume, 20)) - 1) * Rank(-1 * ( (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)) / (TS_MEAN(Return, 20) / (TS_STD(Return, 20) + 1e-6)) )). The first term measures VWAP-based extension; the second term measures the 5-day efficiency relative to the 20-day efficiency. Both are cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0033725318422626,
        "ICIR": 0.02277380120113,
        "RankIC": 0.0193093327492979,
        "RankICIR": 0.1341840108249528,
        "annualized_return": 0.0349020634602554,
        "information_ratio": 0.4360073600053224,
        "max_drawdown": -0.1852642753132095
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:18:16.301854",
      "updated_at": "2026-01-14T21:18:16.301862"
    },
    "0965806078acfa49": {
      "factor_id": "0965806078acfa49",
      "factor_name": "Liquidity_Climax_Exhaustion_Factor",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Climax_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets reversal points where price-volume correlation breaks down during extreme volume spikes. It normalizes the 10-day return by the 10-day Median Absolute Deviation of returns to handle outliers, then scales it by the interaction of volume intensity and the 5-day shift in price-volume alignment.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.815950",
      "updated_at": "2026-01-14T17:26:49.815956"
    },
    "e99c2ba0795b9e8a": {
      "factor_id": "e99c2ba0795b9e8a",
      "factor_name": "Volume_Adjusted_Exhaustion_Divergence_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Adjusted_Exhaustion_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies terminal trend exhaustion by measuring the divergence between price over-extension and volume-price efficiency. It calculates the product of the 10-day price residual (deviation from linear trend) and the negative 5-day slope of volume efficiency. Volume efficiency is defined as the absolute return per unit of relative volume. A high price residual combined with a declining volume efficiency suggests 'churning' at price extremes, signaling a potential reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.613072",
      "updated_at": "2026-01-14T20:55:45.613078"
    },
    "a4ef7d87a06bf894": {
      "factor_id": "a4ef7d87a06bf894",
      "factor_name": "Resistance_Efficiency_Churn_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Resistance_Efficiency_Churn_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the total price path length, scaled by the 10-day volume Z-score. A high value indicates that despite high volume and significant price movement (high path length), the price has failed to reach or maintain its recent resistance level, signaling trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.050704",
      "updated_at": "2026-01-14T21:02:22.050710"
    },
    "dc89cc27bd12469a": {
      "factor_id": "dc89cc27bd12469a",
      "factor_name": "MFI_Surge_Trend_Alignment",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MFI_Surge_Trend_Alignment\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the MFI-Stability hypothesis focusing on the ratio of Money Flow intensity to trend consistency. It identifies stocks where capital is surging (MFI > 3-day average) while the price trend remains structurally sound (high correlation with time), normalized by cross-sectional rank to ensure robustness.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.389138",
      "updated_at": "2026-01-14T18:42:41.389144"
    },
    "3e6761654f9ad4a1": {
      "factor_id": "3e6761654f9ad4a1",
      "factor_name": "Squeeze_Conviction_ZScore_Signal",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) * (TS_MEAN($volume, 20) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) * (TS_MEAN($volume, 20) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Conviction_ZScore_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines a 20/5 range compression index with a Z-scored 5-day return. By using ZSCORE, the momentum signal is normalized across the market. The factor is then adjusted by the inverse of the 5-day volume to highlight breakouts from 'quiet' consolidations where price-volume divergence is highest.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.304794",
      "updated_at": "2026-01-14T17:54:15.304800"
    },
    "5f773998e535e4cb": {
      "factor_id": "5f773998e535e4cb",
      "factor_name": "VWPP_Efficiency_Ratio_15D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Efficiency_Ratio_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between volume-ranked returns and price efficiency. It uses a 15-day window for the volume-weighted return and normalizes the distance from the 10-day VWAP using the 20-day price standard deviation to account for varying volatility levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.312438",
      "updated_at": "2026-01-14T17:33:11.312444"
    },
    "351ac7234f11b736": {
      "factor_id": "351ac7234f11b736",
      "factor_name": "VW_Momentum_Conviction_Interaction_20D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Conviction_Interaction_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between volume-weighted price momentum and the relative distance from the institutional cost basis. It uses the 10-day rolling mean of return scaled by cross-sectional volume rank to identify institutional conviction, and multiplies it by the rank of the price-to-VWAP ratio. The VWAP is calculated over 20 days. By using the product of two ranked components, it preserves signal intensity for stocks where both momentum and positioning are extreme.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.562820",
      "updated_at": "2026-01-14T17:56:26.562827"
    },
    "70587a0f9ccf9eb7": {
      "factor_id": "70587a0f9ccf9eb7",
      "factor_name": "Exhaustion_Climax_Concentration_Factor",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Climax_Concentration_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by filtering extreme 10-day drawdowns with a temporal volume distribution check. It uses the cross-sectional rank of the volatility-normalized return multiplied by the ratio of early-window volume to late-window volume. A high ratio indicates that the selling climax has likely passed, reducing the risk of catching a 'falling knife'.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the price drawdown is extreme relative to its 20-day volatility and is validated by a 'Volume Concentration' state, where a high percentage of the 10-day volume occurs during the first half of the drawdown period, indicating subsequent selling exhaustion.\n                Concise Observation: Previous attempts using 10-day correlation (SOTA IR 1.11) and volume Z-scores (high IC 0.0062) struggled to balance raw alpha and stability, likely because they ignored the 'temporal distribution' of volume within the lookback window, which distinguishes between active capitulation and ongoing trend persistence.\n                Concise Justification: Market microstructure suggests that a 'selling climax' followed by a 'low-volume tail' is a more reliable reversal signal than a climax at the very end of the window. By measuring the ratio of volume in the first 5 days versus the total 10-day volume (Volume Concentration), we can identify if the 'pain' has already peaked, allowing for a safer entry into the reversal.\n                Concise Knowledge: If a short-term price decline is front-loaded with high volume (liquidity shock) followed by a price drift on lower volume, it indicates that the majority of selling pressure has been absorbed; when volume concentration is high in the early phase of a 10-day window, the probability of a mean-reversion bounce in the following days is significantly higher than if volume is back-loaded.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * (Close / Delay(Close, 10) - 1), 20)] * [Sum(Volume, 5, 5) / Sum(Volume, 10)]. The first term is the 20-day Z-score of the 10-day return; the second term is the ratio of volume from day t-10 to t-6 relative to the total volume from t-10 to t-1. All data is from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034116384551348,
        "ICIR": 0.0252113197343331,
        "RankIC": 0.019584592435801,
        "RankICIR": 0.1510952568680467,
        "annualized_return": 0.049572175469758,
        "information_ratio": 0.7335331914229961,
        "max_drawdown": -0.094772055553972
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:53:23.820498",
      "updated_at": "2026-01-14T17:53:23.820504"
    },
    "4ef43361520c1374": {
      "factor_id": "4ef43361520c1374",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by measuring the 'Price Impact' (5-day average high-low range divided by volume) normalized by the 20-day historical volatility. High values indicate price expansion on low volume relative to the stock's typical risk profile, suggesting a liquidity-driven spike prone to reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.121526",
      "updated_at": "2026-01-14T17:37:25.121533"
    },
    "0b1696dec7b25994": {
      "factor_id": "0b1696dec7b25994",
      "factor_name": "ZScore_RSQR20_VWAP_Momentum_2D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_RSQR20_VWAP_Momentum_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trend continuations by multiplying the cross-sectional Z-score of price trend stability (R-squared of close prices over 20 days) with the cross-sectional Z-score of a 2-day volume-weighted return. This ensures that long-term structural stability is validated by immediate volume-supported price action.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.064610",
      "updated_at": "2026-01-14T17:43:57.064617"
    },
    "bb649f19188ec110": {
      "factor_id": "bb649f19188ec110",
      "factor_name": "VW_Price_Slope_Divergence_5D",
      "factor_expression": "REGBETA($close, SEQUENCE(5), 5) - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGBETA($close, SEQUENCE(5), 5) - (TS_SUM((($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)) * $volume, 5) / TS_SUM($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Slope_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the 5-day price trend (regression slope) and the volume-weighted relative position of the price within its high-low range. A high price slope combined with a low volume-weighted position suggests a 'hollow' trend prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.000804",
      "updated_at": "2026-01-14T17:21:26.000811"
    }
  }
}