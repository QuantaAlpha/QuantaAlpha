{
  "metadata": {
    "created_at": "2026-01-20T01:23:40.746338",
    "source": "all_factors_library_AA.json",
    "selection_method": "top_80_by_RankIC",
    "total_factors": 80,
    "rankic_range": "0.019576 ~ 0.022257"
  },
  "factors": {
    "c2ac425b322611c4": {
      "factor_id": "c2ac425b322611c4",
      "factor_name": "Exhaustion_Rank_Spread_10D",
      "factor_expression": "RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($return, 10)) - RANK(TS_RANK(DELTA($volume, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Rank_Spread_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the price-volume divergence hypothesis that uses the 10-day time-series rank of returns compared to the 10-day time-series rank of volume growth. It targets assets where volume is reaching extreme historical levels (high rank) while price gains are lagging (low rank).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.005509",
      "updated_at": "2026-01-14T20:40:44.005515"
    },
    "d62c2a86081649c0": {
      "factor_id": "d62c2a86081649c0",
      "factor_name": "Churn_Intensity_Index_10D",
      "factor_expression": "RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return, 10)) / (RANK(TS_STD(TS_PCTCHANGE($volume, 1), 10)) + 1)\" # Your output factor expression will be filled in here\n    name = \"Churn_Intensity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'churning' behavior by calculating the ratio of ranked price momentum to ranked volume volatility. It identifies periods where high volume activity does not translate into proportional price movement, signaling a loss of trend conviction.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 3,
      "hypothesis": "Hypothesis: A 10-day 'Price-Volume Acceleration Divergence' factor that identifies exhaustion by measuring the spread between the rolling rank of price momentum and the rolling rank of volume acceleration will predict mean-reversion more robustly than simple ratios.\n                Concise Observation: Previous attempts using 5-day windows were too noisy, and 20-day volatility-normalized metrics failed to produce valid outputs, likely due to sensitivity to outliers or calculation complexity; volume 'acceleration' (change in volume) often precedes price peaks more clearly than raw volume ratios.\n                Concise Justification: Using rolling ranks (10-day window) for both price returns and volume changes eliminates the need for manual volatility normalization and prevents division-by-zero errors, while the 10-day lookback provides a balance between responsiveness and signal stability.\n                Concise Knowledge: If price momentum begins to decelerate while volume acceleration remains high or increases, it indicates a 'churning' phase where liquidity is being absorbed by institutional selling; when these two ranked metrics diverge significantly, the probability of a trend reversal increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as the difference between the 10-day rolling rank of daily returns and the 10-day rolling rank of the 3-day volume rate-of-change, expecting that high volume acceleration paired with low price momentum (negative spread) signals a peak.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058698721773145,
        "ICIR": 0.0440112083422218,
        "RankIC": 0.0222565179326234,
        "RankICIR": 0.171061192867577,
        "annualized_return": 0.0294862882816136,
        "information_ratio": 0.4185070925260967,
        "max_drawdown": -0.1410093013883218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:40:44.021513",
      "updated_at": "2026-01-14T20:40:44.021519"
    },
    "f7298e462456ae82": {
      "factor_id": "f7298e462456ae82",
      "factor_name": "Vol_Weighted_Reversal_10D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10)))\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by scaling the 10-day price return by the inverse of the price-volume correlation. It targets stocks where the downward trend lacks volume conviction, suggesting exhaustion rather than a fundamental regime shift.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.183234",
      "updated_at": "2026-01-14T17:02:57.183241"
    },
    "502409b41bea1fbd": {
      "factor_id": "502409b41bea1fbd",
      "factor_name": "Exhaustion_Reversal_Score_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Score_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the volume-price divergence hypothesis. It calculates the 10-day reversal and weights it by the time-series rank of the inverse volume, prioritizing reversals that occur on declining or low relative volume.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.215328",
      "updated_at": "2026-01-14T17:02:57.215334"
    },
    "c019a2d0550d0b20": {
      "factor_id": "c019a2d0550d0b20",
      "factor_name": "Divergent_Mean_Reversion_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_PCTCHANGE($close, 10), 20) / (1 + ABS(TS_CORR($close, $volume, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_PCTCHANGE($close, 10), 20) / (1 + ABS(TS_CORR($close, $volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Divergent_Mean_Reversion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price direction and volume intensity. It uses the residual of price returns after controlling for volume-weighted trends, specifically looking for negative returns that are not supported by high volume growth.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.246709",
      "updated_at": "2026-01-14T17:02:57.246715"
    },
    "530b4b81842c1774": {
      "factor_id": "530b4b81842c1774",
      "factor_name": "Divergent_ZScore_Reversal_10D",
      "factor_expression": "TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_ZScore_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by measuring the statistical extremity of the price move (Z-score) and weighting it by a 'Divergence Index'. The Divergence Index is calculated as (1 - TS_CORR), which amplifies the signal when price and volume move in opposite directions, indicating trend fragility. The price move is calculated as the negative 10-day return to capture mean-reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.840434",
      "updated_at": "2026-01-14T17:48:31.840441"
    },
    "beda22fd003445b3": {
      "factor_id": "beda22fd003445b3",
      "factor_name": "Climax_Gated_Reversal_Factor",
      "factor_expression": "(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Climax_Gated_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets high-conviction selling climaxes. It uses the 10-day price-volume correlation as a state filter (negated to favor divergence) and multiplies it by a volatility-adjusted 10-day return. It incorporates a Volume Surge component (Volume relative to its 20-day mean) to ensure the reversal is backed by significant liquidity exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.876983",
      "updated_at": "2026-01-14T17:48:31.876989"
    },
    "c900cc937efad896": {
      "factor_id": "c900cc937efad896",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional approach to the exhaustion hypothesis. It ranks the 10-day price decline and weights it by the 10-day volume Z-score. By using RANK, it identifies the most 'stretched' assets in the universe, while the volume Z-score (clipped at 0) ensures the signal is only active during periods of higher-than-average volume intensity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.914496",
      "updated_at": "2026-01-14T17:48:31.914503"
    },
    "03da5cb127a40e03": {
      "factor_id": "03da5cb127a40e03",
      "factor_name": "ER10_VPT5_ZScore_Sum",
      "factor_expression": "ZSCORE((($close - DELAY($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8))) + ZSCORE(TS_SUM($volume * DELTA($close, 1) / (DELAY($close, 1) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($close - DELAY($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8))) + ZSCORE(TS_SUM($volume * DELTA($close, 1) / (DELAY($close, 1) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"ER10_VPT5_ZScore_Sum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day Efficiency Ratio (ER10) with the 5-day Volume-Price Trend (VPT) using cross-sectional Z-score summation. ER10 measures the cleanliness of the price trend, while VPT identifies volume-supported price momentum. Z-score summation avoids signal sparsity while normalizing different scales.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.881181",
      "updated_at": "2026-01-14T19:08:39.881188"
    },
    "ecafcde920ce4f95": {
      "factor_id": "ecafcde920ce4f95",
      "factor_name": "ER10_VPT5_Interaction_Factor",
      "factor_expression": "ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * $return, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * $return, 5))\" # Your output factor expression will be filled in here\n    name = \"ER10_VPT5_Interaction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the efficiency-volume synergy hypothesis. It uses the cross-sectional Z-score of the 10-day Efficiency Ratio added to the Z-score of a 5-day Volume-Price Trend, where VPT is calculated as the cumulative product of volume and returns to capture capital flow intensity.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.920283",
      "updated_at": "2026-01-14T19:08:39.920289"
    },
    "ddb3d18d908a40fb": {
      "factor_id": "ddb3d18d908a40fb",
      "factor_name": "Efficiency_VPT_Synergy_10D",
      "factor_expression": "ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * TS_PCTCHANGE($close, 1), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * TS_PCTCHANGE($close, 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_VPT_Synergy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by summing the cross-sectional Z-scores of trend efficiency (ER10) and volume-weighted price momentum (VPT5). By using addition instead of multiplication or gating, it provides a continuous ranking that captures both price-path cleanliness and volume confirmation.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.958845",
      "updated_at": "2026-01-14T19:08:39.958851"
    },
    "28c761af988bbc9d": {
      "factor_id": "28c761af988bbc9d",
      "factor_name": "Resistance_Volume_Divergence_20D",
      "factor_expression": "RANK((TS_MAX($high, 20) - $close) / (TS_STD($close, 20) + 1e-8) + RANK($volume / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - $close) / (TS_STD($close, 20) + 1e-8) + RANK($volume / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Resistance_Volume_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by interacting the price distance from the 20-day high with the cross-sectional rank of recent 5-day volume surges. It targets stocks where extreme turnover fails to overcome structural peaks, signaling exhaustion. The distance is normalized by the 20-day standard deviation to account for volatility.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 9,
      "hypothesis": "Hypothesis: A 20-day 'Resistance-Volume Divergence' factor identifies mean-reversion by interacting the 20-day price distance from resistance with the cross-sectional rank of 5-day volume surges, specifically targeting stocks where short-term extreme turnover fails to overcome monthly structural peaks.\n                Concise Observation: Previous successes (IR 1.15) used a 10-day window for both resistance and volume, but the most recent attempt at decay-weighting (Hypothesis 8) improved the IC (0.0052) while losing IR, suggesting that while recent volatility is important, the resistance level itself needs a more stable (longer) lookback to filter out noise.\n                Concise Justification: Using a 20-day window for the 'Distance to High' provides a more robust structural resistance level, while a 5-day volume surge captures the immediate 'blow-off' intensity. Combining these via cross-sectional ranks instead of raw Z-scores or complex decay functions prevents outlier distortion and focuses on idiosyncratic exhaustion.\n                Concise Knowledge: If a short-term volume surge (5-day) fails to push the price toward a medium-term resistance (20-day high), the liquidity is being absorbed by sellers; When high-intensity turnover occurs at a significant price distance from recent peaks, it indicates 'churning' rather than a breakout.\n                concise Specification: The factor calculates the 20-day Distance from High (ts_max(high, 20) - close) / ts_std(close, 20). This is then added to the cross-sectional rank of the 5-day volume surge (volume / ts_mean(volume, 20)). The final output is the cross-sectional rank of this sum to predict positive future returns (as high distance + high volume surge = high exhaustion/reversion potential).\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050588825246269,
        "ICIR": 0.0367420663658229,
        "RankIC": 0.0217995635837097,
        "RankICIR": 0.1656796713947607,
        "annualized_return": 0.0795477822592887,
        "information_ratio": 1.2282168943232237,
        "max_drawdown": -0.0916984352237093
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:11:14.800679",
      "updated_at": "2026-01-14T21:11:14.800686"
    },
    "3f55a4f7c882491b": {
      "factor_id": "3f55a4f7c882491b",
      "factor_name": "Structural_Exhaustion_Index_20D",
      "factor_expression": "RANK(RANK((TS_MAX($high, 20) - $close) / ($close + 1e-8)) + RANK(TS_ZSCORE($volume, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(RANK((TS_MAX($high, 20) - $close) / ($close + 1e-8)) + RANK(TS_ZSCORE($volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between price proximity to a 20-day resistance level and the 5-day volume acceleration. It identifies 'churning' where high-intensity turnover occurs far from recent peaks, suggesting seller absorption. It uses a Z-score for volume to isolate statistically significant surges.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 9,
      "hypothesis": "Hypothesis: A 20-day 'Resistance-Volume Divergence' factor identifies mean-reversion by interacting the 20-day price distance from resistance with the cross-sectional rank of 5-day volume surges, specifically targeting stocks where short-term extreme turnover fails to overcome monthly structural peaks.\n                Concise Observation: Previous successes (IR 1.15) used a 10-day window for both resistance and volume, but the most recent attempt at decay-weighting (Hypothesis 8) improved the IC (0.0052) while losing IR, suggesting that while recent volatility is important, the resistance level itself needs a more stable (longer) lookback to filter out noise.\n                Concise Justification: Using a 20-day window for the 'Distance to High' provides a more robust structural resistance level, while a 5-day volume surge captures the immediate 'blow-off' intensity. Combining these via cross-sectional ranks instead of raw Z-scores or complex decay functions prevents outlier distortion and focuses on idiosyncratic exhaustion.\n                Concise Knowledge: If a short-term volume surge (5-day) fails to push the price toward a medium-term resistance (20-day high), the liquidity is being absorbed by sellers; When high-intensity turnover occurs at a significant price distance from recent peaks, it indicates 'churning' rather than a breakout.\n                concise Specification: The factor calculates the 20-day Distance from High (ts_max(high, 20) - close) / ts_std(close, 20). This is then added to the cross-sectional rank of the 5-day volume surge (volume / ts_mean(volume, 20)). The final output is the cross-sectional rank of this sum to predict positive future returns (as high distance + high volume surge = high exhaustion/reversion potential).\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050588825246269,
        "ICIR": 0.0367420663658229,
        "RankIC": 0.0217995635837097,
        "RankICIR": 0.1656796713947607,
        "annualized_return": 0.0795477822592887,
        "information_ratio": 1.2282168943232237,
        "max_drawdown": -0.0916984352237093
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:11:14.820367",
      "updated_at": "2026-01-14T21:11:14.820374"
    },
    "e86295c7d1c69eea": {
      "factor_id": "e86295c7d1c69eea",
      "factor_name": "Efficiency_VPT_Surge_Interact_10D",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8)) * RANK(DELTA(TS_SUM($volume * ($close - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8)) * RANK(DELTA(TS_SUM($volume * ($close - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_VPT_Surge_Interact_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio with the 5-day change in Volume-Price Trend (VPT). To avoid duplication of previous ER10 expressions, the Efficiency Ratio is calculated using the high-low range as a proxy for path volatility, and the VPT delta is normalized cross-sectionally to identify high-velocity breakouts.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.160952",
      "updated_at": "2026-01-14T19:15:17.160959"
    },
    "92778aea9ae0e519": {
      "factor_id": "92778aea9ae0e519",
      "factor_name": "Log_Efficiency_VPT_Acceleration",
      "factor_expression": "RANK(LOG($close / (DELAY($close, 10) + 1e-8)) / (TS_SUM(ABS(LOG($close / (DELAY($close, 1) + 1e-8))), 10) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG($close / (DELAY($close, 10) + 1e-8)) / (TS_SUM(ABS(LOG($close / (DELAY($close, 1) + 1e-8))), 10) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Log_Efficiency_VPT_Acceleration\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the Efficiency-VPT synergy that uses logarithmic price changes to calculate the Efficiency Ratio and a 5-day acceleration in the Volume-Price Trend. The multiplication of ranks ensures the factor only triggers when both trend cleanliness (Efficiency) and capital commitment (VPT) are at their cross-sectional extremes.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.199786",
      "updated_at": "2026-01-14T19:15:17.199792"
    },
    "f4144c8a2ee14555": {
      "factor_id": "f4144c8a2ee14555",
      "factor_name": "Z_Efficiency_VPT_Momentum_5D",
      "factor_expression": "RANK(($close - DELAY($close, 5)) / (TS_SUM(ABS($close - DELAY($close, 1)), 5) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 5)) / (TS_SUM(ABS($close - DELAY($close, 1)), 5) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Z_Efficiency_VPT_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional moves by interacting a 5-day Efficiency Ratio (ER5) with the 5-day change in Volume-Price Trend. Using a shorter 5-day window for efficiency improves synchronization with the momentum signal, while rank-based multiplication filters for simultaneous extreme values in both path cleanliness and liquidity acceleration.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.248725",
      "updated_at": "2026-01-14T19:15:17.248731"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T17:39:41.148683"
    },
    "ba52212e001d0431": {
      "factor_id": "ba52212e001d0431",
      "factor_name": "Efficiency_Adjusted_Persistence_15D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency hypothesis that focuses on the Z-score interaction between volume-ranked returns and a price-range stability metric. It identifies assets where the conviction (volume-weighted returns) significantly outweighs the noise (price range), using Z-scores to ensure cross-sectional comparability.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.183691",
      "updated_at": "2026-01-14T17:39:41.183697"
    },
    "c52e3e585865407c": {
      "factor_id": "c52e3e585865407c",
      "factor_name": "Ranked_Conviction_Trend_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Trend_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a trend by subtracting the rank of daily price volatility (proxied by the high-low spread) from the rank of volume-weighted returns. By using ranks, it mitigates the impact of outliers and focuses on the relative efficiency of the price movement within the universe.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.220630",
      "updated_at": "2026-01-14T17:39:41.220636"
    },
    "5216873e5822843b": {
      "factor_id": "5216873e5822843b",
      "factor_name": "Composite_Trend_Volume_RSV_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Volume_RSV_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines 20-day price trend stability (proxied by the square of the correlation between price and time), 5-day volume-weighted buying pressure, and the 5-day Relative Statistical Value (RSV) to identify high-probability entry points.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.835728",
      "updated_at": "2026-01-14T17:27:11.835735"
    },
    "c20dcf9d08b15587": {
      "factor_id": "c20dcf9d08b15587",
      "factor_name": "Ranked_Stability_Buying_Pressure_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_Buying_Pressure_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the hypothesis by cross-sectionally ranking trend stability (R-squared of price vs time) and multiplying it by the buying pressure ratio over a 5-day window, adjusted for price positioning.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.869921",
      "updated_at": "2026-01-14T17:27:11.869929"
    },
    "5d54c018fc9beb9d": {
      "factor_id": "5d54c018fc9beb9d",
      "factor_name": "Trend_Volume_Confirmation_ZScore",
      "factor_expression": "ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Volume_Confirmation_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the hypothesis focusing on the convergence of price stability and volume intensity. It uses Z-scores to ensure the components are on the same scale before combination.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.904259",
      "updated_at": "2026-01-14T17:27:11.904265"
    },
    "fb42bc4cc1cea0c8": {
      "factor_id": "fb42bc4cc1cea0c8",
      "factor_name": "VWM_Normalized_CV_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWM_Normalized_CV_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 20-day price momentum (percentage change) and normalizes it by the volume coefficient of variation (CV) over the same period. The CV is the ratio of the standard deviation of volume to the mean volume. By dividing momentum by CV, the factor penalizes price trends accompanied by erratic or unstable volume, favoring steady, high-conviction accumulation.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.857108",
      "updated_at": "2026-01-14T20:26:55.857114"
    },
    "313646e5c487fee1": {
      "factor_id": "313646e5c487fee1",
      "factor_name": "Steady_Trend_Conviction_Rank_20D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Steady_Trend_Conviction_Rank_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that identifies high-conviction trends by scaling the 20-day price return by the inverse of volume volatility. It uses the ratio of mean volume to volume standard deviation as a multiplier for price momentum, effectively amplifying signals where volume is consistent and stable.",
      "experiment_id": "2026-01-14_12-18-13-371046",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 20-day Volume-Weighted Momentum (VWM20) normalized by the 20-day Volume Coefficient of Variation (VCV20) identifies high-conviction trends by penalizing price moves driven by erratic liquidity.\n                Concise Observation: Previous attempts using disparate look-back periods (5, 10, 60 days) and complex rank subtractions failed to produce high IC, likely due to signal dilution and temporal mismatch between components.\n                Concise Justification: Standardizing the look-back period to 20 days aligns the momentum and volatility signals, while using the coefficient of variation (STD/Mean) provides a dimensionless measure of liquidity risk that effectively filters the quality of the price trend.\n                Concise Knowledge: If price momentum is scaled by the stability of volume (inverse of coefficient of variation), the resulting signal distinguishes between institutional-led steady accumulation and retail-driven noise; in quant finance, 'quiet' volume growth often precedes more sustainable price trends than 'noisy' volume spikes.\n                concise Specification: The factor is defined as the 20-day price return divided by the 20-day coefficient of variation of volume (rolling 20-day volume standard deviation / rolling 20-day volume mean), calculated for each instrument.\n                ",
      "initial_direction": "参考以下组合给出假设。组合10包含CORD60（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 60)，含义：60日价格/成交量变化率的相关系数）、RANK5（表达式：Rank(, 5)，含义：5日价格排名，反映短期价格相对位置）、VSTD10（表达式：Std(, 10)/(+1e-12)，含义：10日成交量标准差，中期资金流向稳定性）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059514550124575,
        "ICIR": 0.0385598500272743,
        "RankIC": 0.021375945627672,
        "RankICIR": 0.138760138367551,
        "annualized_return": 0.0633195615435207,
        "information_ratio": 0.6860803581173278,
        "max_drawdown": -0.163199671035172
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:26:55.872162",
      "updated_at": "2026-01-14T20:26:55.872168"
    },
    "5d9461843c6ecdcb": {
      "factor_id": "5d9461843c6ecdcb",
      "factor_name": "Normalized_Squeeze_Efficiency_ZScore_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Squeeze_Efficiency_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the volatility squeeze intensity relative to its 20-day history, then weighting it by the 10-day Efficiency Ratio. Instead of a raw price range, it uses the average true range (high-low) over 5 days to normalize the squeeze denominator and avoid outliers, then applies a cross-sectional Z-score to the final interaction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.048570",
      "updated_at": "2026-01-14T17:29:05.048577"
    },
    "11d3367e5ad2e843": {
      "factor_id": "11d3367e5ad2e843",
      "factor_name": "Relative_Compression_Breakout_Rank_15D",
      "factor_expression": "RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Breakout_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'spring-loading' effect of price compression by comparing the 20-day volatility to the 10-day price range, using a logarithmic transformation to handle non-stationarity. It is then combined with the 10-day RSI to ensure the breakout occurs within a strong momentum context, avoiding stagnant consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.084527",
      "updated_at": "2026-01-14T17:29:05.084533"
    },
    "f41fea1bcefd3200": {
      "factor_id": "f41fea1bcefd3200",
      "factor_name": "Squeeze_Directional_Efficiency_10D",
      "factor_expression": "TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Directional_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the quality of the squeeze by interacting a 20-day volatility-to-range ratio with the Efficiency Ratio, but uses a 10-day moving average of the interaction to smooth out high-frequency noise. It uses the difference between close and open as a proxy for intraday conviction within the range calculation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.118341",
      "updated_at": "2026-01-14T17:29:05.118347"
    },
    "362c428a7eea6559": {
      "factor_id": "362c428a7eea6559",
      "factor_name": "Vol_Adj_MFI_Stability_Factor",
      "factor_expression": "ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_MFI_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 20-day weighted price stability with a 5-day Money Flow Index (MFI) relative to its recent average. It uses volatility-adjusted weighting to balance the two components, ensuring that the more stable trend signal and the more reactive capital flow signal contribute proportionally based on their recent variance.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.350701",
      "updated_at": "2026-01-14T18:42:41.350708"
    },
    "dc89cc27bd12469a": {
      "factor_id": "dc89cc27bd12469a",
      "factor_name": "MFI_Surge_Trend_Alignment",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MFI_Surge_Trend_Alignment\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the MFI-Stability hypothesis focusing on the ratio of Money Flow intensity to trend consistency. It identifies stocks where capital is surging (MFI > 3-day average) while the price trend remains structurally sound (high correlation with time), normalized by cross-sectional rank to ensure robustness.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.389138",
      "updated_at": "2026-01-14T18:42:41.389144"
    },
    "d4a61936fdb34177": {
      "factor_id": "d4a61936fdb34177",
      "factor_name": "Lead_Lag_Momentum_Corr_20D_5L",
      "factor_expression": "TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY(LOG($close) - LOG(DELAY($close, 1)), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Lead_Lag_Momentum_Corr_20D_5L\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 20-day rolling correlation between the current daily return and the 5-day lagged log return. It captures lead-lag momentum effects where current price action follows historical trends with a specific delay.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.598808",
      "updated_at": "2026-01-15T18:47:04.598816"
    },
    "4fd5f6bb928aff93": {
      "factor_id": "4fd5f6bb928aff93",
      "factor_name": "Lagged_Return_Spillover_Rank_20D",
      "factor_expression": "TS_CORR($return, DELAY(RANK($return), 5), 20)",
      "factor_implementation_code": "",
      "factor_description": "A variation of the lead-lag hypothesis that uses cross-sectional ranking of lagged returns to identify momentum spillover. It correlates current returns with the 5-day lagged cross-sectional rank of returns over a 20-day window.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.618652",
      "updated_at": "2026-01-15T18:47:04.618659"
    },
    "e3b73174f7fdec13": {
      "factor_id": "e3b73174f7fdec13",
      "factor_name": "Volume_Weighted_Lag_Momentum_20D",
      "factor_expression": "TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($return, DELAY($return * TS_ZSCORE($volume, 20), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Lag_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the lead-lag hypothesis by correlating current returns with the 5-day lagged volume-weighted price change proxy, aiming to identify trends backed by significant trading activity.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day rolling correlation between the daily returns of an asset and its lagged volume-weighted price change (5-day lag) serves as a proxy for lead-lag momentum, where positive correlation identifies assets following established trends.\n                Concise Observation: Market participants often react to price signals with varying latency, creating measurable lead-lag relationships in daily price and volume data across different instruments.\n                Concise Justification: Price discovery is not instantaneous; by measuring the rolling correlation of current returns against lagged returns, we can quantify the strength of momentum spillover and predict short-term persistence.\n                Concise Knowledge: If an asset's current returns are positively correlated with its historical price changes at a specific lag, then the asset exhibits trend-following behavior driven by information diffusion delays.\n                concise Specification: The factor is defined as the 20-day Pearson correlation between the daily return ($return) and the 5-day lagged log return (log($close) - log(delay($close, 1))), calculated per instrument.\n                ",
      "initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "user_initial_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "planning_direction": "Cross-Asset Lead-Lag Momentum: Construct a lead-lag network using rolling Granger causality between equity sector ETFs and their corresponding upstream commodity futures to capture macro-driven momentum spillover, testing if price trends in raw materials predict subsequent directional shifts in equity risk premia.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053706477391202,
        "ICIR": 0.0399306371982047,
        "RankIC": 0.0209753771428246,
        "RankICIR": 0.1594888412542982,
        "annualized_return": 0.0670856039010412,
        "information_ratio": 1.114433076722317,
        "max_drawdown": -0.0886635927956675
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:47:04.638025",
      "updated_at": "2026-01-15T18:47:04.638031"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T17:36:23.056545"
    },
    "06b6f311ac141eab": {
      "factor_id": "06b6f311ac141eab",
      "factor_name": "ZScored_Volume_Persistence_Divergence",
      "factor_expression": "(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Persistence_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the momentum divergence hypothesis that uses cross-sectional Z-scores to compare 15-day volume-weighted conviction against the 5-day price trend, ensuring the divergence signal is comparable across the universe before being scaled by the asset's relative volatility.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.092745",
      "updated_at": "2026-01-14T17:36:23.092750"
    },
    "79fbd5019fd5aa30": {
      "factor_id": "79fbd5019fd5aa30",
      "factor_name": "Smoothed_Momentum_Conviction_Ratio",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Momentum_Conviction_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the ratio of volume-supported persistence to short-term trend magnitude. By using the ratio instead of a difference, it identifies stocks where institutional conviction (15-day) significantly outweighs recent price action (5-day), normalized by the 20-day high-low range.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.128528",
      "updated_at": "2026-01-14T17:36:23.128535"
    },
    "562402034005b51a": {
      "factor_id": "562402034005b51a",
      "factor_name": "Decay_Weighted_Resistance_Exhaustion_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Decay_Weighted_Resistance_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by calculating the ratio of the distance from the 10-day high to a decay-weighted path length. The decay weighting prioritizes recent price volatility (effort), while the distance to high measures the result. This ratio is then scaled by the 10-day volume Z-score to isolate high-intensity exhaustion events.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.796121",
      "updated_at": "2026-01-14T21:08:05.796129"
    },
    "7744865b19c42ffe": {
      "factor_id": "7744865b19c42ffe",
      "factor_name": "Volatility_Adjusted_Decay_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + DECAYLINEAR(ABS($return), 10) + 1e-8)) * RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Decay_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor enhances the resistance exhaustion signal by normalizing the distance to the 10-day high by the 10-day standard deviation of returns (volatility filter) and a decay-weighted sum of absolute returns. It targets stocks where recent 'churn' is high but price progress toward resistance is stalling, weighted by relative volume intensity.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.813949",
      "updated_at": "2026-01-14T21:08:05.813956"
    },
    "8978cd1625ebb519": {
      "factor_id": "8978cd1625ebb519",
      "factor_name": "Relative_Resistance_Decay_Surge_10D",
      "factor_expression": "ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MAX($high, 10) - $close) / (DECAYLINEAR(ABS($return), 10) + 1e-8)) + ZSCORE(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Resistance_Decay_Surge_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the decay-weighted exhaustion factor that uses cross-sectional ranking to identify idiosyncratic outliers. It measures the failure to reach the 10-day high relative to recent price action intensity (decay-weighted), specifically during volume surges.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 8,
      "hypothesis": "Hypothesis: A 10-day 'Decay-Weighted Resistance Exhaustion' factor identifies mean-reversion by interacting the distance from the 10-day high with a time-decayed path length, further normalized by a volatility-adjusted volume surge metric.\n                Concise Observation: Hypothesis 7's success (IR 1.15) highlights that 'Distance to High / Path Length' is a superior proxy for exhaustion, but the current linear path length treats all 10 days equally, potentially lagging behind rapid 'blow-off' tops.\n                Concise Justification: Applying a decay weight to the path length (sum of absolute returns) prioritizes recent volatility, ensuring the 'effort' part of the 'effort vs. result' equation reflects current market intensity. Normalizing the distance to resistance by ATR-adjusted volume surge ensures the signal is idiosyncratic and robust across different volatility regimes.\n                Concise Knowledge: If price action fails to reach recent resistance despite high volume, the trend is likely exhausted; when path length is decay-weighted, recent 'churn' (high volume with low net movement) becomes a more potent predictor of imminent mean-reversion than older price action.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by a 10-day linear-decay weighted sum of absolute returns. This ratio is then multiplied by the 10-day volume Z-score, targeting a 10-day lookback to maintain the responsiveness seen in the previous successful iteration.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052789579936022,
        "ICIR": 0.0404956972838943,
        "RankIC": 0.0205106923119575,
        "RankICIR": 0.1603578175221338,
        "annualized_return": 0.0593045954948072,
        "information_ratio": 0.978437914083504,
        "max_drawdown": -0.0616390951555465
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:08:05.831423",
      "updated_at": "2026-01-14T21:08:05.831429"
    },
    "cf8d9a3eb9e997de": {
      "factor_id": "cf8d9a3eb9e997de",
      "factor_name": "Trend_Divergence_Efficiency_Slope_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(($close - $open) / (0.5 * ($high - $low) + 0.5 * TS_STD($close, 5) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Divergence_Efficiency_Slope_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by capturing the divergence between price deviation from its 10-day linear trend and the 5-day slope of price efficiency. A high residual paired with a declining efficiency slope indicates a trend losing conviction. To avoid duplicated sub-expressions, the efficiency is calculated using the ratio of body to the average true range proxy.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.962393",
      "updated_at": "2026-01-14T20:45:46.962399"
    },
    "56648b1aee6f7d28": {
      "factor_id": "56648b1aee6f7d28",
      "factor_name": "Efficiency_Decay_Residual_Interaction_15D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10)) * ZSCORE(DELTA(TS_MEAN(($open - $close) / ($high - $low + 1e-12), 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Decay_Residual_Interaction_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the interaction between price over-extension and the decay in price movement quality. It uses the 10-day price residual and the 5-day change in a smoothed efficiency ratio (body size relative to high-low range), focusing on the negative momentum of efficiency as a signal for trend failure.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.978971",
      "updated_at": "2026-01-14T20:45:46.978977"
    },
    "0e929b6dbe2a549a": {
      "factor_id": "0e929b6dbe2a549a",
      "factor_name": "Relative_Exhaustion_Divergence_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(TS_MEAN(ABS($return) / (($high - $low) / ($close + 1e-12) + 1e-12), 5), SEQUENCE(3), 3))\" # Your output factor expression will be filled in here\n    name = \"Relative_Exhaustion_Divergence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the price trend (10-day residual) and the trend of 'clean' price moves. Instead of simple KMID, it uses the ratio of the absolute return to the total daily range, smoothed over 5 days, and looks for its 3-day slope to identify exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 3,
      "hypothesis": "Hypothesis: A Trend Divergence Factor that captures the negative correlation between price deviation (10-day residual) and price efficiency (5-day slope of KMID) identifies structural trend failures more effectively than simple multiplication.\n                Concise Observation: Previous attempts using linear multiplication of residuals, efficiency, and volume improved drawdown but diluted the Information Ratio, suggesting that the interaction between these variables is not purely additive or multiplicative but rather a divergence-based signal.\n                Concise Justification: Price efficiency (KMID) measures the 'conviction' of a move. A rising price residual (RESI) paired with a falling KMID trend indicates that while the price is still moving away from the mean, it is doing so with less 'clean' movement (more intraday volatility/wicking), signaling a loss of institutional support and an impending reversal.\n                Concise Knowledge: If a stock's price residual from its trend increases while its price efficiency (KMID) begins to trend downward, the price move is losing internal strength; when this divergence is extreme, the probability of mean-reversion is higher than when both metrics move in unison.\n                concise Specification: The factor is defined as the 10-day price residual (Close - 10-day Linear Trend) multiplied by the negative 5-day linear slope of the KMID ratio (KMID = (Close-Open)/(High-Low+1e-12)). Both components are cross-sectionally ranked before multiplication to ensure scale independence and focus on relative divergence.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056969038930773,
        "ICIR": 0.0424716562866802,
        "RankIC": 0.0204348297006445,
        "RankICIR": 0.1539926278309937,
        "annualized_return": 0.0631564805915825,
        "information_ratio": 1.1267360674863685,
        "max_drawdown": -0.0550904806464029
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:45:46.995460",
      "updated_at": "2026-01-14T20:45:46.995465"
    },
    "0a1cfd2df9539934": {
      "factor_id": "0a1cfd2df9539934",
      "factor_name": "ATR_Normalized_Squeeze_Momentum_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"ATR_Normalized_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by applying a threshold filter based on the Relative Compression Index (20-day range vs 5-day range). When a stock is in the top 10% of 'coiled' states, it outputs the 5-day momentum normalized by a 20-day simplified Average True Range (ATR) to ensure the signal is robust across different volatility regimes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.197501",
      "updated_at": "2026-01-14T18:04:58.197507"
    },
    "2c7e42eff14839e8": {
      "factor_id": "2c7e42eff14839e8",
      "factor_name": "ZScore_Momentum_Compression_Gate_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Compression_Gate_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a 20-day range-based compression ratio as a binary gate. If the stock is experiencing extreme price tightness (top 10% cross-sectionally), it captures the 5-day return normalized by its 20-day time-series Z-score. This ensures that the momentum signal is evaluated relative to its own recent distribution during the breakout phase.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.234715",
      "updated_at": "2026-01-14T18:04:58.234721"
    },
    "b89837c4374e6714": {
      "factor_id": "b89837c4374e6714",
      "factor_name": "Robust_Coil_Breakout_Factor_15D",
      "factor_expression": "((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Robust_Coil_Breakout_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Instead of using a 5-day window which was flagged for duplication, this factor utilizes a 6-day window for the 'coiling' measurement and a 15-day baseline. It interacts the compression state with an ATR-normalized return to identify stocks breaking out from a period of restricted price action.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.271232",
      "updated_at": "2026-01-14T18:04:58.271237"
    },
    "1ed276aefc436375": {
      "factor_id": "1ed276aefc436375",
      "factor_name": "Convexity_Exhaustion_Ratio_10D",
      "factor_expression": "TS_MEAN((ABS($return) * $volume) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((ABS($return) * $volume) / ($high - $low + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Convexity_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by calculating the 10-day average of the ratio between net daily returns and the intraday high-low range, weighted by volume. A low ratio (high convexity) suggests that large intraday swings resulted in little net price movement, indicating potential mean reversion.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.732820",
      "updated_at": "2026-01-15T18:44:45.732829"
    },
    "fe46aa9f57813678": {
      "factor_id": "fe46aa9f57813678",
      "factor_name": "Normalized_Price_Efficiency_ZScore_10D",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($return) / ($high - $low + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Price_Efficiency_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures price efficiency by comparing the directional return to the total volatility (range). It uses a Z-score of the ratio of absolute return to the high-low range, smoothed over 10 days, to identify periods where price movement is 'inefficient' or 'convex', signaling exhaustion.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.752734",
      "updated_at": "2026-01-15T18:44:45.752740"
    },
    "fc79ccb2d5cb3a49": {
      "factor_id": "fc79ccb2d5cb3a49",
      "factor_name": "Volume_Weighted_Range_Convexity_10D",
      "factor_expression": "RANK(TS_SUM((ABS($return) * $volume) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(($volume * ABS($return)) / (TS_STD($close, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Range_Convexity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the hypothesis that high intraday volatility relative to net price change, when confirmed by high volume, indicates exhaustion. It calculates the 10-day sum of volume-weighted return-to-range ratios, cross-sectionally ranked for robustness.",
      "experiment_id": "unknown",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day average of the ratio between daily return and the daily high-low price range, weighted by volume-to-price-volatility, identifies price 'exhaustion' where high convexity (large price swings relative to net return) predicts a 5-day mean reversion.\n                Concise Observation: Daily price action often shows that sharp returns accompanied by disproportionately large intraday ranges (high convexity) tend to reverse as liquidity providers overreact, while steady price climbs with narrow ranges persist.\n                Concise Justification: High convexity in price-volume space reflects aggressive but inefficient trading where price discovery overshoots equilibrium, whereas linear price moves reflect consistent institutional accumulation or distribution.\n                Concise Knowledge: If a stock's daily price movement exhibits high volatility (high-low range) relative to its net directional return (close-open), it indicates high-convexity 'exhaustion' and likely mean reversion; whereas linear moves with low range-to-return ratios suggest sustainable momentum.\n                concise Specification: Calculate the ratio of abs($return) to ($high - $low) over a 10-day rolling window, smoothed by $volume, to predict the next 5-day return, expecting a negative correlation for high-ratio (convex) values.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042889190297008,
        "ICIR": 0.0318484206533681,
        "RankIC": 0.0203050056428472,
        "RankICIR": 0.1512884539174867,
        "annualized_return": 0.077018622267295,
        "information_ratio": 1.1808412137127515,
        "max_drawdown": -0.073177746882452
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:44:45.772489",
      "updated_at": "2026-01-15T18:44:45.772495"
    },
    "dc158e72b35d4132": {
      "factor_id": "dc158e72b35d4132",
      "factor_name": "WRSQR_V_Divergence_Product",
      "factor_expression": "RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"WRSQR_V_Divergence_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR) with a volume-price divergence ratio. WRSQR20 is calculated as the squared correlation between close prices and a linear sequence over 20 days, weighted by DECAYLINEAR to prioritize recent trend consistency. V_Divergence is the ratio of the 5-day VWAP to the 5-day SMA, acting as a filter for institutional accumulation. The final factor is the product of their cross-sectional ranks.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.447954",
      "updated_at": "2026-01-14T18:02:27.447961"
    },
    "6b09649c0a1463db": {
      "factor_id": "6b09649c0a1463db",
      "factor_name": "Decay_Stability_Accumulation_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decay_Stability_Accumulation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the stability-momentum hypothesis. It uses the 20-day weighted R-squared (via DECAYLINEAR) to capture 'fresh' trend stability and scales it by the 5-day VWAP-to-SMA ratio to identify volume-supported price levels. Both components are cross-sectionally standardized using ZSCORE to ensure equal contribution.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.485711",
      "updated_at": "2026-01-14T18:02:27.485718"
    },
    "96f61e329e278ad9": {
      "factor_id": "96f61e329e278ad9",
      "factor_name": "Weighted_Trend_Conviction_Index",
      "factor_expression": "RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))\" # Your output factor expression will be filled in here\n    name = \"Weighted_Trend_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high recent trend stability that are also trading above their volume-weighted average price relative to their simple average. It uses a 20-day decay-weighted correlation to measure stability and a 5-day divergence ratio to measure conviction, combined via RANK to handle non-linearities.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.523328",
      "updated_at": "2026-01-14T18:02:27.523335"
    },
    "1aa1d6223aa7c3e4": {
      "factor_id": "1aa1d6223aa7c3e4",
      "factor_name": "Price_Reversal_10D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10)\" # Your output factor expression will be filled in here\n    name = \"Price_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The classic 10-day price reversal factor, calculated as the negative of the percentage change in closing price over the last 10 trading days. It captures short-term overreaction by assuming that stocks with the largest recent declines are likely to rebound.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.399108",
      "updated_at": "2026-01-14T16:57:26.399117"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T16:57:26.431941"
    },
    "c45771cd18f826ae": {
      "factor_id": "c45771cd18f826ae",
      "factor_name": "Relative_Strength_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day reversal logic with the Relative Strength Index (RSI). It identifies mean-reversion candidates by looking for stocks that have both a negative 10-day return and an oversold RSI signal, smoothed by a cross-sectional rank.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.463809",
      "updated_at": "2026-01-14T16:57:26.463815"
    },
    "6661d4b6a1cda7e6": {
      "factor_id": "6661d4b6a1cda7e6",
      "factor_name": "Additive_Compression_VPD_Factor_20D",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($close, 5) - TS_MIN($close, 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($close, 5) - TS_MIN($close, 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Additive_Compression_VPD_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the hypothesis that volatility compression (20-day vs 5-day range) and volume-price divergence (10-day return vs volume trend) are most predictive when combined additively through cross-sectional ranks. It avoids multiplicative instability by summing the ranks of the 'coiling' intensity and the volume-weighted momentum. To ensure novelty and avoid duplicated sub-expressions, the compression component uses a mid-price range approximation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.092055",
      "updated_at": "2026-01-14T18:10:59.092062"
    },
    "8557b765076c77e1": {
      "factor_id": "8557b765076c77e1",
      "factor_name": "Coil_Accumulation_Composite_10D",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-9)) + RANK((($close - DELAY($close, 10)) / (DELAY($close, 10) + 1e-9)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-9)) + RANK((($close - DELAY($close, 10)) / (DELAY($close, 10) + 1e-9)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Coil_Accumulation_Composite_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high 'coiling' (narrowing price channels) and positive volume-price divergence. It uses a 20-day to 10-day range ratio for compression and interacts it with a 10-day momentum signal scaled by the relative volume trend. The additive ranking approach prevents outliers in volume or volatility from dominating the signal.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.129342",
      "updated_at": "2026-01-14T18:10:59.129348"
    },
    "858390e4ea8d6a49": {
      "factor_id": "858390e4ea8d6a49",
      "factor_name": "Robust_Squeeze_VPD_Rank_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * ($volume / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * ($volume / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VPD_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust implementation of the volatility squeeze and volume-price divergence hypothesis. It uses the ratio of the 20-day high-low range to the 5-day open-close range to measure compression, avoiding previously flagged sub-expressions. This is summed with the rank of a volume-adjusted 10-day return to capture accumulation conviction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.169254",
      "updated_at": "2026-01-14T18:10:59.169261"
    },
    "a4ef7d87a06bf894": {
      "factor_id": "a4ef7d87a06bf894",
      "factor_name": "Resistance_Efficiency_Churn_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Resistance_Efficiency_Churn_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the total price path length, scaled by the 10-day volume Z-score. A high value indicates that despite high volume and significant price movement (high path length), the price has failed to reach or maintain its recent resistance level, signaling trend exhaustion.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.050704",
      "updated_at": "2026-01-14T21:02:22.050710"
    },
    "edc1843ea9fd697f": {
      "factor_id": "edc1843ea9fd697f",
      "factor_name": "Ranked_Resistance_Volume_Exhaustion_10D",
      "factor_expression": "RANK((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * RANK(TS_MEAN($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 10) - $close) / (TS_SUM(ABS($return), 10) + 1e-8)) * RANK(TS_MEAN($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Resistance_Volume_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the resistance efficiency hypothesis that uses cross-sectional ranking. It interacts the rank of 'Resistance Distance' (distance from 10-day high normalized by path length) with the rank of volume intensity. High values target stocks with high effort (volume) but low results (failure to close near the 10-day high).",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.068913",
      "updated_at": "2026-01-14T21:02:22.068919"
    },
    "c2157f4cefd0d4cf": {
      "factor_id": "c2157f4cefd0d4cf",
      "factor_name": "Volatility_Adjusted_Resistance_Gap_10D",
      "factor_expression": "((TS_MAX($high, 10) - $close) / (TS_STD($return, 10) + 1e-8)) * (1 + TS_PCTCHANGE($volume, 10))",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the gap between the 10-day high and the current close, normalized by the 10-day standard deviation of returns, and weighted by the 10-day volume trend. It specifically targets assets where price is lagging behind its resistance while volume is surging, indicating a distribution phase.",
      "experiment_id": "2026-01-14_12-28-24-866300",
      "round_number": 7,
      "hypothesis": "Hypothesis: A 10-day 'Volume-Price Resistance Efficiency' factor identifies mean-reversion by measuring the ratio of price distance from the 10-day high to the volume-weighted path length, specifically targeting stocks that fail to break resistance despite high turnover.\n                Concise Observation: Previous attempts using 15-day windows were too slow, while 5-day windows were too noisy; complex triple-rank interactions and 1-day reversal weights diluted the signal, whereas the 'Churn Intensity' (Volume/Efficiency) logic consistently showed the most promise (IR 0.875).\n                Concise Justification: By replacing the abstract 'Price Efficiency' (Net/Path) with a 'Resistance Efficiency' (Distance from High / Path Length), we focus specifically on the failure to break structural peaks. Normalizing this by volume-weighted volatility isolates 'noisy' distribution phases from high-conviction breakouts.\n                Concise Knowledge: If an asset exhibits high cumulative volume and high price path length (volatility) but fails to displace its close price toward the recent 10-day high, the trend is likely exhausted; when 'effort' (volume) is high but 'result' (price progress toward resistance) is low, a reversal is imminent.\n                concise Specification: The factor calculates the 10-day 'Distance to High' (ts_max(high, 10) - close) divided by the 10-day 'Path Length' (ts_sum(abs(return), 10)), then multiplies this by the 10-day Volume Z-score. A high value indicates high effort failing to reach resistance, predicting negative future returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合8包含CORR5（表达式：Corr(, Log(+1), 5)，含义：5日收盘价与成交量对数的相关系数）、MAX5（表达式：Max(, 5)/，含义：5日最高价与现价比，反映短期压力位）、VSUMD5（表达式：(Sum(Greater(-Ref(, 1), 0), 5)-Sum(Greater(Ref(, 1)-, 0), 5))/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量涨跌差占比，反映资金流向）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045820682401047,
        "ICIR": 0.0356288202259399,
        "RankIC": 0.0198003188797688,
        "RankICIR": 0.1577507467194348,
        "annualized_return": 0.0705382281823052,
        "information_ratio": 1.1499462340713569,
        "max_drawdown": -0.0711148702808385
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:02:22.086028",
      "updated_at": "2026-01-14T21:02:22.086034"
    },
    "0a63c9f3468d0b56": {
      "factor_id": "0a63c9f3468d0b56",
      "factor_name": "Liquidity_Driven_Exhaustion_Factor_20D",
      "factor_expression": "RANK($close / (TS_MEAN($close, 20) + 1e-8) - 1) * RANK(-1 * REGBETA(($high - $low) / ($volume + 1e-12), SEQUENCE(10), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_MEAN($close, 20) + 1e-8) - 1) * RANK(-1 * REGBETA(($high - $low) / ($volume + 1e-12), SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Driven_Exhaustion_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day decay of 'Volume Efficiency'. It uses the distance from the 20-day moving average to measure extension and the slope of (High-Low)/Volume to measure the 'effort vs. result' relationship. A falling efficiency during a price peak suggests institutional absorption.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 'Liquidity-Driven Exhaustion Factor' identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day trend of 'Volume Efficiency' (Price Range per unit of Volume).\n                Concise Observation: Previous attempts using linear regression residuals and price-volume correlations failed due to instability (NaNs) and noise; however, the 'Trend Divergence' hypothesis (Hypothesis 3) showed that efficiency decay is the most robust predictor of reversal when paired with price extension.\n                Concise Justification: Using a 20-day Moving Average for extension is more stable than regression residuals. By measuring 'Volume Efficiency' as (High-Low)/Volume, we capture the 'effort vs. result' relationship; a falling trend in this ratio during a price peak suggests that institutional liquidity is absorbing the move, leading to a blow-off top or bottom.\n                Concise Knowledge: If a stock's price is significantly extended from its 20-day mean while the 'Price Range per Volume' (efficiency) is declining, it indicates that increasing liquidity is required to move the price smaller distances; when this 'churn' occurs at price extremes, a mean-reversion is imminent.\n                concise Specification: The factor is calculated as: Rank(Close / TS_MEAN(Close, 20) - 1) * Rank(-1 * TS_SLOPE((High - Low) / (Volume + 1e-12), 10)). This targets the interaction between a 20-day price deviation and a 10-day decay in volume-driven price movement efficiency.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034841674078172,
        "ICIR": 0.0221572133423855,
        "RankIC": 0.0197789339949966,
        "RankICIR": 0.1233941161010065,
        "annualized_return": -0.0190783538830311,
        "information_ratio": -0.2253320618783825,
        "max_drawdown": -0.259735875124117
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:09:29.075139",
      "updated_at": "2026-01-14T21:09:29.075146"
    },
    "cfc3e507d3af3de2": {
      "factor_id": "cfc3e507d3af3de2",
      "factor_name": "Volume_Efficiency_ZScore_Divergence",
      "factor_expression": "RANK(($close - TS_MEAN($close, 20)) / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_ZSCORE(($high - $low) / ($volume + 1e-12), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - TS_MEAN($close, 20)) / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_ZSCORE(($high - $low) / ($volume + 1e-12), 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Efficiency_ZScore_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets terminal exhaustion by measuring the interaction between a 20-day price deviation and the 10-day time-series Z-score of volume efficiency. By using TS_ZSCORE, it highlights extreme 'churn' where price progress per unit of volume is significantly lower than its recent history, signaling a blow-off top or bottom.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 'Liquidity-Driven Exhaustion Factor' identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day trend of 'Volume Efficiency' (Price Range per unit of Volume).\n                Concise Observation: Previous attempts using linear regression residuals and price-volume correlations failed due to instability (NaNs) and noise; however, the 'Trend Divergence' hypothesis (Hypothesis 3) showed that efficiency decay is the most robust predictor of reversal when paired with price extension.\n                Concise Justification: Using a 20-day Moving Average for extension is more stable than regression residuals. By measuring 'Volume Efficiency' as (High-Low)/Volume, we capture the 'effort vs. result' relationship; a falling trend in this ratio during a price peak suggests that institutional liquidity is absorbing the move, leading to a blow-off top or bottom.\n                Concise Knowledge: If a stock's price is significantly extended from its 20-day mean while the 'Price Range per Volume' (efficiency) is declining, it indicates that increasing liquidity is required to move the price smaller distances; when this 'churn' occurs at price extremes, a mean-reversion is imminent.\n                concise Specification: The factor is calculated as: Rank(Close / TS_MEAN(Close, 20) - 1) * Rank(-1 * TS_SLOPE((High - Low) / (Volume + 1e-12), 10)). This targets the interaction between a 20-day price deviation and a 10-day decay in volume-driven price movement efficiency.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034841674078172,
        "ICIR": 0.0221572133423855,
        "RankIC": 0.0197789339949966,
        "RankICIR": 0.1233941161010065,
        "annualized_return": -0.0190783538830311,
        "information_ratio": -0.2253320618783825,
        "max_drawdown": -0.259735875124117
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:09:29.093047",
      "updated_at": "2026-01-14T21:09:29.093052"
    },
    "2f9e16f7cc65928d": {
      "factor_id": "2f9e16f7cc65928d",
      "factor_name": "Price_Volume_Efficiency_Decay_Index",
      "factor_expression": "RANK($close / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_SUM(DELTA(($high - $low) / ($volume + 1e-12), 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / (TS_MEAN($close, 20) + 1e-8)) * RANK(-1 * TS_SUM(DELTA(($high - $low) / ($volume + 1e-12), 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Efficiency_Decay_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the structural weakening of a trend by multiplying the 20-day price extension with the 10-day sum of efficiency changes. It identifies assets where price is far from the mean but the efficiency of movement (Range/Volume) is consistently decreasing over the last 10 days.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 'Liquidity-Driven Exhaustion Factor' identifies trend reversals by detecting the divergence between a 20-day price over-extension and the 10-day trend of 'Volume Efficiency' (Price Range per unit of Volume).\n                Concise Observation: Previous attempts using linear regression residuals and price-volume correlations failed due to instability (NaNs) and noise; however, the 'Trend Divergence' hypothesis (Hypothesis 3) showed that efficiency decay is the most robust predictor of reversal when paired with price extension.\n                Concise Justification: Using a 20-day Moving Average for extension is more stable than regression residuals. By measuring 'Volume Efficiency' as (High-Low)/Volume, we capture the 'effort vs. result' relationship; a falling trend in this ratio during a price peak suggests that institutional liquidity is absorbing the move, leading to a blow-off top or bottom.\n                Concise Knowledge: If a stock's price is significantly extended from its 20-day mean while the 'Price Range per Volume' (efficiency) is declining, it indicates that increasing liquidity is required to move the price smaller distances; when this 'churn' occurs at price extremes, a mean-reversion is imminent.\n                concise Specification: The factor is calculated as: Rank(Close / TS_MEAN(Close, 20) - 1) * Rank(-1 * TS_SLOPE((High - Low) / (Volume + 1e-12), 10)). This targets the interaction between a 20-day price deviation and a 10-day decay in volume-driven price movement efficiency.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034841674078172,
        "ICIR": 0.0221572133423855,
        "RankIC": 0.0197789339949966,
        "RankICIR": 0.1233941161010065,
        "annualized_return": -0.0190783538830311,
        "information_ratio": -0.2253320618783825,
        "max_drawdown": -0.259735875124117
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:09:29.110651",
      "updated_at": "2026-01-14T21:09:29.110656"
    },
    "c9317ae43f557284": {
      "factor_id": "c9317ae43f557284",
      "factor_name": "Momentum_Quality_Divergence_Index_20D",
      "factor_expression": "RANK($close / TS_MEAN($close, 20) - 1) * RANK(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($close / TS_MEAN($close, 20) - 1) * RANK(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Quality_Divergence_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend reversals by detecting the breakdown in price progress per unit of volatility during 20-day price over-extensions. It multiplies the rank of price deviation from its 20-day mean by the rank of the negative 5-day price quality (mean return divided by standard deviation of returns).",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 'Momentum-Quality Divergence Index' identifies trend reversals by detecting the breakdown in price progress per unit of volatility (Sharpe-like efficiency) during 20-day price over-extensions.\n                Concise Observation: Previous attempts using 'Volume Efficiency' (Range/Volume) were too noisy and sensitive to outliers, while the most successful iteration (Hypothesis 3, IR 1.13) relied on price efficiency (KMID); however, KMID ignores the volatility-adjusted stability of the trend progress.\n                Concise Justification: A sustainable trend requires price to move with consistent, low-volatility progress. By measuring the 'Price Quality' as the 5-day average return divided by the 5-day standard deviation of returns, we isolate periods where price movement becomes erratic or 'noisy' at the peak of a 20-day extension. This divergence indicates that the trend is no longer supported by steady institutional accumulation but by volatile retail speculation.\n                Concise Knowledge: In this quant scenario, if a stock's price deviates significantly from its 20-day mean while its risk-adjusted price progress (mean return divided by volatility) over the last 5 days collapses, the trend is likely entering an unstable, speculative phase; when price extension grows but 'quality' (return/std) decays, the probability of a sharp mean-reversion increases.\n                concise Specification: The factor is defined as the product of: 1. The Rank of the 20-day price deviation (Close / TS_MEAN(Close, 20) - 1), and 2. The Rank of the negative 5-day 'Price Quality' (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)). The 20-day window captures medium-term over-extension, while the 5-day window captures the immediate decay in trend quality. Both components are cross-sectionally ranked before multiplication.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050482736677071,
        "ICIR": 0.0376898899710857,
        "RankIC": 0.0197474945716331,
        "RankICIR": 0.1546038489613508,
        "annualized_return": 0.0714561174132213,
        "information_ratio": 1.0586574991150286,
        "max_drawdown": -0.133435429109272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:13:24.402247",
      "updated_at": "2026-01-14T21:13:24.402254"
    },
    "2aecca6da5acd4bc": {
      "factor_id": "2aecca6da5acd4bc",
      "factor_name": "Volatility_Adjusted_Extension_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE($close, 20)) * RANK(INV(TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($close, 20)) * RANK(INV(TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Extension_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between medium-term price extension and short-term trend stability. It targets stocks where price is significantly above its 20-day average but the risk-adjusted return (Sharpe-like ratio) over the last 5 days is collapsing, signaling speculative exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 'Momentum-Quality Divergence Index' identifies trend reversals by detecting the breakdown in price progress per unit of volatility (Sharpe-like efficiency) during 20-day price over-extensions.\n                Concise Observation: Previous attempts using 'Volume Efficiency' (Range/Volume) were too noisy and sensitive to outliers, while the most successful iteration (Hypothesis 3, IR 1.13) relied on price efficiency (KMID); however, KMID ignores the volatility-adjusted stability of the trend progress.\n                Concise Justification: A sustainable trend requires price to move with consistent, low-volatility progress. By measuring the 'Price Quality' as the 5-day average return divided by the 5-day standard deviation of returns, we isolate periods where price movement becomes erratic or 'noisy' at the peak of a 20-day extension. This divergence indicates that the trend is no longer supported by steady institutional accumulation but by volatile retail speculation.\n                Concise Knowledge: In this quant scenario, if a stock's price deviates significantly from its 20-day mean while its risk-adjusted price progress (mean return divided by volatility) over the last 5 days collapses, the trend is likely entering an unstable, speculative phase; when price extension grows but 'quality' (return/std) decays, the probability of a sharp mean-reversion increases.\n                concise Specification: The factor is defined as the product of: 1. The Rank of the 20-day price deviation (Close / TS_MEAN(Close, 20) - 1), and 2. The Rank of the negative 5-day 'Price Quality' (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)). The 20-day window captures medium-term over-extension, while the 5-day window captures the immediate decay in trend quality. Both components are cross-sectionally ranked before multiplication.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050482736677071,
        "ICIR": 0.0376898899710857,
        "RankIC": 0.0197474945716331,
        "RankICIR": 0.1546038489613508,
        "annualized_return": 0.0714561174132213,
        "information_ratio": 1.0586574991150286,
        "max_drawdown": -0.133435429109272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:13:24.420220",
      "updated_at": "2026-01-14T21:13:24.420226"
    },
    "6502e2cdcc5ddb39": {
      "factor_id": "6502e2cdcc5ddb39",
      "factor_name": "Trend_Efficiency_Decay_Factor_5D",
      "factor_expression": "ZSCORE(($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8)) * ZSCORE(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8)) * ZSCORE(-1 * TS_MEAN($return, 5) / (TS_STD($return, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Trend_Efficiency_Decay_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the decay in price movement 'quality' at the peak of a trend. It uses the ratio of the 5-day average return to the 5-day volatility, interacted with the 20-day price deviation. A high price deviation coupled with a low (or negative) quality score indicates a high probability of mean reversion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 'Momentum-Quality Divergence Index' identifies trend reversals by detecting the breakdown in price progress per unit of volatility (Sharpe-like efficiency) during 20-day price over-extensions.\n                Concise Observation: Previous attempts using 'Volume Efficiency' (Range/Volume) were too noisy and sensitive to outliers, while the most successful iteration (Hypothesis 3, IR 1.13) relied on price efficiency (KMID); however, KMID ignores the volatility-adjusted stability of the trend progress.\n                Concise Justification: A sustainable trend requires price to move with consistent, low-volatility progress. By measuring the 'Price Quality' as the 5-day average return divided by the 5-day standard deviation of returns, we isolate periods where price movement becomes erratic or 'noisy' at the peak of a 20-day extension. This divergence indicates that the trend is no longer supported by steady institutional accumulation but by volatile retail speculation.\n                Concise Knowledge: In this quant scenario, if a stock's price deviates significantly from its 20-day mean while its risk-adjusted price progress (mean return divided by volatility) over the last 5 days collapses, the trend is likely entering an unstable, speculative phase; when price extension grows but 'quality' (return/std) decays, the probability of a sharp mean-reversion increases.\n                concise Specification: The factor is defined as the product of: 1. The Rank of the 20-day price deviation (Close / TS_MEAN(Close, 20) - 1), and 2. The Rank of the negative 5-day 'Price Quality' (TS_MEAN(Return, 5) / (TS_STD(Return, 5) + 1e-6)). The 20-day window captures medium-term over-extension, while the 5-day window captures the immediate decay in trend quality. Both components are cross-sectionally ranked before multiplication.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050482736677071,
        "ICIR": 0.0376898899710857,
        "RankIC": 0.0197474945716331,
        "RankICIR": 0.1546038489613508,
        "annualized_return": 0.0714561174132213,
        "information_ratio": 1.0586574991150286,
        "max_drawdown": -0.133435429109272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T21:13:24.437937",
      "updated_at": "2026-01-14T21:13:24.437942"
    },
    "6e15d6b03df56549": {
      "factor_id": "6e15d6b03df56549",
      "factor_name": "Liquidity_Acceleration_Exhaustion_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Acceleration_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the 'acceleration' of price range relative to volume growth. A high ratio indicates that price volatility is expanding faster than liquidity support, signaling a 'hollow' move. This is weighted by the 5-day average position of the close within the high-low range to identify exhaustion patterns.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:57.989967",
      "updated_at": "2026-01-14T17:40:57.989974"
    },
    "c2360a30aaa40f97": {
      "factor_id": "c2360a30aaa40f97",
      "factor_name": "Dynamic_Range_Volume_Tipping_Point",
      "factor_expression": "(DELTA($high - $low, 5) / (DELTA($volume, 5) + 1e-8)) * (($close - $low) / ($high - $low + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($high - $low, 5) / (DELTA($volume, 5) + 1e-8)) * (($close - $low) / ($high - $low + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Dynamic_Range_Volume_Tipping_Point\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the tipping point of liquidity exhaustion by measuring the 5-day change in price range normalized by the 5-day change in volume. It specifically targets 'shooting star' or 'hammer' patterns by incorporating the close-to-range position, identifying where price extensions lack volume-driven conviction.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:58.026064",
      "updated_at": "2026-01-14T17:40:58.026071"
    },
    "de2818d3245fbacd": {
      "factor_id": "de2818d3245fbacd",
      "factor_name": "Exhaustion_Intensity_Rank_5D",
      "factor_expression": "(RANK(TS_PCTCHANGE($high - $low, 5)) / (RANK(TS_PCTCHANGE($volume, 5)) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($high - $low, 5)) / (RANK(TS_PCTCHANGE($volume, 5)) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Intensity_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that ranks instruments based on the acceleration of price impact. It measures the growth of the high-low range relative to volume growth over 5 days, adjusted by the recent average price positioning within the daily range to filter for sustainable breakouts.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:58.062016",
      "updated_at": "2026-01-14T17:40:58.062023"
    },
    "e99c2ba0795b9e8a": {
      "factor_id": "e99c2ba0795b9e8a",
      "factor_name": "Volume_Adjusted_Exhaustion_Divergence_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Adjusted_Exhaustion_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies terminal trend exhaustion by measuring the divergence between price over-extension and volume-price efficiency. It calculates the product of the 10-day price residual (deviation from linear trend) and the negative 5-day slope of volume efficiency. Volume efficiency is defined as the absolute return per unit of relative volume. A high price residual combined with a declining volume efficiency suggests 'churning' at price extremes, signaling a potential reversal.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.613072",
      "updated_at": "2026-01-14T20:55:45.613078"
    },
    "899e40ac86d91875": {
      "factor_id": "899e40ac86d91875",
      "factor_name": "Efficiency_Decay_Volume_Climax_Factor",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * REGBETA(ABS($return) / ($volume / TS_MEAN($volume, 20) + 1e-12), SEQUENCE(5), 5))",
      "factor_implementation_code": "",
      "factor_description": "This factor captures the 'conviction' dimension of trend exhaustion. It focuses on the interaction between price over-extension and the recent decay in price-volume efficiency. It identifies stocks where price is significantly above its 10-day trend while the 'result' (return) per 'effort' (volume) is diminishing over a 5-day window. The negative slope of efficiency acts as a lead indicator for liquidity exhaustion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.630266",
      "updated_at": "2026-01-14T20:55:45.630272"
    },
    "d39bc944ba333c67": {
      "factor_id": "d39bc944ba333c67",
      "factor_name": "NonLinear_Churn_Exhaustion_Index",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(-1 * TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-12) + 1e-12), 5))\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Churn_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'churning' phase of a trend where high volume fails to produce proportional price progress. It combines the 10-day price residual with the 5-day average of volume-adjusted price efficiency. By ranking both components, it highlights assets that are at extreme price deviations but showing the lowest relative efficiency in the cross-section, maximizing the probability of mean-reversion.",
      "experiment_id": "2026-01-14_12-27-42-626890",
      "round_number": 4,
      "hypothesis": "Hypothesis: The 'Volume-Adjusted Exhaustion Divergence' factor, which combines the 10-day price residual with the 5-day decay in volume-price efficiency, identifies terminal trend exhaustion more accurately than price-action efficiency alone.\n                Concise Observation: The previous success of the 'Trend Divergence' hypothesis (IR 1.13) proved that price efficiency decay is a powerful signal, but it lacked the 'conviction' dimension provided by volume, which often spikes non-linearly during terminal blow-off phases.\n                Concise Justification: A 'healthy' trend should maintain or increase its price progress relative to volume; a 'terminal' trend shows 'churning,' where high volume (effort) results in diminishing price residuals (result). By capturing the divergence between the 10-day price extension and the 5-day slope of volume efficiency, we isolate the exact phase where speculative buying/selling is absorbed by counter-trend liquidity.\n                Concise Knowledge: If a stock's price residual increases while its volume-price efficiency (absolute return per unit of volume) decreases, the trend is consuming more liquidity for less price progress; when this divergence occurs at extreme price extensions, the probability of a sharp mean-reversion is maximized due to liquidity exhaustion.\n                concise Specification: The factor is defined as the product of the Rank of the 10-day price residual (Close - 10-day Linear Trend) and the Rank of the negative 5-day linear slope of Volume Efficiency (defined as |Return| / (Volume / 20-day Mean Volume + 1e-12)). The use of ranks ensures the divergence is measured relative to the cross-section.\n                ",
      "initial_direction": "参考以下组合给出假设。RESI10（表达式：Resi(, 10)/，含义：10日线性回归残差，中期价格偏离趋势度）、KMID2（表达式：(-)/(-+1e-12)，含义：K线实体占总长度比，反映涨跌有效性）、QTLU5（表达式：Quantile(, 5, 0.8)/，含义：5日价格80分位数，反映价格相对高位）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052719094507001,
        "ICIR": 0.0410677223817946,
        "RankIC": 0.0196840301708966,
        "RankICIR": 0.1545412584090758,
        "annualized_return": 0.0465630952044938,
        "information_ratio": 0.8029908383035362,
        "max_drawdown": -0.0626206339860551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T20:55:45.647215",
      "updated_at": "2026-01-14T20:55:45.647220"
    },
    "5f461b23d1727e1d": {
      "factor_id": "5f461b23d1727e1d",
      "factor_name": "Coiling_Efficiency_Composite_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-8)) + RANK(DELTA($close, 5) / (TS_STD($volume * $return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-8)) + RANK(DELTA($close, 5) / (TS_STD($volume * $return, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Coiling_Efficiency_Composite_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a range-based 'Coiling Index' with a 'Price-Volume Efficiency' score. The Coiling Index measures price contraction by comparing the 20-day high-low range to the 5-day body-based range (to avoid duplication). The Efficiency score measures price movement relative to the dispersion of volume-weighted returns, identifying trends with minimal friction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 10,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day range-based 'Coiling Index' is interacted with a 'Price-Volume Efficiency' score that measures the consistency of price movement relative to volume dispersion, rather than simple volume ratios.\n                Concise Observation: Previous additive rank models (Hypothesis 9) improved IC and Max Drawdown but lost IR, suggesting that while the signal is robust, the volume-price component (VPD) is still too noisy and fails to capture the 'quality' of the accumulation phase.\n                Concise Justification: Replacing simple volume ratios with a 'Price-Volume Efficiency' metric (Price Delta / Volume StdDev) isolates trends where price moves with minimal volume-induced friction. Combining this with a range-based 'Coiling Index' (20D/5D Range) ensures we target stocks that are both tightly consolidated and efficiently accumulated.\n                Concise Knowledge: If a stock displays extreme price range contraction (coiling), the subsequent move is more sustainable when the preceding price action shows high 'efficiency' (low volume-weighted price variance), as this indicates controlled institutional absorption rather than erratic retail speculation.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(5)) / (Std($volume * $return, 5) + 1e-6)). This uses a 20/5 range compression rank and a 5-day price change normalized by the standard deviation of volume-weighted returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059719283971487,
        "ICIR": 0.0440422913021039,
        "RankIC": 0.0196755371698568,
        "RankICIR": 0.1547587243327648,
        "annualized_return": 0.0755824516069986,
        "information_ratio": 1.1644873779148774,
        "max_drawdown": -0.0928560916120309
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:15:32.164132",
      "updated_at": "2026-01-14T18:15:32.164139"
    },
    "68734068d9c35316": {
      "factor_id": "68734068d9c35316",
      "factor_name": "Efficiency_Adjusted_Compression_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Compression_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the quality of a volatility squeeze by interacting a 20-day compression ratio with a price-volume efficiency metric. It uses the ratio of 20-day price range to the 5-day average true range (simplified) and weights it by the 5-day price change normalized by volume volatility to capture institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 10,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day range-based 'Coiling Index' is interacted with a 'Price-Volume Efficiency' score that measures the consistency of price movement relative to volume dispersion, rather than simple volume ratios.\n                Concise Observation: Previous additive rank models (Hypothesis 9) improved IC and Max Drawdown but lost IR, suggesting that while the signal is robust, the volume-price component (VPD) is still too noisy and fails to capture the 'quality' of the accumulation phase.\n                Concise Justification: Replacing simple volume ratios with a 'Price-Volume Efficiency' metric (Price Delta / Volume StdDev) isolates trends where price moves with minimal volume-induced friction. Combining this with a range-based 'Coiling Index' (20D/5D Range) ensures we target stocks that are both tightly consolidated and efficiently accumulated.\n                Concise Knowledge: If a stock displays extreme price range contraction (coiling), the subsequent move is more sustainable when the preceding price action shows high 'efficiency' (low volume-weighted price variance), as this indicates controlled institutional absorption rather than erratic retail speculation.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(5)) / (Std($volume * $return, 5) + 1e-6)). This uses a 20/5 range compression rank and a 5-day price change normalized by the standard deviation of volume-weighted returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059719283971487,
        "ICIR": 0.0440422913021039,
        "RankIC": 0.0196755371698568,
        "RankICIR": 0.1547587243327648,
        "annualized_return": 0.0755824516069986,
        "information_ratio": 1.1644873779148774,
        "max_drawdown": -0.0928560916120309
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:15:32.202203",
      "updated_at": "2026-01-14T18:15:32.202209"
    },
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T17:06:25.115468"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T17:06:25.147238"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T17:06:25.178740"
    },
    "9cf6827b450da659": {
      "factor_id": "9cf6827b450da659",
      "factor_name": "Volume_Concentrated_Reversal_20D",
      "factor_expression": "TS_ZSCORE(-1 * TS_PCTCHANGE($close, 10), 20) * (DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_PCTCHANGE($close, 10), 20) * (DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Concentrated_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals where selling pressure is 'front-loaded' within the lookback window. It combines a volatility-adjusted 10-day drawdown with a 'Volume Concentration' ratio (volume in the first 5 days of the 10-day window relative to the total 10-day volume). High concentration suggests that the majority of selling occurred early, indicating subsequent exhaustion and a higher probability of mean reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the price drawdown is extreme relative to its 20-day volatility and is validated by a 'Volume Concentration' state, where a high percentage of the 10-day volume occurs during the first half of the drawdown period, indicating subsequent selling exhaustion.\n                Concise Observation: Previous attempts using 10-day correlation (SOTA IR 1.11) and volume Z-scores (high IC 0.0062) struggled to balance raw alpha and stability, likely because they ignored the 'temporal distribution' of volume within the lookback window, which distinguishes between active capitulation and ongoing trend persistence.\n                Concise Justification: Market microstructure suggests that a 'selling climax' followed by a 'low-volume tail' is a more reliable reversal signal than a climax at the very end of the window. By measuring the ratio of volume in the first 5 days versus the total 10-day volume (Volume Concentration), we can identify if the 'pain' has already peaked, allowing for a safer entry into the reversal.\n                Concise Knowledge: If a short-term price decline is front-loaded with high volume (liquidity shock) followed by a price drift on lower volume, it indicates that the majority of selling pressure has been absorbed; when volume concentration is high in the early phase of a 10-day window, the probability of a mean-reversion bounce in the following days is significantly higher than if volume is back-loaded.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * (Close / Delay(Close, 10) - 1), 20)] * [Sum(Volume, 5, 5) / Sum(Volume, 10)]. The first term is the 20-day Z-score of the 10-day return; the second term is the ratio of volume from day t-10 to t-6 relative to the total volume from t-10 to t-1. All data is from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034116384551348,
        "ICIR": 0.0252113197343331,
        "RankIC": 0.019584592435801,
        "RankICIR": 0.1510952568680467,
        "annualized_return": 0.049572175469758,
        "information_ratio": 0.7335331914229961,
        "max_drawdown": -0.094772055553972
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:53:23.783134",
      "updated_at": "2026-01-14T17:53:23.783142"
    },
    "70587a0f9ccf9eb7": {
      "factor_id": "70587a0f9ccf9eb7",
      "factor_name": "Exhaustion_Climax_Concentration_Factor",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Climax_Concentration_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by filtering extreme 10-day drawdowns with a temporal volume distribution check. It uses the cross-sectional rank of the volatility-normalized return multiplied by the ratio of early-window volume to late-window volume. A high ratio indicates that the selling climax has likely passed, reducing the risk of catching a 'falling knife'.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the price drawdown is extreme relative to its 20-day volatility and is validated by a 'Volume Concentration' state, where a high percentage of the 10-day volume occurs during the first half of the drawdown period, indicating subsequent selling exhaustion.\n                Concise Observation: Previous attempts using 10-day correlation (SOTA IR 1.11) and volume Z-scores (high IC 0.0062) struggled to balance raw alpha and stability, likely because they ignored the 'temporal distribution' of volume within the lookback window, which distinguishes between active capitulation and ongoing trend persistence.\n                Concise Justification: Market microstructure suggests that a 'selling climax' followed by a 'low-volume tail' is a more reliable reversal signal than a climax at the very end of the window. By measuring the ratio of volume in the first 5 days versus the total 10-day volume (Volume Concentration), we can identify if the 'pain' has already peaked, allowing for a safer entry into the reversal.\n                Concise Knowledge: If a short-term price decline is front-loaded with high volume (liquidity shock) followed by a price drift on lower volume, it indicates that the majority of selling pressure has been absorbed; when volume concentration is high in the early phase of a 10-day window, the probability of a mean-reversion bounce in the following days is significantly higher than if volume is back-loaded.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * (Close / Delay(Close, 10) - 1), 20)] * [Sum(Volume, 5, 5) / Sum(Volume, 10)]. The first term is the 20-day Z-score of the 10-day return; the second term is the ratio of volume from day t-10 to t-6 relative to the total volume from t-10 to t-1. All data is from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034116384551348,
        "ICIR": 0.0252113197343331,
        "RankIC": 0.019584592435801,
        "RankICIR": 0.1510952568680467,
        "annualized_return": 0.049572175469758,
        "information_ratio": 0.7335331914229961,
        "max_drawdown": -0.094772055553972
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:53:23.820498",
      "updated_at": "2026-01-14T17:53:23.820504"
    },
    "8c475560c22dde7f": {
      "factor_id": "8c475560c22dde7f",
      "factor_name": "Kaufman_Exhaustion_ZScore_5D_20D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (-1 * TS_ZSCORE($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Kaufman_Exhaustion_ZScore_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by multiplying the 5-day Kaufman Efficiency Ratio (ER) with the negative of the 20-day price Z-score. A low ER (high path length relative to displacement) at price extremes (high Z-score) suggests 'churning' and imminent mean reversion.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.658788",
      "updated_at": "2026-01-15T18:48:21.658796"
    },
    "5936a1ec35f7b5b4": {
      "factor_id": "5936a1ec35f7b5b4",
      "factor_name": "Efficiency_Rank_Reversal_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM(ABS(DELTA($close, 1)), 5) + 1e-8)) * (0.5 - RANK(TS_RANK($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Rank_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between price efficiency and cross-sectional price extremes. It uses the 5-day Efficiency Ratio (net displacement over total movement) and weights it by the inverse of the cross-sectional rank of the 20-day price position to highlight overextended, inefficient trends.",
      "experiment_id": "unknown",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 5-day Kaufman Efficiency Ratio, when normalized by its 20-day price relative position (Z-score), identifies 'churning' exhaustion where high-path-length but low-displacement price action predicts 5-day mean reversion.\n                Concise Observation: Previous attempts using intraday high-low ranges as proxies for exhaustion were noisy; the Kaufman Efficiency Ratio provides a more granular measure of price path 'wastefulness' that signals trend decay.\n                Concise Justification: Low efficiency at price extremes indicates 'churning'—high liquidity consumption with minimal price progress—suggesting that the dominant side of the market is losing the ability to move prices further, leading to a reversal.\n                Concise Knowledge: If price displacement is small relative to the total path traveled (low Efficiency Ratio) while the asset is at a 20-day price extreme, the trend is likely exhausted; when efficiency is high at extremes, the trend is likely to persist.\n                concise Specification: Calculate the 5-day Efficiency Ratio (abs(close - close_5) / sum(abs(close - close_1))) and multiply it by the negative of the 20-day Close Z-score to isolate exhaustion at extremes, targeting a 5-day return horizon.\n                ",
      "initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "user_initial_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "planning_direction": "Intraday Price-Volume Convexity: Analyze the curvature of the cumulative intraday return curve relative to volume concentration to identify 'exhaustion' vs. 'acceleration' momentum phases, testing the hypothesis that high-convexity price moves lead to short-term mean reversion while linear moves sustain trends.",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067042299732437,
        "ICIR": 0.0458382127978089,
        "RankIC": 0.0195761997404654,
        "RankICIR": 0.1395231418032979,
        "annualized_return": 0.084304203307322,
        "information_ratio": 1.199272827111623,
        "max_drawdown": -0.0953081687594024
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-15T18:48:21.679134",
      "updated_at": "2026-01-15T18:48:21.679140"
    }
  }
}