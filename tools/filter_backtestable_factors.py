#!/usr/bin/env python3
"""
è¿‡æ»¤å¯å›æµ‹çš„å› å­

ä»å› å­åº“ä¸­ç­›é€‰å‡ºå¯ä»¥è¿›è¡Œå›æµ‹çš„å› å­ï¼š
1. æœ‰ç¼“å­˜æ–‡ä»¶ (result.h5) çš„å› å­ - ç›´æ¥åŠ è½½è®¡ç®—å¥½çš„å€¼
2. æœ‰è§„èŒƒ factor_expression çš„å› å­ - å¯ä»¥é‡æ–°è®¡ç®—

ç”¨æ³•:
    # å¯¼å‡ºå¯å›æµ‹çš„å› å­
    python tools/filter_backtestable_factors.py \
        --input all_factors_library.json \
        --output filtered_factors.json
    
    # åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    python tools/filter_backtestable_factors.py \
        --input all_factors_library.json \
        --stats-only
"""

import argparse
import json
import re
from pathlib import Path
from datetime import datetime
from collections import OrderedDict


# ä¸è§„èŒƒè¡¨è¾¾å¼çš„æ¨¡å¼
INVALID_PATTERNS = [
    r'LET\s*\(',          # LET(...) å˜é‡å®šä¹‰
    r'\bIF\s*\(',         # IF(...) æ¡ä»¶
    r'//',                # // æ³¨é‡Š
    r';\s*\n',            # åˆ†å·æ¢è¡Œï¼ˆå¤šè¯­å¥ï¼‰
    r'\b[a-z_]+\s*=\s*[^=]',  # å˜é‡èµ‹å€¼ (å¦‚ roc60 = ...)
    r'#\s+[A-Za-z]',      # # æ³¨é‡Š
    r'\bAND\b',           # AND å…³é”®å­—
    r'\bOR\b',            # OR å…³é”®å­—
    r'\bNULL\b',          # NULL å…³é”®å­—
]


def is_valid_expression(expr: str) -> tuple:
    """
    æ£€æŸ¥å› å­è¡¨è¾¾å¼æ˜¯å¦è§„èŒƒ
    
    Returns:
        (is_valid, issues_list)
    """
    if not expr or not isinstance(expr, str):
        return False, ["è¡¨è¾¾å¼ä¸ºç©º"]
    
    issues = []
    for pattern in INVALID_PATTERNS:
        if re.search(pattern, expr, re.MULTILINE | re.IGNORECASE):
            issues.append(f"åŒ¹é…åˆ°ä¸è§„èŒƒæ¨¡å¼: {pattern}")
    
    return len(issues) == 0, issues


def check_cache_exists(cache_location: dict) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not cache_location:
        return False
    
    h5_path = cache_location.get("result_h5_path", "")
    if not h5_path:
        return False
    
    return Path(h5_path).exists()


def analyze_factors(data: dict) -> dict:
    """åˆ†æå› å­åº“"""
    factors = data.get("factors", {})
    
    stats = {
        "total": len(factors),
        "has_cache": 0,
        "valid_expr_only": 0,
        "both": 0,  # æœ‰ç¼“å­˜ä¸”è¡¨è¾¾å¼æœ‰æ•ˆ
        "backtestable": 0,  # å¯å›æµ‹ = has_cache OR valid_expr
        "not_backtestable": 0,
        "invalid_expr_with_cache": 0,  # è¡¨è¾¾å¼æ— æ•ˆä½†æœ‰ç¼“å­˜
        "invalid_expr_no_cache": 0,  # è¡¨è¾¾å¼æ— æ•ˆä¸”æ— ç¼“å­˜
        "factors": {
            "backtestable": [],
            "not_backtestable": [],
        }
    }
    
    for fid, factor in factors.items():
        expr = factor.get("factor_expression", "")
        cache = factor.get("cache_location")
        
        has_cache = check_cache_exists(cache)
        is_valid, issues = is_valid_expression(expr)
        
        if has_cache:
            stats["has_cache"] += 1
        if is_valid:
            stats["valid_expr_only"] += 1
        if has_cache and is_valid:
            stats["both"] += 1
        
        # å¯å›æµ‹æ¡ä»¶ï¼šæœ‰ç¼“å­˜ OR è¡¨è¾¾å¼æœ‰æ•ˆ
        if has_cache or is_valid:
            stats["backtestable"] += 1
            stats["factors"]["backtestable"].append({
                "factor_id": fid,
                "factor_name": factor.get("factor_name", ""),
                "has_cache": has_cache,
                "valid_expr": is_valid,
                "source": "cache" if has_cache else "expr",
                "factor": factor,
            })
        else:
            stats["not_backtestable"] += 1
            stats["factors"]["not_backtestable"].append({
                "factor_id": fid,
                "factor_name": factor.get("factor_name", ""),
                "issues": issues,
                "factor": factor,
            })
        
        if not is_valid:
            if has_cache:
                stats["invalid_expr_with_cache"] += 1
            else:
                stats["invalid_expr_no_cache"] += 1
    
    return stats


def export_backtestable_factors(stats: dict, output_path: str, input_path: str):
    """å¯¼å‡ºå¯å›æµ‹çš„å› å­"""
    backtestable = stats["factors"]["backtestable"]
    
    new_factors = OrderedDict()
    for item in backtestable:
        fid = item["factor_id"]
        new_factors[fid] = item["factor"]
    
    output_data = {
        "metadata": {
            "created_at": datetime.now().isoformat(),
            "total_factors": len(new_factors),
            "source": str(input_path),
            "note": f"Filtered backtestable factors: {stats['has_cache']} from cache, {stats['valid_expr_only']} from valid expression",
            "version": "1.0"
        },
        "factors": new_factors
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… å·²å¯¼å‡º {len(new_factors)} ä¸ªå¯å›æµ‹å› å­åˆ°: {output_path}")


def print_stats(stats: dict):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print("å› å­åº“åˆ†ææŠ¥å‘Š")
    print('='*60)
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»å› å­æ•°: {stats['total']}")
    print(f"  âœ… å¯å›æµ‹: {stats['backtestable']} ({stats['backtestable']/stats['total']*100:.1f}%)")
    print(f"  âŒ ä¸å¯å›æµ‹: {stats['not_backtestable']} ({stats['not_backtestable']/stats['total']*100:.1f}%)")
    
    print(f"\nğŸ“ ç¼“å­˜çŠ¶æ€:")
    print(f"  æœ‰ç¼“å­˜æ–‡ä»¶: {stats['has_cache']}")
    print(f"  è¡¨è¾¾å¼æœ‰æ•ˆ: {stats['valid_expr_only']}")
    print(f"  ä¸¤è€…éƒ½æœ‰: {stats['both']}")
    
    print(f"\nâš ï¸ é—®é¢˜å› å­:")
    print(f"  è¡¨è¾¾å¼æ— æ•ˆä½†æœ‰ç¼“å­˜(å¯å›æµ‹): {stats['invalid_expr_with_cache']}")
    print(f"  è¡¨è¾¾å¼æ— æ•ˆä¸”æ— ç¼“å­˜(ä¸å¯å›æµ‹): {stats['invalid_expr_no_cache']}")
    
    # æ˜¾ç¤ºä¸å¯å›æµ‹å› å­
    not_backtestable = stats["factors"]["not_backtestable"]
    if not_backtestable:
        print(f"\nâŒ ä¸å¯å›æµ‹çš„å› å­ ({len(not_backtestable)} ä¸ª):")
        for item in not_backtestable[:10]:
            print(f"  - {item['factor_name']}: {', '.join(item['issues'][:2])}")
        if len(not_backtestable) > 10:
            print(f"  ... è¿˜æœ‰ {len(not_backtestable) - 10} ä¸ª")
    
    print('='*60)


def main():
    parser = argparse.ArgumentParser(description='è¿‡æ»¤å¯å›æµ‹çš„å› å­')
    parser.add_argument('--input', '-i', type=str, required=True, help='è¾“å…¥å› å­åº“JSONè·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--stats-only', action='store_true', help='åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    print(f"ğŸ“‚ åŠ è½½å› å­åº“: {args.input}")
    
    with open(args.input, 'r', encoding='utf-8') as f:
        data = json.load(f, object_pairs_hook=OrderedDict)
    
    stats = analyze_factors(data)
    print_stats(stats)
    
    if not args.stats_only and args.output:
        export_backtestable_factors(stats, args.output, args.input)
    elif not args.stats_only:
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        input_path = Path(args.input)
        output_path = input_path.parent / f"{input_path.stem}_backtestable{input_path.suffix}"
        export_backtestable_factors(stats, str(output_path), args.input)


if __name__ == '__main__':
    main()

