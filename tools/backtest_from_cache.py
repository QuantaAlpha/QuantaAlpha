#!/usr/bin/env python3
"""
ä»ç¼“å­˜ç›´æ¥åŠ è½½å› å­å€¼è¿›è¡Œå›æµ‹

å½“ factor_expression ä¸è§„èŒƒæ—¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ç¼“å­˜çš„ result.h5 æ–‡ä»¶ã€‚
è¿™äº›æ–‡ä»¶åŒ…å«å·²è®¡ç®—å¥½çš„å› å­å€¼ã€‚

ç”¨æ³•:
    # å›æµ‹å•ä¸ªå› å­åº“ä¸­æ‰€æœ‰æœ‰ç¼“å­˜çš„å› å­
    python tools/backtest_from_cache.py --input all_factors_library.json --output results.json
    
    # åªæ£€æŸ¥ç¼“å­˜çŠ¶æ€ï¼Œä¸å›æµ‹
    python tools/backtest_from_cache.py --input all_factors_library.json --check-only
    
    # å¯¼å‡ºæœ‰ç¼“å­˜çš„å› å­åˆ°æ–°çš„JSONï¼ˆç”¨äºåç»­å›æµ‹ï¼‰
    python tools/backtest_from_cache.py --input all_factors_library.json --export-cached factors_with_cache.json
"""

import argparse
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from collections import OrderedDict
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_factor_library(filepath: str) -> dict:
    """åŠ è½½å› å­åº“"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f, object_pairs_hook=OrderedDict)


def check_cache_status(data: dict) -> dict:
    """æ£€æŸ¥å› å­åº“ä¸­çš„ç¼“å­˜çŠ¶æ€"""
    factors = data.get("factors", {})
    
    stats = {
        "total": len(factors),
        "has_cache_path": 0,
        "cache_exists": 0,
        "cache_missing": 0,
        "no_cache_info": 0,
        "factors_with_cache": [],
        "factors_without_cache": [],
    }
    
    for fid, factor in factors.items():
        cache = factor.get("cache_location")
        if not cache:
            stats["no_cache_info"] += 1
            stats["factors_without_cache"].append(fid)
            continue
        
        h5_path = cache.get("result_h5_path", "")
        if not h5_path:
            stats["no_cache_info"] += 1
            stats["factors_without_cache"].append(fid)
            continue
        
        stats["has_cache_path"] += 1
        
        if Path(h5_path).exists():
            stats["cache_exists"] += 1
            stats["factors_with_cache"].append({
                "factor_id": fid,
                "factor_name": factor.get("factor_name", ""),
                "h5_path": h5_path,
                "factor": factor,
            })
        else:
            stats["cache_missing"] += 1
            stats["factors_without_cache"].append(fid)
    
    return stats


def load_factor_from_cache(h5_path: str) -> pd.DataFrame:
    """ä»ç¼“å­˜åŠ è½½å› å­å€¼"""
    try:
        df = pd.read_hdf(h5_path, key='data')
        return df
    except Exception as e:
        print(f"  âš ï¸ åŠ è½½å¤±è´¥ {h5_path}: {e}")
        return None


def export_factors_with_cache(data: dict, stats: dict, output_path: str):
    """å¯¼å‡ºæœ‰ç¼“å­˜çš„å› å­åˆ°æ–°çš„JSON"""
    factors_with_cache = stats["factors_with_cache"]
    
    new_factors = OrderedDict()
    for item in factors_with_cache:
        fid = item["factor_id"]
        new_factors[fid] = item["factor"]
    
    output_data = {
        "metadata": {
            "created_at": datetime.now().isoformat(),
            "total_factors": len(new_factors),
            "note": f"Factors with valid cache from {Path(output_path).stem}",
            "version": "1.0"
        },
        "factors": new_factors
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²å¯¼å‡º {len(new_factors)} ä¸ªæœ‰ç¼“å­˜çš„å› å­åˆ°: {output_path}")


def create_factor_value_index(stats: dict, output_path: str = None):
    """
    åˆ›å»ºå› å­å€¼ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾å› å­å¯¹åº”çš„ç¼“å­˜æ–‡ä»¶
    
    è¾“å‡ºæ ¼å¼:
    {
        "factor_id": {
            "factor_name": "...",
            "h5_path": "...",
            "factor_dir": "..."
        }
    }
    """
    index = {}
    
    for item in stats["factors_with_cache"]:
        fid = item["factor_id"]
        factor = item["factor"]
        cache = factor.get("cache_location", {})
        
        index[fid] = {
            "factor_name": item["factor_name"],
            "h5_path": item["h5_path"],
            "factor_dir": cache.get("factor_dir", ""),
            "factor_workspace_path": cache.get("factor_workspace_path", ""),
        }
    
    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
        print(f"âœ… å·²åˆ›å»ºå› å­ç¼“å­˜ç´¢å¼•: {output_path}")
    
    return index


def main():
    parser = argparse.ArgumentParser(description='ä»ç¼“å­˜åŠ è½½å› å­è¿›è¡Œå›æµ‹')
    parser.add_argument('--input', '-i', type=str, required=True, help='è¾“å…¥å› å­åº“JSONè·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºç»“æœè·¯å¾„')
    parser.add_argument('--check-only', action='store_true', help='åªæ£€æŸ¥ç¼“å­˜çŠ¶æ€')
    parser.add_argument('--export-cached', type=str, help='å¯¼å‡ºæœ‰ç¼“å­˜çš„å› å­åˆ°æ–°JSON')
    parser.add_argument('--create-index', type=str, help='åˆ›å»ºå› å­ç¼“å­˜ç´¢å¼•æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print(f"ğŸ“‚ åŠ è½½å› å­åº“: {args.input}")
    data = load_factor_library(args.input)
    
    print(f"\nğŸ” æ£€æŸ¥ç¼“å­˜çŠ¶æ€...")
    stats = check_cache_status(data)
    
    print(f"\nğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
    print(f"  æ€»å› å­æ•°: {stats['total']}")
    print(f"  æœ‰ç¼“å­˜è·¯å¾„: {stats['has_cache_path']}")
    print(f"  ç¼“å­˜æ–‡ä»¶å­˜åœ¨: {stats['cache_exists']}")
    print(f"  ç¼“å­˜æ–‡ä»¶ç¼ºå¤±: {stats['cache_missing']}")
    print(f"  æ— ç¼“å­˜ä¿¡æ¯: {stats['no_cache_info']}")
    
    if args.check_only:
        print("\nâœ… æ£€æŸ¥å®Œæˆ (--check-only æ¨¡å¼)")
        return
    
    if args.export_cached:
        export_factors_with_cache(data, stats, args.export_cached)
    
    if args.create_index:
        create_factor_value_index(stats, args.create_index)
    
    if not args.export_cached and not args.create_index:
        print("\næç¤º: ä½¿ç”¨ä»¥ä¸‹é€‰é¡¹è¿›è¡Œè¿›ä¸€æ­¥æ“ä½œ:")
        print("  --export-cached <path>  å¯¼å‡ºæœ‰ç¼“å­˜çš„å› å­")
        print("  --create-index <path>   åˆ›å»ºå› å­ç¼“å­˜ç´¢å¼•")


if __name__ == '__main__':
    main()

