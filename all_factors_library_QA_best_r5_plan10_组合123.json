{
  "metadata": {
    "created_at": "2026-01-08T21:03:59.729617",
    "last_updated": "2026-01-17T08:41:46.981387",
    "total_factors": 449,
    "version": "1.0",
    "note": "Cleaned: removed 662 factors before line 15604"
  },
  "factors": {
    "fdee666a2ba26e1d": {
      "factor_id": "fdee666a2ba26e1d",
      "factor_name": "ROC60_Low_Vol_Stability_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ROC60_Low_Vol_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by weighting the 60-day rate of change (ROC) by the inverse of the 5-day volume volatility. High ROC accompanied by low volume standard deviation suggests 'quiet' institutional exhaustion, increasing the probability of a reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.759435",
      "updated_at": "2026-01-17T01:28:06.759443"
    },
    "fe31eaba3ed86e19": {
      "factor_id": "fe31eaba3ed86e19",
      "factor_name": "Institutional_Accumulation_Reversal_5D",
      "factor_expression": "TS_PCTCHANGE($close, 60) * (1 - TS_ZSCORE(TS_STD($volume, 5), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 60) * (1 - TS_ZSCORE(TS_STD($volume, 5), 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction price trends by multiplying the 60-day price momentum with a stability filter. The filter uses the Z-score of the 5-day volume volatility to overweight stocks with steady (low-volatility) volume patterns, indicating institutional positioning.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.768275",
      "updated_at": "2026-01-17T01:28:06.768282"
    },
    "f167722533e1adb7": {
      "factor_id": "f167722533e1adb7",
      "factor_name": "Quiet_Trend_Exhaustion_Factor",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 60) / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 60) / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally normalized factor that targets stocks where the 60-day price momentum is extreme but the short-term volume volatility is minimal. It uses the ratio of momentum to volume volatility to highlight structural trends prone to mean-reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 60-day Rate of Change (ROC60) exhibits a stronger negative correlation with future returns when the 5-day standard deviation of volume (VSTD5) is low, identifying high-conviction institutional accumulation phases.\n                Concise Observation: Price momentum often fails or reverses unpredictably during high-liquidity turbulence, but long-term returns (ROC60) show more consistent mean-reversion patterns when short-term volume fluctuations (VSTD5) are minimized.\n                Concise Justification: Low volume volatility suggests a lack of panic trading and the presence of 'quiet' accumulation or distribution, which reinforces the structural nature of the price level and sets the stage for a mean-reversion correction.\n                Concise Knowledge: If a long-term price trend occurs alongside low volume volatility, it likely reflects steady institutional positioning; when such stability exists, the subsequent price reversal is more statistically significant due to the exhaustion of the prevailing trend.\n                concise Specification: Calculate ROC60 as (close - close_60)/close_60 and VSTD5 as the standard deviation of volume over 5 days; the factor is defined as ROC60 multiplied by the inverse of VSTD5 to overweight low-volatility stability.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "original",
      "trajectory_id": "b4953cf0ffdb",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053168997827081,
        "ICIR": 0.0418434252441355,
        "RankIC": 0.0219785728096424,
        "RankICIR": 0.1789293778617892,
        "annualized_return": 0.0398330647169246,
        "information_ratio": 0.6720559352320243,
        "max_drawdown": -0.0925038327838218
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:28:06.777107",
      "updated_at": "2026-01-17T01:28:06.777114"
    },
    "552fa3c9d347569e": {
      "factor_id": "552fa3c9d347569e",
      "factor_name": "Vol_Adjusted_Residual_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Residual_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day price residual from a linear regression against time, normalized by the 5-day rolling standard deviation of daily returns. This normalization identifies overextended price movements relative to the asset's current volatility regime.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.383540",
      "updated_at": "2026-01-17T01:31:14.383548"
    },
    "ff0456dd0f1e862c": {
      "factor_id": "ff0456dd0f1e862c",
      "factor_name": "ZScore_Residual_Momentum_10D",
      "factor_expression": "ZSCORE(REGRESI($close, SEQUENCE(10), 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGRESI($close, SEQUENCE(10), 10) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Residual_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the volatility-adjusted residual using a 10-day window and cross-sectional Z-scoring. It measures how many standard deviations the current price deviates from its local trend, relative to other stocks in the universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.392740",
      "updated_at": "2026-01-17T01:31:14.392747"
    },
    "d3e961cf16cfa600": {
      "factor_id": "d3e961cf16cfa600",
      "factor_name": "Ranked_Vol_Residual_Ratio_20D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(20), 20) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(20), 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Vol_Residual_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a longer 20-day lookback for the trend residual and normalizes it by the 20-day volatility. The final value is cross-sectionally ranked to provide a robust signal for mean reversion that is less sensitive to extreme outliers in high-volatility environments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Mean Reversion factor, defined as the 5-day price residual (RESI5) divided by the 5-day rolling standard deviation of returns (STD5), provides a superior signal for identifying overextended price movements compared to raw residuals.\n                Concise Observation: Raw price residuals often flag high-volatility stocks as extreme outliers, leading to false signals where the price deviation is actually within the normal expected range of that asset's current risk profile.\n                Concise Justification: Scaling residuals by standard deviation transforms absolute price distance into a statistical significance measure, ensuring that mean-reversion bets are placed only when the deviation exceeds the asset's typical fluctuation threshold.\n                Concise Knowledge: If a price residual is normalized by the asset's recent realized volatility, then the resulting Z-score better distinguishes between high-conviction trend shifts and noise-driven mean reversion opportunities.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing this residual by the 5-day rolling standard deviation of daily log returns.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "original",
      "trajectory_id": "4264359dd7fa",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056897341869444,
        "ICIR": 0.040842403258331,
        "RankIC": 0.0227984619726139,
        "RankICIR": 0.1669572492350197,
        "annualized_return": 0.0410778628441738,
        "information_ratio": 0.6561029645879094,
        "max_drawdown": -0.0805604868421341
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:31:14.401839",
      "updated_at": "2026-01-17T01:31:14.401845"
    },
    "e8c8d125e900c078": {
      "factor_id": "e8c8d125e900c078",
      "factor_name": "Price_Volume_Divergence_Momentum_Filter",
      "factor_expression": "TS_CORR($close, $volume, 20) * (($close / (DELAY($close, 60) + 1e-8)) > 1.2 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (($close / (DELAY($close, 60) + 1e-8)) > 1.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Divergence_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures mean-reversion opportunities by identifying assets where price and volume are negatively correlated over a 20-day window, filtered by a 60-day price momentum threshold. A negative correlation in a downtrend suggests selling exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.414416",
      "updated_at": "2026-01-17T01:33:55.414423"
    },
    "361cf565a18c2fb8": {
      "factor_id": "361cf565a18c2fb8",
      "factor_name": "Exhaustion_Regime_Indicator_20_60",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * TS_PCTCHANGE($close, 60)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * TS_PCTCHANGE($close, 60)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Regime_Indicator_20_60\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies a specific market regime where price trend lacks volume support. It uses the rank of the 20-day price-volume correlation and scales it by a long-term 60-day relative price change to highlight potential reversal points in overextended or distressed assets.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.423623",
      "updated_at": "2026-01-17T01:33:55.423629"
    },
    "62b2bd1a32c42d0d": {
      "factor_id": "62b2bd1a32c42d0d",
      "factor_name": "Volume_Decoupled_Mean_Reversion",
      "factor_expression": "TS_ZSCORE(TS_CORR($close, $volume, 20), 60)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR($close, $volume, 20), 60) * ((TS_MAX($high, 60) - TS_MIN($low, 60)) / (TS_MEAN($close, 60) + 1e-8) > 0.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Volume_Decoupled_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the decoupling of price and volume. It calculates the 20-day correlation between price and volume and applies a conditional check on the 60-day price range. It aims to detect when a price move is losing liquidity support, signaling a potential trend shift.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative correlation of price and volume and a 60-day price momentum threshold identifies mean-reversion opportunities in oversold assets.\n                Concise Observation: In distressed market regimes, price often continues to drift lower on thinning volume (negative correlation), suggesting that the supply of motivated sellers is nearly depleted.\n                Concise Justification: A negative correlation between price and volume (CORR20 < 0) implies that as price falls, volume decreases, which contradicts the 'volume confirms trend' principle and signals a lack of conviction in the downward move.\n                Concise Knowledge: If price and volume exhibit a strong negative correlation during a long-term downtrend, it indicates a decoupling where selling pressure diminishes despite falling prices; when this occurs, a subsequent reversal is likely as liquidity exhaustion precedes a trend shift.\n                concise Specification: The factor is defined as the product of the 20-day Spearman correlation between $close and $volume and a binary indicator where the 60-day Rate of Change ($close / delay($close, 60)) is greater than 1.2, focusing on the specific divergence regime.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "original",
      "trajectory_id": "eee7281a5d10",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0101760305930527,
        "ICIR": 0.0714103862598581,
        "RankIC": 0.0293903175276131,
        "RankICIR": 0.2110825439891154,
        "annualized_return": 0.0936239921992535,
        "information_ratio": 1.323067178220683,
        "max_drawdown": -0.0949365970875541
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:33:55.432925",
      "updated_at": "2026-01-17T01:33:55.432932"
    },
    "1ef674e9335a5506": {
      "factor_id": "1ef674e9335a5506",
      "factor_name": "Intraday_Support_Persistence_3D",
      "factor_expression": "RANK(TS_MEAN($low / ($high + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($low / ($high + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Support_Persistence_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of intraday support by calculating the 3-day average of the ratio between the daily low and the daily high. A higher ratio indicates that the daily price floor is consistently near the daily ceiling, suggesting strong structural buying pressure and shallow retracements.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:31.996149",
      "updated_at": "2026-01-17T01:35:31.996156"
    },
    "aff3a44a82d9f6c2": {
      "factor_id": "aff3a44a82d9f6c2",
      "factor_name": "Relative_Low_Position_Stability_5D",
      "factor_expression": "RANK(TS_MEAN(($low - $low + 0.01) / (($high - $low) / $open + 0.01), 5))",
      "factor_implementation_code": "",
      "factor_description": "This factor captures the stability of the price floor by measuring the 5-day average of the low price's position relative to the daily range (high - low). It uses a slightly longer window than the 3-day version to capture more robust structural support while normalizing by the intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:32.005454",
      "updated_at": "2026-01-17T01:35:32.005459"
    },
    "dbdfe2963b41ca0d": {
      "factor_id": "dbdfe2963b41ca0d",
      "factor_name": "Support_Level_ZScore_3D",
      "factor_expression": "ZSCORE(TS_MEAN($low / ($high + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($low / ($high + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Support_Level_ZScore_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks where the current intraday low is significantly higher than its historical average relative to the high, normalized by the cross-sectional distribution. It highlights abnormal strength in the price floor.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 3-day average of the ratio between the daily low price and the daily price range (high minus low) serves as a proxy for intraday support persistence, where higher values indicate stronger structural buying pressure and predict positive future returns.\n                Concise Observation: Daily price action frequently shows that stocks with 'shallow' pullbacks relative to their volatility (high low-to-range ratios) tend to exhibit more stable trend persistence than those with deep intraday retracements.\n                Concise Justification: The ratio of ($low - $low) / ($high - $low) is always 0, so the intended logic is the relative position of the low within the high-low channel; a high relative low suggests that the 'floor' of the day is elevated, indicating strong limit-order clusters or institutional support.\n                Concise Knowledge: If a stock's daily low consistently resides near the upper end of its intraday range, it suggests that aggressive buyers are absorbing selling pressure before prices can mean-revert to the daily average; such structural support often precedes upward momentum.\n                concise Specification: Calculate the ratio ($low / $high) or more specifically ($low - min_low) is not possible with daily data, so we use ($low / $high) over a 3-day rolling window to measure the persistence of the price floor relative to the ceiling.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "original",
      "trajectory_id": "f774b3beb631",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078813560423296,
        "ICIR": 0.054861950766636,
        "RankIC": 0.0256495059138648,
        "RankICIR": 0.1888602805404589,
        "annualized_return": 0.0782203629547681,
        "information_ratio": 1.23761002347991,
        "max_drawdown": -0.0989708035749755
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:35:32.014723",
      "updated_at": "2026-01-17T01:35:32.014729"
    },
    "f099da69a9738d69": {
      "factor_id": "f099da69a9738d69",
      "factor_name": "Delta_RESI_5D_Acceleration",
      "factor_expression": "DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Delta_RESI_5D_Acceleration\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day difference of the Relative Strength Intensity (RESI), where RESI is the ratio of the 5-day price range (highest high to lowest low) to the absolute 5-day price change. A sharp increase in this ratio indicates that price volatility is expanding much faster than directional displacement, signaling potential trend exhaustion and mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.915433",
      "updated_at": "2026-01-17T01:38:33.915439"
    },
    "731124529417b326": {
      "factor_id": "731124529417b326",
      "factor_name": "Ranked_RESI_Volatility_Exhaustion",
      "factor_expression": "RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_RESI_Volatility_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Delta-RESI factor. It identifies stocks experiencing the most extreme acceleration in price range relative to net displacement. High values suggest 'blow-off' phases where price movement becomes inefficient, increasing the probability of a short-term reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.924868",
      "updated_at": "2026-01-17T01:38:33.924874"
    },
    "0ac2b03eccbd1e52": {
      "factor_id": "0ac2b03eccbd1e52",
      "factor_name": "Smoothed_RESI_Efficiency_Gap",
      "factor_expression": "SMA(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5), 3, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SMA(DELTA((TS_MAX($high, 5) - TS_MIN($low, 5)) / (ABS($close - DELAY($close, 5)) + 1e-8), 5), 3, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_RESI_Efficiency_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a simple moving average to the Delta-RESI calculation to filter out daily noise and isolate sustained acceleration in volatility extremes. It focuses on the inefficiency of price movement over a short window to predict mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day difference in the Relative Strength Intensity (RESI) over a 5-day window, defined as the ratio of high-low range to absolute price change, predicts short-term mean reversion by identifying accelerating exhaustion in price volatility extremes.\n                Concise Observation: Price extremes often exhibit a 'blow-off' phase where daily high-low ranges expand significantly faster than the net directional close-to-close movement, suggesting a loss of directional conviction despite high activity.\n                Concise Justification: RESI measures the efficiency of price movement; a sharp increase in RESI (Delta-Resi) captures the transition from a trending state to a chaotic, high-volatility state, which typically precedes a trend reversal or consolidation.\n                Concise Knowledge: If the ratio of price range to net displacement increases rapidly (high convexity), it indicates inefficient price movement and impending trend exhaustion; when this acceleration peaks, a reversal is likely as liquidity providers demand higher premiums for volatility.\n                concise Specification: Calculate RESI5 as (Highest High - Lowest Low) / Abs(Close - Close_lag5) over a 5-day window, then compute the 5-day difference of this ratio to isolate the acceleration component (Delta-RESI).\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "original",
      "trajectory_id": "18b3311d728e",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0039771549711288,
        "ICIR": 0.0301579078139291,
        "RankIC": 0.020023869351216,
        "RankICIR": 0.1575443144828124,
        "annualized_return": 0.078891051955969,
        "information_ratio": 1.2145317318110254,
        "max_drawdown": -0.0942721926811376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:33.934465",
      "updated_at": "2026-01-17T01:38:33.934470"
    },
    "6cbededfd2d1673b": {
      "factor_id": "6cbededfd2d1673b",
      "factor_name": "Risk_Adj_Momentum_Vol_Stab_60D",
      "factor_expression": "(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) * INV(TS_STD($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 60) / TS_STD(TS_PCTCHANGE($close, 1), 20)) * INV(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Risk_Adj_Momentum_Vol_Stab_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the risk-adjusted momentum (60-day price change divided by 20-day return volatility) and scales it by the inverse of short-term volume volatility. High values indicate a strong, stable price trend accompanied by consistent trading volume, suggesting institutional quality trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.797529",
      "updated_at": "2026-01-17T01:38:36.797535"
    },
    "4954e8114853e7d1": {
      "factor_id": "4954e8114853e7d1",
      "factor_name": "Ranked_Quality_Momentum_Volume_Stability",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60) / (TS_STD($return, 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)) + RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Quality_Momentum_Volume_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the risk-adjusted momentum hypothesis. It combines the rank of 60-day momentum normalized by 20-day volatility with the rank of the inverse 5-day volume volatility to identify assets with the most 'orderly' uptrends relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.807169",
      "updated_at": "2026-01-17T01:38:36.807175"
    },
    "5e44428625b9cb8c": {
      "factor_id": "5e44428625b9cb8c",
      "factor_name": "Zscored_Trend_Persistence_Factor",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 60), 20) / (TS_STD($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "",
      "factor_description": "This factor applies a Z-score to the 60-day return and divides it by the 20-day return standard deviation, then filters the result by the stability of volume. It aims to isolate high-conviction trends where price growth is statistically significant and volume noise is minimal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between risk-adjusted momentum (ROC60/Std20) and short-term volume volatility (VSTD5) provides a more robust signal for trend persistence than raw momentum, specifically that high risk-adjusted returns coupled with low volume volatility identify sustainable price trends.\n                Concise Observation: Raw momentum (ROC60) often captures high-volatility price spikes that mean-revert quickly, whereas normalizing by standard deviation (Std20) filters for 'quality' of the trend.\n                Concise Justification: Risk-adjusting the momentum ensures that the asset is being rewarded for consistent growth rather than erratic jumps, and incorporating volume volatility helps distinguish between institutional accumulation and speculative retail frenzy.\n                Concise Knowledge: If a long-term price trend is accompanied by low return volatility and stable trading volume, it is more likely to persist; conversely, high volume volatility during a trend often signals an exhaustive climax or increased noise.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change divided by the 20-day standard deviation of returns, multiplied by the inverse of the 5-day standard deviation of volume.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "original",
      "trajectory_id": "d6ee4fbd38ba",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005220572777611,
        "ICIR": 0.0390914395469204,
        "RankIC": 0.0222337727308222,
        "RankICIR": 0.1701726074398064,
        "annualized_return": 0.0749502915650849,
        "information_ratio": 1.222525400679778,
        "max_drawdown": -0.0949752776439158
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:38:36.816637",
      "updated_at": "2026-01-17T01:38:36.816643"
    },
    "85da7ff1dec67c97": {
      "factor_id": "85da7ff1dec67c97",
      "factor_name": "Lower_Shadow_Vwap_Reversal_1D",
      "factor_expression": "((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ((($open + $high + $low + $close) / 4) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ((($open + $high + $low + $close) / 4) / ($close + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Lower_Shadow_Vwap_Reversal_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by combining the relative length of the lower shadow with a volume-weighted price deviation. A long lower shadow (KLOW) indicates intraday price rejection, and when combined with a VWAP that is higher than the close price, it suggests institutional support at lower levels.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.760937",
      "updated_at": "2026-01-17T01:40:44.760945"
    },
    "93c985c2b203733a": {
      "factor_id": "93c985c2b203733a",
      "factor_name": "High_Conviction_Support_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 5))\" # Your output factor expression will be filled in here\n    name = \"High_Conviction_Support_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor smooths the intraday support signal over a 5-day window and applies a cross-sectional rank. It captures stocks consistently showing strong price rejection at lows relative to their volume-weighted average price, indicating high-conviction accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.771080",
      "updated_at": "2026-01-17T01:40:44.771088"
    },
    "85a9f9a96cbf1421": {
      "factor_id": "85a9f9a96cbf1421",
      "factor_name": "Volume_Weighted_Shadow_ZScore_10D",
      "factor_expression": "TS_ZSCORE(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * (($open + $high + $low + $close) / (4 * $close + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Shadow_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the lower shadow conviction signal using a 10-day time-series Z-score. It highlights days where the intraday price rejection and VWAP-to-Close ratio are significantly higher than their recent historical norm, signaling an exhaustion of selling pressure.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the lower shadow length relative to the price range and the volume-weighted price deviation (Vwap/Close) identifies high-conviction price reversals; specifically, a long lower shadow combined with high relative volume indicates strong intraday support and predicts positive future returns.\n                Concise Observation: Intraday price dips often create 'shadows' in daily bars, but their predictive power for reversals is inconsistent without accounting for the liquidity and conviction represented by volume distribution.\n                Concise Justification: Lower shadows represent failed attempts by bears to push prices lower; by weighting this physical price action with the ratio of VWAP to Close, we can distinguish between meaningful price floors and low-volume noise that lacks follow-through.\n                Concise Knowledge: If a price rejection (lower shadow) occurs on high relative volume, it signifies institutional absorption of selling pressure; when the closing price is significantly below the volume-weighted average price (VWAP) despite this rejection, it suggests an oversold condition with strong underlying support.\n                concise Specification: Define KLOW as (min(Open, Close) - Low) / (High - Low + 1e-6) and Vwap_Ratio as ((Open + High + Low + Close) / 4) / Close; the factor is the product of KLOW and Vwap_Ratio over a 1-day lookback period.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "original",
      "trajectory_id": "fe7b693fc3e4",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035922585734835,
        "ICIR": 0.0252782902304185,
        "RankIC": 0.0211984131572526,
        "RankICIR": 0.1475194327516285,
        "annualized_return": 0.0693781553981605,
        "information_ratio": 0.9834192414481906,
        "max_drawdown": -0.1143625741238504
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:40:44.782036",
      "updated_at": "2026-01-17T01:40:44.782044"
    },
    "9490425d06133280": {
      "factor_id": "9490425d06133280",
      "factor_name": "Linear_Trend_Volume_Divergence_10D",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8)) * (-1 * TS_CORR($return, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend exhaustion by multiplying the linearity of the price trend (RSQR) with the negative correlation between returns and volume. High linearity combined with volume-price divergence suggests the trend is losing structural support.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.339434",
      "updated_at": "2026-01-17T01:43:23.339444"
    },
    "7bcced8c81d75b33": {
      "factor_id": "7bcced8c81d75b33",
      "factor_name": "Trend_Exhaustion_Signal_20D",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(20), 20), 2) * TS_VAR(SEQUENCE(20), 20) / (TS_VAR($close, 20) + 1e-8)) * SIGN(-1 * TS_CORR($return, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * SIGN(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the trend exhaustion hypothesis using a 20-day window. It captures the interaction between price trend stability and the decoupling of volume, where a negative correlation between volume and price changes indicates a lack of conviction in the prevailing trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.367826",
      "updated_at": "2026-01-17T01:43:23.367834"
    },
    "ee1e2d324e285027": {
      "factor_id": "ee1e2d324e285027",
      "factor_name": "Cross_Sectional_Divergence_Rank_15D",
      "factor_expression": "RANK(POW(REGBETA($close, SEQUENCE(15), 15), 2) * TS_VAR(SEQUENCE(15), 15) / (TS_VAR($close, 15) + 1e-8)) * RANK(-1 * TS_CORR($return, $volume, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(15), 15), 2)) * RANK(-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Divergence_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks the intensity of price-volume divergence relative to the market, weighted by the linearity of the 15-day price trend. It highlights stocks where the trend is most likely to reverse due to a significant drop in volume support during price moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a high 10-day price trend linearity (RSQR10) and a negative correlation between price changes and volume (volume-price divergence) identifies trend exhaustion and potential reversal points.\n                Concise Observation: Strong linear trends often mask underlying liquidity exhaustion which can be detected by observing the divergence between price movement and trading volume intensity.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but if volume fails to support price increases (or decreases), it suggests a lack of conviction among market participants, signaling an imminent breakdown of the current trajectory.\n                Concise Knowledge: If a price trend exhibits high linearity (high RSQR) while volume begins to decouple from price direction (negative correlation), the trend is likely losing structural support and approaching a reversal; when these conditions coincide, the predictive power for mean reversion increases.\n                concise Specification: Define RSQR10 as the coefficient of determination from a 10-day linear regression of price; define Divergence as the 10-day correlation between daily returns and daily volume; the factor is the product of RSQR10 and the negative component of the volume-price correlation.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "original",
      "trajectory_id": "d035d118fac3",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069631684757218,
        "ICIR": 0.0508387665311522,
        "RankIC": 0.0243179360546764,
        "RankICIR": 0.177918731300666,
        "annualized_return": 0.0729069736932787,
        "information_ratio": 1.1044609644706769,
        "max_drawdown": -0.0883567444120492
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:43:23.396155",
      "updated_at": "2026-01-17T01:43:23.396163"
    },
    "b63263adb82f671c": {
      "factor_id": "b63263adb82f671c",
      "factor_name": "VWAP_Volume_Corr_20D",
      "factor_expression": "TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(($open + $high + $low + $close) / 4, $volume, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Volume_Corr_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the 20-day Pearson correlation between the daily Volume-Weighted Average Price (approximated by the average of OHLC) and daily trading volume. High positive correlation suggests institutional accumulation during high-liquidity periods.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.506484",
      "updated_at": "2026-01-17T01:45:05.506490"
    },
    "6ad5cfcd459fa7af": {
      "factor_id": "6ad5cfcd459fa7af",
      "factor_name": "Ranked_VWAP_Volume_Conviction_10D",
      "factor_expression": "RANK(TS_CORR(($open + $high + $low + $close) / 4, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(($open + $high + $low + $close) / 4, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_VWAP_Volume_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of the correlation between the daily average price (VWAP proxy) and volume over a 10-day window. Ranking the correlation helps identify stocks with the strongest institutional conviction relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.516600",
      "updated_at": "2026-01-17T01:45:05.516605"
    },
    "3ec21ce3831ff95e": {
      "factor_id": "3ec21ce3831ff95e",
      "factor_name": "VWAP_Volume_Trend_ZScore_20D",
      "factor_expression": "TS_ZSCORE(TS_CORR(($open + $high + $low + $close) / 4, $volume, 20), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(($open + $high + $low + $close) / 4, $volume, 20), 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Volume_Trend_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Standardizes the 20-day VWAP-Volume correlation using a time-series Z-score. This identifies periods where the institutional accumulation signal is significantly stronger or weaker than its own historical average, providing a signal of trend acceleration.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 20-day correlation between daily Volume-Weighted Average Price (VWAP) and daily volume provides a more accurate signal of institutional accumulation or distribution than close-price-based correlations.\n                Concise Observation: Standard price-volume correlations often fail to distinguish between high-conviction institutional moves and low-volume price manipulation occurring at the market close.\n                Concise Justification: VWAP represents the true average cost basis of participants for a given day; a rising correlation between this average cost and volume suggests that larger players are aggressively moving the price during high-liquidity periods.\n                Concise Knowledge: If price and volume are positively correlated using VWAP, it indicates strong institutional conviction; when VWAP is used instead of close price, the noise from end-of-day retail volatility is reduced, revealing truer liquidity trends.\n                concise Specification: Calculate the Pearson correlation over a rolling 20-day window between daily VWAP (defined as the average of open, high, low, and close) and daily volume, using the daily_pv.h5 dataset.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "original",
      "trajectory_id": "3873625a6349",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098494620981199,
        "ICIR": 0.0637880904469664,
        "RankIC": 0.0245725377660968,
        "RankICIR": 0.1597098083399687,
        "annualized_return": 0.0757884543162963,
        "information_ratio": 1.0152694800996445,
        "max_drawdown": -0.1064575058778648
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:45:05.527381",
      "updated_at": "2026-01-17T01:45:05.527388"
    },
    "931b61570e9c62ec": {
      "factor_id": "931b61570e9c62ec",
      "factor_name": "Low_Vol_Regime_Residual_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) * (TS_STD($close, 5) < TS_STD($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) * (TS_STD($close, 5) < TS_STD($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Regime_Residual_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures mean reversion signals by calculating the 5-day price residual against a linear trend, specifically filtering for regimes where short-term volatility (5-day) is lower than long-term volatility (20-day). This identifies stable environments where price deviations are more likely to be temporary inefficiencies.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.658937",
      "updated_at": "2026-01-17T01:46:16.658944"
    },
    "9583a1d6192db0b5": {
      "factor_id": "9583a1d6192db0b5",
      "factor_name": "Ranked_Stable_Mean_Reversion_5D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(5), 5)) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stable_Mean_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the short-term residual factor, conditioned on a low-volatility ratio. It uses the ratio of 5-day to 20-day volatility as a weight for the 5-day price residual, emphasizing mean reversion in stocks with the most 'quiet' price action relative to their historical norm.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.669801",
      "updated_at": "2026-01-17T01:46:16.669808"
    },
    "9e4d99df124567c1": {
      "factor_id": "9e4d99df124567c1",
      "factor_name": "Conditional_Residual_ZScore_5D",
      "factor_expression": "(TS_STD($close, 5) < TS_STD($close, 20)) ? TS_ZSCORE(REGRESI($close, SEQUENCE(5), 5), 10) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($close, 5) < TS_STD($close, 20)) ? TS_ZSCORE(REGRESI($close, SEQUENCE(5), 5), 10) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Residual_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the 5-day price residual into a Z-score and applies a hard filter. If the short-term volatility is higher than the long-term volatility, the factor returns zero to avoid 'falling knife' scenarios; otherwise, it returns the standardized residual to signal mean reversion strength.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of short-term price residuals (RESI5) for mean reversion is enhanced when the short-term volatility (STD5) is lower than the long-term volatility (STD20), indicating a stable environment for price correction.\n                Concise Observation: Standard mean reversion factors like 5-day residuals often suffer from 'falling knife' scenarios where high volatility drives price further away from the mean rather than back to it.\n                Concise Justification: By filtering for regimes where STD5 < STD20, we isolate periods of 'quiet' price deviations, increasing the probability that the residual represents a temporary inefficiency rather than a fundamental structural shift.\n                Concise Knowledge: If short-term volatility is lower than long-term volatility, the market is likely in a consolidation phase where mean-reverting signals are more reliable; conversely, high relative short-term volatility often indicates a breakout or trend initiation where mean reversion fails.\n                concise Specification: Calculate RESI5 as the residual of close prices against a 5-day linear trend; define the regime filter as a binary multiplier (STD5 < STD20); the final factor is RESI5 * (STD(close, 5) < STD(close, 20)).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "original",
      "trajectory_id": "9051f33ce5a1",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0040436114744968,
        "ICIR": 0.0300203946551501,
        "RankIC": 0.0189076731285943,
        "RankICIR": 0.145046260675874,
        "annualized_return": 0.0496462918758759,
        "information_ratio": 0.8216479586372655,
        "max_drawdown": -0.0770616144866177
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:46:16.680020",
      "updated_at": "2026-01-17T01:46:16.680026"
    },
    "517c0b2db1b4818e": {
      "factor_id": "517c0b2db1b4818e",
      "factor_name": "MSLVR_ROC_Interaction_60D",
      "factor_expression": "(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * ($close / (DELAY($close, 60) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * ($close / (DELAY($close, 60) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"MSLVR_ROC_Interaction_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the Multi-Scale Liquidity Volatility Ratio (MSLVR) to modulate the 60-day Rate of Change (ROC). It captures the hypothesis that medium-term momentum reliability decreases when short-term volume volatility (5-day) significantly deviates from long-term volume volatility (60-day).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.350423",
      "updated_at": "2026-01-17T01:49:23.350431"
    },
    "cc8f4864f664a886": {
      "factor_id": "cc8f4864f664a886",
      "factor_name": "Ranked_MSLVR_Momentum_Signal",
      "factor_expression": "RANK(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * RANK(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8)) * RANK(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Ranked_MSLVR_Momentum_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the MSLVR-modulated momentum. By ranking the ratio and the price change separately before multiplication, the factor becomes more robust to outliers in volume spikes and price gaps while maintaining the regime-switching logic.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.361079",
      "updated_at": "2026-01-17T01:49:23.361085"
    },
    "2b13a01bedaeed68": {
      "factor_id": "2b13a01bedaeed68",
      "factor_name": "ZScore_MSLVR_Inversion_Factor",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 5) / (TS_STD($volume, 60) + 1e-8), 20) * TS_PCTCHANGE($close, 60)",
      "factor_implementation_code": "",
      "factor_description": "This factor uses the Z-score of the volume volatility ratio to identify extreme liquidity shifts. It assumes that when the 5-day volume volatility is extremely high relative to its 60-day history, the 60-day momentum is likely to mean-revert or stall.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Scale Liquidity Volatility Ratio (MSLVR), defined as the 5-day standard deviation of volume divided by the 60-day standard deviation of volume, acts as a regime-switching indicator that negatively modulates the predictive power of the 60-day Rate of Change (ROC60).\n                Concise Observation: Market participants often observe that price momentum (ROC60) loses its predictive reliability when volume patterns become erratic, suggesting that volume dispersion is a leading indicator of liquidity instability.\n                Concise Justification: A high VSTD5/VSTD60 ratio suggests that current trading activity is deviating from historical norms, implying that the existing price trend (ROC60) is likely driven by noise or temporary liquidity shocks rather than sustainable information.\n                Concise Knowledge: If short-term volume volatility significantly exceeds long-term volume volatility, it indicates a liquidity regime shift; such shifts often precede the exhaustion of medium-term price trends and signal a breakdown in mean-reversion or trend-following persistence.\n                concise Specification: The factor is calculated as (std($volume, 5) / std($volume, 60)) * ($close / delay($close, 60) - 1); we expect this interaction term to capture the breakdown of the 60-day price momentum during periods of high relative volume volatility.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "original",
      "trajectory_id": "6a3f5a90d8ab",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049972485139568,
        "ICIR": 0.0371563009885432,
        "RankIC": 0.0224164808428189,
        "RankICIR": 0.1712601627455818,
        "annualized_return": 0.0588182785197663,
        "information_ratio": 0.965930144536669,
        "max_drawdown": -0.1048877298104809
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:23.371604",
      "updated_at": "2026-01-17T01:49:23.371611"
    },
    "8dfd2563d1c47f9f": {
      "factor_id": "8dfd2563d1c47f9f",
      "factor_name": "Asymmetric_Shadow_Volatility_Regime_5D",
      "factor_expression": "(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / ($high - $low + 1e-6) * (RANK(TS_STD($close, 5)) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Shadow_Volatility_Regime_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by calculating the ratio of the lower shadow length to the total daily range, specifically during periods of high 5-day price volatility. A high ratio in a high-volatility environment suggests exhaustive selling pressure and intraday price rejection.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.387299",
      "updated_at": "2026-01-17T01:49:29.387306"
    },
    "f55b990d4989ce20": {
      "factor_id": "f55b990d4989ce20",
      "factor_name": "Normalized_Lower_Shadow_Reversal_10D",
      "factor_expression": "ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ZSCORE(TS_STD($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-6)) * ZSCORE(TS_STD($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Lower_Shadow_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the asymmetric shadow ratio that uses the 10-day rolling median of the shadow ratio to identify extreme intraday rejections relative to recent history, weighted by the cross-sectional rank of historical volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.397872",
      "updated_at": "2026-01-17T01:49:29.397878"
    },
    "5024667fb96dc362": {
      "factor_id": "5024667fb96dc362",
      "factor_name": "Shadow_Exhaustion_Intensity_5D",
      "factor_expression": "(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / (ABS($close - $open) + 1e-6) * (TS_RANK(TS_STD($close, 5), 20) > 0.8 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Shadow_Exhaustion_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of the lower shadow relative to the candle body, conditioned on the stock being in a high-volatility state. It focuses on the 'Hammer' strength by comparing the lower shadow to the absolute price movement between open and close.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Asymmetric Shadow Ratio, defined as the ratio of the lower shadow length to the total candle range, positively predicts next-day returns when the 5-day price volatility is in the top quintile, signaling exhaustive selling pressure.\n                Concise Observation: Market participants often overreact during high-volatility regimes, leading to intraday price dips that are quickly bought up, creating a long lower shadow (KLOW) that serves as a technical reversal signal.\n                Concise Justification: The lower shadow represents the distance between the period low and the minimum of open/close; a high ratio of this shadow to the high-low range suggests that bears lost control by the end of the session, a signal amplified by high STD5 environments.\n                Concise Knowledge: If a stock exhibits a large lower shadow relative to its total daily range during high volatility periods, it indicates a strong intraday price rejection; when this 'hammer' pattern occurs, the probability of a mean-reversion increase due to liquidity exhaustion.\n                concise Specification: Factor = (min($open, $close) - $low) / ($high - $low + 1e-6), conditioned on the 5-day rolling standard deviation of $close being in the top 20% of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "original",
      "trajectory_id": "6b9817de3c64",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051567185778332,
        "ICIR": 0.0402416521391362,
        "RankIC": 0.0196426100001063,
        "RankICIR": 0.1559705445628005,
        "annualized_return": 0.0293933114153078,
        "information_ratio": 0.440711458372042,
        "max_drawdown": -0.1395935566361199
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:49:29.408278",
      "updated_at": "2026-01-17T01:49:29.408284"
    },
    "02c7c583868e4030": {
      "factor_id": "02c7c583868e4030",
      "factor_name": "Price_Volume_Trend_Divergence_10D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Trend_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price momentum and volume-weighted momentum over a 10-day period. It calculates the difference between the cross-sectional rank of the 10-day price change and the cross-sectional rank of the 10-day RSI (Relative Strength Index). A high divergence suggests the price trend is exhausted and likely to undergo mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.133648",
      "updated_at": "2026-01-17T01:52:41.133655"
    },
    "0d21fba9d1db2f28": {
      "factor_id": "0d21fba9d1db2f28",
      "factor_name": "VW_Momentum_Exhaustion_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE(TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE(TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price-volume exhaustion by comparing the 10-day price return rank against the rank of the 10-day volume-weighted average price (VWAP) momentum. It uses the residual of price changes not explained by volume trends to signal potential reversals.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.144355",
      "updated_at": "2026-01-17T01:52:41.144361"
    },
    "d227acabb1805dc1": {
      "factor_id": "d227acabb1805dc1",
      "factor_name": "Relative_Strength_Divergence_ZScore",
      "factor_expression": "ZSCORE(RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK(TS_PCTCHANGE($close, 10)) - RANK(RSI($close, 10)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the standardized divergence between price returns and the Relative Strength Index (RSI). By taking the Z-score of the difference between price return ranks and RSI ranks over 10 days, it highlights extreme cases where price action is decoupled from technical strength, indicating high reversal probability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price-volume trend divergence, calculated as the difference between the 10-day price change percentile and the 10-day volume-weighted momentum percentile, predicts short-term mean reversion in stock returns.\n                Concise Observation: Market participants often observe that new price highs accompanied by declining technical strength indicators (like RESI) frequently precede a trend breakdown.\n                Concise Justification: Divergence between price action and momentum signals a lack of conviction from institutional buyers, suggesting that the current price level is unsustainable and likely to revert.\n                Concise Knowledge: If a stock's price trend is not supported by a corresponding strength in volume-weighted momentum, then the trend is likely exhausted and prone to reversal.\n                concise Specification: The factor is defined as the 10-day change in 'close' minus the 10-day change in 'factor' (RESI), both normalized cross-sectionally to ensure comparability across different instruments.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "original",
      "trajectory_id": "6886de421d28",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068969038155469,
        "ICIR": 0.0508409090534763,
        "RankIC": 0.0239128373388356,
        "RankICIR": 0.1827418040169358,
        "annualized_return": 0.0756910137973694,
        "information_ratio": 1.2351880301739793,
        "max_drawdown": -0.0800861103250965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:52:41.154827",
      "updated_at": "2026-01-17T01:52:41.154832"
    },
    "f0ba63507298d9b8": {
      "factor_id": "f0ba63507298d9b8",
      "factor_name": "PV_Conviction_Momentum_20_5",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"PV_Conviction_Momentum_20_5\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction momentum by calculating the product of the 20-day price-volume correlation and the 5-day volume volatility. A positive correlation combined with high volume dispersion suggests that the price trend is supported by intense information arrival and strong market consensus.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.974850",
      "updated_at": "2026-01-17T01:54:48.974856"
    },
    "cd7ac8d6736c5188": {
      "factor_id": "cd7ac8d6736c5188",
      "factor_name": "Normalized_PV_Synchrony_Intensity",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_STD($volume, 5) / (TS_MEAN(TS_STD($volume, 5), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_PV_Synchrony_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume synchrony hypothesis that normalizes volume volatility by its 20-day average to capture relative intensity. It scales the 20-day price-volume correlation by the ratio of short-term volume volatility to long-term volume volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.985842",
      "updated_at": "2026-01-17T01:54:48.985848"
    },
    "55fd720195d71924": {
      "factor_id": "55fd720195d71924",
      "factor_name": "ZScored_PV_Momentum_Signal",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"ZScored_PV_Momentum_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a cross-sectional Z-score to the price-volume correlation and volume volatility components independently before multiplication. This ensures that both the direction (correlation) and the intensity (volatility) contribute equally to the final high-conviction momentum signal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day price-volume correlation (CORR20) and 5-day volume volatility (VSTD5) identifies high-conviction momentum; specifically, the product of CORR20 and VSTD5 positively predicts future returns by capturing synchronized market participation during periods of intense information flow.\n                Concise Observation: Price-volume synchrony (CORR) often signals trend strength, but its predictive power is inconsistent unless conditioned on the intensity of trading activity, which can be measured by the standard deviation of volume.\n                Concise Justification: High volume volatility indicates a surge in information arrival; when this surge coincides with a strong positive correlation between price and volume, it suggests that the price move is supported by increasing conviction, reducing the likelihood of a mean-reversion event.\n                Concise Knowledge: If price and volume are positively correlated during periods of high volume dispersion, the prevailing price trend is more likely to persist because it reflects a broad consensus among informed traders rather than noise.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation between daily close price and daily volume, and the 5-day standard deviation of daily volume, applied cross-sectionally to identify trend continuation.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "original",
      "trajectory_id": "e61d4a67d477",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078699420500738,
        "ICIR": 0.0517398048082506,
        "RankIC": 0.0253544088301323,
        "RankICIR": 0.1665086703433936,
        "annualized_return": 0.0250113704557489,
        "information_ratio": 0.3304105987829027,
        "max_drawdown": -0.1394595673227112
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:54:48.997555",
      "updated_at": "2026-01-17T01:54:48.997561"
    },
    "74b6a7c467babff2": {
      "factor_id": "74b6a7c467babff2",
      "factor_name": "Gap_Support_Ratio_10D",
      "factor_expression": "($open - DELAY($close, 1)) / (ABS($low - $open) + 0.001 * TS_STD($close, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) / ((ABS($low - MIN($open, $close)) + 1e-8) / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Support_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the overnight gap to the lower shadow length, normalized by the 10-day price volatility. It aims to identify if an overnight shock is supported by intraday price action. A high ratio with a small lower shadow suggests strong conviction, while a large lower shadow suggests a lack of support.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.386343",
      "updated_at": "2026-01-17T01:55:36.386351"
    },
    "cc4e28bbaa236de6": {
      "factor_id": "cc4e28bbaa236de6",
      "factor_name": "Normalized_Overnight_Intraday_Support_Z",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Overnight_Intraday_Support_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the intraday lower shadow, cross-sectionally normalized. It captures the 'shock magnitude' vs 'support distance' hypothesis by comparing the jump from previous close to the subsequent intraday floor.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.397370",
      "updated_at": "2026-01-17T01:55:36.397376"
    },
    "8080ce5352833969": {
      "factor_id": "8080ce5352833969",
      "factor_name": "Smoothed_Gap_To_Shadow_Efficiency",
      "factor_expression": "TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open - DELAY($close, 1)) / (ABS($low - $open) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Gap_To_Shadow_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A smoothed version of the gap-to-lower-shadow ratio using a 5-day moving average. It filters out daily noise to identify stocks where overnight gaps consistently show high intraday support (minimal lower shadows).",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the overnight gap (open minus previous close) to the lower shadow length (low minus open) of the current day, when normalized by daily volatility, inversely predicts short-term returns as it distinguishes between failed opening shocks and strong intraday support.\n                Concise Observation: Opening prices often reflect overnight information shocks, but the intraday 'low' relative to the 'open' reveals whether market participants validated that price level or sought lower liquidity before stabilizing.\n                Concise Justification: A small lower shadow following a gap indicates that the open was near the day's floor, signaling high conviction, whereas a deep lower shadow suggests the gap was an overreaction that required further price discovery.\n                Concise Knowledge: If a large overnight gap is followed by a minimal lower shadow relative to the gap size, it indicates strong immediate absorption of the shock; when the lower shadow is large, it suggests the opening price lacked support, leading to potential mean reversion.\n                concise Specification: Factor = (Open_t - Close_{t-1}) / (Low_t - Open_t + epsilon), calculated daily per instrument, where the denominator represents the 'support distance' and the numerator represents the 'shock magnitude'.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "original",
      "trajectory_id": "7b0163132bde",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005450025029522,
        "ICIR": 0.04169091706771,
        "RankIC": 0.0214886439483393,
        "RankICIR": 0.1682726627370678,
        "annualized_return": 0.0902823117523132,
        "information_ratio": 1.3899388638244816,
        "max_drawdown": -0.0846422320977847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:55:36.408199",
      "updated_at": "2026-01-17T01:55:36.408206"
    },
    "e67d674b23a7a53e": {
      "factor_id": "e67d674b23a7a53e",
      "factor_name": "Exp_Decay_Momentum_60D",
      "factor_expression": "EMA($return, 19)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(TS_PCTCHANGE($close, 1), 60)\" # Your output factor expression will be filled in here\n    name = \"Exp_Decay_Momentum_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A 60-day price momentum factor weighted by an exponential decay function. It uses the EMA function to approximate the weighted sum of returns, where more recent returns have a higher impact on the factor value, effectively capturing trend acceleration while filtering out older noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.677890",
      "updated_at": "2026-01-17T01:58:21.677903"
    },
    "8336f343c9f54590": {
      "factor_id": "8336f343c9f54590",
      "factor_name": "ZScore_Decay_Momentum_60D",
      "factor_expression": "ZSCORE(EMA($return, 19))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(EMA(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Decay_Momentum_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the exponentially weighted 60-day momentum by its cross-sectional volatility. By applying ZSCORE to the EMA of returns, it identifies stocks with the strongest recent momentum relative to the market, adjusted for the decay of older price information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.689291",
      "updated_at": "2026-01-17T01:58:21.689297"
    },
    "30f6c97b79f08892": {
      "factor_id": "30f6c97b79f08892",
      "factor_name": "Decay_Momentum_Volatility_Ratio",
      "factor_expression": "EMA($return, 19) / (TS_STD($return, 60) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(TS_PCTCHANGE($close, 1), 19) / (TS_STD(TS_PCTCHANGE($close, 1), 60) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Decay_Momentum_Volatility_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of exponentially decayed momentum to the 60-day price volatility. It aims to capture risk-adjusted recent momentum, ensuring that the trend acceleration is not merely a result of high idiosyncratic volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 60-day price momentum factor weighted by an exponential decay function (alpha=0.1) provides superior risk-adjusted returns compared to a simple 60-day Rate of Change by emphasizing recent trend acceleration while filtering long-term noise.\n                Concise Observation: Standard 60-day ROC treats price changes from two months ago with the same importance as yesterday's, often leading to delayed signals during trend reversals or momentum exhaustion phases.\n                Concise Justification: Market participants exhibit recency bias and react more strongly to recent price developments, so an exponentially decayed ROC better aligns with the psychological drivers of trend-following behavior and information diffusion.\n                Concise Knowledge: If a long-term momentum signal is weighted exponentially, it captures the persistence of trends while reducing the lag inherent in simple moving windows; when alpha is small, the factor remains stable but becomes more responsive to recent structural shifts in price action.\n                concise Specification: The factor is calculated as the sum of daily log returns over a 60-day window, each multiplied by exp(-alpha * t) where t is the lag in days (0 to 59) and alpha is set to 0.1, normalized cross-sectionally.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "original",
      "trajectory_id": "dc24d789f4d5",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005793040900404,
        "ICIR": 0.037529579859623,
        "RankIC": 0.0238983992975709,
        "RankICIR": 0.1582128591128187,
        "annualized_return": 0.0281640460025536,
        "information_ratio": 0.3463071955323318,
        "max_drawdown": -0.1468070975416018
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T01:58:21.700299",
      "updated_at": "2026-01-17T01:58:21.700304"
    },
    "8a4591d5ab6206a4": {
      "factor_id": "8a4591d5ab6206a4",
      "factor_name": "Cross_Sectional_Residual_Momentum_5D",
      "factor_expression": "RANK(TS_SUM($return - MEAN($return), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Residual_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day accumulated idiosyncratic return by subtracting the cross-sectional mean return (market proxy) from individual stock returns. The resulting residual is ranked cross-sectionally to identify stocks with significant firm-specific price dislocations.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.663430",
      "updated_at": "2026-01-17T02:01:26.663437"
    },
    "2974bff508b08b79": {
      "factor_id": "2974bff508b08b79",
      "factor_name": "ZScored_Idiosyncratic_Shock_5D",
      "factor_expression": "RANK(TS_SUM(ZSCORE($return), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM(ZSCORE(TS_PCTCHANGE($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Idiosyncratic_Shock_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the intensity of stock-specific price movements relative to the market by calculating the 5-day sum of cross-sectionally standardized return residuals. It helps identify assets experiencing extreme idiosyncratic shocks that are likely to mean-revert or trend independently.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.674794",
      "updated_at": "2026-01-17T02:01:26.674800"
    },
    "8e606b3d410c86e0": {
      "factor_id": "8e606b3d410c86e0",
      "factor_name": "Residual_Volatility_Adjusted_Momentum_5D",
      "factor_expression": "RANK(TS_SUM($return - MEAN($return), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 5) / TS_STD(TS_PCTCHANGE($close, 1) - MEAN(TS_PCTCHANGE($close, 1)), 20))\" # Your output factor expression will be filled in here\n    name = \"Residual_Volatility_Adjusted_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the idiosyncratic signal by dividing the 5-day sum of market-neutral residuals by their time-series standard deviation. This normalization ensures that the signal is not dominated by high-volatility stocks, focusing on consistent firm-specific trends.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day price residual, calculated as the difference between individual stock returns and the cross-sectional average return, provides a cleaner signal of idiosyncratic price dislocation when ranked relative to all instruments on a daily basis.\n                Concise Observation: Daily price movements are heavily influenced by broad market trends (beta), which often masks stock-specific information and leads to high correlation among raw momentum factors.\n                Concise Justification: Removing the cross-sectional mean return (a proxy for the market factor) reduces systematic noise, allowing the model to focus on alpha generated by firm-specific events or liquidity-driven imbalances.\n                Concise Knowledge: If the systematic market return is subtracted from individual asset returns, the resulting residual isolates idiosyncratic shocks; when these residuals are ranked cross-sectionally, they identify assets with extreme relative price dislocations that are likely to mean-revert or trend independently of the market.\n                concise Specification: Calculate the 1-day return for all stocks, subtract the daily cross-sectional mean return to obtain the daily residual, sum these residuals over a rolling 5-day window, and output the final cross-sectional rank of this 5-day sum.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "original",
      "trajectory_id": "98bc149cd171",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049577828348935,
        "ICIR": 0.0286357556047108,
        "RankIC": 0.0210813882627131,
        "RankICIR": 0.1203891816430076,
        "annualized_return": 0.0511544948262824,
        "information_ratio": 0.5241368446673793,
        "max_drawdown": -0.2082677417523487
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:01:26.685880",
      "updated_at": "2026-01-17T02:01:26.685886"
    },
    "798c3c97bde13834": {
      "factor_id": "798c3c97bde13834",
      "factor_name": "ROC60_PV_CORR20_Rank_Product",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ROC60_PV_CORR20_Rank_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies assets with both strong long-term momentum and high price-volume synchronization. It calculates the 60-day rate of change and the 20-day correlation between price and volume, then combines their cross-sectional ranks to isolate high-conviction recovery trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.970694",
      "updated_at": "2026-01-17T02:03:45.970701"
    },
    "347805446ee512ab": {
      "factor_id": "347805446ee512ab",
      "factor_name": "Clean_Momentum_Recovery_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($return, DELTA($volume, 1), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Clean_Momentum_Recovery_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the price-volume interaction hypothesis that focuses on the stability of returns relative to volume. It uses the 60-day price change and the 20-day correlation between daily returns and volume changes to filter for assets where price appreciation is consistently supported by volume flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.982125",
      "updated_at": "2026-01-17T02:03:45.982131"
    },
    "b398c32f51f40314": {
      "factor_id": "b398c32f51f40314",
      "factor_name": "ZScore_Momentum_Volume_Stability",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 60)) + ZSCORE(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 60)) + ZSCORE(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Volume_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses cross-sectional Z-scores to combine long-term momentum (60 days) and short-term price-volume correlation (20 days). By summing the Z-scores, it identifies assets that are outliers in both momentum and trend 'cleanliness' simultaneously.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction of long-term price momentum (ROC60) and short-term price-volume stability (CORR20) identifies high-quality recovery assets where the product of their cross-sectional ranks predicts positive future excess returns.\n                Concise Observation: Market participants often overlook assets that have steady, high-correlation price trends (CORR20) in favor of volatile breakouts, yet long-term performance (ROC60) is more sustainable when price movements are highly synchronized with volume flow.\n                Concise Justification: Ranking assets cross-sectionally by ROC60 captures the momentum effect, while ranking by the 20-day correlation between price and volume identifies 'clean' trends; the product of these ranks isolates assets in the top quintiles of both, representing high-conviction institutional accumulation.\n                Concise Knowledge: If an asset exhibits high long-term momentum alongside high price-volume correlation, it indicates a trend supported by consistent liquidity; when these two independent signals are combined via cross-sectional ranking, the resulting intersection filters for 'quiet' trend leaders with lower idiosyncratic noise.\n                concise Specification: Calculate the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20). Transform both into cross-sectional ranks (0 to 1) and define the factor as the product of these ranks to isolate the intersection of the top performers.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "original",
      "trajectory_id": "762b43dcf35d",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050146809326812,
        "ICIR": 0.0309449055988842,
        "RankIC": 0.0224851983656813,
        "RankICIR": 0.1379885035062405,
        "annualized_return": 0.0696689426302724,
        "information_ratio": 0.8453752037223925,
        "max_drawdown": -0.1054711599331423
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:03:45.993489",
      "updated_at": "2026-01-17T02:03:45.993494"
    },
    "58eded43038c1180": {
      "factor_id": "58eded43038c1180",
      "factor_name": "Coiled_Spring_Compression_5D",
      "factor_expression": "RANK(($low - $open) / ($high - $low + 1e-8) * (1 / (TS_MEAN($high - $low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($low - $open) / ($high - $low + 1e-8) * (1 / (TS_MEAN($high - $low, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Coiled_Spring_Compression_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'coiled' price action by measuring the relative position of the daily low within the price range, weighted by the inverse of the 5-day average range. A high value indicates that the low is near the open/close (support) while volatility is shrinking, suggesting potential energy accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.707923",
      "updated_at": "2026-01-17T02:04:05.707930"
    },
    "e0cbcb061fcab14f": {
      "factor_id": "e0cbcb061fcab14f",
      "factor_name": "Volatility_Adjusted_Low_Support_10D",
      "factor_expression": "ZSCORE(($low - $open) / ($close * TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($low - $open) / ($close * TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Low_Support_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price compression by dividing the intraday support level (distance of low from open) by the 10-day historical volatility. It targets stocks where downside movement is restricted relative to historical price swings, normalized by the close price for cross-sectional stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.719599",
      "updated_at": "2026-01-17T02:04:05.719604"
    },
    "e8b47be6a786d40e": {
      "factor_id": "e8b47be6a786d40e",
      "factor_name": "Price_Range_Quantile_Support",
      "factor_expression": "RANK($low - $open) * (1 - TS_RANK($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($low - $open) * (1 - TS_RANK($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Range_Quantile_Support\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the coiled spring hypothesis that uses the 20-day range quantile to identify periods of low volatility (compression) and combines it with the intraday low's position relative to the open price.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the relative position of the low price within the daily range and the 5-day average true range (ATR) identifies 'coiled' price action, where a high relative low in a low-volatility environment predicts positive mean-reversion or breakout returns.\n                Concise Observation: Market volatility tends to cluster, and periods of extremely low range (compression) often precede significant price expansions, especially when the low price is supported near the open/close levels.\n                Concise Justification: A high 'low-to-range' ratio during a period of low volatility suggests that selling pressure is being absorbed immediately, creating a 'coiled spring' effect that leads to higher risk-adjusted returns when the trend resumes.\n                Concise Knowledge: If a stock's low price consistently stays near the top of its daily range while the overall price range (High-Low) is shrinking, it indicates strong intraday support and potential energy accumulation for an upward move.\n                concise Specification: The factor is defined as the product of (Low - Open)/(High - Low) and the inverse of the 5-day moving average of (High - Low), normalized by the close price to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "original",
      "trajectory_id": "c9a3ffee7b88",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0025143315351953,
        "ICIR": 0.0199202837497509,
        "RankIC": 0.0157654734063649,
        "RankICIR": 0.126949536999202,
        "annualized_return": 0.0407475462470534,
        "information_ratio": 0.690673980178766,
        "max_drawdown": -0.0936239709993078
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:04:05.730918",
      "updated_at": "2026-01-17T02:04:05.730924"
    },
    "f7a2decd56930628": {
      "factor_id": "f7a2decd56930628",
      "factor_name": "Neutralized_Volume_Stability_5D",
      "factor_expression": "TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($volume, 5) - MEDIAN(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Neutralized_Volume_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day rolling standard deviation of volume to measure liquidity volatility, then subtracts the cross-sectional median to isolate idiosyncratic liquidity stability from market-wide noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.533818",
      "updated_at": "2026-01-17T02:06:12.533825"
    },
    "8345b03447c1e9c8": {
      "factor_id": "8345b03447c1e9c8",
      "factor_name": "Ranked_Idiosyncratic_Volume_Volatility_5D",
      "factor_expression": "RANK(TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Idiosyncratic_Volume_Volatility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of volume stability that first normalizes volume by its 20-day mean to handle scale differences, then calculates the 5-day volatility and applies cross-sectional ranking to identify stocks with extreme idiosyncratic liquidity shifts.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.545813",
      "updated_at": "2026-01-17T02:06:12.545819"
    },
    "008c300685deb3c0": {
      "factor_id": "008c300685deb3c0",
      "factor_name": "Relative_Liquidity_Stability_ZScore",
      "factor_expression": "ZSCORE(TS_STD($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Relative_Liquidity_Stability_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of a stock's 5-day volume volatility from the cross-sectional average, normalized by the cross-sectional standard deviation (Z-score), to identify significant liquidity exhaustion or accumulation phases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rolling standard deviation of daily volume, when normalized by subtracting the cross-sectional median of all instruments, identifies idiosyncratic liquidity stability that predicts future price reversals or trend persistence.\n                Concise Observation: Raw volume volatility (VSTD) is often dominated by market-wide liquidity shocks or sector-specific news, which masks the unique capital flow signals of individual assets.\n                Concise Justification: Neutralizing volume stability against the cross-sectional median removes common noise, isolating the specific liquidity risk premium or information asymmetry associated with a single instrument.\n                Concise Knowledge: If a stock's volume volatility significantly deviates from the market-wide median, it indicates idiosyncratic trading interest; lower relative volatility suggests stable institutional accumulation, while higher relative volatility often precedes exhaustion.\n                concise Specification: Calculate the 5-day rolling standard deviation of $volume, then subtract the daily cross-sectional median of this value across all instruments to produce the 'Sector-Neutralized Volume Stability' factor.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "original",
      "trajectory_id": "a631c2d31c74",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038106725437709,
        "ICIR": 0.0275071437486949,
        "RankIC": 0.0197065370518232,
        "RankICIR": 0.1436998232787834,
        "annualized_return": 0.0218039660469908,
        "information_ratio": 0.3232778131198651,
        "max_drawdown": -0.1254927058392582
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:06:12.557741",
      "updated_at": "2026-01-17T02:06:12.557748"
    },
    "7e3f80ee8d36b54f": {
      "factor_id": "7e3f80ee8d36b54f",
      "factor_name": "Trend_Fragility_Index_20D",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies imminent regime shifts by measuring the volatility of trend linearity. It calculates the R-squared of the close price against a time index over a 10-day window to assess trend quality, then computes the 20-day rolling standard deviation of these R-squared values. High values indicate that the trend's stability is fluctuating, signaling a potential transition from stable momentum to chaotic price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.501939",
      "updated_at": "2026-01-17T06:03:35.808848"
    },
    "8a9467859f0082d5": {
      "factor_id": "8a9467859f0082d5",
      "factor_name": "Fragility_Adjusted_Momentum_15D",
      "factor_expression": "TS_PCTCHANGE($close, 10) / (TS_STD(TS_CORR($close, SEQUENCE(10), 10), 15) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) / (TS_STD(TS_CORR($close, SEQUENCE(10), 10), 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Fragility_Adjusted_Momentum_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that scales the 10-day price return by the inverse of the R-squared volatility. It penalizes returns that occur during periods of erratic trend fitting, highlighting more 'stable' and reliable price movements.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, defined as the rolling 20-day standard deviation of the R-squared of a 10-day price linear regression, identifies impending trend reversals or regime shifts by quantifying the instability of trend persistence.\n                Concise Observation: Stable trends exhibit consistently high RSQR values with low variance, whereas maturing or failing trends often show erratic shifts in their linear fit before a significant price correction occurs.\n                Concise Justification: High variance in the goodness-of-fit metric (RSQR) suggests that the market's consensus on a directional move is fracturing, making the current trend 'fragile' and susceptible to noise or reversal.\n                Concise Knowledge: If the explanatory power of a linear trend (RSQR) fluctuates significantly, the prevailing market regime is becoming unstable; when this volatility peaks, the probability of a price reversal or a transition to a chaotic state increases.\n                concise Specification: Calculate the R-squared of $close against a time index over a 10-day sliding window, then compute the standard deviation of these R-squared values over a subsequent 20-day rolling period to output a single fragility score per instrument.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "original",
      "trajectory_id": "a74fc4f80eac",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005018283953464,
        "ICIR": 0.0334861927387632,
        "RankIC": 0.0215933859933432,
        "RankICIR": 0.1469933123286931,
        "annualized_return": 0.0803909023026703,
        "information_ratio": 1.0205138841727537,
        "max_drawdown": -0.095441911859979
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.515364",
      "updated_at": "2026-01-17T02:08:33.515372"
    },
    "c51dd08ee3b5d8e1": {
      "factor_id": "c51dd08ee3b5d8e1",
      "factor_name": "Relative_Trend_Stability_Rank",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) - TS_MEDIAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2) - TS_MEDIAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Trend_Stability_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor compares the current goodness-of-fit (R-squared) of a 10-day trend against its 20-day historical median, normalized by its volatility. It identifies stocks where the trend is becoming significantly more or less stable relative to its own recent history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, defined as the rolling 20-day standard deviation of the R-squared of a 10-day price linear regression, identifies impending trend reversals or regime shifts by quantifying the instability of trend persistence.\n                Concise Observation: Stable trends exhibit consistently high RSQR values with low variance, whereas maturing or failing trends often show erratic shifts in their linear fit before a significant price correction occurs.\n                Concise Justification: High variance in the goodness-of-fit metric (RSQR) suggests that the market's consensus on a directional move is fracturing, making the current trend 'fragile' and susceptible to noise or reversal.\n                Concise Knowledge: If the explanatory power of a linear trend (RSQR) fluctuates significantly, the prevailing market regime is becoming unstable; when this volatility peaks, the probability of a price reversal or a transition to a chaotic state increases.\n                concise Specification: Calculate the R-squared of $close against a time index over a 10-day sliding window, then compute the standard deviation of these R-squared values over a subsequent 20-day rolling period to output a single fragility score per instrument.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "original",
      "trajectory_id": "a74fc4f80eac",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005018283953464,
        "ICIR": 0.0334861927387632,
        "RankIC": 0.0215933859933432,
        "RankICIR": 0.1469933123286931,
        "annualized_return": 0.0803909023026703,
        "information_ratio": 1.0205138841727537,
        "max_drawdown": -0.095441911859979
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:08:33.528412",
      "updated_at": "2026-01-17T02:08:33.528419"
    },
    "837d323fefb53783": {
      "factor_id": "837d323fefb53783",
      "factor_name": "VPBD_Volatility_Adjusted_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / (TS_MEAN($close, 5) * (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VPBD_Volatility_Adjusted_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the 5-day VWAP to the 5-day TWAP, normalized by the price volatility. A value greater than 1 suggests volume is concentrated at higher prices relative to the time-average, indicating aggressive institutional accumulation during low-volatility 'stealth' phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.747135",
      "updated_at": "2026-01-17T02:09:58.747143"
    },
    "0a76cc8f99c5c7e6": {
      "factor_id": "0a76cc8f99c5c7e6",
      "factor_name": "Stealth_Accumulation_ZScore_10D",
      "factor_expression": "RANK((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5)) * (1 - RANK(TS_STD($return, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5)) * (1 - RANK(TS_STD(TS_PCTCHANGE($close, 1), 10))))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of the VWAP-TWAP divergence during periods of compressed volatility. It identifies assets where buyers are paying a premium (VWAP > TWAP) while price action remains quiet, a hallmark of institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.759289",
      "updated_at": "2026-01-17T02:09:58.759295"
    },
    "a886230cf326bdc7": {
      "factor_id": "a886230cf326bdc7",
      "factor_name": "VWAP_TWAP_Convexity_5D",
      "factor_expression": "((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) - TS_MEAN($close, 5)) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) - TS_MEAN($close, 5)) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VWAP_TWAP_Convexity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the intensity of volume-weighted price premiums relative to time-weighted prices, specifically targeting low-volatility regimes. High values indicate that volume is heavily skewed toward the upper end of the 5-day price range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volume-Price Basis Divergence (VPBD), calculated as the ratio of the 5-day VWAP to the 5-day TWAP during periods of low price volatility, identifies stealth institutional accumulation that predicts positive future returns.\n                Concise Observation: The previous mean-reversion strategy focused on price exhaustion in high-volatility regimes, but ignored 'quiet' price-volume interactions where high volume concentration at specific price levels often precedes a sustained trend breakout.\n                Concise Justification: Institutional traders use VWAP-targeted algorithms to minimize market impact; a positive basis between VWAP and TWAP suggests buyers are willing to pay a premium over the day's average time-price to fulfill large orders, signaling conviction.\n                Concise Knowledge: If the volume-weighted average price (VWAP) consistently stays above the time-weighted average price (TWAP) while volatility remains low, it indicates aggressive institutional buying that absorbs liquidity without triggering immediate price spikes.\n                concise Specification: The factor is defined as (VWAP_5D / TWAP_5D) / (STD_5D + epsilon), where VWAP is approximated by (Sum(Close * Volume) / Sum(Volume)) and TWAP by Mean(Close) over a 5-day window, targeting assets with high volume-price convexity.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "db811308b0a5",
      "parent_trajectory_ids": [
        "534d813fed12"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057817998132797,
        "ICIR": 0.0425257710632936,
        "RankIC": 0.0231394817830213,
        "RankICIR": 0.1749871086897747,
        "annualized_return": 0.0428988489416409,
        "information_ratio": 0.5977366086287118,
        "max_drawdown": -0.1787039916993693
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:09:58.771189",
      "updated_at": "2026-01-17T02:09:58.771195"
    },
    "dab6d997ce232f8b": {
      "factor_id": "dab6d997ce232f8b",
      "factor_name": "Gap_Over_Intraday_Volatility_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($open / DELAY($close, 1) - 1), 5) / (TS_MEAN(($high - $low) / ($open + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open / DELAY($close, 1) - 1), 5) / (TS_MEAN(($high - $low) / ($open + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Over_Intraday_Volatility_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the relative intensity of the overnight gap volatility compared to intraday volatility. According to the hypothesis, high overnight gaps relative to intraday price action suggest liquidity-induced overreactions that are prone to mean-reversion. A higher ratio indicates a potential reversal in the next session.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.445671",
      "updated_at": "2026-01-17T02:11:31.445678"
    },
    "0ab014079f0136ed": {
      "factor_id": "0ab014079f0136ed",
      "factor_name": "ZScore_Gap_Mean_Reversion_3D",
      "factor_expression": "-1 * ZSCORE(TS_MEAN(ABS($open / DELAY($close, 1) - 1), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ZSCORE(TS_MEAN(ABS($open / DELAY($close, 1) - 1), 3))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Gap_Mean_Reversion_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the cross-sectional intensity of the overnight gap normalized by its recent volatility. It targets the hypothesis that extreme overnight shocks (gaps) represent noise and behavioral biases. By applying ZSCORE cross-sectionally, it identifies stocks with the most significant 'jumps' relative to the market, which are expected to revert.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.458990",
      "updated_at": "2026-01-17T02:11:31.458997"
    },
    "580dcd9321a74d53": {
      "factor_id": "580dcd9321a74d53",
      "factor_name": "Gap_Volatility_Dominance_Rank_10D",
      "factor_expression": "RANK(TS_SUM(ABS($open - DELAY($close, 1)), 10) / (TS_SUM(($high - $low) + ABS($open - DELAY($close, 1)), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS($open - DELAY($close, 1)), 10) / (TS_SUM(($high - $low) + ABS($open - DELAY($close, 1)), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Volatility_Dominance_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor ranks stocks based on the dominance of overnight gap volatility over total daily volatility (gap + intraday). It follows the logic that when volatility is primarily driven by overnight shocks rather than continuous intraday price discovery, the price is more likely to exhibit mean-reverting behavior.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Gap Volatility factor, defined as the absolute difference between the current day's open and the previous day's close, exhibits stronger mean-reversion properties and higher predictive power for next-day returns compared to Intraday Volatility.\n                Concise Observation: Price action is often fragmented between market sessions, where the 'gap' represents a reaction to non-trading hour information which frequently overshoots due to lower liquidity at the market open.\n                Concise Justification: Overnight gaps capture the 'jump' component of price movement which is often subject to noise and behavioral biases, leading to a higher probability of corrective flows in the subsequent sessions compared to smooth intraday trends.\n                Concise Knowledge: If price volatility is driven by overnight information shocks (gaps), it is more likely to represent liquidity-induced overreactions that revert; when volatility is driven by intraday trading, it often reflects continuous price discovery with higher persistence.\n                concise Specification: Define Gap_Vol as abs($open / $close[t-1] - 1) and Intraday_Vol as ($high - $low) / $open; compare the information coefficient (IC) of a 1-day lookback of Gap_Vol against a 1-day lookback of Intraday_Vol for predicting next-day returns.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "original",
      "trajectory_id": "9b454a2c6f34",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064940567462971,
        "ICIR": 0.044540972986808,
        "RankIC": 0.0245115771330177,
        "RankICIR": 0.1794871534739823,
        "annualized_return": 0.0914318287414032,
        "information_ratio": 1.309644988679222,
        "max_drawdown": -0.0947243161524364
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:11:31.471278",
      "updated_at": "2026-01-17T02:11:31.471284"
    },
    "b3321ede1dc55647": {
      "factor_id": "b3321ede1dc55647",
      "factor_name": "PV_Corr_ATR_Regime_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 14) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 14) / ($close + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"PV_Corr_ATR_Regime_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures regime-dependent alpha by interacting the 20-day price-volume correlation with the 14-day Average True Range (ATR) normalized by price. High ATR signifies high-volatility regimes where price-volume divergence or convergence signals are more reliable.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.949028",
      "updated_at": "2026-01-17T02:12:37.949035"
    },
    "3a3929d58669dc91": {
      "factor_id": "3a3929d58669dc91",
      "factor_name": "Volatility_Weighted_PV_Divergence",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Weighted_PV_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the regime hypothesis that weights the 20-day price-volume correlation by the 14-day price volatility (standard deviation) normalized by price. It emphasizes price-volume signals during periods of high relative volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.961311",
      "updated_at": "2026-01-17T02:12:37.961317"
    },
    "66f572336e2eb2b4": {
      "factor_id": "66f572336e2eb2b4",
      "factor_name": "Regime_Filtered_PV_Momentum",
      "factor_expression": "TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * ((TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close) / (TS_MEDIAN(TS_MEAN(MAX(MAX($high-$low, ABS($high-DELAY($close,1))), ABS($low-DELAY($close,1))), 14)/$close, 60) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Regime_Filtered_PV_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the 14-day ATR-to-price ratio as a regime filter. It amplifies the 20-day price-volume correlation when the current volatility is higher than its 60-day median, targeting periods of market stress or significant movement.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 14-day Average True Range (ATR) normalized by price identifies regime-dependent alpha, where high-volatility environments amplify the predictive power of price-volume divergence.\n                Concise Observation: Price-volume relationships are non-stationary, and their effectiveness as predictive features often clusters during periods of significant price movement or heightened market stress.\n                Concise Justification: High ATR indicates significant market participation and disagreement on value, making the correlation between price trends and volume flow a more robust indicator of institutional conviction or retail panic.\n                Concise Knowledge: If a market is in a high-volatility regime, then price-volume correlations often signal exhaustion or breakout strength more reliably than in low-volatility consolidation phases; when volatility is low, such signals are more likely to be noise.\n                concise Specification: Calculate the factor as the product of the 20-day Pearson correlation between $close and $volume and the 14-day ATR (normalized by $close) to weight the signal by the current volatility regime.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "original",
      "trajectory_id": "0d759165800b",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0095640448614114,
        "ICIR": 0.0574871197736066,
        "RankIC": 0.0291213556385526,
        "RankICIR": 0.1788684637200001,
        "annualized_return": 0.0662008843278113,
        "information_ratio": 0.8686541649851323,
        "max_drawdown": -0.1293661451709599
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:12:37.973445",
      "updated_at": "2026-01-17T02:12:37.973451"
    },
    "d4d86729fd6774d5": {
      "factor_id": "d4d86729fd6774d5",
      "factor_name": "Price_Convexity_Volume_Exhaustion_3D",
      "factor_expression": "DELTA(TS_PCTCHANGE($close, 1), 1) * (($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA(TS_PCTCHANGE($close, 1), 1) * (($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Convexity_Volume_Exhaustion_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion opportunities by detecting price acceleration (convexity) decoupled from volume support. It calculates the change in price returns (acceleration) and multiplies it by the intraday range-to-volume ratio to pinpoint retail-driven liquidity exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.523033",
      "updated_at": "2026-01-17T02:16:08.523040"
    },
    "02847e8e88449175": {
      "factor_id": "02847e8e88449175",
      "factor_name": "Ranked_Convexity_Efficiency_5D",
      "factor_expression": "RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_PCTCHANGE($close, 1), 1)) * RANK(($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Convexity_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the convexity hypothesis. It ranks the acceleration of price changes over the last 2 days and multiplies it by the rank of the price range per unit of volume. High values indicate stocks where price is 'blowing off' with low volume efficiency relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.535713",
      "updated_at": "2026-01-17T02:16:08.535720"
    },
    "82602f3ec66b4e93": {
      "factor_id": "82602f3ec66b4e93",
      "factor_name": "ZScored_Acceleration_Volume_Ratio_10D",
      "factor_expression": "TS_ZSCORE(DELTA(TS_PCTCHANGE($close, 1), 1), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(DELTA(TS_PCTCHANGE($close, 1), 1), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Acceleration_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the price acceleration and volume efficiency using time-series Z-scores over a 10-day window. It targets extreme deviations in price convexity that are not supported by proportional volume, signaling unsustainable moves.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by intraday price-volume convexity, where high price acceleration (second derivative) combined with extreme daily range-to-volume ratios identifies retail-driven liquidity exhaustion.\n                Concise Observation: While the parent strategy focuses on 60-day quiet accumulation, daily data often shows sharp price 'spikes' with diminishing volume efficiency (High Close-Low range vs Volume) that lead to immediate reversals regardless of the long-term trend.\n                Concise Justification: Price convexity (the rate of change of the rate of change) captures the 'acceleration' phase of a trend; when this acceleration is decoupled from steady volume support, it indicates a liquidity vacuum or 'panic' exhaustion that is inherently unsustainable.\n                Concise Knowledge: If price movement accelerates rapidly (high convexity) relative to volume growth, the move is likely driven by retail liquidity demand rather than institutional conviction; when such 'blow-off' patterns occur, prices tend to mean-revert within 1-3 days.\n                concise Specification: The factor is defined as the product of the 3-day change in price slope (ROC_1 - ROC_1_lag1) and the daily price range normalized by volume, specifically: (TS_DELTA(TS_PCTCHANGE($close, 1), 1)) * (($high - $low) / ($volume + 1e-8)).\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "988ab96e01bb",
      "parent_trajectory_ids": [
        "d0152a6f7341"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0017950181392994,
        "ICIR": 0.0133457749704844,
        "RankIC": 0.0181190296875023,
        "RankICIR": 0.1357402504475549,
        "annualized_return": 0.0442620443756147,
        "information_ratio": 0.6894046817607756,
        "max_drawdown": -0.0830729922537042
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:08.549256",
      "updated_at": "2026-01-17T02:16:08.549262"
    },
    "b3cd9d1f66a40514": {
      "factor_id": "b3cd9d1f66a40514",
      "factor_name": "Exhaustion_Gap_Reversal_5D",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Gap_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion gaps by calculating the ratio of the overnight gap to the 5-day average volume. It assumes that large gaps on low relative volume are unsustainable and likely to mean-revert. The factor is cross-sectionally ranked to identify the most extreme exhaustion candidates.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.874619",
      "updated_at": "2026-01-17T02:16:09.874626"
    },
    "34be0ab703c37f6b": {
      "factor_id": "34be0ab703c37f6b",
      "factor_name": "Gap_Intraday_Efficiency_Ratio",
      "factor_expression": "(ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * INV(TS_ZSCORE($volume, 10) + 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * INV(ABS(TS_ZSCORE($volume, 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Intraday_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 'efficiency' of a gap by comparing the overnight gap magnitude to the subsequent intraday range, normalized by volume intensity. If the gap is large but the intraday range is small relative to volume, it suggests a lack of follow-through and a high probability of reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.887332",
      "updated_at": "2026-01-17T02:16:09.887338"
    },
    "34fcf06e06ae043f": {
      "factor_id": "34fcf06e06ae043f",
      "factor_name": "Liquidity_Imbalance_Gap_Factor",
      "factor_expression": "SIGN($open - DELAY($close, 1)) * ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open - DELAY($close, 1)) * ABS($open / DELAY($close, 1) - 1) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Imbalance_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Targets gaps driven by liquidity imbalances. It calculates the overnight gap and penalizes it if the intraday volume is significantly lower than the recent average, suggesting the gap was a 'low-conviction' move prone to filling.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Exhaustion Gap Reversal' factor, defined as the ratio of the overnight gap magnitude to the intraday price movement relative to volume intensity, predicts a 5-day mean reversion when large gaps occur on relatively low liquidity.\n                Concise Observation: While the parent strategy confirmed that price persistence (low-to-high ratios) predicts trend continuation, initial data suggests that extreme overnight price jumps often lack the volume support needed to prevent intraday 'gap filling' and subsequent reversal.\n                Concise Justification: Overnight gaps represent a mismatch between supply and demand during non-trading hours; if the subsequent intraday volume is insufficient to push the price further in the direction of the gap, it indicates exhaustion of the move and a likely return to the previous day's equilibrium.\n                Concise Knowledge: If an asset opens with a significant gap but fails to sustain that momentum on high volume, the gap is likely driven by liquidity imbalances rather than fundamental shifts, leading to a high probability of mean reversion.\n                concise Specification: The factor measures the overnight gap ($open / $close_{t-1}$) normalized by the 5-day average volume, specifically targeting the inverse relationship between gap size and subsequent 5-day returns when the intraday range fails to exceed the gap magnitude.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "3f463e1babe5",
      "parent_trajectory_ids": [
        "a3e677a37e74"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0072529196209767,
        "ICIR": 0.0535940282793855,
        "RankIC": 0.0239752515274828,
        "RankICIR": 0.1843502258600213,
        "annualized_return": 0.054424731220714,
        "information_ratio": 0.8394400380483625,
        "max_drawdown": -0.0955475669297207
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:16:09.899914",
      "updated_at": "2026-01-17T02:16:09.899920"
    },
    "ff213d9fa8bc5bb6": {
      "factor_id": "ff213d9fa8bc5bb6",
      "factor_name": "Vol_Adj_WVMA_Momentum_5D",
      "factor_expression": "(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * (DELTA($close, 5) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_WVMA_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 5-day Volume Weighted Moving Average (WVMA) and transforms it using a volatility-adjusted momentum ratio. It aims to identify high-conviction trends by scaling the volume-weighted price by the ratio of 5-day returns to 5-day price volatility, effectively filtering out noise in high-variance regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.632203",
      "updated_at": "2026-01-17T02:17:56.632212"
    },
    "f07da216a4b9559c": {
      "factor_id": "f07da216a4b9559c",
      "factor_name": "Regime_Scaled_WVMA_5D",
      "factor_expression": "RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE($return, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_ZSCORE(TS_PCTCHANGE($close, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"Regime_Scaled_WVMA_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A non-linear transformation of the 5-day WVMA that uses the Z-score of returns relative to volatility. This factor distinguishes between institutional accumulation (low volatility, rising price) and distribution (high volatility, falling price) by multiplying the volume-weighted price level by the 5-day return Z-score.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.645835",
      "updated_at": "2026-01-17T02:17:56.645842"
    },
    "9d12564761d0156b": {
      "factor_id": "9d12564761d0156b",
      "factor_name": "Conviction_Trend_Index_5D",
      "factor_expression": "(DELTA($close, 5) / (TS_MEAN($high - $low, 5) + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / (TS_MEAN($high - $low, 5) + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Trend_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of a trend by normalizing the 5-day price change by the 5-day price range (volatility proxy) and weighting it by the relative volume intensity. It captures the hypothesis that price moves with high volume and low relative volatility are more predictive.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The predictive power of the 5-day Volume Weighted Moving Average (WVMA5) is enhanced by applying a non-linear volatility-adjusted transformation that distinguishes between price-volume accumulation (low volatility, rising price) and distribution (high volatility, falling price).\n                Concise Observation: Standard linear moving averages like WVMA5 fail to capture the regime shifts where the same volume intensity carries different directional signals depending on the underlying price variance.\n                Concise Justification: Volume-weighted indicators are proxies for market conviction, but their reliability is regime-dependent; non-linear scaling by volatility filters out noise and highlights high-conviction trend phases.\n                Concise Knowledge: If price increases are accompanied by rising volume under low volatility, it indicates institutional accumulation; when high volatility is paired with high volume and declining prices, it signals distribution and potential reversal.\n                concise Specification: Calculate the 5-day WVMA and transform it by the ratio of the 5-day price change to the 5-day standard deviation of returns to create a volatility-normalized momentum factor.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "original",
      "trajectory_id": "7c201ace360a",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054753973950478,
        "ICIR": 0.0373271586062011,
        "RankIC": 0.0202884372199828,
        "RankICIR": 0.1412453893688189,
        "annualized_return": 0.0593395318168767,
        "information_ratio": 0.7401245157935983,
        "max_drawdown": -0.1531799361461828
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:17:56.659177",
      "updated_at": "2026-01-17T02:17:56.659183"
    },
    "ab596c4b1cce2d5e": {
      "factor_id": "ab596c4b1cce2d5e",
      "factor_name": "Overnight_Gap_Volume_Intensity_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Volume_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Gap' by calculating the ratio of the overnight return to the 5-day average trading volume. A high overnight return relative to low volume suggests that the price shock hasn't been fully absorbed by the market, potentially leading to a post-announcement drift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.757718",
      "updated_at": "2026-01-17T02:18:50.757725"
    },
    "b6a2b87926f3b41e": {
      "factor_id": "b6a2b87926f3b41e",
      "factor_name": "Ranked_Gap_to_Volume_Ratio_10D",
      "factor_expression": "RANK((($open - DELAY($close, 1)) / DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open - DELAY($close, 1)) / DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_to_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the gap-to-volume ratio, normalized by the 10-day volume trend. It identifies stocks where the overnight price jump is most extreme relative to its recent liquidity context, signaling potential trend continuation due to incomplete information absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.774939",
      "updated_at": "2026-01-17T02:18:50.774945"
    },
    "73054cc654b85f9d": {
      "factor_id": "73054cc654b85f9d",
      "factor_name": "Gap_Liquidity_Divergence_ZScore",
      "factor_expression": "TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($open / DELAY($close, 1)) - 1, 20) / (TS_ZSCORE($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Liquidity_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the overnight price shock and recent volume intensity using a Z-score. It targets the hypothesis that significant gaps on low relative volume lead to multi-day drifts because institutional order imbalances are not cleared immediately.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and the initial day's volume intensity, defined as the ratio of the overnight return to the 5-day average volume, predicts a post-announcement drift where large gaps with relatively low volume signal incomplete information absorption and subsequent trend continuation.\n                Concise Observation: While the parent strategy focused on mean-reversion from volatility exhaustion, many stocks exhibit persistent directional movement following overnight gaps, especially when the initial volume does not fully reflect the magnitude of the price shock.\n                Concise Justification: Institutional investors often execute large orders over several days to minimize market impact following fundamental surprises, creating a predictable drift in the direction of the initial gap when early liquidity is insufficient to clear the order imbalance.\n                Concise Knowledge: If a significant price gap occurs on low relative volume, the market likely lacks sufficient liquidity to fully price in the news immediately, leading to a multi-day drift; whereas high volume gaps suggest immediate price discovery and potential exhaustion.\n                concise Specification: The factor is calculated as the overnight return ($open / $close[t-1] - 1) divided by the 5-day moving average of volume, specifically targeting the 'Information Diffusion Gap' where the magnitude of the price jump exceeds the immediate liquidity response.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "66ce6a72bb63",
      "parent_trajectory_ids": [
        "68bbb159449e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0077804177182668,
        "ICIR": 0.0580827158863872,
        "RankIC": 0.0242323043304744,
        "RankICIR": 0.1866031220309915,
        "annualized_return": 0.0695837938114502,
        "information_ratio": 1.0902022370465765,
        "max_drawdown": -0.0857686849866647
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:18:50.787763",
      "updated_at": "2026-01-17T02:18:50.787769"
    },
    "d99c0a2786538e10": {
      "factor_id": "d99c0a2786538e10",
      "factor_name": "Liquidity_Absorption_Efficiency_20D",
      "factor_expression": "RANK(TS_MEAN($volume, 20) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Absorption_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high institutional accumulation by calculating the ratio of average volume to price volatility. High volume combined with low volatility suggests that large orders are being absorbed without significant price impact, often preceding a breakout. The factor is cross-sectionally ranked for comparability.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.461197",
      "updated_at": "2026-01-17T02:19:32.461203"
    },
    "7ea821869b791a04": {
      "factor_id": "7ea821869b791a04",
      "factor_name": "Tight_Consolidation_Volume_Ratio_10D",
      "factor_expression": "RANK(TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Tight_Consolidation_Volume_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity absorption hypothesis focusing on a shorter 10-day window. It measures the intensity of volume relative to the true range of the price, identifying 'tight' price action under heavy accumulation. It uses the high-low range as a proxy for intraday volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.474462",
      "updated_at": "2026-01-17T02:19:32.474468"
    },
    "8ef60a16ce69bd4d": {
      "factor_id": "8ef60a16ce69bd4d",
      "factor_name": "ZScored_Absorption_Intensity_20D",
      "factor_expression": "TS_ZSCORE($volume, 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume, 20) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Absorption_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the liquidity absorption concept by using Z-scores to identify extreme outliers where volume is significantly higher than its own history while volatility remains suppressed. This highlights the 'coiled spring' effect more precisely.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption' factor, defined as the ratio of 20-day average turnover to 20-day price volatility (ATR), identifies stocks where institutional accumulation stabilizes price despite high volume, predicting a bullish breakout.\n                Concise Observation: The parent strategy focused on mean-reversion in 'thin' markets (low volume divergence), whereas market data shows that high-volume 'thick' markets with suppressed volatility often precede strong trend continuations.\n                Concise Justification: High turnover indicates high conviction, and the lack of price movement (low ATR) suggests that large orders are being filled without moving the market, creating a coiled spring effect for future price discovery.\n                Concise Knowledge: If a stock maintains low price volatility while experiencing high turnover, it suggests institutional liquidity absorption; when this 'tightness' occurs, the subsequent breakout tends to follow the direction of the volume-weighted accumulation.\n                concise Specification: The factor is calculated as the 20-day mean of $volume divided by the 20-day standard deviation of daily returns, cross-sectionally ranked to identify the top decile of 'efficient' liquidity absorption.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "099794449bd1",
      "parent_trajectory_ids": [
        "602b97b242f8"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053379800858387,
        "ICIR": 0.0395250932070123,
        "RankIC": 0.0208593631299133,
        "RankICIR": 0.1574478975308104,
        "annualized_return": 0.0565191662555769,
        "information_ratio": 0.8228531663065085,
        "max_drawdown": -0.1183465600246285
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:19:32.488899",
      "updated_at": "2026-01-17T02:19:32.488906"
    },
    "72899da06635a7c9": {
      "factor_id": "72899da06635a7c9",
      "factor_name": "Overnight_Liquidity_Exhaustion_Factor",
      "factor_expression": "RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / (DELAY($close, 1) + 1e-8)) / (TS_MEAN($high - $low, 5) + 1e-8) * INV(1.1 + TS_CORR($close - $open, $volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Liquidity_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean reversion by calculating the ratio of the overnight gap to the average intraday range, conditioned on a negative correlation between price changes and volume. A high value suggests price dislocation due to liquidity exhaustion rather than fundamental conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.227209",
      "updated_at": "2026-01-17T02:25:06.227216"
    },
    "d8c3febdd45c3cc5": {
      "factor_id": "d8c3febdd45c3cc5",
      "factor_name": "Price_Volume_Divergence_Reversion",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($open, 1) / (TS_STD($high - $low, 5) + 1e-8)) * SIGN(-1 * TS_CORR($close - $open, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($open, 1) / (TS_STD($high - $low, 5) + 1e-8)) * SIGN(-1 * TS_CORR($close - $open, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Divergence_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Targets short-term reversals by capturing instances where the overnight return is disproportionately large compared to the recent volatility (intraday range), specifically when price and volume move in opposite directions (negative correlation), signaling weak conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.240378",
      "updated_at": "2026-01-17T02:25:06.240384"
    },
    "52db75a891a36d98": {
      "factor_id": "52db75a891a36d98",
      "factor_name": "Liquidity_Imbalance_Index",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 5) + 1e-8)) * (1 - TS_CORR(($close / $open - 1), LOG($volume + 1), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 5) + 1e-8)) * (1 - TS_CORR(($close / $open - 1), LOG($volume + 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Imbalance_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of price-volume decoupling. It normalizes the overnight gap by the 5-day median intraday range and scales it by the inverse of the price-volume correlation to highlight liquidity-driven gaps likely to reverse.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight returns to intraday volatility, when conditioned on a negative correlation between price and volume during the market close, identifies short-term liquidity exhaustion and subsequent mean reversion.\n                Concise Observation: The parent strategy focused on 60-day trend stability, but market data shows that sharp price movements often occur on low relative volume during the market close, leading to significant reversals the following day due to overnight liquidity replenishment.\n                Concise Justification: Institutional traders often execute large blocks near the close to minimize tracking error, which can create temporary price dislocations if liquidity is thin; these dislocations are mean-reverting as the market re-equilibrates at the next day's open.\n                Concise Knowledge: If a stock's overnight gap is large relative to its intraday price range and occurs with decreasing volume intensity, it likely reflects a liquidity imbalance rather than fundamental information; When intraday price-volume correlation is negative, it suggests price movements are driven by temporary order flow pressure rather than sustainable conviction.\n                concise Specification: The factor will be defined as the ratio of (Open/Prev_Close) to the 5-day average intraday range (High-Low), multiplied by the inverse of the 5-day correlation between price changes and volume during the trading session, targeting a 1-day holding period.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "cda6651993bf",
      "parent_trajectory_ids": [
        "fb6a3aab1037"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063951464400919,
        "ICIR": 0.0468176222039618,
        "RankIC": 0.0226751898111367,
        "RankICIR": 0.1693352744304375,
        "annualized_return": 0.0654683911047764,
        "information_ratio": 1.0573134908880013,
        "max_drawdown": -0.083766234404315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:25:06.253319",
      "updated_at": "2026-01-17T02:25:06.253325"
    },
    "d422b0c3436a867b": {
      "factor_id": "d422b0c3436a867b",
      "factor_name": "PVDP_Exhaustion_Ratio_10D",
      "factor_expression": "TS_CORR($return, TS_PCTCHANGE($volume, 1), 10) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 0.00001))\" # Your output factor expression will be filled in here\n    name = \"PVDP_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by measuring the divergence between price returns and volume changes, scaled by the ratio of overnight gaps to intraday ranges. A low correlation between returns and volume growth, coupled with a high gap-to-range ratio, suggests institutional withdrawal and potential mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.395591",
      "updated_at": "2026-01-17T02:26:06.395598"
    },
    "84d5431c1331477c": {
      "factor_id": "84d5431c1331477c",
      "factor_name": "Institutional_Exhaustion_Index_V1",
      "factor_expression": "RANK(TS_CORR($return, $volume, 10)) * RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10)) * RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 0.0001))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Index_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'quiet' exhaustion phase where price continues to drift on weakening volume support. It uses the rank-transformed correlation of price-volume and compares the magnitude of the opening jump to the subsequent intraday volatility. High values indicate the trend is driven by inertia rather than conviction.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.409041",
      "updated_at": "2026-01-17T02:26:06.409047"
    },
    "380a7d7077fba3ab": {
      "factor_id": "380a7d7077fba3ab",
      "factor_name": "Gap_Range_Divergence_ZScore",
      "factor_expression": "TS_CORR($return, $volume, 10) * TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10) * TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Gap_Range_Divergence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Normalizes the divergence between the overnight gap and intraday range using Z-scores, then interacts it with the price-volume correlation. This highlights periods where price movements are dominated by overnight sentiment but lack intraday follow-through and volume confirmation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price-Volume Divergence Persistence (PVDP) hypothesis: A trend is likely to exhaust when price returns and volume changes show a decaying rolling correlation combined with a narrowing intraday range relative to the overnight gap, indicating institutional exhaustion and imminent mean reversion.\n                Concise Observation: The parent strategy successfully captured intraday support via shadows, but market trends often fail not because of a sharp rejection, but due to a 'quiet' exhaustion where price moves on thinning volume and smaller intraday ranges compared to the opening gap.\n                Concise Justification: Volume serves as the fuel for price trends; a divergence where price gains persist despite falling volume and narrowing ranges suggests a lack of liquidity depth, making the asset vulnerable to even minor selling pressure as the 'exhaustion' phase concludes.\n                Concise Knowledge: If price continues to trend while volume correlation drops and intraday volatility contracts relative to the overnight gap, then the trend is driven by liquidity inertia rather than active conviction; when institutional participation (volume) fails to confirm price movement, the probability of a 'drift-back' reversal increases.\n                concise Specification: The factor will be calculated as the 10-day rolling correlation between daily returns and volume changes, multiplied by the ratio of the 5-day mean overnight gap (abs(Open - PrevClose)) to the 5-day mean intraday range (High - Low), targeting stocks with high gap-to-range ratios and low PV correlation.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d17ed7e40f10",
      "parent_trajectory_ids": [
        "2e043cd85785"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0081170545425971,
        "ICIR": 0.0549173822976059,
        "RankIC": 0.0270807199086509,
        "RankICIR": 0.1859082085105904,
        "annualized_return": 0.009361776498184,
        "information_ratio": 0.1277620018394183,
        "max_drawdown": -0.1113878286030992
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:26:06.426924",
      "updated_at": "2026-01-17T02:26:06.426931"
    },
    "b288c17cf78e5e8a": {
      "factor_id": "b288c17cf78e5e8a",
      "factor_name": "Volatility_Exhaustion_Reversal_5D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * (($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * (($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean reversion opportunities by detecting 'volatility exhaustion'. It calculates the ratio of the current daily range to its 20-day average and scales it by the relative position of the close within that range. High values indicate the price has stretched to an extreme and closed near that extreme, suggesting a high probability of a 5-day reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.934535",
      "updated_at": "2026-01-17T02:29:19.934542"
    },
    "f31f3f1925246a8d": {
      "factor_id": "f31f3f1925246a8d",
      "factor_name": "Intraday_Skew_Exhaustion_Factor",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 20)) * SIGN($close - 0.5 * ($high + $low))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 20)) * SIGN($close - 0.5 * ($high + $low))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Skew_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures liquidity exhaustion by measuring the daily range expansion relative to historical volatility, specifically when the close is significantly skewed toward the high or low. It targets short-term mean reversion by identifying emotional overshoots in price action.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.948118",
      "updated_at": "2026-01-17T02:29:19.948124"
    },
    "f181f52bc7dfdd49": {
      "factor_id": "f181f52bc7dfdd49",
      "factor_name": "Range_Stretch_Median_Reversion",
      "factor_expression": "ZSCORE(($high - $low) / (TS_MEDIAN($high - $low, 20) + 1e-8)) * ((2 * $close - ($high + $low)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / (TS_MEDIAN($high - $low, 20) + 1e-8)) * ((2 * $close - ($high + $low)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Range_Stretch_Median_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 'stretch' of the current daily range against the 20-day median range. It combines this with the intraday price location to signal exhaustion. It uses TS_MEDIAN for robustness against outliers in historical volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A 5-day mean reversion signal can be generated by identifying 'volatility exhaustion' where the daily range (High-Low) normalized by its 20-day moving average exceeds a threshold, particularly when the intraday price action is skewed towards one extreme (High-Close vs Close-Low).\n                Concise Observation: The parent strategy's volume-weighted correlation focuses on institutional conviction, but fails to capture short-term price reversals triggered by intraday volatility spikes and liquidity exhaustion that occur independently of volume trends.\n                Concise Justification: Price action geometry, specifically the ratio of the current range to historical range, serves as a proxy for market exhaustion; a high ratio suggests that liquidity providers have been pushed to extremes, leading to a high-probability reversal as the 'stretch' reverts to the mean.\n                Concise Knowledge: If the intraday price range expands significantly beyond historical volatility without a corresponding overnight gap, it indicates an emotional liquidity overshoot; when this expansion is accompanied by a close near the day's extreme, the probability of a short-term mean reversion increases.\n                concise Specification: The factor will use the ratio of ($high - $low) to its 20-day average, moderated by the relative position of the close within that range (High-Close vs Close-Low), to predict 1-3 day returns, focusing on the 5-day lookback for mean reversion signals.\n                ",
      "initial_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volume-weighted price correlation: Modify CORR20 to use volume-weighted average price (VWAP) instead of close price to capture the lead-lag relationship between institutional intent and execution.",
      "evolution_phase": "mutation",
      "trajectory_id": "90765b772937",
      "parent_trajectory_ids": [
        "ced58d311301"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.007462325568449,
        "ICIR": 0.0575319036285626,
        "RankIC": 0.0229814000641017,
        "RankICIR": 0.1821446760219512,
        "annualized_return": 0.0577316654087539,
        "information_ratio": 0.90125932775314,
        "max_drawdown": -0.0886117378331481
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:29:19.961533",
      "updated_at": "2026-01-17T02:29:19.961539"
    },
    "714bd241d9bef45d": {
      "factor_id": "714bd241d9bef45d",
      "factor_name": "VW_Price_Efficiency_Regime_5D",
      "factor_expression": "((DELTA($close, 5) * $volume / (TS_MEAN($volume, 20) + 1e-8)) * (ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8))) * ((TS_STD($close, 5) > TS_STD($close, 20)) && ($volume > 1.5 * TS_MEAN($volume, 20)) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((DELTA($close, 5) * $volume / (TS_MEAN($volume, 20) + 1e-8)) * (ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8))) * ((TS_STD($close, 5) > TS_STD($close, 20)) && ($volume > 1.5 * TS_MEAN($volume, 20)) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Efficiency_Regime_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by combining volume-weighted momentum with price discovery efficiency. It focuses on regimes where short-term volatility (5-day) exceeds long-term volatility (20-day) and volume is significantly higher than its 20-day average. Efficiency is defined as the ratio of absolute displacement to the total price range covered.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.291253",
      "updated_at": "2026-01-17T02:30:45.291261"
    },
    "d330a6dddbc6bd32": {
      "factor_id": "d330a6dddbc6bd32",
      "factor_name": "Efficiency_Adjusted_Force_Index_10D",
      "factor_expression": "RANK(TS_SUM($return * $volume, 10)) * RANK(ABS(DELTA($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1) * $volume, 10)) * RANK(ABS(DELTA($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Force_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the regime-shift hypothesis focusing on the 'Force Index' (volume-weighted return) adjusted by price discovery efficiency over a 10-day window. It uses RANK to normalize the interaction between volume surges and directional persistence, identifying institutional accumulation or distribution.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.307816",
      "updated_at": "2026-01-17T02:30:45.307822"
    },
    "29c4edd238c78731": {
      "factor_id": "29c4edd238c78731",
      "factor_name": "Vol_Expansion_Trend_Persistence_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($close, 5) / (TS_STD($close, 20) + 1e-8)) * RANK(ABS(DELTA($close, 5)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Expansion_Trend_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of a trend during volatility expansion. It calculates the product of the 5-day return and the ratio of displacement to volatility, specifically when the short-term volatility is rising relative to its medium-term benchmark, signaling a potential structural regime shift.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: In high-activity regimes defined by short-term volatility expansion (STD5 > STD20) and volume surges, the interaction between volume-weighted price momentum and price discovery efficiency (displacement/path) predicts persistent trend continuation rather than mean reversion.\n                Concise Observation: The parent strategy filters out high-volatility 'falling knife' or 'breakout' scenarios to ensure mean reversion stability, leaving a significant portion of trend-based returns uncaptured during periods of market stress or news-driven activity.\n                Concise Justification: Volume-weighted price changes represent the 'Force Index' of a move, and when normalized by the total path traveled (efficiency), they distinguish between chaotic noise and purposeful institutional accumulation or distribution.\n                Concise Knowledge: If price movement is accompanied by both a volume spike and high discovery efficiency during a volatility expansion, the market is likely undergoing a structural regime shift rather than a temporary deviation; When efficiency is high, the trend is more likely to persist as it reflects high conviction among informed traders.\n                concise Specification: The factor will be calculated as the product of the 5-day volume-weighted price change and the ratio of absolute 5-day displacement to the 5-day high-low range sum, conditioned on (TS_STD($close, 5) > TS_STD($close, 20)) and (volume > 1.5 * mean_volume_20).\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "952384b7b569",
      "parent_trajectory_ids": [
        "1313640a8457"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026043807116103,
        "ICIR": 0.0160801807348422,
        "RankIC": 0.0159260232878783,
        "RankICIR": 0.0964912635562397,
        "annualized_return": 0.0773280221573225,
        "information_ratio": 0.8916421076084982,
        "max_drawdown": -0.1218256306715862
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:30:45.323029",
      "updated_at": "2026-01-17T02:30:45.323034"
    },
    "8a6eb155a91d9ffb": {
      "factor_id": "8a6eb155a91d9ffb",
      "factor_name": "Stealth_Accumulation_Decoupling_20D",
      "factor_expression": "-1 * RANK(TS_CORR($high - $low, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_CORR($high - $low, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Decoupling_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the decoupling between the daily price range (high - low) and daily trading volume over a 20-day period. A lower correlation suggests that price movements are occurring without significant liquidity shocks, indicating informed institutional accumulation with minimal market impact.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.582971",
      "updated_at": "2026-01-17T02:33:31.582977"
    },
    "2288ed9bab90400e": {
      "factor_id": "2288ed9bab90400e",
      "factor_name": "Informed_Range_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Informed_Range_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'stealth' price discovery by calculating the ratio of the price range to the volume, smoothed over 15 days. High values indicate high range efficiency where price moves significantly on relatively low volume, suggesting institutional positioning rather than retail-driven volume spikes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.600892",
      "updated_at": "2026-01-17T02:33:31.600899"
    },
    "973adedc0202ee0d": {
      "factor_id": "973adedc0202ee0d",
      "factor_name": "Stealth_Drift_Persistence_10D",
      "factor_expression": "RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($high - $low, 10) - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price volatility and volume intensity. It uses the difference between the rank of the price range and the rank of volume over a 10-day window. Positive values indicate price volatility is higher than volume intensity, a hallmark of stealth accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Stealth Accumulation Factor (SAF), defined as the divergence between the daily price range and volume intensity, identifies stocks where institutional execution minimizes market impact, leading to persistent price drift.\n                Concise Observation: While the parent strategy focused on volume volatility ratios (MSLVR) to identify regime shifts, it ignored the internal structure of daily price-volume coupling, which often reveals the 'stealth' nature of institutional positioning.\n                Concise Justification: Low correlation between high-low price spreads and volume suggests a lack of liquidity friction during a move, implying that the price discovery is driven by information rather than temporary liquidity shocks, which supports trend persistence.\n                Concise Knowledge: If price range volatility is high while volume remains relatively low or stable, it indicates informed traders are successfully masking their footprint; when price and volume are highly synchronized, the movement is likely retail-driven and prone to mean reversion.\n                concise Specification: The factor is calculated as the 20-day correlation between the daily price range (High - Low) and the daily volume, where a lower correlation (decoupling) is expected to predict higher future returns through drift persistence.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "54ded28fe7f1",
      "parent_trajectory_ids": [
        "d5c2c9c8d643"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064981784696998,
        "ICIR": 0.0490544385522351,
        "RankIC": 0.0259838168464141,
        "RankICIR": 0.2018794294876305,
        "annualized_return": 0.0723950455001276,
        "information_ratio": 1.1591820948311895,
        "max_drawdown": -0.0638259401166411
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:33:31.616048",
      "updated_at": "2026-01-17T02:33:31.616054"
    },
    "ea9e5ed667e7ed94": {
      "factor_id": "ea9e5ed667e7ed94",
      "factor_name": "Quiet_Accumulation_Gap_Factor_20D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * RANK(1 / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * RANK(INV(TS_STD(($close / DELAY($close, 1)) - 1, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Gap_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional accumulation by identifying overnight price gaps that occur during low-volatility consolidation phases. It multiplies the overnight return by the volume surprise (current volume relative to its 20-day mean) and applies a penalty to stocks with high historical volatility to isolate 'quiet' zones.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.490809",
      "updated_at": "2026-01-17T02:34:54.490816"
    },
    "889acbc204290131": {
      "factor_id": "889acbc204290131",
      "factor_name": "Low_Vol_Volume_Surprise_Momentum",
      "factor_expression": "(RANK(TS_STD($return, 20)) < 0.3) ? ((($open / DELAY($close, 1)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_STD(TS_PCTCHANGE($close, 1), 20)) < 0.3) ? ((($open / DELAY($close, 1)) - 1) * ($volume / TS_MEAN($volume, 20))) : 0\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Volume_Surprise_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price movements during low-volatility regimes. It calculates the product of the overnight gap and the volume ratio, specifically filtering for stocks in the bottom 30% of 20-day volatility to target institutional 'quiet' accumulation before a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.504977",
      "updated_at": "2026-01-17T02:34:54.504983"
    },
    "11aa0f7100914260": {
      "factor_id": "11aa0f7100914260",
      "factor_name": "Institutional_Gap_Signal_ZScore",
      "factor_expression": "TS_ZSCORE((($open / DELAY($close, 1)) - 1) * $volume, 20) * (1 - RANK(TS_STD($return, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((($open / DELAY($close, 1)) - 1) * $volume, 20) * (1 - RANK(TS_STD(($close / DELAY($close, 1) - 1), 20)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Signal_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the quiet accumulation hypothesis. It measures the Z-score of the volume-weighted overnight gap, scaled by the inverse of volatility rank to prioritize signals originating from stable price bases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Quiet Accumulation Factor, defined as the ratio of overnight returns to the 20-day average volume during low-volatility consolidation periods, positively predicts multi-day returns as it captures institutional information diffusion before a trend breakout.\n                Concise Observation: The parent strategy focused on high-volatility intraday reversals (shadows), but empirical data shows that significant price trends often originate from low-volatility 'quiet' zones where volume-weighted overnight gaps signal the start of a new information cycle.\n                Concise Justification: Institutional investors often accumulate positions quietly to minimize market impact; an overnight gap during low-volatility periods suggests that new information is being priced in, and the subsequent volume confirms the strength of the conviction, leading to a momentum effect.\n                Concise Knowledge: If a stock exhibits an overnight price gap with abnormal volume during a low-volatility regime, it indicates a high probability of trend persistence; When volatility is low, volume spikes are more likely to represent informed institutional positioning rather than noise-driven retail panic.\n                concise Specification: The factor is calculated by multiplying the overnight return (Open_t / Close_t-1 - 1) by the volume surprise (Volume_t / Mean_Volume_20D) and filtering for stocks where the 20-day volatility (TS_STD) is in the bottom 30th percentile of the cross-section.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "5c8825cf7e52",
      "parent_trajectory_ids": [
        "04c97485bd3e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061819379936305,
        "ICIR": 0.046396281735019,
        "RankIC": 0.0223867612904535,
        "RankICIR": 0.1728927849014101,
        "annualized_return": 0.053788086614834,
        "information_ratio": 0.7800467901833231,
        "max_drawdown": -0.1059925624337808
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:34:54.518903",
      "updated_at": "2026-01-17T02:34:54.518909"
    },
    "2490e493b70901a7": {
      "factor_id": "2490e493b70901a7",
      "factor_name": "Liquidity_Depletion_Reversal_3D",
      "factor_expression": "-1 * RANK(TS_MEAN($volume, 3) / (TS_MEDIAN($volume, 20) + 1e-8) + TS_MEAN($high - $low, 3) / (TS_MEAN($close, 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($volume, 3) / (TS_MEDIAN($volume, 20) + 1e-8) + TS_MEAN($high - $low, 3) / (TS_MEAN($close, 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Depletion_Reversal_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with extreme volume depletion and price range compression over a 3-day window relative to their 20-day baseline. According to the Liquidity Provision Reversal hypothesis, such 'quiet' states represent a liquidity vacuum that precedes a mean-reversion when market makers return.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.318051",
      "updated_at": "2026-01-17T02:37:14.318057"
    },
    "eb86cf43cd13021e": {
      "factor_id": "eb86cf43cd13021e",
      "factor_name": "Price_Efficiency_Vacuum_Factor",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 3) / (TS_SUM($volume, 3) + 1e-8)) * ZSCORE(TS_SUM($volume, 3) / (TS_SUM($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 3) / (TS_SUM($volume, 3) + 1e-8)) * ZSCORE(TS_SUM($volume, 3) / (TS_SUM($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Vacuum_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures 'price efficiency' during low-volume periods. It targets stocks where the price movement per unit of volume is minimal over a short window (3 days) compared to the long-term average, indicating a lack of conviction and a high probability of reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.332468",
      "updated_at": "2026-01-17T02:37:14.332474"
    },
    "9ad4ed63e0efd34f": {
      "factor_id": "9ad4ed63e0efd34f",
      "factor_name": "Quiet_Regime_Mean_Reversion",
      "factor_expression": "-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD($return, 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_MEAN($volume, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 3))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines volume depletion (3-day mean vs 20-day mean) with price stability (3-day volatility). Low values in both suggest a 'quiet' regime susceptible to liquidity-driven reversals. The factor is negated to reflect the expected mean-reversion return.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Provision Reversal' hypothesis: Stocks exhibiting extreme volume depletion combined with price range compression over a 3-day window indicate a temporary withdrawal of liquidity providers, leading to predictable mean-reversion as market makers return.\n                Concise Observation: The parent strategy successfully captured high-intensity momentum through price-volume synchrony, but it likely fails in 'quiet' market regimes where low volume leads to price stagnation or fragile stability.\n                Concise Justification: Low volume depletion ratios combined with low price efficiency (minimal movement per unit of volume) suggest that current price levels are not supported by active conviction, making them susceptible to reversals when liquidity stabilizes.\n                Concise Knowledge: If trading volume falls significantly below its historical median while price volatility remains abnormally low, a liquidity vacuum is formed; when market participants eventually return, the price tends to reverse to its short-term mean due to the re-establishment of the bid-ask spread.\n                concise Specification: The factor will target the lowest decile of 3-day volume relative to 20-day median volume, interacted with the 3-day High-Low price spread; the expected relationship is a negative correlation between this 'quietness' metric and subsequent returns.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "b6a4650ffc4b",
      "parent_trajectory_ids": [
        "c4016b5d2dfb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048289180451195,
        "ICIR": 0.0376149431745163,
        "RankIC": 0.0195025859835787,
        "RankICIR": 0.1513105663463998,
        "annualized_return": 0.0579213705870932,
        "information_ratio": 0.8776615106364191,
        "max_drawdown": -0.1184043578562796
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:14.346788",
      "updated_at": "2026-01-17T02:37:14.346794"
    },
    "a5ce5e3f851fd4d1": {
      "factor_id": "a5ce5e3f851fd4d1",
      "factor_name": "Overnight_Conviction_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Conviction_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of absolute overnight returns to the intraday price range, averaged over 5 days. It identifies high-conviction institutional positioning by highlighting periods where price movement occurs primarily during non-trading hours relative to intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.221118",
      "updated_at": "2026-01-17T02:37:58.221125"
    },
    "82ece24226c9cbeb": {
      "factor_id": "82ece24226c9cbeb",
      "factor_name": "Low_Noise_Institutional_Gap_Factor",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_STD($close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_STD($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Low_Noise_Institutional_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the overnight return magnitude with a penalty for intraday price volatility. It scales the 5-day average overnight return by the inverse of the 5-day price standard deviation, rewarding stable, low-noise price action that suggests institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.235425",
      "updated_at": "2026-01-17T02:37:58.235431"
    },
    "3d503a5431bacb0d": {
      "factor_id": "3d503a5431bacb0d",
      "factor_name": "Ranked_Conviction_Persistence_Index",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($return, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Persistence_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction index. It compares the relative strength of the overnight-to-range ratio against the relative stability of the stock, identifying assets with the highest institutional signal-to-noise ratio.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of overnight return to intraday price range (High-Low) over a 5-day window, when combined with low price volatility, identifies high-conviction institutional positioning that predicts medium-term trend persistence.\n                Concise Observation: While the previous strategy focused on price-volume exhaustion and mean reversion over 10 days, market data often shows that 'quiet' price action with steady overnight gaps indicates institutional accumulation that leads to sustained momentum.\n                Concise Justification: Low intraday volatility (normalized by range) indicates a lack of speculative churn and high information efficiency, suggesting that the current price direction is driven by fundamental conviction rather than temporary liquidity shocks.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, it suggests information is being incorporated during non-trading hours by informed agents; when this occurs with low intraday noise, the resulting trend is more likely to persist rather than mean-revert.\n                concise Specification: The factor is defined as the 5-day average of the absolute overnight return divided by the daily high-low range, filtered by the 5-day standard deviation of close prices to reward stability. Higher values indicate stronger trend conviction.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "e5cfc8d77f88",
      "parent_trajectory_ids": [
        "e4018d0555c2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.005067527827994,
        "ICIR": 0.0363807930229056,
        "RankIC": 0.0202264397382186,
        "RankICIR": 0.1470956971196648,
        "annualized_return": 0.0278449885010213,
        "information_ratio": 0.4246382765531791,
        "max_drawdown": -0.1210102676032457
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:37:58.251412",
      "updated_at": "2026-01-17T02:37:58.251418"
    },
    "e55f48a58d8cef9e": {
      "factor_id": "e55f48a58d8cef9e",
      "factor_name": "Inst_Liquidity_Exhaustion_5D",
      "factor_expression": "TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Inst_Liquidity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional liquidity exhaustion by measuring the divergence between the closing price and the daily average price (HLC/3), normalized by the daily range. A high positive value suggests a late-day markup without broad support, predicting a potential reversal. The value is smoothed over 5 days to capture persistent imbalances.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.369398",
      "updated_at": "2026-01-17T02:40:14.369405"
    },
    "99189547d9fa4c68": {
      "factor_id": "99189547d9fa4c68",
      "factor_name": "Relative_Closing_Imbalance_Rank_10D",
      "factor_expression": "TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Closing_Imbalance_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the relative position of the close within the daily range compared to the average price. By applying a cross-sectional rank to the exhaustion signal and smoothing it, it identifies stocks with the most extreme liquidity traps relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.384880",
      "updated_at": "2026-01-17T02:40:14.384886"
    },
    "066c4742ee84bfb7": {
      "factor_id": "066c4742ee84bfb7",
      "factor_name": "Liquidity_Trap_ZScore_20D",
      "factor_expression": "TS_ZSCORE(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Trap_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the statistical significance of the price-discovery divergence by calculating the time-series Z-score of the daily close-to-average-price distance. High Z-scores indicate abnormal late-session price behavior that is likely to mean-revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the daily average execution price (approximated by the average of high, low, and close) and the final closing price, when scaled by the daily trading range, identifies institutional liquidity exhaustion and predicts a short-term price reversal.\n                Concise Observation: Previous factors focused on overnight gaps and intraday lows (price support), but failed to account for the efficiency of price discovery throughout the full session; specifically, the 'distance' between the average transacted price and the final settlement often signals 'fake' end-of-day moves.\n                Concise Justification: A closing price significantly higher than the day's average (HLC/3) suggests a late-day markup that may not be supported by the day's volume-weighted conviction, leading to a 'liquidity thirst' where the price must revert to find actual buyers.\n                Concise Knowledge: If the closing price deviates significantly from the intraday mean price (VWAP proxy) while the total trading range is narrow, it indicates a liquidity trap where late-session aggressive orders lack fundamental support; such imbalances typically mean-revert as liquidity stabilizes.\n                concise Specification: The factor is defined as (Close - (High + Low + Close) / 3) / (High - Low + 1e-8), calculated on a daily basis and smoothed over a 5-day window to capture persistent institutional exhaustion rather than single-day noise.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "b4d50035c1b2",
      "parent_trajectory_ids": [
        "517312de0ea9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038663000341145,
        "ICIR": 0.0271719797394659,
        "RankIC": 0.018724942373261,
        "RankICIR": 0.133472539439854,
        "annualized_return": 0.0781787508724346,
        "information_ratio": 1.2194168060668948,
        "max_drawdown": -0.0864860681351827
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:40:14.399185",
      "updated_at": "2026-01-17T02:40:14.399192"
    },
    "fffb5eb9485c4f77": {
      "factor_id": "fffb5eb9485c4f77",
      "factor_name": "Amihud_Reversion_5D",
      "factor_expression": "TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (1 - $close / $open)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (1 - $close / ($open + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion candidates by multiplying the 5-day average Amihud illiquidity ratio (absolute return divided by volume) with the negative intraday return. High illiquidity during a price move suggests a transient shock likely to reverse.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.179048",
      "updated_at": "2026-01-17T02:41:08.179055"
    },
    "5ae2eca4ab56957e": {
      "factor_id": "5ae2eca4ab56957e",
      "factor_name": "Illiquidity_Shock_ZScore_Reversal",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($volume + 1e-8), 20) * ($open - $close) / ($open + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 20) * ($open - $close) / ($open + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Illiquidity_Shock_ZScore_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between normalized illiquidity shocks and intraday price direction. It uses the Z-score of the Amihud ratio over 20 days to identify extreme liquidity-driven moves and bets on the reversal of the intraday trend.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.194184",
      "updated_at": "2026-01-17T02:41:08.194191"
    },
    "bbae81fc535fa2c3": {
      "factor_id": "bbae81fc535fa2c3",
      "factor_name": "Ranked_Amihud_Intraday_Reversal",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 10)) * SIGN($open - $close)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(($close - $open) / $open) / ($volume + 1e-8), 10)) * SIGN($open - $close)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Amihud_Intraday_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the illiquidity-reversion hypothesis. It ranks the 10-day average price impact per unit volume and multiplies it by the negative sign of the intraday return to target stocks where illiquid moves are most likely to exhaust.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price moves driven by high illiquidity shocks (Amihud ratio) are likely to mean-revert, especially when the intraday return significantly deviates from the subsequent overnight return, indicating a temporary liquidity imbalance.\n                Concise Observation: Medium-term momentum factors often fail during liquidity-driven spikes where price impact is disproportionate to volume, suggesting that price-volume elasticity can identify exhaustion points in short-term trends.\n                Concise Justification: The Amihud Illiquidity ratio measures the price impact per unit of volume; when this ratio is high, the price move is 'fragile' and likely represents a transient liquidity shock rather than a sustainable trend, providing a mean-reversion opportunity.\n                Concise Knowledge: If price changes occur on low relative volume (high Amihud ratio), they are often driven by noise traders or liquidity demand rather than fundamental information; such moves tend to mean-revert as market makers provide liquidity to capture the premium.\n                concise Specification: Calculate the 5-day average Amihud ratio (abs(return)/volume) and multiply it by the negative of the 1-day intraday return (close/open - 1) to identify reversal candidates after illiquidity-driven moves.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "084ac77c990c",
      "parent_trajectory_ids": [
        "53ff515f8c07"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038960407283515,
        "ICIR": 0.0274180016880432,
        "RankIC": 0.0192110049040767,
        "RankICIR": 0.1351986496392171,
        "annualized_return": -0.0007982829886174,
        "information_ratio": -0.011857486225032,
        "max_drawdown": -0.0908010753263346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:41:08.209027",
      "updated_at": "2026-01-17T02:41:08.209034"
    },
    "1aa53be0817ae109": {
      "factor_id": "1aa53be0817ae109",
      "factor_name": "IPVE_Fragility_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"IPVE_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the Intraday Price-Volume Efficiency (IPVE) by taking the ratio of the daily price range to the trading volume. It identifies 'fragile' price movements where high volatility occurs on low liquidity. A 5-day simple moving average is applied to smooth idiosyncratic noise, and the result is cross-sectionally ranked to identify stocks prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.001869",
      "updated_at": "2026-01-17T02:43:26.001876"
    },
    "4a8501762c4a0bae": {
      "factor_id": "4a8501762c4a0bae",
      "factor_name": "Normalized_IPVE_ZScore_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Normalized_IPVE_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "An alternative measure of price-volume efficiency that normalizes the price range by the 10-day average volume to isolate volume shocks. It uses a Z-score to identify extreme price-impact days relative to the stock's recent history, highlighting liquidity exhaustion points before mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.016885",
      "updated_at": "2026-01-17T02:43:26.016891"
    },
    "93f99fe635358d30": {
      "factor_id": "93f99fe635358d30",
      "factor_name": "Relative_Range_Volume_Efficiency_20D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEDIAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement relative to volume by comparing the current range-to-volume ratio against its 20-day median. It targets stocks where the current price movement is significantly more 'expensive' in terms of liquidity than usual, indicating a high probability of a fragile trend.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price-Volume Efficiency (IPVE) factor, defined as the ratio of the daily price range to the total volume, identifies 'exhausted' price movements where high volatility occurs on low relative liquidity, predicting short-term mean reversion.\n                Concise Observation: The parent strategy focused on 5-day return residuals (the 'what'), but failed to account for the liquidity cost of those moves (the 'how'), often leading to false signals in stocks with thin trading depth.\n                Concise Justification: By normalizing the daily price range (High - Low) by the total volume, we capture the 'price impact' per unit of volume; extreme values indicate price dislocations caused by liquidity exhaustion which are statistically prone to reversal.\n                Concise Knowledge: If a stock exhibits a large price range relative to its trading volume (high illiquidity), the movement is likely driven by temporary liquidity gaps rather than informed trading; such 'fragile' price levels tend to mean-revert as liquidity stabilizes.\n                concise Specification: Calculate the daily range ($high - $low) divided by $volume, then apply a 5-day moving average to smooth idiosyncratic noise, and rank cross-sectionally to isolate stocks with the highest 'fragility' per unit of liquidity.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "c96ea5c447c4",
      "parent_trajectory_ids": [
        "f202389c67c8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057102577200863,
        "ICIR": 0.0403331460170836,
        "RankIC": 0.0265405304179709,
        "RankICIR": 0.1907661192869725,
        "annualized_return": 0.0487895152190456,
        "information_ratio": 0.7621703986104669,
        "max_drawdown": -0.0835352571462169
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:43:26.031536",
      "updated_at": "2026-01-17T02:43:26.031542"
    },
    "893f367c987d653e": {
      "factor_id": "893f367c987d653e",
      "factor_name": "Gap_Stability_Ratio_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS($open / DELAY($close, 1) - 1) / (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Stability_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of the overnight gap to the intraday price range. A high value indicates that the price movement occurred primarily during non-trading hours and was maintained throughout the day with little intraday volatility, suggesting institutional conviction. It is normalized by the 10-day average intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.660769",
      "updated_at": "2026-01-17T02:46:39.660776"
    },
    "753627a010696eb7": {
      "factor_id": "753627a010696eb7",
      "factor_name": "Institutional_Gap_Persistence",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * (1 - ($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * (1 - ($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies days where the overnight gap is significant relative to historical intraday volatility, and the intraday range remains compressed. It uses a conditional logic to highlight 'gap and hold' patterns where the gap is at least 1.5 times the 5-day average intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.677132",
      "updated_at": "2026-01-17T02:46:39.677139"
    },
    "372da11902cb84e1": {
      "factor_id": "372da11902cb84e1",
      "factor_name": "Normalized_Overnight_Dominance",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Overnight_Dominance\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the dominance of the overnight return relative to the total daily range. It is cross-sectionally ranked to identify assets where the 'information gap' is the primary driver of the price trend compared to intraday noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between the overnight price gap and the subsequent intraday price movement, normalized by daily volatility, identifies information asymmetry where persistent overnight gaps followed by intraday price stability signal strong institutional conviction and future trend continuation.\n                Concise Observation: The parent strategy focused on price range compression (coiling), but failed to distinguish between range contraction caused by lack of interest and contraction caused by institutional price setting (gaps), which often leads to different momentum outcomes.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; if the intraday market does not 'fill' the gap despite high volume or normal volatility, it suggests that the initial price move was not an overreaction but a fundamental shift.\n                Concise Knowledge: If an asset opens with a significant gap that is not retraced during the trading day, it indicates that the information shock is being absorbed as a new value floor; when intraday volatility is low relative to the gap, the signal's reliability for trend persistence increases.\n                concise Specification: The factor will measure the ratio of the overnight return (Open_t / Close_{t-1}) to the intraday range (High - Low), specifically targeting days where the gap exceeds the 10-day average range while the intraday volatility remains below its 5-day mean.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "e96bc8d7b800",
      "parent_trajectory_ids": [
        "7ca5789e9bf2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0090954391297086,
        "ICIR": 0.0641704170563025,
        "RankIC": 0.0302589040004389,
        "RankICIR": 0.2145395508170902,
        "annualized_return": 0.0741220731269715,
        "information_ratio": 1.0365973046477746,
        "max_drawdown": -0.1131525381331313
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:39.694076",
      "updated_at": "2026-01-17T02:46:39.694082"
    },
    "79ca87965d5ce3c0": {
      "factor_id": "79ca87965d5ce3c0",
      "factor_name": "Amihud_Fragility_5D",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures short-term price fragility using the Amihud Illiquidity ratio (absolute return divided by volume), smoothed over a 5-day window. High values indicate price movements driven by low liquidity, which are expected to mean-revert.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.169842",
      "updated_at": "2026-01-17T02:46:43.169848"
    },
    "db3bb63c885516b0": {
      "factor_id": "db3bb63c885516b0",
      "factor_name": "Relative_Illiquidity_Shock_10D",
      "factor_expression": "ZSCORE((ABS($return) / ($volume + 1e-8)) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8) / TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Illiquidity_Shock_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the intensity of a liquidity shock by comparing the current daily price impact (absolute return/volume) to its 10-day historical average. A high ratio suggests an unsustainable price extension due to liquidity bottlenecks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.186993",
      "updated_at": "2026-01-17T02:46:43.186999"
    },
    "f2b1e3a9b86377a0": {
      "factor_id": "f2b1e3a9b86377a0",
      "factor_name": "Fragility_Momentum_Divergence_10D",
      "factor_expression": "RANK(TS_SUM($return, 10) * TS_RANK(ABS($return) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1), 10) * TS_RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Fragility_Momentum_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies cases where price trends are 'fragile' by multiplying the 10-day return by the time-series rank of the Amihud illiquidity ratio. High fragility during a price move signals a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: Short-term price fragility, measured by the ratio of absolute daily returns to trading volume (Amihud Illiquidity), predicts a mean-reversion effect where high-impact price movements driven by low liquidity tend to reverse in the subsequent period.\n                Concise Observation: While long-term momentum benefits from price-volume synchronization, short-term extreme price moves often lack volume support, leading to high 'price impact' scores that correlate negatively with next-day returns.\n                Concise Justification: The Amihud Illiquidity ratio captures the 'fragility' of the price; when the ratio is high, the asset is experiencing an illiquidity shock, suggesting that the current price level is unsustainable and likely to revert once liquidity stabilizes.\n                Concise Knowledge: If a significant price change occurs on low trading volume, it is likely a liquidity-driven 'noise' event rather than a fundamental 'information' event; such price extensions are prone to reversal as market makers provide liquidity to capture the spread.\n                concise Specification: The factor is defined as the absolute value of the 1-day percentage change in close price divided by the daily volume, potentially smoothed over a 5-day window to identify persistent liquidity bottlenecks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "b77475abf780",
      "parent_trajectory_ids": [
        "3b1e6adc972a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0069086710117074,
        "ICIR": 0.0450751797798768,
        "RankIC": 0.0235844754543806,
        "RankICIR": 0.1613659382664924,
        "annualized_return": 0.0701141774364177,
        "information_ratio": 0.9613711153037888,
        "max_drawdown": -0.0822860748333083
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:46:43.202044",
      "updated_at": "2026-01-17T02:46:43.202051"
    },
    "9238283d9d0fe1b6": {
      "factor_id": "9238283d9d0fe1b6",
      "factor_name": "Trend_Acceleration_Divergence_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Divergence_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term (5-day) and long-term (20-day) trend quality. It uses the square of the correlation between price and a time sequence (R-squared) to identify parabolic acceleration or trend exhaustion. A high positive value suggests recent linear intensification, while a sharp drop suggests structural breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.832266",
      "updated_at": "2026-01-17T02:49:16.832272"
    },
    "562897a0cf01e5f1": {
      "factor_id": "562897a0cf01e5f1",
      "factor_name": "ZScored_Linearity_Burst_5D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Linearity_Burst_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'linear burst' phenomenon by calculating the cross-sectional Z-score of the short-term (5-day) R-squared relative to its long-term (20-day) baseline. It highlights assets where the short-term trend consistency is significantly deviating from its historical linear stability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.847318",
      "updated_at": "2026-01-17T02:49:16.847323"
    },
    "5d04ffa211d8c42c": {
      "factor_id": "5d04ffa211d8c42c",
      "factor_name": "Trend_Consistency_Decay_Rate",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - TS_MEAN(POW(TS_CORR($close, SEQUENCE(5), 5), 2), 10)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Decay_Rate\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the decay in trend consistency by comparing the current 5-day R-squared to its 10-day moving average, normalized by the 20-day R-squared. This identifies assets where the 'linear consistency' is failing faster than the long-term trend would suggest, signaling potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between short-term (5-day) and long-term (20-day) price-time R-squared values, calculated as the difference between their respective coefficients of determination, predicts trend exhaustion or acceleration when the decay rate exceeds a specific standard deviation threshold.\n                Concise Observation: Financial time series often exhibit 'linear bursts' where price movement becomes highly correlated with time in the short run, but these phases are unsustainable and typically deviate from the longer-term trend stability metric (R-squared).\n                Concise Justification: R-squared measures the strength of a linear trend; by comparing a 5-day 'fast' R-squared with a 20-day 'slow' R-squared, we can quantify the 'acceleration' of the trend's quality, identifying overextended states before price reversals occur.\n                Concise Knowledge: If the short-term R-squared significantly exceeds the long-term R-squared, the price trend is likely entering a parabolic acceleration phase; conversely, if the short-term R-squared drops sharply while the long-term remains high, the trend is losing linear consistency and likely to mean-revert.\n                concise Specification: Calculate RSQR_5 and RSQR_20 using a linear regression of close prices against a time index; define the factor as (RSQR_5 - RSQR_20), where a high positive value indicates recent trend intensification and a negative value indicates structural trend breakdown.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "original",
      "trajectory_id": "47a391e715df",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0075452886259882,
        "ICIR": 0.0591997897151816,
        "RankIC": 0.0202007706325453,
        "RankICIR": 0.162718474675226,
        "annualized_return": 0.0725954848217306,
        "information_ratio": 1.1677538061740649,
        "max_drawdown": -0.0833676991346032
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:16.862200",
      "updated_at": "2026-01-17T02:49:16.862206"
    },
    "831b0bb79204fd79": {
      "factor_id": "831b0bb79204fd79",
      "factor_name": "Intraday_Efficiency_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Efficiency_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement over a 5-day window. It calculates the ratio of the absolute net intraday change to the total intraday range. A high ratio suggests that price movement is driven by persistent institutional flow rather than volatile noise, indicating a stronger likelihood of trend continuation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.532447",
      "updated_at": "2026-01-17T03:54:30.979215"
    },
    "8afb1882b81bac5e": {
      "factor_id": "8afb1882b81bac5e",
      "factor_name": "Efficiency_Adjusted_Momentum_10D",
      "factor_expression": "TS_MEAN(RANK(SIGN($close - $open) * (ABS($close - $open) / ($high - $low + 1e-8))), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK(SIGN($close - $open) * (ABS($close - $open) / ($high - $low + 1e-8))), 10)\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the intraday price efficiency with the direction of the price move. By multiplying the sign of the daily return by the efficiency ratio, it identifies days where price moved decisively in one direction. It is then cross-sectionally ranked and smoothed over 10 days to identify stocks with consistent institutional accumulation or distribution.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price Range Efficiency factor, defined as the ratio of the daily price displacement (Close - Open) to the total daily price range (High - Low), predicts short-term trend persistence by distinguishing between directed institutional flows and high-entropy retail noise.\n                Concise Observation: Daily volume volatility metrics capture liquidity shocks but ignore the 'shape' of price action; often, stocks with similar daily returns exhibit vastly different intraday volatility profiles (efficiency vs. noise).\n                Concise Justification: A high displacement-to-range ratio indicates strong conviction and low resistance in price movement, suggesting institutional accumulation, whereas a low ratio indicates high-frequency 'churn' and lack of directional consensus.\n                Concise Knowledge: If the price displacement is a large fraction of the total daily range, the market is processing information efficiently in a single direction; when the range is large but the net displacement is small, the price path is inefficient and prone to reversal.\n                concise Specification: The factor is calculated as (ABS($close - $open) / ($high - $low + 1e-8)) smoothed over a 5-day window to capture persistent intraday efficiency trends, expected to correlate positively with next-day returns.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "c682652a1743",
      "parent_trajectory_ids": [
        "dcffecfc2bac"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050534531140359,
        "ICIR": 0.0346235292495759,
        "RankIC": 0.0221182072026201,
        "RankICIR": 0.1519411893480342,
        "annualized_return": 0.0355549437763706,
        "information_ratio": 0.525952478763076,
        "max_drawdown": -0.1038771064595254
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.558100",
      "updated_at": "2026-01-17T02:49:18.558108"
    },
    "2a583ee1ec243c76": {
      "factor_id": "2a583ee1ec243c76",
      "factor_name": "Relative_Efficiency_Volatility_ZScore",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Relative_Efficiency_Volatility_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the current intraday efficiency relative to its own history using a Z-score. It identifies periods where the price action becomes significantly more 'efficient' (directional) than usual, which often precedes a breakout. A high Z-score suggests a sudden shift from retail noise to institutional conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Price Range Efficiency factor, defined as the ratio of the daily price displacement (Close - Open) to the total daily price range (High - Low), predicts short-term trend persistence by distinguishing between directed institutional flows and high-entropy retail noise.\n                Concise Observation: Daily volume volatility metrics capture liquidity shocks but ignore the 'shape' of price action; often, stocks with similar daily returns exhibit vastly different intraday volatility profiles (efficiency vs. noise).\n                Concise Justification: A high displacement-to-range ratio indicates strong conviction and low resistance in price movement, suggesting institutional accumulation, whereas a low ratio indicates high-frequency 'churn' and lack of directional consensus.\n                Concise Knowledge: If the price displacement is a large fraction of the total daily range, the market is processing information efficiently in a single direction; when the range is large but the net displacement is small, the price path is inefficient and prone to reversal.\n                concise Specification: The factor is calculated as (ABS($close - $open) / ($high - $low + 1e-8)) smoothed over a 5-day window to capture persistent intraday efficiency trends, expected to correlate positively with next-day returns.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "c682652a1743",
      "parent_trajectory_ids": [
        "dcffecfc2bac"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050534531140359,
        "ICIR": 0.0346235292495759,
        "RankIC": 0.0221182072026201,
        "RankICIR": 0.1519411893480342,
        "annualized_return": 0.0355549437763706,
        "information_ratio": 0.525952478763076,
        "max_drawdown": -0.1038771064595254
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:49:18.581565",
      "updated_at": "2026-01-17T02:49:18.581571"
    },
    "d3139593c4bced5b": {
      "factor_id": "d3139593c4bced5b",
      "factor_name": "Institutional_Support_Gap_Factor_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($return, 20) + 1e-8)) * TS_MEAN(($low - $low) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "",
      "factor_description": "This factor identifies high-conviction trends by multiplying the volatility-normalized overnight gap with the 5-day moving average of the intraday support ratio. The overnight gap captures information asymmetry, while the intraday support (relative position of the low within the high-low range) validates institutional floor-setting.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of the volatility-normalized overnight gap and the 5-day moving average of the ratio between the daily low and the daily range (high-low) identifies high-conviction institutional trends where overnight information is validated by intraday structural support.\n                Concise Observation: Parent 1 showed that intraday support (low/range) has predictive power (RankIC 0.0256), while Parent 2 showed that normalized overnight gaps capture information asymmetry (RankIC 0.0303); however, each alone may capture noise or temporary spikes without cross-temporal confirmation.\n                Concise Justification: The overnight gap represents the market's reaction to new information, while the relative position of the daily low represents the persistence of buying pressure throughout the session; multiplying these ensures that only gaps with sustained intraday support are signaled as high-quality entries.\n                Concise Knowledge: If an overnight price gap is followed by a high relative daily low (low price near the high price relative to the range), it indicates institutional floor-setting; when these two signals are combined multiplicatively, they filter for high-conviction momentum and reduce the risk of exhaustion gaps.\n                concise Specification: The factor is defined as ((Open_t - Close_{t-1}) / StdDev(Returns, 20)) * SMA((Low_t - Low_t) / (High_t - Low_t + epsilon), 5), where the first term captures the normalized gap and the second term captures the 5-day smoothed intraday support persistence.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "59eff6c582b9",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042283937066098,
        "ICIR": 0.0313094228775075,
        "RankIC": 0.0181419910093354,
        "RankICIR": 0.1348464607506115,
        "annualized_return": 0.0839854243634816,
        "information_ratio": 1.1324999228391175,
        "max_drawdown": -0.0954403690053182
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:51:24.820705",
      "updated_at": "2026-01-17T02:51:24.820714"
    },
    "b68696acd91fe1a8": {
      "factor_id": "b68696acd91fe1a8",
      "factor_name": "Cross_Temporal_Conviction_Rank_Factor",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 20) + 1e-8)) * RANK(TS_MEAN(($high - $low) / ($close - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 20) + 1e-8)) * RANK(TS_MEAN(($high - $low) / ($close - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Cross_Temporal_Conviction_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction hypothesis. It combines the rank of the overnight gap (normalized by ATR-like range) with the rank of the 5-day smoothed intraday price floor. This reduces the impact of outliers in raw return volatility while maintaining the logic of institutional validation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of the volatility-normalized overnight gap and the 5-day moving average of the ratio between the daily low and the daily range (high-low) identifies high-conviction institutional trends where overnight information is validated by intraday structural support.\n                Concise Observation: Parent 1 showed that intraday support (low/range) has predictive power (RankIC 0.0256), while Parent 2 showed that normalized overnight gaps capture information asymmetry (RankIC 0.0303); however, each alone may capture noise or temporary spikes without cross-temporal confirmation.\n                Concise Justification: The overnight gap represents the market's reaction to new information, while the relative position of the daily low represents the persistence of buying pressure throughout the session; multiplying these ensures that only gaps with sustained intraday support are signaled as high-quality entries.\n                Concise Knowledge: If an overnight price gap is followed by a high relative daily low (low price near the high price relative to the range), it indicates institutional floor-setting; when these two signals are combined multiplicatively, they filter for high-conviction momentum and reduce the risk of exhaustion gaps.\n                concise Specification: The factor is defined as ((Open_t - Close_{t-1}) / StdDev(Returns, 20)) * SMA((Low_t - Low_t) / (High_t - Low_t + epsilon), 5), where the first term captures the normalized gap and the second term captures the 5-day smoothed intraday support persistence.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "59eff6c582b9",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042283937066098,
        "ICIR": 0.0313094228775075,
        "RankIC": 0.0181419910093354,
        "RankICIR": 0.1348464607506115,
        "annualized_return": 0.0839854243634816,
        "information_ratio": 1.1324999228391175,
        "max_drawdown": -0.0954403690053182
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:51:24.848095",
      "updated_at": "2026-01-17T02:51:24.848103"
    },
    "3167fd05ab02177c": {
      "factor_id": "3167fd05ab02177c",
      "factor_name": "ZScore_Gap_Support_Interaction",
      "factor_expression": "ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Gap_Support_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a Z-score to the overnight gap and the intraday support ratio independently before multiplication. This ensures that the two components have equal weight in the final signal, identifying stocks where both the overnight reaction and intraday price action are statistically significant relative to the cross-section.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of the volatility-normalized overnight gap and the 5-day moving average of the ratio between the daily low and the daily range (high-low) identifies high-conviction institutional trends where overnight information is validated by intraday structural support.\n                Concise Observation: Parent 1 showed that intraday support (low/range) has predictive power (RankIC 0.0256), while Parent 2 showed that normalized overnight gaps capture information asymmetry (RankIC 0.0303); however, each alone may capture noise or temporary spikes without cross-temporal confirmation.\n                Concise Justification: The overnight gap represents the market's reaction to new information, while the relative position of the daily low represents the persistence of buying pressure throughout the session; multiplying these ensures that only gaps with sustained intraday support are signaled as high-quality entries.\n                Concise Knowledge: If an overnight price gap is followed by a high relative daily low (low price near the high price relative to the range), it indicates institutional floor-setting; when these two signals are combined multiplicatively, they filter for high-conviction momentum and reduce the risk of exhaustion gaps.\n                concise Specification: The factor is defined as ((Open_t - Close_{t-1}) / StdDev(Returns, 20)) * SMA((Low_t - Low_t) / (High_t - Low_t + epsilon), 5), where the first term captures the normalized gap and the second term captures the 5-day smoothed intraday support persistence.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "59eff6c582b9",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042283937066098,
        "ICIR": 0.0313094228775075,
        "RankIC": 0.0181419910093354,
        "RankICIR": 0.1348464607506115,
        "annualized_return": 0.0839854243634816,
        "information_ratio": 1.1324999228391175,
        "max_drawdown": -0.0954403690053182
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:51:24.873746",
      "updated_at": "2026-01-17T02:51:24.873753"
    },
    "3cd6d15d89224ff5": {
      "factor_id": "3cd6d15d89224ff5",
      "factor_name": "Relative_Intraday_Intensity_20D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the current day's price range to the 20-day Average True Range (ATR). It identifies stocks with abnormal intraday volatility relative to their historical baseline, normalized for cross-sectional comparison.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:07.993363",
      "updated_at": "2026-01-17T02:52:07.993370"
    },
    "366a311d0a63e223": {
      "factor_id": "366a311d0a63e223",
      "factor_name": "Volatility_Adjusted_Range_Shock_10D",
      "factor_expression": "RANK((($high - $low) / $close) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / $close) / TS_STD(TS_PCTCHANGE($close, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Range_Shock_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the intraday intensity factor that uses a 10-day rolling standard deviation of returns to normalize the daily range-to-price ratio, highlighting price shocks relative to recent volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.010514",
      "updated_at": "2026-01-17T02:52:08.010520"
    },
    "9a62de12186c88c7": {
      "factor_id": "9a62de12186c88c7",
      "factor_name": "Relative_Range_ZScore_20D",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 20))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the time-series Z-score of the daily price range over a 20-day window. It identifies how many standard deviations the current day's range is from its recent mean, providing a unit-less measure of trading intensity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Relative Intraday Intensity factor, defined as the ratio of the daily price range (High - Low) to its 20-day Average True Range (ATR), predicts future returns by identifying stocks with abnormal intraday volatility relative to their historical baseline.\n                Concise Observation: Raw intraday ranges (High - Low) are heavily biased by price levels and inherent stock volatility, making cross-sectional comparisons difficult across diverse market segments.\n                Concise Justification: Normalizing the daily range by the 20-day ATR converts a nominal price spread into a unit-less volatility score, allowing the model to distinguish between routine price movement and significant trading intensity that often precedes trend reversals or continuations.\n                Concise Knowledge: If a stock's current intraday price range is normalized by its historical volatility (ATR), the resulting ratio identifies liquidity-adjusted price shocks; when this ratio is high, it signals significant information arrival or liquidity pressure regardless of the stock's absolute price level.\n                concise Specification: The factor is calculated as (High - Low) divided by the 20-day moving average of the True Range (max(H-L, abs(H-Cp), abs(L-Cp))), focusing on the cross-sectional ranking of this ratio to predict next-day returns.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "original",
      "trajectory_id": "be4e1d055d38",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071669641452989,
        "ICIR": 0.0496265311112702,
        "RankIC": 0.0290910142410575,
        "RankICIR": 0.1996712028648894,
        "annualized_return": 0.0882720304711901,
        "information_ratio": 1.277805290657817,
        "max_drawdown": -0.1184123868650801
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:08.026105",
      "updated_at": "2026-01-17T02:52:08.026110"
    },
    "7edeac1299d5ec7a": {
      "factor_id": "7edeac1299d5ec7a",
      "factor_name": "Price_Efficiency_Ratio_10D",
      "factor_expression": "ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Price_Efficiency_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates Kaufman's Efficiency Ratio over a 10-day window. It measures the net price change relative to the total path traveled (sum of absolute daily returns). Low values indicate high noise and potential for mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.094020",
      "updated_at": "2026-01-17T02:52:25.094027"
    },
    "6f61aa0cb607231a": {
      "factor_id": "6f61aa0cb607231a",
      "factor_name": "Efficiency_Adjusted_Volatility_Rank",
      "factor_expression": "RANK(TS_SUM(ABS(DELTA($close, 1)), 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(ABS(DELTA($close, 1)), 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Volatility_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the Efficiency Ratio with cross-sectional ranking to identify assets that are moving significantly but with high 'noise' (low efficiency). It ranks the inverse of the 10-day Efficiency Ratio to highlight mean-reversion candidates.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.110271",
      "updated_at": "2026-01-17T02:52:25.110276"
    },
    "a68abefcaf887ab0": {
      "factor_id": "a68abefcaf887ab0",
      "factor_name": "Noise_Filtered_Return_Reversion",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 10) / (ABS(DELTA($close, 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Noise_Filtered_Return_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that identifies stocks with high daily variance (high-low range) but low net directional movement over 10 days. It uses the ratio of 10-day range sum to net displacement, standardized by Z-score.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Price Efficiency Ratio (ER), defined as the net price change over a 10-day window divided by the sum of absolute daily price changes, serves as a proxy for liquidity depth where low efficiency values indicate high microstructure noise and a high probability of short-term mean reversion.\n                Concise Observation: While the parent strategy focused on volume-confirmed trends in high-volatility regimes, many assets exhibit 'jagged' price action where large cumulative movement is absent despite high daily variance, suggesting a different alpha source in price path smoothness.\n                Concise Justification: The Efficiency Ratio (Kaufman's Efficiency Ratio) distinguishes between 'directional' volatility and 'noise' volatility; assets with high noise (low ER) often suffer from over-extension and lack institutional trend support, making them prime candidates for reversal.\n                Concise Knowledge: If a price path is highly 'noisy' (low Efficiency Ratio), it indicates a lack of trend conviction and dominant liquidity-providing behavior; When the Efficiency Ratio is low, the asset is more likely to mean-revert as temporary imbalances are absorbed by market makers.\n                concise Specification: The factor is calculated as the absolute difference between the current close and the close 10 days ago, divided by the 10-day sum of the absolute daily returns (high-low range or close-to-close), constrained to a [0, 1] scale where values near 0 trigger mean-reversion signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "c4f0ba54b891",
      "parent_trajectory_ids": [
        "790b0c692f1a"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056537854318725,
        "ICIR": 0.0424597166185202,
        "RankIC": 0.0214688887336841,
        "RankICIR": 0.1647431768730618,
        "annualized_return": 0.0883915789085356,
        "information_ratio": 1.340525051333144,
        "max_drawdown": -0.0829573248921807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:52:25.127010",
      "updated_at": "2026-01-17T02:52:25.127016"
    },
    "99c155b7b71f606d": {
      "factor_id": "99c155b7b71f606d",
      "factor_name": "VW_Efficiency_Ratio_5D",
      "factor_expression": "(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (TS_MEAN($volume * $close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (TS_MEAN($volume * $close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the 5-day Volume-Weighted Efficiency Ratio. It measures the directness of price movement (displacement divided by total path traveled) normalized by the 5-day volume-weighted average price. High efficiency with high volume suggests trend persistence, while low efficiency or low volume suggests potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.137121",
      "updated_at": "2026-01-17T02:55:13.137128"
    },
    "8f46483ca3e55e78": {
      "factor_id": "8f46483ca3e55e78",
      "factor_name": "Path_Efficiency_Liquidity_Rank_5D",
      "factor_expression": "RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) + 1e-8)) / (RANK(TS_MEAN($volume, 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Path_Efficiency_Liquidity_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency ratio that focuses on the cross-sectional rank of path efficiency (displacement over total range) adjusted by the rank of volume intensity. It identifies assets where price moves are 'efficient' relative to the liquidity provided, targeting mean-reversion when efficiency is extreme.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.153925",
      "updated_at": "2026-01-17T02:55:13.153932"
    },
    "0a7f905fc3df233d": {
      "factor_id": "0a7f905fc3df233d",
      "factor_name": "Efficiency_Volatility_Adj_5D",
      "factor_expression": "ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) * TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(DELTA($close, 5)) / (TS_SUM($high - $low, 5) * TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Adj_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day price displacement relative to the cumulative high-low range, further adjusted by the 5-day price volatility (Standard Deviation). It aims to isolate high-conviction trends from noisy, high-volatility price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day Volume-Weighted Efficiency Ratio, defined as the absolute price displacement over 5 days divided by the 5-day sum of high-low ranges and further normalized by the 5-day volume-weighted moving average, predicts mean-reversion in asset returns.\n                Concise Observation: Price trends often exhibit different reliability based on the 'path efficiency' (displacement vs. total travel) and the liquidity (volume) supporting that path.\n                Concise Justification: Dividing displacement by the sum of daily ranges (KLEN) measures the directness of a move, while the WVMA adjustment scales this efficiency by the relative conviction of market participants.\n                Concise Knowledge: If an asset's price movement is achieved with low internal volatility and high volume support, the trend is sustainable; conversely, if high volatility and low volume accompany price displacement, the movement is likely exhaustive and prone to reversal.\n                concise Specification: Calculate the ratio of absolute change in $close over 5 days to the sum of ($high - $low) over the same 5 days, then divide by the 5-day average of ($volume * $close) to generate a static factor for cross-sectional ranking.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "original",
      "trajectory_id": "11691c5035cc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034145795416669,
        "ICIR": 0.0259139006114787,
        "RankIC": 0.0182915707782814,
        "RankICIR": 0.1428004926748366,
        "annualized_return": 0.0229248076613,
        "information_ratio": 0.3578659439711098,
        "max_drawdown": -0.1182143420395976
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:55:13.170470",
      "updated_at": "2026-01-17T02:55:13.170476"
    },
    "1899c2c6dcf66161": {
      "factor_id": "1899c2c6dcf66161",
      "factor_name": "Institutional_Exhaustion_Reversal_10D",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN($return * $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN(TS_PCTCHANGE($close, 1) * $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price-volume exhaustion by calculating the difference between the rank of 10-day price returns and the rank of 10-day volume-weighted momentum, then scales it by the ratio of the absolute overnight gap to the 10-day Average True Range (ATR). A high value indicates institutional-driven price movement (gaps) that lacks broad volume support, signaling a potential reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between 10-day price-volume trend divergence and the overnight-to-intraday volatility ratio identifies high-conviction institutional reversals: specifically, when the 10-day price change rank significantly exceeds the 10-day volume-weighted momentum rank (exhaustion) and is accompanied by a high ratio of overnight gap to intraday range (institutional persistence), a strong short-term mean reversion signal is generated.\n                Concise Observation: Parent 1 (RankIC=0.0239) identifies price-volume exhaustion but suffers from false positives in trending markets, while Parent 2 (RankIC=0.0303) captures institutional conviction via overnight gaps; combining them addresses the weakness of simple divergence by filtering for periods where 'smart money' positioning (gaps) is no longer supported by broad market participation (volume).\n                Concise Justification: Institutional investors often express conviction through overnight gaps, but if the subsequent intraday volume does not support the price level (divergence), it indicates a liquidity trap or exhaustion; normalizing this divergence by the 10-day volatility (ATR) ensures the signal is statistically significant relative to recent market noise.\n                Concise Knowledge: If a price trend exhibits volume exhaustion while being driven primarily by overnight gaps rather than intraday volatility, then the price movement is likely driven by institutional positioning that is reaching a pivot point; when these two conditions coincide, the probability of a sharp mean reversion increases as retail liquidity fails to support the overnight-driven price levels.\n                concise Specification: The factor is defined as the product of (Rank(10-day Price Change) - Rank(10-day Volume-Weighted Momentum)) and the ratio of the absolute overnight gap (Open - Prev Close) to the 10-day Average True Range (ATR), calculated over a rolling 10-day window to capture the synergy between technical exhaustion and institutional conviction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "28f4f15fa7ae",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060657229275013,
        "ICIR": 0.0459182625566494,
        "RankIC": 0.0227499884792698,
        "RankICIR": 0.1769188524920405,
        "annualized_return": 0.0642299835943654,
        "information_ratio": 0.9625429890624204,
        "max_drawdown": -0.1000745294164307
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:56:53.017098",
      "updated_at": "2026-01-17T02:56:53.017108"
    },
    "aa6a513aa02a7c83": {
      "factor_id": "aa6a513aa02a7c83",
      "factor_name": "Gap_Persistence_Exhaustion_Index",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN($return * $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN(TS_PCTCHANGE($close, 1) * $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Persistence_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional reversals by multiplying the divergence between price momentum and volume-weighted returns with the standardized overnight gap. The gap is normalized by the 10-day price volatility to ensure the signal is significant relative to recent noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between 10-day price-volume trend divergence and the overnight-to-intraday volatility ratio identifies high-conviction institutional reversals: specifically, when the 10-day price change rank significantly exceeds the 10-day volume-weighted momentum rank (exhaustion) and is accompanied by a high ratio of overnight gap to intraday range (institutional persistence), a strong short-term mean reversion signal is generated.\n                Concise Observation: Parent 1 (RankIC=0.0239) identifies price-volume exhaustion but suffers from false positives in trending markets, while Parent 2 (RankIC=0.0303) captures institutional conviction via overnight gaps; combining them addresses the weakness of simple divergence by filtering for periods where 'smart money' positioning (gaps) is no longer supported by broad market participation (volume).\n                Concise Justification: Institutional investors often express conviction through overnight gaps, but if the subsequent intraday volume does not support the price level (divergence), it indicates a liquidity trap or exhaustion; normalizing this divergence by the 10-day volatility (ATR) ensures the signal is statistically significant relative to recent market noise.\n                Concise Knowledge: If a price trend exhibits volume exhaustion while being driven primarily by overnight gaps rather than intraday volatility, then the price movement is likely driven by institutional positioning that is reaching a pivot point; when these two conditions coincide, the probability of a sharp mean reversion increases as retail liquidity fails to support the overnight-driven price levels.\n                concise Specification: The factor is defined as the product of (Rank(10-day Price Change) - Rank(10-day Volume-Weighted Momentum)) and the ratio of the absolute overnight gap (Open - Prev Close) to the 10-day Average True Range (ATR), calculated over a rolling 10-day window to capture the synergy between technical exhaustion and institutional conviction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "28f4f15fa7ae",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060657229275013,
        "ICIR": 0.0459182625566494,
        "RankIC": 0.0227499884792698,
        "RankICIR": 0.1769188524920405,
        "annualized_return": 0.0642299835943654,
        "information_ratio": 0.9625429890624204,
        "max_drawdown": -0.1000745294164307
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:56:53.054057",
      "updated_at": "2026-01-17T02:56:53.054068"
    },
    "444528a6f249f730": {
      "factor_id": "444528a6f249f730",
      "factor_name": "Institutional_Divergence_V3",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN($return, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN(TS_PCTCHANGE($close, 1), 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Divergence_V3\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the institutional conviction hypothesis focusing on the interaction between price-volume divergence and the overnight gap relative to the intraday range. It uses the 10-day median to smooth the volatility denominator for robustness against outliers.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between 10-day price-volume trend divergence and the overnight-to-intraday volatility ratio identifies high-conviction institutional reversals: specifically, when the 10-day price change rank significantly exceeds the 10-day volume-weighted momentum rank (exhaustion) and is accompanied by a high ratio of overnight gap to intraday range (institutional persistence), a strong short-term mean reversion signal is generated.\n                Concise Observation: Parent 1 (RankIC=0.0239) identifies price-volume exhaustion but suffers from false positives in trending markets, while Parent 2 (RankIC=0.0303) captures institutional conviction via overnight gaps; combining them addresses the weakness of simple divergence by filtering for periods where 'smart money' positioning (gaps) is no longer supported by broad market participation (volume).\n                Concise Justification: Institutional investors often express conviction through overnight gaps, but if the subsequent intraday volume does not support the price level (divergence), it indicates a liquidity trap or exhaustion; normalizing this divergence by the 10-day volatility (ATR) ensures the signal is statistically significant relative to recent market noise.\n                Concise Knowledge: If a price trend exhibits volume exhaustion while being driven primarily by overnight gaps rather than intraday volatility, then the price movement is likely driven by institutional positioning that is reaching a pivot point; when these two conditions coincide, the probability of a sharp mean reversion increases as retail liquidity fails to support the overnight-driven price levels.\n                concise Specification: The factor is defined as the product of (Rank(10-day Price Change) - Rank(10-day Volume-Weighted Momentum)) and the ratio of the absolute overnight gap (Open - Prev Close) to the 10-day Average True Range (ATR), calculated over a rolling 10-day window to capture the synergy between technical exhaustion and institutional conviction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "28f4f15fa7ae",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060657229275013,
        "ICIR": 0.0459182625566494,
        "RankIC": 0.0227499884792698,
        "RankICIR": 0.1769188524920405,
        "annualized_return": 0.0642299835943654,
        "information_ratio": 0.9625429890624204,
        "max_drawdown": -0.1000745294164307
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:56:53.081144",
      "updated_at": "2026-01-17T02:56:53.081150"
    },
    "448e07a57835204d": {
      "factor_id": "448e07a57835204d",
      "factor_name": "Exhaustion_Stealth_Reversal_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * TS_MEAN(($high - $low) / ($volume + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * TS_MEAN(($high - $low) / ($volume + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Stealth_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures mean-reversion opportunities by identifying price-volume exhaustion (negative correlation) and stealth institutional accumulation (low range-to-volume ratio) specifically within a 60-day downward momentum regime.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The fusion of medium-term price exhaustion and micro-structural stealth accumulation, measured by the interaction of a 20-day negative price-volume correlation and a 10-day range-to-volume efficiency ratio within a 60-day downward momentum regime, predicts superior mean-reversal returns.\n                Concise Observation: Parent 1 successfully identified oversold regimes (RankIC 0.029) while Parent 2 captured subtle institutional footprints (RankIC 0.026); however, both likely suffer from false signals during continuous liquidations or low-volatility drifts.\n                Concise Justification: Combining macro-regime filters with micro-execution metrics ensures that mean-reversion trades are only entered when 'stealth' buying behavior stabilizes the price range, filtering out falling knives that lack institutional support.\n                Concise Knowledge: If an asset exhibits negative price-volume correlation during a significant downtrend, it indicates selling exhaustion; when this coincides with a decreasing ratio of daily price range to volume, it signals institutional absorption of liquidity and an imminent trend reversal.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation (Price, Volume) and the 10-day average of (High-Low)/Volume, conditioned on the 60-day price change being in the bottom quintile of the cross-section.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5e5e3ce55591",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0027254100469313,
        "ICIR": 0.0196622782725537,
        "RankIC": 0.0181251384351378,
        "RankICIR": 0.1276285485652918,
        "annualized_return": 0.0496725864195166,
        "information_ratio": 0.6727011235559099,
        "max_drawdown": -0.139122733193392
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:58:02.132785",
      "updated_at": "2026-01-17T02:58:02.132792"
    },
    "bd57f3aa96b263e1": {
      "factor_id": "bd57f3aa96b263e1",
      "factor_name": "Stealth_Accumulation_ZScore_60D",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) * SIGN(TS_CORR($close, $volume, 20)) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) * SIGN(TS_CORR($close, $volume, 20)) * (RANK(TS_PCTCHANGE($close, 60)) < 0.2 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_ZScore_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis that focuses on the Z-score of range efficiency during price-volume divergence. It targets assets where the current range-to-volume ratio is significantly lower than its 20-day average, conditioned on being in a 60-day oversold state.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The fusion of medium-term price exhaustion and micro-structural stealth accumulation, measured by the interaction of a 20-day negative price-volume correlation and a 10-day range-to-volume efficiency ratio within a 60-day downward momentum regime, predicts superior mean-reversal returns.\n                Concise Observation: Parent 1 successfully identified oversold regimes (RankIC 0.029) while Parent 2 captured subtle institutional footprints (RankIC 0.026); however, both likely suffer from false signals during continuous liquidations or low-volatility drifts.\n                Concise Justification: Combining macro-regime filters with micro-execution metrics ensures that mean-reversion trades are only entered when 'stealth' buying behavior stabilizes the price range, filtering out falling knives that lack institutional support.\n                Concise Knowledge: If an asset exhibits negative price-volume correlation during a significant downtrend, it indicates selling exhaustion; when this coincides with a decreasing ratio of daily price range to volume, it signals institutional absorption of liquidity and an imminent trend reversal.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation (Price, Volume) and the 10-day average of (High-Low)/Volume, conditioned on the 60-day price change being in the bottom quintile of the cross-section.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5e5e3ce55591",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0027254100469313,
        "ICIR": 0.0196622782725537,
        "RankIC": 0.0181251384351378,
        "RankICIR": 0.1276285485652918,
        "annualized_return": 0.0496725864195166,
        "information_ratio": 0.6727011235559099,
        "max_drawdown": -0.139122733193392
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:58:02.149372",
      "updated_at": "2026-01-17T02:58:02.149378"
    },
    "d35a7b785dbdb688": {
      "factor_id": "d35a7b785dbdb688",
      "factor_name": "Efficiency_Exhaustion_Combo",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) + RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) + RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Exhaustion_Combo\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 20-day price-volume correlation with the 10-day range efficiency, normalized by cross-sectional rank, to identify stocks where selling pressure is high but price movement is narrowing, suggesting a floor.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The fusion of medium-term price exhaustion and micro-structural stealth accumulation, measured by the interaction of a 20-day negative price-volume correlation and a 10-day range-to-volume efficiency ratio within a 60-day downward momentum regime, predicts superior mean-reversal returns.\n                Concise Observation: Parent 1 successfully identified oversold regimes (RankIC 0.029) while Parent 2 captured subtle institutional footprints (RankIC 0.026); however, both likely suffer from false signals during continuous liquidations or low-volatility drifts.\n                Concise Justification: Combining macro-regime filters with micro-execution metrics ensures that mean-reversion trades are only entered when 'stealth' buying behavior stabilizes the price range, filtering out falling knives that lack institutional support.\n                Concise Knowledge: If an asset exhibits negative price-volume correlation during a significant downtrend, it indicates selling exhaustion; when this coincides with a decreasing ratio of daily price range to volume, it signals institutional absorption of liquidity and an imminent trend reversal.\n                concise Specification: The factor is defined as the product of the 20-day Pearson correlation (Price, Volume) and the 10-day average of (High-Low)/Volume, conditioned on the 60-day price change being in the bottom quintile of the cross-section.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5e5e3ce55591",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0027254100469313,
        "ICIR": 0.0196622782725537,
        "RankIC": 0.0181251384351378,
        "RankICIR": 0.1276285485652918,
        "annualized_return": 0.0496725864195166,
        "information_ratio": 0.6727011235559099,
        "max_drawdown": -0.139122733193392
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T02:58:02.165686",
      "updated_at": "2026-01-17T02:58:02.165692"
    },
    "c2e2a187a71a6e4a": {
      "factor_id": "c2e2a187a71a6e4a",
      "factor_name": "Volatility_Adjusted_Gap_Reversion_5D",
      "factor_expression": "($close - TS_MEAN($close, 5)) / (TS_STD($return, 5) + 1e-8) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - TS_MEAN($close, 5)) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by scaling price residuals by volatility and weighting them with the inverse of the overnight-to-intraday gap ratio. A high gap ratio suggests institutional conviction, which filters out trend breakouts, while a low gap ratio identifies noise-driven deviations prone to reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 5-day volatility-adjusted price residual (RESI5/STD5) and the 5-day average overnight-to-intraday gap ratio (GAP_RATIO) identifies high-probability mean-reversion entries by filtering out institutional-driven breakouts.\n                Concise Observation: Parent 1 (RankIC=0.0228) struggles with 'value traps' during strong trends, while Parent 2 (RankIC=0.0303) effectively distinguishes between institutional conviction and retail noise through overnight price gaps.\n                Concise Justification: By conditioning the mean-reversion signal (RESI5/STD5) on a measure of institutional conviction (Overnight Gap / Daily Range), we can isolate mean-reversion opportunities to environments where price extremes lack structural support.\n                Concise Knowledge: If a short-term price deviation is accompanied by low overnight gap persistence, it is likely noise-driven and prone to mean reversion; conversely, if the deviation is supported by high overnight conviction, it signals a structural trend breakout.\n                concise Specification: Define RESI5 as (Close - Mean(Close, 5)), STD5 as the 5-day daily return standard deviation, and GAP_RATIO as the 5-day average of (abs(Open - PrevClose) / (High - Low)). The final factor is RESI5 / STD5 * (1 - GAP_RATIO).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "cff31d942462",
      "parent_trajectory_ids": [
        "534d813fed12",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038223203757825,
        "ICIR": 0.0265310893241041,
        "RankIC": 0.0198615195554917,
        "RankICIR": 0.1406405073269134,
        "annualized_return": 0.0572091069734403,
        "information_ratio": 0.7586299454893467,
        "max_drawdown": -0.1096029180672807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:01:26.247687",
      "updated_at": "2026-01-17T03:01:26.247699"
    },
    "b96d59388def39d7": {
      "factor_id": "b96d59388def39d7",
      "factor_name": "Institutional_Filtered_Residual_ZScore_5D",
      "factor_expression": "TS_ZSCORE($close - TS_MEAN($close, 5), 5) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / (ABS($close - $open) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close - TS_MEAN($close, 5), 5) * (1 - TS_MEAN(ABS($open - DELAY($close, 1)) / (ABS($close - $open) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Filtered_Residual_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined mean-reversion factor that uses the Z-score of price residuals adjusted by the relative magnitude of overnight gaps. It targets stocks where recent price movements are extreme relative to historical volatility but lack the 'gap' signature of institutional accumulation or distribution.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 5-day volatility-adjusted price residual (RESI5/STD5) and the 5-day average overnight-to-intraday gap ratio (GAP_RATIO) identifies high-probability mean-reversion entries by filtering out institutional-driven breakouts.\n                Concise Observation: Parent 1 (RankIC=0.0228) struggles with 'value traps' during strong trends, while Parent 2 (RankIC=0.0303) effectively distinguishes between institutional conviction and retail noise through overnight price gaps.\n                Concise Justification: By conditioning the mean-reversion signal (RESI5/STD5) on a measure of institutional conviction (Overnight Gap / Daily Range), we can isolate mean-reversion opportunities to environments where price extremes lack structural support.\n                Concise Knowledge: If a short-term price deviation is accompanied by low overnight gap persistence, it is likely noise-driven and prone to mean reversion; conversely, if the deviation is supported by high overnight conviction, it signals a structural trend breakout.\n                concise Specification: Define RESI5 as (Close - Mean(Close, 5)), STD5 as the 5-day daily return standard deviation, and GAP_RATIO as the 5-day average of (abs(Open - PrevClose) / (High - Low)). The final factor is RESI5 / STD5 * (1 - GAP_RATIO).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "cff31d942462",
      "parent_trajectory_ids": [
        "534d813fed12",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038223203757825,
        "ICIR": 0.0265310893241041,
        "RankIC": 0.0198615195554917,
        "RankICIR": 0.1406405073269134,
        "annualized_return": 0.0572091069734403,
        "information_ratio": 0.7586299454893467,
        "max_drawdown": -0.1096029180672807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:01:26.282544",
      "updated_at": "2026-01-17T03:01:26.282556"
    },
    "608c0ddaa346a1a1": {
      "factor_id": "608c0ddaa346a1a1",
      "factor_name": "Gap_Conditioned_Mean_Reversion_Rank",
      "factor_expression": "RANK(($close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)) * RANK(1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)) * RANK(1 - TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Gap_Conditioned_Mean_Reversion_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor cross-sectionally ranks the interaction between short-term price exhaustion (measured by the 5-day price residual) and the absence of strong overnight price gaps, aiming to capture high-probability mean-reversion entries in the cross-section.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 5-day volatility-adjusted price residual (RESI5/STD5) and the 5-day average overnight-to-intraday gap ratio (GAP_RATIO) identifies high-probability mean-reversion entries by filtering out institutional-driven breakouts.\n                Concise Observation: Parent 1 (RankIC=0.0228) struggles with 'value traps' during strong trends, while Parent 2 (RankIC=0.0303) effectively distinguishes between institutional conviction and retail noise through overnight price gaps.\n                Concise Justification: By conditioning the mean-reversion signal (RESI5/STD5) on a measure of institutional conviction (Overnight Gap / Daily Range), we can isolate mean-reversion opportunities to environments where price extremes lack structural support.\n                Concise Knowledge: If a short-term price deviation is accompanied by low overnight gap persistence, it is likely noise-driven and prone to mean reversion; conversely, if the deviation is supported by high overnight conviction, it signals a structural trend breakout.\n                concise Specification: Define RESI5 as (Close - Mean(Close, 5)), STD5 as the 5-day daily return standard deviation, and GAP_RATIO as the 5-day average of (abs(Open - PrevClose) / (High - Low)). The final factor is RESI5 / STD5 * (1 - GAP_RATIO).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "cff31d942462",
      "parent_trajectory_ids": [
        "534d813fed12",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038223203757825,
        "ICIR": 0.0265310893241041,
        "RankIC": 0.0198615195554917,
        "RankICIR": 0.1406405073269134,
        "annualized_return": 0.0572091069734403,
        "information_ratio": 0.7586299454893467,
        "max_drawdown": -0.1096029180672807
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:01:26.322109",
      "updated_at": "2026-01-17T03:01:26.322121"
    },
    "693777eaee0222f2": {
      "factor_id": "693777eaee0222f2",
      "factor_name": "VASRF_Stealth_Accumulation_20D",
      "factor_expression": "TS_CORR($close, $volume, 20) * INV(TS_CORR($high - $low, $volume, 10) + 1e-8) * (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 14) / (TS_MEAN($close, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * INV(TS_CORR($high - $low, $volume, 10) + 1e-8) * (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 14) / (TS_MEAN($close, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VASRF_Stealth_Accumulation_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Volatility-Adjusted Stealth Regime Factor (VASRF) identifies institutional accumulation by looking for high price-volume correlation (directional synergy) and low price-range-to-volume sensitivity (execution efficiency), weighted by a volatility regime indicator (ATR/Price).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Stealth Regime Factor (VASRF) predicts excess returns by identifying stocks where high directional price-volume correlation coincides with low price-range-to-volume sensitivity, amplified by high ATR-based volatility regimes.\n                Concise Observation: Parent 1 (RankIC 0.029) shows that volatility-normalized regimes improve signal reliability, while Parent 2 (RankIC 0.026) suggests that decoupling between range and volume captures institutional stealth; combining these identifies high-conviction moves hidden in market stress.\n                Concise Justification: High ATR environments mask institutional footprints; by filtering for stocks that maintain directional price-volume synergy (CORR) but exhibit execution efficiency (low Range/Volume ratio), we isolate informed flow from speculative volatility.\n                Concise Knowledge: If institutional accumulation is high-conviction, then price-volume correlation remains high while price-range expansion remains compressed relative to volume; this signal is more reliable in high-volatility regimes where retail noise is prevalent.\n                concise Specification: The factor is defined as the product of the 20-day correlation between close price and volume, the inverse of the 10-day correlation between (high-low) and volume, and the 14-day ATR normalized by the 14-day average close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ad0a3b5110",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "29291150beba"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0091547233938905,
        "ICIR": 0.0573499965140728,
        "RankIC": 0.0285567660741052,
        "RankICIR": 0.1816099464505781,
        "annualized_return": 0.0562170888026229,
        "information_ratio": 0.7272430187875002,
        "max_drawdown": -0.1362635032509346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:05:12.001666",
      "updated_at": "2026-01-17T03:05:12.001673"
    },
    "b268b574c85277ef": {
      "factor_id": "b268b574c85277ef",
      "factor_name": "Stealth_Efficiency_Rank_15D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 15)) - RANK(TS_CORR($high - $low, $volume, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 15)) - RANK(TS_CORR($high - $low, $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Efficiency_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stealth regime hypothesis focusing on the cross-sectional rank of price-volume synergy relative to range expansion. It identifies stocks where volume leads to price direction rather than price volatility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Stealth Regime Factor (VASRF) predicts excess returns by identifying stocks where high directional price-volume correlation coincides with low price-range-to-volume sensitivity, amplified by high ATR-based volatility regimes.\n                Concise Observation: Parent 1 (RankIC 0.029) shows that volatility-normalized regimes improve signal reliability, while Parent 2 (RankIC 0.026) suggests that decoupling between range and volume captures institutional stealth; combining these identifies high-conviction moves hidden in market stress.\n                Concise Justification: High ATR environments mask institutional footprints; by filtering for stocks that maintain directional price-volume synergy (CORR) but exhibit execution efficiency (low Range/Volume ratio), we isolate informed flow from speculative volatility.\n                Concise Knowledge: If institutional accumulation is high-conviction, then price-volume correlation remains high while price-range expansion remains compressed relative to volume; this signal is more reliable in high-volatility regimes where retail noise is prevalent.\n                concise Specification: The factor is defined as the product of the 20-day correlation between close price and volume, the inverse of the 10-day correlation between (high-low) and volume, and the 14-day ATR normalized by the 14-day average close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ad0a3b5110",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "29291150beba"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0091547233938905,
        "ICIR": 0.0573499965140728,
        "RankIC": 0.0285567660741052,
        "RankICIR": 0.1816099464505781,
        "annualized_return": 0.0562170888026229,
        "information_ratio": 0.7272430187875002,
        "max_drawdown": -0.1362635032509346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:05:12.018494",
      "updated_at": "2026-01-17T03:05:12.018500"
    },
    "aa80a0df4f6ebcfd": {
      "factor_id": "aa80a0df4f6ebcfd",
      "factor_name": "Volatility_Regime_Synergy_10D",
      "factor_expression": "TS_CORR($close, $volume, 10) * TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 10) * TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Regime_Synergy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between price-volume correlation and standardized volatility. It targets high-conviction moves that occur during periods of elevated relative price range, suggesting informed participation during market stress.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Stealth Regime Factor (VASRF) predicts excess returns by identifying stocks where high directional price-volume correlation coincides with low price-range-to-volume sensitivity, amplified by high ATR-based volatility regimes.\n                Concise Observation: Parent 1 (RankIC 0.029) shows that volatility-normalized regimes improve signal reliability, while Parent 2 (RankIC 0.026) suggests that decoupling between range and volume captures institutional stealth; combining these identifies high-conviction moves hidden in market stress.\n                Concise Justification: High ATR environments mask institutional footprints; by filtering for stocks that maintain directional price-volume synergy (CORR) but exhibit execution efficiency (low Range/Volume ratio), we isolate informed flow from speculative volatility.\n                Concise Knowledge: If institutional accumulation is high-conviction, then price-volume correlation remains high while price-range expansion remains compressed relative to volume; this signal is more reliable in high-volatility regimes where retail noise is prevalent.\n                concise Specification: The factor is defined as the product of the 20-day correlation between close price and volume, the inverse of the 10-day correlation between (high-low) and volume, and the 14-day ATR normalized by the 14-day average close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ad0a3b5110",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "29291150beba"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0091547233938905,
        "ICIR": 0.0573499965140728,
        "RankIC": 0.0285567660741052,
        "RankICIR": 0.1816099464505781,
        "annualized_return": 0.0562170888026229,
        "information_ratio": 0.7272430187875002,
        "max_drawdown": -0.1362635032509346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:05:12.034823",
      "updated_at": "2026-01-17T03:05:12.034829"
    },
    "a17c9397eede1d19": {
      "factor_id": "a17c9397eede1d19",
      "factor_name": "ISEC_Factor_3_5D",
      "factor_expression": "SIGN($open / (DELAY($close, 1) + 1e-8) - 1) * TS_MEAN(($low - TS_MIN($low, 1)) / ($high - $low + 1e-8), 3) * TS_CORR($return, DELTA($volume, 1), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open / DELAY($close, 1) - 1) * TS_MEAN(($low - TS_MIN($low, 5)) / ($high - $low + 1e-8), 3) * TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"ISEC_Factor_3_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Institutional Support & Exhaustion Convergence (ISEC) factor identifies high-probability reversals and continuations. It combines 'Support Persistence' (intraday stability) with 'PV_Corr' (price-volume synchronization), weighted by the direction of the overnight gap to filter for momentum quality and exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Support & Exhaustion Convergence (ISEC) factor identifies high-probability reversals and continuations by multiplying a 3-day mean of the Low-to-Range ratio with a 5-day rolling correlation between price returns and volume changes, adjusted for the sign of the overnight gap.\n                Concise Observation: Parent 1's support persistence (RankIC 0.0256) captures intraday stability, while Parent 2's price-volume divergence (RankIC 0.0271) captures momentum quality; combining them addresses the 'fake breakout' problem where price levels hold without volume backing.\n                Concise Justification: Multiplying the support persistence by the price-volume correlation creates a conditional filter: it amplifies signals where price structure and volume flow are synchronized and penalizes signals where price levels are maintained on thinning participation.\n                Concise Knowledge: If intraday price support (low price near high) is confirmed by high price-volume correlation, the trend is robust; if high support coincides with price-volume divergence or extreme overnight gaps, the trend is likely exhausting.\n                concise Specification: Calculate Support_Persistence as mean(($low - $low.min(1))/($high - $low), 3). Calculate PV_Corr as corr(returns, volume_change, 5). The final factor is Support_Persistence * PV_Corr, further weighted by the sign of the overnight gap ($open / $close[1] - 1).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "79be26fc03da",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "17cebd62c163"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079784520858973,
        "ICIR": 0.0579017656321037,
        "RankIC": 0.0264983635033115,
        "RankICIR": 0.2012108664698539,
        "annualized_return": 0.0542883418332168,
        "information_ratio": 0.8231440913549766,
        "max_drawdown": -0.0869978471690688
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:07:50.757717",
      "updated_at": "2026-01-17T03:07:50.757723"
    },
    "91dc9d77c55ea6f4": {
      "factor_id": "91dc9d77c55ea6f4",
      "factor_name": "Support_Persistence_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(($low - TS_MIN($low, 5)) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($low - TS_MIN($low, 5)) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Support_Persistence_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the ISEC logic focusing on the persistence of price support relative to the intraday range, cross-sectionally ranked to identify stocks with the strongest institutional floor relative to recent volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Support & Exhaustion Convergence (ISEC) factor identifies high-probability reversals and continuations by multiplying a 3-day mean of the Low-to-Range ratio with a 5-day rolling correlation between price returns and volume changes, adjusted for the sign of the overnight gap.\n                Concise Observation: Parent 1's support persistence (RankIC 0.0256) captures intraday stability, while Parent 2's price-volume divergence (RankIC 0.0271) captures momentum quality; combining them addresses the 'fake breakout' problem where price levels hold without volume backing.\n                Concise Justification: Multiplying the support persistence by the price-volume correlation creates a conditional filter: it amplifies signals where price structure and volume flow are synchronized and penalizes signals where price levels are maintained on thinning participation.\n                Concise Knowledge: If intraday price support (low price near high) is confirmed by high price-volume correlation, the trend is robust; if high support coincides with price-volume divergence or extreme overnight gaps, the trend is likely exhausting.\n                concise Specification: Calculate Support_Persistence as mean(($low - $low.min(1))/($high - $low), 3). Calculate PV_Corr as corr(returns, volume_change, 5). The final factor is Support_Persistence * PV_Corr, further weighted by the sign of the overnight gap ($open / $close[1] - 1).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "79be26fc03da",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "17cebd62c163"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079784520858973,
        "ICIR": 0.0579017656321037,
        "RankIC": 0.0264983635033115,
        "RankICIR": 0.2012108664698539,
        "annualized_return": 0.0542883418332168,
        "information_ratio": 0.8231440913549766,
        "max_drawdown": -0.0869978471690688
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:07:50.774428",
      "updated_at": "2026-01-17T03:07:50.774434"
    },
    "bb7792969402808d": {
      "factor_id": "bb7792969402808d",
      "factor_name": "PV_Exhaustion_Index_10D",
      "factor_expression": "TS_CORR($return, DELTA($volume, 1), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10) * ($open / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"PV_Exhaustion_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures price-volume exhaustion by measuring the divergence between price returns and volume changes, adjusted by the overnight gap. High values suggest price movement is supported by volume flow, whereas low values suggest exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Support & Exhaustion Convergence (ISEC) factor identifies high-probability reversals and continuations by multiplying a 3-day mean of the Low-to-Range ratio with a 5-day rolling correlation between price returns and volume changes, adjusted for the sign of the overnight gap.\n                Concise Observation: Parent 1's support persistence (RankIC 0.0256) captures intraday stability, while Parent 2's price-volume divergence (RankIC 0.0271) captures momentum quality; combining them addresses the 'fake breakout' problem where price levels hold without volume backing.\n                Concise Justification: Multiplying the support persistence by the price-volume correlation creates a conditional filter: it amplifies signals where price structure and volume flow are synchronized and penalizes signals where price levels are maintained on thinning participation.\n                Concise Knowledge: If intraday price support (low price near high) is confirmed by high price-volume correlation, the trend is robust; if high support coincides with price-volume divergence or extreme overnight gaps, the trend is likely exhausting.\n                concise Specification: Calculate Support_Persistence as mean(($low - $low.min(1))/($high - $low), 3). Calculate PV_Corr as corr(returns, volume_change, 5). The final factor is Support_Persistence * PV_Corr, further weighted by the sign of the overnight gap ($open / $close[1] - 1).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "79be26fc03da",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "17cebd62c163"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079784520858973,
        "ICIR": 0.0579017656321037,
        "RankIC": 0.0264983635033115,
        "RankICIR": 0.2012108664698539,
        "annualized_return": 0.0542883418332168,
        "information_ratio": 0.8231440913549766,
        "max_drawdown": -0.0869978471690688
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:07:50.790925",
      "updated_at": "2026-01-17T03:07:50.790930"
    },
    "c7b514099786f958": {
      "factor_id": "c7b514099786f958",
      "factor_name": "LVSP_Support_Density_5D",
      "factor_expression": "TS_MEAN(($close - $low) * $volume / (POW($high - $low, 2) + 1e-6), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $low) * $volume / (POW($high - $low, 2) + 1e-6), 5)\" # Your output factor expression will be filled in here\n    name = \"LVSP_Support_Density_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Validated Support Persistence (LVSP) factor identifies high-conviction accumulation by measuring volume-weighted support density. It calculates the ratio of intraday support (closeness to the low) to price-volume exhaustion (range per unit of volume), smoothed over 5 days. High values indicate 'dense' support where high volume occurs within a narrow range near the day's low, suggesting institutional absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Support Persistence (LVSP) factor, calculated as the 5-day average of the ratio between intraday support strength (low relative to range) and intraday price-volume exhaustion (range relative to volume), identifies high-conviction accumulation by filtering out fragile price floors formed on low liquidity.\n                Concise Observation: Parent 1 showed that intraday support persistence (RankIC 0.0256) is a valid signal, while Parent 2 demonstrated that price-volume efficiency (RankIC 0.0265) captures exhaustion; however, neither accounts for the interaction where volume validates the structural integrity of the support level.\n                Concise Justification: By dividing the support metric by the exhaustion metric, we amplify signals where price floors are 'dense' (high volume, small range) and penalize 'hollow' support levels, creating a synergistic factor that captures the quality of buying pressure rather than just its presence.\n                Concise Knowledge: If intraday price support (low price near high) is accompanied by high volume relative to the price range, it signifies institutional accumulation; conversely, if support occurs with high price-volume exhaustion (large range on low volume), the price level is likely a liquidity gap prone to reversal.\n                concise Specification: The factor is defined as the 5-day rolling mean of [(($high - $low) / ($volume + 1)) / (($high - $low) / ($close - $low + 1e-6))], simplified to the 5-day average of (($close - $low) * $volume) / (($high - $low)^2 + 1e-6) to represent volume-weighted support density.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5dece64bed8e",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030132636768753,
        "ICIR": 0.0215194480321322,
        "RankIC": 0.018658191678368,
        "RankICIR": 0.1376405485497886,
        "annualized_return": 0.0415392551290103,
        "information_ratio": 0.67615156428944,
        "max_drawdown": -0.1046921246221175
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:11.823540",
      "updated_at": "2026-01-17T03:10:11.823547"
    },
    "a71b28d1d7188332": {
      "factor_id": "a71b28d1d7188332",
      "factor_name": "Z_LVSP_Efficiency_10D",
      "factor_expression": "ZSCORE(TS_MEAN((($close - $low) / ($high - $low + 1e-8)) * LOG($volume + 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN((($close - $low) / ($high - $low + 1e-8)) * LOG($volume + 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Z_LVSP_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the Liquidity-Validated Support Persistence hypothesis. It measures the relative efficiency of buying pressure by comparing the support strength (distance from low) against the intraday volatility, weighted by volume. This version uses a 10-day window and Z-score normalization to capture relative institutional accumulation across the universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Support Persistence (LVSP) factor, calculated as the 5-day average of the ratio between intraday support strength (low relative to range) and intraday price-volume exhaustion (range relative to volume), identifies high-conviction accumulation by filtering out fragile price floors formed on low liquidity.\n                Concise Observation: Parent 1 showed that intraday support persistence (RankIC 0.0256) is a valid signal, while Parent 2 demonstrated that price-volume efficiency (RankIC 0.0265) captures exhaustion; however, neither accounts for the interaction where volume validates the structural integrity of the support level.\n                Concise Justification: By dividing the support metric by the exhaustion metric, we amplify signals where price floors are 'dense' (high volume, small range) and penalize 'hollow' support levels, creating a synergistic factor that captures the quality of buying pressure rather than just its presence.\n                Concise Knowledge: If intraday price support (low price near high) is accompanied by high volume relative to the price range, it signifies institutional accumulation; conversely, if support occurs with high price-volume exhaustion (large range on low volume), the price level is likely a liquidity gap prone to reversal.\n                concise Specification: The factor is defined as the 5-day rolling mean of [(($high - $low) / ($volume + 1)) / (($high - $low) / ($close - $low + 1e-6))], simplified to the 5-day average of (($close - $low) * $volume) / (($high - $low)^2 + 1e-6) to represent volume-weighted support density.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5dece64bed8e",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030132636768753,
        "ICIR": 0.0215194480321322,
        "RankIC": 0.018658191678368,
        "RankICIR": 0.1376405485497886,
        "annualized_return": 0.0415392551290103,
        "information_ratio": 0.67615156428944,
        "max_drawdown": -0.1046921246221175
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:11.840816",
      "updated_at": "2026-01-17T03:10:11.840822"
    },
    "d5d5ad13fcc99509": {
      "factor_id": "d5d5ad13fcc99509",
      "factor_name": "Ranked_Support_Integrity_5D",
      "factor_expression": "RANK(TS_MEAN(($close - $low) / (($high - $low) / ($volume + 1e-8) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $low) / (($high - $low) / ($volume + 1e-8) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Support_Integrity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the structural integrity of price floors by ranking the interaction between price support and volume-to-range efficiency. It identifies stocks where the price is supported near the low on high relative liquidity, avoiding 'hollow' price levels characterized by large ranges on low volume.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Support Persistence (LVSP) factor, calculated as the 5-day average of the ratio between intraday support strength (low relative to range) and intraday price-volume exhaustion (range relative to volume), identifies high-conviction accumulation by filtering out fragile price floors formed on low liquidity.\n                Concise Observation: Parent 1 showed that intraday support persistence (RankIC 0.0256) is a valid signal, while Parent 2 demonstrated that price-volume efficiency (RankIC 0.0265) captures exhaustion; however, neither accounts for the interaction where volume validates the structural integrity of the support level.\n                Concise Justification: By dividing the support metric by the exhaustion metric, we amplify signals where price floors are 'dense' (high volume, small range) and penalize 'hollow' support levels, creating a synergistic factor that captures the quality of buying pressure rather than just its presence.\n                Concise Knowledge: If intraday price support (low price near high) is accompanied by high volume relative to the price range, it signifies institutional accumulation; conversely, if support occurs with high price-volume exhaustion (large range on low volume), the price level is likely a liquidity gap prone to reversal.\n                concise Specification: The factor is defined as the 5-day rolling mean of [(($high - $low) / ($volume + 1)) / (($high - $low) / ($close - $low + 1e-6))], simplified to the 5-day average of (($close - $low) * $volume) / (($high - $low)^2 + 1e-6) to represent volume-weighted support density.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "5dece64bed8e",
      "parent_trajectory_ids": [
        "a3e677a37e74",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030132636768753,
        "ICIR": 0.0215194480321322,
        "RankIC": 0.018658191678368,
        "RankICIR": 0.1376405485497886,
        "annualized_return": 0.0415392551290103,
        "information_ratio": 0.67615156428944,
        "max_drawdown": -0.1046921246221175
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:11.857423",
      "updated_at": "2026-01-17T03:10:11.857429"
    },
    "3cbef1cd6406bdd6": {
      "factor_id": "3cbef1cd6406bdd6",
      "factor_name": "WVMA_RSQR_Exhaustion_Ratio_10D",
      "factor_expression": "TS_MEAN(TS_STD($close, 5) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_STD($close, 5) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WVMA_RSQR_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by calculating the ratio of volume-weighted volatility to the linearity of the price trend. A high value suggests that price movements are becoming more volatile and high-conviction (volume-weighted) while the trend's structural linearity (R-squared) is breaking down, signaling a potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.126614",
      "updated_at": "2026-01-17T03:10:24.126622"
    },
    "cdc26453752ef13a": {
      "factor_id": "cdc26453752ef13a",
      "factor_name": "Trend_Instability_Index_5D",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(5), 5), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(5), 5), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Instability_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis focusing on the divergence between volume-weighted price spread and trend stability. It uses the ratio of rolling volume-weighted high-low range to the square of the price-time correlation. High values indicate chaotic price action with high participation, often seen at market tops or bottoms.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.147874",
      "updated_at": "2026-01-17T03:10:24.147880"
    },
    "807104440bd1d4bf": {
      "factor_id": "807104440bd1d4bf",
      "factor_name": "Normalized_Volatility_Linearity_Divergence",
      "factor_expression": "TS_ZSCORE(TS_STD($close, 5) * $volume, 20) - TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_STD($close, 5) * $volume, 20) - TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Volatility_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between standardized volume-weighted volatility and the linearity of the price trend. By using Z-scores, it identifies extreme periods where volatility conviction significantly outpaces the trend's consistency, indicating a regime shift.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: A high ratio of the 5-day volume-weighted moving average of price volatility (WVMA5) relative to the 10-day R-squared of price trend linearity (RSQR10) predicts a decrease in future returns due to trend exhaustion and rising uncertainty.\n                Concise Observation: Market participants often increase trading activity (volume) during periods of high uncertainty (volatility) just as a clear price direction (RSQR) begins to fail, suggesting that the interaction between these two metrics captures the 'turning point' of asset momentum.\n                Concise Justification: Volume-weighted volatility accounts for the conviction behind price swings, while R-squared measures the efficiency of the trend; a divergence where volatility rises as linearity falls suggests an influx of noise and a breakdown of the prevailing market regime.\n                Concise Knowledge: If volume-weighted volatility increases while price trend linearity decreases, the current price trend is likely losing structural integrity; when high-volume volatility spikes precede a drop in R-squared, it indicates a transition from a stable trend to a chaotic or reversal phase.\n                concise Specification: Define WVMA5 as the 5-day rolling mean of (std(close, 5) * volume) and RSQR10 as the coefficient of determination from a linear regression of close prices against time over 10 days; the factor is the ratio of WVMA5 to RSQR10.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "original",
      "trajectory_id": "820f49b71aaf",
      "parent_trajectory_ids": [],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052697558864769,
        "ICIR": 0.0397127092324302,
        "RankIC": 0.0206608572805507,
        "RankICIR": 0.1557392586657852,
        "annualized_return": 0.0546286205661063,
        "information_ratio": 0.8608622196675588,
        "max_drawdown": -0.1050057503224113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:10:24.164853",
      "updated_at": "2026-01-17T03:10:24.164859"
    },
    "19b7bd2ac2235503": {
      "factor_id": "19b7bd2ac2235503",
      "factor_name": "Liquidity_Exhaustion_Divergence_60D",
      "factor_expression": "(TS_SUM($return, 60) < 0) ? (TS_CORR($close, $volume, 20) * TS_ZSCORE(ABS($return) / ($volume + 1e-8), 5)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_PCTCHANGE($close, 60) < 0) ? (TS_CORR($close, $volume, 20) * TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5)) : 0\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Divergence_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies mean-reversion opportunities by multiplying the 20-day price-volume correlation with the 5-day Amihud Illiquidity Z-score, filtered by a 60-day negative momentum to isolate oversold recovery points.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Exhaustion Divergence' factor identifies mean-reversion by multiplying the 20-day negative price-volume correlation (Parent 1) with the 5-day Amihud Illiquidity Z-score (Parent 2) within a 60-day momentum context.\n                Concise Observation: Parent 1 captures structural trend decay (RankIC 0.029) while Parent 2 captures immediate execution stress (RankIC 0.023); however, each alone may trigger premature entries in trending or flat markets respectively.\n                Concise Justification: Combining the 20-day price-volume decoupling with a 5-day illiquidity spike ensures that the mean-reversion signal is only generated when the macro-trend has lost volume support and the micro-structure is fragile enough to snap back.\n                Concise Knowledge: If a medium-term price trend exhibits decoupling (negative price-volume correlation) and is simultaneously hit by a short-term liquidity shock (high Amihud ratio), then the probability of a sharp mean-reversion increases due to exhaustion of the dominant market participants.\n                concise Specification: Define the factor as the product of TS_CORR($close, $volume, 20) and a 5-day Z-score of ($abs(return)/$volume), filtered by a negative 60-day cumulative return to isolate oversold recovery opportunities.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "0d28bc31ac05",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "696eecf82dbb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.009537074802855,
        "ICIR": 0.0664693296707091,
        "RankIC": 0.0265548610396828,
        "RankICIR": 0.1853266300679249,
        "annualized_return": 0.077722993371773,
        "information_ratio": 1.1414703919871785,
        "max_drawdown": -0.1191262636734705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:11:27.307677",
      "updated_at": "2026-01-17T03:11:27.307684"
    },
    "cecbeb683ba33bd9": {
      "factor_id": "cecbeb683ba33bd9",
      "factor_name": "Structural_Decay_Shock_Factor",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(ABS($return) / ($volume + 1e-8)) * (TS_PCTCHANGE($close, 60) < 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8)) * (TS_PCTCHANGE($close, 60) < 0 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Structural_Decay_Shock_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the liquidity exhaustion hypothesis that uses the rank of price-volume decoupling and the rank of illiquidity spikes to identify fragile market structures in a downtrend.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Exhaustion Divergence' factor identifies mean-reversion by multiplying the 20-day negative price-volume correlation (Parent 1) with the 5-day Amihud Illiquidity Z-score (Parent 2) within a 60-day momentum context.\n                Concise Observation: Parent 1 captures structural trend decay (RankIC 0.029) while Parent 2 captures immediate execution stress (RankIC 0.023); however, each alone may trigger premature entries in trending or flat markets respectively.\n                Concise Justification: Combining the 20-day price-volume decoupling with a 5-day illiquidity spike ensures that the mean-reversion signal is only generated when the macro-trend has lost volume support and the micro-structure is fragile enough to snap back.\n                Concise Knowledge: If a medium-term price trend exhibits decoupling (negative price-volume correlation) and is simultaneously hit by a short-term liquidity shock (high Amihud ratio), then the probability of a sharp mean-reversion increases due to exhaustion of the dominant market participants.\n                concise Specification: Define the factor as the product of TS_CORR($close, $volume, 20) and a 5-day Z-score of ($abs(return)/$volume), filtered by a negative 60-day cumulative return to isolate oversold recovery opportunities.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "0d28bc31ac05",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "696eecf82dbb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.009537074802855,
        "ICIR": 0.0664693296707091,
        "RankIC": 0.0265548610396828,
        "RankICIR": 0.1853266300679249,
        "annualized_return": 0.077722993371773,
        "information_ratio": 1.1414703919871785,
        "max_drawdown": -0.1191262636734705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:11:27.325238",
      "updated_at": "2026-01-17T03:11:27.325243"
    },
    "f9649f1e9c75243c": {
      "factor_id": "f9649f1e9c75243c",
      "factor_name": "Exhaustion_ZScore_Combo",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20)) + ZSCORE(TS_MEAN(ABS($return) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20)) + ZSCORE(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_ZScore_Combo\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines the 20-day price-volume correlation with a 5-day moving average of the Amihud ratio, standardized cross-sectionally to identify extreme exhaustion relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Exhaustion Divergence' factor identifies mean-reversion by multiplying the 20-day negative price-volume correlation (Parent 1) with the 5-day Amihud Illiquidity Z-score (Parent 2) within a 60-day momentum context.\n                Concise Observation: Parent 1 captures structural trend decay (RankIC 0.029) while Parent 2 captures immediate execution stress (RankIC 0.023); however, each alone may trigger premature entries in trending or flat markets respectively.\n                Concise Justification: Combining the 20-day price-volume decoupling with a 5-day illiquidity spike ensures that the mean-reversion signal is only generated when the macro-trend has lost volume support and the micro-structure is fragile enough to snap back.\n                Concise Knowledge: If a medium-term price trend exhibits decoupling (negative price-volume correlation) and is simultaneously hit by a short-term liquidity shock (high Amihud ratio), then the probability of a sharp mean-reversion increases due to exhaustion of the dominant market participants.\n                concise Specification: Define the factor as the product of TS_CORR($close, $volume, 20) and a 5-day Z-score of ($abs(return)/$volume), filtered by a negative 60-day cumulative return to isolate oversold recovery opportunities.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "0d28bc31ac05",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "696eecf82dbb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.009537074802855,
        "ICIR": 0.0664693296707091,
        "RankIC": 0.0265548610396828,
        "RankICIR": 0.1853266300679249,
        "annualized_return": 0.077722993371773,
        "information_ratio": 1.1414703919871785,
        "max_drawdown": -0.1191262636734705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:11:27.342265",
      "updated_at": "2026-01-17T03:11:27.342271"
    },
    "e6f126bd33a16828": {
      "factor_id": "e6f126bd33a16828",
      "factor_name": "Institutional_Conviction_Gap_10D",
      "factor_expression": "($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + 1e-8) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + 0.00000001)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 0.00000001)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 'Institutional Conviction Gap' by calculating the ratio of the overnight gap to the sum of the lower shadow and the intraday high-low range. It is normalized by the 10-day rolling standard deviation of returns to identify high-conviction institutional price-setting while penalizing noisy intraday price action.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Conviction Gap' factor, defined as the ratio of the overnight gap to the sum of the lower shadow and the intraday high-low range, normalized by 10-day volatility, positively predicts short-term returns by identifying high-conviction institutional price-setting.\n                Concise Observation: Parent strategies showed that while overnight gaps and lower shadows are predictive, their signal quality is degraded by high intraday volatility and market-wide noise, suggesting a need for a composite metric that penalizes 'messy' intraday price action.\n                Concise Justification: By combining the support level (lower shadow) with a stability filter (intraday range) in the denominator, the factor isolates 'clean' gaps where price discovery occurs overnight and is defended during the day, reflecting strong directional conviction.\n                Concise Knowledge: If an overnight price gap is sustained with minimal lower shadow and low intraday volatility, it indicates institutional absorption of liquidity; when this gap is large relative to subsequent intraday fluctuations and normalized by historical volatility, it signals a persistent trend continuation rather than mean-reverting retail noise.\n                concise Specification: Calculate the overnight gap (Open - PrevClose); divide by the sum of the lower shadow (Open - Low) and the intraday range (High - Low); normalize the resulting ratio by the 10-day rolling standard deviation of daily returns to ensure cross-sectional comparability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "bec99e17b147",
      "parent_trajectory_ids": [
        "517312de0ea9",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060565822750446,
        "ICIR": 0.0432206464740703,
        "RankIC": 0.0252240626801985,
        "RankICIR": 0.1846191059095083,
        "annualized_return": 0.0667336793577806,
        "information_ratio": 1.0273442087857907,
        "max_drawdown": -0.0838719151273794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:14:56.710368",
      "updated_at": "2026-01-17T03:14:56.710375"
    },
    "8e09c786c770a8fa": {
      "factor_id": "8e09c786c770a8fa",
      "factor_name": "Ranked_Conviction_Stability_Ratio",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + 1e-8)) / (RANK(TS_STD($return, 10)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + 0.00000001)) / RANK(TS_STD(TS_PCTCHANGE($close, 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Stability_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction gap, focusing on the ratio of the overnight price discovery to the total daily volatility (shadow plus range). By ranking the ratio and the volatility separately, it isolates stocks with the highest 'clean' gaps relative to their peers.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Conviction Gap' factor, defined as the ratio of the overnight gap to the sum of the lower shadow and the intraday high-low range, normalized by 10-day volatility, positively predicts short-term returns by identifying high-conviction institutional price-setting.\n                Concise Observation: Parent strategies showed that while overnight gaps and lower shadows are predictive, their signal quality is degraded by high intraday volatility and market-wide noise, suggesting a need for a composite metric that penalizes 'messy' intraday price action.\n                Concise Justification: By combining the support level (lower shadow) with a stability filter (intraday range) in the denominator, the factor isolates 'clean' gaps where price discovery occurs overnight and is defended during the day, reflecting strong directional conviction.\n                Concise Knowledge: If an overnight price gap is sustained with minimal lower shadow and low intraday volatility, it indicates institutional absorption of liquidity; when this gap is large relative to subsequent intraday fluctuations and normalized by historical volatility, it signals a persistent trend continuation rather than mean-reverting retail noise.\n                concise Specification: Calculate the overnight gap (Open - PrevClose); divide by the sum of the lower shadow (Open - Low) and the intraday range (High - Low); normalize the resulting ratio by the 10-day rolling standard deviation of daily returns to ensure cross-sectional comparability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "bec99e17b147",
      "parent_trajectory_ids": [
        "517312de0ea9",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060565822750446,
        "ICIR": 0.0432206464740703,
        "RankIC": 0.0252240626801985,
        "RankICIR": 0.1846191059095083,
        "annualized_return": 0.0667336793577806,
        "information_ratio": 1.0273442087857907,
        "max_drawdown": -0.0838719151273794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:14:56.727745",
      "updated_at": "2026-01-17T03:14:56.727750"
    },
    "9f00b6ebb61179b4": {
      "factor_id": "9f00b6ebb61179b4",
      "factor_name": "Smoothed_Institutional_Conviction_Index",
      "factor_expression": "EMA(($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + TS_STD($return, 10) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(($open - DELAY($close, 1)) / (($open - $low) + ($high - $low) + TS_STD(TS_PCTCHANGE($close, 1), 10) + 0.00000001), 5)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Institutional_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a 5-day exponential moving average to the conviction gap ratio to filter out daily idiosyncratic noise, focusing on persistent institutional accumulation patterns where the gap consistently dominates intraday volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Conviction Gap' factor, defined as the ratio of the overnight gap to the sum of the lower shadow and the intraday high-low range, normalized by 10-day volatility, positively predicts short-term returns by identifying high-conviction institutional price-setting.\n                Concise Observation: Parent strategies showed that while overnight gaps and lower shadows are predictive, their signal quality is degraded by high intraday volatility and market-wide noise, suggesting a need for a composite metric that penalizes 'messy' intraday price action.\n                Concise Justification: By combining the support level (lower shadow) with a stability filter (intraday range) in the denominator, the factor isolates 'clean' gaps where price discovery occurs overnight and is defended during the day, reflecting strong directional conviction.\n                Concise Knowledge: If an overnight price gap is sustained with minimal lower shadow and low intraday volatility, it indicates institutional absorption of liquidity; when this gap is large relative to subsequent intraday fluctuations and normalized by historical volatility, it signals a persistent trend continuation rather than mean-reverting retail noise.\n                concise Specification: Calculate the overnight gap (Open - PrevClose); divide by the sum of the lower shadow (Open - Low) and the intraday range (High - Low); normalize the resulting ratio by the 10-day rolling standard deviation of daily returns to ensure cross-sectional comparability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "bec99e17b147",
      "parent_trajectory_ids": [
        "517312de0ea9",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060565822750446,
        "ICIR": 0.0432206464740703,
        "RankIC": 0.0252240626801985,
        "RankICIR": 0.1846191059095083,
        "annualized_return": 0.0667336793577806,
        "information_ratio": 1.0273442087857907,
        "max_drawdown": -0.0838719151273794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:14:56.744885",
      "updated_at": "2026-01-17T03:14:56.744890"
    },
    "3763ab47275c8624": {
      "factor_id": "3763ab47275c8624",
      "factor_name": "Liquidity_Validated_Regime_Factor",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20) * TS_STD($return, 14)) / (ZSCORE(TS_MEAN(ABS($return) / ($volume + 1e-8), 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20) * TS_STD(TS_PCTCHANGE($close, 1), 14)) / (ZSCORE(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5)) + 1.00000001)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Regime_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction regime shifts by interacting the 20-day price-volume correlation with volatility, normalized by a 5-day Amihud Illiquidity measure. It filters out 'liquidity traps' where price moves occur on low volume, prioritizing trends supported by market depth.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation and the 14-day ATR, when normalized by the 5-day Amihud Illiquidity, identifies high-conviction regime shifts by filtering out low-volume 'liquidity traps' that lead to false trend signals.\n                Concise Observation: Parent 1 captures volatility-adjusted regimes (RankIC 0.029) and Parent 2 captures liquidity-driven reversals (RankIC 0.023), but neither distinguishes if a volatile trend is supported by sufficient depth.\n                Concise Justification: By dividing the regime signal (CORR * ATR) by a short-term illiquidity measure, we amplify signals where price discovery is efficient (low illiquidity) and dampen or reverse signals where price moves are disproportionate to volume.\n                Concise Knowledge: If a price-volume trend is accompanied by high volatility but low liquidity (high Amihud), it is likely a mean-reverting fragility event; whereas high liquidity validates the regime's persistence.\n                concise Specification: The factor is defined as (Corr(Close, Volume, 20) * ATR(14) / Close) / (Mean(Abs(Return/Volume), 5)), where all components are z-scored cross-sectionally to ensure scale compatibility before interaction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "62c64bb3c0a6",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "696eecf82dbb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074053998988955,
        "ICIR": 0.0455593270860017,
        "RankIC": 0.0255328451637223,
        "RankICIR": 0.1593400656595424,
        "annualized_return": 0.0475535713674498,
        "information_ratio": 0.5902989201047026,
        "max_drawdown": -0.1281671761192537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:17:55.446103",
      "updated_at": "2026-01-17T03:17:55.446110"
    },
    "1a11d5bfc97b9bc3": {
      "factor_id": "1a11d5bfc97b9bc3",
      "factor_name": "Volatility_Liquidity_Efficiency_Ratio",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) / (RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) / (RANK(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Liquidity_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the liquidity-regime hypothesis focusing on the ratio of price-volume trend strength to illiquidity. It uses the 20-day price-volume correlation as a proxy for trend conviction and divides it by the short-term price impact (Amihud Illiquidity) to identify efficient price discovery.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation and the 14-day ATR, when normalized by the 5-day Amihud Illiquidity, identifies high-conviction regime shifts by filtering out low-volume 'liquidity traps' that lead to false trend signals.\n                Concise Observation: Parent 1 captures volatility-adjusted regimes (RankIC 0.029) and Parent 2 captures liquidity-driven reversals (RankIC 0.023), but neither distinguishes if a volatile trend is supported by sufficient depth.\n                Concise Justification: By dividing the regime signal (CORR * ATR) by a short-term illiquidity measure, we amplify signals where price discovery is efficient (low illiquidity) and dampen or reverse signals where price moves are disproportionate to volume.\n                Concise Knowledge: If a price-volume trend is accompanied by high volatility but low liquidity (high Amihud), it is likely a mean-reverting fragility event; whereas high liquidity validates the regime's persistence.\n                concise Specification: The factor is defined as (Corr(Close, Volume, 20) * ATR(14) / Close) / (Mean(Abs(Return/Volume), 5)), where all components are z-scored cross-sectionally to ensure scale compatibility before interaction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "62c64bb3c0a6",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "696eecf82dbb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074053998988955,
        "ICIR": 0.0455593270860017,
        "RankIC": 0.0255328451637223,
        "RankICIR": 0.1593400656595424,
        "annualized_return": 0.0475535713674498,
        "information_ratio": 0.5902989201047026,
        "max_drawdown": -0.1281671761192537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:17:55.463968",
      "updated_at": "2026-01-17T03:17:55.463974"
    },
    "99128c0d9331c944": {
      "factor_id": "99128c0d9331c944",
      "factor_name": "Regime_Conviction_Index",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20) * ($high - $low) / ($close + 1e-8)) - ZSCORE(TS_MEAN(ABS($return) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20) * ($high - $low) / ($close + 1e-8)) - ZSCORE(TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Regime_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures regime conviction by combining price-volume alignment and price range, dampened by the 5-day average price impact. High values indicate strong, volatile trends occurring in high-liquidity environments.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation and the 14-day ATR, when normalized by the 5-day Amihud Illiquidity, identifies high-conviction regime shifts by filtering out low-volume 'liquidity traps' that lead to false trend signals.\n                Concise Observation: Parent 1 captures volatility-adjusted regimes (RankIC 0.029) and Parent 2 captures liquidity-driven reversals (RankIC 0.023), but neither distinguishes if a volatile trend is supported by sufficient depth.\n                Concise Justification: By dividing the regime signal (CORR * ATR) by a short-term illiquidity measure, we amplify signals where price discovery is efficient (low illiquidity) and dampen or reverse signals where price moves are disproportionate to volume.\n                Concise Knowledge: If a price-volume trend is accompanied by high volatility but low liquidity (high Amihud), it is likely a mean-reverting fragility event; whereas high liquidity validates the regime's persistence.\n                concise Specification: The factor is defined as (Corr(Close, Volume, 20) * ATR(14) / Close) / (Mean(Abs(Return/Volume), 5)), where all components are z-scored cross-sectionally to ensure scale compatibility before interaction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "62c64bb3c0a6",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "696eecf82dbb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074053998988955,
        "ICIR": 0.0455593270860017,
        "RankIC": 0.0255328451637223,
        "RankICIR": 0.1593400656595424,
        "annualized_return": 0.0475535713674498,
        "information_ratio": 0.5902989201047026,
        "max_drawdown": -0.1281671761192537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:17:55.481511",
      "updated_at": "2026-01-17T03:17:55.481517"
    },
    "d822cde10d1bc54f": {
      "factor_id": "d822cde10d1bc54f",
      "factor_name": "Overnight_Gap_Lower_Shadow_Interaction_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Lower_Shadow_Interaction_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional accumulation by multiplying the normalized overnight gap with the relative lower shadow length. A positive gap followed by price rejection at the lows (long lower shadow) suggests 'Smart Money' is defending the position. The gap is normalized by the 5-day price volatility to account for varying market regimes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and intraday support—measured as the product of the normalized overnight gap and the lower shadow length relative to the volume-weighted price deviation—identifies institutional accumulation and trend continuation.\n                Concise Observation: Parent strategies show that overnight gaps capture information asymmetry (RankIC 0.030) and lower shadows indicate price rejection (RankIC 0.021), suggesting that their intersection reveals high-conviction 'breakaway' moves rather than exhaustion.\n                Concise Justification: Institutional 'Smart Money' often positions overnight, and their continued support during intraday dips (lower shadows) confirms the validity of the initial gap, filtering out noise from retail-driven volatility.\n                Concise Knowledge: If an overnight price gap is sustained and subsequently defended by intraday buying pressure (long lower shadows), it indicates institutional conviction; when this recovery is high relative to the volume-weighted average price, the signal for future positive returns is strengthened.\n                concise Specification: The factor is defined as (Gap / Daily_Volatility) * (Lower_Shadow / (High - Low)) * (VWAP / Close), where Gap is (Open - Prev_Close) and the window for volatility and VWAP is 1 day, targeting a multi-day return prediction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4d83ddf20a43",
      "parent_trajectory_ids": [
        "2e043cd85785",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051819354837216,
        "ICIR": 0.0400666235467534,
        "RankIC": 0.0223888233115769,
        "RankICIR": 0.1731252769066772,
        "annualized_return": 0.0800904971652552,
        "information_ratio": 1.1991589482185585,
        "max_drawdown": -0.0851840722238418
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:18:02.149526",
      "updated_at": "2026-01-17T03:18:02.149533"
    },
    "ec49a6f19cb26ce7": {
      "factor_id": "ec49a6f19cb26ce7",
      "factor_name": "Institutional_Defense_VWAP_Proxy_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK((MIN($open, $close) - $low) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK((MIN($open, $close) - $low) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Defense_VWAP_Proxy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction moves where an overnight gap is supported by intraday buying pressure relative to the price level. It uses the ratio of the lower shadow to the daily range, scaled by the overnight gap, and further adjusted by the proximity of the close to the high to ensure trend strength.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and intraday support—measured as the product of the normalized overnight gap and the lower shadow length relative to the volume-weighted price deviation—identifies institutional accumulation and trend continuation.\n                Concise Observation: Parent strategies show that overnight gaps capture information asymmetry (RankIC 0.030) and lower shadows indicate price rejection (RankIC 0.021), suggesting that their intersection reveals high-conviction 'breakaway' moves rather than exhaustion.\n                Concise Justification: Institutional 'Smart Money' often positions overnight, and their continued support during intraday dips (lower shadows) confirms the validity of the initial gap, filtering out noise from retail-driven volatility.\n                Concise Knowledge: If an overnight price gap is sustained and subsequently defended by intraday buying pressure (long lower shadows), it indicates institutional conviction; when this recovery is high relative to the volume-weighted average price, the signal for future positive returns is strengthened.\n                concise Specification: The factor is defined as (Gap / Daily_Volatility) * (Lower_Shadow / (High - Low)) * (VWAP / Close), where Gap is (Open - Prev_Close) and the window for volatility and VWAP is 1 day, targeting a multi-day return prediction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4d83ddf20a43",
      "parent_trajectory_ids": [
        "2e043cd85785",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051819354837216,
        "ICIR": 0.0400666235467534,
        "RankIC": 0.0223888233115769,
        "RankICIR": 0.1731252769066772,
        "annualized_return": 0.0800904971652552,
        "information_ratio": 1.1991589482185585,
        "max_drawdown": -0.0851840722238418
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:18:02.167307",
      "updated_at": "2026-01-17T03:18:02.167314"
    },
    "e96740b7992d2742": {
      "factor_id": "e96740b7992d2742",
      "factor_name": "Gap_Continuation_ZScore_20D",
      "factor_expression": "TS_ZSCORE($open - DELAY($close, 1), 20) * (($open - $low) / (ABS($close - $open) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($open - DELAY($close, 1), 20) * (($open - $low) / (ABS($close - $open) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Continuation_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the conviction of an overnight gap by evaluating if the intraday low stays significantly above the previous day's close, weighted by the relative size of the lower shadow. This version uses Z-scoring to normalize the gap magnitude over a 20-day window.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between the overnight price gap and intraday support—measured as the product of the normalized overnight gap and the lower shadow length relative to the volume-weighted price deviation—identifies institutional accumulation and trend continuation.\n                Concise Observation: Parent strategies show that overnight gaps capture information asymmetry (RankIC 0.030) and lower shadows indicate price rejection (RankIC 0.021), suggesting that their intersection reveals high-conviction 'breakaway' moves rather than exhaustion.\n                Concise Justification: Institutional 'Smart Money' often positions overnight, and their continued support during intraday dips (lower shadows) confirms the validity of the initial gap, filtering out noise from retail-driven volatility.\n                Concise Knowledge: If an overnight price gap is sustained and subsequently defended by intraday buying pressure (long lower shadows), it indicates institutional conviction; when this recovery is high relative to the volume-weighted average price, the signal for future positive returns is strengthened.\n                concise Specification: The factor is defined as (Gap / Daily_Volatility) * (Lower_Shadow / (High - Low)) * (VWAP / Close), where Gap is (Open - Prev_Close) and the window for volatility and VWAP is 1 day, targeting a multi-day return prediction.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4d83ddf20a43",
      "parent_trajectory_ids": [
        "2e043cd85785",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051819354837216,
        "ICIR": 0.0400666235467534,
        "RankIC": 0.0223888233115769,
        "RankICIR": 0.1731252769066772,
        "annualized_return": 0.0800904971652552,
        "information_ratio": 1.1991589482185585,
        "max_drawdown": -0.0851840722238418
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:18:02.184667",
      "updated_at": "2026-01-17T03:18:02.184673"
    },
    "1b8749f85b34a299": {
      "factor_id": "1b8749f85b34a299",
      "factor_name": "Idio_Gap_Conviction_5D",
      "factor_expression": "TS_SUM($return - MEAN($return), 5) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM(($close / DELAY($close, 1) - 1) - MEAN($close / DELAY($close, 1) - 1), 5) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Idio_Gap_Conviction_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional trends by multiplying the 5-day idiosyncratic return (stock return minus market average) by a 'Gap Stability' ratio. The ratio measures the overnight gap relative to the total intraday range, where a high ratio suggests that overnight information is being sustained without significant intraday noise or reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day idiosyncratic price residual, when amplified by the ratio of the overnight gap to the intraday range, identifies high-conviction institutional trends that are more likely to persist than noise-driven price movements.\n                Concise Observation: Parent 1 showed that 5-day residuals capture idiosyncratic dislocations (RankIC 0.021), while Parent 2 demonstrated that overnight gaps normalized by intraday ranges capture information asymmetry (RankIC 0.030).\n                Concise Justification: Fusing these signals filters out market-wide beta and retail-driven intraday noise, ensuring that the momentum signal is derived from 'clean' idiosyncratic moves validated by the conviction of overnight information arrival.\n                Concise Knowledge: If a stock's idiosyncratic return is supported by a persistent overnight gap that is not retraced during intraday trading, the price move is likely driven by informed institutional positioning; when intraday volatility is high relative to the gap, the signal is likely noise.\n                concise Specification: Calculate the 5-day idiosyncratic residual by subtracting the cross-sectional mean return from the stock return; multiply this by the 'Gap Stability' ratio, defined as (Open - Prev_Close) divided by (High - Low + epsilon), using a 5-day lookback for the residual and daily values for the gap.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "538efa2b9476",
      "parent_trajectory_ids": [
        "f202389c67c8",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056491708427519,
        "ICIR": 0.0430405125806527,
        "RankIC": 0.0210635279978666,
        "RankICIR": 0.165275669853,
        "annualized_return": 0.0675573062510109,
        "information_ratio": 0.9526631752292264,
        "max_drawdown": -0.1018099229570179
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:22.425778",
      "updated_at": "2026-01-17T03:23:22.425784"
    },
    "cb527785b98c5ef6": {
      "factor_id": "cb527785b98c5ef6",
      "factor_name": "Ranked_Idio_Gap_Stability_5D",
      "factor_expression": "RANK(TS_SUM($return - MEAN($return), 5)) * RANK(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(REGRESI($close / DELAY($close, 1) - 1, MEAN($close / DELAY($close, 1) - 1), 1), 5)) * RANK(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Idio_Gap_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the idiosyncratic gap conviction factor. It calculates the 5-day cumulative idiosyncratic residual and scales it by the relative strength of the overnight gap compared to the daily price volatility. RANK() is applied to ensure the factor is less sensitive to outliers and suitable for cross-sectional comparison.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day idiosyncratic price residual, when amplified by the ratio of the overnight gap to the intraday range, identifies high-conviction institutional trends that are more likely to persist than noise-driven price movements.\n                Concise Observation: Parent 1 showed that 5-day residuals capture idiosyncratic dislocations (RankIC 0.021), while Parent 2 demonstrated that overnight gaps normalized by intraday ranges capture information asymmetry (RankIC 0.030).\n                Concise Justification: Fusing these signals filters out market-wide beta and retail-driven intraday noise, ensuring that the momentum signal is derived from 'clean' idiosyncratic moves validated by the conviction of overnight information arrival.\n                Concise Knowledge: If a stock's idiosyncratic return is supported by a persistent overnight gap that is not retraced during intraday trading, the price move is likely driven by informed institutional positioning; when intraday volatility is high relative to the gap, the signal is likely noise.\n                concise Specification: Calculate the 5-day idiosyncratic residual by subtracting the cross-sectional mean return from the stock return; multiply this by the 'Gap Stability' ratio, defined as (Open - Prev_Close) divided by (High - Low + epsilon), using a 5-day lookback for the residual and daily values for the gap.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "538efa2b9476",
      "parent_trajectory_ids": [
        "f202389c67c8",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056491708427519,
        "ICIR": 0.0430405125806527,
        "RankIC": 0.0210635279978666,
        "RankICIR": 0.165275669853,
        "annualized_return": 0.0675573062510109,
        "information_ratio": 0.9526631752292264,
        "max_drawdown": -0.1018099229570179
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:22.448761",
      "updated_at": "2026-01-17T03:23:22.448767"
    },
    "97fffe6b7ec7cc1b": {
      "factor_id": "97fffe6b7ec7cc1b",
      "factor_name": "Smoothed_Gap_Residual_Alpha_5D",
      "factor_expression": "TS_SUM($return - MEAN($return), 5) * SMA(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM(($close / DELAY($close, 1) - 1) - MEAN($close / DELAY($close, 1) - 1), 5) * SMA(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Gap_Residual_Alpha_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the persistence of the gap-to-range signal. It calculates the idiosyncratic return over 5 days and weights it by the 5-day simple moving average of the gap-to-intraday-range ratio, filtering out temporary spikes in intraday volatility and highlighting sustained institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day idiosyncratic price residual, when amplified by the ratio of the overnight gap to the intraday range, identifies high-conviction institutional trends that are more likely to persist than noise-driven price movements.\n                Concise Observation: Parent 1 showed that 5-day residuals capture idiosyncratic dislocations (RankIC 0.021), while Parent 2 demonstrated that overnight gaps normalized by intraday ranges capture information asymmetry (RankIC 0.030).\n                Concise Justification: Fusing these signals filters out market-wide beta and retail-driven intraday noise, ensuring that the momentum signal is derived from 'clean' idiosyncratic moves validated by the conviction of overnight information arrival.\n                Concise Knowledge: If a stock's idiosyncratic return is supported by a persistent overnight gap that is not retraced during intraday trading, the price move is likely driven by informed institutional positioning; when intraday volatility is high relative to the gap, the signal is likely noise.\n                concise Specification: Calculate the 5-day idiosyncratic residual by subtracting the cross-sectional mean return from the stock return; multiply this by the 'Gap Stability' ratio, defined as (Open - Prev_Close) divided by (High - Low + epsilon), using a 5-day lookback for the residual and daily values for the gap.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "538efa2b9476",
      "parent_trajectory_ids": [
        "f202389c67c8",
        "20eb8e999e86"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056491708427519,
        "ICIR": 0.0430405125806527,
        "RankIC": 0.0210635279978666,
        "RankICIR": 0.165275669853,
        "annualized_return": 0.0675573062510109,
        "information_ratio": 0.9526631752292264,
        "max_drawdown": -0.1018099229570179
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:22.466238",
      "updated_at": "2026-01-17T03:23:22.466244"
    },
    "6b701aaf8a0ff560": {
      "factor_id": "6b701aaf8a0ff560",
      "factor_name": "High_Conviction_Exhaustion_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * TS_ZSCORE(($high - $low) / ($close + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8) - 0.5) * (TS_MEAN($return, 60) > 0 ? 1 : -1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * TS_ZSCORE(($high - $low) / ($close + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8) - 0.5) * (TS_MEAN(TS_PCTCHANGE($close, 1), 60) > 0 ? 1 : -1)\" # Your output factor expression will be filled in here\n    name = \"High_Conviction_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion points by combining a 20-day price-volume correlation (regime filter), a 5-day volatility-normalized range stretch (tactical exhaustion), and intraday price skew. It is further filtered by a 60-day momentum threshold to avoid 'falling knife' scenarios.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The High-Conviction Exhaustion Factor combines a 20-day price-volume correlation regime filter with a 5-day volatility-normalized range stretch and intraday price skew to identify high-probability mean-reversion points.\n                Concise Observation: Parent 1 (RankIC 0.029) identifies structural trend weakness via price-volume divergence, while Parent 2 (RankIC 0.023) captures tactical exhaustion; combining them reduces the 'falling knife' risk of pure volatility triggers.\n                Concise Justification: Market reversals are most robust when structural exhaustion (20-day volume divergence) aligns with tactical capitulation (5-day range stretch), as the lack of volume support at price extremes suggests an imminent liquidity vacuum and trend flip.\n                Concise Knowledge: If medium-term price-volume decoupling (negative correlation) signals a loss of trend conviction, then short-term volatility spikes (High-Low range expansion) followed by extreme intraday price positioning (Close relative to Range) act as high-probability triggers for mean reversion.\n                concise Specification: The factor is defined as the product of the 20-day rank-correlation of price and volume, the 5-day Z-score of the (High-Low)/Close range, and the intraday skew ((Close-Low)/(High-Low) - 0.5), filtered by a 60-day price momentum threshold.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2f675cfa4c94",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054294617308086,
        "ICIR": 0.0403817037639643,
        "RankIC": 0.0201054522477108,
        "RankICIR": 0.1507632154211738,
        "annualized_return": 0.0591266192987523,
        "information_ratio": 0.8377864499731825,
        "max_drawdown": -0.1556919240039379
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:41.247648",
      "updated_at": "2026-01-17T03:23:41.247655"
    },
    "9693654b8d3f4aea": {
      "factor_id": "9693654b8d3f4aea",
      "factor_name": "Structural_Tactical_Convergence_Factor",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Tactical_Convergence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis focusing on the convergence of structural price-volume decoupling and short-term range expansion. It uses the rank of the product of volume-price divergence and volatility-normalized range to identify high-probability reversal zones.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The High-Conviction Exhaustion Factor combines a 20-day price-volume correlation regime filter with a 5-day volatility-normalized range stretch and intraday price skew to identify high-probability mean-reversion points.\n                Concise Observation: Parent 1 (RankIC 0.029) identifies structural trend weakness via price-volume divergence, while Parent 2 (RankIC 0.023) captures tactical exhaustion; combining them reduces the 'falling knife' risk of pure volatility triggers.\n                Concise Justification: Market reversals are most robust when structural exhaustion (20-day volume divergence) aligns with tactical capitulation (5-day range stretch), as the lack of volume support at price extremes suggests an imminent liquidity vacuum and trend flip.\n                Concise Knowledge: If medium-term price-volume decoupling (negative correlation) signals a loss of trend conviction, then short-term volatility spikes (High-Low range expansion) followed by extreme intraday price positioning (Close relative to Range) act as high-probability triggers for mean reversion.\n                concise Specification: The factor is defined as the product of the 20-day rank-correlation of price and volume, the 5-day Z-score of the (High-Low)/Close range, and the intraday skew ((Close-Low)/(High-Low) - 0.5), filtered by a 60-day price momentum threshold.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2f675cfa4c94",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054294617308086,
        "ICIR": 0.0403817037639643,
        "RankIC": 0.0201054522477108,
        "RankICIR": 0.1507632154211738,
        "annualized_return": 0.0591266192987523,
        "information_ratio": 0.8377864499731825,
        "max_drawdown": -0.1556919240039379
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:41.266101",
      "updated_at": "2026-01-17T03:23:41.266108"
    },
    "d24956c61051bf92": {
      "factor_id": "d24956c61051bf92",
      "factor_name": "Intraday_Exhaustion_Skew_Factor",
      "factor_expression": "TS_RANK(($high - $low) / ($close + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8) - 0.5) / (1 + ABS(TS_CORR($close, $volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / ($close + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8) - 0.5) / (1 + ABS(TS_CORR($close, $volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_Skew_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures tactical capitulation by measuring the interaction between short-term price range expansion and the relative closing position (skew) within that range, normalized by 20-day volume-price correlation to ensure structural alignment.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The High-Conviction Exhaustion Factor combines a 20-day price-volume correlation regime filter with a 5-day volatility-normalized range stretch and intraday price skew to identify high-probability mean-reversion points.\n                Concise Observation: Parent 1 (RankIC 0.029) identifies structural trend weakness via price-volume divergence, while Parent 2 (RankIC 0.023) captures tactical exhaustion; combining them reduces the 'falling knife' risk of pure volatility triggers.\n                Concise Justification: Market reversals are most robust when structural exhaustion (20-day volume divergence) aligns with tactical capitulation (5-day range stretch), as the lack of volume support at price extremes suggests an imminent liquidity vacuum and trend flip.\n                Concise Knowledge: If medium-term price-volume decoupling (negative correlation) signals a loss of trend conviction, then short-term volatility spikes (High-Low range expansion) followed by extreme intraday price positioning (Close relative to Range) act as high-probability triggers for mean reversion.\n                concise Specification: The factor is defined as the product of the 20-day rank-correlation of price and volume, the 5-day Z-score of the (High-Low)/Close range, and the intraday skew ((Close-Low)/(High-Low) - 0.5), filtered by a 60-day price momentum threshold.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2f675cfa4c94",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054294617308086,
        "ICIR": 0.0403817037639643,
        "RankIC": 0.0201054522477108,
        "RankICIR": 0.1507632154211738,
        "annualized_return": 0.0591266192987523,
        "information_ratio": 0.8377864499731825,
        "max_drawdown": -0.1556919240039379
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:23:41.283759",
      "updated_at": "2026-01-17T03:23:41.283764"
    },
    "5f3f4b1b8c689ea1": {
      "factor_id": "5f3f4b1b8c689ea1",
      "factor_name": "Exhaustion_Stability_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Stability_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price exhaustion by calculating the 5-day average of the ratio between the candle body and the total daily range, weighted by the 10-day R-squared of the price trend. A low body-to-range ratio combined with high trend linearity (R-squared) suggests a potential reversal after a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.722344",
      "updated_at": "2026-01-17T03:25:33.722351"
    },
    "cad94aa0b8ce9de8": {
      "factor_id": "cad94aa0b8ce9de8",
      "factor_name": "Ranked_Exhaustion_Persistence_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the exhaustion hypothesis. It ranks the 5-day smoothed body-to-range ratio and multiplies it by the 10-day price trend persistence (R-squared). This helps identify stocks that are showing the most significant signs of trend exhaustion relative to the market universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.741138",
      "updated_at": "2026-01-17T03:25:33.741144"
    },
    "acd93be4bfe19b46": {
      "factor_id": "acd93be4bfe19b46",
      "factor_name": "Trend_Stability_Rejection_Ratio",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Rejection_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price linearity and intraday rejection. It uses the 10-day R-squared as a filter for trend maturity and measures the relative size of the candle body. Lower values indicate higher reversal probability at the end of a stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day average of the ratio between the daily price body (absolute difference of open and close) and the total daily range (high minus low), weighted by the 10-day R-squared of the price trend, serves as a reversal indicator for price exhaustion.\n                Concise Observation: Market trends often terminate with 'long-shadow' candles or 'dojis' where the price fails to close near its extremes despite high volatility, especially after a period of high trend persistence (RSQR).\n                Concise Justification: A low body-to-range ratio signifies intra-day price rejection; combining this with a high RSQR10 ensures we are identifying these 'exhaustion' signals at the peak of a mature, stable trend rather than in noisy sideways markets.\n                Concise Knowledge: If the daily candle body is small relative to the total range (high-low) while the recent price trend is highly linear (high RSQR), it indicates a loss of directional conviction; when this occurs after a stable trend, a mean-reversion or exhaustion event is likely.\n                concise Specification: Calculate the daily ratio (abs(close-open)/(high-low)), smooth it over a 5-day window, and multiply by the 10-day R-squared of the closing prices to define the 'Exhaustion Stability Factor'.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "original",
      "trajectory_id": "b02e697c8375",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043071631777548,
        "ICIR": 0.0312669358883301,
        "RankIC": 0.0217588620254243,
        "RankICIR": 0.1554834654293152,
        "annualized_return": 0.0500212463677318,
        "information_ratio": 0.7519805747447755,
        "max_drawdown": -0.0993098144555597
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:25:33.758911",
      "updated_at": "2026-01-17T03:25:33.758916"
    },
    "ab48d0b9b27ffa64": {
      "factor_id": "ab48d0b9b27ffa64",
      "factor_name": "Exhaustion_Flow_Divergence_20D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) * TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Flow_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price exhaustion by multiplying the normalized intraday range (volatility spike) with the price-volume correlation. A high range relative to its 20-day average combined with a low or negative price-volume correlation suggests a 'blow-off top' or retail exhaustion, signaling a potential reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid factor 'Exhaustion_Flow_Divergence' is calculated by multiplying the 5-day intraday range normalized by its 20-day ATR with the 20-day rolling correlation between price and volume, capturing high-conviction reversals when volatility spikes are unsupported by volume flow.\n                Concise Observation: Parent 1 (PV correlation) captures trend quality (RankIC 0.029) and Parent 2 (Range expansion) captures volatility extremes (RankIC 0.023), but neither distinguishes between a 'breakout' and a 'blow-off top' in isolation.\n                Concise Justification: By interacting the short-term range stretch with medium-term PV correlation, we create a non-linear filter where the signal strength is amplified only when price urgency (volatility) and flow conviction (correlation) diverge.\n                Concise Knowledge: If a volatility spike (High-Low) occurs with declining price-volume correlation, it indicates a retail-driven exhaustion climax likely to reverse; whereas high correlation during spikes suggests institutional trend confirmation.\n                concise Specification: The factor is defined as ( (High - Low) / SMA(High - Low, 20) ) * Correlation(Close, Volume, 20). A high positive value suggests trend continuation, while a high value with a sign flip in correlation indicates a mean-reversion opportunity.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "993b2c78a85b",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059925956114096,
        "ICIR": 0.0438085618038032,
        "RankIC": 0.021177103155139,
        "RankICIR": 0.1596705791765874,
        "annualized_return": 0.062064173995162,
        "information_ratio": 0.8276913265386626,
        "max_drawdown": -0.1271856852731376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:28:58.715046",
      "updated_at": "2026-01-17T03:28:58.715053"
    },
    "b183dd71e0bcb4a3": {
      "factor_id": "b183dd71e0bcb4a3",
      "factor_name": "Relative_Range_Conviction_10D",
      "factor_expression": "ZSCORE((($high - $low) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high - $low) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the exhaustion hypothesis focusing on short-term price range expansion relative to its recent volatility, weighted by the 10-day price-volume correlation. It identifies whether price movements are supported by volume flow or are merely high-volatility noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid factor 'Exhaustion_Flow_Divergence' is calculated by multiplying the 5-day intraday range normalized by its 20-day ATR with the 20-day rolling correlation between price and volume, capturing high-conviction reversals when volatility spikes are unsupported by volume flow.\n                Concise Observation: Parent 1 (PV correlation) captures trend quality (RankIC 0.029) and Parent 2 (Range expansion) captures volatility extremes (RankIC 0.023), but neither distinguishes between a 'breakout' and a 'blow-off top' in isolation.\n                Concise Justification: By interacting the short-term range stretch with medium-term PV correlation, we create a non-linear filter where the signal strength is amplified only when price urgency (volatility) and flow conviction (correlation) diverge.\n                Concise Knowledge: If a volatility spike (High-Low) occurs with declining price-volume correlation, it indicates a retail-driven exhaustion climax likely to reverse; whereas high correlation during spikes suggests institutional trend confirmation.\n                concise Specification: The factor is defined as ( (High - Low) / SMA(High - Low, 20) ) * Correlation(Close, Volume, 20). A high positive value suggests trend continuation, while a high value with a sign flip in correlation indicates a mean-reversion opportunity.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "993b2c78a85b",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059925956114096,
        "ICIR": 0.0438085618038032,
        "RankIC": 0.021177103155139,
        "RankICIR": 0.1596705791765874,
        "annualized_return": 0.062064173995162,
        "information_ratio": 0.8276913265386626,
        "max_drawdown": -0.1271856852731376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:28:58.733610",
      "updated_at": "2026-01-17T03:28:58.733615"
    },
    "4d4bc33fafeeed85": {
      "factor_id": "4d4bc33fafeeed85",
      "factor_name": "Exhaustion_Volume_Decay_15D",
      "factor_expression": "(($high - $low) / (TS_MEDIAN($high - $low, 15) + 1e-8)) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (TS_MEDIAN($high - $low, 15) + 1e-8)) * TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 15)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Volume_Decay_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies exhaustion by comparing the current intraday range to its median and interacting it with the 15-day correlation between price returns and volume changes. It aims to detect trend weakening when price ranges expand but volume support (correlation) diminishes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid factor 'Exhaustion_Flow_Divergence' is calculated by multiplying the 5-day intraday range normalized by its 20-day ATR with the 20-day rolling correlation between price and volume, capturing high-conviction reversals when volatility spikes are unsupported by volume flow.\n                Concise Observation: Parent 1 (PV correlation) captures trend quality (RankIC 0.029) and Parent 2 (Range expansion) captures volatility extremes (RankIC 0.023), but neither distinguishes between a 'breakout' and a 'blow-off top' in isolation.\n                Concise Justification: By interacting the short-term range stretch with medium-term PV correlation, we create a non-linear filter where the signal strength is amplified only when price urgency (volatility) and flow conviction (correlation) diverge.\n                Concise Knowledge: If a volatility spike (High-Low) occurs with declining price-volume correlation, it indicates a retail-driven exhaustion climax likely to reverse; whereas high correlation during spikes suggests institutional trend confirmation.\n                concise Specification: The factor is defined as ( (High - Low) / SMA(High - Low, 20) ) * Correlation(Close, Volume, 20). A high positive value suggests trend continuation, while a high value with a sign flip in correlation indicates a mean-reversion opportunity.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "993b2c78a85b",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "a951f9cf59d1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059925956114096,
        "ICIR": 0.0438085618038032,
        "RankIC": 0.021177103155139,
        "RankICIR": 0.1596705791765874,
        "annualized_return": 0.062064173995162,
        "information_ratio": 0.8276913265386626,
        "max_drawdown": -0.1271856852731376
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:28:58.751698",
      "updated_at": "2026-01-17T03:28:58.751704"
    },
    "4834dbee6b9fd7f3": {
      "factor_id": "4834dbee6b9fd7f3",
      "factor_name": "MDEC_Exhaustion_Reversal_10D",
      "factor_expression": "(RANK(TS_RANK($return, 10)) - RANK(TS_RANK($return * $volume, 10))) * INV(1 + ABS(TS_CORR($return, $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_RANK(TS_PCTCHANGE($close, 1), 10)) - RANK(TS_RANK(TS_PCTCHANGE($close, 1) * $volume, 10))) * INV(1 + ABS(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10))) * (ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 0.00001))\" # Your output factor expression will be filled in here\n    name = \"MDEC_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price reversals by detecting momentum-volume divergence. It calculates the difference between price return rank and volume-weighted momentum rank, scaled by the inverse of return-volume correlation and the ratio of overnight gaps to intraday volatility. High values signal 'hollow' price moves likely to mean-revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Dimensional Exhaustion Convergence (MDEC) factor predicts short-term reversals by identifying 10-day price-volume momentum divergences that are validated by a decay in return-volume correlation and an increase in the ratio of overnight gaps to intraday volatility.\n                Concise Observation: Parent 1 (RankIC 0.0239) identifies simple momentum-volume divergence, while Parent 2 (RankIC 0.0271) captures structural decay in volume support; combining these filters reduces false positives in trend-following by isolating 'hollow' price moves.\n                Concise Justification: A price trend lacking volume correlation indicates diminishing liquidity support, and a high overnight-to-intraday range ratio suggests that price discovery is shifting away from active trading sessions, both of which are hallmarks of trend exhaustion.\n                Concise Knowledge: If price momentum diverges from volume-weighted momentum while the rolling correlation between returns and volume decreases, the trend is likely driven by low-conviction flows; when this coincides with expanding overnight gaps relative to intraday ranges, it signals institutional exhaustion and an impending mean reversion.\n                concise Specification: Calculate the difference between 10-day price return percentile and 10-day VWAP momentum percentile; multiply this by the inverse of the 10-day rolling correlation between daily returns and volume, and scale by the ratio of the absolute overnight gap (abs(open - prev_close)) to the 10-day average intraday range (high - low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "977c8dae85e8",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "17cebd62c163"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:31:51.502092",
      "updated_at": "2026-01-17T03:31:51.502099"
    },
    "253fe3b93ae08cc4": {
      "factor_id": "253fe3b93ae08cc4",
      "factor_name": "Hollow_Trend_Divergence_10D",
      "factor_expression": "RANK(TS_RANK($return, 10) - TS_RANK($return * $volume, 10)) * RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) / (1 + TS_CORR($return, $volume, 10))",
      "factor_implementation_code": "",
      "factor_description": "Focuses on the structural decay of volume support during price trends. It measures the divergence between price returns and volume-weighted returns, weighted by the cross-sectional rank of the overnight gap ratio. A higher divergence with lower volume correlation indicates trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Dimensional Exhaustion Convergence (MDEC) factor predicts short-term reversals by identifying 10-day price-volume momentum divergences that are validated by a decay in return-volume correlation and an increase in the ratio of overnight gaps to intraday volatility.\n                Concise Observation: Parent 1 (RankIC 0.0239) identifies simple momentum-volume divergence, while Parent 2 (RankIC 0.0271) captures structural decay in volume support; combining these filters reduces false positives in trend-following by isolating 'hollow' price moves.\n                Concise Justification: A price trend lacking volume correlation indicates diminishing liquidity support, and a high overnight-to-intraday range ratio suggests that price discovery is shifting away from active trading sessions, both of which are hallmarks of trend exhaustion.\n                Concise Knowledge: If price momentum diverges from volume-weighted momentum while the rolling correlation between returns and volume decreases, the trend is likely driven by low-conviction flows; when this coincides with expanding overnight gaps relative to intraday ranges, it signals institutional exhaustion and an impending mean reversion.\n                concise Specification: Calculate the difference between 10-day price return percentile and 10-day VWAP momentum percentile; multiply this by the inverse of the 10-day rolling correlation between daily returns and volume, and scale by the ratio of the absolute overnight gap (abs(open - prev_close)) to the 10-day average intraday range (high - low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "977c8dae85e8",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "17cebd62c163"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:31:51.520639",
      "updated_at": "2026-01-17T03:31:51.520644"
    },
    "f32b0d6bfb71bef4": {
      "factor_id": "f32b0d6bfb71bef4",
      "factor_name": "Institutional_Exhaustion_Gap_10D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8), 10) * (1 - TS_CORR($return, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 0.001), 10) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Signals mean reversion by identifying periods where price discovery happens primarily overnight (gaps) while intraday volume-return correlation drops, suggesting a lack of active market participation in the current trend.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Multi-Dimensional Exhaustion Convergence (MDEC) factor predicts short-term reversals by identifying 10-day price-volume momentum divergences that are validated by a decay in return-volume correlation and an increase in the ratio of overnight gaps to intraday volatility.\n                Concise Observation: Parent 1 (RankIC 0.0239) identifies simple momentum-volume divergence, while Parent 2 (RankIC 0.0271) captures structural decay in volume support; combining these filters reduces false positives in trend-following by isolating 'hollow' price moves.\n                Concise Justification: A price trend lacking volume correlation indicates diminishing liquidity support, and a high overnight-to-intraday range ratio suggests that price discovery is shifting away from active trading sessions, both of which are hallmarks of trend exhaustion.\n                Concise Knowledge: If price momentum diverges from volume-weighted momentum while the rolling correlation between returns and volume decreases, the trend is likely driven by low-conviction flows; when this coincides with expanding overnight gaps relative to intraday ranges, it signals institutional exhaustion and an impending mean reversion.\n                concise Specification: Calculate the difference between 10-day price return percentile and 10-day VWAP momentum percentile; multiply this by the inverse of the 10-day rolling correlation between daily returns and volume, and scale by the ratio of the absolute overnight gap (abs(open - prev_close)) to the 10-day average intraday range (high - low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "977c8dae85e8",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "17cebd62c163"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:31:51.538673",
      "updated_at": "2026-01-17T03:31:51.538679"
    },
    "29b0d7c09ec7d71a": {
      "factor_id": "29b0d7c09ec7d71a",
      "factor_name": "LAME_Divergence_Efficiency_10D_5D",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"LAME_Divergence_Efficiency_10D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Liquidity-Adjusted Momentum Exhaustion (LAME) factor. It identifies fragile price trends by multiplying the divergence between price momentum and volume-weighted momentum (VWAP-like) with the recent average intraday price-volume efficiency. High values indicate price trends that are 'expensive' in terms of liquidity, signaling potential mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Momentum Exhaustion (LAME) factor, calculated as the product of the 10-day price-volume trend divergence and the 5-day average intraday price-volume efficiency, identifies fragile price trends prone to mean reversion.\n                Concise Observation: Parent strategies show that price-volume divergence (RankIC 0.0239) and intraday efficiency (RankIC 0.0265) both capture exhaustion, but individual signals often fail during high-liquidity trend continuations.\n                Concise Justification: Combining divergence with efficiency filters for 'expensive' price movements; a trend that requires high volatility on low relative volume to sustain itself is fundamentally unstable compared to one backed by dense liquidity.\n                Concise Knowledge: If a stock exhibits high price momentum relative to its volume-weighted momentum while simultaneously showing high intraday range per unit volume, then the trend is likely liquidity-constrained and prone to reversal.\n                concise Specification: Define Divergence as the difference between 10-day price change percentile and 10-day VWAP momentum percentile; define IPVE as (High-Low)/Volume; the factor is the product of Divergence and the 5-day moving average of IPVE.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a685230d9429",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:34:38.127860",
      "updated_at": "2026-01-17T03:34:38.127869"
    },
    "29de2f90c029124e": {
      "factor_id": "29de2f90c029124e",
      "factor_name": "LAME_ZScore_Efficiency_Trend",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 10) - TS_PCTCHANGE($close * $volume, 10)) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 10) - TS_PCTCHANGE($close * $volume, 10)) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"LAME_ZScore_Efficiency_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the LAME hypothesis focusing on the z-score of price-volume divergence relative to the efficiency of price discovery. It captures the degree to which price is overextending relative to the liquidity required to move it.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Momentum Exhaustion (LAME) factor, calculated as the product of the 10-day price-volume trend divergence and the 5-day average intraday price-volume efficiency, identifies fragile price trends prone to mean reversion.\n                Concise Observation: Parent strategies show that price-volume divergence (RankIC 0.0239) and intraday efficiency (RankIC 0.0265) both capture exhaustion, but individual signals often fail during high-liquidity trend continuations.\n                Concise Justification: Combining divergence with efficiency filters for 'expensive' price movements; a trend that requires high volatility on low relative volume to sustain itself is fundamentally unstable compared to one backed by dense liquidity.\n                Concise Knowledge: If a stock exhibits high price momentum relative to its volume-weighted momentum while simultaneously showing high intraday range per unit volume, then the trend is likely liquidity-constrained and prone to reversal.\n                concise Specification: Define Divergence as the difference between 10-day price change percentile and 10-day VWAP momentum percentile; define IPVE as (High-Low)/Volume; the factor is the product of Divergence and the 5-day moving average of IPVE.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a685230d9429",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:34:38.146402",
      "updated_at": "2026-01-17T03:34:38.146408"
    },
    "40f08d46d096ced8": {
      "factor_id": "40f08d46d096ced8",
      "factor_name": "LAME_Rank_Efficiency_Product",
      "factor_expression": "(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_PCTCHANGE($close * $volume, 10))) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"LAME_Rank_Efficiency_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the LAME hypothesis by using the cross-sectional rank of the intraday price-volume efficiency multiplied by the momentum divergence. This ensures the factor is robust to outliers in volume and price range across different stocks.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Momentum Exhaustion (LAME) factor, calculated as the product of the 10-day price-volume trend divergence and the 5-day average intraday price-volume efficiency, identifies fragile price trends prone to mean reversion.\n                Concise Observation: Parent strategies show that price-volume divergence (RankIC 0.0239) and intraday efficiency (RankIC 0.0265) both capture exhaustion, but individual signals often fail during high-liquidity trend continuations.\n                Concise Justification: Combining divergence with efficiency filters for 'expensive' price movements; a trend that requires high volatility on low relative volume to sustain itself is fundamentally unstable compared to one backed by dense liquidity.\n                Concise Knowledge: If a stock exhibits high price momentum relative to its volume-weighted momentum while simultaneously showing high intraday range per unit volume, then the trend is likely liquidity-constrained and prone to reversal.\n                concise Specification: Define Divergence as the difference between 10-day price change percentile and 10-day VWAP momentum percentile; define IPVE as (High-Low)/Volume; the factor is the product of Divergence and the 5-day moving average of IPVE.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a685230d9429",
      "parent_trajectory_ids": [
        "e4018d0555c2",
        "5c95bd6eae0f"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:34:38.164585",
      "updated_at": "2026-01-17T03:34:38.164590"
    },
    "525b9fd9ff076a5a": {
      "factor_id": "525b9fd9ff076a5a",
      "factor_name": "Liquidity_Exhaustion_Reversion_20D",
      "factor_expression": "(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close / (($open + $high + $low + $close) / 4)) - 1) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 20-day abnormal turnover ratio. A high positive value indicates a 'blow-off top' where prices are pushed significantly above the average intraday cost on high volume, suggesting liquidity exhaustion and a likely downward reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.768309",
      "updated_at": "2026-01-17T03:37:08.768316"
    },
    "78b1d1c3e8ceffa4": {
      "factor_id": "78b1d1c3e8ceffa4",
      "factor_name": "Ranked_Intraday_Exhaustion_10D",
      "factor_expression": "RANK(($close - ($high + $low) / 2) / (($high + $low) / 2 + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - ($high + $low) / 2) / (($high + $low) / 2 + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Intraday_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the liquidity exhaustion hypothesis. It measures the divergence of the close from the intraday mid-point, scaled by the relative volume intensity over 10 days. By using RANK, it focuses on the stocks with the most extreme exhaustion signals relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.787163",
      "updated_at": "2026-01-17T03:37:08.787169"
    },
    "7147211d46e7ca79": {
      "factor_id": "7147211d46e7ca79",
      "factor_name": "ZScored_Liquidity_Divergence_15D",
      "factor_expression": "TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close / (($open + $high + $low + $close) / 4), 15) + TS_ZSCORE($volume, 15)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Liquidity_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the price-VWAP deviation and the Z-score of volume to identify statistical outliers in liquidity consumption. It captures periods where the price is at a multi-standard deviation distance from the daily average price on significantly higher-than-normal volume.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversion Factor identifies mean reversion opportunities by calculating the product of the late-session price-VWAP divergence and the 5-day abnormal turnover ratio, capturing periods where retail-driven price pushes exceed market maker liquidity capacity.\n                Concise Observation: While the parent strategy focused on overnight gaps and institutional support floors, market data often exhibits intraday 'blow-off tops' or 'selling climaxes' where high turnover at price extremes (relative to VWAP) precedes a sharp reversal in the subsequent sessions.\n                Concise Justification: The divergence between the Close and VWAP serves as a proxy for late-day price manipulation or retail FOMO, which, when coupled with abnormal turnover, indicates that the current trend has exhausted available liquidity and is prone to mean reversion.\n                Concise Knowledge: If the closing price deviates significantly from the Volume-Weighted Average Price (VWAP) under conditions of extreme relative turnover, then the price is likely to revert; when volume-weighted conviction fails to support the final price print, liquidity exhaustion triggers a trend reversal.\n                concise Specification: The factor is defined as ((Close / VWAP) - 1) * (Turnover / TS_MEAN(Turnover, 20)), where VWAP is approximated as (Open + High + Low + Close) / 4 or (Volume * Price) proxies; the expected relationship is a negative correlation with future returns over a 1-5 day horizon.\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "4557f861aea5",
      "parent_trajectory_ids": [
        "3c9e614ed4e3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078335046700758,
        "ICIR": 0.0577883219638908,
        "RankIC": 0.0247815152342388,
        "RankICIR": 0.1839845859353132,
        "annualized_return": 0.0794678135596061,
        "information_ratio": 1.195706280993639,
        "max_drawdown": -0.0804043522238998
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:08.805539",
      "updated_at": "2026-01-17T03:37:08.805545"
    },
    "82b73f670ff5b1f9": {
      "factor_id": "82b73f670ff5b1f9",
      "factor_name": "Structural_Exhaustion_Reversal_Factor",
      "factor_expression": "TS_CORR($return, $volume, 20) * (($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20) * (($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by combining 20-day price-volume decoupling (exhaustion) with an overnight price gap normalized by recent intraday volatility. It targets assets where a tactical liquidity shock occurs after a period of structural trend weakening.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid reversal signal combining structural price-volume decoupling over 20 days with overnight price gaps normalized by 5-day intraday volatility identifies high-probability mean-reversion points in assets exhibiting medium-term trend exhaustion.\n                Concise Observation: Parent 1 showed that 20-day price-volume decoupling (RankIC 0.029) captures structural exhaustion, while Parent 2 demonstrated that overnight gaps relative to volatility (RankIC 0.022) capture short-term liquidity shocks.\n                Concise Justification: Normalizing the overnight gap by the 5-day average true range ensures the signal is sensitive to the current volatility regime, while the 20-day price-volume correlation filters for assets already in a state of drift, preventing 'falling knife' entries during high-conviction trends.\n                Concise Knowledge: If a medium-term negative correlation between price and volume indicates trend exhaustion, then an overnight price gap that is disproportionate to recent intraday volatility serves as a tactical liquidity shock, triggering a higher probability reversal; When structural divergence and tactical imbalances align, the predictive power of mean reversion increases.\n                concise Specification: Calculate the 20-day correlation between daily returns and volume; calculate the overnight gap (Open_t / Close_{t-1} - 1) and divide it by the 5-day mean of (High - Low); the factor is the product of this volatility-adjusted gap and the 20-day correlation, further conditioned by the 60-day cumulative return.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4cf51b1d412c",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054274865645129,
        "ICIR": 0.0400660580256816,
        "RankIC": 0.0227679384440127,
        "RankICIR": 0.1735880949033326,
        "annualized_return": 0.0885021449087228,
        "information_ratio": 1.4742681484192723,
        "max_drawdown": -0.0738424159308874
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:32.742317",
      "updated_at": "2026-01-17T03:37:32.742323"
    },
    "415a0997df699516": {
      "factor_id": "415a0997df699516",
      "factor_name": "Volatility_Adjusted_Gap_Exhaustion",
      "factor_expression": "RANK(TS_CORR($return, $volume, 20)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * SIGN(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * SIGN(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined reversal signal that scales the overnight gap by the 5-day average range and interacts it with the 20-day price-volume correlation. It is further filtered by the 60-day price momentum to ensure the reversal is occurring in a context of medium-term trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid reversal signal combining structural price-volume decoupling over 20 days with overnight price gaps normalized by 5-day intraday volatility identifies high-probability mean-reversion points in assets exhibiting medium-term trend exhaustion.\n                Concise Observation: Parent 1 showed that 20-day price-volume decoupling (RankIC 0.029) captures structural exhaustion, while Parent 2 demonstrated that overnight gaps relative to volatility (RankIC 0.022) capture short-term liquidity shocks.\n                Concise Justification: Normalizing the overnight gap by the 5-day average true range ensures the signal is sensitive to the current volatility regime, while the 20-day price-volume correlation filters for assets already in a state of drift, preventing 'falling knife' entries during high-conviction trends.\n                Concise Knowledge: If a medium-term negative correlation between price and volume indicates trend exhaustion, then an overnight price gap that is disproportionate to recent intraday volatility serves as a tactical liquidity shock, triggering a higher probability reversal; When structural divergence and tactical imbalances align, the predictive power of mean reversion increases.\n                concise Specification: Calculate the 20-day correlation between daily returns and volume; calculate the overnight gap (Open_t / Close_{t-1} - 1) and divide it by the 5-day mean of (High - Low); the factor is the product of this volatility-adjusted gap and the 20-day correlation, further conditioned by the 60-day cumulative return.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4cf51b1d412c",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054274865645129,
        "ICIR": 0.0400660580256816,
        "RankIC": 0.0227679384440127,
        "RankICIR": 0.1735880949033326,
        "annualized_return": 0.0885021449087228,
        "information_ratio": 1.4742681484192723,
        "max_drawdown": -0.0738424159308874
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:32.761510",
      "updated_at": "2026-01-17T03:37:32.761516"
    },
    "495b8e01cf3df69a": {
      "factor_id": "495b8e01cf3df69a",
      "factor_name": "Decoupled_Gap_Mean_Reversion",
      "factor_expression": "ZSCORE(TS_CORR($return, $volume, 20)) + ZSCORE(($open - DELAY($close, 1)) / (DELAY(TS_STD($return, 20) * $close, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20)) + ZSCORE(($open - DELAY($close, 1)) / (DELAY(TS_STD(TS_PCTCHANGE($close, 1), 20) * $close, 1) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Gap_Mean_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the alignment of structural divergence (price-volume correlation) and tactical imbalances (overnight gaps). It uses Z-scoring to normalize the components and focuses on the interaction between liquidity shocks and trend fragility.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A hybrid reversal signal combining structural price-volume decoupling over 20 days with overnight price gaps normalized by 5-day intraday volatility identifies high-probability mean-reversion points in assets exhibiting medium-term trend exhaustion.\n                Concise Observation: Parent 1 showed that 20-day price-volume decoupling (RankIC 0.029) captures structural exhaustion, while Parent 2 demonstrated that overnight gaps relative to volatility (RankIC 0.022) capture short-term liquidity shocks.\n                Concise Justification: Normalizing the overnight gap by the 5-day average true range ensures the signal is sensitive to the current volatility regime, while the 20-day price-volume correlation filters for assets already in a state of drift, preventing 'falling knife' entries during high-conviction trends.\n                Concise Knowledge: If a medium-term negative correlation between price and volume indicates trend exhaustion, then an overnight price gap that is disproportionate to recent intraday volatility serves as a tactical liquidity shock, triggering a higher probability reversal; When structural divergence and tactical imbalances align, the predictive power of mean reversion increases.\n                concise Specification: Calculate the 20-day correlation between daily returns and volume; calculate the overnight gap (Open_t / Close_{t-1} - 1) and divide it by the 5-day mean of (High - Low); the factor is the product of this volatility-adjusted gap and the 20-day correlation, further conditioned by the 60-day cumulative return.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "4cf51b1d412c",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054274865645129,
        "ICIR": 0.0400660580256816,
        "RankIC": 0.0227679384440127,
        "RankICIR": 0.1735880949033326,
        "annualized_return": 0.0885021449087228,
        "information_ratio": 1.4742681484192723,
        "max_drawdown": -0.0738424159308874
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:37:32.780545",
      "updated_at": "2026-01-17T03:37:32.780551"
    },
    "5223064962986e06": {
      "factor_id": "5223064962986e06",
      "factor_name": "Micro_Stability_Absorption_3D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 3)) * -1",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 3)) * -1\" # Your output factor expression will be filled in here\n    name = \"Micro_Stability_Absorption_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional price absorption by measuring the 3-day average of the ratio between intraday price range and volume. A lower ratio indicates high volume with low price volatility, suggesting hidden liquidity is clearing orders without slippage. The factor is cross-sectionally ranked to identify stocks with the highest micro-structure stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.416884",
      "updated_at": "2026-01-17T03:39:34.416891"
    },
    "c3c1d58825d6e03f": {
      "factor_id": "c3c1d58825d6e03f",
      "factor_name": "Absorption_Breakout_Proximity_3D",
      "factor_expression": "($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close / TS_MAX($high, 3)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Absorption_Breakout_Proximity_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the micro-structure stability (low range-to-volume ratio) with the proximity of the current price to the 3-day high. It targets breakout continuation by identifying stocks where absorption is occurring near resistance levels. The stability component is inverted so that higher values represent more stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.435984",
      "updated_at": "2026-01-17T03:39:34.435990"
    },
    "643d95ac0e36ae82": {
      "factor_id": "643d95ac0e36ae82",
      "factor_name": "Relative_Absorption_Intensity_5D",
      "factor_expression": "1 - TS_RANK(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"1 - TS_RANK(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Relative_Absorption_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of price absorption by comparing the current range-to-volume ratio to its 5-day historical distribution using TS_RANK. A low time-series rank of the ratio indicates a significant increase in micro-structure stability relative to the stock's own recent history, signaling institutional clearing.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Micro-Structure Stability factor, defined by the inverse ratio of intraday price range to volume intensity over a 3-day window, identifies price absorption by institutional liquidity providers, predicting trend continuation.\n                Concise Observation: While the parent strategy focused on price-volume divergence as a sign of exhaustion and reversal, market data often shows periods where high volume fails to move prices significantly, suggesting 'absorption' rather than 'exhaustion'.\n                Concise Justification: Low price variance during high-volume periods suggests market makers or large institutions are providing liquidity at specific price levels, effectively 'clearing' the order book without allowing price slippage, which typically precedes a strong directional move once the absorption phase ends.\n                Concise Knowledge: If a stock exhibits high trading volume relative to its intraday price volatility (low range-to-volume ratio), it indicates the presence of hidden liquidity (iceberg orders) absorbing market pressure; when this stability occurs near the daily high or low, a breakout continuation is likely.\n                concise Specification: The factor is calculated as the 3-day moving average of the ratio ($high - $low) / $volume; lower values represent higher micro-structure stability and absorption, which are expected to positively correlate with future returns when the current price is near the 3-day high.\n                ",
      "initial_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Intraday Support Persistence: Measure the 3-day moving average of KLOW relative to the daily trading range to identify stocks with consistent structural buying pressure.",
      "evolution_phase": "mutation",
      "trajectory_id": "29d3a8a615a0",
      "parent_trajectory_ids": [
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049750723441706,
        "ICIR": 0.0365101155632983,
        "RankIC": 0.0229019107448328,
        "RankICIR": 0.1716822284735126,
        "annualized_return": 0.0341146889735628,
        "information_ratio": 0.5229023894183041,
        "max_drawdown": -0.1058289648801805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:39:34.454766",
      "updated_at": "2026-01-17T03:39:34.454771"
    },
    "2cd7851c51b79b5a": {
      "factor_id": "2cd7851c51b79b5a",
      "factor_name": "Stability_Reversion_RSQR_WVMA_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stability_Reversion_RSQR_WVMA_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by multiplying the trend stability (R-squared of price against time) with the price deviation from a Volume Weighted Moving Average. High R-squared indicates a consensus-driven trend, while a large deviation from WVMA suggests exhaustion. The factor uses TS_CORR squared to represent R-squared and a volume-weighted price proxy.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.879266",
      "updated_at": "2026-01-17T03:40:59.879273"
    },
    "ec7e0fd06961de67": {
      "factor_id": "ec7e0fd06961de67",
      "factor_name": "Trend_Exhaustion_Linearity_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Linearity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stability-reversion hypothesis focusing on a shorter 5-day window. It captures the interaction between the linearity of the price trend (R-squared) and the standardized distance from the volume-weighted average price to detect speculative blow-off points.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.899548",
      "updated_at": "2026-01-17T03:40:59.899554"
    },
    "71202d9fd3bd3bce": {
      "factor_id": "71202d9fd3bd3bce",
      "factor_name": "Cross_Sectional_Stability_Reversion",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Stability_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies cross-sectional ranking to the stability-reversion logic. It ranks the trend linearity (R-squared) and the volume-weighted price residual separately before combining them, ensuring the factor is robust across different market regimes and asset scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stability-Reversion' factor, defined as the product of the 10-day R-squared of price against time and the 5-day Volume Weighted Moving Average (WVMA) deviation from price, identifies mean-reversion opportunities where high trend stability is coupled with over-extended price-volume exhaustion.\n                Concise Observation: Market trends often show high statistical linearity just before exhaustion; combining a measure of fit (RSQR10) with a volume-weighted price distance (WVMA5) can capture the specific moment when stable growth becomes unsustainable.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but when this 'stability' occurs at price levels significantly detached from the volume-weighted average, it suggests a speculative blow-off top or bottom ripe for reversal.\n                Concise Knowledge: If a price trend exhibits high linear stability (RSQR) while simultaneously reaching extreme volume-weighted price levels (WVMA), the probability of a corrective mean-reversion increases as the trend's structural integrity exhausts its liquidity support.\n                concise Specification: Calculate RSQR over a 10-day window of daily close prices against a time index; calculate WVMA over 5 days; the factor is the interaction (product) of RSQR10 and the standardized residual of (Close - WVMA5).\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "original",
      "trajectory_id": "2d0e4ff6d5dc",
      "parent_trajectory_ids": [],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0098091580601709,
        "ICIR": 0.0673059445533896,
        "RankIC": 0.0219378534446624,
        "RankICIR": 0.1572197738446831,
        "annualized_return": 0.0456953138265331,
        "information_ratio": 0.6126699497043858,
        "max_drawdown": -0.1032345691094138
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:40:59.918294",
      "updated_at": "2026-01-17T03:40:59.918300"
    },
    "464853529eb9b105": {
      "factor_id": "464853529eb9b105",
      "factor_name": "Delta_RESI5_Convexity",
      "factor_expression": "DELTA($close - TS_MEAN($close, 5), 5) / (TS_STD($close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA($close - TS_MEAN($close, 5), 5) / (TS_STD($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Delta_RESI5_Convexity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 5-day rate of change in the price residual (current price minus its 5-day mean), normalized by the 5-day price volatility. A sharp increase in this residual velocity indicates price acceleration away from the mean, suggesting trend exhaustion and potential mean-reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.105605",
      "updated_at": "2026-01-17T03:43:00.105611"
    },
    "ac2e9b90c0052852": {
      "factor_id": "ac2e9b90c0052852",
      "factor_name": "ZScore_Residual_Velocity_5D",
      "factor_expression": "RANK(DELTA(TS_ZSCORE($close, 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_ZSCORE($close, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Residual_Velocity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the residual convexity hypothesis that uses the 5-day change in the Z-scored price deviation. By calculating the change in how many standard deviations the price is from its mean over a 5-day window, it identifies accelerating speculative climaxes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.125338",
      "updated_at": "2026-01-17T03:43:00.125344"
    },
    "ada1d67af3c47fe6": {
      "factor_id": "ada1d67af3c47fe6",
      "factor_name": "Normalized_Exhaustion_Index_5D",
      "factor_expression": "(($close - TS_MEAN($close, 5)) - DELAY($close - TS_MEAN($close, 5), 5)) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - TS_MEAN($close, 5)) - DELAY($close - TS_MEAN($close, 5), 5)) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the second-order momentum of price residuals. It calculates the difference between the current residual and its 5-day lag, scaled by the 20-day volatility to provide a more stable normalization against long-term regime changes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 5-day rate of change in the volatility-normalized price residual (Delta-RESI5) identifies the 'convexity' of price movements, where a sharp acceleration in residuals indicates trend exhaustion and an imminent mean-reversion, even before price action confirms a peak.\n                Concise Observation: Previous mean-reversion factors (RankIC=0.0199) focused on static residual levels, often entering too early during parabolic moves; observing the velocity of change in these residuals (RESI5) can differentiate between a steady trend and an overextended exhaustion point.\n                Concise Justification: By calculating the 5-day change in the residual (Delta-RESI), we capture the momentum of the error term; a high positive Delta-RESI suggests the asset is moving away from its mean at an accelerating rate, which is physically and economically unsustainable, leading to a 'snap-back' effect.\n                Concise Knowledge: If the second derivative of price residuals (convexity) increases sharply while volatility remains constant, the current trend is likely driven by speculative climax rather than sustainable flow; when this acceleration peaks, the probability of a sharp reversal increases.\n                concise Specification: The factor is defined as the difference between the current 5-day price residual (Price - 5D Mean) and its value 5 days ago, normalized by the 5-day price standard deviation to ensure cross-sectional comparability across different volatility regimes.\n                ",
      "initial_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Convexity of Price Extremes: Calculate the 5-day change in RESI5 (Delta-Resi) to detect accelerating trend exhaustion before a formal reversal occurs.",
      "evolution_phase": "mutation",
      "trajectory_id": "3089f0226d6b",
      "parent_trajectory_ids": [
        "f6e466a375f5"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008855674484948,
        "ICIR": 0.0653472704154563,
        "RankIC": 0.0237151075456045,
        "RankICIR": 0.1828286912711504,
        "annualized_return": 0.0812270459717321,
        "information_ratio": 1.324605423732854,
        "max_drawdown": -0.0796451516927676
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:00.144818",
      "updated_at": "2026-01-17T03:43:00.144824"
    },
    "ce9a3652c285e455": {
      "factor_id": "ce9a3652c285e455",
      "factor_name": "PV_Regime_Overnight_Exhaustion_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * (($open - DELAY($close, 1)) / (MAX(DELAY($high - $low, 1), 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (($open - DELAY($close, 1)) / (MAX(DELAY($high - $low, 1), 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"PV_Regime_Overnight_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by combining a 20-day price-volume correlation (regime filter) with an overnight return normalized by the previous day's volatility. It targets liquidity gaps that occur during phases of trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of a 20-day price-volume correlation scaled by the 14-day Average True Range and the ratio of overnight returns to the previous day's high-low range identifies high-conviction mean-reversion opportunities during structural liquidity gaps.\n                Concise Observation: Parent 1 (RankIC 0.029) captures regime-based alpha via price-volume correlation, while Parent 2 (RankIC 0.022) identifies overnight exhaustion; combining them addresses the noise inherent in high-frequency signals by filtering for structural regimes.\n                Concise Justification: The 20-day PV correlation acts as a regime filter that validates whether an overnight gap is occurring within a trend-exhaustion phase, while the intraday-range-normalized overnight return provides the specific execution trigger.\n                Concise Knowledge: If long-term price-volume divergence coincides with high structural volatility, then short-term overnight price shocks are more likely to represent exhaustible liquidity gaps rather than sustainable trend continuations.\n                concise Specification: Define Regime_Multiplier as CORR($close, $volume, 20) * (ATR($high, $low, $close, 14) / $close) and Liquidity_Trigger as ($open / delay($close, 1) - 1) / (($high - $low) / $close); the final factor is the product of these two components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f030eae56348",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0102457687069676,
        "ICIR": 0.0677039951765419,
        "RankIC": 0.0313366592666852,
        "RankICIR": 0.2112574251923435,
        "annualized_return": 0.0569777081135771,
        "information_ratio": 0.8481474170356921,
        "max_drawdown": -0.0962304710287989
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:45.472231",
      "updated_at": "2026-01-17T03:43:45.472239"
    },
    "07dccb9ed49d527d": {
      "factor_id": "07dccb9ed49d527d",
      "factor_name": "Structural_Liquidity_Gap_V2",
      "factor_expression": "TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / $close) * (($open - DELAY($close, 1)) / DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / $close) * (($open - DELAY($close, 1)) / DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"Structural_Liquidity_Gap_V2\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity gap hypothesis that uses the 14-day range-based volatility (ATR proxy) to scale the price-volume regime, multiplied by the overnight gap relative to the previous day's close. This captures high-conviction reversals in volatile regimes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of a 20-day price-volume correlation scaled by the 14-day Average True Range and the ratio of overnight returns to the previous day's high-low range identifies high-conviction mean-reversion opportunities during structural liquidity gaps.\n                Concise Observation: Parent 1 (RankIC 0.029) captures regime-based alpha via price-volume correlation, while Parent 2 (RankIC 0.022) identifies overnight exhaustion; combining them addresses the noise inherent in high-frequency signals by filtering for structural regimes.\n                Concise Justification: The 20-day PV correlation acts as a regime filter that validates whether an overnight gap is occurring within a trend-exhaustion phase, while the intraday-range-normalized overnight return provides the specific execution trigger.\n                Concise Knowledge: If long-term price-volume divergence coincides with high structural volatility, then short-term overnight price shocks are more likely to represent exhaustible liquidity gaps rather than sustainable trend continuations.\n                concise Specification: Define Regime_Multiplier as CORR($close, $volume, 20) * (ATR($high, $low, $close, 14) / $close) and Liquidity_Trigger as ($open / delay($close, 1) - 1) / (($high - $low) / $close); the final factor is the product of these two components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f030eae56348",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0102457687069676,
        "ICIR": 0.0677039951765419,
        "RankIC": 0.0313366592666852,
        "RankICIR": 0.2112574251923435,
        "annualized_return": 0.0569777081135771,
        "information_ratio": 0.8481474170356921,
        "max_drawdown": -0.0962304710287989
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:45.493241",
      "updated_at": "2026-01-17T03:43:45.493249"
    },
    "af53e375082d4e8b": {
      "factor_id": "af53e375082d4e8b",
      "factor_name": "Ranked_Regime_Exhaustion_Trigger",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20) * TS_STD($return, 14)) * RANK(($open - DELAY($close, 1)) / DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20) * TS_STD(TS_PCTCHANGE($close, 1), 14)) * RANK(($open - DELAY($close, 1)) / DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Regime_Exhaustion_Trigger\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies cross-sectional ranking to the regime multiplier (Price-Volume correlation and volatility) and the liquidity trigger (overnight gap) separately before combining them, ensuring the signal is robust across different market conditions.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The product of a 20-day price-volume correlation scaled by the 14-day Average True Range and the ratio of overnight returns to the previous day's high-low range identifies high-conviction mean-reversion opportunities during structural liquidity gaps.\n                Concise Observation: Parent 1 (RankIC 0.029) captures regime-based alpha via price-volume correlation, while Parent 2 (RankIC 0.022) identifies overnight exhaustion; combining them addresses the noise inherent in high-frequency signals by filtering for structural regimes.\n                Concise Justification: The 20-day PV correlation acts as a regime filter that validates whether an overnight gap is occurring within a trend-exhaustion phase, while the intraday-range-normalized overnight return provides the specific execution trigger.\n                Concise Knowledge: If long-term price-volume divergence coincides with high structural volatility, then short-term overnight price shocks are more likely to represent exhaustible liquidity gaps rather than sustainable trend continuations.\n                concise Specification: Define Regime_Multiplier as CORR($close, $volume, 20) * (ATR($high, $low, $close, 14) / $close) and Liquidity_Trigger as ($open / delay($close, 1) - 1) / (($high - $low) / $close); the final factor is the product of these two components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f030eae56348",
      "parent_trajectory_ids": [
        "790b0c692f1a",
        "918b70d0dae2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0102457687069676,
        "ICIR": 0.0677039951765419,
        "RankIC": 0.0313366592666852,
        "RankICIR": 0.2112574251923435,
        "annualized_return": 0.0569777081135771,
        "information_ratio": 0.8481474170356921,
        "max_drawdown": -0.0962304710287989
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:43:45.522070",
      "updated_at": "2026-01-17T03:43:45.522076"
    },
    "be6b50ad31dd469e": {
      "factor_id": "be6b50ad31dd469e",
      "factor_name": "CSVD_Volatility_Convexity_Ratio",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / TS_MEAN($high - $low, 20)) / STD($close / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"CSVD_Volatility_Convexity_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio of short-term (5-day) price range to medium-term (20-day) price range, normalized by the cross-sectional standard deviation of returns. It identifies stocks where idiosyncratic price-range expansion or contraction decouples from market-wide return dispersion, signaling potential alpha from stock-specific re-pricing.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.169035",
      "updated_at": "2026-01-17T03:46:21.169042"
    },
    "016dc251bf05446e": {
      "factor_id": "016dc251bf05446e",
      "factor_name": "Idiosyncratic_Range_Decoupling_Rank",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD(TS_PCTCHANGE($close, 1)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Range_Decoupling_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Volatility Convexity' of a stock relative to the cross-sectional market dispersion. It uses RANK to normalize the ratio of current range volatility against its historical mean, then scales it by the inverse of market-wide return dispersion to isolate assets undergoing unique fundamental adjustments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.188725",
      "updated_at": "2026-01-17T03:46:21.188731"
    },
    "6cf31eb6d71efdc1": {
      "factor_id": "6cf31eb6d71efdc1",
      "factor_name": "ZScore_Range_Dispersion_Alpha",
      "factor_expression": "ZSCORE(TS_MEAN($high - $low, 5) / (TS_MEAN($high - $low, 20) + 1e-8)) / (STD($return) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($high - $low, 5) / TS_MEAN($high - $low, 20)) / (STD(TS_PCTCHANGE($close, 1)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Range_Dispersion_Alpha\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the CSVD hypothesis. It calculates the Z-score of the 5-day range relative to its 20-day baseline and divides it by the cross-sectional volatility of returns. This highlights stocks with extreme idiosyncratic volatility shifts relative to the broader market noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Cross-Sectional Volatility Dispersion (CSVD) factor identifies alpha by capturing the divergence between individual stock price-range volatility and market-wide return dispersion, specifically targeting periods where idiosyncratic risk expansion signals stock-specific re-pricing.\n                Concise Observation: Previous price-volume strategies (ISEC) focused on first-order momentum and support, yet failed to account for second-order volatility structures that signal whether price movement is driven by macro-beta or micro-fundamental shifts.\n                Concise Justification: Market inefficiencies often manifest as volatility clusters; by measuring the 'Volatility Convexity' (current range vs. 20-day mean) against the universe's return dispersion, we can isolate assets undergoing unique fundamental adjustments independent of broad market noise.\n                Concise Knowledge: If the cross-sectional dispersion of returns increases while the individual stock's relative price range (High-Low) contracts relative to its historical mean, it indicates a decoupling from systematic risk; such stocks often exhibit mean-reversion or alpha-generating idiosyncratic trends.\n                concise Specification: The factor is defined as the ratio of a stock's 5-day average High-Low range to its 20-day average range, divided by the cross-sectional standard deviation of returns for that day across all instruments.\n                ",
      "initial_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volume-Weighted Shadow Dynamics: Interact KLOW with relative volume (Vwap/Close) to distinguish between high-conviction intraday support and low-liquidity noise.",
      "evolution_phase": "mutation",
      "trajectory_id": "d413dc974089",
      "parent_trajectory_ids": [
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063977112269123,
        "ICIR": 0.0460624556438021,
        "RankIC": 0.0260142054116006,
        "RankICIR": 0.1896942274776803,
        "annualized_return": 0.0853787810855281,
        "information_ratio": 1.2626675346978145,
        "max_drawdown": -0.1204610840645767
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:46:21.207951",
      "updated_at": "2026-01-17T03:46:21.207957"
    },
    "9724358e7953d565": {
      "factor_id": "9724358e7953d565",
      "factor_name": "Overnight_Sentiment_Volatility_Ratio_20D",
      "factor_expression": "($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_STD(($close / (DELAY($close, 1) + 1e-8)) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by measuring the overnight price gap relative to historical volatility. A large gap compared to the 20-day standard deviation of returns suggests a potential emotional overreaction that is likely to revert.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.407397",
      "updated_at": "2026-01-17T03:49:20.407403"
    },
    "181ee1d93dac7aac": {
      "factor_id": "181ee1d93dac7aac",
      "factor_name": "Hollow_Gap_Liquidity_Divergence_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Gap_Liquidity_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets 'hollow' gaps where the overnight price jump is unsupported by volume trends. It scales the overnight return by the ratio of current volume to its 20-day average, identifying gaps that lack structural capital commitment.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.427009",
      "updated_at": "2026-01-17T03:49:20.427015"
    },
    "22af8b8c6538acb9": {
      "factor_id": "22af8b8c6538acb9",
      "factor_name": "Ranked_Overnight_Mean_Reversion_Signal",
      "factor_expression": "RANK(($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_STD(($close / (DELAY($close, 1) + 1e-8)) - 1, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Overnight_Mean_Reversion_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the overnight sentiment divergence. It measures the intensity of the overnight gap relative to the 20-day return volatility, normalized across the universe to identify the most extreme sentiment shifts.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Divergence (OSD) factor identifies mean-reversion opportunities by measuring the ratio of the overnight price gap to the previous 20-day volatility, specifically targeting 'hollow' gaps where the opening price jump is unsupported by historical volume trends.\n                Concise Observation: The parent strategy focused on 5-day intraday support persistence; however, market gaps often represent discrete sentiment shifts that occur outside of continuous trading hours, creating a distinct opportunity for short-term reversal signals.\n                Concise Justification: Price discovery during non-trading hours is often less efficient than intraday trading; a large gap-up on low relative volume suggests an emotional overreaction that lacks the structural capital commitment needed to sustain the new price level.\n                Concise Knowledge: If an asset experiences a significant overnight price gap relative to its historical volatility without a corresponding surge in liquidity, the gap is likely driven by retail sentiment and tends to mean-revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is defined as the overnight return (Open/PrevClose - 1) divided by the 20-day standard deviation of returns, further scaled by the ratio of the current day's opening volume (approximated by daily volume if intraday is unavailable) to its 20-day average.\n                ",
      "initial_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Multi-Horizon Volatility Regime: Compare STD5 against STD20 to filter RESI5 signals, focusing on mean reversion only when short-term volatility is lower than long-term volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "198b1aef2d24",
      "parent_trajectory_ids": [
        "32b05dcb6838"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0079347319357676,
        "ICIR": 0.05939449869332,
        "RankIC": 0.0253551794556677,
        "RankICIR": 0.1915386522742667,
        "annualized_return": 0.0926328382340116,
        "information_ratio": 1.4402579537569864,
        "max_drawdown": -0.1106618049443328
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:20.446277",
      "updated_at": "2026-01-17T03:49:20.446283"
    },
    "d8f036d6e6b62e0a": {
      "factor_id": "d8f036d6e6b62e0a",
      "factor_name": "Mean_Reversion_Efficiency_Factor",
      "factor_expression": "TS_CORR($close, $volume, 20) * TS_PCTCHANGE($close, 60) * TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * TS_PCTCHANGE($close, 60) * TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Mean_Reversion_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion entries by combining negative price-volume correlation (indicating selling exhaustion) with medium-term price momentum and a short-term intraday efficiency ratio. High values suggest that a downward trend is losing steam and showing signs of high-conviction intraday buying.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative price-volume correlation and a 60-day price momentum, when filtered by a 5-day average intraday price efficiency ratio (Close-Open)/(High-Low), identifies high-conviction mean-reversion entries by distinguishing institutional accumulation from retail noise.\n                Concise Observation: Parent 1 identifies mean-reversion regimes but suffers from 'falling knives' due to lack of timing; Parent 2 identifies intraday conviction but lacks trend context; combining them targets assets where price drift has exhausted and new directional conviction is emerging.\n                Concise Justification: Negative price-volume correlation indicates a lack of selling pressure at lower prices (exhaustion), while a high ratio of (Close-Open) to (High-Low) indicates that intraday price movement is efficient and dominated by directional flow rather than random noise.\n                Concise Knowledge: If a medium-term price decline is accompanied by decoupling volume (exhaustion) and high intraday displacement efficiency (conviction), then the probability of a persistent trend reversal is higher than in cases with high intraday volatility but low net displacement.\n                concise Specification: Define Factor as the product of: (1) 20-day Spearman correlation of $close and $volume, (2) 60-day price return, and (3) 5-day moving average of abs($close - $open) / ($high - $low + epsilon), focusing on the intersection of low momentum and high efficiency.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a765057e4a75",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "677bfa9f37b3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059444334061954,
        "ICIR": 0.0415344081304131,
        "RankIC": 0.0231783460341772,
        "RankICIR": 0.1675708044085009,
        "annualized_return": 0.0496824335896681,
        "information_ratio": 0.7773368973755901,
        "max_drawdown": -0.0585744017921535
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:41.513713",
      "updated_at": "2026-01-17T03:49:41.513720"
    },
    "d63fa301338b8c8f": {
      "factor_id": "d63fa301338b8c8f",
      "factor_name": "Ranked_Exhaustion_Conviction_Factor",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the exhaustion-momentum hypothesis. It ranks the interaction between price-volume decoupling and price efficiency to identify stocks where the downward momentum is most likely to reverse due to institutional absorption.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative price-volume correlation and a 60-day price momentum, when filtered by a 5-day average intraday price efficiency ratio (Close-Open)/(High-Low), identifies high-conviction mean-reversion entries by distinguishing institutional accumulation from retail noise.\n                Concise Observation: Parent 1 identifies mean-reversion regimes but suffers from 'falling knives' due to lack of timing; Parent 2 identifies intraday conviction but lacks trend context; combining them targets assets where price drift has exhausted and new directional conviction is emerging.\n                Concise Justification: Negative price-volume correlation indicates a lack of selling pressure at lower prices (exhaustion), while a high ratio of (Close-Open) to (High-Low) indicates that intraday price movement is efficient and dominated by directional flow rather than random noise.\n                Concise Knowledge: If a medium-term price decline is accompanied by decoupling volume (exhaustion) and high intraday displacement efficiency (conviction), then the probability of a persistent trend reversal is higher than in cases with high intraday volatility but low net displacement.\n                concise Specification: Define Factor as the product of: (1) 20-day Spearman correlation of $close and $volume, (2) 60-day price return, and (3) 5-day moving average of abs($close - $open) / ($high - $low + epsilon), focusing on the intersection of low momentum and high efficiency.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a765057e4a75",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "677bfa9f37b3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059444334061954,
        "ICIR": 0.0415344081304131,
        "RankIC": 0.0231783460341772,
        "RankICIR": 0.1675708044085009,
        "annualized_return": 0.0496824335896681,
        "information_ratio": 0.7773368973755901,
        "max_drawdown": -0.0585744017921535
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:41.534401",
      "updated_at": "2026-01-17T03:49:41.534408"
    },
    "11b79651f6ff40ad": {
      "factor_id": "11b79651f6ff40ad",
      "factor_name": "ZScored_Reversal_Conviction_Index",
      "factor_expression": "TS_ZSCORE(TS_CORR($close, $volume, 20), 20) + TS_ZSCORE(TS_PCTCHANGE($close, 60), 60) + TS_ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR($close, $volume, 20), 20) + TS_ZSCORE(TS_PCTCHANGE($close, 60), 60) + TS_ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Reversal_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the components of the reversal hypothesis using Z-scores to ensure each signal (exhaustion, momentum, and efficiency) contributes equally to the final score, reducing the impact of outliers in raw price/volume data.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between a 20-day negative price-volume correlation and a 60-day price momentum, when filtered by a 5-day average intraday price efficiency ratio (Close-Open)/(High-Low), identifies high-conviction mean-reversion entries by distinguishing institutional accumulation from retail noise.\n                Concise Observation: Parent 1 identifies mean-reversion regimes but suffers from 'falling knives' due to lack of timing; Parent 2 identifies intraday conviction but lacks trend context; combining them targets assets where price drift has exhausted and new directional conviction is emerging.\n                Concise Justification: Negative price-volume correlation indicates a lack of selling pressure at lower prices (exhaustion), while a high ratio of (Close-Open) to (High-Low) indicates that intraday price movement is efficient and dominated by directional flow rather than random noise.\n                Concise Knowledge: If a medium-term price decline is accompanied by decoupling volume (exhaustion) and high intraday displacement efficiency (conviction), then the probability of a persistent trend reversal is higher than in cases with high intraday volatility but low net displacement.\n                concise Specification: Define Factor as the product of: (1) 20-day Spearman correlation of $close and $volume, (2) 60-day price return, and (3) 5-day moving average of abs($close - $open) / ($high - $low + epsilon), focusing on the intersection of low momentum and high efficiency.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a765057e4a75",
      "parent_trajectory_ids": [
        "602b97b242f8",
        "677bfa9f37b3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059444334061954,
        "ICIR": 0.0415344081304131,
        "RankIC": 0.0231783460341772,
        "RankICIR": 0.1675708044085009,
        "annualized_return": 0.0496824335896681,
        "information_ratio": 0.7773368973755901,
        "max_drawdown": -0.0585744017921535
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:41.554102",
      "updated_at": "2026-01-17T03:49:41.554109"
    },
    "1b1fa0567b320f2c": {
      "factor_id": "1b1fa0567b320f2c",
      "factor_name": "Overnight_Sentiment_Persistence_5D",
      "factor_expression": "TS_MEAN(($open / DELAY($close, 1) - 1) / (TS_STD($close / $open - 1, 5) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open / DELAY($close, 1) - 1) / (TS_STD($close / $open - 1, 5) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional sentiment by calculating the 5-day moving average of overnight returns normalized by intraday volatility. High values suggest persistent institutional accumulation during non-trading hours relative to noisy intraday price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.932942",
      "updated_at": "2026-01-17T03:49:44.932949"
    },
    "27d0dacce74686ae": {
      "factor_id": "27d0dacce74686ae",
      "factor_name": "Z_Overnight_Sentiment_Efficiency",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 10) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Z_Overnight_Sentiment_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the overnight sentiment factor, measuring the efficiency of overnight price discovery. It uses the ratio of overnight return to the 10-day intraday range to identify stocks where news is being priced in cleanly at the open.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.953263",
      "updated_at": "2026-01-17T03:49:44.953269"
    },
    "ed7666f723507327": {
      "factor_id": "ed7666f723507327",
      "factor_name": "Overnight_Relative_Strength_Persistence",
      "factor_expression": "TS_SUM($open / DELAY($close, 1) - 1, 10) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM(($open / DELAY($close, 1) - 1), 10) / (TS_STD(($close / DELAY($close, 1) - 1), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Relative_Strength_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of overnight returns relative to the total daily return volatility. By focusing on the 10-day sum of overnight gaps divided by the 10-day standard deviation of daily returns, it highlights stocks with consistent institutional directionality.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Overnight Sentiment Persistence factor, defined as the 5-day moving average of the ratio between overnight returns and intraday volatility, predicts positive future returns by capturing institutional information processing that occurs outside of noisy intraday trading hours.\n                Concise Observation: Intraday price movements are often dominated by high-frequency noise and liquidity-driven mean reversion, whereas the gap between the previous close and current open represents the market's reaction to overnight news and global sentiment shifts.\n                Concise Justification: Institutional investors often execute orders based on fundamental news that breaks after market close, leading to overnight 'gaps' that are more predictive of long-term trends than intraday volume-heavy price action which the parent strategy focused on.\n                Concise Knowledge: If overnight returns are consistently positive and large relative to intraday price swings, then the stock is likely experiencing institutional accumulation; when price discovery happens at the open rather than during the session, it indicates high information asymmetry and persistent sentiment.\n                concise Specification: Calculate the overnight return as ($open / REF($close, 1) - 1) and the intraday volatility as the 5-day standard deviation of ($close / $open - 1); the factor is the 5-day simple moving average of the overnight return divided by this intraday volatility.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0a6e348c8602",
      "parent_trajectory_ids": [
        "3cb6ea9034b4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056256087863135,
        "ICIR": 0.0424126244044838,
        "RankIC": 0.021276779045442,
        "RankICIR": 0.1665371296636353,
        "annualized_return": 0.0690102715053271,
        "information_ratio": 1.0982838188879505,
        "max_drawdown": -0.0952473045365962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:49:44.972983",
      "updated_at": "2026-01-17T03:49:44.972989"
    },
    "dbfd1381630af6e3": {
      "factor_id": "dbfd1381630af6e3",
      "factor_name": "Liquidity_Exhaustion_Reversal_5D",
      "factor_expression": "(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by measuring the relative closing position within the daily range, weighted by volume intensity relative to 5-day price volatility. A high value indicates the price closed near the high despite high volume, suggesting exhaustion of buying pressure and potential mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.284646",
      "updated_at": "2026-01-17T03:51:37.284654"
    },
    "b1eb4e19eecaf117": {
      "factor_id": "b1eb4e19eecaf117",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "ZSCORE(($close - $low) / ($high - $low + 1e-8)) * ZSCORE($volume / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - $low) / ($high - $low + 1e-8)) * ZSCORE($volume / (TS_STD($close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional version of the liquidity exhaustion hypothesis. It ranks the intensity of volume-weighted price overextension. By using Z-scored volume-to-volatility ratios, it identifies stocks where liquidity consumption is statistically extreme relative to the cross-section, signaling a higher probability of a 1-3 day reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.305370",
      "updated_at": "2026-01-17T03:51:37.305377"
    },
    "69b9b972e8d4304f": {
      "factor_id": "69b9b972e8d4304f",
      "factor_name": "Smoothed_Liquidity_Pressure_3D",
      "factor_expression": "SMA((($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8)), 3, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SMA((($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_STD($close, 5) + 1e-8)), 3, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Liquidity_Pressure_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistent state of liquidity exhaustion by applying a 3-day simple moving average to the exhaustion ratio. It filters out single-day noise to identify sustained periods where prices are failing to hold extremes despite high volume-to-volatility ratios.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the distance between the close and the daily low to the total daily range, weighted by the daily volume-to-volatility ratio, negatively predicts short-term returns by identifying price overextensions driven by unsustainable liquidity consumption.\n                Concise Observation: While the parent strategy focused on institutional conviction through gaps, market data often shows that high-volume pushes towards price extremes (high/low) frequently fail to sustain, especially when the closing price retreats significantly from those extremes.\n                Concise Justification: The 'Liquidity Provision Reversal' theory suggests that extreme intraday moves often 'empty' the order book; if the volume is high but the price cannot hold the extreme, it signifies that liquidity providers have absorbed the aggressive flow, leading to a reversal.\n                Concise Knowledge: If a price move occurs with high volume relative to its volatility but fails to close near the day's extreme, it indicates liquidity exhaustion; when such imbalances occur, mean reversion to the average price level is likely as the temporary order flow pressure dissipates.\n                concise Specification: The factor calculates ($close - $low) / ($high - $low + 1e-8) to find the relative closing position, then scales it by ($volume / TS_STD($close, 5)) to capture volume intensity relative to recent volatility, targeting a 1-day to 3-day reversal horizon.\n                ",
      "initial_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Asymmetric Shadow Ratio: Define the ratio of KLOW to the total daily candle body to identify 'hammer' patterns that signal a reversal in high-STD5 environments.",
      "evolution_phase": "mutation",
      "trajectory_id": "a606d77ced9c",
      "parent_trajectory_ids": [
        "77bb890cab72"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004127509741568,
        "ICIR": 0.0318278228841232,
        "RankIC": 0.0184339525969154,
        "RankICIR": 0.142161350594195,
        "annualized_return": 0.0496401062299101,
        "information_ratio": 0.7679353847830596,
        "max_drawdown": -0.1257312229840479
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:51:37.325947",
      "updated_at": "2026-01-17T03:51:37.325954"
    },
    "1121ca9a99cc49c9": {
      "factor_id": "1121ca9a99cc49c9",
      "factor_name": "LAE_Liquidity_Fragility_10D",
      "factor_expression": "RANK((($high - $low) / $close) / (TS_STD($volume, 10) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / $close) / (TS_STD($volume, 10) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LAE_Liquidity_Fragility_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity Absorption Efficiency (LAE) factor identifies structural exhaustion by measuring the ratio of the volume-weighted price range to volume volatility. High values indicate that price movements require extreme volume consistency, while a spike in volume volatility relative to range suggests a liquidity vacuum and potential reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.617057",
      "updated_at": "2026-01-17T03:52:20.617064"
    },
    "1f99d421bb121b0f": {
      "factor_id": "1f99d421bb121b0f",
      "factor_name": "Liquidity_Elasticity_Index_10D",
      "factor_expression": "ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high - $low) / $close) / (TS_STD(TS_ZSCORE($volume, 20), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Elasticity_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the elasticity of liquidity by comparing the price range to the standardized volume turnover. It targets regimes where price trends become fragile due to surging execution costs (proxied by volume volatility), signaling an impending mean-reversion event.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.637184",
      "updated_at": "2026-01-17T03:52:20.637190"
    },
    "56c76c86b6cae379": {
      "factor_id": "56c76c86b6cae379",
      "factor_name": "Volume_Price_Coupling_Exhaustion",
      "factor_expression": "TS_MEAN(($high - $low) / $close, 10) / (TS_STD($volume / (MEDIAN($volume) + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / $close, 10) / (TS_STD($volume / (MEDIAN($volume) + 1e-8), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Coupling_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'Liquidity Fragility' by identifying when the volume required to move the price a single unit becomes unstable. It uses the ratio of the 10-day average price range to the 10-day volume volatility, normalized by cross-sectional median volume to ensure comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity Absorption Efficiency' (LAE) factor, defined as the ratio of volume-weighted price range to total turnover volatility, identifies structural exhaustion in liquidity provision that precedes price reversals.\n                Concise Observation: The parent 'Trend Fragility' strategy failed to capture reversals in high-turnover regimes where price trends remained linear but execution costs (implicit in volume-price coupling) surged, indicating a liquidity-driven rather than geometry-driven regime shift.\n                Concise Justification: Market makers and passive liquidity providers require higher premiums (wider effective spreads) as inventory risk increases; this 'Liquidity Fragility' manifests as an increase in the volume required to move price a single unit, signaling an impending vacuum.\n                Concise Knowledge: If a price movement is accompanied by disproportionately high volume volatility relative to its range, the liquidity provision is becoming inelastic; when this elasticity breaks, a mean-reversion event is likely regardless of the prior trend's linearity.\n                concise Specification: The factor will be calculated using a 10-day window, measuring the ratio of the daily (High-Low)/Close to the 10-day standard deviation of Volume, normalized by the 20-day average turnover to ensure cross-sectional comparability.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "344d8b404e07",
      "parent_trajectory_ids": [
        "fe2976b173a7"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0042941878788717,
        "ICIR": 0.0311662010524424,
        "RankIC": 0.0194943809554497,
        "RankICIR": 0.1455118030568113,
        "annualized_return": 0.060993808492265,
        "information_ratio": 0.9275711774268118,
        "max_drawdown": -0.0748926361716847
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:52:20.656874",
      "updated_at": "2026-01-17T03:52:20.656880"
    },
    "91a4c2e2fc281a70": {
      "factor_id": "91a4c2e2fc281a70",
      "factor_name": "IVCS_Exhaustion_5D",
      "factor_expression": "TS_MEAN(($close - ($high + $low) / 2) * $volume / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($high + $low) / 2) * $volume / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"IVCS_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the Intraday Volume Concentration Skew (IVCS) over a 5-day window. It calculates the distance of the closing price from the daily midpoint, weighted by volume relative to the daily range. High values indicate volume concentration at price extremes without significant range expansion, signaling potential liquidity exhaustion and mean reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.362465",
      "updated_at": "2026-01-17T03:53:53.362472"
    },
    "243c743e2fe55295": {
      "factor_id": "243c743e2fe55295",
      "factor_name": "Relative_Extreme_Volume_Skew_10D",
      "factor_expression": "RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((2 * $close - ($high + $low)) / ($high - $low + 1e-8) * $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Extreme_Volume_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 10-day average of volume-weighted price skewness. It normalizes the intraday position of the close relative to the high-low range and scales it by volume. By applying a cross-sectional RANK, it identifies stocks where volume is most heavily concentrated at price extremes relative to the peer group, suggesting trend exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.382751",
      "updated_at": "2026-01-17T03:53:53.382758"
    },
    "27a0fd17ace83e7b": {
      "factor_id": "27a0fd17ace83e7b",
      "factor_name": "Volume_Price_Divergence_ZScore_5D",
      "factor_expression": "TS_ZSCORE(($close - $open) / ($high - $low + 1e-8) * $volume, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - $open) / ($high - $low + 1e-8) * $volume, 5)\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Divergence_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies exhaustion by measuring the time-series Z-score of the volume-weighted price displacement. A high Z-score indicates that the current day's volume concentration at a price extreme is statistically significant compared to the last 5 days, increasing the probability of a reversal.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume Concentration Skew (IVCS) identifies mean reversion opportunities by measuring the ratio of volume traded at daily price extremes relative to the total range, where high volume concentration at the high/low without price breakout signals liquidity exhaustion.\n                Concise Observation: While the parent strategy focused on overnight gaps and lower shadows for trend continuation, market data often shows that high-volume 'congestion' near price boundaries without price expansion precedes a trend exhaustion phase.\n                Concise Justification: High volume at price extremes indicates a 'battleground' where liquidity is being consumed; if the price fails to penetrate these levels despite high turnover, it suggests the exhaustion of the dominant side and an impending shift in supply-demand balance.\n                Concise Knowledge: If a significant portion of daily volume is localized near the day's high or low without resulting in a breakout, then aggressive market participants are likely being absorbed by passive limit orders, leading to a high probability of price reversal.\n                concise Specification: The factor will be calculated as the ratio of volume-weighted price distance from the daily midpoint to the total daily range, specifically focusing on the 5-day and 10-day moving averages of the volume-price skewness to capture persistent exhaustion signals.\n                ",
      "initial_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Residual Momentum Divergence: Identify stocks where the price is making new highs but RESI5 is declining, suggesting a loss of trend strength and imminent mean reversion.",
      "evolution_phase": "mutation",
      "trajectory_id": "8b9f55da4621",
      "parent_trajectory_ids": [
        "10aa507c1b53"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022406710604275,
        "ICIR": 0.0156174121872119,
        "RankIC": 0.0164845259987674,
        "RankICIR": 0.1178364059984633,
        "annualized_return": 0.0504458733214887,
        "information_ratio": 0.7367026626146007,
        "max_drawdown": -0.1156441355830681
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:53:53.402782",
      "updated_at": "2026-01-17T03:53:53.402788"
    },
    "f2e8b0bf5cbd2fa2": {
      "factor_id": "f2e8b0bf5cbd2fa2",
      "factor_name": "Intraday_Efficiency_Ratio_20D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Efficiency_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures long-term institutional positioning by measuring the average intraday efficiency over a 20-day window. It identifies stocks where price appreciation is achieved with low path-volatility relative to the daily range, filtering out high-frequency noise and retail-driven shocks.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.001994",
      "updated_at": "2026-01-17T03:54:31.002003"
    },
    "b1a1d0ebf13c8116": {
      "factor_id": "b1a1d0ebf13c8116",
      "factor_name": "ZScore_IER_Trend_10D",
      "factor_expression": "ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"ZScore_IER_Trend_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the Intraday Efficiency Ratio (IER) cross-sectionally to identify stocks with the most efficient price trends relative to the market. It uses a 10-day moving average of the ratio to ensure stability and then applies a Z-score for cross-sectional comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Efficiency Ratio (IER), defined as the ratio of the net daily return to the sum of absolute price movements (volatility), identifies informed institutional trends that exhibit higher momentum persistence than gap-driven movements.\n                Concise Observation: While overnight gaps often lead to mean-reversion due to liquidity imbalances, steady intraday price appreciation (high net change relative to high-low range) suggests a persistent trend that continues into the following sessions.\n                Concise Justification: Institutional investors typically use algorithms to minimize market impact, leading to 'smoother' price trends; a high ratio of net displacement to total range (Efficiency Ratio) filters out high-volatility noise and captures these persistent informed flows.\n                Concise Knowledge: If a price trend is achieved with low path-volatility (high efficiency), it is more likely to represent informed institutional accumulation; when price movement is highly fragmented or volatile, it likely reflects noise or retail-driven liquidity shocks prone to mean-reversion.\n                concise Specification: The factor will be calculated as the absolute net return ($close - $open) divided by the total intraday range ($high - $low) over a 5-day and 20-day window to distinguish between short-term trend strength and long-term institutional positioning.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "c452b24d5699",
      "parent_trajectory_ids": [
        "5482374782e1"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0036505777466138,
        "ICIR": 0.0269456356984456,
        "RankIC": 0.0188476956849478,
        "RankICIR": 0.1408061438679682,
        "annualized_return": 0.050539329319232,
        "information_ratio": 0.7311239593458523,
        "max_drawdown": -0.0955697380820632
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:54:31.038363",
      "updated_at": "2026-01-17T03:54:31.038371"
    },
    "ffa41311903d2f78": {
      "factor_id": "ffa41311903d2f78",
      "factor_name": "ICD_Factor_20D_5D",
      "factor_expression": "TS_MEAN(TS_CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), 5)\" # Your output factor expression will be filled in here\n    name = \"ICD_Factor_20D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Institutional Conviction Divergence (ICD) factor identifies high-conviction institutional trends in low-impact accumulation phases. It combines price-volume correlation (conviction) with a range-to-volume efficiency ratio (stealth), smoothed to reduce noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Conviction Divergence (ICD) factor, defined as the product of the 20-day price-volume correlation and the 5-day range-to-volume efficiency ratio, identifies high-conviction institutional trends that are currently in a low-impact accumulation phase.\n                Concise Observation: Parent 1 showed that price-volume synchrony (RankIC 0.025) captures momentum conviction, while Parent 2 showed that decoupling price range from volume intensity (RankIC 0.026) identifies stealth institutional activity.\n                Concise Justification: By multiplying the conviction metric (CORR) with the efficiency metric (Range/Volume), we amplify signals where the market agrees on direction but the execution remains 'stealthy' and efficient, filtering out high-friction retail exhaustion phases.\n                Concise Knowledge: If a strong positive correlation between price and volume is accompanied by a high price-range-to-volume ratio, it indicates efficient institutional accumulation; when these two signals converge, the resulting momentum is more sustainable than volume-heavy retail-driven moves.\n                concise Specification: The factor is calculated as CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), smoothed by a 5-day moving average to ensure signal stability and reduce noise from daily liquidity fluctuations.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "27a5787f65fc",
      "parent_trajectory_ids": [
        "c4016b5d2dfb",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058738787037622,
        "ICIR": 0.0409147214264877,
        "RankIC": 0.0237358595926097,
        "RankICIR": 0.1682903117923777,
        "annualized_return": 0.0450439052909164,
        "information_ratio": 0.6313711650225228,
        "max_drawdown": -0.1046087378096799
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:55:10.915099",
      "updated_at": "2026-01-17T03:55:10.915106"
    },
    "716991e7c705be64": {
      "factor_id": "716991e7c705be64",
      "factor_name": "Ranked_ICD_Efficiency",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_ICD_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Institutional Conviction Divergence hypothesis. It ranks the product of the 20-day price-volume synchrony and the 5-day price range efficiency to identify stocks with the highest institutional accumulation conviction relative to the market.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Conviction Divergence (ICD) factor, defined as the product of the 20-day price-volume correlation and the 5-day range-to-volume efficiency ratio, identifies high-conviction institutional trends that are currently in a low-impact accumulation phase.\n                Concise Observation: Parent 1 showed that price-volume synchrony (RankIC 0.025) captures momentum conviction, while Parent 2 showed that decoupling price range from volume intensity (RankIC 0.026) identifies stealth institutional activity.\n                Concise Justification: By multiplying the conviction metric (CORR) with the efficiency metric (Range/Volume), we amplify signals where the market agrees on direction but the execution remains 'stealthy' and efficient, filtering out high-friction retail exhaustion phases.\n                Concise Knowledge: If a strong positive correlation between price and volume is accompanied by a high price-range-to-volume ratio, it indicates efficient institutional accumulation; when these two signals converge, the resulting momentum is more sustainable than volume-heavy retail-driven moves.\n                concise Specification: The factor is calculated as CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), smoothed by a 5-day moving average to ensure signal stability and reduce noise from daily liquidity fluctuations.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "27a5787f65fc",
      "parent_trajectory_ids": [
        "c4016b5d2dfb",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058738787037622,
        "ICIR": 0.0409147214264877,
        "RankIC": 0.0237358595926097,
        "RankICIR": 0.1682903117923777,
        "annualized_return": 0.0450439052909164,
        "information_ratio": 0.6313711650225228,
        "max_drawdown": -0.1046087378096799
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:55:10.936712",
      "updated_at": "2026-01-17T03:55:10.936718"
    },
    "76335bf894fdf686": {
      "factor_id": "76335bf894fdf686",
      "factor_name": "ICD_ZScore_Stability",
      "factor_expression": "SIGN(TS_CORR($close, $volume, 20)) * TS_ZSCORE(($high - $low) / ($volume + 1e-5), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_CORR($close, $volume, 20)) * TS_ZSCORE(($high - $low) / ($volume + 1e-5), 10)\" # Your output factor expression will be filled in here\n    name = \"ICD_ZScore_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the institutional conviction by calculating the Z-score of the efficiency ratio (Range/Volume) multiplied by the sign of the price-volume correlation, ensuring that only positive synchrony (accumulation) drives the signal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Conviction Divergence (ICD) factor, defined as the product of the 20-day price-volume correlation and the 5-day range-to-volume efficiency ratio, identifies high-conviction institutional trends that are currently in a low-impact accumulation phase.\n                Concise Observation: Parent 1 showed that price-volume synchrony (RankIC 0.025) captures momentum conviction, while Parent 2 showed that decoupling price range from volume intensity (RankIC 0.026) identifies stealth institutional activity.\n                Concise Justification: By multiplying the conviction metric (CORR) with the efficiency metric (Range/Volume), we amplify signals where the market agrees on direction but the execution remains 'stealthy' and efficient, filtering out high-friction retail exhaustion phases.\n                Concise Knowledge: If a strong positive correlation between price and volume is accompanied by a high price-range-to-volume ratio, it indicates efficient institutional accumulation; when these two signals converge, the resulting momentum is more sustainable than volume-heavy retail-driven moves.\n                concise Specification: The factor is calculated as CORR($close, $volume, 20) * (($high - $low) / ($volume + 1e-5)), smoothed by a 5-day moving average to ensure signal stability and reduce noise from daily liquidity fluctuations.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "27a5787f65fc",
      "parent_trajectory_ids": [
        "c4016b5d2dfb",
        "29291150beba"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0058738787037622,
        "ICIR": 0.0409147214264877,
        "RankIC": 0.0237358595926097,
        "RankICIR": 0.1682903117923777,
        "annualized_return": 0.0450439052909164,
        "information_ratio": 0.6313711650225228,
        "max_drawdown": -0.1046087378096799
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:55:10.956980",
      "updated_at": "2026-01-17T03:55:10.956986"
    },
    "b1435518c0e34cff": {
      "factor_id": "b1435518c0e34cff",
      "factor_name": "Liquidity_Exhaustion_Ratio_1D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) * ABS(($close - 0.5 * ($high + $low)) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price exhaustion by measuring the ratio of the daily price range to the trading volume, normalized by the relative position of the close. High values indicate 'thin' price moves where price discovery occurs on low volume intensity, signaling a likely mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.927814",
      "updated_at": "2026-01-17T03:57:08.927821"
    },
    "65d79c435508c9e4": {
      "factor_id": "65d79c435508c9e4",
      "factor_name": "Relative_Volume_Intensity_Reversal_5D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Intensity_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the exhaustion of momentum by comparing the current day's price range per unit of volume against its 5-day historical average. It highlights days where price moves are disproportionately large relative to the liquidity provided, suggesting a structural void.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.948630",
      "updated_at": "2026-01-17T03:57:08.948636"
    },
    "e6aa23f628500dca": {
      "factor_id": "e6aa23f628500dca",
      "factor_name": "Extreme_Price_Liquidity_Trap",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 10)) - RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Extreme_Price_Liquidity_Trap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies liquidity traps by detecting daily price extremes (high or low) that occur on significantly lower volume than the recent average. It uses the inverse of volume intensity to signal that the trend is unsustainable.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Liquidity Exhaustion Factor (ILEF) predicts short-term mean reversion by identifying assets where price reaches daily extremes (high/low) on diminishing volume intensity relative to the price range, signaling a structural liquidity void.\n                Concise Observation: Parent strategies focusing on 5-day momentum often fail at turning points because they assume volume confirms trend persistence, ignoring that extreme price moves on low relative volume often signal exhaustion rather than conviction.\n                Concise Justification: Market makers and informed traders often withdraw liquidity at overextended price levels, causing 'thin' price moves that lack the volume support necessary to maintain the new price level, leading to mean reversion.\n                Concise Knowledge: If price discovery occurs with decreasing volume-per-unit-of-range at daily extremes, the trend is likely unsustainable; when the daily close is far from the high despite a large range, it indicates liquidity traps and imminent reversal.\n                concise Specification: The factor measures the ratio of the daily price range (High-Low) to volume, scaled by the relative position of the close within that range, focusing on the 1-day 'exhaustion' signature to ensure orthogonality to 5-day trend factors.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "27a980b96a39",
      "parent_trajectory_ids": [
        "56527829d459"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059160471719719,
        "ICIR": 0.044616018064394,
        "RankIC": 0.0269585042651749,
        "RankICIR": 0.205847460568864,
        "annualized_return": 0.0472382632626234,
        "information_ratio": 0.7744172356327634,
        "max_drawdown": -0.0874532222830994
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:08.968980",
      "updated_at": "2026-01-17T03:57:08.968986"
    },
    "95b87a37f6256346": {
      "factor_id": "95b87a37f6256346",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS($return) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) / (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price-volume divergence by calculating the ratio of the 5-day price change to the 5-day average volume-weighted price velocity. A high ratio indicates that price is moving significantly on relatively low volume intensity, suggesting a liquidity vacuum prone to mean-reversion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.518658",
      "updated_at": "2026-01-17T03:57:26.518666"
    },
    "a1ce18ab8bc5af65": {
      "factor_id": "a1ce18ab8bc5af65",
      "factor_name": "Thin_Market_Reversal_Signal",
      "factor_expression": "RANK(ABS($return)) * (1.0 - TS_RANK($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($close / DELAY($close, 1) - 1)) * (1.0 - TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Thin_Market_Reversal_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures mean-reversion opportunities by identifying days with high return magnitude but significantly low relative volume. It uses the ratio of absolute return to the 20-day volume rank to highlight 'thin' price moves.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.541106",
      "updated_at": "2026-01-17T03:57:26.541113"
    },
    "e67723e910000cb7": {
      "factor_id": "e67723e910000cb7",
      "factor_name": "Price_Volume_Fragility_Index",
      "factor_expression": "(DELTA($close, 5) / ($close + 1e-8)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / DELAY($close, 5)) / (TS_MEAN($volume, 5) / TS_MEAN($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Fragility_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the fragility of the current price trend by comparing the 5-day price momentum against the volume-weighted participation. It identifies exhaustion when price momentum is high but volume-weighted intensity is declining relative to its 20-day average.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The divergence between price trend and volume-weighted intensity, specifically when extreme price moves occur on diminishing relative volume, identifies liquidity exhaustion points that trigger mean-reversion.\n                Concise Observation: The parent strategy's momentum approach (RankIC 0.021) struggles during trend exhaustion; market data shows that price extremes often coincide with a 'thinning' of the order book where small volumes cause large price impacts.\n                Concise Justification: Price discovery occurring on low volume indicates a lack of broad market participation and high execution fragility, suggesting that the current price level is unsustainable once liquidity returns to the mean.\n                Concise Knowledge: If a price trend is supported by increasing volume, it indicates sustainable conviction; however, when price continues to push while volume-weighted intensity (relative to its own history) declines, the move is likely driven by a liquidity vacuum and prone to reversal.\n                concise Specification: Measure the ratio of the 5-day price change to the 5-day average volume-weighted price velocity, specifically identifying cases where the 1-day return magnitude is high but the 1-day volume is significantly below its 20-day average.\n                ",
      "initial_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Overnight Gap vs. Intraday Support: Analyze the correlation between overnight gaps and the subsequent KLOW length to model how opening shocks are absorbed by market participants.",
      "evolution_phase": "mutation",
      "trajectory_id": "8a5f3cfc26f4",
      "parent_trajectory_ids": [
        "5626ca44d728"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0076692312337767,
        "ICIR": 0.0474433744643148,
        "RankIC": 0.0218634984802075,
        "RankICIR": 0.1350048572269716,
        "annualized_return": 0.0580605679932974,
        "information_ratio": 0.633470166205027,
        "max_drawdown": -0.1664619976290701
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:57:26.563108",
      "updated_at": "2026-01-17T03:57:26.563114"
    },
    "ca9b0af6a43479c3": {
      "factor_id": "ca9b0af6a43479c3",
      "factor_name": "Gap_Diffusion_Lag_Factor_5D",
      "factor_expression": "TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open / DELAY($close, 1)) - 1, 5) * TS_STD($volume, 20) * ((($close / $open) - 1 < ($open / DELAY($close, 1)) - 1) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Gap_Diffusion_Lag_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Information Diffusion Lag' by measuring the interaction between the average overnight gap and volume volatility. It identifies stocks where price discovery is delayed, specifically when the intraday return is lower than the overnight impulse, suggesting a potential catch-up effect in high-volatility regimes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.742894",
      "updated_at": "2026-01-17T03:58:17.742900"
    },
    "bb952250c0b75dda": {
      "factor_id": "bb952250c0b75dda",
      "factor_name": "Frictional_Price_Discovery_Rank",
      "factor_expression": "RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD($return, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD(($close / DELAY($close, 1) - 1), 10))\" # Your output factor expression will be filled in here\n    name = \"Frictional_Price_Discovery_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on the cross-sectional lag by identifying stocks with high idiosyncratic volatility relative to their overnight gap. It uses the ratio of intraday range to the overnight gap, scaled by volume stability, to predict short-term momentum laggards.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.766747",
      "updated_at": "2026-01-17T03:58:17.766753"
    },
    "13a64ce6d82bff1b": {
      "factor_id": "13a64ce6d82bff1b",
      "factor_name": "Institutional_Gap_Laggard_Signal",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / DELAY($close, 1), 5)) / (TS_STD(($close - $open) / $open, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Laggard_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the discrepancy between overnight institutional positioning (gap) and retail-driven intraday volatility. It targets stocks where the overnight gap is significant but the intraday movement is muted, suggesting a delayed reaction to market-wide information.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Information Diffusion Lag' factor, defined by the interaction between an asset's sensitivity to market-wide overnight gaps and its idiosyncratic intraday volatility, predicts short-term momentum in laggard stocks during high-volatility regimes.\n                Concise Observation: Parent strategies focused on mean-reversion in oversold regimes (RankIC 0.018); however, they ignored the cross-sectional lead-lag effects where price discovery is hindered by liquidity friction in high-volatility environments.\n                Concise Justification: Stocks with high 'Gap-to-Intraday' ratios often signal institutional positioning, while laggards with high retail participation exhibit 'frictional' price discovery, creating a predictable 1-3 day window where laggards catch up to the leader's initial impulse.\n                Concise Knowledge: If market-leading information is first priced in via overnight gaps, then assets with high intraday idiosyncratic volatility and low correlation to the previous day's market move will exhibit a delayed price adjustment (lagged momentum) as retail participants react to the established trend.\n                concise Specification: The factor is calculated as the product of the 5-day average overnight return ($open / prev $close - 1) and the 20-day rolling standard deviation of volume, conditioned on the current day's intraday return being less than the overnight gap.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "c174aa2d2dcd",
      "parent_trajectory_ids": [
        "cb7e9d8118bb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048776141624714,
        "ICIR": 0.0347257060259473,
        "RankIC": 0.0212953259457163,
        "RankICIR": 0.155017228904739,
        "annualized_return": 0.0479323517483069,
        "information_ratio": 0.7108452506030689,
        "max_drawdown": -0.082676620999565
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:58:17.787462",
      "updated_at": "2026-01-17T03:58:17.787468"
    },
    "d31b51f2cd614148": {
      "factor_id": "d31b51f2cd614148",
      "factor_name": "Volume_Vol_Overnight_Gap_Reversion_5D",
      "factor_expression": "-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * RANK(TS_STD($volume, 5) * ($open / (DELAY($close, 1) + 1e-8) - 1))\" # Your output factor expression will be filled in here\n    name = \"Volume_Vol_Overnight_Gap_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the mean-reversion effect of overnight price gaps when accompanied by high volume volatility at the previous day's close. High volume volatility suggests dealer inventory stress, making the opening gap likely to revert. The factor is negated to align with a long-short prediction of the reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.080482",
      "updated_at": "2026-01-17T03:59:50.080490"
    },
    "eb89102aa260b117": {
      "factor_id": "eb89102aa260b117",
      "factor_name": "Liquidity_Stress_Gap_Reversal_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_STD($volume, 5), 10) * ($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Stress_Gap_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the liquidity-driven reversion factor that uses the Z-score of volume volatility to identify extreme inventory imbalances. It focuses on the interaction between standardized volume dispersion and the overnight return, predicting that extreme imbalances lead to gap dissipation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.102507",
      "updated_at": "2026-01-17T03:59:50.102513"
    },
    "ccda060b09b8cfce": {
      "factor_id": "ccda060b09b8cfce",
      "factor_name": "Relative_Volume_Dispersion_Gap_Factor",
      "factor_expression": "-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_RANK(TS_STD($volume, 5), 20) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Dispersion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between the overnight gap and the relative intensity of volume volatility. By using TS_RANK of volume volatility, it identifies periods where liquidity-driven distortions are historically high for the specific asset, signaling a higher probability of opening gap mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high-frequency volume volatility and the overnight price gap predicts a mean-reversion effect, where assets with extreme volume dispersion during the previous day's close tend to reverse their opening gap due to the resolution of liquidity-driven inventory imbalances.\n                Concise Observation: While trend-based factors use multi-day price linearity, intraday volume patterns often show that price gaps accompanied by high volume variance at the prior close are frequently overextended and subject to immediate correction.\n                Concise Justification: Market micro-structure theory suggests that dealers charging high risk-premia for liquidity at the close create temporary price distortions; these distortions are amplified in the overnight gap but dissipate once the market opens and broader liquidity returns.\n                Concise Knowledge: If a stock exhibits high volume volatility during the market close, it indicates dealer inventory stress; when this is followed by a significant overnight gap, the opening price likely reflects a liquidity premium that will mean-revert as inventory rebalances.\n                concise Specification: The factor measures the product of the 5-day standard deviation of closing volume and the overnight gap (Open/PrevClose - 1), specifically targeting the mean-reversion of the gap when volume instability is high.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "d8f2e2396727",
      "parent_trajectory_ids": [
        "b9dbda212269"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046840604617433,
        "ICIR": 0.0349310132696017,
        "RankIC": 0.0228022131126801,
        "RankICIR": 0.1749975776212974,
        "annualized_return": 0.0383216109530597,
        "information_ratio": 0.6103326711159421,
        "max_drawdown": -0.0794239792730248
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T03:59:50.123301",
      "updated_at": "2026-01-17T03:59:50.123307"
    },
    "667c8534e6e3442b": {
      "factor_id": "667c8534e6e3442b",
      "factor_name": "Informed_Liquidity_Accumulation_10D",
      "factor_expression": "TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / ($high - $low + 1e-8), 10) / (TS_STD($close, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Liquidity_Accumulation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend breakouts by detecting periods of high volume density within narrow price ranges. It calculates the 10-day average of the ratio between volume and the high-low range, scaled by the inverse of price volatility to isolate 'quiet' institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.815968",
      "updated_at": "2026-01-17T04:00:06.815975"
    },
    "2aba12657a8d146a": {
      "factor_id": "2aba12657a8d146a",
      "factor_name": "Volume_Density_Compression_ZScore_10D",
      "factor_expression": "TS_ZSCORE($volume / ($high - $low + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Density_Compression_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of volume relative to price movement, standardized against its 10-day history. A high value suggests that volume is clustering within a tight price range, indicating institutional absorption before a volatility expansion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.837299",
      "updated_at": "2026-01-17T04:00:06.837305"
    },
    "9ff730c073fc8d6a": {
      "factor_id": "9ff730c073fc8d6a",
      "factor_name": "Accumulation_Coil_Factor_15D",
      "factor_expression": "RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 15) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Coil_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies a 'coiled' market state where price dispersion is at a minimum relative to volume intensity. It uses the ratio of the 15-day average volume to the 15-day price range, cross-sectionally ranked to find the most compressed instruments.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Accumulation (ILA) factor identifies forthcoming trend breakouts by measuring the concentration of volume within low-volatility price windows, specifically where the 10-day average of intraday range-normalized volume is high and price dispersion is at a cyclical minimum.\n                Concise Observation: The parent strategy focuses on high-volatility exhaustion and price-volume divergence (reversals), whereas market data shows significant predictive power in periods of extreme price compression where volume density increases without moving the price.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume clusters within narrow price ranges; measuring this 'quiet' accumulation captures the preparation phase of a new trend, ensuring orthogonality to exhaustion-based signals.\n                Concise Knowledge: If price volatility reaches a local minimum while volume remains steady or increasing, it indicates institutional absorption; when this 'coiled' state is identified via low high-low spreads relative to volume, it precedes a breakout rather than a reversal.\n                concise Specification: The factor is defined as the 10-day moving average of the ratio between daily volume and the daily high-low price range, scaled by the inverse of the 10-day price standard deviation, to isolate high-intensity trading within tight consolidation zones.\n                ",
      "initial_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Cross-Sectional Residual Ranking: Rank RESI5 within specific industry sectors to remove systematic beta noise and isolate idiosyncratic price dislocations.",
      "evolution_phase": "mutation",
      "trajectory_id": "90908703b5db",
      "parent_trajectory_ids": [
        "3e076fd5d13b"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049547169744411,
        "ICIR": 0.0366780726765981,
        "RankIC": 0.0234390965631809,
        "RankICIR": 0.1747659247618395,
        "annualized_return": 0.036668284881419,
        "information_ratio": 0.581836575922925,
        "max_drawdown": -0.0824714638689562
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:00:06.858139",
      "updated_at": "2026-01-17T04:00:06.858145"
    },
    "2eb4cc9253e7aff3": {
      "factor_id": "2eb4cc9253e7aff3",
      "factor_name": "Liquidity_Exhaustion_Reversal_10D",
      "factor_expression": "TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($high - $low, 10) - TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in volume. It calculates the difference between the time-series Z-score of the intraday range and the time-series Z-score of volume over a 10-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.759885",
      "updated_at": "2026-01-17T04:01:01.759892"
    },
    "10a3628cfd4ea100": {
      "factor_id": "10a3628cfd4ea100",
      "factor_name": "Cross_Sectional_Liquidity_Vacuum_20D",
      "factor_expression": "RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Vacuum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the relative liquidity exhaustion across the market. It ranks the ratio of a smoothed price range to smoothed volume, highlighting stocks where price volatility is disproportionately high compared to trading activity, adjusted for a 20-day lookback.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.781726",
      "updated_at": "2026-01-17T04:01:01.781732"
    },
    "cd30d6c8ccbc13e8": {
      "factor_id": "cd30d6c8ccbc13e8",
      "factor_name": "Range_Volume_Divergence_ZScore_5D",
      "factor_expression": "ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE($high - $low, 5) / (TS_ZSCORE($volume, 5) + 3))\" # Your output factor expression will be filled in here\n    name = \"Range_Volume_Divergence_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Focuses on short-term liquidity gaps by measuring the divergence between price range and volume growth. It uses a 5-day window to capture rapid 'overshooting' events where the range expands while volume stays low or decreases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Exhaustion Reversal Factor (LERF) identifies mean-reversion opportunities by detecting extreme intraday price dispersion (High-Low range) coupled with a sharp decline in turnover, signaling a 'liquidity vacuum' where price moves are unsustainable.\n                Concise Observation: Previous trend-following factors based on price-volume correlation (RankIC 0.0286) struggle during market turning points where liquidity gaps cause price 'overshooting' on low participation.\n                Concise Justification: Market microstructure theory suggests that large price swings on low turnover indicate a thinning order book (liquidity vacuum), which typically precedes a reversal as liquidity providers return to capture the spread.\n                Concise Knowledge: If price volatility increases while turnover decreases, the price movement is likely driven by a lack of liquidity rather than informed conviction; When high price dispersion occurs without volume support, the asset is prone to a mean-reverting correction.\n                concise Specification: The factor is defined as the ratio of the 10-day Z-score of the intraday range ($high - $low) to the 10-day Z-score of volume, specifically targeting periods where range expansion exceeds volume growth.\n                ",
      "initial_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Price-Volume divergence in distressed assets: Analyze if a negative CORR20 combined with a ROC60 > 1.2 identifies 'exhaustion selling' where price drops on decreasing volume, signaling a bottom.",
      "evolution_phase": "mutation",
      "trajectory_id": "16e029c7d1d1",
      "parent_trajectory_ids": [
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063784432146131,
        "ICIR": 0.0464444348688443,
        "RankIC": 0.0267802323944021,
        "RankICIR": 0.1973365754409312,
        "annualized_return": 0.0299092083157557,
        "information_ratio": 0.4728457882647971,
        "max_drawdown": -0.1029066736013134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:01:01.802827",
      "updated_at": "2026-01-17T04:01:01.802833"
    },
    "ee5011636f3af683": {
      "factor_id": "ee5011636f3af683",
      "factor_name": "Stealth_Liquidity_Absorption_20D",
      "factor_expression": "($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($volume / POW($high - $low + 1e-8, 2)) / (TS_MEAN($volume / POW($high - $low + 1e-8, 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Liquidity_Absorption_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of trading volume to the squared intraday price range. A high ratio indicates high turnover within a narrow price band, suggesting 'stealth' liquidity absorption. The value is normalized by its 20-day moving average to identify abnormal accumulation phases.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.920019",
      "updated_at": "2026-01-17T04:02:51.920027"
    },
    "f31a3d208db11e89": {
      "factor_id": "f31a3d208db11e89",
      "factor_name": "Relative_Volume_Density_Rank_10D",
      "factor_expression": "RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Density_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the cross-sectional rank of volume density (volume per unit of price range) relative to its recent time-series distribution. It targets stocks where the current volume-to-range ratio is at a historical peak, signaling potential exhaustion of sellers and a forthcoming breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.950367",
      "updated_at": "2026-01-17T04:02:51.950373"
    },
    "64b2836e01ce5097": {
      "factor_id": "64b2836e01ce5097",
      "factor_name": "ZScore_Accumulation_Density_15D",
      "factor_expression": "TS_ZSCORE($volume / (ABS($high - $low) + 1e-8), 15)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($volume / (($high - $low) > 0.0001 ? ($high - $low) : 0.0001), 15)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Accumulation_Density_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the time-series Z-score of the volume-to-range ratio over a 15-day window. By using Z-score, it identifies statistically significant 'quiet' accumulation periods where volume density exceeds the normal distribution of the specific instrument's trading activity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Liquidity Drain' factor, calculated as the ratio of daily volume to the squared daily price range, identifies institutional accumulation phases where high volume occurs within a narrow price band, predicting positive future returns when this ratio exceeds its 20-day historical mean.\n                Concise Observation: The parent strategy successfully captured high-volatility shocks using ATR-normalized ranges, but it fails to identify 'quiet' accumulation periods where price movement is suppressed despite significant turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to high volume with low price dispersion. Measuring the density of volume per unit of price range (Volume / (High - Low)^2) reveals conviction that price-only volatility metrics miss.\n                Concise Knowledge: If high trading volume is concentrated within a narrow intraday price range, it indicates high liquidity absorption by institutional players; when this volume-to-range ratio is abnormally high relative to its history, it suggests a forthcoming price breakout due to inventory exhaustion.\n                concise Specification: The factor is defined as (Volume / (High - Low + epsilon)^2) normalized by its 20-day moving average. It specifically targets instruments with low price volatility but high turnover, expecting a positive correlation with next-period returns during the accumulation phase.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "5ec06367644d",
      "parent_trajectory_ids": [
        "493f083fc9f4"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0085583084684651,
        "ICIR": 0.0595476659580015,
        "RankIC": 0.0303410838064745,
        "RankICIR": 0.2113441650937267,
        "annualized_return": 0.0807439656809508,
        "information_ratio": 1.2016865585959693,
        "max_drawdown": -0.099785165016142
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:02:51.971394",
      "updated_at": "2026-01-17T04:02:51.971400"
    },
    "3030871e1ca545c4": {
      "factor_id": "3030871e1ca545c4",
      "factor_name": "IIA_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies Institutional Inventory Absorption (IIA) by calculating the ratio of the 20-day average volume to the 20-day price volatility. High values indicate 'Quiet Accumulation' where high volume is absorbed with minimal price movement, signaling a potential breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.319517",
      "updated_at": "2026-01-17T04:03:00.319524"
    },
    "d17fc8759133d362": {
      "factor_id": "d17fc8759133d362",
      "factor_name": "IIA_Rank_Tightness_20D",
      "factor_expression": "RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 20)) - RANK(TS_STD($close, 20))\" # Your output factor expression will be filled in here\n    name = \"IIA_Rank_Tightness_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiled spring' effect by cross-sectionally ranking volume and price stability. It identifies stocks in the top decile of volume and bottom decile of volatility by subtracting the volatility rank from the volume rank.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.341262",
      "updated_at": "2026-01-17T04:03:00.341269"
    },
    "b1e96ffb77a4c8bb": {
      "factor_id": "b1e96ffb77a4c8bb",
      "factor_name": "IIA_Relative_Efficiency_20D",
      "factor_expression": "TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 20) / (TS_MEAN($high - $low, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IIA_Relative_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of volume in moving prices. It uses the inverse of the 20-day price range normalized by volume. A high value suggests that large volumes are being traded within a very narrow price range, indicating institutional absorption.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Inventory Absorption (IIA) factor, defined as the ratio of the 20-day rolling average volume to the 20-day price volatility, identifies 'Quiet Accumulation' phases where high liquidity absorbs price impact, signaling an imminent trend breakout.\n                Concise Observation: While the parent LAME strategy identifies mean reversion from price-volume divergence, market data shows that periods where volume surges without price movement often precede powerful, non-reverting breakouts.\n                Concise Justification: Low volatility during high volume suggests that large orders are being filled without moving the market significantly (absorption), creating a coiled spring effect that is orthogonal to the exhaustion-based logic of the parent strategy.\n                Concise Knowledge: If high trading volume is accompanied by exceptionally low price dispersion, it indicates institutional absorption; when this 'tightness' reaches an extreme, the subsequent break in equilibrium typically leads to a high-conviction trend initiation.\n                concise Specification: The factor is calculated as the 20-day mean of volume divided by the 20-day standard deviation of close prices, specifically targeting instruments in the highest decile of volume and lowest decile of volatility.\n                ",
      "initial_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Clustered Support: Use the interaction of KLOW and the 5-day range (High-Low) to identify 'coiled' price action where intraday support meets shrinking volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "8f79f592c6e4",
      "parent_trajectory_ids": [
        "716fea2e54d8"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004137757145848,
        "ICIR": 0.0328621164700709,
        "RankIC": 0.0199485158062353,
        "RankICIR": 0.1587801779570425,
        "annualized_return": 0.0428076956504241,
        "information_ratio": 0.695812712475948,
        "max_drawdown": -0.1257608938624982
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:03:00.363832",
      "updated_at": "2026-01-17T04:03:00.363839"
    },
    "c092235ba2e172e2": {
      "factor_id": "c092235ba2e172e2",
      "factor_name": "Overnight_Intraday_Asymmetry_Ratio",
      "factor_expression": "RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((ABS($open / DELAY($close, 1) - 1) / (($high - $low) / $open + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Intraday_Asymmetry_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the ratio of the overnight gap return to the intraday price range, weighted by the current volume relative to its 5-day average. High values indicate a significant overnight gap followed by low-volatility intraday consolidation, suggesting institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.785370",
      "updated_at": "2026-01-17T04:05:47.785376"
    },
    "b829d8b82d07f289": {
      "factor_id": "b829d8b82d07f289",
      "factor_name": "Gap_Consolidation_Efficiency_5D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)) / (($high - $low) + 0.0001), 5)\" # Your output factor expression will be filled in here\n    name = \"Gap_Consolidation_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the efficiency of price discovery by comparing the magnitude of overnight gaps to the intraday volatility over a 5-day period. It uses Z-scores to normalize the gap-to-range ratio, identifying days where the gap dominates the daily price action.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.807039",
      "updated_at": "2026-01-17T04:05:47.807045"
    },
    "13a0cd3f1b427b42": {
      "factor_id": "13a0cd3f1b427b42",
      "factor_name": "Institutional_Stealth_Accumulation",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / $close + 1e-8)) * RANK($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Stealth_Accumulation\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies potential institutional accumulation by looking for days with a positive overnight gap but a narrow intraday range relative to the 10-day average range, further filtered by volume strength.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight-Intraday Information Asymmetry' factor, defined as the ratio of the overnight gap return to the intraday price range normalized by volume, predicts positive future returns when a significant gap is followed by low-volatility intraday consolidation.\n                Concise Observation: Parent strategies focusing on 5-day path efficiency fail to capture the alpha generated by the temporal decoupling of price discovery between the market close and the next day's open.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information, while the subsequent intraday behavior (range/volume) distinguishes between retail exhaustion and institutional accumulation or distribution.\n                Concise Knowledge: If a significant overnight price gap occurs without subsequent intraday volatility expansion, it indicates institutional 'stealth' positioning; when high volume supports a narrow intraday range after a gap, the price discovery is likely informed and persistent.\n                concise Specification: Calculate the ratio of the absolute overnight return (Open_t / Close_{t-1} - 1) to the intraday volatility (High_t - Low_t), weighted by the 1-day volume relative to its 5-day average, focusing on the current day's structure.\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "90858acbb827",
      "parent_trajectory_ids": [
        "1b6967fb12b2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067199626943525,
        "ICIR": 0.048838675363754,
        "RankIC": 0.024328700001654,
        "RankICIR": 0.1831696836310786,
        "annualized_return": 0.0502456403226744,
        "information_ratio": 0.7414288438353506,
        "max_drawdown": -0.1088293446149705
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:05:47.828509",
      "updated_at": "2026-01-17T04:05:47.828514"
    },
    "82be3d9678adc2b3": {
      "factor_id": "82be3d9678adc2b3",
      "factor_name": "LVSR_Factor_20D_3D",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_STD($return, 20) + 1e-8)) * TS_MEAN(($low - TS_MIN($low, 1)) / (TS_MAX($high, 1) - TS_MIN($low, 1) + 1e-8), 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8)) * TS_MEAN(($low - TS_MIN($low, 3)) / (TS_MAX($high, 3) - TS_MIN($low, 3) + 1e-8), 3)\" # Your output factor expression will be filled in here\n    name = \"LVSR_Factor_20D_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Validated Sentiment Reversal (LVSR) factor identifies mean-reversion points by multiplying a volatility-normalized overnight gap by a rolling average of the Low-to-Range ratio. A high gap combined with a high Low-to-Range ratio suggests a sentiment-driven 'fake-out' at institutional support levels.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Reversal (LVSR) factor, defined as the product of the 20-day volatility-normalized overnight gap and the 3-day average Low-to-Range ratio, identifies high-conviction mean-reversion points by isolating price gaps that occur at levels of institutional exhaustion.\n                Concise Observation: Parent 1 showed that volatility-normalized overnight gaps (RankIC=0.025) capture sentiment, while Parent 2 showed that the Low-to-Range ratio (RankIC=0.026) effectively identifies institutional support levels; combining them addresses the 'quality' of the price gap.\n                Concise Justification: Overnight gaps often represent emotional reactions; when these reactions push prices toward levels where the stock historically finds support (high Low-to-Range ratio), the lack of liquidity-backed follow-through leads to a high-probability mean reversion as institutional buyers absorb the retail-driven gap.\n                Concise Knowledge: If an overnight price gap occurs in the opposite direction of recent price support persistence (Low-to-Range ratio), it is likely a sentiment-driven 'fake-out'; normalizing this gap by historical volatility ensures the signal strength is comparable across different market regimes.\n                concise Specification: Calculate the Overnight Gap as (Open - Previous Close) / Previous Close; normalize this by the 20-day standard deviation of daily returns; multiply this ratio by the 3-day rolling mean of ($low - $low.min(window)) / ($high.max(window) - $low.min(window)) where window is 1 day, to create the LVSR factor.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e269464fd421",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051461170034441,
        "ICIR": 0.0392369479583639,
        "RankIC": 0.0216096189745738,
        "RankICIR": 0.1698726381756861,
        "annualized_return": 0.082844185188918,
        "information_ratio": 1.2488502886490094,
        "max_drawdown": -0.0882147442279386
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:07:42.271301",
      "updated_at": "2026-01-17T04:07:42.271309"
    },
    "c5bc527b87bf4b59": {
      "factor_id": "c5bc527b87bf4b59",
      "factor_name": "Normalized_Gap_Support_Rank",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * TS_MEAN(($low - $close) / ($high - $low + 1e-8), 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * TS_MEAN(($low - $close) / ($high - $low + 1e-8), 3)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Gap_Support_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the LVSR hypothesis that focuses on the cross-sectional rank of the volatility-adjusted overnight gap interacted with the 3-day mean of the price's position within its daily range, emphasizing relative institutional exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Reversal (LVSR) factor, defined as the product of the 20-day volatility-normalized overnight gap and the 3-day average Low-to-Range ratio, identifies high-conviction mean-reversion points by isolating price gaps that occur at levels of institutional exhaustion.\n                Concise Observation: Parent 1 showed that volatility-normalized overnight gaps (RankIC=0.025) capture sentiment, while Parent 2 showed that the Low-to-Range ratio (RankIC=0.026) effectively identifies institutional support levels; combining them addresses the 'quality' of the price gap.\n                Concise Justification: Overnight gaps often represent emotional reactions; when these reactions push prices toward levels where the stock historically finds support (high Low-to-Range ratio), the lack of liquidity-backed follow-through leads to a high-probability mean reversion as institutional buyers absorb the retail-driven gap.\n                Concise Knowledge: If an overnight price gap occurs in the opposite direction of recent price support persistence (Low-to-Range ratio), it is likely a sentiment-driven 'fake-out'; normalizing this gap by historical volatility ensures the signal strength is comparable across different market regimes.\n                concise Specification: Calculate the Overnight Gap as (Open - Previous Close) / Previous Close; normalize this by the 20-day standard deviation of daily returns; multiply this ratio by the 3-day rolling mean of ($low - $low.min(window)) / ($high.max(window) - $low.min(window)) where window is 1 day, to create the LVSR factor.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e269464fd421",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051461170034441,
        "ICIR": 0.0392369479583639,
        "RankIC": 0.0216096189745738,
        "RankICIR": 0.1698726381756861,
        "annualized_return": 0.082844185188918,
        "information_ratio": 1.2488502886490094,
        "max_drawdown": -0.0882147442279386
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:07:42.294329",
      "updated_at": "2026-01-17T04:07:42.294335"
    },
    "9442f38cb6b65e19": {
      "factor_id": "9442f38cb6b65e19",
      "factor_name": "Institutional_Exhaustion_Gap",
      "factor_expression": "TS_ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 20) * TS_MEAN(($low - TS_MIN($low, 2)) / (TS_MAX($high, 2) - TS_MIN($low, 2) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 20) * TS_MEAN(($low - TS_MIN($low, 2)) / (TS_MAX($high, 2) - TS_MIN($low, 2) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the reversal potential of overnight gaps by normalizing the gap with the 20-day standard deviation of returns and weighting it by the 5-day average proximity of the low to the daily range floor.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Reversal (LVSR) factor, defined as the product of the 20-day volatility-normalized overnight gap and the 3-day average Low-to-Range ratio, identifies high-conviction mean-reversion points by isolating price gaps that occur at levels of institutional exhaustion.\n                Concise Observation: Parent 1 showed that volatility-normalized overnight gaps (RankIC=0.025) capture sentiment, while Parent 2 showed that the Low-to-Range ratio (RankIC=0.026) effectively identifies institutional support levels; combining them addresses the 'quality' of the price gap.\n                Concise Justification: Overnight gaps often represent emotional reactions; when these reactions push prices toward levels where the stock historically finds support (high Low-to-Range ratio), the lack of liquidity-backed follow-through leads to a high-probability mean reversion as institutional buyers absorb the retail-driven gap.\n                Concise Knowledge: If an overnight price gap occurs in the opposite direction of recent price support persistence (Low-to-Range ratio), it is likely a sentiment-driven 'fake-out'; normalizing this gap by historical volatility ensures the signal strength is comparable across different market regimes.\n                concise Specification: Calculate the Overnight Gap as (Open - Previous Close) / Previous Close; normalize this by the 20-day standard deviation of daily returns; multiply this ratio by the 3-day rolling mean of ($low - $low.min(window)) / ($high.max(window) - $low.min(window)) where window is 1 day, to create the LVSR factor.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e269464fd421",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0051461170034441,
        "ICIR": 0.0392369479583639,
        "RankIC": 0.0216096189745738,
        "RankICIR": 0.1698726381756861,
        "annualized_return": 0.082844185188918,
        "information_ratio": 1.2488502886490094,
        "max_drawdown": -0.0882147442279386
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:07:42.317101",
      "updated_at": "2026-01-17T04:07:42.317108"
    },
    "b543bbfaef7ecdae": {
      "factor_id": "b543bbfaef7ecdae",
      "factor_name": "Liquidity_Drift_Persistence_10D",
      "factor_expression": "TS_CORR($return, DELAY($return, 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10) * (TS_RANK($volume, 20) < 0.3 ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'liquidity-driven drifting' by measuring the autocorrelation of returns during periods of low trading volume. High price persistence on low volume suggests a lack of institutional liquidity, which often leads to mean-reversion when volume returns. The factor targets regimes where volume is in the bottom 30th percentile and return autocorrelation is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.731871",
      "updated_at": "2026-01-17T04:12:15.731878"
    },
    "e99dc8eb50384b19": {
      "factor_id": "e99dc8eb50384b19",
      "factor_name": "Hollow_Trend_Reversal_Factor",
      "factor_expression": "RANK(TS_CORR($return, DELAY($return, 1), 10)) * (1.0 - TS_RANK($volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10)) * (1.0 - TS_RANK($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Trend_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trends that lack structural support by multiplying the 10-day return autocorrelation with a volume-based penalty. It uses the inverse of the volume rank to amplify signals where price persistence is high but market participation is low, indicating a higher probability of reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.754210",
      "updated_at": "2026-01-17T04:12:15.754216"
    },
    "c194349585ccf845": {
      "factor_id": "c194349585ccf845",
      "factor_name": "Low_Volume_Autocorr_ZScore",
      "factor_expression": "TS_ZSCORE(TS_CORR($return, DELAY($return, 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10), 20) * ($volume < TS_MEDIAN($volume, 20) ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Low_Volume_Autocorr_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the return autocorrelation and filters for low-volume environments. It identifies assets where the current 10-day price persistence is significantly higher than its own history while the volume remains below its 20-day median, signaling an overextended move likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: High price persistence (autocorrelation) during periods of low trading volume identifies 'liquidity-driven drifting' that predicts a significant mean-reversion return when institutional liquidity returns to the market.\n                Concise Observation: The parent strategy focused on trend exhaustion during high-volume volatility spikes; however, many assets exhibit low-volatility price 'creep' on thin volume that lacks structural support, creating a different type of predictable reversal.\n                Concise Justification: In a liquidity vacuum, small retail orders can cause persistent price trends (high autocorrelation) because there is no institutional counterparty to provide mean-reverting liquidity, leading to an overextended price that corrects when professional participants re-enter.\n                Concise Knowledge: If price movement exhibits high serial correlation while volume is below its moving average, it likely reflects a lack of informed market-making rather than fundamental price discovery; when volume subsequently increases, these 'hollow' price moves tend to reverse.\n                concise Specification: The factor will measure the 10-day autocorrelation of daily returns filtered by a 10-day volume moving average, specifically targeting regimes where volume is in the bottom 30th percentile and autocorrelation is in the top 70th percentile.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "275df91fba41",
      "parent_trajectory_ids": [
        "26790ecac14c"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046685654325572,
        "ICIR": 0.0351285988518779,
        "RankIC": 0.0197127417439345,
        "RankICIR": 0.1523602359484614,
        "annualized_return": 0.0754975145207329,
        "information_ratio": 1.158626920738434,
        "max_drawdown": -0.0770141170970558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:12:15.776481",
      "updated_at": "2026-01-17T04:12:15.776488"
    },
    "b91b4b10f8866df0": {
      "factor_id": "b91b4b10f8866df0",
      "factor_name": "LIFA_Reversal_Core_10D",
      "factor_expression": "TS_ZSCORE($close - TS_MEAN($close, 5), 5) * TS_MEAN(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8), 3) / (ABS(TS_CORR($close, $volume, 10)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close - TS_MEAN($close, 5), 5) * TS_MEAN(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8), 3) / (ABS(TS_CORR($close, $volume, 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"LIFA_Reversal_Core_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies price reversals by combining retail exhaustion (divergence from average price) with institutional support breakdown. It calculates the product of the 5-day Z-score of price relative to its 5-day mean and the 3-day average position within the 5-day range, scaled by the inverse of price-volume correlation to detect trend decoupling.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Institutional Flow Asymmetry (LIFA) factor predicts price reversals by identifying scenarios where retail-driven liquidity exhaustion (high late-session price-VWAP divergence) occurs simultaneously with a breakdown in institutional support (low 3-day Low-to-Range ratio) and is confirmed by a decoupling of price-volume correlation.\n                Concise Observation: Parent 1 (RankIC=0.0248) successfully captures retail over-extension via VWAP divergence, while Parent 2 (RankIC=0.0265) identifies institutional price floors; combining these reveals that price extremes are most mean-reverting when the structural support levels and volume-driven momentum disagree.\n                Concise Justification: Retail exhaustion often marks the end of a price move, but without checking institutional support levels (Low-to-Range), it is difficult to distinguish between a temporary pullback and a trend exhaustion. Integrating both ensures the factor captures both the intensity of the move and its structural location.\n                Concise Knowledge: If high turnover and late-session price-VWAP divergence (retail exhaustion) coincide with a price position near the bottom of the recent range (institutional floor failure), then the probability of a sharp mean reversion increases; this signal is more robust when price-volume correlation is low, indicating a lack of trend conviction.\n                concise Specification: The factor is calculated as the product of the 5-day Z-score of (Close - VWAP) and the 3-day mean of ((Low - Min(Low, 5)) / (Max(High, 5) - Min(Low, 5))), further scaled by the inverse of the 10-day price-volume correlation.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "86305af25597",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0089195923003938,
        "ICIR": 0.0709347875880521,
        "RankIC": 0.0222380896811452,
        "RankICIR": 0.1868603002457731,
        "annualized_return": 0.077421642056292,
        "information_ratio": 1.2212093417608447,
        "max_drawdown": -0.0728690176970663
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:13:23.762432",
      "updated_at": "2026-01-17T04:13:23.762440"
    },
    "14ab16974a927eb5": {
      "factor_id": "14ab16974a927eb5",
      "factor_name": "Retail_Exhaustion_Institutional_Floor_5D",
      "factor_expression": "RANK(TS_ZSCORE($return, 5)) * RANK(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_PCTCHANGE($close, 1), 5)) * RANK(($low - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Retail_Exhaustion_Institutional_Floor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the LIFA hypothesis focusing on the interaction between retail-driven price spikes (Z-score of returns) and the failure of institutional support levels (Low-to-Range ratio). It uses RANK to normalize the components cross-sectionally for better stability.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Institutional Flow Asymmetry (LIFA) factor predicts price reversals by identifying scenarios where retail-driven liquidity exhaustion (high late-session price-VWAP divergence) occurs simultaneously with a breakdown in institutional support (low 3-day Low-to-Range ratio) and is confirmed by a decoupling of price-volume correlation.\n                Concise Observation: Parent 1 (RankIC=0.0248) successfully captures retail over-extension via VWAP divergence, while Parent 2 (RankIC=0.0265) identifies institutional price floors; combining these reveals that price extremes are most mean-reverting when the structural support levels and volume-driven momentum disagree.\n                Concise Justification: Retail exhaustion often marks the end of a price move, but without checking institutional support levels (Low-to-Range), it is difficult to distinguish between a temporary pullback and a trend exhaustion. Integrating both ensures the factor captures both the intensity of the move and its structural location.\n                Concise Knowledge: If high turnover and late-session price-VWAP divergence (retail exhaustion) coincide with a price position near the bottom of the recent range (institutional floor failure), then the probability of a sharp mean reversion increases; this signal is more robust when price-volume correlation is low, indicating a lack of trend conviction.\n                concise Specification: The factor is calculated as the product of the 5-day Z-score of (Close - VWAP) and the 3-day mean of ((Low - Min(Low, 5)) / (Max(High, 5) - Min(Low, 5))), further scaled by the inverse of the 10-day price-volume correlation.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "86305af25597",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0089195923003938,
        "ICIR": 0.0709347875880521,
        "RankIC": 0.0222380896811452,
        "RankICIR": 0.1868603002457731,
        "annualized_return": 0.077421642056292,
        "information_ratio": 1.2212093417608447,
        "max_drawdown": -0.0728690176970663
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:13:23.785027",
      "updated_at": "2026-01-17T04:13:23.785033"
    },
    "44974a2d1e0f693f": {
      "factor_id": "44974a2d1e0f693f",
      "factor_name": "Decoupled_Liquidity_Asymmetry_15D",
      "factor_expression": "TS_RANK($close, 10) * (1 - ABS(TS_CORR($close, $volume, 15)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK($close, 10) * (1 - ABS(TS_CORR($close, $volume, 15)))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Liquidity_Asymmetry_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'decoupling' aspect of the LIFA hypothesis. It measures the divergence between price action and volume conviction, specifically looking for instances where price is at an extreme relative to its 10-day range but volume correlation is collapsing, suggesting a lack of institutional follow-through.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Institutional Flow Asymmetry (LIFA) factor predicts price reversals by identifying scenarios where retail-driven liquidity exhaustion (high late-session price-VWAP divergence) occurs simultaneously with a breakdown in institutional support (low 3-day Low-to-Range ratio) and is confirmed by a decoupling of price-volume correlation.\n                Concise Observation: Parent 1 (RankIC=0.0248) successfully captures retail over-extension via VWAP divergence, while Parent 2 (RankIC=0.0265) identifies institutional price floors; combining these reveals that price extremes are most mean-reverting when the structural support levels and volume-driven momentum disagree.\n                Concise Justification: Retail exhaustion often marks the end of a price move, but without checking institutional support levels (Low-to-Range), it is difficult to distinguish between a temporary pullback and a trend exhaustion. Integrating both ensures the factor captures both the intensity of the move and its structural location.\n                Concise Knowledge: If high turnover and late-session price-VWAP divergence (retail exhaustion) coincide with a price position near the bottom of the recent range (institutional floor failure), then the probability of a sharp mean reversion increases; this signal is more robust when price-volume correlation is low, indicating a lack of trend conviction.\n                concise Specification: The factor is calculated as the product of the 5-day Z-score of (Close - VWAP) and the 3-day mean of ((Low - Min(Low, 5)) / (Max(High, 5) - Min(Low, 5))), further scaled by the inverse of the 10-day price-volume correlation.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "86305af25597",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0089195923003938,
        "ICIR": 0.0709347875880521,
        "RankIC": 0.0222380896811452,
        "RankICIR": 0.1868603002457731,
        "annualized_return": 0.077421642056292,
        "information_ratio": 1.2212093417608447,
        "max_drawdown": -0.0728690176970663
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:13:23.807451",
      "updated_at": "2026-01-17T04:13:23.807457"
    },
    "85c86e3efae357d7": {
      "factor_id": "85c86e3efae357d7",
      "factor_name": "Institutional_Absorption_Ratio_5D",
      "factor_expression": "(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / ($volume / $close + 1e-8)) * (1 / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of price range to volume-weighted impact. A low value suggests 'quiet' accumulation where high volume turnover occurs within a tight price range, indicating institutional absorption before a potential breakout.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.310621",
      "updated_at": "2026-01-17T04:16:58.310627"
    },
    "d51246ff8f20a25c": {
      "factor_id": "d51246ff8f20a25c",
      "factor_name": "Compressed_Range_Volume_Efficiency",
      "factor_expression": "RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume / $close, 5) * TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Range_Volume_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of volume in moving price. It targets assets where the 5-day price range is compressed relative to the volume-to-price ratio, normalized by the stability of volume (inverse of 10-day volume volatility) to detect non-volatile institutional positioning.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.333594",
      "updated_at": "2026-01-17T04:16:58.333600"
    },
    "68f8b445de3c1f81": {
      "factor_id": "68f8b445de3c1f81",
      "factor_name": "Accumulation_Spring_Factor",
      "factor_expression": "(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / $close + 1e-8)) * INV(TS_VAR($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Spring_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the divergence between price volatility and volume intensity. It specifically looks for periods where the price range (high-low) is small compared to the dollar volume, weighted by the inverse of volume variance to highlight 'stable' high-liquidity zones.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The ratio of the 5-day average daily price range to volume-weighted price impact, when filtered by low volume entropy, identifies institutional accumulation phases that precede momentum breakouts.\n                Concise Observation: The parent strategy focuses on price exhaustion via candle geometry and trend stability (RSQR), but fails to capture 'quiet' volume accumulation where price remains range-bound despite significant liquidity turnover.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact, leading to high volume in 'dead zones' with tight price ranges; identifying this divergence allows for capturing the 'spring-loading' effect before a trend initiates.\n                Concise Knowledge: If volume becomes concentrated (low entropy) while price volatility remains compressed relative to historical norms, it indicates institutional absorption; when this occurs, subsequent breakouts are more likely to be persistent rather than mean-reverting.\n                concise Specification: The factor is defined as the 5-day mean of ($high - $low) divided by ($volume / $close), multiplied by the inverse of the 10-day volume volatility, targeting assets where liquidity is high but price displacement is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "86adf96c099f",
      "parent_trajectory_ids": [
        "00a6075cc504"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:16:58.355989",
      "updated_at": "2026-01-17T04:16:58.355995"
    },
    "1dc38a227b730b92": {
      "factor_id": "1dc38a227b730b92",
      "factor_name": "Idiosyncratic_Conviction_Divergence_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (TS_MEAN(STD($return), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / TS_MEAN(STD($close / DELAY($close, 1) - 1) + $close * 0, 10)\" # Your output factor expression will be filled in here\n    name = \"Idiosyncratic_Conviction_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies alpha by isolating high-conviction institutional re-pricing. It calculates the ratio of the overnight gap (Open/Previous Close - 1) to the 10-day moving average of cross-sectional return volatility. A high ratio suggests that the stock-specific move is significantly stronger than the prevailing market noise/dispersion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Idiosyncratic Conviction Divergence' factor, calculated as the ratio of the overnight gap to the 10-day cross-sectional volatility dispersion, identifies alpha by isolating high-conviction institutional re-pricing that occurs independently of systemic market noise.\n                Concise Observation: Parent strategies show that both intraday volatility dispersion (RankIC 0.026) and institutional gap signals (RankIC 0.025) provide predictive power, but they often struggle to distinguish between broad market beta spikes and stock-specific information events.\n                Concise Justification: By normalizing the overnight gap (a proxy for institutional conviction) by the cross-sectional volatility dispersion (a proxy for market noise), we create a signal-to-noise ratio that highlights 'clean' price discoveries likely to persist.\n                Concise Knowledge: If an overnight price gap is large relative to the current cross-sectional dispersion of returns, it indicates idiosyncratic institutional conviction; when such moves occur during periods of low market-wide dispersion, they are more likely to represent sustainable momentum rather than systemic noise.\n                concise Specification: The factor is defined as (Open_t / Close_{t-1} - 1) divided by the standard deviation of all stock returns in the cross-section over the previous 10 days, capturing the purity of the price move relative to the market environment.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a981c8bd8bfe",
      "parent_trajectory_ids": [
        "7513729d3145",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063446725914684,
        "ICIR": 0.0473629018593917,
        "RankIC": 0.0238336727388599,
        "RankICIR": 0.1805527973251633,
        "annualized_return": 0.0883968772409901,
        "information_ratio": 1.3528728247110378,
        "max_drawdown": -0.0963561551508521
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:18:29.796015",
      "updated_at": "2026-01-17T04:18:29.796022"
    },
    "6676834534de5750": {
      "factor_id": "6676834534de5750",
      "factor_name": "Z_Conviction_Gap_Dispersion_10D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) * (TS_MEAN(STD($return), 10) + 1e-8)))",
      "factor_implementation_code": "",
      "factor_description": "A cross-sectionally standardized version of the conviction divergence. It measures the overnight gap relative to the recent cross-sectional dispersion of returns, then applies a Z-score to ensure the signal is comparable across different market regimes. This highlights idiosyncratic moves that deviate most from the current market noise level.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Idiosyncratic Conviction Divergence' factor, calculated as the ratio of the overnight gap to the 10-day cross-sectional volatility dispersion, identifies alpha by isolating high-conviction institutional re-pricing that occurs independently of systemic market noise.\n                Concise Observation: Parent strategies show that both intraday volatility dispersion (RankIC 0.026) and institutional gap signals (RankIC 0.025) provide predictive power, but they often struggle to distinguish between broad market beta spikes and stock-specific information events.\n                Concise Justification: By normalizing the overnight gap (a proxy for institutional conviction) by the cross-sectional volatility dispersion (a proxy for market noise), we create a signal-to-noise ratio that highlights 'clean' price discoveries likely to persist.\n                Concise Knowledge: If an overnight price gap is large relative to the current cross-sectional dispersion of returns, it indicates idiosyncratic institutional conviction; when such moves occur during periods of low market-wide dispersion, they are more likely to represent sustainable momentum rather than systemic noise.\n                concise Specification: The factor is defined as (Open_t / Close_{t-1} - 1) divided by the standard deviation of all stock returns in the cross-section over the previous 10 days, capturing the purity of the price move relative to the market environment.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a981c8bd8bfe",
      "parent_trajectory_ids": [
        "7513729d3145",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063446725914684,
        "ICIR": 0.0473629018593917,
        "RankIC": 0.0238336727388599,
        "RankICIR": 0.1805527973251633,
        "annualized_return": 0.0883968772409901,
        "information_ratio": 1.3528728247110378,
        "max_drawdown": -0.0963561551508521
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:18:29.819030",
      "updated_at": "2026-01-17T04:18:29.819036"
    },
    "35fe80011a9596bf": {
      "factor_id": "35fe80011a9596bf",
      "factor_name": "Ranked_Idiosyncratic_Momentum_Signal",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_MEAN(STD($return), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / TS_MEAN(STD($open / DELAY($close, 1) - 1) + $close * 0, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Idiosyncratic_Momentum_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the conviction gap concept with cross-sectional ranking. It divides the current overnight return by the 10-day average of cross-sectional return standard deviation, then ranks the result to identify the top idiosyncratic movers relative to market-wide volatility.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Idiosyncratic Conviction Divergence' factor, calculated as the ratio of the overnight gap to the 10-day cross-sectional volatility dispersion, identifies alpha by isolating high-conviction institutional re-pricing that occurs independently of systemic market noise.\n                Concise Observation: Parent strategies show that both intraday volatility dispersion (RankIC 0.026) and institutional gap signals (RankIC 0.025) provide predictive power, but they often struggle to distinguish between broad market beta spikes and stock-specific information events.\n                Concise Justification: By normalizing the overnight gap (a proxy for institutional conviction) by the cross-sectional volatility dispersion (a proxy for market noise), we create a signal-to-noise ratio that highlights 'clean' price discoveries likely to persist.\n                Concise Knowledge: If an overnight price gap is large relative to the current cross-sectional dispersion of returns, it indicates idiosyncratic institutional conviction; when such moves occur during periods of low market-wide dispersion, they are more likely to represent sustainable momentum rather than systemic noise.\n                concise Specification: The factor is defined as (Open_t / Close_{t-1} - 1) divided by the standard deviation of all stock returns in the cross-section over the previous 10 days, capturing the purity of the price move relative to the market environment.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a981c8bd8bfe",
      "parent_trajectory_ids": [
        "7513729d3145",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063446725914684,
        "ICIR": 0.0473629018593917,
        "RankIC": 0.0238336727388599,
        "RankICIR": 0.1805527973251633,
        "annualized_return": 0.0883968772409901,
        "information_ratio": 1.3528728247110378,
        "max_drawdown": -0.0963561551508521
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:18:29.841621",
      "updated_at": "2026-01-17T04:18:29.841627"
    },
    "4b7ce1906bab598a": {
      "factor_id": "4b7ce1906bab598a",
      "factor_name": "Stealth_Momentum_Ratio_3D",
      "factor_expression": "TS_SUM($return, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 3) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Momentum_Ratio_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'stealth' institutional accumulation by calculating the ratio of the 3-day price return to the average volume-volatility product. High values suggest price discovery is occurring with minimal market impact and retail noise, indicating a high-conviction trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.871702",
      "updated_at": "2026-01-17T04:20:15.871709"
    },
    "505941f44d7074fe": {
      "factor_id": "505941f44d7074fe",
      "factor_name": "Clean_Breakout_Efficiency_5D",
      "factor_expression": "ZSCORE(TS_MEAN($return, 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Breakout_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the stealth momentum hypothesis focusing on price efficiency over a slightly longer window (5 days). It uses the Z-score of the return divided by the volume-volatility product to identify outliers where price moves significantly despite low 'noise' (volume and volatility).",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.895356",
      "updated_at": "2026-01-17T04:20:15.895362"
    },
    "5d4a5307ed5d0e9c": {
      "factor_id": "5d4a5307ed5d0e9c",
      "factor_name": "Relative_Stealth_Intensity_10D",
      "factor_expression": "TS_RANK($return / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(TS_PCTCHANGE($close, 1) / ($volume * ($high - $low) / ($close + 1e-8) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Stealth_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the intensity of stealth momentum by comparing the current return-to-volatility-volume ratio against its own 10-day history using TS_RANK. This identifies moments where the 'cleanliness' of the price move is at a local peak.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Stealth Momentum' factor, defined as the ratio of the 3-day price change to the 3-day average volume-volatility product, identifies high-conviction institutional positioning when price trends emerge despite low trading intensity and minimal volatility noise.\n                Concise Observation: The parent strategy successfully captured mean-reversion by targeting high-volume exhaustion in linear trends, but it misses 'quiet' breakouts where price moves steadily without triggering volume-based exhaustion signals.\n                Concise Justification: Institutional 'stealth' accumulation often avoids triggering high-volume alerts to minimize market impact; therefore, a high ratio of return to volume-weighted volatility signifies a 'clean' price discovery process that precedes a stronger trend.\n                Concise Knowledge: If a price move occurs with low volume and low volatility, it suggests a lack of retail noise and high information asymmetry; when price efficiency (return per unit of volume-volatility) is high, the trend is more likely to persist rather than reverse.\n                concise Specification: The factor will be calculated as the 3-day price return divided by the 3-day rolling mean of ($volume * ($high - $low) / $close), focusing on instruments where this ratio is in the top decile to capture momentum driven by information asymmetry.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "1cb09c386264",
      "parent_trajectory_ids": [
        "6c7b79d75672"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067878446746207,
        "ICIR": 0.0487055461102645,
        "RankIC": 0.0207521328270728,
        "RankICIR": 0.1529009441927854,
        "annualized_return": 0.0422608864294751,
        "information_ratio": 0.6444097700616528,
        "max_drawdown": -0.1025632457279407
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:20:15.917949",
      "updated_at": "2026-01-17T04:20:15.917955"
    },
    "d13e8e08d6ee9dce": {
      "factor_id": "d13e8e08d6ee9dce",
      "factor_name": "LVIG_Institutional_Conviction_10D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LVIG_Institutional_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Validated Institutional Gap (LVIG) factor. It scales the overnight gap by 20-day volatility to normalize size, multiplies by the ratio of gap to intraday range to measure 'solidness' (conviction), and applies a volume multiplier to ensure liquidity support. High values suggest institutional momentum, while low values suggest noise or exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Institutional Gap (LVIG) factor predicts returns by multiplying the overnight gap (normalized by 20-day volatility) with an 'Institutional Conviction' ratio (gap size relative to intraday range), further scaled by a volume-based liquidity multiplier to distinguish between sustainable breakaway moves and mean-reverting exhaustion.\n                Concise Observation: Parent strategies showed that overnight gaps have predictive power (RankIC ~0.025), but their effectiveness is limited by failing to distinguish between high-conviction institutional moves and low-liquidity noise that tends to mean-revert.\n                Concise Justification: Combining the overnight gap with intraday price structure (shadows and range) and volume validation creates a regime-switching mechanism that captures momentum when price action is 'solid' and mean-reversion when price action is 'hollow'.\n                Concise Knowledge: If an overnight price gap is accompanied by a small intraday range (high conviction) and high relative volume, it indicates institutional trend continuation; conversely, if the gap is large but followed by high intraday volatility or low volume, it signals a mean-reverting exhaustion gap.\n                concise Specification: The factor is calculated as (Gap / 20-day Volatility) * (Gap / (High - Low + 1e-6)) * (Volume / 10-day Moving Average Volume), where Gap is (Open - Previous Close).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "758c1d6f5792",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056646558545069,
        "ICIR": 0.0409743114100333,
        "RankIC": 0.0231878175384502,
        "RankICIR": 0.1667542903070123,
        "annualized_return": 0.0974907403790993,
        "information_ratio": 1.4980137589442482,
        "max_drawdown": -0.0892909265930361
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:21:36.495953",
      "updated_at": "2026-01-17T04:21:36.495959"
    },
    "bcd1c01af077b394": {
      "factor_id": "bcd1c01af077b394",
      "factor_name": "Z_LVIG_Momentum_Refined",
      "factor_expression": "ZSCORE((($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Z_LVIG_Momentum_Refined\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the LVIG factor. It captures the relative strength of institutional gap conviction across the market. By using ZSCORE, it identifies stocks with the most significant liquidity-validated breakaway moves relative to the universe.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Institutional Gap (LVIG) factor predicts returns by multiplying the overnight gap (normalized by 20-day volatility) with an 'Institutional Conviction' ratio (gap size relative to intraday range), further scaled by a volume-based liquidity multiplier to distinguish between sustainable breakaway moves and mean-reverting exhaustion.\n                Concise Observation: Parent strategies showed that overnight gaps have predictive power (RankIC ~0.025), but their effectiveness is limited by failing to distinguish between high-conviction institutional moves and low-liquidity noise that tends to mean-revert.\n                Concise Justification: Combining the overnight gap with intraday price structure (shadows and range) and volume validation creates a regime-switching mechanism that captures momentum when price action is 'solid' and mean-reversion when price action is 'hollow'.\n                Concise Knowledge: If an overnight price gap is accompanied by a small intraday range (high conviction) and high relative volume, it indicates institutional trend continuation; conversely, if the gap is large but followed by high intraday volatility or low volume, it signals a mean-reverting exhaustion gap.\n                concise Specification: The factor is calculated as (Gap / 20-day Volatility) * (Gap / (High - Low + 1e-6)) * (Volume / 10-day Moving Average Volume), where Gap is (Open - Previous Close).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "758c1d6f5792",
      "parent_trajectory_ids": [
        "b8240cacc900",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056646558545069,
        "ICIR": 0.0409743114100333,
        "RankIC": 0.0231878175384502,
        "RankICIR": 0.1667542903070123,
        "annualized_return": 0.0974907403790993,
        "information_ratio": 1.4980137589442482,
        "max_drawdown": -0.0892909265930361
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:21:36.519526",
      "updated_at": "2026-01-17T04:21:36.519532"
    },
    "831e8e4246d13178": {
      "factor_id": "831e8e4246d13178",
      "factor_name": "VVDE_Hollow_Expansion_5D",
      "factor_expression": "(($high - $low) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8)) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8)) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VVDE_Hollow_Expansion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Volatility-Volume Divergence Efficiency (VVDE) factor identifies 'hollow' price moves by calculating the ratio of the ATR-normalized intraday range to the 5-day relative volume intensity. High values suggest price expansion on low relative volume, indicating potential mean reversion due to a lack of liquidity depth.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Volume Divergence Efficiency (VVDE) factor, calculated as the ratio of the ATR-normalized intraday price range to the 5-day relative volume intensity, predicts future returns by identifying 'hollow' price expansions prone to mean reversion.\n                Concise Observation: Parent strategies showed that while ATR-normalized ranges (RankIC 0.029) and volume exhaustion (RankIC 0.027) are individually predictive, price shocks without volume support often represent unsustainable 'hollow' moves.\n                Concise Justification: By dividing the Relative Intraday Intensity by Relative Volume Intensity, we isolate stocks where the 'cost' of moving price in terms of volume is abnormally high, signaling a lack of liquidity depth and impending trend exhaustion.\n                Concise Knowledge: If intraday price volatility expands significantly while volume remains low relative to its recent average, the price move is likely driven by liquidity voids rather than institutional conviction, leading to a higher probability of reversal.\n                concise Specification: Define VVDE as [(High - Low) / ATR(20)] / [Volume / Mean(Volume, 5)]; high values indicate volatility-volume divergence; expect a negative correlation with next-day returns as these 'hollow' moves mean-revert.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "02ca504bc6bd",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "3806921571eb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078726148102835,
        "ICIR": 0.0524784406475679,
        "RankIC": 0.0298113390161144,
        "RankICIR": 0.1971814056117819,
        "annualized_return": 0.1149124625429248,
        "information_ratio": 1.6386987543596918,
        "max_drawdown": -0.116216639948346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:23:23.015490",
      "updated_at": "2026-01-17T04:23:23.015497"
    },
    "baba2b3086bea1bd": {
      "factor_id": "baba2b3086bea1bd",
      "factor_name": "Hollow_Move_ZScore_10D",
      "factor_expression": "RANK((($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)) / ($volume / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)) / ($volume / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the VVDE hypothesis focusing on the cross-sectional rank of the ratio between price volatility and volume. It identifies stocks where the intraday range is disproportionately large compared to the recent volume trend, signaling exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Volume Divergence Efficiency (VVDE) factor, calculated as the ratio of the ATR-normalized intraday price range to the 5-day relative volume intensity, predicts future returns by identifying 'hollow' price expansions prone to mean reversion.\n                Concise Observation: Parent strategies showed that while ATR-normalized ranges (RankIC 0.029) and volume exhaustion (RankIC 0.027) are individually predictive, price shocks without volume support often represent unsustainable 'hollow' moves.\n                Concise Justification: By dividing the Relative Intraday Intensity by Relative Volume Intensity, we isolate stocks where the 'cost' of moving price in terms of volume is abnormally high, signaling a lack of liquidity depth and impending trend exhaustion.\n                Concise Knowledge: If intraday price volatility expands significantly while volume remains low relative to its recent average, the price move is likely driven by liquidity voids rather than institutional conviction, leading to a higher probability of reversal.\n                concise Specification: Define VVDE as [(High - Low) / ATR(20)] / [Volume / Mean(Volume, 5)]; high values indicate volatility-volume divergence; expect a negative correlation with next-day returns as these 'hollow' moves mean-revert.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "02ca504bc6bd",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "3806921571eb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078726148102835,
        "ICIR": 0.0524784406475679,
        "RankIC": 0.0298113390161144,
        "RankICIR": 0.1971814056117819,
        "annualized_return": 0.1149124625429248,
        "information_ratio": 1.6386987543596918,
        "max_drawdown": -0.116216639948346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:23:23.038627",
      "updated_at": "2026-01-17T04:23:23.038634"
    },
    "e8e0aece3bacf7f6": {
      "factor_id": "e8e0aece3bacf7f6",
      "factor_name": "Relative_Cost_of_Price_Movement",
      "factor_expression": "(ABS($return) / (TS_STD($return, 20) + 1e-8)) / ($volume / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(TS_PCTCHANGE($close, 1)) / TS_STD(TS_PCTCHANGE($close, 1), 20)) / ($volume / TS_MEAN($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Relative_Cost_of_Price_Movement\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 'cost' of price movement by looking at the ratio of the absolute return to the relative volume. It targets the hypothesis that high price movement on low relative volume is unsustainable. We use a 20-day window for volume normalization to capture structural divergence.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Volume Divergence Efficiency (VVDE) factor, calculated as the ratio of the ATR-normalized intraday price range to the 5-day relative volume intensity, predicts future returns by identifying 'hollow' price expansions prone to mean reversion.\n                Concise Observation: Parent strategies showed that while ATR-normalized ranges (RankIC 0.029) and volume exhaustion (RankIC 0.027) are individually predictive, price shocks without volume support often represent unsustainable 'hollow' moves.\n                Concise Justification: By dividing the Relative Intraday Intensity by Relative Volume Intensity, we isolate stocks where the 'cost' of moving price in terms of volume is abnormally high, signaling a lack of liquidity depth and impending trend exhaustion.\n                Concise Knowledge: If intraday price volatility expands significantly while volume remains low relative to its recent average, the price move is likely driven by liquidity voids rather than institutional conviction, leading to a higher probability of reversal.\n                concise Specification: Define VVDE as [(High - Low) / ATR(20)] / [Volume / Mean(Volume, 5)]; high values indicate volatility-volume divergence; expect a negative correlation with next-day returns as these 'hollow' moves mean-revert.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "02ca504bc6bd",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "3806921571eb"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078726148102835,
        "ICIR": 0.0524784406475679,
        "RankIC": 0.0298113390161144,
        "RankICIR": 0.1971814056117819,
        "annualized_return": 0.1149124625429248,
        "information_ratio": 1.6386987543596918,
        "max_drawdown": -0.116216639948346
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:23:23.061329",
      "updated_at": "2026-01-17T04:23:23.061335"
    },
    "c6cd00c3c33218f2": {
      "factor_id": "c6cd00c3c33218f2",
      "factor_name": "CLC_Convexity_Liquidity_Factor",
      "factor_expression": "DELTA(TS_ZSCORE($close, 20), 5) * TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"DELTA(TS_ZSCORE($close, 20), 5) * TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3)\" # Your output factor expression will be filled in here\n    name = \"CLC_Convexity_Liquidity_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Convexity-Liquidity Convergence (CLC) factor identifies alpha by combining the velocity of volatility-normalized price residuals with a liquidity support metric. High residual acceleration (convexity) combined with high institutional support (Low-to-Range ratio) suggests trend persistence, while divergence suggests exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Convexity-Liquidity Convergence (CLC) factor, defined as the product of the 5-day change in volatility-normalized price residuals and the 3-day mean of the Low-to-Range ratio, identifies superior alpha by distinguishing between exhaustion-driven reversals and institutional-backed trend accelerations.\n                Concise Observation: Parent 1 (RankIC 0.0237) captures price exhaustion via residuals, while Parent 2 (RankIC 0.0265) captures liquidity support; combining them addresses the false signals generated when price momentum lacks volume/support confirmation.\n                Concise Justification: Price residuals represent the 'unexplained' component of returns; when their velocity (convexity) peaks, it indicates a potential limit to current price action, which becomes a high-conviction signal when filtered by the physical support levels of daily price ranges.\n                Concise Knowledge: If price residual acceleration (convexity) is high while institutional support (Low-to-Range ratio) is low, a mean-reversion is likely; if both are high, the trend is likely to persist; normalizing residuals by rolling volatility ensures signal stability across regimes.\n                concise Specification: The factor calculates the 5-day difference of (Close - 20-day Mean Close) / 20-day StdDev, then multiplies this by the 3-day rolling average of (Low - Open) / (High - Low), using daily_pv.h5 data.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ced5b34d842b",
      "parent_trajectory_ids": [
        "c7199504b485",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071058661397089,
        "ICIR": 0.0533324050492334,
        "RankIC": 0.0215694843177437,
        "RankICIR": 0.1663182255077696,
        "annualized_return": 0.0583205464909847,
        "information_ratio": 0.921718266716346,
        "max_drawdown": -0.1056371884367749
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:24:41.758096",
      "updated_at": "2026-01-17T04:24:41.758103"
    },
    "c0c266cb2a021cb5": {
      "factor_id": "c0c266cb2a021cb5",
      "factor_name": "CLC_Ranked_Convergence_V2",
      "factor_expression": "RANK(DELTA(TS_ZSCORE($close, 20), 5)) + RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA(TS_ZSCORE($close, 20), 5)) + RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"CLC_Ranked_Convergence_V2\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the CLC factor. It ranks the 5-day momentum of price residuals and the 3-day average of the low-to-range ratio independently before combining them, ensuring the factor is less sensitive to outliers and market regimes.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Convexity-Liquidity Convergence (CLC) factor, defined as the product of the 5-day change in volatility-normalized price residuals and the 3-day mean of the Low-to-Range ratio, identifies superior alpha by distinguishing between exhaustion-driven reversals and institutional-backed trend accelerations.\n                Concise Observation: Parent 1 (RankIC 0.0237) captures price exhaustion via residuals, while Parent 2 (RankIC 0.0265) captures liquidity support; combining them addresses the false signals generated when price momentum lacks volume/support confirmation.\n                Concise Justification: Price residuals represent the 'unexplained' component of returns; when their velocity (convexity) peaks, it indicates a potential limit to current price action, which becomes a high-conviction signal when filtered by the physical support levels of daily price ranges.\n                Concise Knowledge: If price residual acceleration (convexity) is high while institutional support (Low-to-Range ratio) is low, a mean-reversion is likely; if both are high, the trend is likely to persist; normalizing residuals by rolling volatility ensures signal stability across regimes.\n                concise Specification: The factor calculates the 5-day difference of (Close - 20-day Mean Close) / 20-day StdDev, then multiplies this by the 3-day rolling average of (Low - Open) / (High - Low), using daily_pv.h5 data.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ced5b34d842b",
      "parent_trajectory_ids": [
        "c7199504b485",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071058661397089,
        "ICIR": 0.0533324050492334,
        "RankIC": 0.0215694843177437,
        "RankICIR": 0.1663182255077696,
        "annualized_return": 0.0583205464909847,
        "information_ratio": 0.921718266716346,
        "max_drawdown": -0.1056371884367749
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:24:41.781397",
      "updated_at": "2026-01-17T04:24:41.781403"
    },
    "e9459ad6115ba31a": {
      "factor_id": "e9459ad6115ba31a",
      "factor_name": "CLC_Residual_Acceleration_Support",
      "factor_expression": "TS_ZSCORE(DELTA(TS_ZSCORE($close, 20), 5), 10) * TS_MEAN(($low - $open) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(DELTA(TS_ZSCORE($close, 20), 5), 10) * TS_MEAN(($low - $open) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"CLC_Residual_Acceleration_Support\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the interaction between price residual acceleration and price range positioning. It uses the 5-day delta of a 20-day Z-score of close prices as a proxy for convexity, multiplied by the smoothed relative position of the low within the daily range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Convexity-Liquidity Convergence (CLC) factor, defined as the product of the 5-day change in volatility-normalized price residuals and the 3-day mean of the Low-to-Range ratio, identifies superior alpha by distinguishing between exhaustion-driven reversals and institutional-backed trend accelerations.\n                Concise Observation: Parent 1 (RankIC 0.0237) captures price exhaustion via residuals, while Parent 2 (RankIC 0.0265) captures liquidity support; combining them addresses the false signals generated when price momentum lacks volume/support confirmation.\n                Concise Justification: Price residuals represent the 'unexplained' component of returns; when their velocity (convexity) peaks, it indicates a potential limit to current price action, which becomes a high-conviction signal when filtered by the physical support levels of daily price ranges.\n                Concise Knowledge: If price residual acceleration (convexity) is high while institutional support (Low-to-Range ratio) is low, a mean-reversion is likely; if both are high, the trend is likely to persist; normalizing residuals by rolling volatility ensures signal stability across regimes.\n                concise Specification: The factor calculates the 5-day difference of (Close - 20-day Mean Close) / 20-day StdDev, then multiplies this by the 3-day rolling average of (Low - Open) / (High - Low), using daily_pv.h5 data.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ced5b34d842b",
      "parent_trajectory_ids": [
        "c7199504b485",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0071058661397089,
        "ICIR": 0.0533324050492334,
        "RankIC": 0.0215694843177437,
        "RankICIR": 0.1663182255077696,
        "annualized_return": 0.0583205464909847,
        "information_ratio": 0.921718266716346,
        "max_drawdown": -0.1056371884367749
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:24:41.804532",
      "updated_at": "2026-01-17T04:24:41.804538"
    },
    "bb39c6ce137a746c": {
      "factor_id": "bb39c6ce137a746c",
      "factor_name": "Gap_Liquidity_Absorption_5D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) * ($volume / ($high - $low + 1e-8)), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) * ($volume / ($high - $low + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Gap_Liquidity_Absorption_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price reversals by identifying overnight gaps that are stabilized by high intraday liquidity density. It multiplies the absolute overnight gap by the ratio of volume to the intraday price range, smoothed over 5 days. High values suggest institutional absorption of the price shock.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Gap-Liquidity Absorption' factor, defined as the product of the overnight gap magnitude and the intraday volume-to-range ratio, predicts price reversals by identifying overnight shocks that are stabilized by high-density institutional liquidity.\n                Concise Observation: Overnight gaps provide a volatility trigger (RankIC 0.0245) and volume-to-range ratios identify stealth accumulation (RankIC 0.0303), suggesting that price shocks are most informative when filtered by the 'cost' of subsequent price movement.\n                Concise Justification: Combining overnight volatility with intraday liquidity density filters out 'noisy' gaps caused by retail panic, focusing on gaps where high institutional participation (volume) prevents further price extension (narrow range), signaling a high-probability reversal.\n                Concise Knowledge: If an overnight price gap is met with high intraday volume relative to price movement, it indicates institutional absorption; when this liquidity density is high, the initial gap is more likely to mean-revert as the market reaches a new equilibrium.\n                concise Specification: Calculate the absolute overnight gap as |Open(t) - Close(t-1)| and the liquidity density as Volume(t) / (High(t) - Low(t) + epsilon); the final factor is the 5-day moving average of their product to capture sustained absorption patterns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "00ea7de3cae5",
      "parent_trajectory_ids": [
        "5482374782e1",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.003602371538765,
        "ICIR": 0.0261826926348426,
        "RankIC": 0.0189261894110395,
        "RankICIR": 0.1407993373099098,
        "annualized_return": 0.0387849367123169,
        "information_ratio": 0.5802346477030225,
        "max_drawdown": -0.1000862548913718
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:26:34.306680",
      "updated_at": "2026-01-17T04:26:34.306687"
    },
    "28c386bbadc5ab70": {
      "factor_id": "28c386bbadc5ab70",
      "factor_name": "Ranked_Gap_Absorption_Density",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1))) * RANK($volume / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1))) * RANK($volume / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_Absorption_Density\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the gap-liquidity absorption hypothesis. It normalizes the overnight gap and the liquidity density (volume per price unit) separately before combining them, ensuring the factor is robust to different volatility regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Gap-Liquidity Absorption' factor, defined as the product of the overnight gap magnitude and the intraday volume-to-range ratio, predicts price reversals by identifying overnight shocks that are stabilized by high-density institutional liquidity.\n                Concise Observation: Overnight gaps provide a volatility trigger (RankIC 0.0245) and volume-to-range ratios identify stealth accumulation (RankIC 0.0303), suggesting that price shocks are most informative when filtered by the 'cost' of subsequent price movement.\n                Concise Justification: Combining overnight volatility with intraday liquidity density filters out 'noisy' gaps caused by retail panic, focusing on gaps where high institutional participation (volume) prevents further price extension (narrow range), signaling a high-probability reversal.\n                Concise Knowledge: If an overnight price gap is met with high intraday volume relative to price movement, it indicates institutional absorption; when this liquidity density is high, the initial gap is more likely to mean-revert as the market reaches a new equilibrium.\n                concise Specification: Calculate the absolute overnight gap as |Open(t) - Close(t-1)| and the liquidity density as Volume(t) / (High(t) - Low(t) + epsilon); the final factor is the 5-day moving average of their product to capture sustained absorption patterns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "00ea7de3cae5",
      "parent_trajectory_ids": [
        "5482374782e1",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.003602371538765,
        "ICIR": 0.0261826926348426,
        "RankIC": 0.0189261894110395,
        "RankICIR": 0.1407993373099098,
        "annualized_return": 0.0387849367123169,
        "information_ratio": 0.5802346477030225,
        "max_drawdown": -0.1000862548913718
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:26:34.332212",
      "updated_at": "2026-01-17T04:26:34.332218"
    },
    "1b344bc10de015a0": {
      "factor_id": "1b344bc10de015a0",
      "factor_name": "ZScore_Liquidity_Shock_Absorption",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)) * ($volume / ($high - $low + 1e-8)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)) * ($volume / MAX($high - $low, 0.001 * $close)), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Liquidity_Shock_Absorption\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of liquidity absorption relative to historical norms. It calculates the product of the overnight gap and the intraday volume-to-range ratio, then applies a time-series Z-score over 20 days to identify significant absorption events.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Gap-Liquidity Absorption' factor, defined as the product of the overnight gap magnitude and the intraday volume-to-range ratio, predicts price reversals by identifying overnight shocks that are stabilized by high-density institutional liquidity.\n                Concise Observation: Overnight gaps provide a volatility trigger (RankIC 0.0245) and volume-to-range ratios identify stealth accumulation (RankIC 0.0303), suggesting that price shocks are most informative when filtered by the 'cost' of subsequent price movement.\n                Concise Justification: Combining overnight volatility with intraday liquidity density filters out 'noisy' gaps caused by retail panic, focusing on gaps where high institutional participation (volume) prevents further price extension (narrow range), signaling a high-probability reversal.\n                Concise Knowledge: If an overnight price gap is met with high intraday volume relative to price movement, it indicates institutional absorption; when this liquidity density is high, the initial gap is more likely to mean-revert as the market reaches a new equilibrium.\n                concise Specification: Calculate the absolute overnight gap as |Open(t) - Close(t-1)| and the liquidity density as Volume(t) / (High(t) - Low(t) + epsilon); the final factor is the 5-day moving average of their product to capture sustained absorption patterns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "00ea7de3cae5",
      "parent_trajectory_ids": [
        "5482374782e1",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.003602371538765,
        "ICIR": 0.0261826926348426,
        "RankIC": 0.0189261894110395,
        "RankICIR": 0.1407993373099098,
        "annualized_return": 0.0387849367123169,
        "information_ratio": 0.5802346477030225,
        "max_drawdown": -0.1000862548913718
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:26:34.355344",
      "updated_at": "2026-01-17T04:26:34.355350"
    },
    "f8d517c6f31a9154": {
      "factor_id": "f8d517c6f31a9154",
      "factor_name": "Institutional_Conviction_Liquidity_Ratio",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-6)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-6)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Liquidity_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover. It identifies sustainable price movements by rewarding high institutional conviction (gap) that is not yet undermined by retail-driven liquidity exhaustion (abnormal turnover).",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Liquidity Equilibrium' factor, calculated as the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover, identifies sustainable price movements by rewarding high institutional conviction that is not yet undermined by retail-driven liquidity exhaustion.\n                Concise Observation: Parent 1's liquidity exhaustion (RankIC 0.0248) and Parent 2's institutional conviction (RankIC 0.0252) both capture distinct alpha sources, but individually fail to distinguish between trend persistence and trend exhaustion during high-volatility events.\n                Concise Justification: Institutional investors typically express conviction through overnight gaps, while retail investors often drive late-stage volume surges; a factor that scales the strength of the gap by the inverse of recent volume intensity captures the 'purity' of the institutional signal.\n                Concise Knowledge: If institutional conviction (overnight gap) is high while retail participation (abnormal turnover) remains moderate, the price trend is more likely to persist; conversely, when high conviction is accompanied by extreme turnover, the probability of a mean-reversion event increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as ( (Open - Close_prev) / (High - Low + 1e-6) ) / ( (Volume_5d_mean / Volume_20d_mean) + 1e-6 ), where the numerator represents the conviction gap and the denominator represents the 5-day abnormal turnover ratio as a proxy for liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "fd2838afc896",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059976693228329,
        "ICIR": 0.0442200815507922,
        "RankIC": 0.0227144863478864,
        "RankICIR": 0.1738311683058916,
        "annualized_return": 0.0701262051024463,
        "information_ratio": 1.0822167722531244,
        "max_drawdown": -0.1238228584092356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:27:51.109291",
      "updated_at": "2026-01-17T04:27:51.109297"
    },
    "b9224ea2f095ac2a": {
      "factor_id": "b9224ea2f095ac2a",
      "factor_name": "Ranked_Institutional_Purity_Signal",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) - RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) - RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Institutional_Purity_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Institutional-Liquidity Equilibrium hypothesis. It compares the strength of the overnight price jump relative to the total daily volatility, scaled by the inverse of the relative volume surge, to isolate 'pure' institutional signals from retail noise.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Liquidity Equilibrium' factor, calculated as the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover, identifies sustainable price movements by rewarding high institutional conviction that is not yet undermined by retail-driven liquidity exhaustion.\n                Concise Observation: Parent 1's liquidity exhaustion (RankIC 0.0248) and Parent 2's institutional conviction (RankIC 0.0252) both capture distinct alpha sources, but individually fail to distinguish between trend persistence and trend exhaustion during high-volatility events.\n                Concise Justification: Institutional investors typically express conviction through overnight gaps, while retail investors often drive late-stage volume surges; a factor that scales the strength of the gap by the inverse of recent volume intensity captures the 'purity' of the institutional signal.\n                Concise Knowledge: If institutional conviction (overnight gap) is high while retail participation (abnormal turnover) remains moderate, the price trend is more likely to persist; conversely, when high conviction is accompanied by extreme turnover, the probability of a mean-reversion event increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as ( (Open - Close_prev) / (High - Low + 1e-6) ) / ( (Volume_5d_mean / Volume_20d_mean) + 1e-6 ), where the numerator represents the conviction gap and the denominator represents the 5-day abnormal turnover ratio as a proxy for liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "fd2838afc896",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059976693228329,
        "ICIR": 0.0442200815507922,
        "RankIC": 0.0227144863478864,
        "RankICIR": 0.1738311683058916,
        "annualized_return": 0.0701262051024463,
        "information_ratio": 1.0822167722531244,
        "max_drawdown": -0.1238228584092356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:27:51.132867",
      "updated_at": "2026-01-17T04:27:51.132872"
    },
    "573e9aa091969665": {
      "factor_id": "573e9aa091969665",
      "factor_name": "ZScored_Conviction_Exhaustion_Index",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (1 + ABS(ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (1 + ABS(ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Conviction_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the conviction gap and the abnormal turnover using Z-scores to identify extreme institutional conviction relative to moderate turnover, mitigating the impact of cross-sectional outliers.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Liquidity Equilibrium' factor, calculated as the ratio of the Institutional Conviction Gap (overnight gap relative to intraday range) to the 5-day Abnormal Turnover, identifies sustainable price movements by rewarding high institutional conviction that is not yet undermined by retail-driven liquidity exhaustion.\n                Concise Observation: Parent 1's liquidity exhaustion (RankIC 0.0248) and Parent 2's institutional conviction (RankIC 0.0252) both capture distinct alpha sources, but individually fail to distinguish between trend persistence and trend exhaustion during high-volatility events.\n                Concise Justification: Institutional investors typically express conviction through overnight gaps, while retail investors often drive late-stage volume surges; a factor that scales the strength of the gap by the inverse of recent volume intensity captures the 'purity' of the institutional signal.\n                Concise Knowledge: If institutional conviction (overnight gap) is high while retail participation (abnormal turnover) remains moderate, the price trend is more likely to persist; conversely, when high conviction is accompanied by extreme turnover, the probability of a mean-reversion event increases due to liquidity exhaustion.\n                concise Specification: The factor is defined as ( (Open - Close_prev) / (High - Low + 1e-6) ) / ( (Volume_5d_mean / Volume_20d_mean) + 1e-6 ), where the numerator represents the conviction gap and the denominator represents the 5-day abnormal turnover ratio as a proxy for liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "fd2838afc896",
      "parent_trajectory_ids": [
        "558b7ad50fac",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0059976693228329,
        "ICIR": 0.0442200815507922,
        "RankIC": 0.0227144863478864,
        "RankICIR": 0.1738311683058916,
        "annualized_return": 0.0701262051024463,
        "information_ratio": 1.0822167722531244,
        "max_drawdown": -0.1238228584092356
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:27:51.155933",
      "updated_at": "2026-01-17T04:27:51.155939"
    },
    "c02477aa5a4b255b": {
      "factor_id": "c02477aa5a4b255b",
      "factor_name": "ISB_Coil_Support_Gap_10D",
      "factor_expression": "(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * TS_MEAN(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8), 5) * SIGN($open - DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * TS_MEAN(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8), 5) * SIGN($open - DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"ISB_Coil_Support_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Informed Structural Breakout factor identifies sustainable price moves by multiplying a 10-day volume density (Coil) with a 5-day institutional support score and the sign of the overnight price gap. High volume in a narrow range signifies accumulation, which, when combined with price support and a positive gap, indicates a high-conviction breakout.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Structural Breakout (ISB) factor identifies sustainable price moves by multiplying a 10-day volatility-normalized volume density (representing 'coiled' liquidity) with a 5-day institutional support persistence score and the sign of the overnight price gap.\n                Concise Observation: Parent 1 (RankIC=0.0234) successfully captures volume concentration but lacks directional conviction, while Parent 2 (RankIC=0.0265) identifies support levels but misses the explosive potential of low-volatility 'coils'.\n                Concise Justification: Multiplying volume density by a support metric creates a non-linear filter that prioritizes assets where liquidity is being actively absorbed at established price floors, while the overnight gap provides a high-conviction directional trigger.\n                Concise Knowledge: If high volume density occurs within a narrow price range (compression), it signifies accumulation; when this state is combined with institutional price support and confirmed by overnight sentiment, the subsequent breakout is more likely to be persistent.\n                concise Specification: Define 'Coil' as the 10-day sum of volume divided by the 10-day price range; define 'Support' as the 5-day average of (Low - Close.min) / (High - Low); the final factor is Coil * Support * sign(Open - Close_prev).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "8a6e9fe51078",
      "parent_trajectory_ids": [
        "2e3d00378ae9",
        "d75e00a65fc2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029805922840875,
        "ICIR": 0.0220525340961762,
        "RankIC": 0.0180366356582126,
        "RankICIR": 0.1365198838404512,
        "annualized_return": 0.0320310098625329,
        "information_ratio": 0.4775910895196999,
        "max_drawdown": -0.1228907016328854
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:30:31.004543",
      "updated_at": "2026-01-17T04:30:31.004550"
    },
    "b5d213c5e57ba216": {
      "factor_id": "b5d213c5e57ba216",
      "factor_name": "Z_Informed_Breakout_Ranked",
      "factor_expression": "RANK(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * RANK(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM($volume, 10) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)) * RANK(($low - TS_MIN($close, 5)) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"Z_Informed_Breakout_Ranked\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Informed Structural Breakout hypothesis. It normalizes the 'Coil' (volume/range ratio) and 'Support' (relative low position) components to ensure the factor is robust across different market regimes and asset scales before applying the overnight gap trigger.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Structural Breakout (ISB) factor identifies sustainable price moves by multiplying a 10-day volatility-normalized volume density (representing 'coiled' liquidity) with a 5-day institutional support persistence score and the sign of the overnight price gap.\n                Concise Observation: Parent 1 (RankIC=0.0234) successfully captures volume concentration but lacks directional conviction, while Parent 2 (RankIC=0.0265) identifies support levels but misses the explosive potential of low-volatility 'coils'.\n                Concise Justification: Multiplying volume density by a support metric creates a non-linear filter that prioritizes assets where liquidity is being actively absorbed at established price floors, while the overnight gap provides a high-conviction directional trigger.\n                Concise Knowledge: If high volume density occurs within a narrow price range (compression), it signifies accumulation; when this state is combined with institutional price support and confirmed by overnight sentiment, the subsequent breakout is more likely to be persistent.\n                concise Specification: Define 'Coil' as the 10-day sum of volume divided by the 10-day price range; define 'Support' as the 5-day average of (Low - Close.min) / (High - Low); the final factor is Coil * Support * sign(Open - Close_prev).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "8a6e9fe51078",
      "parent_trajectory_ids": [
        "2e3d00378ae9",
        "d75e00a65fc2"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029805922840875,
        "ICIR": 0.0220525340961762,
        "RankIC": 0.0180366356582126,
        "RankICIR": 0.1365198838404512,
        "annualized_return": 0.0320310098625329,
        "information_ratio": 0.4775910895196999,
        "max_drawdown": -0.1228907016328854
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:30:31.028117",
      "updated_at": "2026-01-17T04:30:31.028123"
    },
    "8963de14678f1aaa": {
      "factor_id": "8963de14678f1aaa",
      "factor_name": "LASC_Factor_3_5D",
      "factor_expression": "SIGN($open - DELAY($close, 1)) * TS_MEAN($volume / ($high - $low + 1e-6), 3) * TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open - DELAY($close, 1)) * TS_MEAN($volume / ($high - $low + 1e-6), 3) * TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5)\" # Your output factor expression will be filled in here\n    name = \"LASC_Factor_3_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Liquidity Absorption & Support Convergence (LASC) factor. It identifies institutional accumulation by measuring price absorption (high volume in narrow range) and support persistence (lows held relative to range), adjusted by the overnight gap sentiment.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Absorption & Support Convergence (LASC) factor, calculated as the product of a 3-day price absorption ratio (volume divided by high-low range) and a 5-day support persistence metric (mean of low-to-range ratio), identifies high-quality institutional accumulation when adjusted by the sign of the overnight gap.\n                Concise Observation: Parent 1 showed that intraday stability (low range per volume) captures institutional activity (RankIC=0.0229), while Parent 2 demonstrated that support levels and overnight gaps predict reversals (RankIC=0.0265); combining these filters reduces noise from low-volatility drift.\n                Concise Justification: Institutional buyers often hide their tracks by absorbing liquidity within tight price bands; by multiplying the absorption efficiency with a support-based persistence measure, we isolate periods where price floors are actively defended by large-scale limit orders.\n                Concise Knowledge: If high volume occurs within a narrow price range (absorption) while prices consistently hold near the daily lows (support persistence), then the underlying asset is likely experiencing institutional accumulation; this signal is more reliable when confirmed by overnight sentiment (gap direction).\n                concise Specification: Define Absorption as $volume / ($high - $low + 1e-6) over 3 days; define Support as ($low - $open) / ($high - $low + 1e-6) over 5 days; the final factor is the product of these two, multiplied by the sign of ($open_t - $close_{t-1}) to align with short-term sentiment bias.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f2aa418d8203",
      "parent_trajectory_ids": [
        "09b9e0babff9",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045555821708553,
        "ICIR": 0.034049696424528,
        "RankIC": 0.0188423534034833,
        "RankICIR": 0.1444675523442208,
        "annualized_return": 0.0612561414231417,
        "information_ratio": 0.9483138314734816,
        "max_drawdown": -0.0778155499757223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:32:47.860472",
      "updated_at": "2026-01-17T04:32:47.860479"
    },
    "c8fbcdcf82df067d": {
      "factor_id": "c8fbcdcf82df067d",
      "factor_name": "Ranked_LASC_Institutional_Accumulation",
      "factor_expression": "SIGN($open - DELAY($close, 1)) * RANK(TS_MEAN($volume / ($high - $low + 1e-6), 3)) * RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($open - DELAY($close, 1)) * RANK(TS_MEAN($volume / ($high - $low + 1e-6), 3)) * RANK(TS_MEAN(($low - $open) / ($high - $low + 1e-6), 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_LASC_Institutional_Accumulation\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the LASC factor. It focuses on the relative strength of liquidity absorption and support persistence across the universe, smoothing the components to ensure robustness against outliers in volume and range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity Absorption & Support Convergence (LASC) factor, calculated as the product of a 3-day price absorption ratio (volume divided by high-low range) and a 5-day support persistence metric (mean of low-to-range ratio), identifies high-quality institutional accumulation when adjusted by the sign of the overnight gap.\n                Concise Observation: Parent 1 showed that intraday stability (low range per volume) captures institutional activity (RankIC=0.0229), while Parent 2 demonstrated that support levels and overnight gaps predict reversals (RankIC=0.0265); combining these filters reduces noise from low-volatility drift.\n                Concise Justification: Institutional buyers often hide their tracks by absorbing liquidity within tight price bands; by multiplying the absorption efficiency with a support-based persistence measure, we isolate periods where price floors are actively defended by large-scale limit orders.\n                Concise Knowledge: If high volume occurs within a narrow price range (absorption) while prices consistently hold near the daily lows (support persistence), then the underlying asset is likely experiencing institutional accumulation; this signal is more reliable when confirmed by overnight sentiment (gap direction).\n                concise Specification: Define Absorption as $volume / ($high - $low + 1e-6) over 3 days; define Support as ($low - $open) / ($high - $low + 1e-6) over 5 days; the final factor is the product of these two, multiplied by the sign of ($open_t - $close_{t-1}) to align with short-term sentiment bias.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "f2aa418d8203",
      "parent_trajectory_ids": [
        "09b9e0babff9",
        "d75e00a65fc2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0045555821708553,
        "ICIR": 0.034049696424528,
        "RankIC": 0.0188423534034833,
        "RankICIR": 0.1444675523442208,
        "annualized_return": 0.0612561414231417,
        "information_ratio": 0.9483138314734816,
        "max_drawdown": -0.0778155499757223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:32:47.884159",
      "updated_at": "2026-01-17T04:32:47.884165"
    },
    "850138de110e25e1": {
      "factor_id": "850138de110e25e1",
      "factor_name": "Institutional_Absorption_Exhaustion_10D",
      "factor_expression": "TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 10) * (1 - POW(TS_CORR($close, SEQUENCE(10), 10), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 10) * (1 - POW(TS_CORR($close, SEQUENCE(10), 10), 2))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential trend reversals by combining volume density (absorption) with trend linearity decay. It calculates the product of the average volume-to-squared-range ratio and the degree of non-linearity (1 - RSQR) over a 10-day period. High values suggest institutional absorption during a maturing trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption-Exhaustion' factor, defined as the product of the 10-day Volume-to-Squared-Range ratio and the 10-day Price Trend Non-Linearity (1 - RSQR), identifies high-probability reversals by detecting institutional liquidity absorption at the climax of rigid price trends.\n                Concise Observation: Parent 1 showed that trend linearity (RSQR) effectively identifies trend maturity, while Parent 2 demonstrated that volume density relative to squared price range captures stealth institutional activity; combining them addresses the weakness of each acting in isolation.\n                Concise Justification: Institutional investors often accumulate or distribute large positions near trend exhaustion points without causing large price swings (stealth); by weighting this 'absorption' by the decay in trend linearity, we isolate the specific moment where smart money overcomes the prevailing trend's inertia.\n                Concise Knowledge: If high volume occurs within a narrow price range (high absorption density) while a previously linear price trend loses its structural rigidity (low RSQR), then a trend reversal or high-quality breakout is imminent; institutional positioning is most effective when it disrupts established retail momentum.\n                concise Specification: Calculate the 10-day rolling RSQR of daily close prices and the 10-day rolling average of (Volume / (High - Low)^2); the final factor is the product of the average volume density and (1 - RSQR), targeting assets with high consolidation density and low trend fit.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "574cd1e862c0",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047167361451284,
        "ICIR": 0.0364844064841437,
        "RankIC": 0.0191266897767354,
        "RankICIR": 0.1502700646302422,
        "annualized_return": 0.0513879652748899,
        "information_ratio": 0.8647905410225525,
        "max_drawdown": -0.0999122671344044
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:35:28.438738",
      "updated_at": "2026-01-17T04:35:28.438750"
    },
    "0c23295be2fe9201": {
      "factor_id": "0c23295be2fe9201",
      "factor_name": "Cross_Sectional_Absorption_Density_20D",
      "factor_expression": "RANK(TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Absorption_Density_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the absorption density focused on price range efficiency. It measures where volume is high relative to the price volatility (squared range), identifying stocks under heavy accumulation or distribution relative to the market universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption-Exhaustion' factor, defined as the product of the 10-day Volume-to-Squared-Range ratio and the 10-day Price Trend Non-Linearity (1 - RSQR), identifies high-probability reversals by detecting institutional liquidity absorption at the climax of rigid price trends.\n                Concise Observation: Parent 1 showed that trend linearity (RSQR) effectively identifies trend maturity, while Parent 2 demonstrated that volume density relative to squared price range captures stealth institutional activity; combining them addresses the weakness of each acting in isolation.\n                Concise Justification: Institutional investors often accumulate or distribute large positions near trend exhaustion points without causing large price swings (stealth); by weighting this 'absorption' by the decay in trend linearity, we isolate the specific moment where smart money overcomes the prevailing trend's inertia.\n                Concise Knowledge: If high volume occurs within a narrow price range (high absorption density) while a previously linear price trend loses its structural rigidity (low RSQR), then a trend reversal or high-quality breakout is imminent; institutional positioning is most effective when it disrupts established retail momentum.\n                concise Specification: Calculate the 10-day rolling RSQR of daily close prices and the 10-day rolling average of (Volume / (High - Low)^2); the final factor is the product of the average volume density and (1 - RSQR), targeting assets with high consolidation density and low trend fit.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "574cd1e862c0",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047167361451284,
        "ICIR": 0.0364844064841437,
        "RankIC": 0.0191266897767354,
        "RankICIR": 0.1502700646302422,
        "annualized_return": 0.0513879652748899,
        "information_ratio": 0.8647905410225525,
        "max_drawdown": -0.0999122671344044
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:35:28.477002",
      "updated_at": "2026-01-17T04:35:28.477009"
    },
    "5e621ca92d46931b": {
      "factor_id": "5e621ca92d46931b",
      "factor_name": "Trend_Linearity_Exhaustion_15D",
      "factor_expression": "ABS(REGRESI($close, SEQUENCE(15), 15)) / (TS_STD($close, 15) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(REGRESI($close, SEQUENCE(15), 15)) / (TS_STD($close, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Linearity_Exhaustion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'exhaustion' component of the hypothesis by identifying assets whose price trends are losing their linear rigidity. It uses the residual of a linear regression of price against time, normalized by the standard deviation, to detect structural breaks in momentum.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption-Exhaustion' factor, defined as the product of the 10-day Volume-to-Squared-Range ratio and the 10-day Price Trend Non-Linearity (1 - RSQR), identifies high-probability reversals by detecting institutional liquidity absorption at the climax of rigid price trends.\n                Concise Observation: Parent 1 showed that trend linearity (RSQR) effectively identifies trend maturity, while Parent 2 demonstrated that volume density relative to squared price range captures stealth institutional activity; combining them addresses the weakness of each acting in isolation.\n                Concise Justification: Institutional investors often accumulate or distribute large positions near trend exhaustion points without causing large price swings (stealth); by weighting this 'absorption' by the decay in trend linearity, we isolate the specific moment where smart money overcomes the prevailing trend's inertia.\n                Concise Knowledge: If high volume occurs within a narrow price range (high absorption density) while a previously linear price trend loses its structural rigidity (low RSQR), then a trend reversal or high-quality breakout is imminent; institutional positioning is most effective when it disrupts established retail momentum.\n                concise Specification: Calculate the 10-day rolling RSQR of daily close prices and the 10-day rolling average of (Volume / (High - Low)^2); the final factor is the product of the average volume density and (1 - RSQR), targeting assets with high consolidation density and low trend fit.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "574cd1e862c0",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047167361451284,
        "ICIR": 0.0364844064841437,
        "RankIC": 0.0191266897767354,
        "RankICIR": 0.1502700646302422,
        "annualized_return": 0.0513879652748899,
        "information_ratio": 0.8647905410225525,
        "max_drawdown": -0.0999122671344044
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:35:28.510721",
      "updated_at": "2026-01-17T04:35:28.510731"
    },
    "6c85d665d5418c64": {
      "factor_id": "6c85d665d5418c64",
      "factor_name": "Inst_Exhaustion_Reversal_10D",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-8) / (TS_STD($close, 10) + 1e-8)) * (1 / (1 + ABS(DELTA(REGRESI($close, SEQUENCE(5), 5), 1))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-8) / (TS_STD($close, 10) + 1e-8)) * (1 / (1 + ABS(DELTA(REGRESI($close, SEQUENCE(5), 5), 1))))\" # Your output factor expression will be filled in here\n    name = \"Inst_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price exhaustion by interacting the institutional conviction gap (overnight gap relative to range) with the 5-day change in price residual convexity. It aims to capture 'blow-off' tops or bottoms where high institutional activity meets decelerating price energy.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Momentum-Exhaustion' factor, calculated as the 10-day volatility-normalized Institutional Conviction Gap multiplied by the negative 5-day change in price-residual convexity, identifies high-probability reversals and sustainable trends by filtering institutional signals through a lens of price exhaustion.\n                Concise Observation: Parent 1's residual convexity (RankIC 0.0237) and Parent 2's conviction gap (RankIC 0.0252) both capture price-volume anomalies, but they fail to distinguish between the start of a trend and its final exhaustion phase.\n                Concise Justification: By interacting the conviction gap with the inverse of residual velocity, we isolate 'clean' smart-money entries that have not yet depleted their price energy, thereby reducing the risk of buying into a climax.\n                Concise Knowledge: If institutional conviction (overnight gap relative to range) is high while price residual acceleration (convexity) is low or negative, the trend is likely sustainable; when high conviction coincides with extreme residual acceleration, it signals a 'blow-off' exhaustion point.\n                concise Specification: The factor is defined as (Gap_Ratio / TS_STD($close, 10)) * (1 / (1 + ABS(Delta_RESI5))), where Gap_Ratio is ($open - $close.shift(1)) / (($high - $low) + ($low - $close.shift(1))), and Delta_RESI5 is the 5-day difference of the residual of $close regressed against time.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "75821eb5ffff",
      "parent_trajectory_ids": [
        "c7199504b485",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048621246374715,
        "ICIR": 0.0383360805784428,
        "RankIC": 0.0191808615256612,
        "RankICIR": 0.1535564180682635,
        "annualized_return": 0.0663555207704074,
        "information_ratio": 1.0807202666469589,
        "max_drawdown": -0.0762739481620921
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:37:30.357928",
      "updated_at": "2026-01-17T04:37:30.357936"
    },
    "75f75ad197c75734": {
      "factor_id": "75f75ad197c75734",
      "factor_name": "Sustainable_Conviction_Gap_15D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_STD($close, 15) + 1e-8)) * (1 - RANK(ABS(REGRESI($close, SEQUENCE(10), 10))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_STD($close, 15) + 1e-8)) * (1 - RANK(ABS(REGRESI($close, SEQUENCE(10), 10))))\" # Your output factor expression will be filled in here\n    name = \"Sustainable_Conviction_Gap_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the volatility-normalized institutional gap filtered by the stability of price residuals. It favors stocks where the overnight gap is supported by consistent price behavior rather than extreme acceleration, suggesting a more sustainable trend.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Momentum-Exhaustion' factor, calculated as the 10-day volatility-normalized Institutional Conviction Gap multiplied by the negative 5-day change in price-residual convexity, identifies high-probability reversals and sustainable trends by filtering institutional signals through a lens of price exhaustion.\n                Concise Observation: Parent 1's residual convexity (RankIC 0.0237) and Parent 2's conviction gap (RankIC 0.0252) both capture price-volume anomalies, but they fail to distinguish between the start of a trend and its final exhaustion phase.\n                Concise Justification: By interacting the conviction gap with the inverse of residual velocity, we isolate 'clean' smart-money entries that have not yet depleted their price energy, thereby reducing the risk of buying into a climax.\n                Concise Knowledge: If institutional conviction (overnight gap relative to range) is high while price residual acceleration (convexity) is low or negative, the trend is likely sustainable; when high conviction coincides with extreme residual acceleration, it signals a 'blow-off' exhaustion point.\n                concise Specification: The factor is defined as (Gap_Ratio / TS_STD($close, 10)) * (1 / (1 + ABS(Delta_RESI5))), where Gap_Ratio is ($open - $close.shift(1)) / (($high - $low) + ($low - $close.shift(1))), and Delta_RESI5 is the 5-day difference of the residual of $close regressed against time.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "75821eb5ffff",
      "parent_trajectory_ids": [
        "c7199504b485",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048621246374715,
        "ICIR": 0.0383360805784428,
        "RankIC": 0.0191808615256612,
        "RankICIR": 0.1535564180682635,
        "annualized_return": 0.0663555207704074,
        "information_ratio": 1.0807202666469589,
        "max_drawdown": -0.0762739481620921
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:37:30.382521",
      "updated_at": "2026-01-17T04:37:30.382527"
    },
    "747074138c6e3b7c": {
      "factor_id": "747074138c6e3b7c",
      "factor_name": "Institutional_Momentum_Energy_Ratio",
      "factor_expression": "TS_ZSCORE($open - DELAY($close, 1), 10) / (1 + TS_STD(DELTA($close, 1), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($open - DELAY($close, 1), 10) / (1 + TS_STD(DELTA($close, 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Momentum_Energy_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the gap-based conviction metric with a volume-weighted price range to assess the 'energy' behind institutional moves. It seeks to identify entries where conviction is high but the price has not yet reached a state of volatility exhaustion.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Momentum-Exhaustion' factor, calculated as the 10-day volatility-normalized Institutional Conviction Gap multiplied by the negative 5-day change in price-residual convexity, identifies high-probability reversals and sustainable trends by filtering institutional signals through a lens of price exhaustion.\n                Concise Observation: Parent 1's residual convexity (RankIC 0.0237) and Parent 2's conviction gap (RankIC 0.0252) both capture price-volume anomalies, but they fail to distinguish between the start of a trend and its final exhaustion phase.\n                Concise Justification: By interacting the conviction gap with the inverse of residual velocity, we isolate 'clean' smart-money entries that have not yet depleted their price energy, thereby reducing the risk of buying into a climax.\n                Concise Knowledge: If institutional conviction (overnight gap relative to range) is high while price residual acceleration (convexity) is low or negative, the trend is likely sustainable; when high conviction coincides with extreme residual acceleration, it signals a 'blow-off' exhaustion point.\n                concise Specification: The factor is defined as (Gap_Ratio / TS_STD($close, 10)) * (1 / (1 + ABS(Delta_RESI5))), where Gap_Ratio is ($open - $close.shift(1)) / (($high - $low) + ($low - $close.shift(1))), and Delta_RESI5 is the 5-day difference of the residual of $close regressed against time.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "75821eb5ffff",
      "parent_trajectory_ids": [
        "c7199504b485",
        "77bb890cab72"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048621246374715,
        "ICIR": 0.0383360805784428,
        "RankIC": 0.0191808615256612,
        "RankICIR": 0.1535564180682635,
        "annualized_return": 0.0663555207704074,
        "information_ratio": 1.0807202666469589,
        "max_drawdown": -0.0762739481620921
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:37:30.406766",
      "updated_at": "2026-01-17T04:37:30.406772"
    },
    "2ca3a9a4260666f5": {
      "factor_id": "2ca3a9a4260666f5",
      "factor_name": "Gap_Efficiency_Ratio_20D",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Gap_Efficiency_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the ratio of the absolute overnight gap to the intraday range, smoothed over 20 days. A high ratio suggests that price discovery is occurring primarily through overnight information shocks rather than intraday noise, indicating high-conviction institutional movement.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Gap Efficiency factor, calculated as the ratio of the absolute overnight gap to the 20-day ATR-normalized intraday range, predicts future returns by identifying high-conviction information shocks that occur without excessive intraday exhaustion.\n                Concise Observation: Parent 1 showed that ATR-normalized ranges capture volatility regimes (RankIC 0.029), while Parent 2 highlighted that overnight gaps contain unique information (RankIC 0.024); however, both struggle when high volatility is purely noise-driven.\n                Concise Justification: By using the 20-day ATR to scale the intraday range, we create a 'noise' baseline that allows the overnight 'signal' (the gap) to be evaluated for efficiency, where a high ratio signifies a clean price discovery process.\n                Concise Knowledge: If a significant overnight price gap is followed by a narrow, ATR-normalized intraday range, it indicates institutional conviction; conversely, wide intraday ranges relative to historical volatility suggest speculative exhaustion and noise.\n                concise Specification: The factor is defined as (abs(Open_t - Close_{t-1}) / ATR(20)_t) / ((High_t - Low_t) / ATR(20)_t), which simplifies to abs(Open_t - Close_{t-1}) / (High_t - Low_t), where ATR(20) provides the context for 'normal' movement.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b94108e85f56",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "a79c88fcd924"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049839754120521,
        "ICIR": 0.0347786556387274,
        "RankIC": 0.0221394957570045,
        "RankICIR": 0.1582793905217302,
        "annualized_return": 0.0745694145530136,
        "information_ratio": 1.1045058007815225,
        "max_drawdown": -0.0884942850477227
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:38:49.382244",
      "updated_at": "2026-01-17T04:38:49.382252"
    },
    "55d6f7c75c8976f9": {
      "factor_id": "55d6f7c75c8976f9",
      "factor_name": "Volatility_Adjusted_Gap_Conviction",
      "factor_expression": "ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, ABS($high - DELAY($close, 1))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8)) / (($high - $low) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Conviction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the 20-day average true range (ATR) divided by the intraday range relative to the same ATR. It identifies days where the gap is significant but the subsequent intraday volatility is suppressed, signifying efficient price adjustment.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Gap Efficiency factor, calculated as the ratio of the absolute overnight gap to the 20-day ATR-normalized intraday range, predicts future returns by identifying high-conviction information shocks that occur without excessive intraday exhaustion.\n                Concise Observation: Parent 1 showed that ATR-normalized ranges capture volatility regimes (RankIC 0.029), while Parent 2 highlighted that overnight gaps contain unique information (RankIC 0.024); however, both struggle when high volatility is purely noise-driven.\n                Concise Justification: By using the 20-day ATR to scale the intraday range, we create a 'noise' baseline that allows the overnight 'signal' (the gap) to be evaluated for efficiency, where a high ratio signifies a clean price discovery process.\n                Concise Knowledge: If a significant overnight price gap is followed by a narrow, ATR-normalized intraday range, it indicates institutional conviction; conversely, wide intraday ranges relative to historical volatility suggest speculative exhaustion and noise.\n                concise Specification: The factor is defined as (abs(Open_t - Close_{t-1}) / ATR(20)_t) / ((High_t - Low_t) / ATR(20)_t), which simplifies to abs(Open_t - Close_{t-1}) / (High_t - Low_t), where ATR(20) provides the context for 'normal' movement.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b94108e85f56",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "a79c88fcd924"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049839754120521,
        "ICIR": 0.0347786556387274,
        "RankIC": 0.0221394957570045,
        "RankICIR": 0.1582793905217302,
        "annualized_return": 0.0745694145530136,
        "information_ratio": 1.1045058007815225,
        "max_drawdown": -0.0884942850477227
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:38:49.407431",
      "updated_at": "2026-01-17T04:38:49.407437"
    },
    "d8fd499046307bae": {
      "factor_id": "d8fd499046307bae",
      "factor_name": "Cross_Sectional_Gap_Efficiency_Z",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Gap_Efficiency_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the gap efficiency ratio. It ranks stocks based on how much of their daily volatility is explained by the overnight gap versus intraday churn, highlighting stocks with the cleanest information-driven price moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Volatility-Adjusted Gap Efficiency factor, calculated as the ratio of the absolute overnight gap to the 20-day ATR-normalized intraday range, predicts future returns by identifying high-conviction information shocks that occur without excessive intraday exhaustion.\n                Concise Observation: Parent 1 showed that ATR-normalized ranges capture volatility regimes (RankIC 0.029), while Parent 2 highlighted that overnight gaps contain unique information (RankIC 0.024); however, both struggle when high volatility is purely noise-driven.\n                Concise Justification: By using the 20-day ATR to scale the intraday range, we create a 'noise' baseline that allows the overnight 'signal' (the gap) to be evaluated for efficiency, where a high ratio signifies a clean price discovery process.\n                Concise Knowledge: If a significant overnight price gap is followed by a narrow, ATR-normalized intraday range, it indicates institutional conviction; conversely, wide intraday ranges relative to historical volatility suggest speculative exhaustion and noise.\n                concise Specification: The factor is defined as (abs(Open_t - Close_{t-1}) / ATR(20)_t) / ((High_t - Low_t) / ATR(20)_t), which simplifies to abs(Open_t - Close_{t-1}) / (High_t - Low_t), where ATR(20) provides the context for 'normal' movement.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b94108e85f56",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "a79c88fcd924"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049839754120521,
        "ICIR": 0.0347786556387274,
        "RankIC": 0.0221394957570045,
        "RankICIR": 0.1582793905217302,
        "annualized_return": 0.0745694145530136,
        "information_ratio": 1.1045058007815225,
        "max_drawdown": -0.0884942850477227
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:38:49.431054",
      "updated_at": "2026-01-17T04:38:49.431060"
    },
    "5495e194e6b567f6": {
      "factor_id": "5495e194e6b567f6",
      "factor_name": "Idio_Vol_Exhaustion_V1",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($close + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN($return * $volume, 10))) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($close + 1e-8), 10) * (RANK(TS_PCTCHANGE($close, 10)) - RANK(TS_MEAN(TS_PCTCHANGE($close, 1) * $volume, 10))) * (TS_MEAN(ABS($open - DELAY($close, 1)), 5) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Idio_Vol_Exhaustion_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by combining idiosyncratic volatility dispersion with price-volume divergence. It calculates the 10-day TS_ZSCORE of the intraday range, multiplies it by the rank difference between 10-day price momentum and volume-weighted returns, and scales it by the ratio of overnight volatility to intraday range.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Idiosyncratic Volatility-Volume Exhaustion factor, defined by the product of 10-day Cross-Sectional Volatility Dispersion (CSVD) and the rank-difference between price momentum and volume-weighted returns, identifies high-conviction reversals when filtered by the overnight-to-intraday volatility ratio.\n                Concise Observation: Parent 1 (CSVD) captures alpha from volatility dispersion (RankIC 0.026), while Parent 2 identifies institutional reversals through price-volume divergence (RankIC 0.022); combining them addresses the noise inherent in individual volatility spikes.\n                Concise Justification: CSVD identifies assets undergoing unique re-pricing, but requires a conviction filter (price-volume rank difference) and a volatility regime check (overnight gap ratio) to distinguish between sustainable trends and mean-reverting exhaustion points.\n                Concise Knowledge: If a stock's idiosyncratic range volatility expands while its price-volume trend diverges, it indicates institutional exhaustion; when this occurs alongside high overnight-to-intraday volatility, the likelihood of a price reversal increases due to liquidity-driven overextension.\n                concise Specification: Calculate CSVD as the 10-day rolling Z-score of (High-Low)/Close; multiply by the difference between 10-day price change rank and 10-day volume-weighted return rank; then scale by the ratio of the 5-day average overnight gap to intraday range.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a5cc0d100065",
      "parent_trajectory_ids": [
        "7513729d3145",
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:40:09.105511",
      "updated_at": "2026-01-17T04:40:09.105517"
    },
    "2acc07ebc4d05204": {
      "factor_id": "2acc07ebc4d05204",
      "factor_name": "Vol_Dispersion_Conviction_Reversal",
      "factor_expression": "ZSCORE(TS_STD(($high - $low) / ($close + 1e-8), 10)) * RANK(TS_PCTCHANGE($close, 10) - TS_PCTCHANGE($volume, 10)) * (ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_STD(($high - $low) / ($close + 1e-8), 10)) * RANK(DELTA($close, 10) - DELTA($volume, 10)) * (ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Dispersion_Conviction_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the idiosyncratic exhaustion hypothesis focusing on the interaction between volatility dispersion (CSVD) and the divergence between price trends and volume-weighted activity, normalized by the overnight gap intensity.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Idiosyncratic Volatility-Volume Exhaustion factor, defined by the product of 10-day Cross-Sectional Volatility Dispersion (CSVD) and the rank-difference between price momentum and volume-weighted returns, identifies high-conviction reversals when filtered by the overnight-to-intraday volatility ratio.\n                Concise Observation: Parent 1 (CSVD) captures alpha from volatility dispersion (RankIC 0.026), while Parent 2 identifies institutional reversals through price-volume divergence (RankIC 0.022); combining them addresses the noise inherent in individual volatility spikes.\n                Concise Justification: CSVD identifies assets undergoing unique re-pricing, but requires a conviction filter (price-volume rank difference) and a volatility regime check (overnight gap ratio) to distinguish between sustainable trends and mean-reverting exhaustion points.\n                Concise Knowledge: If a stock's idiosyncratic range volatility expands while its price-volume trend diverges, it indicates institutional exhaustion; when this occurs alongside high overnight-to-intraday volatility, the likelihood of a price reversal increases due to liquidity-driven overextension.\n                concise Specification: Calculate CSVD as the 10-day rolling Z-score of (High-Low)/Close; multiply by the difference between 10-day price change rank and 10-day volume-weighted return rank; then scale by the ratio of the 5-day average overnight gap to intraday range.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a5cc0d100065",
      "parent_trajectory_ids": [
        "7513729d3145",
        "5b9cfce9cb57"
      ],
      "is_sota": false,
      "quality": "Poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:40:09.130081",
      "updated_at": "2026-01-17T04:40:09.130086"
    },
    "a189234f57dc4140": {
      "factor_id": "a189234f57dc4140",
      "factor_name": "IAP_Factor_10D",
      "factor_expression": "(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IAP_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Information Asymmetry Persistence (IAP) factor: It calculates the ratio of the volume coefficient of variation to the price return volatility over a 10-day window. High values identify stocks with significant volume dispersion during price consolidation, signaling institutional positioning.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.946476",
      "updated_at": "2026-01-17T04:43:37.946483"
    },
    "54f8a6f63ea313e6": {
      "factor_id": "54f8a6f63ea313e6",
      "factor_name": "Z_IAP_Divergence_15D",
      "factor_expression": "ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 1e-8)) / (TS_STD($return, 15) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_STD($volume, 15) / (TS_MEAN($volume, 15) + 0.000001)) / (TS_STD(TS_PCTCHANGE($close, 1), 15) + 0.000001))\" # Your output factor expression will be filled in here\n    name = \"Z_IAP_Divergence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the Information Asymmetry Persistence hypothesis using a 15-day window. It measures the relative intensity of volume-price divergence compared to other stocks, highlighting extreme institutional accumulation phases.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.970699",
      "updated_at": "2026-01-17T04:43:37.970705"
    },
    "fc91fb2a85d935be": {
      "factor_id": "fc91fb2a85d935be",
      "factor_name": "IAP_Rank_Trend_20D",
      "factor_expression": "TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD($return, 10) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK((TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"IAP_Rank_Trend_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the persistence of information asymmetry by taking the 20-day time-series rank of the IAP ratio. A high rank suggests that the current 'quiet' accumulation phase is at its most intense relative to the past month.",
      "experiment_id": "2026-01-16_17-24-42-691566",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Persistence (IAP) factor, defined as the ratio of 10-day volume coefficient of variation to 10-day price volatility, identifies stocks where concentrated trading volume occurs during price consolidation, signaling institutional positioning before a trend breakout.\n                Concise Observation: Previous mean-reversion strategies focused on price exhaustion (Low-to-Range ratios) and sentiment gaps, but failed to capture the 'quiet' accumulation phases where volume spikes occur without immediate price impact.\n                Concise Justification: Institutional investors often use execution algorithms to minimize price impact during accumulation, leading to high volume variance across days while keeping price volatility low; this 'hidden' flow is a leading indicator of information asymmetry being resolved through a breakout.\n                Concise Knowledge: If trading volume becomes highly dispersed (high CV) while price remains stable (low volatility), it indicates non-random informed accumulation; such divergence suggests that the subsequent price movement will be a sustained trend rather than a mean-reversion event.\n                concise Specification: The factor is calculated as the 10-day standard deviation of volume divided by the 10-day mean volume, then divided by the 10-day standard deviation of daily returns (TS_STD($volume, 10) / TS_MEAN($volume, 10)) / TS_STD($close / DELAY($close, 1) - 1, 10).\n                ",
      "initial_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "user_initial_direction": "参考以下组合给出假设。组合3包含RESI5（表达式：Resi(, 5)/，含义：5日线性回归残差，反映价格偏离趋势程度）、KLOW（表达式：(Less(, )-)/，含义：K线下影线长度，反映盘中支撑力度）、STD5（表达式：Std(, 5)/，含义：5日收盘价标准差，衡量纯价格波动幅度）。",
      "planning_direction": "Volatility-Adjusted Mean Reversion: Scale the RESI5 factor by STD5 to identify price deviations that are statistically significant relative to recent realized volatility.",
      "evolution_phase": "mutation",
      "trajectory_id": "9d6755cab1f8",
      "parent_trajectory_ids": [
        "874eadba2218"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046383314193003,
        "ICIR": 0.0348111861289998,
        "RankIC": 0.021050608051061,
        "RankICIR": 0.1598321847801712,
        "annualized_return": 0.0665044181775811,
        "information_ratio": 1.073833126228163,
        "max_drawdown": -0.0841183580262917
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:43:37.994614",
      "updated_at": "2026-01-17T04:43:37.994620"
    },
    "1a592c4b2c507dc2": {
      "factor_id": "1a592c4b2c507dc2",
      "factor_name": "Inst_Absorp_Exhaustion_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close / (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) - 1) * TS_ZSCORE($volume / (POW($high - $low, 2) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close / (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) - 1) * TS_ZSCORE($volume / (MAX(POW($high - $low, 2), 1e-4)), 10)\" # Your output factor expression will be filled in here\n    name = \"Inst_Absorp_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction reversal points by combining trend linearity (R-squared), VWMA price deviation, and liquidity density. High R-squared indicates a stable trend, while a high volume-to-squared-range ratio suggests institutional accumulation. A subsequent deviation from the VWMA signals exhaustion of that institutional regime.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption Exhaustion' factor, defined as the product of the 10-day price-time R-squared and the 5-day VWMA price deviation, scaled by the 10-day Z-score of the volume-to-squared-range ratio, identifies high-conviction reversal points following institutional liquidity accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies trend stability but lacks volume context, while Parent 2 (RankIC 0.0303) identifies institutional presence but lacks trend directionality; combining them targets the 'maturation' phase of a move.\n                Concise Justification: High volume within narrow price ranges (Stealth Liquidity) creates a 'coiled spring' effect; when this occurs within a stable linear trend, the eventual deviation from the VWMA indicates a structural breakdown of the institutional accumulation/distribution regime.\n                Concise Knowledge: If a security exhibits high trend linearity (R-squared) alongside high liquidity density (Volume/Range^2), then subsequent deviations from the volume-weighted average price (VWMA) signify exhaustion of institutional support rather than random noise.\n                concise Specification: Calculate the 10-day R-squared of $close vs. time; calculate the 5-day VWMA deviation ($close / VWMA - 1); calculate the 10-day Z-score of ($volume / ($high - $low + epsilon)^2); the final factor is the product of these three components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "eaa213f8926b",
      "parent_trajectory_ids": [
        "6c7b79d75672",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035798662382449,
        "ICIR": 0.0243715991744727,
        "RankIC": 0.0170600930317845,
        "RankICIR": 0.1177336289915161,
        "annualized_return": 0.0067228323166186,
        "information_ratio": 0.089167333949632,
        "max_drawdown": -0.1571893892605717
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:54:32.127741",
      "updated_at": "2026-01-17T04:54:32.127747"
    },
    "610a2ceb1f65e65d": {
      "factor_id": "610a2ceb1f65e65d",
      "factor_name": "Liquidity_Density_Reversal_8D",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(8), 8)) * RANK($volume / ($high - $low + 1e-8)) * RANK($close - TS_MEAN($close, 8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(8), 8)) * RANK($volume / ($high - $low + 1e-8)) * RANK($close - TS_MEAN($close, 8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Density_Reversal_8D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the institutional exhaustion hypothesis focusing on the interaction between liquidity density (volume relative to price range) and price momentum. It identifies 'coiled spring' effects where high volume in tight ranges precedes a breakdown in trend linearity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption Exhaustion' factor, defined as the product of the 10-day price-time R-squared and the 5-day VWMA price deviation, scaled by the 10-day Z-score of the volume-to-squared-range ratio, identifies high-conviction reversal points following institutional liquidity accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies trend stability but lacks volume context, while Parent 2 (RankIC 0.0303) identifies institutional presence but lacks trend directionality; combining them targets the 'maturation' phase of a move.\n                Concise Justification: High volume within narrow price ranges (Stealth Liquidity) creates a 'coiled spring' effect; when this occurs within a stable linear trend, the eventual deviation from the VWMA indicates a structural breakdown of the institutional accumulation/distribution regime.\n                Concise Knowledge: If a security exhibits high trend linearity (R-squared) alongside high liquidity density (Volume/Range^2), then subsequent deviations from the volume-weighted average price (VWMA) signify exhaustion of institutional support rather than random noise.\n                concise Specification: Calculate the 10-day R-squared of $close vs. time; calculate the 5-day VWMA deviation ($close / VWMA - 1); calculate the 10-day Z-score of ($volume / ($high - $low + epsilon)^2); the final factor is the product of these three components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "eaa213f8926b",
      "parent_trajectory_ids": [
        "6c7b79d75672",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035798662382449,
        "ICIR": 0.0243715991744727,
        "RankIC": 0.0170600930317845,
        "RankICIR": 0.1177336289915161,
        "annualized_return": 0.0067228323166186,
        "information_ratio": 0.089167333949632,
        "max_drawdown": -0.1571893892605717
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:54:32.152270",
      "updated_at": "2026-01-17T04:54:32.152276"
    },
    "a1c2a770cf5cf908": {
      "factor_id": "a1c2a770cf5cf908",
      "factor_name": "Stealth_Accumulation_ZScore_12D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(12), 12), 2)) * ZSCORE($volume / (POW($high - $low, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(12), 12), 2)) * ZSCORE($volume / (POW($high - $low, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_ZScore_12D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'maturation' phase of a move by measuring the cross-sectional intensity of volume relative to price volatility (squared range) during periods of high trend persistence (R-squared).",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Absorption Exhaustion' factor, defined as the product of the 10-day price-time R-squared and the 5-day VWMA price deviation, scaled by the 10-day Z-score of the volume-to-squared-range ratio, identifies high-conviction reversal points following institutional liquidity accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies trend stability but lacks volume context, while Parent 2 (RankIC 0.0303) identifies institutional presence but lacks trend directionality; combining them targets the 'maturation' phase of a move.\n                Concise Justification: High volume within narrow price ranges (Stealth Liquidity) creates a 'coiled spring' effect; when this occurs within a stable linear trend, the eventual deviation from the VWMA indicates a structural breakdown of the institutional accumulation/distribution regime.\n                Concise Knowledge: If a security exhibits high trend linearity (R-squared) alongside high liquidity density (Volume/Range^2), then subsequent deviations from the volume-weighted average price (VWMA) signify exhaustion of institutional support rather than random noise.\n                concise Specification: Calculate the 10-day R-squared of $close vs. time; calculate the 5-day VWMA deviation ($close / VWMA - 1); calculate the 10-day Z-score of ($volume / ($high - $low + epsilon)^2); the final factor is the product of these three components.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "eaa213f8926b",
      "parent_trajectory_ids": [
        "6c7b79d75672",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0035798662382449,
        "ICIR": 0.0243715991744727,
        "RankIC": 0.0170600930317845,
        "RankICIR": 0.1177336289915161,
        "annualized_return": 0.0067228323166186,
        "information_ratio": 0.089167333949632,
        "max_drawdown": -0.1571893892605717
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T04:54:32.176148",
      "updated_at": "2026-01-17T04:54:32.176153"
    },
    "6dc247e8e817889e": {
      "factor_id": "6dc247e8e817889e",
      "factor_name": "Inertial_Compression_Absorption_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (SMA($volume / ($high - $low + 1e-8), 5, 1) / (SMA(ABS($close - $open) / ($high - $low + 1e-8), 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (SMA($volume / ($high - $low + 1e-8), 5, 1) / (SMA(ABS($close - $open) / ($high - $low + 1e-8), 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Inertial_Compression_Absorption_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining trend stability (R-squared of price) with price-volume density. High R-squared indicates a persistent trend, while a high ratio of volume-to-range relative to body-to-range suggests 'absorption' where high volume occurs within narrow price bands, signaling a continuation of the prior move.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Inertial Compression-Absorption' factor, defined as the product of the 10-day price trend R-squared and the ratio of 5-day average volume-to-range density to the 5-day average body-to-range ratio, identifies high-conviction institutional accumulation phases that precede trend-following breakouts.\n                Concise Observation: Parent 1 successfully used price body ratios to find exhaustion, while Parent 2 used volume-to-range squared to find stealth liquidity; however, both lacked a filter for trend stability, often leading to false signals in mean-reverting or chaotic regimes.\n                Concise Justification: High volume within narrow price bands suggests institutional absorption (liquidity drain), and when this occurs alongside a high R-squared (trend stability) and small price bodies (indecision), it indicates a temporary pause for accumulation before the next leg of the trend.\n                Concise Knowledge: If a market exhibits high structural persistence (R-squared) while volume is concentrated in narrow price ranges (high volume/range) and price bodies are small relative to total range (low body/range), then the resulting 'compressed absorption' signals a high-probability continuation of the existing trend.\n                concise Specification: The factor is calculated as (10-day R-squared of $close) * (SMA(Volume / (High - Low + epsilon), 5) / SMA(abs(Close - Open) / (High - Low + epsilon), 5)), where epsilon is a small constant to prevent division by zero.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d6415d4aa6f7",
      "parent_trajectory_ids": [
        "00a6075cc504",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026012431262506,
        "ICIR": 0.0192586554014756,
        "RankIC": 0.0179616309709079,
        "RankICIR": 0.1329784901916024,
        "annualized_return": 0.0073720711364907,
        "information_ratio": 0.1072068122868142,
        "max_drawdown": -0.1169963401656844
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:01:17.258409",
      "updated_at": "2026-01-17T05:01:17.258416"
    },
    "37b29548df676e25": {
      "factor_id": "37b29548df676e25",
      "factor_name": "Trend_Persistence_Absorption_Ratio",
      "factor_expression": "TS_RANK($close, 10) * (TS_MEAN($volume, 5) / (TS_MEAN(ABS($close - $open), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK($close, 10) * (TS_MEAN($volume, 5) / (TS_MEAN(ABS($close - $open), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Persistence_Absorption_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the compression-absorption hypothesis focusing on the interaction between price persistence and liquidity density. It uses the time-series rank of closing prices as a proxy for trend stability and compares the total volume relative to the price range versus the body size to identify stealth accumulation phases.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Inertial Compression-Absorption' factor, defined as the product of the 10-day price trend R-squared and the ratio of 5-day average volume-to-range density to the 5-day average body-to-range ratio, identifies high-conviction institutional accumulation phases that precede trend-following breakouts.\n                Concise Observation: Parent 1 successfully used price body ratios to find exhaustion, while Parent 2 used volume-to-range squared to find stealth liquidity; however, both lacked a filter for trend stability, often leading to false signals in mean-reverting or chaotic regimes.\n                Concise Justification: High volume within narrow price bands suggests institutional absorption (liquidity drain), and when this occurs alongside a high R-squared (trend stability) and small price bodies (indecision), it indicates a temporary pause for accumulation before the next leg of the trend.\n                Concise Knowledge: If a market exhibits high structural persistence (R-squared) while volume is concentrated in narrow price ranges (high volume/range) and price bodies are small relative to total range (low body/range), then the resulting 'compressed absorption' signals a high-probability continuation of the existing trend.\n                concise Specification: The factor is calculated as (10-day R-squared of $close) * (SMA(Volume / (High - Low + epsilon), 5) / SMA(abs(Close - Open) / (High - Low + epsilon), 5)), where epsilon is a small constant to prevent division by zero.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d6415d4aa6f7",
      "parent_trajectory_ids": [
        "00a6075cc504",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026012431262506,
        "ICIR": 0.0192586554014756,
        "RankIC": 0.0179616309709079,
        "RankICIR": 0.1329784901916024,
        "annualized_return": 0.0073720711364907,
        "information_ratio": 0.1072068122868142,
        "max_drawdown": -0.1169963401656844
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:01:17.282882",
      "updated_at": "2026-01-17T05:01:17.282888"
    },
    "14f311511630f9db": {
      "factor_id": "14f311511630f9db",
      "factor_name": "Cross_Sectional_Absorption_Strength",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 10)) * (($volume / ($high - $low + 1e-8)) / (ABS($close - $open) / ($high - $low + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 10)) * (($volume / ($high - $low + 1e-8)) / (ABS($close - $open) / ($high - $low + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Absorption_Strength\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor normalizes the absorption signal across the market. It calculates the density of volume relative to the price range and divides it by the relative candle body size, then scales this by the cross-sectional rank of the 10-day price momentum to find the strongest accumulation in the most stable trends.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Inertial Compression-Absorption' factor, defined as the product of the 10-day price trend R-squared and the ratio of 5-day average volume-to-range density to the 5-day average body-to-range ratio, identifies high-conviction institutional accumulation phases that precede trend-following breakouts.\n                Concise Observation: Parent 1 successfully used price body ratios to find exhaustion, while Parent 2 used volume-to-range squared to find stealth liquidity; however, both lacked a filter for trend stability, often leading to false signals in mean-reverting or chaotic regimes.\n                Concise Justification: High volume within narrow price bands suggests institutional absorption (liquidity drain), and when this occurs alongside a high R-squared (trend stability) and small price bodies (indecision), it indicates a temporary pause for accumulation before the next leg of the trend.\n                Concise Knowledge: If a market exhibits high structural persistence (R-squared) while volume is concentrated in narrow price ranges (high volume/range) and price bodies are small relative to total range (low body/range), then the resulting 'compressed absorption' signals a high-probability continuation of the existing trend.\n                concise Specification: The factor is calculated as (10-day R-squared of $close) * (SMA(Volume / (High - Low + epsilon), 5) / SMA(abs(Close - Open) / (High - Low + epsilon), 5)), where epsilon is a small constant to prevent division by zero.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d6415d4aa6f7",
      "parent_trajectory_ids": [
        "00a6075cc504",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0026012431262506,
        "ICIR": 0.0192586554014756,
        "RankIC": 0.0179616309709079,
        "RankICIR": 0.1329784901916024,
        "annualized_return": 0.0073720711364907,
        "information_ratio": 0.1072068122868142,
        "max_drawdown": -0.1169963401656844
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:01:17.306832",
      "updated_at": "2026-01-17T05:01:17.306838"
    },
    "a4c66b2dd186bd3f": {
      "factor_id": "a4c66b2dd186bd3f",
      "factor_name": "Informed_Flow_Persistence_5D",
      "factor_expression": "TS_ZSCORE(SKEW($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SKEW(TS_PCTCHANGE($close, 1), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Flow_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend continuation by measuring the ratio of 5-day return skewness to the 5-day standard deviation of the overnight gap. High positive values suggest 'quiet' institutional accumulation characterized by smooth, positively skewed intraday discovery with minimal overnight volatility shocks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.654977",
      "updated_at": "2026-01-17T05:02:29.654984"
    },
    "54a8292e9cd61523": {
      "factor_id": "54a8292e9cd61523",
      "factor_name": "Smooth_Discovery_Ratio_5D",
      "factor_expression": "TS_MEAN(ABS($return), 5) / (TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)), 5) / (TS_STD(($open / DELAY($close, 1)) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smooth_Discovery_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of price trends by comparing the magnitude of daily returns to the volatility of overnight gaps. It targets regimes where price discovery is 'smooth' and driven by continuous intraday flow rather than discrete overnight jumps.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.679452",
      "updated_at": "2026-01-17T05:02:29.679458"
    },
    "835a287e74598f97": {
      "factor_id": "835a287e74598f97",
      "factor_name": "Intraday_Skew_Gap_Stability_5D",
      "factor_expression": "RANK(SKEW($return)) - RANK(TS_STD(($open / (DELAY($close, 1) + 1e-8)) - 1, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SKEW(($close - $open) / $open, 5)) - RANK(TS_STD(($open / DELAY($close, 1)) - 1, 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Skew_Gap_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked factor that rewards stocks with high intraday return skewness relative to their overnight gap risk. This aligns with the hypothesis that institutional accumulation creates positive skewness without triggering high-volatility gap events.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Informed Flow Persistence' factor identifies trend continuation by measuring the ratio of intraday return skewness to overnight gap volatility over a 5-day window, capturing 'quiet' institutional accumulation.\n                Concise Observation: Previous 'Liquidity-Exhaustion' strategies focused on high-stress mean-reversion (IC 0.0095), but often failed in low-volatility trending regimes where price-volume decoupling does not occur.\n                Concise Justification: Institutional investors often split orders to minimize market impact (intraday skew), whereas retail-driven 'shocks' often manifest as large overnight gaps or symmetric high-volatility spikes.\n                Concise Knowledge: If intraday price discovery exhibits positive skewness while overnight volatility remains low, it indicates informed buying; when price moves are 'smooth' (high intraday-to-overnight volatility ratio), the trend is more likely to persist than mean-revert.\n                concise Specification: The factor is defined as the 5-day skewness of daily returns (intraday proxy) divided by the 5-day standard deviation of the gap (Open/PrevClose - 1), targeting a multi-day momentum horizon orthogonal to reversal signals.\n                ",
      "initial_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Volatility-adjusted momentum transition: Replace ROC60 with a risk-adjusted return metric (ROC60/Std20) to see if stable long-term trends interact differently with short-term volume spikes (VSTD5).",
      "evolution_phase": "mutation",
      "trajectory_id": "727ecdcd9309",
      "parent_trajectory_ids": [
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0047416731906741,
        "ICIR": 0.0339612732608561,
        "RankIC": 0.0221188540341502,
        "RankICIR": 0.1630943825120815,
        "annualized_return": 0.0643871826216965,
        "information_ratio": 0.9790085286900424,
        "max_drawdown": -0.1059163916856372
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:02:29.703585",
      "updated_at": "2026-01-17T05:02:29.703590"
    },
    "05a42dacbddf8ae7": {
      "factor_id": "05a42dacbddf8ae7",
      "factor_name": "Inst_Trend_Integrity_20D",
      "factor_expression": "TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / (POW($high - $low, 2) + 1e-8), 20) / (TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Integrity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining volume density (volume relative to price range) with trend stability. High volume density suggests liquidity absorption within narrow price bands, while low volatility in the R-squared of price regression indicates a consistent, non-erratic trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Trend Integrity' factor, defined as the 20-day rolling average of the (Volume / (High - Low + epsilon)^2) ratio scaled by the inverse of the 20-day standard deviation of the 10-day price regression R-squared, predicts superior forward returns by identifying stable institutional accumulation.\n                Concise Observation: Parent 1 showed that trend fragility (R-squared volatility) captures regime shifts (RankIC 0.0216), while Parent 2 demonstrated that volume-to-price-range ratios identify institutional footprints (RankIC 0.0303), suggesting a synergistic link between volume density and trend consistency.\n                Concise Justification: Institutional investors often execute large orders within narrow price bands to minimize impact, creating high volume density; when this behavior is paired with a stable, non-erratic linear trend, it signals a high-conviction regime shift that the market has yet to fully price in.\n                Concise Knowledge: If high volume density (liquidity absorption) coincides with low volatility in trend goodness-of-fit (trend stability), then the underlying price movement is likely driven by institutional accumulation rather than retail noise; such moves are more persistent and less prone to immediate reversal.\n                concise Specification: Calculate the daily ratio of volume to the square of the daily range; compute its 20-day mean; calculate the 20-day standard deviation of the R-squared from a 10-day linear regression of close prices; the final factor is the ratio of the 20-day mean volume density to the 20-day R-squared volatility.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2406a677c638",
      "parent_trajectory_ids": [
        "fe2976b173a7",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048202276785119,
        "ICIR": 0.0360916624363226,
        "RankIC": 0.0218515919024348,
        "RankICIR": 0.1686860189406379,
        "annualized_return": 0.0474429812813558,
        "information_ratio": 0.810910955831541,
        "max_drawdown": -0.1034097001433274
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:13:50.502117",
      "updated_at": "2026-01-17T05:13:50.502124"
    },
    "ed5f14f9b9ce3e5d": {
      "factor_id": "ed5f14f9b9ce3e5d",
      "factor_name": "Vol_Density_Stability_Ratio",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 20)) / (RANK(TS_STD($return, 20)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 20)) / (RANK(TS_STD(TS_PCTCHANGE($close, 1), 20)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Density_Stability_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the institutional footprint factor, focusing on the ratio between the 20-day average volume density and the 20-day standard deviation of price returns, normalized cross-sectionally to identify stocks with high-conviction liquidity absorption and low price volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Trend Integrity' factor, defined as the 20-day rolling average of the (Volume / (High - Low + epsilon)^2) ratio scaled by the inverse of the 20-day standard deviation of the 10-day price regression R-squared, predicts superior forward returns by identifying stable institutional accumulation.\n                Concise Observation: Parent 1 showed that trend fragility (R-squared volatility) captures regime shifts (RankIC 0.0216), while Parent 2 demonstrated that volume-to-price-range ratios identify institutional footprints (RankIC 0.0303), suggesting a synergistic link between volume density and trend consistency.\n                Concise Justification: Institutional investors often execute large orders within narrow price bands to minimize impact, creating high volume density; when this behavior is paired with a stable, non-erratic linear trend, it signals a high-conviction regime shift that the market has yet to fully price in.\n                Concise Knowledge: If high volume density (liquidity absorption) coincides with low volatility in trend goodness-of-fit (trend stability), then the underlying price movement is likely driven by institutional accumulation rather than retail noise; such moves are more persistent and less prone to immediate reversal.\n                concise Specification: Calculate the daily ratio of volume to the square of the daily range; compute its 20-day mean; calculate the 20-day standard deviation of the R-squared from a 10-day linear regression of close prices; the final factor is the ratio of the 20-day mean volume density to the 20-day R-squared volatility.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2406a677c638",
      "parent_trajectory_ids": [
        "fe2976b173a7",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048202276785119,
        "ICIR": 0.0360916624363226,
        "RankIC": 0.0218515919024348,
        "RankICIR": 0.1686860189406379,
        "annualized_return": 0.0474429812813558,
        "information_ratio": 0.810910955831541,
        "max_drawdown": -0.1034097001433274
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:13:50.526854",
      "updated_at": "2026-01-17T05:13:50.526860"
    },
    "892928c119672f0a": {
      "factor_id": "892928c119672f0a",
      "factor_name": "Trend_Efficiency_Volume_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN($volume / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN($volume / ($high - $low + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Trend_Efficiency_Volume_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price movement relative to volume. It uses the 10-day price regression R-squared as a proxy for trend integrity and scales it by the 20-day moving average of volume density, rewarding stocks with high volume absorption and linear price paths.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Trend Integrity' factor, defined as the 20-day rolling average of the (Volume / (High - Low + epsilon)^2) ratio scaled by the inverse of the 20-day standard deviation of the 10-day price regression R-squared, predicts superior forward returns by identifying stable institutional accumulation.\n                Concise Observation: Parent 1 showed that trend fragility (R-squared volatility) captures regime shifts (RankIC 0.0216), while Parent 2 demonstrated that volume-to-price-range ratios identify institutional footprints (RankIC 0.0303), suggesting a synergistic link between volume density and trend consistency.\n                Concise Justification: Institutional investors often execute large orders within narrow price bands to minimize impact, creating high volume density; when this behavior is paired with a stable, non-erratic linear trend, it signals a high-conviction regime shift that the market has yet to fully price in.\n                Concise Knowledge: If high volume density (liquidity absorption) coincides with low volatility in trend goodness-of-fit (trend stability), then the underlying price movement is likely driven by institutional accumulation rather than retail noise; such moves are more persistent and less prone to immediate reversal.\n                concise Specification: Calculate the daily ratio of volume to the square of the daily range; compute its 20-day mean; calculate the 20-day standard deviation of the R-squared from a 10-day linear regression of close prices; the final factor is the ratio of the 20-day mean volume density to the 20-day R-squared volatility.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2406a677c638",
      "parent_trajectory_ids": [
        "fe2976b173a7",
        "1d7506acce10"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048202276785119,
        "ICIR": 0.0360916624363226,
        "RankIC": 0.0218515919024348,
        "RankICIR": 0.1686860189406379,
        "annualized_return": 0.0474429812813558,
        "information_ratio": 0.810910955831541,
        "max_drawdown": -0.1034097001433274
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:13:50.551002",
      "updated_at": "2026-01-17T05:13:50.551008"
    },
    "242b9288cdf59fa0": {
      "factor_id": "242b9288cdf59fa0",
      "factor_name": "Gap_Intraday_Intensity_Reversal_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE(($high - $low) / (TS_MEAN(MAX($high, DELAY($close, 1)) - MIN($low, DELAY($close, 1)), 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE(($high - $low) / (TS_MEAN(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Gap_Intraday_Intensity_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion signals by multiplying the overnight gap with the 20-day Z-score of the intraday range normalized by ATR. High values indicate exhaustion after a gap-up, while low values indicate exhaustion after a gap-down.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Intensity-Adjusted Gap Reversal' factor, calculated as the product of the overnight price gap and the 20-day Z-score of the (High-Low)/ATR20 ratio, identifies high-conviction mean-reversion signals by isolating liquidity-driven exhaustion points.\n                Concise Observation: Parent 1 showed that normalized intraday intensity (Range/ATR) captures price exhaustion (RankIC 0.029), while Parent 2 demonstrated that overnight gaps coupled with volume dispersion signal reversals (RankIC 0.022); combining these filters out 'noisy' gaps that lack the volatility confirmation needed for high-conviction trades.\n                Concise Justification: By scaling the overnight gap by the relative intraday intensity, we weight the signal toward 'over-extended' states where the price has moved significantly beyond its typical volatility envelope, suggesting a higher likelihood of inventory-driven correction.\n                Concise Knowledge: If an overnight price gap occurs in conjunction with extreme intraday price range expansion relative to its historical ATR, the price movement is more likely driven by temporary liquidity imbalances rather than fundamental shifts; when volume volatility is also high, the probability of a mean-reversion reversal increases.\n                concise Specification: The factor is defined as: Gap * TS_ZScore((High - Low) / ATR(20), 20), where Gap is (Open - Prev_Close) / Prev_Close and ATR(20) is the 20-day Average True Range; a high positive value suggests a gap-up with extreme intensity (sell signal), and a low negative value suggests a gap-down with extreme intensity (buy signal).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67a65f59ba9a",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "ccbd1a1bc892"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074614630650547,
        "ICIR": 0.0552835729971314,
        "RankIC": 0.0252842146188579,
        "RankICIR": 0.1900184381652116,
        "annualized_return": 0.070876744457745,
        "information_ratio": 1.0589173674031032,
        "max_drawdown": -0.0948577377005152
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:17:13.624532",
      "updated_at": "2026-01-17T05:17:13.624539"
    },
    "17dc6ce14c0fa34f": {
      "factor_id": "17dc6ce14c0fa34f",
      "factor_name": "Liquidity_Exhaustion_Gap_Factor",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_RANK(($high - $low) / (TS_STD($close, 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_RANK(($high - $low) / (TS_STD($close, 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the intensity-adjusted gap reversal. It uses the cross-sectional rank of the overnight gap and the time-series rank of the intraday range relative to volume-weighted volatility to find high-conviction reversal points.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Intensity-Adjusted Gap Reversal' factor, calculated as the product of the overnight price gap and the 20-day Z-score of the (High-Low)/ATR20 ratio, identifies high-conviction mean-reversion signals by isolating liquidity-driven exhaustion points.\n                Concise Observation: Parent 1 showed that normalized intraday intensity (Range/ATR) captures price exhaustion (RankIC 0.029), while Parent 2 demonstrated that overnight gaps coupled with volume dispersion signal reversals (RankIC 0.022); combining these filters out 'noisy' gaps that lack the volatility confirmation needed for high-conviction trades.\n                Concise Justification: By scaling the overnight gap by the relative intraday intensity, we weight the signal toward 'over-extended' states where the price has moved significantly beyond its typical volatility envelope, suggesting a higher likelihood of inventory-driven correction.\n                Concise Knowledge: If an overnight price gap occurs in conjunction with extreme intraday price range expansion relative to its historical ATR, the price movement is more likely driven by temporary liquidity imbalances rather than fundamental shifts; when volume volatility is also high, the probability of a mean-reversion reversal increases.\n                concise Specification: The factor is defined as: Gap * TS_ZScore((High - Low) / ATR(20), 20), where Gap is (Open - Prev_Close) / Prev_Close and ATR(20) is the 20-day Average True Range; a high positive value suggests a gap-up with extreme intensity (sell signal), and a low negative value suggests a gap-down with extreme intensity (buy signal).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67a65f59ba9a",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "ccbd1a1bc892"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074614630650547,
        "ICIR": 0.0552835729971314,
        "RankIC": 0.0252842146188579,
        "RankICIR": 0.1900184381652116,
        "annualized_return": 0.070876744457745,
        "information_ratio": 1.0589173674031032,
        "max_drawdown": -0.0948577377005152
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:17:13.649487",
      "updated_at": "2026-01-17T05:17:13.649493"
    },
    "c8fca406cf44ce2a": {
      "factor_id": "c8fca406cf44ce2a",
      "factor_name": "Volatility_Confirmed_Gap_Reversal",
      "factor_expression": "ZSCORE((($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * (($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Confirmed_Gap_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price exhaustion by checking if the overnight gap is accompanied by an extreme intraday range relative to its 10-day historical mean, then applying a cross-sectional Z-score for comparability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Intensity-Adjusted Gap Reversal' factor, calculated as the product of the overnight price gap and the 20-day Z-score of the (High-Low)/ATR20 ratio, identifies high-conviction mean-reversion signals by isolating liquidity-driven exhaustion points.\n                Concise Observation: Parent 1 showed that normalized intraday intensity (Range/ATR) captures price exhaustion (RankIC 0.029), while Parent 2 demonstrated that overnight gaps coupled with volume dispersion signal reversals (RankIC 0.022); combining these filters out 'noisy' gaps that lack the volatility confirmation needed for high-conviction trades.\n                Concise Justification: By scaling the overnight gap by the relative intraday intensity, we weight the signal toward 'over-extended' states where the price has moved significantly beyond its typical volatility envelope, suggesting a higher likelihood of inventory-driven correction.\n                Concise Knowledge: If an overnight price gap occurs in conjunction with extreme intraday price range expansion relative to its historical ATR, the price movement is more likely driven by temporary liquidity imbalances rather than fundamental shifts; when volume volatility is also high, the probability of a mean-reversion reversal increases.\n                concise Specification: The factor is defined as: Gap * TS_ZScore((High - Low) / ATR(20), 20), where Gap is (Open - Prev_Close) / Prev_Close and ATR(20) is the 20-day Average True Range; a high positive value suggests a gap-up with extreme intensity (sell signal), and a low negative value suggests a gap-down with extreme intensity (buy signal).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67a65f59ba9a",
      "parent_trajectory_ids": [
        "493f083fc9f4",
        "ccbd1a1bc892"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0074614630650547,
        "ICIR": 0.0552835729971314,
        "RankIC": 0.0252842146188579,
        "RankICIR": 0.1900184381652116,
        "annualized_return": 0.070876744457745,
        "information_ratio": 1.0589173674031032,
        "max_drawdown": -0.0948577377005152
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:17:13.674106",
      "updated_at": "2026-01-17T05:17:13.674112"
    },
    "4c772ab65d1c8aef": {
      "factor_id": "4c772ab65d1c8aef",
      "factor_name": "LGGRF_Gap_Intensity_10D",
      "factor_expression": "TS_ZSCORE(ABS($open - DELAY($close, 1)), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($open - DELAY($close, 1)), 10) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"LGGRF_Gap_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Gated Gap Reversion Factor (LGGRF) identifies potential mean reversion by combining overnight price shocks with intraday price expansion on low volume. It calculates the product of the 10-day time-series Z-score of the overnight gap and the 10-day time-series Z-score of intraday intensity (range divided by volume). High values suggest the price movement is overextended and lacks institutional liquidity support.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Gated Gap Reversion Factor (LGGRF) predicts short-term price reversals by identifying large overnight price gaps that are subsequently accompanied by intraday price expansion on declining volume intensity, signaling a lack of institutional support for the gap's direction.\n                Concise Observation: Parent 1 showed that overnight gaps (RankIC 0.0245) have mean-reversion potential, while Parent 2 showed that intraday price extremes on low volume (RankIC 0.0269) signal exhaustion; combining them addresses the weakness of trading gaps that are actually supported by strong intraday flow.\n                Concise Justification: Overnight gaps represent information shocks, but their sustainability depends on intraday follow-through; a 'liquidity trap' occurs when price continues to move in the gap direction but volume fades, suggesting the initial shock has overextended beyond the market's current clearing capacity.\n                Concise Knowledge: If an overnight price gap is followed by intraday price extremes reached with lower-than-average volume, the price movement is likely exhaustive; when high overnight volatility meets low intraday liquidity, mean reversion is more probable than trend continuation.\n                concise Specification: Define Gap as abs(Open - Close[1]); define Intraday Intensity as (High - Low) / Volume; the factor is the product of the 10-day Z-score of the Gap and the 10-day Z-score of the Intraday Intensity, where a high value indicates a volatile gap followed by exhaustive intraday price action.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "61b88053c4c0",
      "parent_trajectory_ids": [
        "5482374782e1",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043323998793942,
        "ICIR": 0.0323540901856198,
        "RankIC": 0.0212825093775084,
        "RankICIR": 0.1617653671916123,
        "annualized_return": 0.0502685120758134,
        "information_ratio": 0.8333518050177452,
        "max_drawdown": -0.074595041048191
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:20:12.919859",
      "updated_at": "2026-01-17T05:20:12.919865"
    },
    "80430b43effd83e0": {
      "factor_id": "80430b43effd83e0",
      "factor_name": "Liquidity_Trap_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE(ABS($open - DELAY($close, 1)), 20)) + RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(ABS($open - DELAY($close, 1)), 20)) + RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Trap_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'liquidity traps' where overnight gaps are followed by low-volume intraday price ranges. It uses a 20-day window to normalize the gap and intensity, then applies a cross-sectional rank to identify stocks with the most exhaustive price action relative to their peers. High ranks indicate a higher probability of short-term reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Gated Gap Reversion Factor (LGGRF) predicts short-term price reversals by identifying large overnight price gaps that are subsequently accompanied by intraday price expansion on declining volume intensity, signaling a lack of institutional support for the gap's direction.\n                Concise Observation: Parent 1 showed that overnight gaps (RankIC 0.0245) have mean-reversion potential, while Parent 2 showed that intraday price extremes on low volume (RankIC 0.0269) signal exhaustion; combining them addresses the weakness of trading gaps that are actually supported by strong intraday flow.\n                Concise Justification: Overnight gaps represent information shocks, but their sustainability depends on intraday follow-through; a 'liquidity trap' occurs when price continues to move in the gap direction but volume fades, suggesting the initial shock has overextended beyond the market's current clearing capacity.\n                Concise Knowledge: If an overnight price gap is followed by intraday price extremes reached with lower-than-average volume, the price movement is likely exhaustive; when high overnight volatility meets low intraday liquidity, mean reversion is more probable than trend continuation.\n                concise Specification: Define Gap as abs(Open - Close[1]); define Intraday Intensity as (High - Low) / Volume; the factor is the product of the 10-day Z-score of the Gap and the 10-day Z-score of the Intraday Intensity, where a high value indicates a volatile gap followed by exhaustive intraday price action.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "61b88053c4c0",
      "parent_trajectory_ids": [
        "5482374782e1",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043323998793942,
        "ICIR": 0.0323540901856198,
        "RankIC": 0.0212825093775084,
        "RankICIR": 0.1617653671916123,
        "annualized_return": 0.0502685120758134,
        "information_ratio": 0.8333518050177452,
        "max_drawdown": -0.074595041048191
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:20:12.944776",
      "updated_at": "2026-01-17T05:20:12.944781"
    },
    "c93af09889ffcd5b": {
      "factor_id": "c93af09889ffcd5b",
      "factor_name": "Exhaustive_Gap_Index_5D",
      "factor_expression": "TS_MEAN((ABS($open - DELAY($close, 1)) * ($high - $low)) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((ABS($open - DELAY($close, 1)) * ($high - $low)) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Exhaustive_Gap_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A shorter-term version of the liquidity-gated gap factor focusing on a 5-day window. It identifies extreme exhaustion by multiplying the normalized overnight gap by the ratio of intraday range to volume, smoothed over 5 days to capture immediate mean-reversion signals.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Gated Gap Reversion Factor (LGGRF) predicts short-term price reversals by identifying large overnight price gaps that are subsequently accompanied by intraday price expansion on declining volume intensity, signaling a lack of institutional support for the gap's direction.\n                Concise Observation: Parent 1 showed that overnight gaps (RankIC 0.0245) have mean-reversion potential, while Parent 2 showed that intraday price extremes on low volume (RankIC 0.0269) signal exhaustion; combining them addresses the weakness of trading gaps that are actually supported by strong intraday flow.\n                Concise Justification: Overnight gaps represent information shocks, but their sustainability depends on intraday follow-through; a 'liquidity trap' occurs when price continues to move in the gap direction but volume fades, suggesting the initial shock has overextended beyond the market's current clearing capacity.\n                Concise Knowledge: If an overnight price gap is followed by intraday price extremes reached with lower-than-average volume, the price movement is likely exhaustive; when high overnight volatility meets low intraday liquidity, mean reversion is more probable than trend continuation.\n                concise Specification: Define Gap as abs(Open - Close[1]); define Intraday Intensity as (High - Low) / Volume; the factor is the product of the 10-day Z-score of the Gap and the 10-day Z-score of the Intraday Intensity, where a high value indicates a volatile gap followed by exhaustive intraday price action.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "61b88053c4c0",
      "parent_trajectory_ids": [
        "5482374782e1",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043323998793942,
        "ICIR": 0.0323540901856198,
        "RankIC": 0.0212825093775084,
        "RankICIR": 0.1617653671916123,
        "annualized_return": 0.0502685120758134,
        "information_ratio": 0.8333518050177452,
        "max_drawdown": -0.074595041048191
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:20:12.972425",
      "updated_at": "2026-01-17T05:20:12.972431"
    },
    "25427044e1ce974e": {
      "factor_id": "25427044e1ce974e",
      "factor_name": "SEMS_Linearity_Exhaustion_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"SEMS_Linearity_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential price reversals by multiplying the trend linearity (R-squared of price over 10 days) with the 5-day average of liquidity exhaustion (price range per unit of volume). High values suggest a strong trend is losing institutional backing and becoming 'thin'.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Multi-Scale (SEMS) factor identifies price reversals by multiplying the 10-day price trend linearity (RSQR) with the 5-day average ratio of price range to volume intensity, capturing the convergence of macro-trend maturity and micro-liquidity collapse.\n                Concise Observation: Parent 1 (RSQR10) captures medium-term trend persistence (RankIC 0.0243), while Parent 2 (ILEF) captures short-term liquidity traps (RankIC 0.0270); combining them addresses the weakness of entering reversals too early in strong linear trends.\n                Concise Justification: Linear trends (high RSQR) are sustainable only if supported by efficient liquidity; a rising price-to-volume ratio (range/volume) at the end of such a trend indicates 'thin' trading and a liquidity void, signaling an imminent structural breakdown.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but is accompanied by a decreasing ratio of price movement per unit of volume, then the trend is likely driven by retail exhaustion rather than institutional conviction; when these multi-scale signals align, the probability of mean reversion increases.\n                concise Specification: Calculate RSQR of close prices over 10 days; calculate the daily Liquidity Intensity as (High - Low) / Volume; compute the 5-day moving average of this intensity; the final factor is the product of RSQR and the 5-day intensity average, targeting assets with high linearity and high liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a34c9bb86b45",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038162505599264,
        "ICIR": 0.0278069908189633,
        "RankIC": 0.0196482391902487,
        "RankICIR": 0.1453964088361926,
        "annualized_return": 0.0303750622438065,
        "information_ratio": 0.4422539176493897,
        "max_drawdown": -0.101040702168971
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:34:45.766346",
      "updated_at": "2026-01-17T05:34:45.766352"
    },
    "58eb807b84a6278a": {
      "factor_id": "58eb807b84a6278a",
      "factor_name": "SEMS_Ranked_Reversal_Signal",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"SEMS_Ranked_Reversal_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the Structural Exhaustion Multi-Scale factor. It combines the 10-day price trend linearity with the short-term liquidity intensity, applying RANK to both components to ensure scale-invariance across different assets.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Multi-Scale (SEMS) factor identifies price reversals by multiplying the 10-day price trend linearity (RSQR) with the 5-day average ratio of price range to volume intensity, capturing the convergence of macro-trend maturity and micro-liquidity collapse.\n                Concise Observation: Parent 1 (RSQR10) captures medium-term trend persistence (RankIC 0.0243), while Parent 2 (ILEF) captures short-term liquidity traps (RankIC 0.0270); combining them addresses the weakness of entering reversals too early in strong linear trends.\n                Concise Justification: Linear trends (high RSQR) are sustainable only if supported by efficient liquidity; a rising price-to-volume ratio (range/volume) at the end of such a trend indicates 'thin' trading and a liquidity void, signaling an imminent structural breakdown.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but is accompanied by a decreasing ratio of price movement per unit of volume, then the trend is likely driven by retail exhaustion rather than institutional conviction; when these multi-scale signals align, the probability of mean reversion increases.\n                concise Specification: Calculate RSQR of close prices over 10 days; calculate the daily Liquidity Intensity as (High - Low) / Volume; compute the 5-day moving average of this intensity; the final factor is the product of RSQR and the 5-day intensity average, targeting assets with high linearity and high liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a34c9bb86b45",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038162505599264,
        "ICIR": 0.0278069908189633,
        "RankIC": 0.0196482391902487,
        "RankICIR": 0.1453964088361926,
        "annualized_return": 0.0303750622438065,
        "information_ratio": 0.4422539176493897,
        "max_drawdown": -0.101040702168971
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:34:45.791633",
      "updated_at": "2026-01-17T05:34:45.791639"
    },
    "cda1b49df004b2e6": {
      "factor_id": "cda1b49df004b2e6",
      "factor_name": "SEMS_Zscore_Exhaustion_15D",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(15), 15), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(15), 15), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5), 20)\" # Your output factor expression will be filled in here\n    name = \"SEMS_Zscore_Exhaustion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This variation uses a 15-day window for trend linearity and a 5-day window for liquidity exhaustion, standardized using TS_ZSCORE to identify extreme exhaustion events relative to the asset's own history before a reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Multi-Scale (SEMS) factor identifies price reversals by multiplying the 10-day price trend linearity (RSQR) with the 5-day average ratio of price range to volume intensity, capturing the convergence of macro-trend maturity and micro-liquidity collapse.\n                Concise Observation: Parent 1 (RSQR10) captures medium-term trend persistence (RankIC 0.0243), while Parent 2 (ILEF) captures short-term liquidity traps (RankIC 0.0270); combining them addresses the weakness of entering reversals too early in strong linear trends.\n                Concise Justification: Linear trends (high RSQR) are sustainable only if supported by efficient liquidity; a rising price-to-volume ratio (range/volume) at the end of such a trend indicates 'thin' trading and a liquidity void, signaling an imminent structural breakdown.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but is accompanied by a decreasing ratio of price movement per unit of volume, then the trend is likely driven by retail exhaustion rather than institutional conviction; when these multi-scale signals align, the probability of mean reversion increases.\n                concise Specification: Calculate RSQR of close prices over 10 days; calculate the daily Liquidity Intensity as (High - Low) / Volume; compute the 5-day moving average of this intensity; the final factor is the product of RSQR and the 5-day intensity average, targeting assets with high linearity and high liquidity exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "a34c9bb86b45",
      "parent_trajectory_ids": [
        "3cb6ea9034b4",
        "3806921571eb"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0038162505599264,
        "ICIR": 0.0278069908189633,
        "RankIC": 0.0196482391902487,
        "RankICIR": 0.1453964088361926,
        "annualized_return": 0.0303750622438065,
        "information_ratio": 0.4422539176493897,
        "max_drawdown": -0.101040702168971
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:34:45.816466",
      "updated_at": "2026-01-17T05:34:45.816471"
    },
    "411d946cbcb95d0b": {
      "factor_id": "411d946cbcb95d0b",
      "factor_name": "Institutional_Commitment_Persistence_Ratio_20D",
      "factor_expression": "RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Commitment_Persistence_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable trends by calculating the ratio of the Coefficient of Variation (CV) of the price range to the CV of volume over a 20-day window. A lower ratio indicates that volume is more stable relative to price volatility, suggesting 'quiet' institutional accumulation. CV is calculated as the standard deviation divided by the mean.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.092594",
      "updated_at": "2026-01-17T05:49:14.092601"
    },
    "d256ede617306ae6": {
      "factor_id": "d256ede617306ae6",
      "factor_name": "Institutional_Accumulation_Stability_20D",
      "factor_expression": "TS_ZSCORE(TS_STD($volume, 20), 20) + TS_ZSCORE(TS_STD(ABS($close - $open), 20), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the stability of institutional commitment by comparing the rolling 20-day volatility of volume against the rolling 20-day volatility of intraday returns. It targets periods where price movement is orderly (low range volatility) and volume is consistent, which is characteristic of algorithmic execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.117822",
      "updated_at": "2026-01-17T05:49:14.117828"
    },
    "b15a9e66a9933ad3": {
      "factor_id": "b15a9e66a9933ad3",
      "factor_name": "Volume_Consistency_Trend_Filter_20D",
      "factor_expression": "((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAD($volume, 20) / (TS_MEDIAN($volume, 20) + 1e-8)) / ((TS_MAD($high - $low, 20) / (TS_MEDIAN($high - $low, 20) + 1e-8)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Consistency_Trend_Filter_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the persistence of institutional activity by measuring the inverse of volume dispersion relative to price range dispersion. It uses the ratio of 20-day Mean Absolute Deviation (MAD) of volume to the 20-day range to filter out speculative spikes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Commitment Persistence (ICP) factor, defined as the ratio of volume stability to price range stability over a 20-day window, identifies sustainable trends driven by steady institutional accumulation rather than speculative shocks.\n                Concise Observation: While short-term price-volume shocks (VVDE) predict mean reversion, medium-term stability in volume often precedes persistent trend continuation, suggesting that 'quiet' accumulation is a distinct alpha source from 'hollow' expansions.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to steady volume profiles and compressed volatility; this 'consistency' acts as a lead indicator for trend quality.\n                Concise Knowledge: If a price trend is accompanied by low-variance volume growth and decreasing intraday volatility, it indicates institutional accumulation; when volume becomes highly volatile or price ranges expand rapidly, the trend is likely nearing exhaustion.\n                concise Specification: The factor will be calculated as the Coefficient of Variation (CV) of the 20-day price range divided by the CV of the 20-day volume, where lower values of the resulting ratio (after ranking) signify higher institutional persistence.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "0fd13bc799fd",
      "parent_trajectory_ids": [
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055593529897595,
        "ICIR": 0.041629141769247,
        "RankIC": 0.0222452937839841,
        "RankICIR": 0.1696298296435427,
        "annualized_return": 0.0558620301876618,
        "information_ratio": 0.8394558690722355,
        "max_drawdown": -0.0847799387165127
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T05:49:14.142727",
      "updated_at": "2026-01-17T05:49:14.142732"
    },
    "f31d8c4ef20d75c6": {
      "factor_id": "f31d8c4ef20d75c6",
      "factor_name": "Linear_Trend_Decay_ZScore",
      "factor_expression": "TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Decay_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the trend fragility concept that focuses on the standardized deviation of trend linearity. It uses the Z-score of the 10-day R-squared over a 20-day period to detect extreme departures from the recent trend stability regime, helping to identify points where the 'quality' of the price movement is breaking down.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.834190",
      "updated_at": "2026-01-17T06:03:35.834196"
    },
    "373b3a86b027bfcc": {
      "factor_id": "373b3a86b027bfcc",
      "factor_name": "Relative_Trend_Instability",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) / (TS_MEAN(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Trend_Instability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the instability of price trends by comparing the current trend's R-squared to its 20-day moving average, normalized by its volatility. It captures the 'fragility' of the trend by highlighting periods where the goodness-of-fit of the linear price-time relationship is significantly more volatile than its recent history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Fragility' index, measured by the 20-day rolling standard deviation of the R-squared from a 10-day price-time linear regression, identifies imminent regime shifts where high volatility in trend linearity signals a transition from stable momentum to chaotic price action.\n                Concise Observation: While simple momentum factors capture the direction of price movement, they often fail to account for the 'quality' or 'stability' of that movement, leading to significant drawdowns during sudden regime shifts where previously linear trends become erratic.\n                Concise Justification: A stable trend is characterized by a consistently high R-squared in a price-time regression; therefore, the standard deviation of this R-squared (Trend Fragility) serves as a second-order indicator of structural market change, capturing the decay of trend persistence before it is reflected in price returns.\n                Concise Knowledge: If a price trend's goodness-of-fit (R-squared) exhibits high variance over time, the underlying market regime is becoming unstable; when trend linearity fluctuates significantly, the probability of a trend reversal or a transition into a non-directional high-volatility state increases.\n                concise Specification: Calculate the R-squared of $close against a time index {1...10} over a 10-day rolling window (RSQR10), then compute the 20-day rolling standard deviation of these RSQR10 values to define the 'Trend Fragility' factor.\n                ",
      "initial_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Develop a 'Trend Fragility' index by calculating the rolling 20-day standard deviation of RSQR10 to detect shifts from stable trends to chaotic regimes.",
      "evolution_phase": "mutation",
      "trajectory_id": "88298f0c18af",
      "parent_trajectory_ids": [
        "1e7770199dd1"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050478946185362,
        "ICIR": 0.0380737559228687,
        "RankIC": 0.0215498818029696,
        "RankICIR": 0.1662806223069315,
        "annualized_return": 0.0867791270859219,
        "information_ratio": 1.395062368534296,
        "max_drawdown": -0.0680354159216622
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:03:35.859234",
      "updated_at": "2026-01-17T06:03:35.859239"
    },
    "1be142da9be01930": {
      "factor_id": "1be142da9be01930",
      "factor_name": "Overnight_Informed_Gap_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Informed_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies informed price discovery by multiplying the overnight return (gap) with the relative trading volume of the current day. High volume during the gap's subsequent session suggests institutional validation of the price shock, while low volume suggests retail noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.778853",
      "updated_at": "2026-01-17T06:06:12.778860"
    },
    "5f27b35f17420f9d": {
      "factor_id": "5f27b35f17420f9d",
      "factor_name": "ZScore_Overnight_Volume_Shock",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_ZSCORE($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Volume_Shock\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the overnight sentiment gap that uses Z-score normalization for the volume component and cross-sectional ranking for the gap, ensuring the factor is robust to different market regimes and stock scales.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.804532",
      "updated_at": "2026-01-17T06:06:12.804538"
    },
    "a38885cb88142b61": {
      "factor_id": "a38885cb88142b61",
      "factor_name": "Informed_Gap_Momentum_Filter",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ($volume / (TS_MEDIAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Informed_Gap_Momentum_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the overnight gap by applying a sign-based volume weight. It captures the conviction of the overnight move by scaling the gap magnitude by the 5-day relative volume, specifically focusing on cases where volume exceeds the recent median to filter out low-conviction noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment-Informed Gap' factor, calculated as the product of the overnight return and the ratio of daily volume to the 10-day average volume, predicts short-term momentum by distinguishing informed overnight price discovery from retail noise.\n                Concise Observation: The parent strategy focused on long-term trend exhaustion via price-volume density, but failed to account for the discrete information shocks captured in overnight price jumps which often serve as catalysts for new trends rather than ends of old ones.\n                Concise Justification: Overnight returns represent the market's reaction to non-trading hour information; by weighting this 'gap' by the current day's relative volume, we identify 'informed' gaps that have the liquidity support to sustain a directional move.\n                Concise Knowledge: If a significant overnight price gap occurs with high relative volume during the subsequent trading day, it indicates institutional validation of the new price level; when gaps occur on low volume, they are more likely to be mean-reverting retail noise.\n                concise Specification: The factor is defined as (Open / Ref(Close, 1) - 1) * (Volume / TS_MEAN(Volume, 10)). It expects a positive correlation with next-day returns when the gap and volume are high, focusing on the first-day reaction to information shocks.\n                ",
      "initial_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Decompose KLEN into 'Gap-driven' vs 'Intraday-driven' components to test if volatility originating from overnight gaps has higher predictive power for next-day reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "db5df6d13abb",
      "parent_trajectory_ids": [
        "2752fa0c81e2"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055313815038277,
        "ICIR": 0.040934437930848,
        "RankIC": 0.0216332090996994,
        "RankICIR": 0.1646911368617207,
        "annualized_return": 0.0626845477064053,
        "information_ratio": 0.982016619737888,
        "max_drawdown": -0.091246382502045
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:06:12.831460",
      "updated_at": "2026-01-17T06:06:12.831466"
    },
    "97893b031c147033": {
      "factor_id": "97893b031c147033",
      "factor_name": "Intraday_VWAP_Midpoint_Deviation_5D",
      "factor_expression": "TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($open + $close + $high + $low) / 4 - ($high + $low) / 2) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_VWAP_Midpoint_Deviation_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the deviation of the approximated Volume-Weighted Average Price (VWAP) from the daily price midpoint, normalized by the daily range. A high deviation indicates that volume is concentrated at one extreme of the price range, suggesting liquidity exhaustion and potential mean-reversion. It is smoothed over a 5-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.432281",
      "updated_at": "2026-01-17T06:08:21.432288"
    },
    "298e0ab6776e2256": {
      "factor_id": "298e0ab6776e2256",
      "factor_name": "Hollow_Price_Extreme_Reversal_5D",
      "factor_expression": "TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Price_Extreme_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'hollow' price moves by calculating the distance between the daily close and the approximated VWAP relative to the daily range. If the close is far from where the volume was executed (VWAP), the price level is considered low-conviction. The factor uses a 5-day moving average to signal mean-reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.458630",
      "updated_at": "2026-01-17T06:08:21.458636"
    },
    "ad0df9d76562d7e7": {
      "factor_id": "ad0df9d76562d7e7",
      "factor_name": "Volume_Weighted_Position_ZScore_5D",
      "factor_expression": "ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN((($open + $close + $high + $low) / 4 - $low) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Position_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the position of the VWAP within the daily range using a cross-sectional Z-score to identify assets where price extremes are most disconnected from volume centers across the universe, targeting mean-reversion over a 5-day lookback.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Intraday Volume-Price Density factor, defined as the ratio of Volume-Weighted Average Price (VWAP) deviation from the daily midpoint to the total intraday range, predicts mean-reversion by identifying liquidity exhaustion where price is pushed to extremes by low-volume aggressive orders.\n                Concise Observation: While the parent strategy successfully captured overnight information shocks (RankIC 0.022), it ignored the intraday distribution of volume which often signals whether a price move is supported by broad participation or driven by temporary liquidity imbalances.\n                Concise Justification: Market microstructure theory suggests that price moves on thin volume at the edges of the daily range are often driven by temporary liquidity demand (noise) rather than fundamental information; identifying these 'hollow' price levels via volume-weighted positioning allows for capturing the subsequent reversal as market makers provide liquidity.\n                Concise Knowledge: If the volume-weighted average price (VWAP) significantly deviates from the simple arithmetic mean of the high-low range, it indicates that the majority of trading occurred at one extreme, suggesting potential liquidity exhaustion and a high probability of price mean-reversion; when volume is concentrated far from the price extreme, the extreme price is likely a 'low-conviction' liquidity gap.\n                concise Specification: The factor is calculated as (VWAP - (High + Low)/2) / (High - Low + 1e-8), where VWAP is approximated by (Open+Close+High+Low)/4 weighted by Volume, or simplified as the distance of the daily Close from the VWAP relative to the daily volatility, tested over a 5-day lookback for mean-reversion signals.\n                ",
      "initial_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Apply a non-linear transformation to WVMA5 using a regime-switching model (Hidden Markov Model) to distinguish between high-volatility accumulation and high-volatility distribution phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "4b3936ec40e7",
      "parent_trajectory_ids": [
        "f1db5bf19d27"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057747652033695,
        "ICIR": 0.0396958548760556,
        "RankIC": 0.0181608123599028,
        "RankICIR": 0.128431621730016,
        "annualized_return": 0.0796038071808874,
        "information_ratio": 1.1192406312685086,
        "max_drawdown": -0.1311148706988178
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:08:21.484297",
      "updated_at": "2026-01-17T06:08:21.484303"
    },
    "ed8a5a26050ad169": {
      "factor_id": "ed8a5a26050ad169",
      "factor_name": "Trend_Acceleration_Decay_5_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)\" # Your output factor expression will be filled in here\n    name = \"Trend_Acceleration_Decay_5_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between short-term and long-term price linearity. It calculates the difference between the 5-day R-squared and the 20-day R-squared of closing prices against time. A high value indicates a speculative blow-off where short-term linearity far exceeds long-term structural stability, while a low value suggests a breakdown of a previously stable trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.069444",
      "updated_at": "2026-01-17T06:38:46.069451"
    },
    "1d239eda75962a9c": {
      "factor_id": "1d239eda75962a9c",
      "factor_name": "ZScore_Trend_Linearity_Divergence",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Trend_Linearity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally standardized version of the trend acceleration decay. It identifies assets where the short-term (5-day) trend linearity is an outlier relative to its long-term (20-day) historical linearity, highlighting potential mean-reversion candidates in the broader market context.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.096980",
      "updated_at": "2026-01-17T06:38:46.096986"
    },
    "3469c1a0a46fd14e": {
      "factor_id": "3469c1a0a46fd14e",
      "factor_name": "Relative_Linearity_Efficiency_Ratio",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(5), 5), 2) - POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (POW(TS_CORR($close, SEQUENCE(20), 20), 2) + 0.01)\" # Your output factor expression will be filled in here\n    name = \"Relative_Linearity_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the efficiency of trend acceleration by scaling the linearity difference by the long-term linearity baseline. It highlights cases where a stable trend (high 20-day R-squared) is suddenly disrupted or exponentially accelerated, providing a normalized measure of structural decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Trend Acceleration Decay' factor, defined as the difference between the 5-day and 20-day price-time R-squared values, identifies late-stage trend exhaustion where short-term linear persistence significantly deviates from long-term structural stability.\n                Concise Observation: Previous factors focused on static 10-day or 12-day window linearity (R-squared), which captures trend strength but fails to identify the 'acceleration of the trend' or the point where short-term momentum becomes unsustainable relative to its historical baseline.\n                Concise Justification: Measuring the distance between short-term and long-term R-squared acts as a second-order derivative of price structure; a high positive spread suggests a 'speculative rush' (short-term linearity > long-term), while a negative spread suggests a structural breakdown of a previously stable trend.\n                Concise Knowledge: If short-term trend linearity (5-day R-squared) rapidly exceeds or collapses relative to long-term linearity (20-day R-squared), the asset is likely experiencing a terminal blow-off top or a breakdown, signaling an imminent mean reversion; When these two time-series metrics diverge, the 'information decay' of the trend is accelerating.\n                concise Specification: The factor is calculated as the 5-day R-squared of price against a time sequence minus the 20-day R-squared of price against a time sequence, where R-squared is the square of the Pearson correlation between close price and an ordinal time vector.\n                ",
      "initial_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Evaluate the decay rate of RSQR10 by measuring the time-series distance between 5-day and 20-day R-squared values to identify late-stage trend acceleration.",
      "evolution_phase": "mutation",
      "trajectory_id": "fa09e5c16f92",
      "parent_trajectory_ids": [
        "a672c9f588ce"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0060872093567875,
        "ICIR": 0.045360360435883,
        "RankIC": 0.0203699216784831,
        "RankICIR": 0.1546668410047381,
        "annualized_return": 0.0684960046402598,
        "information_ratio": 1.0253705455698687,
        "max_drawdown": -0.0984589328328349
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:38:46.122928",
      "updated_at": "2026-01-17T06:38:46.122933"
    },
    "f463f63909a625be": {
      "factor_id": "f463f63909a625be",
      "factor_name": "Intraday_Exhaustion_ATR_Normalized_20D",
      "factor_expression": "TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies overextended emotional positioning by calculating the 20-day average of the ratio between the daily high-low range and the absolute open-close body, normalized by the 20-day Average True Range (ATR). High values indicate failed price discovery and potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.738933",
      "updated_at": "2026-01-17T06:42:00.738939"
    },
    "99540186c19ce407": {
      "factor_id": "99540186c19ce407",
      "factor_name": "Shadow_to_Body_Efficiency_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Shadow_to_Body_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified measure of the 'hollow' price move hypothesis. It calculates the 20-day average of the ratio of the total intraday range to the price displacement (body), cross-sectionally ranked to identify stocks with the most extreme 'exhaustion' patterns relative to the market.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.765086",
      "updated_at": "2026-01-17T06:42:00.765091"
    },
    "f3aada6b8df9d2b5": {
      "factor_id": "f3aada6b8df9d2b5",
      "factor_name": "Relative_Intraday_Volatility_Skew_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (ABS($close - $open) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (MAX(ABS($close - $open), 0.001 * $close)), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Volatility_Skew_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between total intraday movement and net progress by comparing the current shadow-to-body ratio against its 10-day historical standard deviation, identifying statistical instability in price discovery.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Asymmetry Exhaustion' factor, calculated as the 20-day average of the ratio between daily price range and the absolute difference of open-to-close (normalized by ATR), identifies overextended emotional positioning that predicts short-term mean reversion.\n                Concise Observation: The parent strategy focused on volume-driven absorption and trend persistence (R-squared), but it failed to capture the statistical instability of 'hollow' price moves where high volatility occurs without significant net price displacement.\n                Concise Justification: Extreme intraday skewness and large 'shadows' relative to the 'body' of a candle represent failed price discovery and emotional exhaustion, suggesting that the current price level is unsustainable and likely to revert as liquidity providers re-anchor the price.\n                Concise Knowledge: If the daily price range significantly exceeds the daily price body (open-to-close) consistently over a window, it indicates high intraday volatility with low directional conviction; when this 'shadow-to-body' ratio reaches extremes relative to historical ATR, mean reversion becomes highly probable.\n                concise Specification: The factor is defined as the 20-day SMA of (($high - $low) / (ABS($close - $open) + 1e-8)) divided by the 20-day Average True Range (ATR), targeting the divergence between total intraday movement and net daily progress.\n                ",
      "initial_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Normalize KLEN by the 20-day Average True Range (ATR) to create a 'Relative Intraday Intensity' factor that is cross-sectionally comparable across different liquidity tiers.",
      "evolution_phase": "mutation",
      "trajectory_id": "71ba9c25a87a",
      "parent_trajectory_ids": [
        "39ac7955b842"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004219150485339,
        "ICIR": 0.0312504837998102,
        "RankIC": 0.0195632885477191,
        "RankICIR": 0.142873529902817,
        "annualized_return": 0.0431680673280097,
        "information_ratio": 0.7100792017482512,
        "max_drawdown": -0.0765492214310965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:42:00.790636",
      "updated_at": "2026-01-17T06:42:00.790641"
    },
    "d339476e2577b31e": {
      "factor_id": "d339476e2577b31e",
      "factor_name": "Overnight_Sentiment_Exhaustion_5D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential short-term mean reversion by calculating the ratio of the overnight price gap to the average volume-weighted intraday range over the last 5 days. A high value suggests an emotional overnight overextension on low relative liquidity density, which is likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.308356",
      "updated_at": "2026-01-17T06:44:28.308362"
    },
    "924aeaafa3d5d17d": {
      "factor_id": "924aeaafa3d5d17d",
      "factor_name": "Ranked_Gap_to_Liquidity_Density_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) / (RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_to_Liquidity_Density_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized version of the sentiment exhaustion hypothesis. It compares the current overnight gap against the average intraday price movement per unit of volume over 10 days, applying cross-sectional ranking to identify the most overextended stocks relative to their recent liquidity profile.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.334292",
      "updated_at": "2026-01-17T06:44:28.334298"
    },
    "858f84aee06050b8": {
      "factor_id": "858f84aee06050b8",
      "factor_name": "Volatility_Adjusted_Overnight_Gap_3D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Overnight_Gap_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the overnight gap relative to the 3-day average intraday range, excluding volume to focus purely on price-action exhaustion. It targets stocks where the overnight move is disproportionately large compared to recent daily price volatility.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Overnight Sentiment Exhaustion' factor, calculated as the ratio of the overnight price gap to the 5-day average volume-weighted intraday price range, predicts short-term mean reversion by identifying retail-driven price overextensions that lack institutional support.\n                Concise Observation: The parent strategy focused on 20-day trend stability and volume density, whereas market gaps often represent overnight information asymmetry that frequently overshoots and reverses within the first few days of trading.\n                Concise Justification: Retail investors often drive overnight price movements through emotional reactions to news, while institutional liquidity providers tend to fade these gaps if they are not supported by fundamental volume density, leading to a predictable reversal.\n                Concise Knowledge: If a significant overnight price gap occurs on low relative volume or narrow intraday spreads, it is likely a sentiment-driven overreaction; when such gaps are mean-reverting, they provide liquidity-driven entry points for short-term reversals.\n                concise Specification: The factor is defined as (Open / Prev_Close - 1) divided by the 5-day rolling average of (High - Low) / Volume; it targets the 1-3 day return horizon and is expected to have a negative correlation with forward returns (high gap/low density = lower future returns).\n                ",
      "initial_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Construct a 'Volume-Weighted Efficiency Ratio' by dividing the 5-day price displacement by the sum of KLEN over the same period, adjusted by WVMA5.",
      "evolution_phase": "mutation",
      "trajectory_id": "4a13ef00c045",
      "parent_trajectory_ids": [
        "aa0af49df764"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046467760984208,
        "ICIR": 0.0358848834900863,
        "RankIC": 0.0212644582095298,
        "RankICIR": 0.168298689289537,
        "annualized_return": 0.0679279422787479,
        "information_ratio": 1.1304975822218142,
        "max_drawdown": -0.0839631529988696
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:44:28.359855",
      "updated_at": "2026-01-17T06:44:28.359861"
    },
    "2a7824bde358fdcf": {
      "factor_id": "2a7824bde358fdcf",
      "factor_name": "WV_Trend_Linearity_Ratio_5_10",
      "factor_expression": "TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) * $volume, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"WV_Trend_Linearity_Ratio_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the ratio between the 5-day volume-weighted price range and the 10-day R-squared of price against a time index. It identifies trend exhaustion by detecting when the 'energy' (volume-weighted volatility) spikes while the 'order' (linear trend persistence) begins to plateau or decay.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:09.983407",
      "updated_at": "2026-01-17T06:59:09.983414"
    },
    "1b788843ad56ac76": {
      "factor_id": "1b788843ad56ac76",
      "factor_name": "Vol_Weighted_Volatility_ZScore_Trend_Decay",
      "factor_expression": "TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) * $volume, 5) - POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Volatility_ZScore_Trend_Decay\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between standardized volume-weighted volatility and trend persistence. It targets the lead-lag relationship where a surge in volatility (Z-score of WV) relative to the trend stability (R-squared) signals an imminent regime shift or trend breakdown.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.009807",
      "updated_at": "2026-01-17T06:59:10.009813"
    },
    "97f062d37da14737": {
      "factor_id": "97f062d37da14737",
      "factor_name": "Institutional_Distribution_Energy_Factor",
      "factor_expression": "RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) * $volume, 5)) / (RANK(ABS(TS_CORR($close, SEQUENCE(10), 10))) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Distribution_Energy_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the lead-lag hypothesis focusing on the ratio of short-term volume-weighted price movement to the persistence of the trend. High values suggest that price movement is becoming erratic and volume-heavy, indicating potential institutional distribution before a trend reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Volume-Weighted Volatility Lead-Lag' factor, defined as the 5-day average of volume-weighted price range (WVMA5) relative to the 10-day R-squared of price against time (RSQR10), predicts trend breakdowns when volatility spikes precede a decay in linear trend persistence.\n                Concise Observation: Previous strategies focused on overnight gap reversals and price exhaustion; however, they ignored the lead-lag relationship between the intensity of price movement (WVMA) and the quality of the trend (RSQR), which often signals institutional distribution before price turns.\n                Concise Justification: WVMA captures the 'energy' of price movement by weighting volatility with volume, while RSQR measures the 'order' or linearity of the trend; a divergence where energy spikes but order plateaus suggests that the trend is no longer efficient and likely to fail.\n                Concise Knowledge: If volume-weighted volatility increases while price linearity (R-squared) remains high, a trend exhaustion is imminent; when high volatility is followed by a sharp drop in R-squared, it signals a structural regime shift from trend to mean-reversion.\n                concise Specification: The factor calculates the ratio of the 5-day moving average of ($high-$low)*$volume to the 10-day coefficient of determination (R-squared) of $close prices against a linear time index, specifically targeting the lead-lag window where volatility exceeds trend stability.\n                ",
      "initial_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Test the lead-lag relationship between WVMA5 and RSQR10 to determine if spikes in volume-weighted volatility consistently precede a breakdown in trend linearity.",
      "evolution_phase": "mutation",
      "trajectory_id": "5edd10f890a1",
      "parent_trajectory_ids": [
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037336914555705,
        "ICIR": 0.0275321696876615,
        "RankIC": 0.0188917764787048,
        "RankICIR": 0.1401068587280018,
        "annualized_return": 0.0666524233826713,
        "information_ratio": 1.0396635069087794,
        "max_drawdown": -0.090774721993315
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:10.035784",
      "updated_at": "2026-01-17T06:59:10.035789"
    },
    "628b34f333f9c1b3": {
      "factor_id": "628b34f333f9c1b3",
      "factor_name": "Stealth_Accumulation_Efficiency_20D",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(DELTA($close, 20)) / (TS_SUM(ABS(DELTA($close, 1)), 20) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-8), 5) * (TS_STD($close, 20) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining price path efficiency with a volume-weighted positioning metric, filtered for low-volatility 'quiet' regimes. High efficiency (net move vs total move) and volume concentrated near the high during low turnover-to-volatility periods signal sustainable stealth trends.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.576468",
      "updated_at": "2026-01-17T06:59:34.576476"
    },
    "775ac856b5e37fdc": {
      "factor_id": "775ac856b5e37fdc",
      "factor_name": "Quiet_Regime_Path_Linearity_10D",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(TS_STD($return, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 0.00000001)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 10) / (TS_MEAN($volume, 10) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Regime_Path_Linearity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the stealth accumulation hypothesis focusing on the linearity of price movement (Efficiency Ratio) normalized by the relative volatility-to-turnover ratio. It targets stocks moving steadily with low market noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.603817",
      "updated_at": "2026-01-17T06:59:34.603823"
    },
    "3d7dd83af034db9d": {
      "factor_id": "3d7dd83af034db9d",
      "factor_name": "Volume_Skew_Efficiency_Combined",
      "factor_expression": "(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($return), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($close - DELAY($close, 20)) / (TS_SUM(ABS($close - DELAY($close, 1)), 20) + 1e-8)) * TS_MEAN((2 * $close - $high - $low) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Volume_Skew_Efficiency_Combined\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the synergy between price efficiency and the intraday volume-weighted close position. It uses the 20-day efficiency ratio and weights it by the 5-day average of where the close sits relative to the daily range, emphasizing 'quiet' accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Stealth Accumulation Factor identifies sustainable trend continuation by measuring the synergy between price path efficiency (Efficiency Ratio) and volume-weighted price positioning during low-volatility 'quiet' regimes.\n                Concise Observation: The previous 'Exhaustion' strategy (RankIC 0.0201) focused on high-volatility reversals, but missed 'quiet' trends where price moves monotonically with low turnover-to-volatility ratios, suggesting that price efficiency is a distinct alpha source from volatility stretch.\n                Concise Justification: Institutional investors minimize market impact by accumulating positions during periods of low 'attention' (low turnover-to-volatility), creating a 'stealth' drift characterized by high path efficiency and positive volume-weighted skewness before the broader market reacts.\n                Concise Knowledge: If a stock exhibits a high price-path linearity (net change relative to total movement) alongside volume concentration at the day's high during low-volatility periods, it indicates institutional accumulation; conversely, high-volatility price-volume divergence typically signals retail-driven exhaustion.\n                concise Specification: The factor is defined as the product of a 20-day Efficiency Ratio (abs(close - close_20) / sum(abs(return), 20)) and a 5-day Volume-Weighted Skew (measuring close proximity to high/low weighted by volume), filtered by the inverse of the 20-day turnover-to-volatility ratio.\n                ",
      "initial_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Multi-scale liquidity regime switching: Use the ratio of VSTD5 to VSTD60 to identify periods of abnormal volume volatility that precede a breakdown in the ROC60 reversal trend.",
      "evolution_phase": "mutation",
      "trajectory_id": "cb909fe5bc56",
      "parent_trajectory_ids": [
        "9fdcc47fed4d"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0032422943365224,
        "ICIR": 0.0236042388474684,
        "RankIC": 0.014824015948914,
        "RankICIR": 0.1084823886275642,
        "annualized_return": 0.0421742591067469,
        "information_ratio": 0.57687448266113,
        "max_drawdown": -0.1352582596621223
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T06:59:34.630010",
      "updated_at": "2026-01-17T06:59:34.630016"
    },
    "47ab5689d1d20430": {
      "factor_id": "47ab5689d1d20430",
      "factor_name": "Liquidity_Drift_Efficiency_20D",
      "factor_expression": "TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $high + $low + $close) / 4) / (TS_STD($close, 20) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Drift_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistent drift of price relative to the proxy VWAP (average of OHLC), normalized by price volatility. It identifies sustainable trends by calculating the 20-day moving average of this normalized distance, capturing high-conviction liquidity-taking phases.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.104134",
      "updated_at": "2026-01-17T07:02:02.104141"
    },
    "612c20e61471a5fb": {
      "factor_id": "612c20e61471a5fb",
      "factor_name": "Stable_Trend_Consensus_Factor",
      "factor_expression": "RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($close + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Stable_Trend_Consensus_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend stability by combining the price-VWAP distance with its cross-sectional rank. It targets assets where the price is consistently re-rated relative to the average cost basis, avoiding temporary spikes by using a smoothed 20-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.131054",
      "updated_at": "2026-01-17T07:02:02.131060"
    },
    "01c133f13ad1a4f7": {
      "factor_id": "01c133f13ad1a4f7",
      "factor_name": "VWAP_Distance_ZScore_20D",
      "factor_expression": "TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close - ($open + $high + $low + $close) / 4, 20)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Distance_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A normalized measure of the price's deviation from the proxy VWAP, expressed as a time-series Z-score over 20 days. This captures the statistical significance of the price drift relative to its own historical volatility to signal trend continuation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity_Drift_Efficiency' factor, defined as the 20-day average of the daily price-to-VWAP distance normalized by price volatility, predicts trend continuation when the skewness of this distance remains low, indicating a stable shift in the consensus value.\n                Concise Observation: Previous exhaustion-based factors focused on the intensity of price-volume correlation (RankIC 0.0212), but they failed to capture the structural stability of price relative to the average cost basis (VWAP) which often distinguishes sustainable trends from temporary spikes.\n                Concise Justification: VWAP represents the average price paid by all market participants; a persistent and stable deviation from this benchmark suggests that the market is re-pricing the asset based on new information rather than temporary supply/demand imbalances.\n                Concise Knowledge: If the price maintains a consistent distance from the VWAP with low distribution skewness, it indicates a high-conviction liquidity-taking phase; when price distribution around the mean becomes highly skewed, the trend is likely to exhaust as it moves into a liquidity-providing regime.\n                concise Specification: The factor is calculated by taking the daily difference between the Close and a proxy VWAP (approximated as the average of Open, High, Low, Close), normalized by the 20-day standard deviation of price, and then smoothed over a 20-day window to identify persistent drift.\n                ",
      "initial_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Information flow asymmetry: Test if the interaction of positive CORR20 (price-volume synchrony) and high VSTD5 identifies 'high-conviction' trend continuations rather than reversals.",
      "evolution_phase": "mutation",
      "trajectory_id": "9dbdcae095fb",
      "parent_trajectory_ids": [
        "596841141570"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0043061462308353,
        "ICIR": 0.0285587966120163,
        "RankIC": 0.0212999873008188,
        "RankICIR": 0.1425640812701231,
        "annualized_return": 0.0381715048101109,
        "information_ratio": 0.4522959828612787,
        "max_drawdown": -0.1488130977189043
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:02.157264",
      "updated_at": "2026-01-17T07:02:02.157270"
    },
    "f6b570215828664b": {
      "factor_id": "f6b570215828664b",
      "factor_name": "Institutional_Accumulation_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($close - $open) / ($high - $low + 1e-8)) * ($volume / ($high - $low + 1e-8)), 20) / (TS_STD($close / DELAY($close, 1) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring 'price efficiency' (the ratio of net price movement to total intraday range) scaled by volume density. It targets steady price appreciation accompanied by high relative volume and low volatility, which suggests structural absorption of supply.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.446055",
      "updated_at": "2026-01-17T07:02:26.446062"
    },
    "3972ceec7e301721": {
      "factor_id": "3972ceec7e301721",
      "factor_name": "Low_Vol_Volume_Density_Rank_15D",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($return, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 15)) - RANK(TS_STD($close / DELAY($close, 1) - 1, 15))\" # Your output factor expression will be filled in here\n    name = \"Low_Vol_Volume_Density_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-quality momentum by ranking stocks that exhibit a high ratio of volume to intraday range (volume density) while maintaining low return volatility. High volume density indicates that large orders are being filled within a tight price range, a hallmark of institutional execution.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.472976",
      "updated_at": "2026-01-17T07:02:26.472982"
    },
    "60d07cdfa713d25a": {
      "factor_id": "60d07cdfa713d25a",
      "factor_name": "Structural_Liquidity_Absorption_Ratio_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8), 20) * TS_RANK($volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Liquidity_Absorption_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the persistence of price trends by evaluating the consistency of positive returns relative to the intraday range, weighted by the 20-day time-series rank of volume. It identifies 'quiet' trends where volume is high relative to historical norms but price volatility remains suppressed.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Accumulation Persistence Factor (IAPF) identifies structural price trends by measuring the synergy between low-volatility price appreciation and high volume concentration relative to the price range, signaling institutional absorption of supply.\n                Concise Observation: Previous gap-based strategies focused on high-volatility exhaustion (RankIC 0.0213), but failed to capture 'quiet' trends where price moves steadily on high relative volume without triggering volatility-based mean reversion signals.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to price trends characterized by low intraday variance and high volume density, which represents 'quality' momentum compared to retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits positive returns with decreasing price volatility and high volume relative to the day's range, it indicates institutional accumulation; when price trends are supported by structural liquidity absorption rather than speculative volatility, they are more likely to persist.\n                concise Specification: The factor will be calculated over a 20-day window using the ratio of daily returns to intraday range (Price Efficiency) multiplied by the volume-to-range ratio, targeting instruments where the 20-day mean of ($close - $open) / ($high - $low + 1e-8) is positive and volatility is low.\n                ",
      "initial_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Analyze the skewness of the daily K-line body relative to KLEN (the total length) to identify 'exhaustion candles' during periods of high RSQR10 stability.",
      "evolution_phase": "mutation",
      "trajectory_id": "91d95dd748b3",
      "parent_trajectory_ids": [
        "a3791ccfd4b6"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050968802027141,
        "ICIR": 0.0378884609353758,
        "RankIC": 0.0202412327745931,
        "RankICIR": 0.1530184044457323,
        "annualized_return": 0.0798926958736866,
        "information_ratio": 1.3083048416000642,
        "max_drawdown": -0.0768585588287608
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:02:26.499248",
      "updated_at": "2026-01-17T07:02:26.499253"
    },
    "c3727aed18a981b4": {
      "factor_id": "c3727aed18a981b4",
      "factor_name": "Intraday_Conviction_Factor_5D",
      "factor_expression": "TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 5) * TS_MEAN($volume, 5) / (TS_STD($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Conviction_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional trend conviction by measuring the alignment between price direction and intraday range, weighted by volume intensity and penalized by volume instability. It calculates the 5-day average price efficiency (body-to-range ratio) multiplied by the 5-day average volume, normalized by the 20-day volume standard deviation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.499804",
      "updated_at": "2026-01-17T07:04:53.499811"
    },
    "b35305f10d1e3564": {
      "factor_id": "b35305f10d1e3564",
      "factor_name": "Cross_Sectional_Institutional_Flow_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) * RANK(TS_MEAN($volume, 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Institutional_Flow_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the conviction hypothesis that focuses on the relative strength of price-volume synchronization. It uses the ratio of price efficiency to volume volatility over a 10-day window to identify stocks with the most stable institutional accumulation.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.526663",
      "updated_at": "2026-01-17T07:04:53.526669"
    },
    "67c375461e7ad2ef": {
      "factor_id": "67c375461e7ad2ef",
      "factor_name": "Conviction_Momentum_ZScore_20D",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Momentum_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the conviction of price moves by standardizing the price efficiency ratio against its own history and scaling it by the relative volume level. It highlights periods where price movement is unusually 'clean' relative to the intraday noise, supported by high relative volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Intraday Conviction Factor' (ICF) identifies institutional trend continuation by measuring the alignment between price direction and volume intensity using the ratio of daily returns to high-low range, weighted by the stability of volume distribution.\n                Concise Observation: The parent strategy successfully used price-volume decoupling for mean-reversion, but failed to capture the 'momentum' phase where high volume and price movement are positively synchronized and stable.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that smooth volume throughout the day to minimize impact; therefore, a high ratio of (Close-Open) to (High-Low) combined with high volume indicates a 'clean' directional flow with minimal retail noise.\n                Concise Knowledge: If price moves with low intraday volatility relative to its total daily range while volume remains high, it indicates institutional conviction; when such coupling occurs, the trend is more likely to persist than to mean-revert.\n                concise Specification: The factor is defined as the product of the 5-day average price efficiency (Abs(Close-Open)/(High-Low)) and the 5-day average volume, normalized by the 20-day standard deviation of volume to penalize 'lumpy' liquidity shocks.\n                ",
      "initial_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Non-linear decay of long-term signals: Apply an exponential decay function to the ROC60 components to give more weight to recent price action while maintaining the long-term trend context.",
      "evolution_phase": "mutation",
      "trajectory_id": "22fb10b7f147",
      "parent_trajectory_ids": [
        "062b97d8a5f7"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055649869805205,
        "ICIR": 0.0405067466279985,
        "RankIC": 0.0222089314781546,
        "RankICIR": 0.1593665754106688,
        "annualized_return": 0.0349582518551075,
        "information_ratio": 0.5410017003465224,
        "max_drawdown": -0.0770637373137879
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:04:53.552981",
      "updated_at": "2026-01-17T07:04:53.552987"
    },
    "461bb144da4b724a": {
      "factor_id": "461bb144da4b724a",
      "factor_name": "Inst_Trend_Stability_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * RANK(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Stability_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by measuring the stability of volume relative to price range. A low ratio of price range to volume volatility, smoothed over 20 days and normalized by 60-day momentum, suggests a steady, low-impact trend characteristic of institutional buying.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.610923",
      "updated_at": "2026-01-17T07:08:38.610930"
    },
    "c5e624a879656b21": {
      "factor_id": "c5e624a879656b21",
      "factor_name": "Smooth_Volume_Efficiency_20D",
      "factor_expression": "ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN($return, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20)) * ZSCORE(TS_MEAN(TS_PCTCHANGE($close, 1), 60))\" # Your output factor expression will be filled in here\n    name = \"Smooth_Volume_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price efficiency by comparing the daily price range to volume dispersion. It targets regimes where price moves are achieved with consistent volume rather than spikes, indicating sustainable trend persistence. It uses Z-score for cross-sectional normalization.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.637858",
      "updated_at": "2026-01-17T07:08:38.637863"
    },
    "629b1b2a695e6c1d": {
      "factor_id": "629b1b2a695e6c1d",
      "factor_name": "Institutional_Accumulation_Proxy",
      "factor_expression": "TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / (TS_STD($volume, 20) + 1e-8), 20) * SIGN(TS_PCTCHANGE($close, 60))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Proxy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined measure of institutional trend persistence. It calculates the ratio of price range to volume volatility, then applies a time-series rank to ensure the indicator is robust to outliers before multiplying by the long-term trend direction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The stability of intraday volume distribution, measured by the ratio of the daily high-low range to the standard deviation of volume-weighted price movements over a 20-day window, predicts medium-term trend persistence by identifying institutional accumulation patterns.\n                Concise Observation: The parent strategy successfully exploited price-volume exhaustion for mean reversion (RankIC 0.031), but it failed to capture periods where steady, low-volatility volume growth signaled the start of a sustained institutional trend.\n                Concise Justification: Institutional investors typically execute large orders using algorithms that minimize market impact, leading to a 'smoother' volume profile and higher price efficiency compared to the erratic volume spikes seen during retail-driven exhaustion events.\n                Concise Knowledge: If volume accumulation is consistent and lacks extreme spikes relative to price movement, the current trend is more likely to persist; when volume is concentrated in short bursts, it indicates retail-driven noise prone to reversal.\n                concise Specification: The factor is defined as the 20-day moving average of the ratio between the daily price range ($high - $low) and the standard deviation of volume, normalized by the 60-day price momentum to isolate trend-following regimes from mean-reverting shocks.\n                ",
      "initial_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Cross-sectional ranking interaction: Rank assets by ROC60 and CORR20 independently, then test the performance of the intersection of the top quintiles to find 'quiet' recovery candidates.",
      "evolution_phase": "mutation",
      "trajectory_id": "bfe2313e58b0",
      "parent_trajectory_ids": [
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053407011053905,
        "ICIR": 0.0408019199251397,
        "RankIC": 0.0222204708460169,
        "RankICIR": 0.1664763280977649,
        "annualized_return": 0.0596090232667381,
        "information_ratio": 0.9511716047694744,
        "max_drawdown": -0.0765745783643069
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:08:38.666387",
      "updated_at": "2026-01-17T07:08:38.666393"
    },
    "837f1167178d649c": {
      "factor_id": "837f1167178d649c",
      "factor_name": "IAG_Factor_5D",
      "factor_expression": "RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / DELAY($close, 1)) - 1) / (TS_STD(($close / $open) - 1, 5) + 1e-8) * (($close - $low) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"IAG_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's closing position relative to its daily range. High values suggest informed institutional positioning with low retail resistance.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.531668",
      "updated_at": "2026-01-17T07:09:48.531675"
    },
    "395e6e416c3c22cc": {
      "factor_id": "395e6e416c3c22cc",
      "factor_name": "Institutional_Gap_Persistence_10D",
      "factor_expression": "ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(LOG($open / (DELAY($close, 1) + 1e-8)) / (TS_STD(LOG($close / $open), 10) + 1e-8) * SIGN($close - $open))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Persistence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the persistence of information-driven gaps by scaling the overnight return by the 10-day volatility of intraday returns, further filtered by the intraday price location to confirm trend strength. It targets 'quiet' trend initiations where institutional consensus is high.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.562432",
      "updated_at": "2026-01-17T07:09:48.562439"
    },
    "36354e062634e726": {
      "factor_id": "36354e062634e726",
      "factor_name": "Quiet_Trend_Initiation_Index",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MAD($close - $open, 5) + 1e-8)) * RANK(($close - $open) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Initiation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Calculates the ratio of the overnight return to the trailing 5-day median absolute deviation of intraday returns. It uses TS_MAD for robustness against outliers and scales by the intraday range ratio to identify high-conviction institutional moves.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Information Asymmetry Gap (IAG) factor identifies nascent trends by calculating the ratio of overnight price gaps to trailing five-day intraday volatility, adjusted by the stock's idiosyncratic return relative to its daily range, to isolate informed institutional positioning from retail noise.\n                Concise Observation: The parent strategy (SEMS) focused on trend exhaustion via price-volume linearity, but failed to capture the 'quiet' initiation of trends where price gaps occur without immediate volume-driven volatility spikes.\n                Concise Justification: Informed traders often act on overnight news, causing price gaps; if the subsequent intraday trading remains stable (low volatility), it suggests a lack of counter-party resistance and a high probability of trend continuation.\n                Concise Knowledge: If overnight returns are large relative to intraday volatility, the price movement is likely driven by discrete information arrival; when this is coupled with low intraday price dispersion, it signals institutional consensus and higher return persistence.\n                concise Specification: The factor is defined as the overnight return ($open / $close[t-1] - 1) divided by the 5-day standard deviation of intraday returns, further scaled by the position of the close within the daily high-low range to ensure the trend direction is maintained.\n                ",
      "initial_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Integrate RSQR10 with a mean-reversion framework by identifying 'Over-extended Stability' where high R-squared values coincide with extreme WVMA5 readings.",
      "evolution_phase": "mutation",
      "trajectory_id": "98cd588efa3b",
      "parent_trajectory_ids": [
        "99febcc39b9e"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055650057298061,
        "ICIR": 0.0438105329500937,
        "RankIC": 0.0190541035167376,
        "RankICIR": 0.1580630497050389,
        "annualized_return": 0.0505974892798452,
        "information_ratio": 0.8235152897210087,
        "max_drawdown": -0.0768624946391001
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:09:48.590704",
      "updated_at": "2026-01-17T07:09:48.590711"
    },
    "f6f5d9c29160fdcf": {
      "factor_id": "f6f5d9c29160fdcf",
      "factor_name": "Overnight_Gap_ATR_Normalized_20D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_ATR_Normalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the overnight price gap (current open minus previous close) and normalizes it by the 20-day Average True Range (ATR). It identifies institutional information shocks where the overnight surprise significantly exceeds typical daily volatility, signaling a momentum breakout.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.322229",
      "updated_at": "2026-01-17T07:11:55.322236"
    },
    "33dde5198bb9a733": {
      "factor_id": "33dde5198bb9a733",
      "factor_name": "ZScore_Overnight_Shock_20D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_Overnight_Shock_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the cross-sectional strength of the overnight gap relative to its historical volatility. By applying a Z-score to the ATR-normalized gap, it highlights stocks experiencing the most significant idiosyncratic information shocks relative to the market universe.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.350013",
      "updated_at": "2026-01-17T07:11:55.350019"
    },
    "5d7b0005e2695a36": {
      "factor_id": "5d7b0005e2695a36",
      "factor_name": "Ranked_Information_Shock_Persistence",
      "factor_expression": "RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 20) + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Information_Shock_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the ATR-normalized overnight gap with its time-series rank over the last 10 days. It aims to identify 'breakout' days where the overnight shock is not only large relative to volatility but also represents a recent peak in surprise intensity.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's overnight return normalized by its 20-day Average True Range (ATR) predicts short-term trend persistence, where extreme positive gaps relative to idiosyncratic volatility signal institutional information shocks that trigger momentum breakouts.\n                Concise Observation: The parent strategy focused on mean-reversion via price-volume exhaustion, but failed to capture aggressive trend breakouts driven by overnight news that creates price-volatility coupling.\n                Concise Justification: Overnight gaps represent the market's reaction to non-trading hour information; normalizing this gap by the 20-day ATR isolates the 'surprise' component from regular volatility, identifying high-conviction entries that override standard price-volume correlations.\n                Concise Knowledge: If an asset's overnight price gap significantly exceeds its recent historical volatility (ATR), it indicates a structural revaluation; when this 'Information Shock' ratio is high, the asset is likely to exhibit momentum persistence rather than mean-reversion.\n                concise Specification: Calculate the Overnight Gap ($open_t - $close_{t-1}) divided by the 20-day ATR; a window of 20 days is used for the volatility baseline to ensure stability, and the factor is expected to have a positive correlation with next-day returns during high-volatility regimes.\n                ",
      "initial_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Sector-neutralized volume stability: Calculate VSTD5 relative to its sector median to filter out market-wide liquidity shocks and isolate idiosyncratic capital flows.",
      "evolution_phase": "mutation",
      "trajectory_id": "74bfe2c08800",
      "parent_trajectory_ids": [
        "e5e9bb6d8676"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053688443075677,
        "ICIR": 0.0415952225722003,
        "RankIC": 0.0205067993386611,
        "RankICIR": 0.1629828530914591,
        "annualized_return": 0.0681494176173975,
        "information_ratio": 1.1160596564664005,
        "max_drawdown": -0.0976388476237805
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:11:55.377120",
      "updated_at": "2026-01-17T07:11:55.377126"
    },
    "3aa5d8e96e906741": {
      "factor_id": "3aa5d8e96e906741",
      "factor_name": "ILVG_Base_5D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (($high - $low) / ($close + 1e-8) / ($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / (($high - $low) / ($close + 1e-8) / ($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ILVG_Base_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Informed Liquidity-Validation Gap (ILVG) factor. It scales the overnight return (sentiment) by the inverse of the price movement cost (intraday range relative to volume intensity). High volume supporting a narrow range after a gap indicates efficient price discovery, while low volume with high volatility suggests a 'hollow' gap prone to reversal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity-Validation Gap (ILVG) factor, defined as the overnight return divided by the ratio of intraday price range (High-Low) to relative volume intensity over a 5-day window, predicts positive returns when gaps are efficiently supported by volume and negative returns when gaps are 'hollow' expansions.\n                Concise Observation: Parent 1 showed that overnight gaps carry sentiment (RankIC 0.0216), while Parent 2 demonstrated that the ratio of price range to volume intensity (VVDE) identifies price efficiency (RankIC 0.0298).\n                Concise Justification: By scaling the overnight sentiment signal by the inverse of the 'cost of price movement' (VVDE), we filter out gaps that lack liquidity validation, thereby isolating high-conviction institutional flows from retail-driven exhaustion gaps.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday volatility but low relative volume, the price move is likely noise-driven and prone to mean reversion; conversely, when high volume supports a narrow intraday range following a gap, the price discovery is efficient and momentum-persistent.\n                concise Specification: The ILVG factor is calculated as (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / Close_t / (Volume_t / Mean(Volume_{t-1...t-5}))). The look-back period for volume normalization is 5 days, and the intraday range is normalized by the current close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "21809a7d6aca",
      "parent_trajectory_ids": [
        "c45ed08a92fb",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0065254216645761,
        "ICIR": 0.0472355092847189,
        "RankIC": 0.0270520258483099,
        "RankICIR": 0.2024824929100111,
        "annualized_return": 0.0821097882309767,
        "information_ratio": 1.2176888122530412,
        "max_drawdown": -0.098122127271157
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:12:54.311467",
      "updated_at": "2026-01-17T07:12:54.311474"
    },
    "fd532a0a4a268e0d": {
      "factor_id": "fd532a0a4a268e0d",
      "factor_name": "Ranked_ILVG_Efficiency_5D",
      "factor_expression": "RANK($open / DELAY($close, 1) - 1) * RANK(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(RANK($open / DELAY($close, 1) - 1) * RANK(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_ILVG_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the ILVG factor. It uses RANK to normalize the overnight gap and the volume-validated intraday range (VVDE) before combining them. This reduces the impact of outliers in price range and volume spikes, focusing on the relative conviction of the gap across the universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity-Validation Gap (ILVG) factor, defined as the overnight return divided by the ratio of intraday price range (High-Low) to relative volume intensity over a 5-day window, predicts positive returns when gaps are efficiently supported by volume and negative returns when gaps are 'hollow' expansions.\n                Concise Observation: Parent 1 showed that overnight gaps carry sentiment (RankIC 0.0216), while Parent 2 demonstrated that the ratio of price range to volume intensity (VVDE) identifies price efficiency (RankIC 0.0298).\n                Concise Justification: By scaling the overnight sentiment signal by the inverse of the 'cost of price movement' (VVDE), we filter out gaps that lack liquidity validation, thereby isolating high-conviction institutional flows from retail-driven exhaustion gaps.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday volatility but low relative volume, the price move is likely noise-driven and prone to mean reversion; conversely, when high volume supports a narrow intraday range following a gap, the price discovery is efficient and momentum-persistent.\n                concise Specification: The ILVG factor is calculated as (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / Close_t / (Volume_t / Mean(Volume_{t-1...t-5}))). The look-back period for volume normalization is 5 days, and the intraday range is normalized by the current close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "21809a7d6aca",
      "parent_trajectory_ids": [
        "c45ed08a92fb",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0065254216645761,
        "ICIR": 0.0472355092847189,
        "RankIC": 0.0270520258483099,
        "RankICIR": 0.2024824929100111,
        "annualized_return": 0.0821097882309767,
        "information_ratio": 1.2176888122530412,
        "max_drawdown": -0.098122127271157
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:12:54.339426",
      "updated_at": "2026-01-17T07:12:54.339432"
    },
    "c077f13bd7bec6f8": {
      "factor_id": "c077f13bd7bec6f8",
      "factor_name": "Smoothed_ILVG_Validation_10D",
      "factor_expression": "($open / DELAY($close, 1) - 1) * TS_MEAN(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) * TS_MEAN(($volume / (TS_MEAN(DELAY($volume, 1), 5) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_ILVG_Validation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A smoothed version of the Informed Liquidity-Validation Gap that uses a 10-day moving average of the validation component (Volume/Range) to identify persistent institutional support for overnight moves rather than single-day noise.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity-Validation Gap (ILVG) factor, defined as the overnight return divided by the ratio of intraday price range (High-Low) to relative volume intensity over a 5-day window, predicts positive returns when gaps are efficiently supported by volume and negative returns when gaps are 'hollow' expansions.\n                Concise Observation: Parent 1 showed that overnight gaps carry sentiment (RankIC 0.0216), while Parent 2 demonstrated that the ratio of price range to volume intensity (VVDE) identifies price efficiency (RankIC 0.0298).\n                Concise Justification: By scaling the overnight sentiment signal by the inverse of the 'cost of price movement' (VVDE), we filter out gaps that lack liquidity validation, thereby isolating high-conviction institutional flows from retail-driven exhaustion gaps.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday volatility but low relative volume, the price move is likely noise-driven and prone to mean reversion; conversely, when high volume supports a narrow intraday range following a gap, the price discovery is efficient and momentum-persistent.\n                concise Specification: The ILVG factor is calculated as (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / Close_t / (Volume_t / Mean(Volume_{t-1...t-5}))). The look-back period for volume normalization is 5 days, and the intraday range is normalized by the current close price.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "21809a7d6aca",
      "parent_trajectory_ids": [
        "c45ed08a92fb",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0065254216645761,
        "ICIR": 0.0472355092847189,
        "RankIC": 0.0270520258483099,
        "RankICIR": 0.2024824929100111,
        "annualized_return": 0.0821097882309767,
        "information_ratio": 1.2176888122530412,
        "max_drawdown": -0.098122127271157
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:12:54.366828",
      "updated_at": "2026-01-17T07:12:54.366834"
    },
    "beceb91b44bbc95e": {
      "factor_id": "beceb91b44bbc95e",
      "factor_name": "MRLV_Liquidity_Vacuum_5D_20D",
      "factor_expression": "TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"MRLV_Liquidity_Vacuum_5D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Mean-Reverting Liquidity Vacuum (MRLV) factor identifies price exhaustion by calculating the ratio of short-term price range volatility to long-term average volume. High values indicate 'hollow' price movements driven by liquidity gaps rather than institutional conviction, signaling a likely reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.831791",
      "updated_at": "2026-01-17T07:15:34.831797"
    },
    "ab092a4ed20eeabf": {
      "factor_id": "ab092a4ed20eeabf",
      "factor_name": "Hollow_Volatility_Reversal_Factor",
      "factor_expression": "RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($return, $volume, 10) < 0 ? 1 : 0.5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($high - $low, 5) / (TS_MEAN($volume, 20) + 1e-8)) * (TS_CORR($close / DELAY($close, 1) - 1, $volume, 10) < 0 ? 1 : 0.5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Volatility_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets assets where price range expansion is decoupled from volume support. It uses the ratio of the 5-day range standard deviation to the 20-day volume mean, cross-sectionally ranked and filtered for low price-volume correlation to isolate non-institutional noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.861060",
      "updated_at": "2026-01-17T07:15:34.861066"
    },
    "b9875be6ef7bd575": {
      "factor_id": "b9875be6ef7bd575",
      "factor_name": "ZScore_Range_Volume_Imbalance",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Range_Volume_Imbalance\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the standardized imbalance between price range volatility and volume. By using TS_ZSCORE, it identifies extreme 'liquidity vacuum' events relative to the asset's own history, which are historically prone to mean reversion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Mean-Reverting Liquidity Vacuum (MRLV) factor, defined as the ratio of price range volatility to volume-weighted price stability, identifies short-term price exhaustion points where retail-driven noise lacks institutional support, signaling an imminent reversal.\n                Concise Observation: The parent strategy successfully captured institutional accumulation through high price-volume synchrony, but it failed to account for 'noisy' price spikes where high range-to-volume ratios actually signaled trend exhaustion rather than efficiency.\n                Concise Justification: High price ranges on low relative volume indicate a 'liquidity vacuum' where small trades move prices disproportionately; such movements are fragile and tend to reverse once the temporary supply-demand imbalance is exhausted.\n                Concise Knowledge: If price volatility increases while volume intensity remains stagnant or decreases, the price movement is likely driven by liquidity gaps rather than fundamental conviction; When such 'hollow' volatility peaks, the probability of a mean-reversion to the previous 20-day value area increases.\n                concise Specification: The factor is calculated as the 5-day standard deviation of daily ranges ($high-$low) divided by the 20-day average volume, specifically targeting assets where the current price-volume correlation is negative or near zero to ensure orthogonality to trend-following signals.\n                ",
      "initial_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Macro-regime sensitivity: Evaluate if the CORR20 signal's effectiveness shifts during high-volatility regimes (measured by VIX or ATR) compared to low-volatility consolidation phases.",
      "evolution_phase": "mutation",
      "trajectory_id": "ca595afd8043",
      "parent_trajectory_ids": [
        "569bf5cd5eb9"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057672492670453,
        "ICIR": 0.0408660672545633,
        "RankIC": 0.0261975093804158,
        "RankICIR": 0.1882589995380309,
        "annualized_return": 0.0558446811463958,
        "information_ratio": 0.8596891429568351,
        "max_drawdown": -0.0632254502068216
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:15:34.889105",
      "updated_at": "2026-01-17T07:15:34.889111"
    },
    "82c28ed6e206d317": {
      "factor_id": "82c28ed6e206d317",
      "factor_name": "LRRF_Liquidity_Exhaustion_20D",
      "factor_expression": "(($high - $low) / (TS_STD($close, 14) + 1e-8)) / (TS_MEAN($volume, 5) + 1e-8) * (1 - ABS(TS_CORR($close, $volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (TS_STD($close, 14) + 1e-8)) / (TS_MEAN($volume, 5) + 1e-8) * (1 - ABS(TS_CORR($close, $volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"LRRF_Liquidity_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential mean-reversion points by detecting liquidity exhaustion. It calculates the ratio of intraday price dispersion (High-Low) normalized by volatility (ATR) to the average volume. This signal is then weighted by the divergence from typical price-volume correlation (1 - ABS(CORR)) to filter for non-trending 'failed' discovery moves.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Regime Reversal Factor (LRRF) identifies high-conviction mean-reversion points by combining ATR-normalized intraday price dispersion with a volume-exhaustion filter, weighted by the 20-day price-volume correlation and validated by the ratio of overnight gaps to previous day volatility.\n                Concise Observation: Parent 1 successfully used High-Low/Volume for mean reversion (RankIC 0.026), while Parent 2 showed that price-volume correlation and overnight gaps (RankIC 0.031) provide strong regime filters, suggesting a synergistic effect if combined.\n                Concise Justification: Liquidity exhaustion is most predictive of reversal when it represents a 'failed' price discovery process (low correlation) rather than a trending move, and scaling by ATR ensures that the dispersion signal is statistically significant relative to the asset's historical noise.\n                Concise Knowledge: If extreme price dispersion occurs on declining volume while price-volume correlation is low, a liquidity vacuum is likely; when these signals are normalized by ATR and confirmed by overnight gaps, the resulting reversal signal is more robust across different volatility regimes.\n                concise Specification: Calculate the ratio of (High-Low)/ATR(14) divided by Volume(5-day mean), multiply by the absolute difference of 1 and the 20-day Spearman correlation of price and volume, then scale by the ratio of the absolute overnight gap to the 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "32d8562e2ac5",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004582143450058,
        "ICIR": 0.0323815285094316,
        "RankIC": 0.0206565794098764,
        "RankICIR": 0.1499498185884695,
        "annualized_return": 0.032041373972513,
        "information_ratio": 0.4373950925488938,
        "max_drawdown": -0.120092798839113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:20:03.581524",
      "updated_at": "2026-01-17T07:20:03.581531"
    },
    "722b01272514c293": {
      "factor_id": "722b01272514c293",
      "factor_name": "LRRF_Gap_Volatility_Reversal_14D",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LRRF_Gap_Volatility_Reversal_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the validation of reversal signals using overnight gaps relative to historical volatility. It identifies regimes where the overnight price jump is large compared to the 14-day ATR, suggesting a liquidity vacuum that is likely to revert when combined with high intraday price dispersion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Regime Reversal Factor (LRRF) identifies high-conviction mean-reversion points by combining ATR-normalized intraday price dispersion with a volume-exhaustion filter, weighted by the 20-day price-volume correlation and validated by the ratio of overnight gaps to previous day volatility.\n                Concise Observation: Parent 1 successfully used High-Low/Volume for mean reversion (RankIC 0.026), while Parent 2 showed that price-volume correlation and overnight gaps (RankIC 0.031) provide strong regime filters, suggesting a synergistic effect if combined.\n                Concise Justification: Liquidity exhaustion is most predictive of reversal when it represents a 'failed' price discovery process (low correlation) rather than a trending move, and scaling by ATR ensures that the dispersion signal is statistically significant relative to the asset's historical noise.\n                Concise Knowledge: If extreme price dispersion occurs on declining volume while price-volume correlation is low, a liquidity vacuum is likely; when these signals are normalized by ATR and confirmed by overnight gaps, the resulting reversal signal is more robust across different volatility regimes.\n                concise Specification: Calculate the ratio of (High-Low)/ATR(14) divided by Volume(5-day mean), multiply by the absolute difference of 1 and the 20-day Spearman correlation of price and volume, then scale by the ratio of the absolute overnight gap to the 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "32d8562e2ac5",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004582143450058,
        "ICIR": 0.0323815285094316,
        "RankIC": 0.0206565794098764,
        "RankICIR": 0.1499498185884695,
        "annualized_return": 0.032041373972513,
        "information_ratio": 0.4373950925488938,
        "max_drawdown": -0.120092798839113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:20:03.609356",
      "updated_at": "2026-01-17T07:20:03.609362"
    },
    "6ca82a7475bfe00f": {
      "factor_id": "6ca82a7475bfe00f",
      "factor_name": "LRRF_Combined_Regime_Factor",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-8)) * (1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($volume + 1e-8)) * (1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"LRRF_Combined_Regime_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Liquidity-Regime Reversal Factor. It combines the price-volume correlation filter with the ratio of intraday range to volume, cross-sectionally ranked to identify stocks experiencing the most significant liquidity-driven exhaustion relative to their peers.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Regime Reversal Factor (LRRF) identifies high-conviction mean-reversion points by combining ATR-normalized intraday price dispersion with a volume-exhaustion filter, weighted by the 20-day price-volume correlation and validated by the ratio of overnight gaps to previous day volatility.\n                Concise Observation: Parent 1 successfully used High-Low/Volume for mean reversion (RankIC 0.026), while Parent 2 showed that price-volume correlation and overnight gaps (RankIC 0.031) provide strong regime filters, suggesting a synergistic effect if combined.\n                Concise Justification: Liquidity exhaustion is most predictive of reversal when it represents a 'failed' price discovery process (low correlation) rather than a trending move, and scaling by ATR ensures that the dispersion signal is statistically significant relative to the asset's historical noise.\n                Concise Knowledge: If extreme price dispersion occurs on declining volume while price-volume correlation is low, a liquidity vacuum is likely; when these signals are normalized by ATR and confirmed by overnight gaps, the resulting reversal signal is more robust across different volatility regimes.\n                concise Specification: Calculate the ratio of (High-Low)/ATR(14) divided by Volume(5-day mean), multiply by the absolute difference of 1 and the 20-day Spearman correlation of price and volume, then scale by the ratio of the absolute overnight gap to the 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "32d8562e2ac5",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.004582143450058,
        "ICIR": 0.0323815285094316,
        "RankIC": 0.0206565794098764,
        "RankICIR": 0.1499498185884695,
        "annualized_return": 0.032041373972513,
        "information_ratio": 0.4373950925488938,
        "max_drawdown": -0.120092798839113
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:20:03.636873",
      "updated_at": "2026-01-17T07:20:03.636879"
    },
    "885d228959d7ac35": {
      "factor_id": "885d228959d7ac35",
      "factor_name": "Structural_Exhaustion_Factor_V1",
      "factor_expression": "TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) * (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(POW(TS_CORR($close, SEQUENCE(10), 10), 2), 20) * (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Factor_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by multiplying the instability of the price-time linear fit (20-day volatility of 10-day R-squared) with price-volume divergence (ATR to relative volume ratio). High values indicate a 'hollow' trend where price linearity is breaking down while liquidity support is diminishing.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Factor' (SEF) predicts asset returns by identifying periods where high Trend Fragility (20-day volatility of 10-day price-time R-squared) coincides with high Price-Volume Divergence (5-day ATR divided by relative volume), signaling a breakdown in trend integrity.\n                Concise Observation: Parent 1 identifies regime shifts through R-squared volatility (RankIC 0.0215), while Parent 2 captures efficiency via ATR/Volume (RankIC 0.0298); combining them targets the specific failure mode where statistical linearity and volume support diverge.\n                Concise Justification: Trends often collapse when they become 'hollow'—maintaining price movement through low liquidity rather than conviction; by weighting price-volume efficiency by the instability of the trend's linear fit, we isolate high-conviction exhaustion signals.\n                Concise Knowledge: If a price trend exhibits high volatility in its linear consistency while price ranges expand on diminishing volume, then the trend is structurally exhausted; such conditions typically precede mean reversion as the 'brittle' momentum lacks liquidity support.\n                concise Specification: Calculate SEF as the product of the 20-day standard deviation of the 10-day price-time R-squared and the ratio of the 5-day ATR to the 5-day average volume normalized by its 20-day mean; high values indicate imminent reversal.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "c83bda189fad",
      "parent_trajectory_ids": [
        "d28523b947b5",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029310941342914,
        "ICIR": 0.0228851278151406,
        "RankIC": 0.0172368444764199,
        "RankICIR": 0.1323453288932452,
        "annualized_return": 0.0279175594805435,
        "information_ratio": 0.4815084563662187,
        "max_drawdown": -0.1050173850263145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:21:03.208677",
      "updated_at": "2026-01-17T07:21:03.208685"
    },
    "0c76b7045de5e73d": {
      "factor_id": "0c76b7045de5e73d",
      "factor_name": "Trend_Fragility_Efficiency_Index",
      "factor_expression": "RANK(TS_STD($return, 10)) * RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD(TS_PCTCHANGE($close, 1), 10)) * RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Efficiency_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the structural exhaustion hypothesis focusing on the ratio of price range expansion to volume support, weighted by the recent variability in price momentum consistency. It captures the breakdown of efficient market movement.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Factor' (SEF) predicts asset returns by identifying periods where high Trend Fragility (20-day volatility of 10-day price-time R-squared) coincides with high Price-Volume Divergence (5-day ATR divided by relative volume), signaling a breakdown in trend integrity.\n                Concise Observation: Parent 1 identifies regime shifts through R-squared volatility (RankIC 0.0215), while Parent 2 captures efficiency via ATR/Volume (RankIC 0.0298); combining them targets the specific failure mode where statistical linearity and volume support diverge.\n                Concise Justification: Trends often collapse when they become 'hollow'—maintaining price movement through low liquidity rather than conviction; by weighting price-volume efficiency by the instability of the trend's linear fit, we isolate high-conviction exhaustion signals.\n                Concise Knowledge: If a price trend exhibits high volatility in its linear consistency while price ranges expand on diminishing volume, then the trend is structurally exhausted; such conditions typically precede mean reversion as the 'brittle' momentum lacks liquidity support.\n                concise Specification: Calculate SEF as the product of the 20-day standard deviation of the 10-day price-time R-squared and the ratio of the 5-day ATR to the 5-day average volume normalized by its 20-day mean; high values indicate imminent reversal.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "c83bda189fad",
      "parent_trajectory_ids": [
        "d28523b947b5",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029310941342914,
        "ICIR": 0.0228851278151406,
        "RankIC": 0.0172368444764199,
        "RankICIR": 0.1323453288932452,
        "annualized_return": 0.0279175594805435,
        "information_ratio": 0.4815084563662187,
        "max_drawdown": -0.1050173850263145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:21:03.237316",
      "updated_at": "2026-01-17T07:21:03.237323"
    },
    "256d133878405598": {
      "factor_id": "256d133878405598",
      "factor_name": "Linear_Consistency_Decay_Factor",
      "factor_expression": "TS_STD(REGRESI($close, SEQUENCE(10), 10), 20) / (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD(REGRESI($close, SEQUENCE(10), 10), 20) / (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Linear_Consistency_Decay_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'hollow trend' hypothesis by measuring the divergence between price range (volatility) and the statistical linearity of the price path. It uses the residual of price against time as a proxy for trend instability.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Structural Exhaustion Factor' (SEF) predicts asset returns by identifying periods where high Trend Fragility (20-day volatility of 10-day price-time R-squared) coincides with high Price-Volume Divergence (5-day ATR divided by relative volume), signaling a breakdown in trend integrity.\n                Concise Observation: Parent 1 identifies regime shifts through R-squared volatility (RankIC 0.0215), while Parent 2 captures efficiency via ATR/Volume (RankIC 0.0298); combining them targets the specific failure mode where statistical linearity and volume support diverge.\n                Concise Justification: Trends often collapse when they become 'hollow'—maintaining price movement through low liquidity rather than conviction; by weighting price-volume efficiency by the instability of the trend's linear fit, we isolate high-conviction exhaustion signals.\n                Concise Knowledge: If a price trend exhibits high volatility in its linear consistency while price ranges expand on diminishing volume, then the trend is structurally exhausted; such conditions typically precede mean reversion as the 'brittle' momentum lacks liquidity support.\n                concise Specification: Calculate SEF as the product of the 20-day standard deviation of the 10-day price-time R-squared and the ratio of the 5-day ATR to the 5-day average volume normalized by its 20-day mean; high values indicate imminent reversal.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "c83bda189fad",
      "parent_trajectory_ids": [
        "d28523b947b5",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0029310941342914,
        "ICIR": 0.0228851278151406,
        "RankIC": 0.0172368444764199,
        "RankICIR": 0.1323453288932452,
        "annualized_return": 0.0279175594805435,
        "information_ratio": 0.4815084563662187,
        "max_drawdown": -0.1050173850263145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:21:03.265728",
      "updated_at": "2026-01-17T07:21:03.265735"
    },
    "435a335ef9096e7a": {
      "factor_id": "435a335ef9096e7a",
      "factor_name": "LVSE_Factor_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_MEAN($volume, 5) + 1e-8)) * (($high - $low) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_MEAN($volume, 5) + 1e-8)) * (($high - $low) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LVSE_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Validated Sentiment Exhaustion (LVSE) factor identifies mean-reverting price moves by multiplying the normalized overnight gap with the intraday range efficiency. It targets 'hollow' price moves where volatility is high but relative volume is low, suggesting a lack of institutional conviction.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Exhaustion (LVSE) factor, defined as the product of the overnight gap normalized by the 5-day average volume and the intraday range normalized by the 5-day relative volume intensity, identifies mean-reverting price moves driven by institutional liquidity vacuums.\n                Concise Observation: Parent strategies show that overnight gaps and intraday volatility-volume divergences independently predict returns (RankIC 0.021 and 0.029), but they often suffer from false positives when institutional participation is actually high during one of the sessions.\n                Concise Justification: By multiplying the overnight exhaustion signal with the intraday efficiency signal, the factor isolates periods where price discovery is inefficient across the entire trading cycle, specifically targeting retail-driven 'liquidity vacuums' that lack the capital depth to sustain the new price level.\n                Concise Knowledge: If a significant overnight price gap is followed by a high-volatility intraday session on low relative volume, then the price move lacks institutional conviction and is likely to mean-revert; When price moves are decoupled from volume across both overnight and intraday sessions, the resulting 'hollow' expansion indicates sentiment exhaustion.\n                concise Specification: Calculate the overnight gap as (Open - Previous Close) / Previous Close; normalize this by the 5-day moving average of volume; multiply this by the ratio of the intraday range (High - Low) to the 5-day relative volume (Current Volume / 5-day Avg Volume); use a 5-day lookback for all moving averages.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67f2bb4e6644",
      "parent_trajectory_ids": [
        "7be123f3452d",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0062924490755552,
        "ICIR": 0.0488930632043071,
        "RankIC": 0.0219184141665883,
        "RankICIR": 0.1712070931153219,
        "annualized_return": 0.0505599073713051,
        "information_ratio": 0.9402729093250598,
        "max_drawdown": -0.0542230106351212
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:24:16.623388",
      "updated_at": "2026-01-17T07:24:16.623395"
    },
    "24427ac81e280c5b": {
      "factor_id": "24427ac81e280c5b",
      "factor_name": "CrossSectional_LVSE_Rank",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(($high - $low) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(($high - $low) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"CrossSectional_LVSE_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the LVSE factor. It isolates stocks exhibiting the most extreme decoupling between price expansion (overnight and intraday) and volume intensity over a 5-day window, signaling potential sentiment exhaustion relative to the universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Exhaustion (LVSE) factor, defined as the product of the overnight gap normalized by the 5-day average volume and the intraday range normalized by the 5-day relative volume intensity, identifies mean-reverting price moves driven by institutional liquidity vacuums.\n                Concise Observation: Parent strategies show that overnight gaps and intraday volatility-volume divergences independently predict returns (RankIC 0.021 and 0.029), but they often suffer from false positives when institutional participation is actually high during one of the sessions.\n                Concise Justification: By multiplying the overnight exhaustion signal with the intraday efficiency signal, the factor isolates periods where price discovery is inefficient across the entire trading cycle, specifically targeting retail-driven 'liquidity vacuums' that lack the capital depth to sustain the new price level.\n                Concise Knowledge: If a significant overnight price gap is followed by a high-volatility intraday session on low relative volume, then the price move lacks institutional conviction and is likely to mean-revert; When price moves are decoupled from volume across both overnight and intraday sessions, the resulting 'hollow' expansion indicates sentiment exhaustion.\n                concise Specification: Calculate the overnight gap as (Open - Previous Close) / Previous Close; normalize this by the 5-day moving average of volume; multiply this by the ratio of the intraday range (High - Low) to the 5-day relative volume (Current Volume / 5-day Avg Volume); use a 5-day lookback for all moving averages.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67f2bb4e6644",
      "parent_trajectory_ids": [
        "7be123f3452d",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0062924490755552,
        "ICIR": 0.0488930632043071,
        "RankIC": 0.0219184141665883,
        "RankICIR": 0.1712070931153219,
        "annualized_return": 0.0505599073713051,
        "information_ratio": 0.9402729093250598,
        "max_drawdown": -0.0542230106351212
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:24:16.652398",
      "updated_at": "2026-01-17T07:24:16.652404"
    },
    "817200c44756edcb": {
      "factor_id": "817200c44756edcb",
      "factor_name": "Normalized_Exhaustion_Intensity_5D",
      "factor_expression": "(MAX($high, DELAY($close, 1)) - MIN($low, DELAY($close, 1))) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MAX($high, DELAY($close, 1)) - MIN($low, DELAY($close, 1))) / ($volume / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Intensity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the LVSE hypothesis by calculating the ratio of the total daily price range (including the gap) to the relative volume intensity. High values indicate price 'sprinting' on thin liquidity, which is a precursor to mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Validated Sentiment Exhaustion (LVSE) factor, defined as the product of the overnight gap normalized by the 5-day average volume and the intraday range normalized by the 5-day relative volume intensity, identifies mean-reverting price moves driven by institutional liquidity vacuums.\n                Concise Observation: Parent strategies show that overnight gaps and intraday volatility-volume divergences independently predict returns (RankIC 0.021 and 0.029), but they often suffer from false positives when institutional participation is actually high during one of the sessions.\n                Concise Justification: By multiplying the overnight exhaustion signal with the intraday efficiency signal, the factor isolates periods where price discovery is inefficient across the entire trading cycle, specifically targeting retail-driven 'liquidity vacuums' that lack the capital depth to sustain the new price level.\n                Concise Knowledge: If a significant overnight price gap is followed by a high-volatility intraday session on low relative volume, then the price move lacks institutional conviction and is likely to mean-revert; When price moves are decoupled from volume across both overnight and intraday sessions, the resulting 'hollow' expansion indicates sentiment exhaustion.\n                concise Specification: Calculate the overnight gap as (Open - Previous Close) / Previous Close; normalize this by the 5-day moving average of volume; multiply this by the ratio of the intraday range (High - Low) to the 5-day relative volume (Current Volume / 5-day Avg Volume); use a 5-day lookback for all moving averages.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "67f2bb4e6644",
      "parent_trajectory_ids": [
        "7be123f3452d",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0062924490755552,
        "ICIR": 0.0488930632043071,
        "RankIC": 0.0219184141665883,
        "RankICIR": 0.1712070931153219,
        "annualized_return": 0.0505599073713051,
        "information_ratio": 0.9402729093250598,
        "max_drawdown": -0.0542230106351212
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:24:16.681094",
      "updated_at": "2026-01-17T07:24:16.681099"
    },
    "4f57a842513604dc": {
      "factor_id": "4f57a842513604dc",
      "factor_name": "ILA_MeanReversion_Factor_20D",
      "factor_expression": "(($high - $low) / (TS_MEAN($volume, 5) + 1e-8)) * (($open - DELAY($close, 1)) / (TS_MEAN(ABS($high - $low), 14) + 1e-8)) * (1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (TS_MEAN($volume, 5) + 1e-8)) * (($open - DELAY($close, 1)) / (TS_MEAN(ABS($high - $low), 14) + 1e-8)) * (1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ILA_MeanReversion_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Institutional Liquidity Anchor (ILA) factor identifies mean-reversion opportunities by combining liquidity exhaustion (range/volume), overnight gaps normalized by ATR, and a price-volume correlation filter. It targets 'hollow' volatility where price moves without institutional conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Liquidity Anchor (ILA) factor, calculated as the product of the 5-day Mean-Reverting Liquidity Vacuum and the ratio of overnight returns to the 14-day Average True Range, inversely weighted by the 20-day price-volume correlation, identifies high-conviction mean-reversion opportunities by isolating retail-driven 'hollow' volatility from institutional trend shifts.\n                Concise Observation: Parent 1 successfully captured liquidity exhaustion (RankIC 0.026) but suffered in trending markets, while Parent 2's use of overnight gaps and price-volume correlation (RankIC 0.031) provided better regime filtering; combining them addresses the 'hollow volatility' problem where range expands without institutional backing.\n                Concise Justification: The MRLV identifies the structural imbalance between price movement and volume absorption, while the overnight-to-ATR ratio acts as a temporal exhaustion trigger; filtering these by price-volume correlation ensures the strategy avoids 'hot' trends and focuses on regimes where price action is no longer validated by participation.\n                Concise Knowledge: If extreme price range expansion occurs on diminishing volume support (low MRLV) and is accompanied by an overnight price gap that exhausts the current intraday trend (high overnight/ATR ratio), then a mean-reversion event is likely; this signal is strongest when price-volume correlation is low, indicating a decoupling of trend conviction.\n                concise Specification: The factor is defined as: [ (High-Low)/Volume_5d_Mean ] * [ (Open_t - Close_t-1) / ATR_14d ] * [ 1 - Correlation(Price, Volume, 20d) ]. It targets a 5-day mean-reversion window, requires daily OHLCV data, and uses a 20-day lookback for regime normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ba35ee401aef",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053902685189598,
        "ICIR": 0.0389735757534377,
        "RankIC": 0.0212505001327532,
        "RankICIR": 0.1586913891138825,
        "annualized_return": 0.0228619169740838,
        "information_ratio": 0.3241337988861403,
        "max_drawdown": -0.0977853442542883
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:25:15.234428",
      "updated_at": "2026-01-17T07:25:15.234435"
    },
    "1851a80d85192a7d": {
      "factor_id": "1851a80d85192a7d",
      "factor_name": "Liquidity_Vacuum_Exhaustion_Z",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($volume, 5) + 1e-8)) * RANK(1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($volume, 5) + 1e-8)) * RANK(1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Exhaustion_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the ILA hypothesis focusing on cross-sectional ranking of liquidity vacuums. It identifies stocks where the current intraday range relative to volume is extreme, filtered by the decoupling of price and volume trends over a 20-day window.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Liquidity Anchor (ILA) factor, calculated as the product of the 5-day Mean-Reverting Liquidity Vacuum and the ratio of overnight returns to the 14-day Average True Range, inversely weighted by the 20-day price-volume correlation, identifies high-conviction mean-reversion opportunities by isolating retail-driven 'hollow' volatility from institutional trend shifts.\n                Concise Observation: Parent 1 successfully captured liquidity exhaustion (RankIC 0.026) but suffered in trending markets, while Parent 2's use of overnight gaps and price-volume correlation (RankIC 0.031) provided better regime filtering; combining them addresses the 'hollow volatility' problem where range expands without institutional backing.\n                Concise Justification: The MRLV identifies the structural imbalance between price movement and volume absorption, while the overnight-to-ATR ratio acts as a temporal exhaustion trigger; filtering these by price-volume correlation ensures the strategy avoids 'hot' trends and focuses on regimes where price action is no longer validated by participation.\n                Concise Knowledge: If extreme price range expansion occurs on diminishing volume support (low MRLV) and is accompanied by an overnight price gap that exhausts the current intraday trend (high overnight/ATR ratio), then a mean-reversion event is likely; this signal is strongest when price-volume correlation is low, indicating a decoupling of trend conviction.\n                concise Specification: The factor is defined as: [ (High-Low)/Volume_5d_Mean ] * [ (Open_t - Close_t-1) / ATR_14d ] * [ 1 - Correlation(Price, Volume, 20d) ]. It targets a 5-day mean-reversion window, requires daily OHLCV data, and uses a 20-day lookback for regime normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ba35ee401aef",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053902685189598,
        "ICIR": 0.0389735757534377,
        "RankIC": 0.0212505001327532,
        "RankICIR": 0.1586913891138825,
        "annualized_return": 0.0228619169740838,
        "information_ratio": 0.3241337988861403,
        "max_drawdown": -0.0977853442542883
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:25:15.262984",
      "updated_at": "2026-01-17T07:25:15.262990"
    },
    "8577bfdf55bc246c": {
      "factor_id": "8577bfdf55bc246c",
      "factor_name": "Overnight_Gap_ATR_Filter",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8)) * (1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8)) * (1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_ATR_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates the 'temporal exhaustion trigger' from the ILA hypothesis. It measures the overnight gap relative to the 14-day average range, scaled by the inverse of the price-volume correlation to detect non-institutional gap-and-crap scenarios.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Liquidity Anchor (ILA) factor, calculated as the product of the 5-day Mean-Reverting Liquidity Vacuum and the ratio of overnight returns to the 14-day Average True Range, inversely weighted by the 20-day price-volume correlation, identifies high-conviction mean-reversion opportunities by isolating retail-driven 'hollow' volatility from institutional trend shifts.\n                Concise Observation: Parent 1 successfully captured liquidity exhaustion (RankIC 0.026) but suffered in trending markets, while Parent 2's use of overnight gaps and price-volume correlation (RankIC 0.031) provided better regime filtering; combining them addresses the 'hollow volatility' problem where range expands without institutional backing.\n                Concise Justification: The MRLV identifies the structural imbalance between price movement and volume absorption, while the overnight-to-ATR ratio acts as a temporal exhaustion trigger; filtering these by price-volume correlation ensures the strategy avoids 'hot' trends and focuses on regimes where price action is no longer validated by participation.\n                Concise Knowledge: If extreme price range expansion occurs on diminishing volume support (low MRLV) and is accompanied by an overnight price gap that exhausts the current intraday trend (high overnight/ATR ratio), then a mean-reversion event is likely; this signal is strongest when price-volume correlation is low, indicating a decoupling of trend conviction.\n                concise Specification: The factor is defined as: [ (High-Low)/Volume_5d_Mean ] * [ (Open_t - Close_t-1) / ATR_14d ] * [ 1 - Correlation(Price, Volume, 20d) ]. It targets a 5-day mean-reversion window, requires daily OHLCV data, and uses a 20-day lookback for regime normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ba35ee401aef",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053902685189598,
        "ICIR": 0.0389735757534377,
        "RankIC": 0.0212505001327532,
        "RankICIR": 0.1586913891138825,
        "annualized_return": 0.0228619169740838,
        "information_ratio": 0.3241337988861403,
        "max_drawdown": -0.0977853442542883
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:25:15.291127",
      "updated_at": "2026-01-17T07:25:15.291133"
    },
    "388b5b4490903e26": {
      "factor_id": "388b5b4490903e26",
      "factor_name": "ISA_Factor_10D",
      "factor_expression": "TS_CORR($close, $volume, 10) / (($high - $low) / ($volume + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 10) / (($high - $low) / ($volume + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ISA_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Institutional Stealth Absorption (ISA) factor: It identifies high-conviction directional moves with minimal price dispersion by calculating the 10-day correlation between price and volume, normalized by the range-to-volume ratio. High values suggest institutional accumulation with low market impact.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Stealth Absorption (ISA) factor, calculated as the 10-day correlation between price and volume divided by the 10-day ratio of high-low range to volume, identifies superior returns by isolating high-conviction directional moves that occur with minimal price dispersion.\n                Concise Observation: Parent strategies showed that while price-volume correlation (RankIC 0.028) and liquidity vacuum ratios (RankIC 0.026) are independently predictive, their intersection captures 'efficient' price discovery that avoids the mean-reversion traps of high-volatility exhaustion.\n                Concise Justification: Institutional buyers seek to minimize market impact, leading to high directional conviction (correlation) with compressed intra-day ranges relative to the volume traded (absorption), whereas retail-driven moves typically exhibit high range volatility and 'hollow' liquidity.\n                Concise Knowledge: If price-volume correlation is high while price-range volatility per unit of volume is low, then the asset is likely undergoing institutional accumulation; when these conditions diverge, price moves are often driven by retail noise or liquidity exhaustion.\n                concise Specification: The factor is defined as TS_CORR($close, $volume, 10) / (($high - $low) / $volume). It expects a positive relationship with future returns, where higher values indicate 'stealth' accumulation and lower values indicate either lack of conviction or volatile price exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b0acffbb7c07",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068294348773451,
        "ICIR": 0.0468938169997795,
        "RankIC": 0.0234412453878346,
        "RankICIR": 0.1634847987247056,
        "annualized_return": 0.0335898031429351,
        "information_ratio": 0.4671604333292865,
        "max_drawdown": -0.1349401268889269
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:30:01.084851",
      "updated_at": "2026-01-17T07:30:01.084858"
    },
    "2231f6a60e698a66": {
      "factor_id": "2231f6a60e698a66",
      "factor_name": "Ranked_ISA_Efficiency_15D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 15)) * RANK($volume / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 15)) * RANK($volume / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_ISA_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the ISA hypothesis using a 15-day window to capture more stable institutional trends. It measures the efficiency of price discovery by comparing price-volume synchronicity against the standardized price range per unit of volume.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Stealth Absorption (ISA) factor, calculated as the 10-day correlation between price and volume divided by the 10-day ratio of high-low range to volume, identifies superior returns by isolating high-conviction directional moves that occur with minimal price dispersion.\n                Concise Observation: Parent strategies showed that while price-volume correlation (RankIC 0.028) and liquidity vacuum ratios (RankIC 0.026) are independently predictive, their intersection captures 'efficient' price discovery that avoids the mean-reversion traps of high-volatility exhaustion.\n                Concise Justification: Institutional buyers seek to minimize market impact, leading to high directional conviction (correlation) with compressed intra-day ranges relative to the volume traded (absorption), whereas retail-driven moves typically exhibit high range volatility and 'hollow' liquidity.\n                Concise Knowledge: If price-volume correlation is high while price-range volatility per unit of volume is low, then the asset is likely undergoing institutional accumulation; when these conditions diverge, price moves are often driven by retail noise or liquidity exhaustion.\n                concise Specification: The factor is defined as TS_CORR($close, $volume, 10) / (($high - $low) / $volume). It expects a positive relationship with future returns, where higher values indicate 'stealth' accumulation and lower values indicate either lack of conviction or volatile price exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b0acffbb7c07",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068294348773451,
        "ICIR": 0.0468938169997795,
        "RankIC": 0.0234412453878346,
        "RankICIR": 0.1634847987247056,
        "annualized_return": 0.0335898031429351,
        "information_ratio": 0.4671604333292865,
        "max_drawdown": -0.1349401268889269
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:30:01.114625",
      "updated_at": "2026-01-17T07:30:01.114632"
    },
    "fcc42d3aade820ce": {
      "factor_id": "fcc42d3aade820ce",
      "factor_name": "Smoothed_Stealth_Accumulation_20D",
      "factor_expression": "TS_CORR($close, $volume, 20) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Stealth_Accumulation_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the ISA hypothesis by applying a 20-day moving average to the absorption ratio, focusing on sustained institutional activity rather than daily noise. It isolates assets where price-volume correlation is rising while the relative range remains compressed.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Stealth Absorption (ISA) factor, calculated as the 10-day correlation between price and volume divided by the 10-day ratio of high-low range to volume, identifies superior returns by isolating high-conviction directional moves that occur with minimal price dispersion.\n                Concise Observation: Parent strategies showed that while price-volume correlation (RankIC 0.028) and liquidity vacuum ratios (RankIC 0.026) are independently predictive, their intersection captures 'efficient' price discovery that avoids the mean-reversion traps of high-volatility exhaustion.\n                Concise Justification: Institutional buyers seek to minimize market impact, leading to high directional conviction (correlation) with compressed intra-day ranges relative to the volume traded (absorption), whereas retail-driven moves typically exhibit high range volatility and 'hollow' liquidity.\n                Concise Knowledge: If price-volume correlation is high while price-range volatility per unit of volume is low, then the asset is likely undergoing institutional accumulation; when these conditions diverge, price moves are often driven by retail noise or liquidity exhaustion.\n                concise Specification: The factor is defined as TS_CORR($close, $volume, 10) / (($high - $low) / $volume). It expects a positive relationship with future returns, where higher values indicate 'stealth' accumulation and lower values indicate either lack of conviction or volatile price exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b0acffbb7c07",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "27bd4849a020"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068294348773451,
        "ICIR": 0.0468938169997795,
        "RankIC": 0.0234412453878346,
        "RankICIR": 0.1634847987247056,
        "annualized_return": 0.0335898031429351,
        "information_ratio": 0.4671604333292865,
        "max_drawdown": -0.1349401268889269
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:30:01.144529",
      "updated_at": "2026-01-17T07:30:01.144537"
    },
    "8f1ace708a0c8bb4": {
      "factor_id": "8f1ace708a0c8bb4",
      "factor_name": "ILCF_Conviction_Exhaustion_20D",
      "factor_expression": "(($close - $open) / ($high - $low + 1e-8)) * (1 / (TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)) + 1e-8)) * ($open / ($DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - $open) / ($high - $low + 1e-8)) * (1 / (TS_CORR($close, $volume, 20) * (TS_STD($close, 14) / ($close + 1e-8)) + 1e-8)) * ($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"ILCF_Conviction_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the Institutional Liquidity-Conviction Framework by multiplying intraday price conviction (body-to-range ratio) by the inverse of price-volume exhaustion, scaled by the overnight liquidity gap. It identifies high-conviction institutional moves that are not yet exhausted by volume-price divergence.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Liquidity-Conviction Framework' (ILCF) generates alpha by multiplying the intraday conviction (daily price body relative to total range) by the inverse of price-volume exhaustion, scaled by overnight liquidity gaps and volatility.\n                Concise Observation: Parent 1 showed that intraday conviction (RankIC 0.022) captures institutional flow, while Parent 2's use of overnight gaps and ATR-scaled correlation (RankIC 0.031) identifies regime exhaustion and liquidity shifts.\n                Concise Justification: Fusing these identifies 'clean' institutional moves by filtering out exhausted trends, using the overnight gap as a liquidity catalyst and the ATR-scaled body-to-range ratio as a measure of directional intensity.\n                Concise Knowledge: If intraday price conviction is high but volume-price exhaustion is low, the trend is more likely to persist; when high conviction occurs alongside high exhaustion and significant overnight gaps, it signals a potential liquidity trap or reversal.\n                concise Specification: Factor = ((Close - Open) / (High - Low + 1e-6)) * (1 / (Rolling_Corr(Price, Volume, 20) * (ATR_14 / Close) + 1e-6)) * (Open / Close_prev - 1); using 20-day correlation and 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e913fda48832",
      "parent_trajectory_ids": [
        "adb31bc9b7cc",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078853278799918,
        "ICIR": 0.0553941332374025,
        "RankIC": 0.0244174710904535,
        "RankICIR": 0.1772463916351617,
        "annualized_return": 0.025702904391085,
        "information_ratio": 0.3521897160107543,
        "max_drawdown": -0.1178038015788236
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:35:18.290141",
      "updated_at": "2026-01-17T07:35:18.290148"
    },
    "c8a012389b01c1d7": {
      "factor_id": "c8a012389b01c1d7",
      "factor_name": "Ranked_ILCF_Simplified_15D",
      "factor_expression": "RANK(($close - $open) / ($high - $low + 1e-8)) * RANK(($open / ($DELAY($close, 1) + 1e-8)) - 1) * (1 - TS_CORR($close, $volume, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $open) / ($high - $low + 1e-8)) * RANK(($open / (DELAY($close, 1) + 1e-8)) - 1) * (1 - TS_CORR($close, $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_ILCF_Simplified_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the ILCF hypothesis, focusing on the interaction between intraday conviction and the overnight gap, normalized by price-volume correlation to filter out exhausted trends. It uses a 15-day window for stability.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Liquidity-Conviction Framework' (ILCF) generates alpha by multiplying the intraday conviction (daily price body relative to total range) by the inverse of price-volume exhaustion, scaled by overnight liquidity gaps and volatility.\n                Concise Observation: Parent 1 showed that intraday conviction (RankIC 0.022) captures institutional flow, while Parent 2's use of overnight gaps and ATR-scaled correlation (RankIC 0.031) identifies regime exhaustion and liquidity shifts.\n                Concise Justification: Fusing these identifies 'clean' institutional moves by filtering out exhausted trends, using the overnight gap as a liquidity catalyst and the ATR-scaled body-to-range ratio as a measure of directional intensity.\n                Concise Knowledge: If intraday price conviction is high but volume-price exhaustion is low, the trend is more likely to persist; when high conviction occurs alongside high exhaustion and significant overnight gaps, it signals a potential liquidity trap or reversal.\n                concise Specification: Factor = ((Close - Open) / (High - Low + 1e-6)) * (1 / (Rolling_Corr(Price, Volume, 20) * (ATR_14 / Close) + 1e-6)) * (Open / Close_prev - 1); using 20-day correlation and 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e913fda48832",
      "parent_trajectory_ids": [
        "adb31bc9b7cc",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078853278799918,
        "ICIR": 0.0553941332374025,
        "RankIC": 0.0244174710904535,
        "RankICIR": 0.1772463916351617,
        "annualized_return": 0.025702904391085,
        "information_ratio": 0.3521897160107543,
        "max_drawdown": -0.1178038015788236
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:35:18.318750",
      "updated_at": "2026-01-17T07:35:18.318756"
    },
    "0ee50e4633690b13": {
      "factor_id": "0ee50e4633690b13",
      "factor_name": "Institutional_Intensity_Index_20D",
      "factor_expression": "ZSCORE(($close - $open) / ($high - $low + 1e-8)) * (1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - $open) / ($high - $low + 1e-8)) * (1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Intensity_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures directional intensity by scaling the intraday body-to-range ratio with the inverse of the rolling price-volume correlation. It targets 'clean' institutional flows where price movement is not accompanied by the volume exhaustion typically seen at trend peaks.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Liquidity-Conviction Framework' (ILCF) generates alpha by multiplying the intraday conviction (daily price body relative to total range) by the inverse of price-volume exhaustion, scaled by overnight liquidity gaps and volatility.\n                Concise Observation: Parent 1 showed that intraday conviction (RankIC 0.022) captures institutional flow, while Parent 2's use of overnight gaps and ATR-scaled correlation (RankIC 0.031) identifies regime exhaustion and liquidity shifts.\n                Concise Justification: Fusing these identifies 'clean' institutional moves by filtering out exhausted trends, using the overnight gap as a liquidity catalyst and the ATR-scaled body-to-range ratio as a measure of directional intensity.\n                Concise Knowledge: If intraday price conviction is high but volume-price exhaustion is low, the trend is more likely to persist; when high conviction occurs alongside high exhaustion and significant overnight gaps, it signals a potential liquidity trap or reversal.\n                concise Specification: Factor = ((Close - Open) / (High - Low + 1e-6)) * (1 / (Rolling_Corr(Price, Volume, 20) * (ATR_14 / Close) + 1e-6)) * (Open / Close_prev - 1); using 20-day correlation and 14-day ATR.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "e913fda48832",
      "parent_trajectory_ids": [
        "adb31bc9b7cc",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0078853278799918,
        "ICIR": 0.0553941332374025,
        "RankIC": 0.0244174710904535,
        "RankICIR": 0.1772463916351617,
        "annualized_return": 0.025702904391085,
        "information_ratio": 0.3521897160107543,
        "max_drawdown": -0.1178038015788236
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:35:18.349186",
      "updated_at": "2026-01-17T07:35:18.349192"
    },
    "bd8eaac583a7476e": {
      "factor_id": "bd8eaac583a7476e",
      "factor_name": "Structural_Exhaustion_Efficiency_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_MEAN(($high - $low) / ($volume + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Structural Exhaustion Efficiency (SEE) factor identifies high-conviction trend reversals by detecting 'hollow' price accelerations. It combines the 5-day price-time linearity (R-squared) with the ratio of price range to volume. High values indicate a blow-off phase where price moves are linear but lack liquidity support, signaling imminent exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the product of the 5-day price-time R-squared and the 5-day ATR-to-Volume ratio, identifies high-conviction trend reversals by detecting 'hollow' price accelerations that lack liquidity support.\n                Concise Observation: Parent 1 showed that short-term price linearity decay precedes reversals (RankIC 0.020), and Parent 2 demonstrated that high price range relative to volume signals efficiency exhaustion (RankIC 0.030).\n                Concise Justification: Combining these captures 'Structural Fragility': the R-squared component ensures the trend is technically 'stretched' and linear, while the ATR/Volume ratio confirms the move is 'expensive' and unsupported by deep liquidity, creating a synergistic signal for trend exhaustion.\n                Concise Knowledge: If a price trend exhibits high short-term linearity (R-squared) but requires increasing price volatility per unit of volume (ATR/Volume), it indicates a liquidity-driven 'blow-off' phase likely to reverse; whereas high linearity with low relative volatility suggests a sustainable, fundamentally backed trend.\n                concise Specification: Calculate the 5-day rolling R-squared of $close against a time index; calculate the 5-day average of ($high-$low)/$volume; the SEE factor is the product of these two metrics, where high values signal imminent exhaustion and low values signal structural stability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d025bb6b3900",
      "parent_trajectory_ids": [
        "d7555a47a787",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049294871514049,
        "ICIR": 0.0369113585360031,
        "RankIC": 0.0224614532776789,
        "RankICIR": 0.1688719622945828,
        "annualized_return": 0.0374867846205408,
        "information_ratio": 0.5864814292730505,
        "max_drawdown": -0.1089300550887258
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:39:22.159784",
      "updated_at": "2026-01-17T07:39:22.159790"
    },
    "9c27fd388a38e2d2": {
      "factor_id": "9c27fd388a38e2d2",
      "factor_name": "Linear_Volatility_Exhaustion_Rank_10D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Linear_Volatility_Exhaustion_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the exhaustion hypothesis using a 10-day window and cross-sectional ranking to enhance signal stability. It measures the intensity of linear price trends relative to the volume-weighted range, identifying assets where price movement is overextended relative to the effort (volume) provided.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the product of the 5-day price-time R-squared and the 5-day ATR-to-Volume ratio, identifies high-conviction trend reversals by detecting 'hollow' price accelerations that lack liquidity support.\n                Concise Observation: Parent 1 showed that short-term price linearity decay precedes reversals (RankIC 0.020), and Parent 2 demonstrated that high price range relative to volume signals efficiency exhaustion (RankIC 0.030).\n                Concise Justification: Combining these captures 'Structural Fragility': the R-squared component ensures the trend is technically 'stretched' and linear, while the ATR/Volume ratio confirms the move is 'expensive' and unsupported by deep liquidity, creating a synergistic signal for trend exhaustion.\n                Concise Knowledge: If a price trend exhibits high short-term linearity (R-squared) but requires increasing price volatility per unit of volume (ATR/Volume), it indicates a liquidity-driven 'blow-off' phase likely to reverse; whereas high linearity with low relative volatility suggests a sustainable, fundamentally backed trend.\n                concise Specification: Calculate the 5-day rolling R-squared of $close against a time index; calculate the 5-day average of ($high-$low)/$volume; the SEE factor is the product of these two metrics, where high values signal imminent exhaustion and low values signal structural stability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d025bb6b3900",
      "parent_trajectory_ids": [
        "d7555a47a787",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049294871514049,
        "ICIR": 0.0369113585360031,
        "RankIC": 0.0224614532776789,
        "RankICIR": 0.1688719622945828,
        "annualized_return": 0.0374867846205408,
        "information_ratio": 0.5864814292730505,
        "max_drawdown": -0.1089300550887258
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:39:22.188486",
      "updated_at": "2026-01-17T07:39:22.188492"
    },
    "114d105f79e6f1b9": {
      "factor_id": "114d105f79e6f1b9",
      "factor_name": "Standardized_Structural_Fragility_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(5), 5), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Standardized_Structural_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor standardizes the Structural Exhaustion signal by applying a Z-score to the price-range-to-volume ratio before multiplying by the trend linearity. This ensures that the 'hollow' price acceleration is measured relative to the asset's own recent liquidity history.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the product of the 5-day price-time R-squared and the 5-day ATR-to-Volume ratio, identifies high-conviction trend reversals by detecting 'hollow' price accelerations that lack liquidity support.\n                Concise Observation: Parent 1 showed that short-term price linearity decay precedes reversals (RankIC 0.020), and Parent 2 demonstrated that high price range relative to volume signals efficiency exhaustion (RankIC 0.030).\n                Concise Justification: Combining these captures 'Structural Fragility': the R-squared component ensures the trend is technically 'stretched' and linear, while the ATR/Volume ratio confirms the move is 'expensive' and unsupported by deep liquidity, creating a synergistic signal for trend exhaustion.\n                Concise Knowledge: If a price trend exhibits high short-term linearity (R-squared) but requires increasing price volatility per unit of volume (ATR/Volume), it indicates a liquidity-driven 'blow-off' phase likely to reverse; whereas high linearity with low relative volatility suggests a sustainable, fundamentally backed trend.\n                concise Specification: Calculate the 5-day rolling R-squared of $close against a time index; calculate the 5-day average of ($high-$low)/$volume; the SEE factor is the product of these two metrics, where high values signal imminent exhaustion and low values signal structural stability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "d025bb6b3900",
      "parent_trajectory_ids": [
        "d7555a47a787",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049294871514049,
        "ICIR": 0.0369113585360031,
        "RankIC": 0.0224614532776789,
        "RankICIR": 0.1688719622945828,
        "annualized_return": 0.0374867846205408,
        "information_ratio": 0.5864814292730505,
        "max_drawdown": -0.1089300550887258
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:39:22.216542",
      "updated_at": "2026-01-17T07:39:22.216548"
    },
    "e2dc8db3ff8924c4": {
      "factor_id": "e2dc8db3ff8924c4",
      "factor_name": "IAEI_Absorption_Index_5D",
      "factor_expression": "TS_MEAN($volume / ($high - $low + 1e-8), 5) * TS_MEAN($volume / (TS_STD($close, 5) + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / ($high - $low + 1e-8), 5) * TS_MEAN($volume / (TS_STD($close, 5) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"IAEI_Absorption_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Institutional Absorption Efficiency Index (IAEI): This factor identifies institutional accumulation by looking for high volume-to-price-range density combined with high price efficiency. It multiplies the rolling average of volume density by the inverse of volatility-normalized range to filter out low-conviction breakouts.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Absorption Efficiency Index (IAEI) predicts asset returns by identifying periods where high volume-to-price-range density (Institutional Accumulation) is paired with low volatility-normalized price efficiency, filtering out low-conviction breakouts.\n                Concise Observation: Parent 1 (IAPF) captures trend persistence through volume concentration (RankIC 0.020), while Parent 2 (VVDE) captures price efficiency (RankIC 0.029); combining them addresses the weakness of buying into low-liquidity volatility spikes.\n                Concise Justification: Institutional players accumulate positions over time to minimize market impact, leading to high volume per unit of price range; by weighting volume density with the inverse of volatility-normalized range, we isolate high-conviction structural trends.\n                Concise Knowledge: If price appreciation occurs with high volume density and low relative volatility, it indicates institutional absorption; when price moves are 'hollow' (high volatility, low volume), they are prone to mean reversion.\n                concise Specification: Define IAEI as the product of a 5-day rolling average of (Volume / (High - Low)) and the 5-day inverse of (ATR / Relative Volume), ensuring both volume support and price efficiency are maximized simultaneously.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "949f65a01ea5",
      "parent_trajectory_ids": [
        "acb39605a28d",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037083274031751,
        "ICIR": 0.0276066445176113,
        "RankIC": 0.0194354575836202,
        "RankICIR": 0.1489870304438573,
        "annualized_return": 0.0179828042632012,
        "information_ratio": 0.2936536264072802,
        "max_drawdown": -0.122562838916295
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:42:11.721962",
      "updated_at": "2026-01-17T07:42:11.721968"
    },
    "9de952d54942159e": {
      "factor_id": "9de952d54942159e",
      "factor_name": "Institutional_Accumulation_Density_10D",
      "factor_expression": "RANK($volume / ($high - $low + 1e-8)) * RANK(INV(TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($volume / ($high - $low + 1e-8)) * RANK(INV(TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Density_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the absorption hypothesis focusing on the cross-sectional rank of volume density relative to price volatility. It captures periods where price moves are supported by heavy volume relative to the realized range, normalized by the 10-day volatility to ensure the trend is structural rather than speculative.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Absorption Efficiency Index (IAEI) predicts asset returns by identifying periods where high volume-to-price-range density (Institutional Accumulation) is paired with low volatility-normalized price efficiency, filtering out low-conviction breakouts.\n                Concise Observation: Parent 1 (IAPF) captures trend persistence through volume concentration (RankIC 0.020), while Parent 2 (VVDE) captures price efficiency (RankIC 0.029); combining them addresses the weakness of buying into low-liquidity volatility spikes.\n                Concise Justification: Institutional players accumulate positions over time to minimize market impact, leading to high volume per unit of price range; by weighting volume density with the inverse of volatility-normalized range, we isolate high-conviction structural trends.\n                Concise Knowledge: If price appreciation occurs with high volume density and low relative volatility, it indicates institutional absorption; when price moves are 'hollow' (high volatility, low volume), they are prone to mean reversion.\n                concise Specification: Define IAEI as the product of a 5-day rolling average of (Volume / (High - Low)) and the 5-day inverse of (ATR / Relative Volume), ensuring both volume support and price efficiency are maximized simultaneously.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "949f65a01ea5",
      "parent_trajectory_ids": [
        "acb39605a28d",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037083274031751,
        "ICIR": 0.0276066445176113,
        "RankIC": 0.0194354575836202,
        "RankICIR": 0.1489870304438573,
        "annualized_return": 0.0179828042632012,
        "information_ratio": 0.2936536264072802,
        "max_drawdown": -0.122562838916295
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:42:11.750856",
      "updated_at": "2026-01-17T07:42:11.750862"
    },
    "9222937a074f8aa4": {
      "factor_id": "9222937a074f8aa4",
      "factor_name": "Efficiency_Weighted_Volume_5D",
      "factor_expression": "TS_MEAN($volume, 5) / (TS_MEAN($high - $low, 5) * TS_STD($close, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 5) / (TS_MEAN($high - $low, 5) * TS_STD($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Weighted_Volume_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of volume in driving price trends. It calculates the ratio of volume to the price range, weighted by the inverse of recent volatility. High values indicate 'efficient' absorption where volume is high but price volatility is contained, suggesting controlled institutional buying.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Absorption Efficiency Index (IAEI) predicts asset returns by identifying periods where high volume-to-price-range density (Institutional Accumulation) is paired with low volatility-normalized price efficiency, filtering out low-conviction breakouts.\n                Concise Observation: Parent 1 (IAPF) captures trend persistence through volume concentration (RankIC 0.020), while Parent 2 (VVDE) captures price efficiency (RankIC 0.029); combining them addresses the weakness of buying into low-liquidity volatility spikes.\n                Concise Justification: Institutional players accumulate positions over time to minimize market impact, leading to high volume per unit of price range; by weighting volume density with the inverse of volatility-normalized range, we isolate high-conviction structural trends.\n                Concise Knowledge: If price appreciation occurs with high volume density and low relative volatility, it indicates institutional absorption; when price moves are 'hollow' (high volatility, low volume), they are prone to mean reversion.\n                concise Specification: Define IAEI as the product of a 5-day rolling average of (Volume / (High - Low)) and the 5-day inverse of (ATR / Relative Volume), ensuring both volume support and price efficiency are maximized simultaneously.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "949f65a01ea5",
      "parent_trajectory_ids": [
        "acb39605a28d",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037083274031751,
        "ICIR": 0.0276066445176113,
        "RankIC": 0.0194354575836202,
        "RankICIR": 0.1489870304438573,
        "annualized_return": 0.0179828042632012,
        "information_ratio": 0.2936536264072802,
        "max_drawdown": -0.122562838916295
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:42:11.779389",
      "updated_at": "2026-01-17T07:42:11.779395"
    },
    "3e35e902f32a93e8": {
      "factor_id": "3e35e902f32a93e8",
      "factor_name": "Structural_Exhaustion_Efficiency_20D",
      "factor_expression": "TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8) / ($volume / (TS_MEAN($volume, 5) + 1e-8)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8) / ($volume / (TS_MEAN($volume, 5) + 1e-8)), 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Efficiency_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The SEE factor identifies mean-reversion opportunities by calculating the ratio of intraday price travel (range) to net movement (body), normalized by relative volume. High values indicate 'hollow' volatility where price expands on low conviction, signaling potential exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the 20-day average of the ratio between intraday range-to-body asymmetry and 5-day relative volume intensity, identifies mean-reversion opportunities where price expansion is decoupled from liquidity support.\n                Concise Observation: Parent 1 (RankIC 0.0196) captures price-action indecision, while Parent 2 (RankIC 0.0298) identifies volume-price divergence; combining them targets 'hollow' volatility where high range occurs on low conviction.\n                Concise Justification: By dividing the intraday range-to-body ratio by the relative volume, we isolate periods where price 'travel' is high but 'efficiency' is low, signaling that the current trend is unsustainable due to a lack of volume-weighted cost basis.\n                Concise Knowledge: If a stock exhibits high intraday price volatility relative to its net open-to-close movement (asymmetry) while simultaneously experiencing low relative volume (hollow liquidity), then the price movement is likely driven by retail exhaustion rather than institutional conviction, leading to predictable reversals.\n                concise Specification: The SEE factor is calculated as (High-Low)/(abs(Close-Open) + epsilon) divided by (Volume / Rolling_Mean(Volume, 5)), smoothed over a 20-day window to capture persistent structural exhaustion while filtering for high-ATR regimes.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "54bba1c4e2b3",
      "parent_trajectory_ids": [
        "f0c2093c047e",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048152811794458,
        "ICIR": 0.0373798278647546,
        "RankIC": 0.0208149822955344,
        "RankICIR": 0.1635624640411027,
        "annualized_return": 0.0399757029352592,
        "information_ratio": 0.6571625664999783,
        "max_drawdown": -0.0882684243465727
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:45:37.553954",
      "updated_at": "2026-01-17T07:45:37.553960"
    },
    "56b4c928d1cab681": {
      "factor_id": "56b4c928d1cab681",
      "factor_name": "Relative_Range_Efficiency_Rank",
      "factor_expression": "RANK(TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Efficiency_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the exhaustion principle, focusing on the divergence between price range and volume intensity. It identifies stocks with the most disproportionate price travel relative to their liquidity support over a 10-day window.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the 20-day average of the ratio between intraday range-to-body asymmetry and 5-day relative volume intensity, identifies mean-reversion opportunities where price expansion is decoupled from liquidity support.\n                Concise Observation: Parent 1 (RankIC 0.0196) captures price-action indecision, while Parent 2 (RankIC 0.0298) identifies volume-price divergence; combining them targets 'hollow' volatility where high range occurs on low conviction.\n                Concise Justification: By dividing the intraday range-to-body ratio by the relative volume, we isolate periods where price 'travel' is high but 'efficiency' is low, signaling that the current trend is unsustainable due to a lack of volume-weighted cost basis.\n                Concise Knowledge: If a stock exhibits high intraday price volatility relative to its net open-to-close movement (asymmetry) while simultaneously experiencing low relative volume (hollow liquidity), then the price movement is likely driven by retail exhaustion rather than institutional conviction, leading to predictable reversals.\n                concise Specification: The SEE factor is calculated as (High-Low)/(abs(Close-Open) + epsilon) divided by (Volume / Rolling_Mean(Volume, 5)), smoothed over a 20-day window to capture persistent structural exhaustion while filtering for high-ATR regimes.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "54bba1c4e2b3",
      "parent_trajectory_ids": [
        "f0c2093c047e",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048152811794458,
        "ICIR": 0.0373798278647546,
        "RankIC": 0.0208149822955344,
        "RankICIR": 0.1635624640411027,
        "annualized_return": 0.0399757029352592,
        "information_ratio": 0.6571625664999783,
        "max_drawdown": -0.0882684243465727
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:45:37.583024",
      "updated_at": "2026-01-17T07:45:37.583030"
    },
    "f47dbbb5b1798846": {
      "factor_id": "f47dbbb5b1798846",
      "factor_name": "Hollow_Volatility_ZScore",
      "factor_expression": "TS_MEAN(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 15), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 15), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Volatility_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 15-day average of the ratio between price volatility (High-Low) and volume-weighted movement. It uses Z-score normalization to highlight extreme decoupling between price action and market participation.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Exhaustion Efficiency (SEE) factor, defined as the 20-day average of the ratio between intraday range-to-body asymmetry and 5-day relative volume intensity, identifies mean-reversion opportunities where price expansion is decoupled from liquidity support.\n                Concise Observation: Parent 1 (RankIC 0.0196) captures price-action indecision, while Parent 2 (RankIC 0.0298) identifies volume-price divergence; combining them targets 'hollow' volatility where high range occurs on low conviction.\n                Concise Justification: By dividing the intraday range-to-body ratio by the relative volume, we isolate periods where price 'travel' is high but 'efficiency' is low, signaling that the current trend is unsustainable due to a lack of volume-weighted cost basis.\n                Concise Knowledge: If a stock exhibits high intraday price volatility relative to its net open-to-close movement (asymmetry) while simultaneously experiencing low relative volume (hollow liquidity), then the price movement is likely driven by retail exhaustion rather than institutional conviction, leading to predictable reversals.\n                concise Specification: The SEE factor is calculated as (High-Low)/(abs(Close-Open) + epsilon) divided by (Volume / Rolling_Mean(Volume, 5)), smoothed over a 20-day window to capture persistent structural exhaustion while filtering for high-ATR regimes.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "54bba1c4e2b3",
      "parent_trajectory_ids": [
        "f0c2093c047e",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048152811794458,
        "ICIR": 0.0373798278647546,
        "RankIC": 0.0208149822955344,
        "RankICIR": 0.1635624640411027,
        "annualized_return": 0.0399757029352592,
        "information_ratio": 0.6571625664999783,
        "max_drawdown": -0.0882684243465727
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:45:37.611684",
      "updated_at": "2026-01-17T07:45:37.611690"
    },
    "c91c0cc9e19b6247": {
      "factor_id": "c91c0cc9e19b6247",
      "factor_name": "Informed_Liquidity_Absorption_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) / (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8)) / (TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Informed_Liquidity_Absorption_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional trends by calculating the ratio of the overnight gap (normalized by historical volatility) to the intraday price discovery efficiency. A high gap validated by low price-to-volume divergence suggests institutional absorption and trend persistence.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Absorption (ILA) factor, defined as the product of the overnight gap (normalized by 5-day intraday volatility) and the inverse of the 5-day Volatility-Volume Divergence Efficiency, identifies high-conviction institutional trends by rewarding gaps that are sustained by efficient, high-volume intraday price discovery.\n                Concise Observation: Parent 1 (IAG) captures pre-market intent but lacks intraday validation, while Parent 2 (VVDE) measures execution efficiency but ignores the signaling power of overnight positioning; combining them addresses the 'hollow move' problem in gap trading.\n                Concise Justification: Institutional players often express conviction through overnight positioning, but the sustainability of the resulting trend depends on whether intraday liquidity is sufficient to absorb the move without excessive volatility, a state captured by the ratio of gap magnitude to intraday efficiency.\n                Concise Knowledge: If an overnight price gap is validated by high volume relative to price range (low VVDE), it indicates institutional absorption and trend persistence; if a gap occurs with wide price swings on low volume (high VVDE), it indicates liquidity exhaustion and likely mean reversion.\n                concise Specification: The factor is calculated as (Gap / ATR_5) / (Range_5 / Volume_Rel_5), where Gap is (Open - Prev_Close), ATR_5 is the 5-day average true range, Range_5 is the 5-day average (High - Low), and Volume_Rel_5 is the 5-day average volume; a higher value predicts positive future returns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "df7dfd9db5e1",
      "parent_trajectory_ids": [
        "2c2098e706e5",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063747927182966,
        "ICIR": 0.0474726293488803,
        "RankIC": 0.0218360517214985,
        "RankICIR": 0.1675279251410049,
        "annualized_return": 0.0553551326154067,
        "information_ratio": 0.8556669485594854,
        "max_drawdown": -0.0968061621215196
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:48:28.530475",
      "updated_at": "2026-01-17T07:48:28.530481"
    },
    "70e549c8cea3371f": {
      "factor_id": "70e549c8cea3371f",
      "factor_name": "Institutional_Gap_Efficiency_Rank_10D",
      "factor_expression": "RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Efficiency_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the Informed Liquidity Absorption hypothesis. It measures the strength of the overnight gap relative to the 10-day volatility, divided by the efficiency of intraday price movement (range per unit of volume). Higher values indicate gaps that are more likely to be sustained by institutional liquidity.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Absorption (ILA) factor, defined as the product of the overnight gap (normalized by 5-day intraday volatility) and the inverse of the 5-day Volatility-Volume Divergence Efficiency, identifies high-conviction institutional trends by rewarding gaps that are sustained by efficient, high-volume intraday price discovery.\n                Concise Observation: Parent 1 (IAG) captures pre-market intent but lacks intraday validation, while Parent 2 (VVDE) measures execution efficiency but ignores the signaling power of overnight positioning; combining them addresses the 'hollow move' problem in gap trading.\n                Concise Justification: Institutional players often express conviction through overnight positioning, but the sustainability of the resulting trend depends on whether intraday liquidity is sufficient to absorb the move without excessive volatility, a state captured by the ratio of gap magnitude to intraday efficiency.\n                Concise Knowledge: If an overnight price gap is validated by high volume relative to price range (low VVDE), it indicates institutional absorption and trend persistence; if a gap occurs with wide price swings on low volume (high VVDE), it indicates liquidity exhaustion and likely mean reversion.\n                concise Specification: The factor is calculated as (Gap / ATR_5) / (Range_5 / Volume_Rel_5), where Gap is (Open - Prev_Close), ATR_5 is the 5-day average true range, Range_5 is the 5-day average (High - Low), and Volume_Rel_5 is the 5-day average volume; a higher value predicts positive future returns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "df7dfd9db5e1",
      "parent_trajectory_ids": [
        "2c2098e706e5",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063747927182966,
        "ICIR": 0.0474726293488803,
        "RankIC": 0.0218360517214985,
        "RankICIR": 0.1675279251410049,
        "annualized_return": 0.0553551326154067,
        "information_ratio": 0.8556669485594854,
        "max_drawdown": -0.0968061621215196
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:48:28.559726",
      "updated_at": "2026-01-17T07:48:28.559731"
    },
    "f3fe51235e211641": {
      "factor_id": "f3fe51235e211641",
      "factor_name": "Volatility_Volume_Divergence_Ratio_5D",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / (DELAY(TS_MEAN($high - $low, 5), 1) + 1e-8)) * TS_MEAN($volume, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / (DELAY(TS_MEAN($high - $low, 5), 1) + 1e-8)) * TS_MEAN($volume, 5)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Volume_Divergence_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the inverse of the Volatility-Volume Divergence Efficiency (VVDE) as part of the ILA hypothesis. It focuses on identifying periods where high volume supports small price ranges, suggesting efficient absorption of orders, normalized by the overnight gap signal.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Informed Liquidity Absorption (ILA) factor, defined as the product of the overnight gap (normalized by 5-day intraday volatility) and the inverse of the 5-day Volatility-Volume Divergence Efficiency, identifies high-conviction institutional trends by rewarding gaps that are sustained by efficient, high-volume intraday price discovery.\n                Concise Observation: Parent 1 (IAG) captures pre-market intent but lacks intraday validation, while Parent 2 (VVDE) measures execution efficiency but ignores the signaling power of overnight positioning; combining them addresses the 'hollow move' problem in gap trading.\n                Concise Justification: Institutional players often express conviction through overnight positioning, but the sustainability of the resulting trend depends on whether intraday liquidity is sufficient to absorb the move without excessive volatility, a state captured by the ratio of gap magnitude to intraday efficiency.\n                Concise Knowledge: If an overnight price gap is validated by high volume relative to price range (low VVDE), it indicates institutional absorption and trend persistence; if a gap occurs with wide price swings on low volume (high VVDE), it indicates liquidity exhaustion and likely mean reversion.\n                concise Specification: The factor is calculated as (Gap / ATR_5) / (Range_5 / Volume_Rel_5), where Gap is (Open - Prev_Close), ATR_5 is the 5-day average true range, Range_5 is the 5-day average (High - Low), and Volume_Rel_5 is the 5-day average volume; a higher value predicts positive future returns.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "df7dfd9db5e1",
      "parent_trajectory_ids": [
        "2c2098e706e5",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063747927182966,
        "ICIR": 0.0474726293488803,
        "RankIC": 0.0218360517214985,
        "RankICIR": 0.1675279251410049,
        "annualized_return": 0.0553551326154067,
        "information_ratio": 0.8556669485594854,
        "max_drawdown": -0.0968061621215196
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T07:48:28.592537",
      "updated_at": "2026-01-17T07:48:28.592543"
    },
    "9864a82513415328": {
      "factor_id": "9864a82513415328",
      "factor_name": "LAVPE_Efficiency_Ratio_10D",
      "factor_expression": "(TS_MEAN(($high - $low) / ($close + 1e-8), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(($high - $low) / ($close + 1e-8), 5) / (TS_MEAN($volume * ($high - $low) / ($close + 1e-8), 5) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"LAVPE_Efficiency_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the Linearity-Adjusted Volume-Price Efficiency (LAVPE) hypothesis. It measures price-volume decoupling by calculating the ratio of price range to volume-weighted range (energy), weighted by the linearity (R-squared) of the price trend. High linearity combined with low volume-weighted efficiency suggests structural exhaustion and potential mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Linearity-Adjusted Volume-Price Efficiency' (LAVPE) factor, defined as the ratio of 5-day ATR-normalized price range to 5-day volume-weighted volatility, scaled by the 10-day price-time R-squared, predicts mean reversion by identifying structural exhaustion in linear trends.\n                Concise Observation: Parent 1's trend linearity (RSQR10) identifies stable regimes, while Parent 2's efficiency ratio (VVDE) flags price-volume decoupling; combining them addresses the 'hollow expansion' observed when price moves exceed institutional backing.\n                Concise Justification: The 'Effort-vs-Result' principle suggests that price moves requiring disproportionately low or erratic volume-weighted energy are unsustainable; weighting this efficiency by trend linearity filters out noise and focuses on structural breakdown points.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) but low volume-weighted efficiency (range/volume-volatility), it is likely a liquidity-driven exhaustion point; When volume-weighted energy fails to support price expansion, the trend's structural integrity is compromised.\n                concise Specification: Calculate the 5-day average of (High-Low)/Close as price range, divide by the 5-day average of ($volume * (High-Low)/Close) for volume-weighted energy, and multiply by the 10-day R-squared of $close against a time index.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6d40bf7cdeda",
      "parent_trajectory_ids": [
        "b3f61a773f43",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030771522236266,
        "ICIR": 0.0227185928599906,
        "RankIC": 0.0192694488128021,
        "RankICIR": 0.1455545567998845,
        "annualized_return": 0.0327616494366824,
        "information_ratio": 0.4481053444880533,
        "max_drawdown": -0.0983948914523569
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:04:01.612595",
      "updated_at": "2026-01-17T08:04:01.612602"
    },
    "af25db02d368cf6f": {
      "factor_id": "af25db02d368cf6f",
      "factor_name": "Structural_Exhaustion_Index_5D",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($volume + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the LAVPE hypothesis focusing on the 'Effort-vs-Result' principle. It identifies 'hollow expansions' where price range is high relative to the volume-weighted energy, normalized by the cross-sectional rank of trend linearity to focus on the most stable regimes.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Linearity-Adjusted Volume-Price Efficiency' (LAVPE) factor, defined as the ratio of 5-day ATR-normalized price range to 5-day volume-weighted volatility, scaled by the 10-day price-time R-squared, predicts mean reversion by identifying structural exhaustion in linear trends.\n                Concise Observation: Parent 1's trend linearity (RSQR10) identifies stable regimes, while Parent 2's efficiency ratio (VVDE) flags price-volume decoupling; combining them addresses the 'hollow expansion' observed when price moves exceed institutional backing.\n                Concise Justification: The 'Effort-vs-Result' principle suggests that price moves requiring disproportionately low or erratic volume-weighted energy are unsustainable; weighting this efficiency by trend linearity filters out noise and focuses on structural breakdown points.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) but low volume-weighted efficiency (range/volume-volatility), it is likely a liquidity-driven exhaustion point; When volume-weighted energy fails to support price expansion, the trend's structural integrity is compromised.\n                concise Specification: Calculate the 5-day average of (High-Low)/Close as price range, divide by the 5-day average of ($volume * (High-Low)/Close) for volume-weighted energy, and multiply by the 10-day R-squared of $close against a time index.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6d40bf7cdeda",
      "parent_trajectory_ids": [
        "b3f61a773f43",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030771522236266,
        "ICIR": 0.0227185928599906,
        "RankIC": 0.0192694488128021,
        "RankICIR": 0.1455545567998845,
        "annualized_return": 0.0327616494366824,
        "information_ratio": 0.4481053444880533,
        "max_drawdown": -0.0983948914523569
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:04:01.641847",
      "updated_at": "2026-01-17T08:04:01.641853"
    },
    "fff9f0a8c12cc53a": {
      "factor_id": "fff9f0a8c12cc53a",
      "factor_name": "Volume_Weighted_Efficiency_ZScore",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume * ($high - $low) + 1e-8), 5) * TS_CORR($close, SEQUENCE(10), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume * ($high - $low) + 1e-8), 5) * TS_CORR($close, SEQUENCE(10), 10)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Efficiency_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the decoupling between price movement and institutional backing by calculating the Z-score of the ratio between price range and volume-weighted range over a 5-day window, then scaling it by the linearity of the 10-day price trend.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Linearity-Adjusted Volume-Price Efficiency' (LAVPE) factor, defined as the ratio of 5-day ATR-normalized price range to 5-day volume-weighted volatility, scaled by the 10-day price-time R-squared, predicts mean reversion by identifying structural exhaustion in linear trends.\n                Concise Observation: Parent 1's trend linearity (RSQR10) identifies stable regimes, while Parent 2's efficiency ratio (VVDE) flags price-volume decoupling; combining them addresses the 'hollow expansion' observed when price moves exceed institutional backing.\n                Concise Justification: The 'Effort-vs-Result' principle suggests that price moves requiring disproportionately low or erratic volume-weighted energy are unsustainable; weighting this efficiency by trend linearity filters out noise and focuses on structural breakdown points.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) but low volume-weighted efficiency (range/volume-volatility), it is likely a liquidity-driven exhaustion point; When volume-weighted energy fails to support price expansion, the trend's structural integrity is compromised.\n                concise Specification: Calculate the 5-day average of (High-Low)/Close as price range, divide by the 5-day average of ($volume * (High-Low)/Close) for volume-weighted energy, and multiply by the 10-day R-squared of $close against a time index.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6d40bf7cdeda",
      "parent_trajectory_ids": [
        "b3f61a773f43",
        "7fb27aabe9cd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0030771522236266,
        "ICIR": 0.0227185928599906,
        "RankIC": 0.0192694488128021,
        "RankICIR": 0.1455545567998845,
        "annualized_return": 0.0327616494366824,
        "information_ratio": 0.4481053444880533,
        "max_drawdown": -0.0983948914523569
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:04:01.670835",
      "updated_at": "2026-01-17T08:04:01.670841"
    },
    "b4b942eb0eb8463e": {
      "factor_id": "b4b942eb0eb8463e",
      "factor_name": "LAHEI_Hollow_Expansion_5D",
      "factor_expression": "(($high - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) * (($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) * (($close - ($open + $close + $high + $low) / 4) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LAHEI_Hollow_Expansion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Liquidity-Adjusted Hollow Expansion Index identifies price expansions where the closing price deviates significantly from the volume-weighted center of gravity (approximated by the daily mean price). A high value indicates a 'hollow' move likely driven by liquidity gaps, suggesting a short-term mean reversion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Hollow Expansion Index (LAHEI), defined as the product of the ATR-normalized intraday range and the distance between the daily close and the Volume-Weighted Average Price (VWAP), identifies price 'hollows' that predict short-term mean reversion.\n                Concise Observation: Parent strategies showed that intraday price positioning relative to volume (RankIC 0.018) and volatility-normalized volume divergence (RankIC 0.030) are both predictive; combining them addresses the weakness of volume-only or price-only exhaustion signals.\n                Concise Justification: By multiplying the range-based volatility (from Parent 2) with the VWAP-to-Close deviation (from Parent 1), we isolate instances where price moved significantly but the 'center of gravity' of trading volume failed to follow, indicating a lack of structural support.\n                Concise Knowledge: If a large price expansion occurs with a significant gap between the closing price and the volume-weighted average price, the move is likely driven by liquidity voids rather than institutional conviction; when such 'hollow' moves occur, they tend to revert as liquidity stabilizes.\n                concise Specification: The factor is calculated as [(High - Low) / ATR(5)] * [(Close - VWAP) / (High - Low)], where VWAP is approximated as (Open+Close+High+Low)/4, focusing on the 5-day lookback period for volatility normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ab0815655d5d",
      "parent_trajectory_ids": [
        "94f4a684161a",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049273018425848,
        "ICIR": 0.0332149350767551,
        "RankIC": 0.020188325843943,
        "RankICIR": 0.1407029517125129,
        "annualized_return": 0.0657937117078128,
        "information_ratio": 0.9010570874521956,
        "max_drawdown": -0.0985490242912436
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:06:48.367102",
      "updated_at": "2026-01-17T08:06:48.367109"
    },
    "8cee304738fda193": {
      "factor_id": "8cee304738fda193",
      "factor_name": "ZScore_VWAP_Deviation_Range_10D",
      "factor_expression": "RANK(TS_ZSCORE($high - $low, 10)) * RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($high - $low, 10)) * RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_VWAP_Deviation_Range_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the hollow expansion hypothesis that uses cross-sectional ranking to identify stocks where the intraday price range is large relative to its recent history, and the price has closed far from the intraday mid-point, signaling potential exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Hollow Expansion Index (LAHEI), defined as the product of the ATR-normalized intraday range and the distance between the daily close and the Volume-Weighted Average Price (VWAP), identifies price 'hollows' that predict short-term mean reversion.\n                Concise Observation: Parent strategies showed that intraday price positioning relative to volume (RankIC 0.018) and volatility-normalized volume divergence (RankIC 0.030) are both predictive; combining them addresses the weakness of volume-only or price-only exhaustion signals.\n                Concise Justification: By multiplying the range-based volatility (from Parent 2) with the VWAP-to-Close deviation (from Parent 1), we isolate instances where price moved significantly but the 'center of gravity' of trading volume failed to follow, indicating a lack of structural support.\n                Concise Knowledge: If a large price expansion occurs with a significant gap between the closing price and the volume-weighted average price, the move is likely driven by liquidity voids rather than institutional conviction; when such 'hollow' moves occur, they tend to revert as liquidity stabilizes.\n                concise Specification: The factor is calculated as [(High - Low) / ATR(5)] * [(Close - VWAP) / (High - Low)], where VWAP is approximated as (Open+Close+High+Low)/4, focusing on the 5-day lookback period for volatility normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ab0815655d5d",
      "parent_trajectory_ids": [
        "94f4a684161a",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049273018425848,
        "ICIR": 0.0332149350767551,
        "RankIC": 0.020188325843943,
        "RankICIR": 0.1407029517125129,
        "annualized_return": 0.0657937117078128,
        "information_ratio": 0.9010570874521956,
        "max_drawdown": -0.0985490242912436
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:06:48.396749",
      "updated_at": "2026-01-17T08:06:48.396755"
    },
    "aece3d4216d0e360": {
      "factor_id": "aece3d4216d0e360",
      "factor_name": "Hollow_Move_Exhaustion_Index_5D",
      "factor_expression": "TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($high - $low + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - ($open + $high + $low + $close) / 4) / ($high - $low + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_Exhaustion_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price exhaustion by measuring the ratio of the distance between the close and the daily mean to the total range, smoothed over 5 days to identify persistent liquidity-driven price voids.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Liquidity-Adjusted Hollow Expansion Index (LAHEI), defined as the product of the ATR-normalized intraday range and the distance between the daily close and the Volume-Weighted Average Price (VWAP), identifies price 'hollows' that predict short-term mean reversion.\n                Concise Observation: Parent strategies showed that intraday price positioning relative to volume (RankIC 0.018) and volatility-normalized volume divergence (RankIC 0.030) are both predictive; combining them addresses the weakness of volume-only or price-only exhaustion signals.\n                Concise Justification: By multiplying the range-based volatility (from Parent 2) with the VWAP-to-Close deviation (from Parent 1), we isolate instances where price moved significantly but the 'center of gravity' of trading volume failed to follow, indicating a lack of structural support.\n                Concise Knowledge: If a large price expansion occurs with a significant gap between the closing price and the volume-weighted average price, the move is likely driven by liquidity voids rather than institutional conviction; when such 'hollow' moves occur, they tend to revert as liquidity stabilizes.\n                concise Specification: The factor is calculated as [(High - Low) / ATR(5)] * [(Close - VWAP) / (High - Low)], where VWAP is approximated as (Open+Close+High+Low)/4, focusing on the 5-day lookback period for volatility normalization.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "ab0815655d5d",
      "parent_trajectory_ids": [
        "94f4a684161a",
        "7fb27aabe9cd"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0049273018425848,
        "ICIR": 0.0332149350767551,
        "RankIC": 0.020188325843943,
        "RankICIR": 0.1407029517125129,
        "annualized_return": 0.0657937117078128,
        "information_ratio": 0.9010570874521956,
        "max_drawdown": -0.0985490242912436
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:06:48.426075",
      "updated_at": "2026-01-17T08:06:48.426081"
    },
    "234ecf17f52471e1": {
      "factor_id": "234ecf17f52471e1",
      "factor_name": "Inst_Gap_Persistence_V1",
      "factor_expression": "(TS_ZSCORE(($close-$open)/$open, 5) / (TS_STD($open - DELAY($close, 1), 5) + 1e-8)) * TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / ($close + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SKEW(($close - $open) / $open, 5) / (TS_STD(($open - DELAY($close, 1)) / DELAY($close, 1), 5) + 1e-8)) * TS_CORR($close, $volume, 20) * (TS_MEAN($high - $low, 14) / $close)\" # Your output factor expression will be filled in here\n    name = \"Inst_Gap_Persistence_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies institutional accumulation by combining intraday return skewness relative to overnight volatility with price-volume correlation. Low skewness relative to gap volatility suggests 'quiet' informed flow, while high price-volume correlation confirms structural trend conviction.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Gap-Persistence' factor identifies sustainable price movements by multiplying the 5-day ratio of intraday return skewness to overnight volatility with the 20-day price-volume correlation, scaled by the 14-day price range, to distinguish institutional accumulation from noise.\n                Concise Observation: Parent 1 (RankIC 0.022) captures short-term informed flow via distribution shapes, while Parent 2 (RankIC 0.031) captures medium-term structural liquidity; combining them addresses the noise inherent in overnight gaps by filtering them through intraday persistence metrics.\n                Concise Justification: Institutional investors often hide their trades intraday (low skewness) while their impact is felt in overnight gaps and volume-price alignment; multiplying these cross-dimensional metrics creates a regime-adaptive signal that rewards consistency across multiple time horizons.\n                Concise Knowledge: If short-term intraday skewness is low relative to overnight volatility, it indicates institutional 'quiet' accumulation; when this aligns with a strong 20-day price-volume correlation, the resulting signal identifies high-conviction structural trends rather than temporary liquidity traps.\n                concise Specification: The factor is defined as (5-day Intraday Skew / 5-day StdDev of (Open - PrevClose)) * (20-day Correlation of Close and Volume) * (14-day ATR / Close), where ATR is the 14-day average of (High - Low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "94e2b000cf8b",
      "parent_trajectory_ids": [
        "8b13845457df",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.006797536530237,
        "ICIR": 0.0514909043766003,
        "RankIC": 0.0213743344969453,
        "RankICIR": 0.1644779678783632,
        "annualized_return": 0.0541896324471593,
        "information_ratio": 0.7837050863467108,
        "max_drawdown": -0.1641871046121855
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:08:12.502814",
      "updated_at": "2026-01-17T08:08:12.502821"
    },
    "c31fecd25d09b27a": {
      "factor_id": "c31fecd25d09b27a",
      "factor_name": "Institutional_Quiet_Flow_20D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 20)) * RANK(($high - $low) / (TS_STD($close, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Quiet_Flow_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the institutional persistence hypothesis focusing on the ratio of price range stability to volume-driven price movement. It uses RANK to normalize the components across the cross-section to ensure robustness against market-wide volatility spikes.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Gap-Persistence' factor identifies sustainable price movements by multiplying the 5-day ratio of intraday return skewness to overnight volatility with the 20-day price-volume correlation, scaled by the 14-day price range, to distinguish institutional accumulation from noise.\n                Concise Observation: Parent 1 (RankIC 0.022) captures short-term informed flow via distribution shapes, while Parent 2 (RankIC 0.031) captures medium-term structural liquidity; combining them addresses the noise inherent in overnight gaps by filtering them through intraday persistence metrics.\n                Concise Justification: Institutional investors often hide their trades intraday (low skewness) while their impact is felt in overnight gaps and volume-price alignment; multiplying these cross-dimensional metrics creates a regime-adaptive signal that rewards consistency across multiple time horizons.\n                Concise Knowledge: If short-term intraday skewness is low relative to overnight volatility, it indicates institutional 'quiet' accumulation; when this aligns with a strong 20-day price-volume correlation, the resulting signal identifies high-conviction structural trends rather than temporary liquidity traps.\n                concise Specification: The factor is defined as (5-day Intraday Skew / 5-day StdDev of (Open - PrevClose)) * (20-day Correlation of Close and Volume) * (14-day ATR / Close), where ATR is the 14-day average of (High - Low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "94e2b000cf8b",
      "parent_trajectory_ids": [
        "8b13845457df",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.006797536530237,
        "ICIR": 0.0514909043766003,
        "RankIC": 0.0213743344969453,
        "RankICIR": 0.1644779678783632,
        "annualized_return": 0.0541896324471593,
        "information_ratio": 0.7837050863467108,
        "max_drawdown": -0.1641871046121855
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:08:12.532584",
      "updated_at": "2026-01-17T08:08:12.532590"
    },
    "3162184d49f077b4": {
      "factor_id": "3162184d49f077b4",
      "factor_name": "Gap_Trend_Alignment_14D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close - $open, $volume, 14)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) * TS_CORR($close - $open, $volume, 14)\" # Your output factor expression will be filled in here\n    name = \"Gap_Trend_Alignment_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the alignment between overnight price gaps and the subsequent intraday range, scaled by volume conviction. It targets stocks where the gap is supported by consistent price-volume behavior rather than speculative noise.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional Gap-Persistence' factor identifies sustainable price movements by multiplying the 5-day ratio of intraday return skewness to overnight volatility with the 20-day price-volume correlation, scaled by the 14-day price range, to distinguish institutional accumulation from noise.\n                Concise Observation: Parent 1 (RankIC 0.022) captures short-term informed flow via distribution shapes, while Parent 2 (RankIC 0.031) captures medium-term structural liquidity; combining them addresses the noise inherent in overnight gaps by filtering them through intraday persistence metrics.\n                Concise Justification: Institutional investors often hide their trades intraday (low skewness) while their impact is felt in overnight gaps and volume-price alignment; multiplying these cross-dimensional metrics creates a regime-adaptive signal that rewards consistency across multiple time horizons.\n                Concise Knowledge: If short-term intraday skewness is low relative to overnight volatility, it indicates institutional 'quiet' accumulation; when this aligns with a strong 20-day price-volume correlation, the resulting signal identifies high-conviction structural trends rather than temporary liquidity traps.\n                concise Specification: The factor is defined as (5-day Intraday Skew / 5-day StdDev of (Open - PrevClose)) * (20-day Correlation of Close and Volume) * (14-day ATR / Close), where ATR is the 14-day average of (High - Low).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "94e2b000cf8b",
      "parent_trajectory_ids": [
        "8b13845457df",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.006797536530237,
        "ICIR": 0.0514909043766003,
        "RankIC": 0.0213743344969453,
        "RankICIR": 0.1644779678783632,
        "annualized_return": 0.0541896324471593,
        "information_ratio": 0.7837050863467108,
        "max_drawdown": -0.1641871046121855
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:08:12.562042",
      "updated_at": "2026-01-17T08:08:12.562048"
    },
    "2053467206340414": {
      "factor_id": "2053467206340414",
      "factor_name": "Institutional_Gap_Exhaustion_20D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) / ((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) + 1e-8)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) / ((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) + 1e-8)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by weighting the overnight gap with the inverse of the Institutional Commitment Persistence (ICP). ICP is defined as the ratio of volume volatility (CV) to price range volatility (CV). A high gap with low institutional commitment (high ICP inverse) suggests a retail-driven exhaustion gap likely to reverse.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional-Anchored Gap Exhaustion factor identifies mean-reversion opportunities by multiplying the overnight gap by the inverse of the Institutional Commitment Persistence (ICP) ratio, where ICP is the 20-day ratio of volume coefficient of variation to price range coefficient of variation.\n                Concise Observation: Parent strategies show that volume-price stability ratios (RankIC 0.022) and intraday-adjusted gaps (RankIC 0.025) both capture market conviction, but gaps often fail when they align with strong institutional trends.\n                Concise Justification: By weighting the overnight gap with the inverse of the ICP ratio, we suppress signals where institutional support is high (trend continuation) and amplify signals where gaps occur amidst speculative noise (mean reversion).\n                Concise Knowledge: If a price gap is accompanied by low institutional commitment (high price volatility relative to volume stability), it is likely a retail-driven exhaustion gap prone to reversal; conversely, high institutional commitment suggests a breakaway gap that persists.\n                concise Specification: Calculate the overnight gap (Open/Close_prev - 1), the ICP ratio (std(volume)/mean(volume) divided by std(high-low)/mean(high-low) over 20 days), and define the factor as Gap / ICP_20d.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "dc81b9f456d5",
      "parent_trajectory_ids": [
        "7a86a1bcdb62",
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064552567567684,
        "ICIR": 0.0489313919474272,
        "RankIC": 0.0243504580851714,
        "RankICIR": 0.1871340713676423,
        "annualized_return": 0.0702566002458133,
        "information_ratio": 1.074291924942996,
        "max_drawdown": -0.0971841268829109
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:11:30.903168",
      "updated_at": "2026-01-17T08:11:30.903175"
    },
    "31c17d6a34d909b4": {
      "factor_id": "31c17d6a34d909b4",
      "factor_name": "Ranked_Gap_Institutional_Reversion_20D",
      "factor_expression": "RANK(($open / DELAY($close, 1)) - 1) * RANK((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1)) - 1) * RANK((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) / ((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_Institutional_Reversion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the Institutional Gap Exhaustion factor. It compares the overnight gap against the relative stability of volume versus price range. By using RANK, it normalizes the gap and the institutional commitment ratio to identify the most significant mean-reversion candidates across the universe.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional-Anchored Gap Exhaustion factor identifies mean-reversion opportunities by multiplying the overnight gap by the inverse of the Institutional Commitment Persistence (ICP) ratio, where ICP is the 20-day ratio of volume coefficient of variation to price range coefficient of variation.\n                Concise Observation: Parent strategies show that volume-price stability ratios (RankIC 0.022) and intraday-adjusted gaps (RankIC 0.025) both capture market conviction, but gaps often fail when they align with strong institutional trends.\n                Concise Justification: By weighting the overnight gap with the inverse of the ICP ratio, we suppress signals where institutional support is high (trend continuation) and amplify signals where gaps occur amidst speculative noise (mean reversion).\n                Concise Knowledge: If a price gap is accompanied by low institutional commitment (high price volatility relative to volume stability), it is likely a retail-driven exhaustion gap prone to reversal; conversely, high institutional commitment suggests a breakaway gap that persists.\n                concise Specification: Calculate the overnight gap (Open/Close_prev - 1), the ICP ratio (std(volume)/mean(volume) divided by std(high-low)/mean(high-low) over 20 days), and define the factor as Gap / ICP_20d.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "dc81b9f456d5",
      "parent_trajectory_ids": [
        "7a86a1bcdb62",
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064552567567684,
        "ICIR": 0.0489313919474272,
        "RankIC": 0.0243504580851714,
        "RankICIR": 0.1871340713676423,
        "annualized_return": 0.0702566002458133,
        "information_ratio": 1.074291924942996,
        "max_drawdown": -0.0971841268829109
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:11:30.933185",
      "updated_at": "2026-01-17T08:11:30.933191"
    },
    "3bb4752cea3296f5": {
      "factor_id": "3bb4752cea3296f5",
      "factor_name": "Smoothed_Institutional_Gap_Exhaustion_10D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / SMA((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) / ((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) + 1e-8), 10, 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / SMA((TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) / ((TS_STD($high - $low, 20) / (TS_MEAN($high - $low, 20) + 1e-8)) + 1e-8), 10, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Institutional_Gap_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor applies a 10-day simple moving average to the Institutional Commitment Persistence ratio to provide a more stable signal of institutional anchoring, reducing noise in the gap exhaustion identification.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional-Anchored Gap Exhaustion factor identifies mean-reversion opportunities by multiplying the overnight gap by the inverse of the Institutional Commitment Persistence (ICP) ratio, where ICP is the 20-day ratio of volume coefficient of variation to price range coefficient of variation.\n                Concise Observation: Parent strategies show that volume-price stability ratios (RankIC 0.022) and intraday-adjusted gaps (RankIC 0.025) both capture market conviction, but gaps often fail when they align with strong institutional trends.\n                Concise Justification: By weighting the overnight gap with the inverse of the ICP ratio, we suppress signals where institutional support is high (trend continuation) and amplify signals where gaps occur amidst speculative noise (mean reversion).\n                Concise Knowledge: If a price gap is accompanied by low institutional commitment (high price volatility relative to volume stability), it is likely a retail-driven exhaustion gap prone to reversal; conversely, high institutional commitment suggests a breakaway gap that persists.\n                concise Specification: Calculate the overnight gap (Open/Close_prev - 1), the ICP ratio (std(volume)/mean(volume) divided by std(high-low)/mean(high-low) over 20 days), and define the factor as Gap / ICP_20d.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "dc81b9f456d5",
      "parent_trajectory_ids": [
        "7a86a1bcdb62",
        "db4bb8b2509e"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0064552567567684,
        "ICIR": 0.0489313919474272,
        "RankIC": 0.0243504580851714,
        "RankICIR": 0.1871340713676423,
        "annualized_return": 0.0702566002458133,
        "information_ratio": 1.074291924942996,
        "max_drawdown": -0.0971841268829109
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:11:30.963158",
      "updated_at": "2026-01-17T08:11:30.963164"
    },
    "b9a08347802a4c0a": {
      "factor_id": "b9a08347802a4c0a",
      "factor_name": "SLVR_Structural_Exhaustion_5D",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-5)) * RANK(TS_CORR($close, $volume, 20)) * ZSCORE(ABS($return) / ($volume + 1e-5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-9), 5)) * RANK(TS_CORR($close, $volume, 20)) * ZSCORE(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-9), 5))\" # Your output factor expression will be filled in here\n    name = \"SLVR_Structural_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by combining intraday price dispersion, price-volume correlation decay, and illiquidity. This version focuses on the 5-day interaction between range-to-volume and Amihud illiquidity, moderated by the 20-day price-volume correlation to identify unsustainable exhaustion.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by multiplying the 5-day intraday price dispersion (High-Low range normalized by Volume) with the 20-day negative price-volume correlation, further scaled by a 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1 successfully captured intraday exhaustion (RankIC 0.0268) and Parent 2 captured structural decay (RankIC 0.0266), but both suffer from false positives during high-volume trend breakouts where price-volume synergy remains intact.\n                Concise Justification: Fusing these metrics ensures that high volatility is only traded as a reversal if it lacks structural support (negative correlation) and occurs in a high-impact environment (Amihud), filtering out healthy trend continuations.\n                Concise Knowledge: If extreme intraday price volatility occurs while price-volume synergy is decaying and illiquidity is peaking, then the price movement is likely a 'liquidity vacuum' spike prone to reversal; When high range-to-volume ratios coincide with negative price-volume correlation, market participants are exhausted.\n                concise Specification: The factor is defined as: Rank((High-Low)/(Volume+1e-5), 5) * Rank(Correlation(Close, Volume, 20), 20) * ZScore((Abs(Return)/Volume), 5). It expects a negative relationship with future returns as high values indicate unsustainable exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ef9400abf2",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "8b31cd9afab3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067035766755135,
        "ICIR": 0.0465146591916888,
        "RankIC": 0.0229687226052108,
        "RankICIR": 0.1598980304505583,
        "annualized_return": 0.006762518040761,
        "information_ratio": 0.0919589333845521,
        "max_drawdown": -0.1258508606308615
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:15:46.032114",
      "updated_at": "2026-01-17T08:15:46.032121"
    },
    "344815c17b246ca5": {
      "factor_id": "344815c17b246ca5",
      "factor_name": "Liquidity_Vacuum_Intensity_10D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-5), 5)) * RANK(TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK(TS_MEAN(($high - $low) / ($volume + 1e-5), 5)) * RANK(1 - TS_CORR($close, $volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the SLVR hypothesis that measures the intensity of a liquidity vacuum. It captures the divergence between price volatility and volume support, specifically looking for high range/volume ratios when price-volume correlation is low (exhaustion), standardized cross-sectionally.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by multiplying the 5-day intraday price dispersion (High-Low range normalized by Volume) with the 20-day negative price-volume correlation, further scaled by a 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1 successfully captured intraday exhaustion (RankIC 0.0268) and Parent 2 captured structural decay (RankIC 0.0266), but both suffer from false positives during high-volume trend breakouts where price-volume synergy remains intact.\n                Concise Justification: Fusing these metrics ensures that high volatility is only traded as a reversal if it lacks structural support (negative correlation) and occurs in a high-impact environment (Amihud), filtering out healthy trend continuations.\n                Concise Knowledge: If extreme intraday price volatility occurs while price-volume synergy is decaying and illiquidity is peaking, then the price movement is likely a 'liquidity vacuum' spike prone to reversal; When high range-to-volume ratios coincide with negative price-volume correlation, market participants are exhausted.\n                concise Specification: The factor is defined as: Rank((High-Low)/(Volume+1e-5), 5) * Rank(Correlation(Close, Volume, 20), 20) * ZScore((Abs(Return)/Volume), 5). It expects a negative relationship with future returns as high values indicate unsustainable exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ef9400abf2",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "8b31cd9afab3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067035766755135,
        "ICIR": 0.0465146591916888,
        "RankIC": 0.0229687226052108,
        "RankICIR": 0.1598980304505583,
        "annualized_return": 0.006762518040761,
        "information_ratio": 0.0919589333845521,
        "max_drawdown": -0.1258508606308615
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:15:46.061947",
      "updated_at": "2026-01-17T08:15:46.061953"
    },
    "adb04d205aaddcce": {
      "factor_id": "adb04d205aaddcce",
      "factor_name": "Amihud_Exhaustion_Reversal_20D",
      "factor_expression": "RANK(TS_ZSCORE(ABS($return) / ($volume + 1e-5), 5)) * RANK(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-5), 5)) * RANK(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Exhaustion_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Illiquidity Z-score' component of the SLVR hypothesis. It identifies stocks where the current return-to-volume ratio (Amihud Illiquidity) is an outlier relative to its own history, filtered by the 20-day price-volume trend to catch reversal points.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversal (SLVR) factor identifies mean-reversion signals by multiplying the 5-day intraday price dispersion (High-Low range normalized by Volume) with the 20-day negative price-volume correlation, further scaled by a 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1 successfully captured intraday exhaustion (RankIC 0.0268) and Parent 2 captured structural decay (RankIC 0.0266), but both suffer from false positives during high-volume trend breakouts where price-volume synergy remains intact.\n                Concise Justification: Fusing these metrics ensures that high volatility is only traded as a reversal if it lacks structural support (negative correlation) and occurs in a high-impact environment (Amihud), filtering out healthy trend continuations.\n                Concise Knowledge: If extreme intraday price volatility occurs while price-volume synergy is decaying and illiquidity is peaking, then the price movement is likely a 'liquidity vacuum' spike prone to reversal; When high range-to-volume ratios coincide with negative price-volume correlation, market participants are exhausted.\n                concise Specification: The factor is defined as: Rank((High-Low)/(Volume+1e-5), 5) * Rank(Correlation(Close, Volume, 20), 20) * ZScore((Abs(Return)/Volume), 5). It expects a negative relationship with future returns as high values indicate unsustainable exhaustion.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "38ef9400abf2",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "8b31cd9afab3"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067035766755135,
        "ICIR": 0.0465146591916888,
        "RankIC": 0.0229687226052108,
        "RankICIR": 0.1598980304505583,
        "annualized_return": 0.006762518040761,
        "information_ratio": 0.0919589333845521,
        "max_drawdown": -0.1258508606308615
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:15:46.091344",
      "updated_at": "2026-01-17T08:15:46.091350"
    },
    "2271e15798e03902": {
      "factor_id": "2271e15798e03902",
      "factor_name": "IRSF_Structural_Friction_5D",
      "factor_expression": "ZSCORE((($high - $low) / $close) / ($volume / (TS_MEAN($volume, 20) + 1e-8))) * (-1 * TS_CORR($return, DELTA($volume, 1), 20)) * ZSCORE(ABS($return) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / ($volume / TS_MEAN($volume, 20))) * (-1 * TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20)) * ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / $volume)\" # Your output factor expression will be filled in here\n    name = \"IRSF_Structural_Friction_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The Institutional-Retail Structural Friction (IRSF) factor identifies high-probability reversals by combining a 5-day Mean-Reverting Liquidity Vacuum (MRLV) with 20-day price-volume divergence, scaled by the Amihud Illiquidity Z-score. It targets 'hollow' volatility spikes in thin markets where price moves lack institutional support.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Retail Structural Friction' (IRSF) factor identifies high-probability reversals by multiplying the 5-day Mean-Reverting Liquidity Vacuum (MRLV) with the 20-day negative price-volume correlation, weighted by the 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1's MRLV (RankIC 0.0262) captures micro-exhaustion, while Parent 2's divergence (RankIC 0.0266) captures structural decay; combining them targets 'hollow' volatility spikes in thin markets where price discovery is inefficient.\n                Concise Justification: The MRLV identifies the 'exhaustion' trigger, while the negative price-volume correlation ensures the move is a 'divergence' from fundamental accumulation, and the Amihud Z-score scales the signal by the difficulty of price maintenance in low-liquidity environments.\n                Concise Knowledge: If short-term price range expansion occurs on declining relative volume (Liquidity Vacuum) while the medium-term trend shows negative price-volume correlation, the price move is likely retail-driven and prone to reversal; when these conditions coincide with high illiquidity, the mean-reversion effect is amplified due to the lack of institutional support.\n                concise Specification: Define MRLV as (High-Low)/Close divided by (Volume/SMA(Volume,20)) over 5 days; calculate the 20-day correlation between daily returns and volume changes; multiply the Z-scored MRLV by the negative correlation and the 5-day Amihud Illiquidity ratio (abs(return)/volume).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b7098cdae6bc",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073375787075466,
        "ICIR": 0.0532128482617706,
        "RankIC": 0.024067797281387,
        "RankICIR": 0.1764820283550209,
        "annualized_return": 0.078373715075335,
        "information_ratio": 1.099977462153051,
        "max_drawdown": -0.1230286729484408
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:28.165735",
      "updated_at": "2026-01-17T08:22:28.165742"
    },
    "348629c09066e01e": {
      "factor_id": "348629c09066e01e",
      "factor_name": "MRLV_Exhaustion_Trigger",
      "factor_expression": "RANK(($high - $low) / $close) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / $close) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MRLV_Exhaustion_Trigger\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Mean-Reverting Liquidity Vacuum (MRLV) focusing on micro-exhaustion. It measures price range expansion relative to normalized volume, identifying instances where price moves are 'thin' and likely to reverse due to lack of liquidity depth.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Retail Structural Friction' (IRSF) factor identifies high-probability reversals by multiplying the 5-day Mean-Reverting Liquidity Vacuum (MRLV) with the 20-day negative price-volume correlation, weighted by the 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1's MRLV (RankIC 0.0262) captures micro-exhaustion, while Parent 2's divergence (RankIC 0.0266) captures structural decay; combining them targets 'hollow' volatility spikes in thin markets where price discovery is inefficient.\n                Concise Justification: The MRLV identifies the 'exhaustion' trigger, while the negative price-volume correlation ensures the move is a 'divergence' from fundamental accumulation, and the Amihud Z-score scales the signal by the difficulty of price maintenance in low-liquidity environments.\n                Concise Knowledge: If short-term price range expansion occurs on declining relative volume (Liquidity Vacuum) while the medium-term trend shows negative price-volume correlation, the price move is likely retail-driven and prone to reversal; when these conditions coincide with high illiquidity, the mean-reversion effect is amplified due to the lack of institutional support.\n                concise Specification: Define MRLV as (High-Low)/Close divided by (Volume/SMA(Volume,20)) over 5 days; calculate the 20-day correlation between daily returns and volume changes; multiply the Z-scored MRLV by the negative correlation and the 5-day Amihud Illiquidity ratio (abs(return)/volume).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b7098cdae6bc",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073375787075466,
        "ICIR": 0.0532128482617706,
        "RankIC": 0.024067797281387,
        "RankICIR": 0.1764820283550209,
        "annualized_return": 0.078373715075335,
        "information_ratio": 1.099977462153051,
        "max_drawdown": -0.1230286729484408
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:28.195795",
      "updated_at": "2026-01-17T08:22:28.195801"
    },
    "935737e4c24adabd": {
      "factor_id": "935737e4c24adabd",
      "factor_name": "Amihud_Divergence_Reversal",
      "factor_expression": "(-1 * TS_CORR($return, DELTA($volume, 1), 20)) * RANK(ABS($return) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20)) * RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Divergence_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures structural decay by multiplying the negative correlation between returns and volume changes with the cross-sectional rank of the Amihud illiquidity ratio. It highlights assets where price trends are diverging from volume support in illiquid conditions.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Institutional-Retail Structural Friction' (IRSF) factor identifies high-probability reversals by multiplying the 5-day Mean-Reverting Liquidity Vacuum (MRLV) with the 20-day negative price-volume correlation, weighted by the 5-day Amihud Illiquidity Z-score.\n                Concise Observation: Parent 1's MRLV (RankIC 0.0262) captures micro-exhaustion, while Parent 2's divergence (RankIC 0.0266) captures structural decay; combining them targets 'hollow' volatility spikes in thin markets where price discovery is inefficient.\n                Concise Justification: The MRLV identifies the 'exhaustion' trigger, while the negative price-volume correlation ensures the move is a 'divergence' from fundamental accumulation, and the Amihud Z-score scales the signal by the difficulty of price maintenance in low-liquidity environments.\n                Concise Knowledge: If short-term price range expansion occurs on declining relative volume (Liquidity Vacuum) while the medium-term trend shows negative price-volume correlation, the price move is likely retail-driven and prone to reversal; when these conditions coincide with high illiquidity, the mean-reversion effect is amplified due to the lack of institutional support.\n                concise Specification: Define MRLV as (High-Low)/Close divided by (Volume/SMA(Volume,20)) over 5 days; calculate the 20-day correlation between daily returns and volume changes; multiply the Z-scored MRLV by the negative correlation and the 5-day Amihud Illiquidity ratio (abs(return)/volume).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "b7098cdae6bc",
      "parent_trajectory_ids": [
        "e929c80ee882",
        "8b31cd9afab3"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073375787075466,
        "ICIR": 0.0532128482617706,
        "RankIC": 0.024067797281387,
        "RankICIR": 0.1764820283550209,
        "annualized_return": 0.078373715075335,
        "information_ratio": 1.099977462153051,
        "max_drawdown": -0.1230286729484408
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:28.225565",
      "updated_at": "2026-01-17T08:22:28.225571"
    },
    "bc5cd0033670fd71": {
      "factor_id": "bc5cd0033670fd71",
      "factor_name": "TED_Linearity_Volume_Divergence_10D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"TED_Linearity_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies unsustainable price trends by multiplying the trend linearity (R-squared of price over time) by the negative correlation between price and volume. High linearity combined with price-volume divergence (negative correlation) suggests trend exhaustion.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.951902",
      "updated_at": "2026-01-17T08:22:54.951909"
    },
    "1b9594382311ea4a": {
      "factor_id": "1b9594382311ea4a",
      "factor_name": "Trend_Fragility_Index_10D",
      "factor_expression": "RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(REGBETA($close, SEQUENCE(10), 10))) * RANK(-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the Trend Exhaustion Divergence hypothesis. It uses the time-series rank of price linearity and combines it with the cross-sectional rank of the negative price-volume correlation to find stocks where the trend is most 'crowded' yet unsupported by volume.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:54.982889",
      "updated_at": "2026-01-17T08:22:54.982895"
    },
    "d8bcc7cc594a12bc": {
      "factor_id": "d8bcc7cc594a12bc",
      "factor_name": "Exhaustion_Volume_Decay_10D",
      "factor_expression": "TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2), 20) - TS_CORR($close, $volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Volume_Decay_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price trend exhaustion by looking at the interaction between price momentum and the decline in volume support. It uses the R-squared of the price trend scaled by the inverse of the price-volume correlation, focusing on cases where price moves linearly but volume participation is fading.",
      "experiment_id": "2026-01-16_17-22-57-898541",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Trend Exhaustion Divergence (TED) factor, defined as the 10-day price trend linearity (R-squared) multiplied by the negative 10-day correlation between price changes and volume, identifies unsustainable price trends prone to imminent reversal.\n                Concise Observation: While the parent strategy focused on overnight gap validation, it ignored the internal stability of the preceding trend; high R-squared values often signal 'crowded' trades that become fragile when volume fails to support price direction.\n                Concise Justification: A high R-squared indicates a persistent trend, but if price increases are accompanied by declining volume (or vice versa), it suggests a divergence where the 'effort' (volume) no longer supports the 'result' (price), signaling a structural weakness in the trend.\n                Concise Knowledge: If a price trend exhibits high linearity (R-squared) while volume is inversely correlated with price movement, the trend is likely driven by liquidity exhaustion rather than institutional conviction; when these conditions peak, mean-reversion is expected.\n                concise Specification: The factor uses a 10-day window to calculate the R-squared of $close against a time index and the Pearson correlation between $close and $volume; the final factor is the product of R-squared and the negative correlation, targeting high-linearity divergence cases.\n                ",
      "initial_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "user_initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "planning_direction": "Investigate the interaction between RSQR10 and volume-price divergence by filtering high R-squared trends with negative volume-price correlation to identify exhaustion points.",
      "evolution_phase": "mutation",
      "trajectory_id": "e3d08eb9b33a",
      "parent_trajectory_ids": [
        "86bfc8a0f3bd"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0048744687089455,
        "ICIR": 0.0343411522399499,
        "RankIC": 0.0201222063232752,
        "RankICIR": 0.1460700250557991,
        "annualized_return": 0.0225438782694708,
        "information_ratio": 0.3010455334667145,
        "max_drawdown": -0.1186460798115613
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:22:55.013504",
      "updated_at": "2026-01-17T08:22:55.013510"
    },
    "ca3ce44b59213899": {
      "factor_id": "ca3ce44b59213899",
      "factor_name": "Adaptive_Consensus_Exhaustion_20D",
      "factor_expression": "TS_ZSCORE($close / (TS_SUM($close * $volume, 20) / TS_SUM($volume, 20)), 20) * TS_CORR($close, $volume, 20) * (($open / DELAY($close, 1) - 1) / (TS_MEAN(TS_MAX($high, 1) - TS_MIN($low, 1), 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($close / (TS_SUM($close * $volume, 20) / TS_SUM($volume, 20)), 20) * TS_CORR($close, $volume, 20) * (($open / DELAY($close, 1) - 1) / (TS_MEAN(TS_MAX($high, 1) - TS_MIN($low, 1), 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Adaptive_Consensus_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by combining price-VWAP distance, price-volume correlation, and overnight liquidity shocks. It uses a 20-day Z-score of the distance between price and a volume-weighted average proxy to capture consensus drift, multiplied by price-volume correlation to measure trend health, and adjusted by the ratio of overnight returns to a 14-day volatility measure (ATR proxy).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Adaptive_Consensus_Exhaustion' factor, calculated as the 20-day Z-score of the price-to-VWAP distance multiplied by the 20-day price-volume correlation and adjusted by the ratio of overnight returns to the 14-day ATR, identifies trend continuation when consensus drift is stable and reversals when liquidity shocks occur at extreme valuations.\n                Concise Observation: Parent 1 shows that normalized VWAP distance captures consensus efficiency (RankIC 0.021), while Parent 2 demonstrates that overnight returns relative to volatility identify conviction (RankIC 0.031); however, neither accounts for the transition between trend stability and exhaustion.\n                Concise Justification: Fusing long-term consensus drift with short-term liquidity shocks allows the factor to distinguish between 'healthy' price appreciation supported by volume and 'exhausted' price spikes caused by overnight liquidity gaps, leading to more robust predictive power across different market regimes.\n                Concise Knowledge: If price-to-VWAP distance is normalized by volatility, it represents valuation drift; when this drift is accompanied by high price-volume correlation, the trend is reinforced, but if coupled with high overnight return shocks (liquidity gaps), the probability of mean-reversion increases.\n                concise Specification: The factor uses a 20-day window for VWAP and price-volume correlation to establish the trend anchor, a 14-day ATR for volatility normalization, and a 1-day overnight return (Open/PrevClose - 1) as the exhaustion trigger, targeting a non-linear combination of trend strength and reversal probability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6ab1bd4c02a3",
      "parent_trajectory_ids": [
        "a52ba1223e8c",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073779907857329,
        "ICIR": 0.0523821340778484,
        "RankIC": 0.0217374772276411,
        "RankICIR": 0.1617357917821639,
        "annualized_return": 0.0626651264624249,
        "information_ratio": 0.8305351420356816,
        "max_drawdown": -0.1069402707821122
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:27:09.402197",
      "updated_at": "2026-01-17T08:27:09.402204"
    },
    "23dfc1a331d9c480": {
      "factor_id": "23dfc1a331d9c480",
      "factor_name": "Liquidity_Shock_Trend_Adjuster_14D",
      "factor_expression": "($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8) * TS_CORR($close, $volume, 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open - DELAY($close, 1)) / (TS_STD($close, 14) + 1e-8) * TS_CORR($close, $volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Shock_Trend_Adjuster_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the exhaustion hypothesis focusing on the interaction between overnight returns (liquidity gaps) and the prevailing price-volume trend. It normalizes the overnight gap by the 14-day price range and scales it by the 20-day price-volume correlation to detect if gaps are confirming or contradicting the volume-supported trend.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Adaptive_Consensus_Exhaustion' factor, calculated as the 20-day Z-score of the price-to-VWAP distance multiplied by the 20-day price-volume correlation and adjusted by the ratio of overnight returns to the 14-day ATR, identifies trend continuation when consensus drift is stable and reversals when liquidity shocks occur at extreme valuations.\n                Concise Observation: Parent 1 shows that normalized VWAP distance captures consensus efficiency (RankIC 0.021), while Parent 2 demonstrates that overnight returns relative to volatility identify conviction (RankIC 0.031); however, neither accounts for the transition between trend stability and exhaustion.\n                Concise Justification: Fusing long-term consensus drift with short-term liquidity shocks allows the factor to distinguish between 'healthy' price appreciation supported by volume and 'exhausted' price spikes caused by overnight liquidity gaps, leading to more robust predictive power across different market regimes.\n                Concise Knowledge: If price-to-VWAP distance is normalized by volatility, it represents valuation drift; when this drift is accompanied by high price-volume correlation, the trend is reinforced, but if coupled with high overnight return shocks (liquidity gaps), the probability of mean-reversion increases.\n                concise Specification: The factor uses a 20-day window for VWAP and price-volume correlation to establish the trend anchor, a 14-day ATR for volatility normalization, and a 1-day overnight return (Open/PrevClose - 1) as the exhaustion trigger, targeting a non-linear combination of trend strength and reversal probability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6ab1bd4c02a3",
      "parent_trajectory_ids": [
        "a52ba1223e8c",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073779907857329,
        "ICIR": 0.0523821340778484,
        "RankIC": 0.0217374772276411,
        "RankICIR": 0.1617357917821639,
        "annualized_return": 0.0626651264624249,
        "information_ratio": 0.8305351420356816,
        "max_drawdown": -0.1069402707821122
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:27:09.433020",
      "updated_at": "2026-01-17T08:27:09.433026"
    },
    "fe64b5e15c32e0b9": {
      "factor_id": "fe64b5e15c32e0b9",
      "factor_name": "Consensus_Drift_Volatility_Ratio_20D",
      "factor_expression": "($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8) * ABS($open / DELAY($close, 1) - 1)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - TS_MEAN($close, 20)) / (TS_STD($close, 20) + 1e-8) * ABS($open / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"Consensus_Drift_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the efficiency of price discovery by comparing the distance of the current price from its 20-day mean to the overnight volatility shock. High values suggest price is overextending relative to consensus, especially when triggered by overnight gaps.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Adaptive_Consensus_Exhaustion' factor, calculated as the 20-day Z-score of the price-to-VWAP distance multiplied by the 20-day price-volume correlation and adjusted by the ratio of overnight returns to the 14-day ATR, identifies trend continuation when consensus drift is stable and reversals when liquidity shocks occur at extreme valuations.\n                Concise Observation: Parent 1 shows that normalized VWAP distance captures consensus efficiency (RankIC 0.021), while Parent 2 demonstrates that overnight returns relative to volatility identify conviction (RankIC 0.031); however, neither accounts for the transition between trend stability and exhaustion.\n                Concise Justification: Fusing long-term consensus drift with short-term liquidity shocks allows the factor to distinguish between 'healthy' price appreciation supported by volume and 'exhausted' price spikes caused by overnight liquidity gaps, leading to more robust predictive power across different market regimes.\n                Concise Knowledge: If price-to-VWAP distance is normalized by volatility, it represents valuation drift; when this drift is accompanied by high price-volume correlation, the trend is reinforced, but if coupled with high overnight return shocks (liquidity gaps), the probability of mean-reversion increases.\n                concise Specification: The factor uses a 20-day window for VWAP and price-volume correlation to establish the trend anchor, a 14-day ATR for volatility normalization, and a 1-day overnight return (Open/PrevClose - 1) as the exhaustion trigger, targeting a non-linear combination of trend strength and reversal probability.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "6ab1bd4c02a3",
      "parent_trajectory_ids": [
        "a52ba1223e8c",
        "c42ef4440166"
      ],
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073779907857329,
        "ICIR": 0.0523821340778484,
        "RankIC": 0.0217374772276411,
        "RankICIR": 0.1617357917821639,
        "annualized_return": 0.0626651264624249,
        "information_ratio": 0.8305351420356816,
        "max_drawdown": -0.1069402707821122
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:27:09.463318",
      "updated_at": "2026-01-17T08:27:09.463324"
    },
    "f69a4064a16066fa": {
      "factor_id": "f69a4064a16066fa",
      "factor_name": "Friction_Discovery_V1",
      "factor_expression": "TS_CORR($close, $volume, 20) * (ABS($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, $volume, 20) * (ABS($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Friction_Discovery_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between price discovery efficiency and structural liquidity. It multiplies the 20-day price-volume correlation by the normalized overnight gap. The gap is normalized by the 14-day Average True Range (ATR) to identify if overnight information shocks are supported by intraday liquidity capacity.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Friction-Adjusted Discovery' factor, calculated as the product of the 20-day price-volume correlation and the ratio of the absolute overnight gap to the 14-day Average True Range, identifies assets where overnight information is inefficiently integrated into intraday liquidity, predicting short-term price reversals or continuations based on the magnitude of this friction.\n                Concise Observation: Parent 1 showed that overnight gaps relative to intraday volatility capture diffusion lags (RankIC 0.021), while Parent 2 demonstrated that price-volume correlation scaled by ATR identifies high-conviction liquidity states (RankIC 0.031).\n                Concise Justification: The fusion leverages price-volume correlation as a proxy for structural liquidity and ATR as a volatility normalizer, ensuring that the overnight 'information shock' is measured against the asset's current capacity to process information without excessive slippage or exhaustion.\n                Concise Knowledge: If a significant overnight price gap is not supported by a corresponding intraday price-volume correlation relative to historical volatility (ATR), the price discovery is considered incomplete or 'frictional'; when this friction is high, the asset is prone to mean-reversion as liquidity eventually absorbs the information shock.\n                concise Specification: The factor is defined as (Correlation($close, $volume, 20) * (Abs($open / Delay($close, 1) - 1) / ATR(14))), where ATR is the 14-day rolling average of (High - Low); a high value indicates high-conviction information diffusion, while a low value suggests a lack of liquidity support for the price move.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "16f63ed20036",
      "parent_trajectory_ids": [
        "ddd892827174",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068032163816015,
        "ICIR": 0.0463246430445467,
        "RankIC": 0.0236913075245471,
        "RankICIR": 0.1659601070478587,
        "annualized_return": 0.0230248837679552,
        "information_ratio": 0.3111210249824456,
        "max_drawdown": -0.179194916529402
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:33:02.118815",
      "updated_at": "2026-01-17T08:33:02.118821"
    },
    "5981b3cc0eeb6c45": {
      "factor_id": "5981b3cc0eeb6c45",
      "factor_name": "Ranked_Friction_Discovery_14D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 14)) * RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 14)) * RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 14) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Friction_Discovery_14D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the friction-adjusted discovery factor. It evaluates the relative intensity of overnight information shocks against liquidity (proxied by price-volume correlation) and volatility (ATR). High values indicate high-conviction diffusion, while low values suggest frictional discovery prone to reversal.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Friction-Adjusted Discovery' factor, calculated as the product of the 20-day price-volume correlation and the ratio of the absolute overnight gap to the 14-day Average True Range, identifies assets where overnight information is inefficiently integrated into intraday liquidity, predicting short-term price reversals or continuations based on the magnitude of this friction.\n                Concise Observation: Parent 1 showed that overnight gaps relative to intraday volatility capture diffusion lags (RankIC 0.021), while Parent 2 demonstrated that price-volume correlation scaled by ATR identifies high-conviction liquidity states (RankIC 0.031).\n                Concise Justification: The fusion leverages price-volume correlation as a proxy for structural liquidity and ATR as a volatility normalizer, ensuring that the overnight 'information shock' is measured against the asset's current capacity to process information without excessive slippage or exhaustion.\n                Concise Knowledge: If a significant overnight price gap is not supported by a corresponding intraday price-volume correlation relative to historical volatility (ATR), the price discovery is considered incomplete or 'frictional'; when this friction is high, the asset is prone to mean-reversion as liquidity eventually absorbs the information shock.\n                concise Specification: The factor is defined as (Correlation($close, $volume, 20) * (Abs($open / Delay($close, 1) - 1) / ATR(14))), where ATR is the 14-day rolling average of (High - Low); a high value indicates high-conviction information diffusion, while a low value suggests a lack of liquidity support for the price move.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "16f63ed20036",
      "parent_trajectory_ids": [
        "ddd892827174",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068032163816015,
        "ICIR": 0.0463246430445467,
        "RankIC": 0.0236913075245471,
        "RankICIR": 0.1659601070478587,
        "annualized_return": 0.0230248837679552,
        "information_ratio": 0.3111210249824456,
        "max_drawdown": -0.179194916529402
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:33:02.149668",
      "updated_at": "2026-01-17T08:33:02.149674"
    },
    "89652c4e5155f48b": {
      "factor_id": "89652c4e5155f48b",
      "factor_name": "Discovery_Efficiency_ZScore",
      "factor_expression": "TS_CORR($return, $volume, 20) * TS_ZSCORE(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor standardizes the overnight gap by the recent volatility range and scales it by the sign of the price-volume relationship. It aims to identify 'exhaustion' gaps where the price move lacks the liquidity support required for continuation, using a 20-day window for stability.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Friction-Adjusted Discovery' factor, calculated as the product of the 20-day price-volume correlation and the ratio of the absolute overnight gap to the 14-day Average True Range, identifies assets where overnight information is inefficiently integrated into intraday liquidity, predicting short-term price reversals or continuations based on the magnitude of this friction.\n                Concise Observation: Parent 1 showed that overnight gaps relative to intraday volatility capture diffusion lags (RankIC 0.021), while Parent 2 demonstrated that price-volume correlation scaled by ATR identifies high-conviction liquidity states (RankIC 0.031).\n                Concise Justification: The fusion leverages price-volume correlation as a proxy for structural liquidity and ATR as a volatility normalizer, ensuring that the overnight 'information shock' is measured against the asset's current capacity to process information without excessive slippage or exhaustion.\n                Concise Knowledge: If a significant overnight price gap is not supported by a corresponding intraday price-volume correlation relative to historical volatility (ATR), the price discovery is considered incomplete or 'frictional'; when this friction is high, the asset is prone to mean-reversion as liquidity eventually absorbs the information shock.\n                concise Specification: The factor is defined as (Correlation($close, $volume, 20) * (Abs($open / Delay($close, 1) - 1) / ATR(14))), where ATR is the 14-day rolling average of (High - Low); a high value indicates high-conviction information diffusion, while a low value suggests a lack of liquidity support for the price move.\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "16f63ed20036",
      "parent_trajectory_ids": [
        "ddd892827174",
        "c42ef4440166"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0068032163816015,
        "ICIR": 0.0463246430445467,
        "RankIC": 0.0236913075245471,
        "RankICIR": 0.1659601070478587,
        "annualized_return": 0.0230248837679552,
        "information_ratio": 0.3111210249824456,
        "max_drawdown": -0.179194916529402
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:33:02.179825",
      "updated_at": "2026-01-17T08:33:02.179831"
    },
    "136f1dd35e873a74": {
      "factor_id": "136f1dd35e873a74",
      "factor_name": "LSDI_Structural_Reversal_5D",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 5) * (1 - TS_CORR($return, $volume, 20)) * TS_MEAN(ABS($return) / ($volume * $close + 1e-8), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 5) * (1 - TS_CORR($close / DELAY($close, 1) - 1, $volume, 20)) * TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume * $close + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"LSDI_Structural_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Liquidity-Structural Divergence Index: Identifies mean-reversion candidates by combining high intraday price dispersion relative to volume (liquidity exhaustion), low price-volume correlation (structural weakness), and rising illiquidity (Amihud).",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Structural Divergence Index' (LSDI) predicts reversals by identifying assets where the 5-day Z-score of the (High-Low)/Volume ratio is high, while the 20-day price-volume correlation is low and the 5-day Amihud Illiquidity is rising.\n                Concise Observation: Parent 1 successfully captured mean-reversion via intraday range/volume (RankIC 0.0268), while Parent 2 identified regime shifts via price-volume correlation and Amihud illiquidity (RankIC 0.0255); however, both suffer from noise during trending markets with low-quality volume.\n                Concise Justification: Fusing these identifies 'Liquidity Vacuums' where price moves are 'expensive' (high Amihud) and 'disorganized' (low PV correlation), ensuring that the exhaustion signal from Parent 1 is validated by the structural weakness identified in Parent 2.\n                Concise Knowledge: If extreme intraday price dispersion occurs without a corresponding increase in price-volume reflexivity, the price move is likely a liquidity-driven exhaustion rather than a sustainable trend; when high illiquidity coincides with low correlation, the market is in a 'regime trap' prone to mean reversion.\n                concise Specification: The factor is defined as the product of the 5-day Z-score of (High-Low)/Volume and the inverse of the 20-day rolling correlation between price changes and volume, scaled by the 5-day average of absolute return divided by dollar volume (Amihud).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2978591db7ac",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "3c37422cea0a"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046096241986078,
        "ICIR": 0.032824358114378,
        "RankIC": 0.021486235632396,
        "RankICIR": 0.1551139432987301,
        "annualized_return": 0.0164555744396186,
        "information_ratio": 0.2351988131090285,
        "max_drawdown": -0.1148980339497351
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:38:04.473403",
      "updated_at": "2026-01-17T08:38:04.473410"
    },
    "dc804a0cabe34420": {
      "factor_id": "dc804a0cabe34420",
      "factor_name": "Liquidity_Vacuum_Exhaustion_10D",
      "factor_expression": "RANK(($high - $low) / ($volume + 1e-8)) * RANK(1 - ABS(TS_CORR($close, $volume, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($volume + 1e-8)) * RANK(1 - ABS(TS_CORR($close, $volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures 'Liquidity Vacuums' where price range expands on low relative volume efficiency. It uses the rank of the ratio between price range and volume, weighted by the inverse of the recent price-volume trend stability.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Structural Divergence Index' (LSDI) predicts reversals by identifying assets where the 5-day Z-score of the (High-Low)/Volume ratio is high, while the 20-day price-volume correlation is low and the 5-day Amihud Illiquidity is rising.\n                Concise Observation: Parent 1 successfully captured mean-reversion via intraday range/volume (RankIC 0.0268), while Parent 2 identified regime shifts via price-volume correlation and Amihud illiquidity (RankIC 0.0255); however, both suffer from noise during trending markets with low-quality volume.\n                Concise Justification: Fusing these identifies 'Liquidity Vacuums' where price moves are 'expensive' (high Amihud) and 'disorganized' (low PV correlation), ensuring that the exhaustion signal from Parent 1 is validated by the structural weakness identified in Parent 2.\n                Concise Knowledge: If extreme intraday price dispersion occurs without a corresponding increase in price-volume reflexivity, the price move is likely a liquidity-driven exhaustion rather than a sustainable trend; when high illiquidity coincides with low correlation, the market is in a 'regime trap' prone to mean reversion.\n                concise Specification: The factor is defined as the product of the 5-day Z-score of (High-Low)/Volume and the inverse of the 20-day rolling correlation between price changes and volume, scaled by the 5-day average of absolute return divided by dollar volume (Amihud).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2978591db7ac",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "3c37422cea0a"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046096241986078,
        "ICIR": 0.032824358114378,
        "RankIC": 0.021486235632396,
        "RankICIR": 0.1551139432987301,
        "annualized_return": 0.0164555744396186,
        "information_ratio": 0.2351988131090285,
        "max_drawdown": -0.1148980339497351
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:38:04.504382",
      "updated_at": "2026-01-17T08:38:04.504388"
    },
    "d1c4f598a5239432": {
      "factor_id": "d1c4f598a5239432",
      "factor_name": "Amihud_Regime_Trap_Index",
      "factor_expression": "RANK(ABS($return) / ($volume * $close + 1e-8)) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume * $close + 1e-8)) * RANK(TS_MEAN($volume, 20) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Regime_Trap_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Identifies 'Regime Traps' where illiquidity is high but price movement lacks volume confirmation. It measures the cross-sectional rank of Amihud illiquidity multiplied by the divergence of current volume from its 20-day mean.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 'Liquidity-Structural Divergence Index' (LSDI) predicts reversals by identifying assets where the 5-day Z-score of the (High-Low)/Volume ratio is high, while the 20-day price-volume correlation is low and the 5-day Amihud Illiquidity is rising.\n                Concise Observation: Parent 1 successfully captured mean-reversion via intraday range/volume (RankIC 0.0268), while Parent 2 identified regime shifts via price-volume correlation and Amihud illiquidity (RankIC 0.0255); however, both suffer from noise during trending markets with low-quality volume.\n                Concise Justification: Fusing these identifies 'Liquidity Vacuums' where price moves are 'expensive' (high Amihud) and 'disorganized' (low PV correlation), ensuring that the exhaustion signal from Parent 1 is validated by the structural weakness identified in Parent 2.\n                Concise Knowledge: If extreme intraday price dispersion occurs without a corresponding increase in price-volume reflexivity, the price move is likely a liquidity-driven exhaustion rather than a sustainable trend; when high illiquidity coincides with low correlation, the market is in a 'regime trap' prone to mean reversion.\n                concise Specification: The factor is defined as the product of the 5-day Z-score of (High-Low)/Volume and the inverse of the 20-day rolling correlation between price changes and volume, scaled by the 5-day average of absolute return divided by dollar volume (Amihud).\n                ",
      "initial_direction": "",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "",
      "evolution_phase": "crossover",
      "trajectory_id": "2978591db7ac",
      "parent_trajectory_ids": [
        "0b251d2e379b",
        "3c37422cea0a"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0046096241986078,
        "ICIR": 0.032824358114378,
        "RankIC": 0.021486235632396,
        "RankICIR": 0.1551139432987301,
        "annualized_return": 0.0164555744396186,
        "information_ratio": 0.2351988131090285,
        "max_drawdown": -0.1148980339497351
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:38:04.535079",
      "updated_at": "2026-01-17T08:38:04.535085"
    },
    "164030fafe4ad9c9": {
      "factor_id": "164030fafe4ad9c9",
      "factor_name": "Institutional_Flow_Persistence_20D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8) * (1 + TS_PCTCHANGE($volume, 5)), 20)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Flow_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional conviction by measuring the average intraday price positioning (Close-Open relative to High-Low) weighted by the 5-day volume trend, identifying persistent directional flow.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.945249",
      "updated_at": "2026-01-17T08:41:46.945258"
    },
    "e8edb408831788e7": {
      "factor_id": "e8edb408831788e7",
      "factor_name": "Aggressive_Skew_Momentum_10D",
      "factor_expression": "RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($return))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $low) / ($high - $low + 1e-8), 10)) * SIGN(SKEW($close / DELAY($close, 1) - 1))\" # Your output factor expression will be filled in here\n    name = \"Aggressive_Skew_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies aggressive trend-following behavior by combining cross-sectional return skewness with the consistency of price relative to its recent range, signaling institutional dominance.",
      "experiment_id": "2026-01-16_17-24-17-907337",
      "round_number": 1,
      "hypothesis": "Hypothesis: The Institutional Order-Flow Persistence Factor (IOPF) predicts medium-term momentum by identifying directional conviction through the interaction of price-volume skewness and the consistency of volume-weighted price positioning.\n                Concise Observation: The parent strategy focused on short-term reversal via liquidity exhaustion (low price-volume correlation), but market data often shows that high-volume price trends exhibit significant multi-day autocorrelation driven by institutional execution cycles.\n                Concise Justification: Institutional investors execute large orders over multiple days to minimize market impact, creating a 'footprint' of persistent price-volume convergence and positive skewness that signals sustainable momentum rather than temporary exhaustion.\n                Concise Knowledge: If a stock's closing price consistently stays above its daily volume-weighted mean while volume growth remains stable, it indicates informed institutional accumulation; When price-volume skewness is positive, it reflects aggressive buyer dominance that tends to persist over a 20-day horizon.\n                concise Specification: The factor will measure the 20-day average of the ratio between (Close - Open) and (High - Low), weighted by the 5-day volume trend consistency, and filtered by the 10-day skewness of the daily returns to capture 'aggressive' trend-following behavior.\n                ",
      "initial_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "user_initial_direction": "参考以下组合给出假设。组合2包含ROC60（表达式：Ref(, 60)/，含义：60日价格反转因子，值>1表示长期下跌）、CORR20（表达式：Corr(, Log(+1), 20)，含义：20日收盘价与成交量对数的相关系数）、VSTD5（表达式：Std(, 5)/(+1e-12)，含义：5日成交量标准差，反映资金流向稳定性）。",
      "planning_direction": "Long-term reversal conditioning on liquidity stability: Test if ROC60's predictive power for mean reversion is enhanced when VSTD5 is in the lowest decile, indicating institutional accumulation.",
      "evolution_phase": "mutation",
      "trajectory_id": "b93f2f9e6772",
      "parent_trajectory_ids": [
        "039e160d1be5"
      ],
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.008357476501947,
        "ICIR": 0.0521638560501109,
        "RankIC": 0.0249339747014853,
        "RankICIR": 0.1601932835174474,
        "annualized_return": 0.0416185481785047,
        "information_ratio": 0.5441338713529469,
        "max_drawdown": -0.1387524028453887
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-17T08:41:46.977170",
      "updated_at": "2026-01-17T08:41:46.977177"
    }
  }
}