{
  "metadata": {
    "created_at": "2026-01-20T21:14:48.210445",
    "last_updated": "2026-01-21T14:08:56.372021",
    "total_factors": 327,
    "version": "1.0"
  },
  "factors": {
    "e52899da30b824a3": {
      "factor_id": "e52899da30b824a3",
      "factor_name": "Trend_Exhaustion_RSQR_RESI_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close - TS_MEAN($close, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($close - TS_MEAN($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_RSQR_RESI_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential trend exhaustion by multiplying the 10-day price-time R-squared (representing trend consistency) with the 5-day mean-adjusted residual return. High values suggest the price is over-extended relative to its recent trend, signaling a potential mean-reverting correction.",
      "factor_formulation": "\\text{RSQR10} \\times (\\text{close} - \\text{TS_MEAN}(\\text{close}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "14304b6f775a",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Exhaustion Factor, defined as the product of the 10-day price-time R-squared and the 5-day mean-adjusted residual return, negatively predicts future returns as high values indicate unsustainable price acceleration.\n                Concise Observation: In quantitative momentum strategies, strong trends often terminate abruptly after a period of accelerating returns that deviate significantly from the primary trend line.\n                Concise Justification: High R-squared measures trend strength and consistency, while high residuals capture the 'over-extension' or verticality of the move; their interaction identifies speculative blow-offs where buying pressure is depleted.\n                Concise Knowledge: If a price trend exhibits both high linear persistence (R-squared) and significant positive deviation from its mean (residuals), it is likely entering an exhaustion phase; when these conditions peak, the probability of a mean-reverting correction increases.\n                concise Specification: Calculate RSQR10 as the R-squared of $close against a time index over 10 days, calculate RESI5 as the average residual of $close from its 5-day mean, and define the factor as RSQR10 * RESI5.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T21:14:48.210058"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2407228039736877,
        "ICIR": 0.0341950239773277,
        "1day.excess_return_without_cost.std": 0.00515884726711,
        "1day.excess_return_with_cost.annualized_return": -0.024287063804217,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.750531099987838e-05,
        "1day.excess_return_without_cost.annualized_return": 0.023206264017971,
        "1day.excess_return_with_cost.std": 0.0051592755209335,
        "Rank IC": 0.019824123748762,
        "IC": 0.0049447272417562,
        "1day.excess_return_without_cost.max_drawdown": -0.1912204784677683,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.2915842622844319,
        "1day.pa": 0.0,
        "l2.valid": 0.9965674222983596,
        "Rank ICIR": 0.1375790917161934,
        "l2.train": 0.9933546434192824,
        "1day.excess_return_with_cost.information_ratio": -0.3051390670679622,
        "1day.excess_return_with_cost.mean": -0.0001020464865723
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. While the core idea—that strong price-time consistency (R-squared) combined with recent vertical deviation predicts a reversal—is theoretically sound, the current implementations underperformed the SOTA result across all key metrics. Specifically, the Information Ratio (0.29 vs 0.97) and Max Drawdown (-0.19 vs -0.07) show significantly higher risk and lower risk-adjusted returns compared to the existing benchmark. The IC (0.0049) remains positive but is lower than the SOTA (0.0058), suggesting the signal is weak or the interaction between trend strength and residual deviation is not yet optimally captured.",
        "hypothesis_evaluation": "The results partially support the hypothesis in direction (positive IC suggests some predictive power), but the magnitude and stability are insufficient. The 'Standardized_Trend_Overextension_10D' factor, which used cross-sectional ranking and volatility normalization, likely performed the best among the three but still suffered from noise. The interaction between a 10-day trend and a 5-day residual might be too sensitive to short-term noise. The 'Accelerated_Blowoff' approach using REGRESI is mathematically cleaner but might be capturing momentum rather than exhaustion if the 'exhaustion' threshold isn't explicitly defined.",
        "decision": false,
        "reason": "The current factors use a linear residual from a mean or a single regression. However, exhaustion often manifests as a non-linear acceleration (parabolic move). By calculating the ratio of a short-term moving average slope to a long-term moving average slope, specifically when the long-term trend is highly linear (High R-squared), we can isolate stocks that are 'veering off' their sustainable path. Using a 20-day window for the base trend provides a more stable anchor than the 10-day window used in the current iteration."
      }
    },
    "8a5786743923ad73": {
      "factor_id": "8a5786743923ad73",
      "factor_name": "Accelerated_Blowoff_Factor_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * REGRESI($close, SEQUENCE(5), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * REGRESI($close, SEQUENCE(5), 5)\" # Your output factor expression will be filled in here\n    name = \"Accelerated_Blowoff_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures speculative blow-off phases by interacting the R-squared of the price trend with the residual of the price relative to a linear time trend. This highlights stocks that are not only trending strongly but are also currently deviating vertically from that trend line.",
      "factor_formulation": "\\text{RSQR10} \\times \\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(5), 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "14304b6f775a",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Exhaustion Factor, defined as the product of the 10-day price-time R-squared and the 5-day mean-adjusted residual return, negatively predicts future returns as high values indicate unsustainable price acceleration.\n                Concise Observation: In quantitative momentum strategies, strong trends often terminate abruptly after a period of accelerating returns that deviate significantly from the primary trend line.\n                Concise Justification: High R-squared measures trend strength and consistency, while high residuals capture the 'over-extension' or verticality of the move; their interaction identifies speculative blow-offs where buying pressure is depleted.\n                Concise Knowledge: If a price trend exhibits both high linear persistence (R-squared) and significant positive deviation from its mean (residuals), it is likely entering an exhaustion phase; when these conditions peak, the probability of a mean-reverting correction increases.\n                concise Specification: Calculate RSQR10 as the R-squared of $close against a time index over 10 days, calculate RESI5 as the average residual of $close from its 5-day mean, and define the factor as RSQR10 * RESI5.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T21:14:48.210058"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2407228039736877,
        "ICIR": 0.0341950239773277,
        "1day.excess_return_without_cost.std": 0.00515884726711,
        "1day.excess_return_with_cost.annualized_return": -0.024287063804217,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.750531099987838e-05,
        "1day.excess_return_without_cost.annualized_return": 0.023206264017971,
        "1day.excess_return_with_cost.std": 0.0051592755209335,
        "Rank IC": 0.019824123748762,
        "IC": 0.0049447272417562,
        "1day.excess_return_without_cost.max_drawdown": -0.1912204784677683,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.2915842622844319,
        "1day.pa": 0.0,
        "l2.valid": 0.9965674222983596,
        "Rank ICIR": 0.1375790917161934,
        "l2.train": 0.9933546434192824,
        "1day.excess_return_with_cost.information_ratio": -0.3051390670679622,
        "1day.excess_return_with_cost.mean": -0.0001020464865723
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. While the core idea—that strong price-time consistency (R-squared) combined with recent vertical deviation predicts a reversal—is theoretically sound, the current implementations underperformed the SOTA result across all key metrics. Specifically, the Information Ratio (0.29 vs 0.97) and Max Drawdown (-0.19 vs -0.07) show significantly higher risk and lower risk-adjusted returns compared to the existing benchmark. The IC (0.0049) remains positive but is lower than the SOTA (0.0058), suggesting the signal is weak or the interaction between trend strength and residual deviation is not yet optimally captured.",
        "hypothesis_evaluation": "The results partially support the hypothesis in direction (positive IC suggests some predictive power), but the magnitude and stability are insufficient. The 'Standardized_Trend_Overextension_10D' factor, which used cross-sectional ranking and volatility normalization, likely performed the best among the three but still suffered from noise. The interaction between a 10-day trend and a 5-day residual might be too sensitive to short-term noise. The 'Accelerated_Blowoff' approach using REGRESI is mathematically cleaner but might be capturing momentum rather than exhaustion if the 'exhaustion' threshold isn't explicitly defined.",
        "decision": false,
        "reason": "The current factors use a linear residual from a mean or a single regression. However, exhaustion often manifests as a non-linear acceleration (parabolic move). By calculating the ratio of a short-term moving average slope to a long-term moving average slope, specifically when the long-term trend is highly linear (High R-squared), we can isolate stocks that are 'veering off' their sustainable path. Using a 20-day window for the base trend provides a more stable anchor than the 10-day window used in the current iteration."
      }
    },
    "9eb1acdd93feb30c": {
      "factor_id": "9eb1acdd93feb30c",
      "factor_name": "Standardized_Trend_Overextension_10D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(($return - TS_MEAN($return, 5)) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(($close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Standardized_Trend_Overextension_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the trend exhaustion hypothesis. It combines the strength of the linear trend (R-squared) with the recent return deviation, standardized by volatility to ensure comparability across different stocks.",
      "factor_formulation": "\\text{RANK}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2) \\times \\text{RANK}(\\frac{\\text{return} - \\text{TS_MEAN}(\\text{return}, 5)}{\\text{TS_STD}(\\text{return}, 5)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "14304b6f775a",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Exhaustion Factor, defined as the product of the 10-day price-time R-squared and the 5-day mean-adjusted residual return, negatively predicts future returns as high values indicate unsustainable price acceleration.\n                Concise Observation: In quantitative momentum strategies, strong trends often terminate abruptly after a period of accelerating returns that deviate significantly from the primary trend line.\n                Concise Justification: High R-squared measures trend strength and consistency, while high residuals capture the 'over-extension' or verticality of the move; their interaction identifies speculative blow-offs where buying pressure is depleted.\n                Concise Knowledge: If a price trend exhibits both high linear persistence (R-squared) and significant positive deviation from its mean (residuals), it is likely entering an exhaustion phase; when these conditions peak, the probability of a mean-reverting correction increases.\n                concise Specification: Calculate RSQR10 as the R-squared of $close against a time index over 10 days, calculate RESI5 as the average residual of $close from its 5-day mean, and define the factor as RSQR10 * RESI5.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T21:14:48.210058"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2407228039736877,
        "ICIR": 0.0341950239773277,
        "1day.excess_return_without_cost.std": 0.00515884726711,
        "1day.excess_return_with_cost.annualized_return": -0.024287063804217,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.750531099987838e-05,
        "1day.excess_return_without_cost.annualized_return": 0.023206264017971,
        "1day.excess_return_with_cost.std": 0.0051592755209335,
        "Rank IC": 0.019824123748762,
        "IC": 0.0049447272417562,
        "1day.excess_return_without_cost.max_drawdown": -0.1912204784677683,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.2915842622844319,
        "1day.pa": 0.0,
        "l2.valid": 0.9965674222983596,
        "Rank ICIR": 0.1375790917161934,
        "l2.train": 0.9933546434192824,
        "1day.excess_return_with_cost.information_ratio": -0.3051390670679622,
        "1day.excess_return_with_cost.mean": -0.0001020464865723
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. While the core idea—that strong price-time consistency (R-squared) combined with recent vertical deviation predicts a reversal—is theoretically sound, the current implementations underperformed the SOTA result across all key metrics. Specifically, the Information Ratio (0.29 vs 0.97) and Max Drawdown (-0.19 vs -0.07) show significantly higher risk and lower risk-adjusted returns compared to the existing benchmark. The IC (0.0049) remains positive but is lower than the SOTA (0.0058), suggesting the signal is weak or the interaction between trend strength and residual deviation is not yet optimally captured.",
        "hypothesis_evaluation": "The results partially support the hypothesis in direction (positive IC suggests some predictive power), but the magnitude and stability are insufficient. The 'Standardized_Trend_Overextension_10D' factor, which used cross-sectional ranking and volatility normalization, likely performed the best among the three but still suffered from noise. The interaction between a 10-day trend and a 5-day residual might be too sensitive to short-term noise. The 'Accelerated_Blowoff' approach using REGRESI is mathematically cleaner but might be capturing momentum rather than exhaustion if the 'exhaustion' threshold isn't explicitly defined.",
        "decision": false,
        "reason": "The current factors use a linear residual from a mean or a single regression. However, exhaustion often manifests as a non-linear acceleration (parabolic move). By calculating the ratio of a short-term moving average slope to a long-term moving average slope, specifically when the long-term trend is highly linear (High R-squared), we can isolate stocks that are 'veering off' their sustainable path. Using a 20-day window for the base trend provides a more stable anchor than the 10-day window used in the current iteration."
      }
    },
    "6ff96e558c287e6b": {
      "factor_id": "6ff96e558c287e6b",
      "factor_name": "Quality_Volatility_Resonance_5D",
      "factor_expression": "RANK(($high - $low) / ($close + 1e-8)) * RANK(DELTA(TS_MEAN($close * $volume, 5), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($close + 1e-8)) * RANK(DELTA(TS_MEAN($close * $volume, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Quality_Volatility_Resonance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-quality volatility by interacting the intraday range (KLEN) with the 5-day change in the weighted volume moving average (WVMA). It captures price moves backed by institutional conviction, where high intraday range coincides with strong volume-weighted price trends.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{high} - \\text{low}}{\\text{close} + 1e-8}\\right) \\times \\text{RANK}\\left(\\text{DELTA}(\\text{TS_MEAN}(\\text{close} \\times \\text{volume}, 5), 5)\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "370a9cad520d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the Intraday Range (KLEN) and the 5-day Weighted Volume Moving Average (WVMA5) identifies high-quality volatility: specifically, price moves with high intraday ranges and high price-volume resonance (high WVMA5) predict stronger future returns than those with low resonance.\n                Concise Observation: Intraday volatility (High-Low) often fails as a standalone predictor because it conflates informed trading with random noise, but volume-weighted trends (WVMA) can filter for liquidity-backed movements.\n                Concise Justification: Institutional participation requires significant volume to move prices, so 'quality' volatility—that which persists—should be positively correlated with the strength of volume-weighted price trends.\n                Concise Knowledge: If a large intraday price range is accompanied by high volume-weighted momentum, it signifies institutional conviction; conversely, high range on low volume resonance represents noise or liquidity gaps.\n                concise Specification: Define KLEN as (High-Low)/Close and WVMA5 as the 5-day moving average of (Close * Volume); the factor is the product of KLEN and the 5-day change in WVMA5.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T21:18:14.441928"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739497258439768,
        "ICIR": 0.0472211920492118,
        "1day.excess_return_without_cost.std": 0.0040673776424795,
        "1day.excess_return_with_cost.annualized_return": 0.0251085926817033,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002999465066513,
        "1day.excess_return_without_cost.annualized_return": 0.0713872685830279,
        "1day.excess_return_with_cost.std": 0.0040671490365025,
        "Rank IC": 0.0240167622243152,
        "IC": 0.0063624234303612,
        "1day.excess_return_without_cost.max_drawdown": -0.066761727514072,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1376738866452547,
        "1day.pa": 0.0,
        "l2.valid": 0.996319489627366,
        "Rank ICIR": 0.1866865990478907,
        "l2.train": 0.9939602273670832,
        "1day.excess_return_with_cost.information_ratio": 0.4001693354082368,
        "1day.excess_return_with_cost.mean": 0.0001054982885785
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Quality Volatility Resonance' hypothesis by testing different smoothing methods (EMA vs. TS_MEAN) and normalization techniques (RANK vs. ZSCORE). The results show a significant improvement across all key performance metrics. Specifically, the Information Ratio increased from 0.97 to 1.14, and the Annualized Return rose from 5.2% to 7.1%. The IC also showed a healthy improvement to 0.0063. The use of EMA in 'Smoothed_WVMA_Volatility_Interaction' likely contributed to reducing noise in the volume-weighted price component, while the interaction with intraday range effectively isolated high-conviction price movements.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The interaction between intraday range (volatility) and volume-weighted price trends (resonance) successfully identifies alpha. The improvement from 'Quality_Volatility_Resonance_5D' to 'Smoothed_WVMA_Volatility_Interaction' suggests that the 'resonance' component is sensitive to noise and benefits from exponential smoothing. The low complexity of the factors (using only 4 base features and minimal parameters) suggests these results are robust and not driven by overfitting.",
        "decision": true,
        "reason": "While the current interaction is effective, 'high intraday range' is a relative concept; a high range in a low-volatility environment is more significant than the same range in a high-volatility environment. Normalizing the range by ATR (Average True Range) should provide a cleaner signal. Furthermore, the current WVMA measures trend strength; incorporating the relationship between volume flow and price direction (e.g., using a modified Chaikin Money Flow or Volume-Price Trend logic) within the resonance framework may better distinguish between retail-driven spikes and institutional accumulation."
      }
    },
    "b1e62f00f99f1d53": {
      "factor_id": "b1e62f00f99f1d53",
      "factor_name": "Institutional_Conviction_Index_10D",
      "factor_expression": "ZSCORE(($high - $low) / ($close + 1e-8)) + ZSCORE(TS_PCTCHANGE(TS_MEAN($close * $volume, 5), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / ($close + 1e-8)) + ZSCORE(TS_PCTCHANGE(TS_MEAN($close * $volume, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A refined version of the quality volatility hypothesis focusing on the cross-sectional strength of volume-weighted momentum relative to intraday range. It uses Z-scores to normalize the interaction between the intraday price spread and the trend in volume-weighted price levels over a 10-day window.",
      "factor_formulation": "\\text{ZSCORE}\\left(\\frac{\\text{high} - \\text{low}}{\\text{close}}\\right) + \\text{ZSCORE}(\\text{TS_PCTCHANGE}(\\text{TS_MEAN}(\\text{close} \\times \\text{volume}, 5), 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "370a9cad520d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the Intraday Range (KLEN) and the 5-day Weighted Volume Moving Average (WVMA5) identifies high-quality volatility: specifically, price moves with high intraday ranges and high price-volume resonance (high WVMA5) predict stronger future returns than those with low resonance.\n                Concise Observation: Intraday volatility (High-Low) often fails as a standalone predictor because it conflates informed trading with random noise, but volume-weighted trends (WVMA) can filter for liquidity-backed movements.\n                Concise Justification: Institutional participation requires significant volume to move prices, so 'quality' volatility—that which persists—should be positively correlated with the strength of volume-weighted price trends.\n                Concise Knowledge: If a large intraday price range is accompanied by high volume-weighted momentum, it signifies institutional conviction; conversely, high range on low volume resonance represents noise or liquidity gaps.\n                concise Specification: Define KLEN as (High-Low)/Close and WVMA5 as the 5-day moving average of (Close * Volume); the factor is the product of KLEN and the 5-day change in WVMA5.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T21:18:14.441928"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739497258439768,
        "ICIR": 0.0472211920492118,
        "1day.excess_return_without_cost.std": 0.0040673776424795,
        "1day.excess_return_with_cost.annualized_return": 0.0251085926817033,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002999465066513,
        "1day.excess_return_without_cost.annualized_return": 0.0713872685830279,
        "1day.excess_return_with_cost.std": 0.0040671490365025,
        "Rank IC": 0.0240167622243152,
        "IC": 0.0063624234303612,
        "1day.excess_return_without_cost.max_drawdown": -0.066761727514072,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1376738866452547,
        "1day.pa": 0.0,
        "l2.valid": 0.996319489627366,
        "Rank ICIR": 0.1866865990478907,
        "l2.train": 0.9939602273670832,
        "1day.excess_return_with_cost.information_ratio": 0.4001693354082368,
        "1day.excess_return_with_cost.mean": 0.0001054982885785
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Quality Volatility Resonance' hypothesis by testing different smoothing methods (EMA vs. TS_MEAN) and normalization techniques (RANK vs. ZSCORE). The results show a significant improvement across all key performance metrics. Specifically, the Information Ratio increased from 0.97 to 1.14, and the Annualized Return rose from 5.2% to 7.1%. The IC also showed a healthy improvement to 0.0063. The use of EMA in 'Smoothed_WVMA_Volatility_Interaction' likely contributed to reducing noise in the volume-weighted price component, while the interaction with intraday range effectively isolated high-conviction price movements.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The interaction between intraday range (volatility) and volume-weighted price trends (resonance) successfully identifies alpha. The improvement from 'Quality_Volatility_Resonance_5D' to 'Smoothed_WVMA_Volatility_Interaction' suggests that the 'resonance' component is sensitive to noise and benefits from exponential smoothing. The low complexity of the factors (using only 4 base features and minimal parameters) suggests these results are robust and not driven by overfitting.",
        "decision": true,
        "reason": "While the current interaction is effective, 'high intraday range' is a relative concept; a high range in a low-volatility environment is more significant than the same range in a high-volatility environment. Normalizing the range by ATR (Average True Range) should provide a cleaner signal. Furthermore, the current WVMA measures trend strength; incorporating the relationship between volume flow and price direction (e.g., using a modified Chaikin Money Flow or Volume-Price Trend logic) within the resonance framework may better distinguish between retail-driven spikes and institutional accumulation."
      }
    },
    "ca42cea9078e3e20": {
      "factor_id": "ca42cea9078e3e20",
      "factor_name": "Smoothed_WVMA_Volatility_Interaction",
      "factor_expression": "RANK(($high - $low) / ($close + 1e-8)) * RANK(DELTA(EMA($close * $volume, 5), 3))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / ($close + 1e-8)) * RANK(DELTA(EMA($close * $volume, 5), 3))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_WVMA_Volatility_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor uses the Exponential Moving Average (EMA) to smooth the volume-weighted price component, reducing noise in the WVMA calculation. It then multiplies this smoothed trend indicator by the normalized intraday range to highlight stocks with persistent, liquidity-backed volatility.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{high} - \\text{low}}{\\text{close}}\\right) \\times \\text{RANK}(\\text{DELTA}(\\text{EMA}(\\text{close} \\times \\text{volume}, 5), 3))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "370a9cad520d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the Intraday Range (KLEN) and the 5-day Weighted Volume Moving Average (WVMA5) identifies high-quality volatility: specifically, price moves with high intraday ranges and high price-volume resonance (high WVMA5) predict stronger future returns than those with low resonance.\n                Concise Observation: Intraday volatility (High-Low) often fails as a standalone predictor because it conflates informed trading with random noise, but volume-weighted trends (WVMA) can filter for liquidity-backed movements.\n                Concise Justification: Institutional participation requires significant volume to move prices, so 'quality' volatility—that which persists—should be positively correlated with the strength of volume-weighted price trends.\n                Concise Knowledge: If a large intraday price range is accompanied by high volume-weighted momentum, it signifies institutional conviction; conversely, high range on low volume resonance represents noise or liquidity gaps.\n                concise Specification: Define KLEN as (High-Low)/Close and WVMA5 as the 5-day moving average of (Close * Volume); the factor is the product of KLEN and the 5-day change in WVMA5.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T21:18:14.441928"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739497258439768,
        "ICIR": 0.0472211920492118,
        "1day.excess_return_without_cost.std": 0.0040673776424795,
        "1day.excess_return_with_cost.annualized_return": 0.0251085926817033,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002999465066513,
        "1day.excess_return_without_cost.annualized_return": 0.0713872685830279,
        "1day.excess_return_with_cost.std": 0.0040671490365025,
        "Rank IC": 0.0240167622243152,
        "IC": 0.0063624234303612,
        "1day.excess_return_without_cost.max_drawdown": -0.066761727514072,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1376738866452547,
        "1day.pa": 0.0,
        "l2.valid": 0.996319489627366,
        "Rank ICIR": 0.1866865990478907,
        "l2.train": 0.9939602273670832,
        "1day.excess_return_with_cost.information_ratio": 0.4001693354082368,
        "1day.excess_return_with_cost.mean": 0.0001054982885785
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Quality Volatility Resonance' hypothesis by testing different smoothing methods (EMA vs. TS_MEAN) and normalization techniques (RANK vs. ZSCORE). The results show a significant improvement across all key performance metrics. Specifically, the Information Ratio increased from 0.97 to 1.14, and the Annualized Return rose from 5.2% to 7.1%. The IC also showed a healthy improvement to 0.0063. The use of EMA in 'Smoothed_WVMA_Volatility_Interaction' likely contributed to reducing noise in the volume-weighted price component, while the interaction with intraday range effectively isolated high-conviction price movements.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The interaction between intraday range (volatility) and volume-weighted price trends (resonance) successfully identifies alpha. The improvement from 'Quality_Volatility_Resonance_5D' to 'Smoothed_WVMA_Volatility_Interaction' suggests that the 'resonance' component is sensitive to noise and benefits from exponential smoothing. The low complexity of the factors (using only 4 base features and minimal parameters) suggests these results are robust and not driven by overfitting.",
        "decision": true,
        "reason": "While the current interaction is effective, 'high intraday range' is a relative concept; a high range in a low-volatility environment is more significant than the same range in a high-volatility environment. Normalizing the range by ATR (Average True Range) should provide a cleaner signal. Furthermore, the current WVMA measures trend strength; incorporating the relationship between volume flow and price direction (e.g., using a modified Chaikin Money Flow or Volume-Price Trend logic) within the resonance framework may better distinguish between retail-driven spikes and institutional accumulation."
      }
    },
    "bf73055a0f11209a": {
      "factor_id": "bf73055a0f11209a",
      "factor_name": "Support_Integrity_V1_5D",
      "factor_expression": "(MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Support_Integrity_V1_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies price support integrity by calculating the ratio of the lower shadow length to the 5-day rolling standard deviation of volume. A high value suggests that price rebounds (long lower shadows) are occurring under stable volume conditions, indicating firm institutional absorption rather than volatile price discovery.",
      "factor_formulation": "SI_{5D} = \\frac{\\min(open, close) - low}{TS\\_STD(volume, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "08047bc58707",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the ratio of the lower shadow length (KLOW) to the 5-day rolling standard deviation of volume (VSTD5), positively predicts future returns by identifying price levels where stable accumulation occurs under low-volatility conditions.\n                Concise Observation: Market participants often interpret long lower shadows as signs of recovery, but these signals are frequently false if accompanied by high volume volatility, which indicates unstable price discovery rather than firm support.\n                Concise Justification: Crossing a price-action metric (KLOW) with a volume-stability metric (VSTD5) filters out 'noisy' price rebounds, ensuring that the identified support is characterized by deliberate and steady buying pressure.\n                Concise Knowledge: If a security exhibits significant lower shadows (KLOW) while volume volatility (VSTD5) remains low, it suggests consistent institutional absorption at price floors rather than panic selling or erratic trading; when these two conditions coincide, the price support is more likely to hold.\n                concise Specification: The factor is calculated as KLOW divided by the 5-day standard deviation of volume, where KLOW is the difference between the minimum of open/close and the low price, applied to daily frequency data.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T21:20:41.336586"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1220663117847332,
        "ICIR": 0.0440301932004756,
        "1day.excess_return_without_cost.std": 0.0040936414426882,
        "1day.excess_return_with_cost.annualized_return": 0.0196034096373383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002803713366073,
        "1day.excess_return_without_cost.annualized_return": 0.0667283781125529,
        "1day.excess_return_with_cost.std": 0.0040952096821865,
        "Rank IC": 0.0217174998163428,
        "IC": 0.0058491950065442,
        "1day.excess_return_without_cost.max_drawdown": -0.094328360552949,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0566040960038003,
        "1day.pa": 0.0,
        "l2.valid": 0.9962600993062564,
        "Rank ICIR": 0.1675278112313153,
        "l2.train": 0.9940286244375036,
        "1day.excess_return_with_cost.information_ratio": 0.3102894383287448,
        "1day.excess_return_with_cost.mean": 8.236726738377446e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Support Integrity' framework has successfully improved upon the previous SOTA across most key performance metrics. Specifically, the Smoothed_Support_Integrity_5D (SSI_5D) and its variants have demonstrated a higher Information Ratio (1.056 vs 0.972), a higher Annualized Return (6.67% vs 5.20%), and a slightly improved IC (0.0058 vs 0.0057). However, the Max Drawdown has worsened (-0.094 vs -0.072), suggesting that while the signal is more predictive on average, it may be susceptible to higher tail risk or market-wide volatility regimes. The complexity of the factors remains low (SL < 300, ER < 6), which is positive for generalization.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the ratio of lower shadow length to volume volatility predicts future returns. The improvement seen in the 'Smoothed' version (SSI_5D) indicates that the 'Support Integrity' signal is not just a transient daily noise but a structural accumulation pattern that benefits from temporal filtering. The 'Ranked' version also suggests that the relative strength of this support across the cross-section is a valid alpha source.",
        "decision": true,
        "reason": "Currently, the numerator (lower shadow) is an absolute price value, which might bias the factor towards higher-priced or more volatile stocks. Normalizing the lower shadow by the daily range (KLOW / (High - Low)) creates a unitless ratio of 'recovery strength'. Furthermore, adding a condition or a multiplier that rewards increasing volume (positive volume gradient) alongside low volume volatility could distinguish between 'quiet accumulation' and 'lack of interest'. This aims to address the increased Max Drawdown by ensuring we only capture active support levels."
      }
    },
    "b346bfcb3d9aec73": {
      "factor_id": "b346bfcb3d9aec73",
      "factor_name": "Ranked_Support_Stability_10D",
      "factor_expression": "RANK((MIN($open, $close) - $low) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((MIN($open, $close) - $low) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Support_Stability_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the Support Integrity hypothesis, focusing on the relative strength of price floors. It normalizes the lower shadow by the 10-day volume volatility to identify stocks with the most reliable 'buying-the-dip' signals relative to the market.",
      "factor_formulation": "RSS_{10D} = RANK\\left(\\frac{\\min(open, close) - low}{TS\\_STD(volume, 10)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "08047bc58707",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the ratio of the lower shadow length (KLOW) to the 5-day rolling standard deviation of volume (VSTD5), positively predicts future returns by identifying price levels where stable accumulation occurs under low-volatility conditions.\n                Concise Observation: Market participants often interpret long lower shadows as signs of recovery, but these signals are frequently false if accompanied by high volume volatility, which indicates unstable price discovery rather than firm support.\n                Concise Justification: Crossing a price-action metric (KLOW) with a volume-stability metric (VSTD5) filters out 'noisy' price rebounds, ensuring that the identified support is characterized by deliberate and steady buying pressure.\n                Concise Knowledge: If a security exhibits significant lower shadows (KLOW) while volume volatility (VSTD5) remains low, it suggests consistent institutional absorption at price floors rather than panic selling or erratic trading; when these two conditions coincide, the price support is more likely to hold.\n                concise Specification: The factor is calculated as KLOW divided by the 5-day standard deviation of volume, where KLOW is the difference between the minimum of open/close and the low price, applied to daily frequency data.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T21:20:41.336586"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1220663117847332,
        "ICIR": 0.0440301932004756,
        "1day.excess_return_without_cost.std": 0.0040936414426882,
        "1day.excess_return_with_cost.annualized_return": 0.0196034096373383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002803713366073,
        "1day.excess_return_without_cost.annualized_return": 0.0667283781125529,
        "1day.excess_return_with_cost.std": 0.0040952096821865,
        "Rank IC": 0.0217174998163428,
        "IC": 0.0058491950065442,
        "1day.excess_return_without_cost.max_drawdown": -0.094328360552949,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0566040960038003,
        "1day.pa": 0.0,
        "l2.valid": 0.9962600993062564,
        "Rank ICIR": 0.1675278112313153,
        "l2.train": 0.9940286244375036,
        "1day.excess_return_with_cost.information_ratio": 0.3102894383287448,
        "1day.excess_return_with_cost.mean": 8.236726738377446e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Support Integrity' framework has successfully improved upon the previous SOTA across most key performance metrics. Specifically, the Smoothed_Support_Integrity_5D (SSI_5D) and its variants have demonstrated a higher Information Ratio (1.056 vs 0.972), a higher Annualized Return (6.67% vs 5.20%), and a slightly improved IC (0.0058 vs 0.0057). However, the Max Drawdown has worsened (-0.094 vs -0.072), suggesting that while the signal is more predictive on average, it may be susceptible to higher tail risk or market-wide volatility regimes. The complexity of the factors remains low (SL < 300, ER < 6), which is positive for generalization.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the ratio of lower shadow length to volume volatility predicts future returns. The improvement seen in the 'Smoothed' version (SSI_5D) indicates that the 'Support Integrity' signal is not just a transient daily noise but a structural accumulation pattern that benefits from temporal filtering. The 'Ranked' version also suggests that the relative strength of this support across the cross-section is a valid alpha source.",
        "decision": true,
        "reason": "Currently, the numerator (lower shadow) is an absolute price value, which might bias the factor towards higher-priced or more volatile stocks. Normalizing the lower shadow by the daily range (KLOW / (High - Low)) creates a unitless ratio of 'recovery strength'. Furthermore, adding a condition or a multiplier that rewards increasing volume (positive volume gradient) alongside low volume volatility could distinguish between 'quiet accumulation' and 'lack of interest'. This aims to address the increased Max Drawdown by ensuring we only capture active support levels."
      }
    },
    "1a43e8255bf79e56": {
      "factor_id": "1a43e8255bf79e56",
      "factor_name": "Smoothed_Support_Integrity_5D",
      "factor_expression": "TS_MEAN((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8), 3)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8), 3)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Support_Integrity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor applies a 3-day simple moving average to the Support Integrity ratio to filter out single-day noise. It captures sustained periods where price dips are consistently met with steady, low-volatility buying pressure.",
      "factor_formulation": "SSI_{5D} = TS\\_MEAN\\left(\\frac{\\min(open, close) - low}{TS\\_STD(volume, 5)}, 3\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "08047bc58707",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the ratio of the lower shadow length (KLOW) to the 5-day rolling standard deviation of volume (VSTD5), positively predicts future returns by identifying price levels where stable accumulation occurs under low-volatility conditions.\n                Concise Observation: Market participants often interpret long lower shadows as signs of recovery, but these signals are frequently false if accompanied by high volume volatility, which indicates unstable price discovery rather than firm support.\n                Concise Justification: Crossing a price-action metric (KLOW) with a volume-stability metric (VSTD5) filters out 'noisy' price rebounds, ensuring that the identified support is characterized by deliberate and steady buying pressure.\n                Concise Knowledge: If a security exhibits significant lower shadows (KLOW) while volume volatility (VSTD5) remains low, it suggests consistent institutional absorption at price floors rather than panic selling or erratic trading; when these two conditions coincide, the price support is more likely to hold.\n                concise Specification: The factor is calculated as KLOW divided by the 5-day standard deviation of volume, where KLOW is the difference between the minimum of open/close and the low price, applied to daily frequency data.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T21:20:41.336586"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1220663117847332,
        "ICIR": 0.0440301932004756,
        "1day.excess_return_without_cost.std": 0.0040936414426882,
        "1day.excess_return_with_cost.annualized_return": 0.0196034096373383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002803713366073,
        "1day.excess_return_without_cost.annualized_return": 0.0667283781125529,
        "1day.excess_return_with_cost.std": 0.0040952096821865,
        "Rank IC": 0.0217174998163428,
        "IC": 0.0058491950065442,
        "1day.excess_return_without_cost.max_drawdown": -0.094328360552949,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0566040960038003,
        "1day.pa": 0.0,
        "l2.valid": 0.9962600993062564,
        "Rank ICIR": 0.1675278112313153,
        "l2.train": 0.9940286244375036,
        "1day.excess_return_with_cost.information_ratio": 0.3102894383287448,
        "1day.excess_return_with_cost.mean": 8.236726738377446e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Support Integrity' framework has successfully improved upon the previous SOTA across most key performance metrics. Specifically, the Smoothed_Support_Integrity_5D (SSI_5D) and its variants have demonstrated a higher Information Ratio (1.056 vs 0.972), a higher Annualized Return (6.67% vs 5.20%), and a slightly improved IC (0.0058 vs 0.0057). However, the Max Drawdown has worsened (-0.094 vs -0.072), suggesting that while the signal is more predictive on average, it may be susceptible to higher tail risk or market-wide volatility regimes. The complexity of the factors remains low (SL < 300, ER < 6), which is positive for generalization.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the ratio of lower shadow length to volume volatility predicts future returns. The improvement seen in the 'Smoothed' version (SSI_5D) indicates that the 'Support Integrity' signal is not just a transient daily noise but a structural accumulation pattern that benefits from temporal filtering. The 'Ranked' version also suggests that the relative strength of this support across the cross-section is a valid alpha source.",
        "decision": true,
        "reason": "Currently, the numerator (lower shadow) is an absolute price value, which might bias the factor towards higher-priced or more volatile stocks. Normalizing the lower shadow by the daily range (KLOW / (High - Low)) creates a unitless ratio of 'recovery strength'. Furthermore, adding a condition or a multiplier that rewards increasing volume (positive volume gradient) alongside low volume volatility could distinguish between 'quiet accumulation' and 'lack of interest'. This aims to address the increased Max Drawdown by ensuring we only capture active support levels."
      }
    },
    "ce9a6bdb524aff8b": {
      "factor_id": "ce9a6bdb524aff8b",
      "factor_name": "Capitulation_Reversal_Factor_60D_20D",
      "factor_expression": "TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 20)\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Reversal_Factor_60D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential mean-reversion opportunities by multiplying the 60-day price rate of change with the 20-day correlation between price and volume. A high positive value suggests a significant price decline accompanied by a negative price-volume correlation (selling climax), signaling an imminent reversal.",
      "factor_formulation": "CRF = TS\\_PCTCHANGE(close, 60) \\times TS\\_CORR(close, volume, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "0b905e4baccd",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Long-term Mean Reversion' factor can be constructed by identifying assets where a significant 60-day price decline (ROC60) coincides with a negative 20-day price-volume correlation (CORR20), signaling an exhaustive capitulation phase and an imminent reversal.\n                Concise Observation: Market participants often exhibit panic selling at the end of a prolonged downtrend, leading to high volume at local price bottoms which creates a divergence between price trend and volume sentiment.\n                Concise Justification: Negative correlation between price changes and volume during a downtrend suggests that price drops are being met with high liquidity absorption, often marking the transition from weak-hand sellers to strong-hand buyers.\n                Concise Knowledge: If a long-term price decline is accompanied by increasing volume on down days (negative price-volume correlation), it indicates a 'selling climax' or capitulation; when this occurs, the asset is likely oversold and primed for a mean-reversion bounce.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20), where a large positive value (negative ROC * negative CORR) indicates a strong reversal signal.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T21:26:42.805877"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105290493078646,
        "ICIR": 0.0439195784524141,
        "1day.excess_return_without_cost.std": 0.0048330436216784,
        "1day.excess_return_with_cost.annualized_return": 0.0382655995505111,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003592290116985,
        "1day.excess_return_without_cost.annualized_return": 0.0854965047842451,
        "1day.excess_return_with_cost.std": 0.0048352393107134,
        "Rank IC": 0.023432169172062,
        "IC": 0.0066239443812915,
        "1day.excess_return_without_cost.max_drawdown": -0.0970875209736863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1466718922887986,
        "1day.pa": 0.0,
        "l2.valid": 0.996886175851892,
        "Rank ICIR": 0.1576605159055305,
        "l2.train": 0.9940730344097998,
        "1day.excess_return_with_cost.information_ratio": 0.5129819336478243,
        "1day.excess_return_with_cost.mean": 0.0001607798300441
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Long-term Mean Reversion' hypothesis by moving from a simple product of signals to a Z-score-based intensity measure and a cross-sectional ranking approach. The results show a significant improvement across most key performance indicators. Specifically, the Information Ratio (IR) increased from 0.97 to 1.15, the Annualized Return rose from 5.2% to 8.5%, and the Information Coefficient (IC) improved from 0.0058 to 0.0066. Although the Max Drawdown slightly worsened (-0.097 vs -0.072), the overall risk-adjusted return profile is substantially stronger.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining a long-term price decline (60-day) with a negative price-volume correlation (20-day) identifies high-probability mean reversion points. The 'Capitulation_Intensity_ZScore' and 'Ranked_Capitulation_Signal_V1' implementations demonstrate that normalizing the magnitude of the decline (via Z-score) or the relative position (via Rank) provides a more robust signal than the raw product used in the initial CRF factor.",
        "decision": true,
        "reason": "While the current factors identify price and volume exhaustion, they do not account for the 'quietness' of the bottom. High volatility at the bottom can often lead to further 'falling knife' scenarios. By requiring the 60-day decline and negative PV correlation to coincide with a 5-day volatility that is low relative to the 20-day average, we can isolate the exact moment where the selling pressure vanishes, leading to a higher quality entry for the reversal."
      }
    },
    "0430473113fff2ac": {
      "factor_id": "0430473113fff2ac",
      "factor_name": "Ranked_Capitulation_Signal_V1",
      "factor_expression": "RANK(0 - TS_PCTCHANGE($close, 60)) + RANK(0 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(0 - TS_PCTCHANGE($close, 60)) + RANK(0 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Capitulation_Signal_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the capitulation hypothesis. It focuses on assets with the most extreme negative 60-day returns and the most negative 20-day price-volume correlations. By ranking these components, the factor becomes more robust to market-wide regime shifts.",
      "factor_formulation": "RCS = RANK(-TS\\_PCTCHANGE(close, 60)) + RANK(-TS\\_CORR(close, volume, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "0b905e4baccd",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Long-term Mean Reversion' factor can be constructed by identifying assets where a significant 60-day price decline (ROC60) coincides with a negative 20-day price-volume correlation (CORR20), signaling an exhaustive capitulation phase and an imminent reversal.\n                Concise Observation: Market participants often exhibit panic selling at the end of a prolonged downtrend, leading to high volume at local price bottoms which creates a divergence between price trend and volume sentiment.\n                Concise Justification: Negative correlation between price changes and volume during a downtrend suggests that price drops are being met with high liquidity absorption, often marking the transition from weak-hand sellers to strong-hand buyers.\n                Concise Knowledge: If a long-term price decline is accompanied by increasing volume on down days (negative price-volume correlation), it indicates a 'selling climax' or capitulation; when this occurs, the asset is likely oversold and primed for a mean-reversion bounce.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20), where a large positive value (negative ROC * negative CORR) indicates a strong reversal signal.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T21:26:42.805877"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105290493078646,
        "ICIR": 0.0439195784524141,
        "1day.excess_return_without_cost.std": 0.0048330436216784,
        "1day.excess_return_with_cost.annualized_return": 0.0382655995505111,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003592290116985,
        "1day.excess_return_without_cost.annualized_return": 0.0854965047842451,
        "1day.excess_return_with_cost.std": 0.0048352393107134,
        "Rank IC": 0.023432169172062,
        "IC": 0.0066239443812915,
        "1day.excess_return_without_cost.max_drawdown": -0.0970875209736863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1466718922887986,
        "1day.pa": 0.0,
        "l2.valid": 0.996886175851892,
        "Rank ICIR": 0.1576605159055305,
        "l2.train": 0.9940730344097998,
        "1day.excess_return_with_cost.information_ratio": 0.5129819336478243,
        "1day.excess_return_with_cost.mean": 0.0001607798300441
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Long-term Mean Reversion' hypothesis by moving from a simple product of signals to a Z-score-based intensity measure and a cross-sectional ranking approach. The results show a significant improvement across most key performance indicators. Specifically, the Information Ratio (IR) increased from 0.97 to 1.15, the Annualized Return rose from 5.2% to 8.5%, and the Information Coefficient (IC) improved from 0.0058 to 0.0066. Although the Max Drawdown slightly worsened (-0.097 vs -0.072), the overall risk-adjusted return profile is substantially stronger.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining a long-term price decline (60-day) with a negative price-volume correlation (20-day) identifies high-probability mean reversion points. The 'Capitulation_Intensity_ZScore' and 'Ranked_Capitulation_Signal_V1' implementations demonstrate that normalizing the magnitude of the decline (via Z-score) or the relative position (via Rank) provides a more robust signal than the raw product used in the initial CRF factor.",
        "decision": true,
        "reason": "While the current factors identify price and volume exhaustion, they do not account for the 'quietness' of the bottom. High volatility at the bottom can often lead to further 'falling knife' scenarios. By requiring the 60-day decline and negative PV correlation to coincide with a 5-day volatility that is low relative to the 20-day average, we can isolate the exact moment where the selling pressure vanishes, leading to a higher quality entry for the reversal."
      }
    },
    "ccdb6c28bb089f3f": {
      "factor_id": "ccdb6c28bb089f3f",
      "factor_name": "Capitulation_Intensity_ZScore",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 60), 60) * (0 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_PCTCHANGE($close, 60), 60) * (0 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Intensity_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the intensity of the capitulation by calculating the Z-score of the 60-day price decline and multiplying it by the sign-inverted 20-day price-volume correlation. It targets stocks that are statistically oversold while exhibiting volume-driven exhaustion.",
      "factor_formulation": "CIZ = TS\\_ZSCORE(TS\\_PCTCHANGE(close, 60), 60) \\times (-TS\\_CORR(close, volume, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "0b905e4baccd",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Long-term Mean Reversion' factor can be constructed by identifying assets where a significant 60-day price decline (ROC60) coincides with a negative 20-day price-volume correlation (CORR20), signaling an exhaustive capitulation phase and an imminent reversal.\n                Concise Observation: Market participants often exhibit panic selling at the end of a prolonged downtrend, leading to high volume at local price bottoms which creates a divergence between price trend and volume sentiment.\n                Concise Justification: Negative correlation between price changes and volume during a downtrend suggests that price drops are being met with high liquidity absorption, often marking the transition from weak-hand sellers to strong-hand buyers.\n                Concise Knowledge: If a long-term price decline is accompanied by increasing volume on down days (negative price-volume correlation), it indicates a 'selling climax' or capitulation; when this occurs, the asset is likely oversold and primed for a mean-reversion bounce.\n                concise Specification: The factor is defined as the product of the 60-day Rate of Change (ROC60) and the 20-day Pearson correlation between daily close price and daily volume (CORR20), where a large positive value (negative ROC * negative CORR) indicates a strong reversal signal.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T21:26:42.805877"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105290493078646,
        "ICIR": 0.0439195784524141,
        "1day.excess_return_without_cost.std": 0.0048330436216784,
        "1day.excess_return_with_cost.annualized_return": 0.0382655995505111,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003592290116985,
        "1day.excess_return_without_cost.annualized_return": 0.0854965047842451,
        "1day.excess_return_with_cost.std": 0.0048352393107134,
        "Rank IC": 0.023432169172062,
        "IC": 0.0066239443812915,
        "1day.excess_return_without_cost.max_drawdown": -0.0970875209736863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1466718922887986,
        "1day.pa": 0.0,
        "l2.valid": 0.996886175851892,
        "Rank ICIR": 0.1576605159055305,
        "l2.train": 0.9940730344097998,
        "1day.excess_return_with_cost.information_ratio": 0.5129819336478243,
        "1day.excess_return_with_cost.mean": 0.0001607798300441
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Long-term Mean Reversion' hypothesis by moving from a simple product of signals to a Z-score-based intensity measure and a cross-sectional ranking approach. The results show a significant improvement across most key performance indicators. Specifically, the Information Ratio (IR) increased from 0.97 to 1.15, the Annualized Return rose from 5.2% to 8.5%, and the Information Coefficient (IC) improved from 0.0058 to 0.0066. Although the Max Drawdown slightly worsened (-0.097 vs -0.072), the overall risk-adjusted return profile is substantially stronger.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining a long-term price decline (60-day) with a negative price-volume correlation (20-day) identifies high-probability mean reversion points. The 'Capitulation_Intensity_ZScore' and 'Ranked_Capitulation_Signal_V1' implementations demonstrate that normalizing the magnitude of the decline (via Z-score) or the relative position (via Rank) provides a more robust signal than the raw product used in the initial CRF factor.",
        "decision": true,
        "reason": "While the current factors identify price and volume exhaustion, they do not account for the 'quietness' of the bottom. High volatility at the bottom can often lead to further 'falling knife' scenarios. By requiring the 60-day decline and negative PV correlation to coincide with a 5-day volatility that is low relative to the 20-day average, we can isolate the exact moment where the selling pressure vanishes, leading to a higher quality entry for the reversal."
      }
    },
    "b02c44856a726753": {
      "factor_id": "b02c44856a726753",
      "factor_name": "Trend_Fragility_Index_10D",
      "factor_expression": "TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the instability of a price trend by taking the ratio of short-term volatility (5-day standard deviation) to the strength of the linear trend (R-squared over 10 days). A high ratio indicates that price movements are erratic and lack a clear linear direction, suggesting trend exhaustion or potential reversal.",
      "factor_formulation": "\\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "e56a8686d095",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Fragility Factor, defined as the ratio of the 5-day standard deviation of closing prices to the 10-day R-squared of a linear price trend, negatively predicts future returns as high volatility coupled with low trend linearity signals an exhausted or unstable price movement.\n                Concise Observation: Financial time series often exhibit periods where price moves significantly but without a consistent directional trend, often preceding a change in market regime or a mean-reversion event.\n                Concise Justification: Standard deviation measures total risk/uncertainty, while R-squared measures the strength of a linear trend; a high ratio suggests that the price movement is driven by erratic fluctuations rather than a sustainable, persistent trend.\n                Concise Knowledge: If price volatility increases while the linear fit of the price trend decreases, the current price direction is likely to reverse or stall; high 'Trend Fragility' identifies points where noise dominates the signal, suggesting a structural break.\n                concise Specification: The factor is calculated as STD($close, 5) divided by the R-squared of $close against a time index over a 10-day window, where higher values are expected to correlate with lower subsequent 5-day returns.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T21:41:56.661882"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1352256581710751,
        "ICIR": 0.026527077984914,
        "1day.excess_return_without_cost.std": 0.0038799464095435,
        "1day.excess_return_with_cost.annualized_return": -0.0189183095099073,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001198950015471,
        "1day.excess_return_without_cost.annualized_return": 0.0285350103682255,
        "1day.excess_return_with_cost.std": 0.0038810371915785,
        "Rank IC": 0.0167505831134485,
        "IC": 0.0035282763914872,
        "1day.excess_return_without_cost.max_drawdown": -0.0866660210780321,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4767205012622743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967005579695858,
        "Rank ICIR": 0.1272032735820837,
        "l2.train": 0.9943085630183977,
        "1day.excess_return_with_cost.information_ratio": -0.3159701405140768,
        "1day.excess_return_with_cost.mean": -7.948869541977874e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility' hypothesis. While the core concept—that high volatility relative to trend linearity (R-squared) predicts poor returns—is theoretically sound, the current implementations (Trend_Fragility_Index_10D, Cross_Sectional_Fragility_Rank, and Linear_Trend_Efficiency_Ratio) underperformed compared to the SOTA result across all key metrics including IC, Information Ratio, and Annualized Return. The best performing variant in this batch was the 'Linear_Trend_Efficiency_Ratio', but it still failed to surpass the previous SOTA benchmark. The results suggest that while the 'fragility' signal exists, the current mathematical formulations might be too sensitive to absolute price levels or short-term noise.",
        "hypothesis_evaluation": "The hypothesis that trend fragility negatively predicts returns is partially supported by the positive IC (0.0035), but the magnitude is weak. The 'Linear_Trend_Efficiency_Ratio' performed relatively better by normalizing volatility with the mean price (Coefficient of Variation), suggesting that raw standard deviation without price-level normalization (as seen in the first two factors) introduces scale bias that weakens the signal.",
        "decision": false,
        "reason": "The current factors used absolute TS_STD, which is highly dependent on the stock's price level. By replacing TS_STD with the 'Average True Range (ATR) / Price' or 'High-Low Range / Close', we create a scale-invariant measure of volatility. Furthermore, the 10-day window for R-squared might be too short and sensitive to 1-2 day outliers; extending this to 20 days while maintaining a 5-day volatility measure will better capture the 'instability' of a established trend. This maintains a low complexity (ER < 6) while improving the robustness of the fragility measure."
      }
    },
    "7123b8b76a5eeeef": {
      "factor_id": "7123b8b76a5eeeef",
      "factor_name": "Cross_Sectional_Fragility_Rank",
      "factor_expression": "RANK(TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 0.01))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 0.01))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Fragility_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the Trend Fragility hypothesis. It identifies stocks with the most 'noisy' price action relative to their trend persistence by comparing the 5-day price range volatility to the squared correlation of price against time over 10 days.",
      "factor_formulation": "RANK(TS\\_STD(close, 5) / (POW(TS\\_CORR(close, SEQUENCE(10), 10), 2) + 0.01))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "e56a8686d095",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Fragility Factor, defined as the ratio of the 5-day standard deviation of closing prices to the 10-day R-squared of a linear price trend, negatively predicts future returns as high volatility coupled with low trend linearity signals an exhausted or unstable price movement.\n                Concise Observation: Financial time series often exhibit periods where price moves significantly but without a consistent directional trend, often preceding a change in market regime or a mean-reversion event.\n                Concise Justification: Standard deviation measures total risk/uncertainty, while R-squared measures the strength of a linear trend; a high ratio suggests that the price movement is driven by erratic fluctuations rather than a sustainable, persistent trend.\n                Concise Knowledge: If price volatility increases while the linear fit of the price trend decreases, the current price direction is likely to reverse or stall; high 'Trend Fragility' identifies points where noise dominates the signal, suggesting a structural break.\n                concise Specification: The factor is calculated as STD($close, 5) divided by the R-squared of $close against a time index over a 10-day window, where higher values are expected to correlate with lower subsequent 5-day returns.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T21:41:56.661882"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1352256581710751,
        "ICIR": 0.026527077984914,
        "1day.excess_return_without_cost.std": 0.0038799464095435,
        "1day.excess_return_with_cost.annualized_return": -0.0189183095099073,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001198950015471,
        "1day.excess_return_without_cost.annualized_return": 0.0285350103682255,
        "1day.excess_return_with_cost.std": 0.0038810371915785,
        "Rank IC": 0.0167505831134485,
        "IC": 0.0035282763914872,
        "1day.excess_return_without_cost.max_drawdown": -0.0866660210780321,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4767205012622743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967005579695858,
        "Rank ICIR": 0.1272032735820837,
        "l2.train": 0.9943085630183977,
        "1day.excess_return_with_cost.information_ratio": -0.3159701405140768,
        "1day.excess_return_with_cost.mean": -7.948869541977874e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility' hypothesis. While the core concept—that high volatility relative to trend linearity (R-squared) predicts poor returns—is theoretically sound, the current implementations (Trend_Fragility_Index_10D, Cross_Sectional_Fragility_Rank, and Linear_Trend_Efficiency_Ratio) underperformed compared to the SOTA result across all key metrics including IC, Information Ratio, and Annualized Return. The best performing variant in this batch was the 'Linear_Trend_Efficiency_Ratio', but it still failed to surpass the previous SOTA benchmark. The results suggest that while the 'fragility' signal exists, the current mathematical formulations might be too sensitive to absolute price levels or short-term noise.",
        "hypothesis_evaluation": "The hypothesis that trend fragility negatively predicts returns is partially supported by the positive IC (0.0035), but the magnitude is weak. The 'Linear_Trend_Efficiency_Ratio' performed relatively better by normalizing volatility with the mean price (Coefficient of Variation), suggesting that raw standard deviation without price-level normalization (as seen in the first two factors) introduces scale bias that weakens the signal.",
        "decision": false,
        "reason": "The current factors used absolute TS_STD, which is highly dependent on the stock's price level. By replacing TS_STD with the 'Average True Range (ATR) / Price' or 'High-Low Range / Close', we create a scale-invariant measure of volatility. Furthermore, the 10-day window for R-squared might be too short and sensitive to 1-2 day outliers; extending this to 20 days while maintaining a 5-day volatility measure will better capture the 'instability' of a established trend. This maintains a low complexity (ER < 6) while improving the robustness of the fragility measure."
      }
    },
    "62ace64de277e4c6": {
      "factor_id": "62ace64de277e4c6",
      "factor_name": "Linear_Trend_Efficiency_Ratio",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_STD($close, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_STD($close, 10) / (TS_MEAN($close, 10) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the inverse of trend fragility, representing 'Trend Efficiency'. It uses the 10-day R-squared (linearity) normalized by the 10-day price volatility. Low values of this factor correspond to high fragility, indicating that the price is moving without a stable linear structure.",
      "factor_formulation": "\\frac{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}{TS\\_STD(close, 10) / TS\\_MEAN(close, 10) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "e56a8686d095",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Trend Fragility Factor, defined as the ratio of the 5-day standard deviation of closing prices to the 10-day R-squared of a linear price trend, negatively predicts future returns as high volatility coupled with low trend linearity signals an exhausted or unstable price movement.\n                Concise Observation: Financial time series often exhibit periods where price moves significantly but without a consistent directional trend, often preceding a change in market regime or a mean-reversion event.\n                Concise Justification: Standard deviation measures total risk/uncertainty, while R-squared measures the strength of a linear trend; a high ratio suggests that the price movement is driven by erratic fluctuations rather than a sustainable, persistent trend.\n                Concise Knowledge: If price volatility increases while the linear fit of the price trend decreases, the current price direction is likely to reverse or stall; high 'Trend Fragility' identifies points where noise dominates the signal, suggesting a structural break.\n                concise Specification: The factor is calculated as STD($close, 5) divided by the R-squared of $close against a time index over a 10-day window, where higher values are expected to correlate with lower subsequent 5-day returns.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T21:41:56.661882"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1352256581710751,
        "ICIR": 0.026527077984914,
        "1day.excess_return_without_cost.std": 0.0038799464095435,
        "1day.excess_return_with_cost.annualized_return": -0.0189183095099073,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001198950015471,
        "1day.excess_return_without_cost.annualized_return": 0.0285350103682255,
        "1day.excess_return_with_cost.std": 0.0038810371915785,
        "Rank IC": 0.0167505831134485,
        "IC": 0.0035282763914872,
        "1day.excess_return_without_cost.max_drawdown": -0.0866660210780321,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4767205012622743,
        "1day.pa": 0.0,
        "l2.valid": 0.9967005579695858,
        "Rank ICIR": 0.1272032735820837,
        "l2.train": 0.9943085630183977,
        "1day.excess_return_with_cost.information_ratio": -0.3159701405140768,
        "1day.excess_return_with_cost.mean": -7.948869541977874e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility' hypothesis. While the core concept—that high volatility relative to trend linearity (R-squared) predicts poor returns—is theoretically sound, the current implementations (Trend_Fragility_Index_10D, Cross_Sectional_Fragility_Rank, and Linear_Trend_Efficiency_Ratio) underperformed compared to the SOTA result across all key metrics including IC, Information Ratio, and Annualized Return. The best performing variant in this batch was the 'Linear_Trend_Efficiency_Ratio', but it still failed to surpass the previous SOTA benchmark. The results suggest that while the 'fragility' signal exists, the current mathematical formulations might be too sensitive to absolute price levels or short-term noise.",
        "hypothesis_evaluation": "The hypothesis that trend fragility negatively predicts returns is partially supported by the positive IC (0.0035), but the magnitude is weak. The 'Linear_Trend_Efficiency_Ratio' performed relatively better by normalizing volatility with the mean price (Coefficient of Variation), suggesting that raw standard deviation without price-level normalization (as seen in the first two factors) introduces scale bias that weakens the signal.",
        "decision": false,
        "reason": "The current factors used absolute TS_STD, which is highly dependent on the stock's price level. By replacing TS_STD with the 'Average True Range (ATR) / Price' or 'High-Low Range / Close', we create a scale-invariant measure of volatility. Furthermore, the 10-day window for R-squared might be too short and sensitive to 1-2 day outliers; extending this to 20 days while maintaining a 5-day volatility measure will better capture the 'instability' of a established trend. This maintains a low complexity (ER < 6) while improving the robustness of the fragility measure."
      }
    },
    "ec7649aee54fdd53": {
      "factor_id": "ec7649aee54fdd53",
      "factor_name": "LAR_Residual_Volume_Stability_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) / (1.0 + TS_STD($volume, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) / (1.0 + TS_STD($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"LAR_Residual_Volume_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Liquidity-Adjusted Rebound (LAR) factor identifies mean-reversion opportunities by dividing the 5-day price residual (capturing deviations from the trend) by the volume volatility. Low volume volatility during a price dip suggests orderly selling rather than panic, increasing the probability of a rebound.",
      "factor_formulation": "LAR = \\frac{REGRESI(close, SEQUENCE(5), 5)}{1 + TS\\_STD(volume, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "1fbc23296342",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Liquidity-Adjusted Rebound (LAR) factor, defined as the product of the 5-day price residual (RESI5) and the inverse of the 5-day volume standard deviation (VSTD5), identifies high-probability mean-reversion opportunities by isolating price exhaustion from liquidity-driven volatility.\n                Concise Observation: Price residuals often capture noise, but their predictive power for rebounds increases significantly when the underlying volume trend is stable, suggesting a lack of institutional 'fire-sale' behavior.\n                Concise Justification: Stable volume (low VSTD) during a price dip suggests the selling pressure is being absorbed by a steady hand, implying that the negative residual is a temporary deviation from the mean rather than a structural breakdown.\n                Concise Knowledge: If a significant price decline occurs with low volume volatility, it indicates a consistent, non-panic sell-off; when such orderly price residuals are isolated, they are more likely to mean-revert compared to high-volatility price shocks.\n                concise Specification: RESI5 is the residual of a 5-day linear regression of close prices; VSTD5 is the standard deviation of volume over 5 days; the factor is RESI5 divided by (1 + VSTD5) to reward deep negative residuals with low volume variance.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T21:47:31.207738"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current experiment results for the three implemented factors (LAR_Residual_Volume_Stability_5D, Z_LAR_Reversion_10D, and Smoothed_LAR_Momentum_Exhaustion) are missing ('NaN') in the provided results table. Only the SOTA Result is available for comparison. This indicates that while the factors were implemented, they either failed to generate valid signals across the testing period or the performance metrics were not successfully captured in this specific summary. The SOTA result itself shows a modest IC of 0.0058 and an Information Ratio of 0.97, suggesting the general 'Liquidity-Adjusted Rebound' framework has some predictive power but requires more robust scaling or signal isolation.",
        "hypothesis_evaluation": "The hypothesis that isolating price residuals from volume-driven volatility identifies mean-reversion is theoretically sound, but the current implementation using '1 + TS_STD(volume, n)' as a denominator might be problematic. Volume standard deviation is highly scale-dependent across different stocks; a high-priced stock with high volume will naturally have a much larger STD than a small-cap stock, which could drown out the price residual signal in the cross-section. The 'NaN' results suggest the factors might be producing extreme values or lack sufficient coverage.",
        "decision": false,
        "reason": "To address the scale-dependency of volume volatility, using the Coefficient of Variation (TS_STD(volume, n) / SMA(volume, n)) provides a unitless measure of 'orderly vs. chaotic' volume. Furthermore, replacing the raw regression residual with a Z-score or a normalized distance from the trend will prevent a few high-volatility stocks from dominating the factor's distribution. This maintains the core logic of the LAR hypothesis while improving its mathematical robustness and comparability across the universe."
      }
    },
    "ee478a1bdebbd132": {
      "factor_id": "ee478a1bdebbd132",
      "factor_name": "Z_LAR_Reversion_10D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(10), 10) / (1.0 + TS_STD($volume, 10)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(10), 10) / (1.0 + TS_STD($volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Z_LAR_Reversion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the Liquidity-Adjusted Rebound factor using a 10-day window for volume stability. It isolates stocks where the price has deviated negatively from its 10-day trend while volume remains stable, normalized by the cross-sectional rank for better comparability.",
      "factor_formulation": "Z\\_LAR = RANK(REGRESI(close, SEQUENCE(10), 10) / (1 + TS\\_STD(volume, 10)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "1fbc23296342",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Liquidity-Adjusted Rebound (LAR) factor, defined as the product of the 5-day price residual (RESI5) and the inverse of the 5-day volume standard deviation (VSTD5), identifies high-probability mean-reversion opportunities by isolating price exhaustion from liquidity-driven volatility.\n                Concise Observation: Price residuals often capture noise, but their predictive power for rebounds increases significantly when the underlying volume trend is stable, suggesting a lack of institutional 'fire-sale' behavior.\n                Concise Justification: Stable volume (low VSTD) during a price dip suggests the selling pressure is being absorbed by a steady hand, implying that the negative residual is a temporary deviation from the mean rather than a structural breakdown.\n                Concise Knowledge: If a significant price decline occurs with low volume volatility, it indicates a consistent, non-panic sell-off; when such orderly price residuals are isolated, they are more likely to mean-revert compared to high-volatility price shocks.\n                concise Specification: RESI5 is the residual of a 5-day linear regression of close prices; VSTD5 is the standard deviation of volume over 5 days; the factor is RESI5 divided by (1 + VSTD5) to reward deep negative residuals with low volume variance.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T21:47:31.207738"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current experiment results for the three implemented factors (LAR_Residual_Volume_Stability_5D, Z_LAR_Reversion_10D, and Smoothed_LAR_Momentum_Exhaustion) are missing ('NaN') in the provided results table. Only the SOTA Result is available for comparison. This indicates that while the factors were implemented, they either failed to generate valid signals across the testing period or the performance metrics were not successfully captured in this specific summary. The SOTA result itself shows a modest IC of 0.0058 and an Information Ratio of 0.97, suggesting the general 'Liquidity-Adjusted Rebound' framework has some predictive power but requires more robust scaling or signal isolation.",
        "hypothesis_evaluation": "The hypothesis that isolating price residuals from volume-driven volatility identifies mean-reversion is theoretically sound, but the current implementation using '1 + TS_STD(volume, n)' as a denominator might be problematic. Volume standard deviation is highly scale-dependent across different stocks; a high-priced stock with high volume will naturally have a much larger STD than a small-cap stock, which could drown out the price residual signal in the cross-section. The 'NaN' results suggest the factors might be producing extreme values or lack sufficient coverage.",
        "decision": false,
        "reason": "To address the scale-dependency of volume volatility, using the Coefficient of Variation (TS_STD(volume, n) / SMA(volume, n)) provides a unitless measure of 'orderly vs. chaotic' volume. Furthermore, replacing the raw regression residual with a Z-score or a normalized distance from the trend will prevent a few high-volatility stocks from dominating the factor's distribution. This maintains the core logic of the LAR hypothesis while improving its mathematical robustness and comparability across the universe."
      }
    },
    "2a145e7ee6ef7c9d": {
      "factor_id": "2a145e7ee6ef7c9d",
      "factor_name": "Smoothed_LAR_Momentum_Exhaustion",
      "factor_expression": "SMA(REGRESI($close, SEQUENCE(5), 5) / (1.0 + TS_STD($volume, 5)), 3, 1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SMA(REGRESI($close, SEQUENCE(5), 5) / (1.0 + TS_STD($volume, 5)), 3, 1)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_LAR_Momentum_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor applies a 3-day simple moving average to the LAR logic to filter out high-frequency noise. It identifies sustained price exhaustion under low liquidity volatility, suggesting a higher confidence mean-reversion signal.",
      "factor_formulation": "SLAR = SMA(\\frac{REGRESI(close, SEQUENCE(5), 5)}{1 + TS\\_STD(volume, 5)}, 3, 1)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "1fbc23296342",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The Liquidity-Adjusted Rebound (LAR) factor, defined as the product of the 5-day price residual (RESI5) and the inverse of the 5-day volume standard deviation (VSTD5), identifies high-probability mean-reversion opportunities by isolating price exhaustion from liquidity-driven volatility.\n                Concise Observation: Price residuals often capture noise, but their predictive power for rebounds increases significantly when the underlying volume trend is stable, suggesting a lack of institutional 'fire-sale' behavior.\n                Concise Justification: Stable volume (low VSTD) during a price dip suggests the selling pressure is being absorbed by a steady hand, implying that the negative residual is a temporary deviation from the mean rather than a structural breakdown.\n                Concise Knowledge: If a significant price decline occurs with low volume volatility, it indicates a consistent, non-panic sell-off; when such orderly price residuals are isolated, they are more likely to mean-revert compared to high-volatility price shocks.\n                concise Specification: RESI5 is the residual of a 5-day linear regression of close prices; VSTD5 is the standard deviation of volume over 5 days; the factor is RESI5 divided by (1 + VSTD5) to reward deep negative residuals with low volume variance.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T21:47:31.207738"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current experiment results for the three implemented factors (LAR_Residual_Volume_Stability_5D, Z_LAR_Reversion_10D, and Smoothed_LAR_Momentum_Exhaustion) are missing ('NaN') in the provided results table. Only the SOTA Result is available for comparison. This indicates that while the factors were implemented, they either failed to generate valid signals across the testing period or the performance metrics were not successfully captured in this specific summary. The SOTA result itself shows a modest IC of 0.0058 and an Information Ratio of 0.97, suggesting the general 'Liquidity-Adjusted Rebound' framework has some predictive power but requires more robust scaling or signal isolation.",
        "hypothesis_evaluation": "The hypothesis that isolating price residuals from volume-driven volatility identifies mean-reversion is theoretically sound, but the current implementation using '1 + TS_STD(volume, n)' as a denominator might be problematic. Volume standard deviation is highly scale-dependent across different stocks; a high-priced stock with high volume will naturally have a much larger STD than a small-cap stock, which could drown out the price residual signal in the cross-section. The 'NaN' results suggest the factors might be producing extreme values or lack sufficient coverage.",
        "decision": false,
        "reason": "To address the scale-dependency of volume volatility, using the Coefficient of Variation (TS_STD(volume, n) / SMA(volume, n)) provides a unitless measure of 'orderly vs. chaotic' volume. Furthermore, replacing the raw regression residual with a Z-score or a normalized distance from the trend will prevent a few high-volatility stocks from dominating the factor's distribution. This maintains the core logic of the LAR hypothesis while improving its mathematical robustness and comparability across the universe."
      }
    },
    "94d25e79ba1d9311": {
      "factor_id": "94d25e79ba1d9311",
      "factor_name": "Abnormal_Liquidity_Consumption_Ratio_5D",
      "factor_expression": "RANK(($high - $low) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_STD($close / DELAY($close, 1) - 1, 5) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Abnormal_Liquidity_Consumption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the ratio of the current day's price range (High-Low) to the 5-day rolling standard deviation of daily returns. It identifies periods where intraday price volatility significantly exceeds the recent interday volatility regime, suggesting potential liquidity exhaustion or overextension.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{high} - \\text{low}}{\\text{TS\\_STD}(\\text{return}, 5) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "c8d9fff8e6e4",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The ratio of the current day's price range (High-Low) to the 5-day standard deviation of daily returns identifies periods of abnormal liquidity consumption and predicts short-term mean reversion or trend exhaustion.\n                Concise Observation: The relationship between daily price extremes (High/Low) and closing-price-based volatility (STD) often diverges during market stress, where intraday noise increases faster than interday trend strength.\n                Concise Justification: Comparing a point-in-time range (KLEN) to a trailing volatility measure (STD5) captures the 'volatility of volatility' and the immediate imbalance between buyer and seller urgency relative to the established regime.\n                Concise Knowledge: If the intraday range significantly exceeds the recent historical volatility, it indicates a surge in informed trading or panic-driven liquidity demand; when this ratio reaches extreme levels, the market is likely to experience a temporary price correction as liquidity providers demand a premium for the heightened risk.\n                concise Specification: The factor is defined as (High - Low) / STD(LogReturn, 5). A high value suggests an 'overextended' intraday move relative to the 5-day baseline, expected to negatively correlate with the next 5-day forward returns in a mean-reverting market.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T21:51:13.205695"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0994481113999163,
        "ICIR": 0.0342210459476005,
        "1day.excess_return_without_cost.std": 0.0038531976957521,
        "1day.excess_return_with_cost.annualized_return": 0.0170952998995187,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002718211856144,
        "1day.excess_return_without_cost.annualized_return": 0.064693442176239,
        "1day.excess_return_with_cost.std": 0.003855677316592,
        "Rank IC": 0.0216769045323516,
        "IC": 0.0043713920080057,
        "1day.excess_return_without_cost.max_drawdown": -0.0861035372663329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0883046606789435,
        "1day.pa": 0.0,
        "l2.valid": 0.9962563804229888,
        "Rank ICIR": 0.1685037786293848,
        "l2.train": 0.9935761979131807,
        "1day.excess_return_with_cost.information_ratio": 0.2874005301850193,
        "1day.excess_return_with_cost.mean": 7.182899117444871e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the ratio of intraday range to interday return volatility. The results show a significant improvement in the Information Ratio (1.088 vs 0.972) and Annualized Return (0.0647 vs 0.0520) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. The 'Abnormal_Liquidity_Consumption_Ratio_5D' and its smoothed/Z-scored variants successfully captured short-term alpha, suggesting that the relationship between intraday price action and recent volatility regimes is a potent predictor.",
        "hypothesis_evaluation": "The hypothesis is strongly supported. The metrics indicate that normalizing the intraday range by return standard deviation effectively identifies profitable signals. The improvement in Information Ratio suggests that this normalization provides a more stable risk-adjusted return than previous methods. However, the slight drop in IC and increase in drawdown suggest that while the 'extreme' signals are profitable, they may introduce higher tail risk or timing sensitivity.",
        "decision": true,
        "reason": "While the current range-to-volatility ratio works well, it treats all 'wide range' days equally. A wide range on low volume might indicate a lack of liquidity (slippage), whereas a wide range on high volume indicates active liquidity consumption. By integrating a volume component (e.g., current volume relative to its 5-day average), we can refine the signal to focus on 'True' liquidity exhaustion events, likely improving the IC and reducing the Max Drawdown by filtering out false signals."
      }
    },
    "cfc1ea350f314ce9": {
      "factor_id": "cfc1ea350f314ce9",
      "factor_name": "Relative_Range_Volatility_ZScore_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (TS_STD($return, 10) + 1e-8), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / TS_STD(TS_PCTCHANGE($close, 1), 10), 10)\" # Your output factor expression will be filled in here\n    name = \"Relative_Range_Volatility_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor calculates the Z-score of the intraday range normalized by the trailing 10-day return volatility. By applying a time-series Z-score to the ratio, it highlights extreme deviations from the local average liquidity consumption, signaling mean reversion opportunities.",
      "factor_formulation": "\\text{TS\\_ZSCORE}\\left(\\frac{\\text{high} - \\text{low}}{\\text{TS\\_STD}(\\text{return}, 10) + 1e-8}, 10\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "c8d9fff8e6e4",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The ratio of the current day's price range (High-Low) to the 5-day standard deviation of daily returns identifies periods of abnormal liquidity consumption and predicts short-term mean reversion or trend exhaustion.\n                Concise Observation: The relationship between daily price extremes (High/Low) and closing-price-based volatility (STD) often diverges during market stress, where intraday noise increases faster than interday trend strength.\n                Concise Justification: Comparing a point-in-time range (KLEN) to a trailing volatility measure (STD5) captures the 'volatility of volatility' and the immediate imbalance between buyer and seller urgency relative to the established regime.\n                Concise Knowledge: If the intraday range significantly exceeds the recent historical volatility, it indicates a surge in informed trading or panic-driven liquidity demand; when this ratio reaches extreme levels, the market is likely to experience a temporary price correction as liquidity providers demand a premium for the heightened risk.\n                concise Specification: The factor is defined as (High - Low) / STD(LogReturn, 5). A high value suggests an 'overextended' intraday move relative to the 5-day baseline, expected to negatively correlate with the next 5-day forward returns in a mean-reverting market.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T21:51:13.205695"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0994481113999163,
        "ICIR": 0.0342210459476005,
        "1day.excess_return_without_cost.std": 0.0038531976957521,
        "1day.excess_return_with_cost.annualized_return": 0.0170952998995187,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002718211856144,
        "1day.excess_return_without_cost.annualized_return": 0.064693442176239,
        "1day.excess_return_with_cost.std": 0.003855677316592,
        "Rank IC": 0.0216769045323516,
        "IC": 0.0043713920080057,
        "1day.excess_return_without_cost.max_drawdown": -0.0861035372663329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0883046606789435,
        "1day.pa": 0.0,
        "l2.valid": 0.9962563804229888,
        "Rank ICIR": 0.1685037786293848,
        "l2.train": 0.9935761979131807,
        "1day.excess_return_with_cost.information_ratio": 0.2874005301850193,
        "1day.excess_return_with_cost.mean": 7.182899117444871e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the ratio of intraday range to interday return volatility. The results show a significant improvement in the Information Ratio (1.088 vs 0.972) and Annualized Return (0.0647 vs 0.0520) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. The 'Abnormal_Liquidity_Consumption_Ratio_5D' and its smoothed/Z-scored variants successfully captured short-term alpha, suggesting that the relationship between intraday price action and recent volatility regimes is a potent predictor.",
        "hypothesis_evaluation": "The hypothesis is strongly supported. The metrics indicate that normalizing the intraday range by return standard deviation effectively identifies profitable signals. The improvement in Information Ratio suggests that this normalization provides a more stable risk-adjusted return than previous methods. However, the slight drop in IC and increase in drawdown suggest that while the 'extreme' signals are profitable, they may introduce higher tail risk or timing sensitivity.",
        "decision": true,
        "reason": "While the current range-to-volatility ratio works well, it treats all 'wide range' days equally. A wide range on low volume might indicate a lack of liquidity (slippage), whereas a wide range on high volume indicates active liquidity consumption. By integrating a volume component (e.g., current volume relative to its 5-day average), we can refine the signal to focus on 'True' liquidity exhaustion events, likely improving the IC and reducing the Max Drawdown by filtering out false signals."
      }
    },
    "5293a32e7f3267d7": {
      "factor_id": "5293a32e7f3267d7",
      "factor_name": "Smoothed_Range_Volatility_Imbalance_5D",
      "factor_expression": "RANK(SMA(($high - $low) / (TS_STD($return, 5) + 1e-8), 5, 1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SMA(($high - $low) / (TS_STD($close / DELAY($close, 1) - 1, 5) + 0.00000001), 5, 1))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Range_Volatility_Imbalance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor uses a 5-day simple moving average of the range-to-volatility ratio to capture persistent liquidity imbalances. It compares the intraday range magnitude against the 5-day return standard deviation, cross-sectionally ranked to identify stocks with the highest relative volatility of volatility.",
      "factor_formulation": "\\text{RANK}\\left(\\text{SMA}\\left(\\frac{\\text{high} - \\text{low}}{\\text{TS\\_STD}(\\text{return}, 5) + 1e-8}, 5, 1\\right)\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "c8d9fff8e6e4",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The ratio of the current day's price range (High-Low) to the 5-day standard deviation of daily returns identifies periods of abnormal liquidity consumption and predicts short-term mean reversion or trend exhaustion.\n                Concise Observation: The relationship between daily price extremes (High/Low) and closing-price-based volatility (STD) often diverges during market stress, where intraday noise increases faster than interday trend strength.\n                Concise Justification: Comparing a point-in-time range (KLEN) to a trailing volatility measure (STD5) captures the 'volatility of volatility' and the immediate imbalance between buyer and seller urgency relative to the established regime.\n                Concise Knowledge: If the intraday range significantly exceeds the recent historical volatility, it indicates a surge in informed trading or panic-driven liquidity demand; when this ratio reaches extreme levels, the market is likely to experience a temporary price correction as liquidity providers demand a premium for the heightened risk.\n                concise Specification: The factor is defined as (High - Low) / STD(LogReturn, 5). A high value suggests an 'overextended' intraday move relative to the 5-day baseline, expected to negatively correlate with the next 5-day forward returns in a mean-reverting market.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T21:51:13.205695"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0994481113999163,
        "ICIR": 0.0342210459476005,
        "1day.excess_return_without_cost.std": 0.0038531976957521,
        "1day.excess_return_with_cost.annualized_return": 0.0170952998995187,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002718211856144,
        "1day.excess_return_without_cost.annualized_return": 0.064693442176239,
        "1day.excess_return_with_cost.std": 0.003855677316592,
        "Rank IC": 0.0216769045323516,
        "IC": 0.0043713920080057,
        "1day.excess_return_without_cost.max_drawdown": -0.0861035372663329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0883046606789435,
        "1day.pa": 0.0,
        "l2.valid": 0.9962563804229888,
        "Rank ICIR": 0.1685037786293848,
        "l2.train": 0.9935761979131807,
        "1day.excess_return_with_cost.information_ratio": 0.2874005301850193,
        "1day.excess_return_with_cost.mean": 7.182899117444871e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the ratio of intraday range to interday return volatility. The results show a significant improvement in the Information Ratio (1.088 vs 0.972) and Annualized Return (0.0647 vs 0.0520) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. The 'Abnormal_Liquidity_Consumption_Ratio_5D' and its smoothed/Z-scored variants successfully captured short-term alpha, suggesting that the relationship between intraday price action and recent volatility regimes is a potent predictor.",
        "hypothesis_evaluation": "The hypothesis is strongly supported. The metrics indicate that normalizing the intraday range by return standard deviation effectively identifies profitable signals. The improvement in Information Ratio suggests that this normalization provides a more stable risk-adjusted return than previous methods. However, the slight drop in IC and increase in drawdown suggest that while the 'extreme' signals are profitable, they may introduce higher tail risk or timing sensitivity.",
        "decision": true,
        "reason": "While the current range-to-volatility ratio works well, it treats all 'wide range' days equally. A wide range on low volume might indicate a lack of liquidity (slippage), whereas a wide range on high volume indicates active liquidity consumption. By integrating a volume component (e.g., current volume relative to its 5-day average), we can refine the signal to focus on 'True' liquidity exhaustion events, likely improving the IC and reducing the Max Drawdown by filtering out false signals."
      }
    },
    "3c5aabb076f3e31e": {
      "factor_id": "3c5aabb076f3e31e",
      "factor_name": "Institutional_Absorption_RSQR_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (1 + TS_MEAN(($high - $low) / ($close * $volume + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (1 + TS_MEAN(($high - $low) / ($close * $volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_RSQR_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional accumulation by measuring price trend linearity (RSQR) and volume-weighted volatility. RSQR is calculated as the square of the correlation between price and time. High linearity combined with low volume-weighted price range indicates stealthy buying pressure.",
      "factor_formulation": "RSQR10 = TS\\_CORR(close, SEQUENCE(10), 10)^2, WVMA5 = TS\\_MEAN(\\frac{high-low}{close \\cdot volume}, 5), Factor = \\frac{RSQR10}{1 + WVMA5}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "f342699c166b",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor, defined as the product of the 10-day price trend linearity (RSQR10) and the inverse of the 5-day volume-weighted price volatility (WVMA5), predicts positive future returns by identifying stealthy accumulation phases.\n                Concise Observation: Market participants often overlook steady, low-volatility price trends in favor of high-volume breakouts, yet these 'quiet' trends frequently represent more sustainable buying pressure from informed actors.\n                Concise Justification: Institutional investors use execution algorithms to minimize market impact, leading to price paths that are statistically 'smoother' (high RSQR) and less volatile relative to volume (low WVMA) than retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits a highly linear price increase (high R-squared) while simultaneously maintaining low volume-weighted volatility, it signifies institutional accumulation that avoids triggering liquidity-seeking algorithms; such periods often precede further price appreciation as supply is absorbed.\n                concise Specification: Calculate RSQR10 as the R-squared of $close over a 10-day linear regression against time, and WVMA5 as the 5-day moving average of the ratio between (high-low)/close and volume; the final factor is RSQR10 divided by (1 + WVMA5).\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T22:02:53.274315"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1156092444232029,
        "ICIR": 0.0427503408864524,
        "1day.excess_return_without_cost.std": 0.0046946942750529,
        "1day.excess_return_with_cost.annualized_return": -0.0016267993637364,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001920442455047,
        "1day.excess_return_without_cost.annualized_return": 0.0457065304301312,
        "1day.excess_return_with_cost.std": 0.0046972723110519,
        "Rank IC": 0.0248104417101632,
        "IC": 0.0064235342383618,
        "1day.excess_return_without_cost.max_drawdown": -0.098395177543724,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6310771581633398,
        "1day.pa": 0.0,
        "l2.valid": 0.9963454906016967,
        "Rank ICIR": 0.1691871762746937,
        "l2.train": 0.9937834605149448,
        "1day.excess_return_with_cost.information_ratio": -0.0224491435713705,
        "1day.excess_return_with_cost.mean": -6.83529144427091e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption' hypothesis. The current results show a significant improvement in the Information Coefficient (IC) reaching 0.006424, which is higher than the SOTA result of 0.005798. However, the risk-adjusted returns (Information Ratio) and the Max Drawdown have deteriorated compared to the SOTA. This suggests that while the signal's predictive correlation with future returns has improved, the stability and tail risk of the resulting portfolio have worsened, likely due to the increased noise or volatility in the current factor implementations.",
        "hypothesis_evaluation": "The hypothesis that price trend linearity (RSQR) combined with low volume-weighted volatility predicts positive returns is partially supported by the improved IC. However, the deterioration in Information Ratio (0.631 vs 0.972) and Max Drawdown (-0.098 vs -0.072) suggests that the current mathematical formulations (specifically the division by volume or the raw Z-score subtraction) might be introducing instability. The 'Institutional_Smoothness_Index' and 'Stealth_Accumulation_Linearity_Z' involve multiple raw features (close, high, low, volume), approaching the complexity limit (ER=4), and the linear combination of Z-scores may be too simplistic for the underlying non-linear distribution of volume.",
        "decision": false,
        "reason": "The current factors suffer from high drawdown, possibly because dividing by volume or using raw volume in the denominator creates extreme values during low-liquidity periods. By shifting to 'Path Efficiency' (e.g., Abs(Close-Close[10]) / Sum(Abs(Close-Close[1]))) and using a rank-based or capped volume adjustment, we can capture the 'stealth' nature of the trend without the mathematical instability of the current formulations. This maintains the core concept of 'smooth trends' while improving the Information Ratio and reducing drawdown through better complexity control and normalization."
      }
    },
    "bc5d49829722cdfb": {
      "factor_id": "bc5d49829722cdfb",
      "factor_name": "Stealth_Accumulation_Linearity_Z",
      "factor_expression": "TS_ZSCORE(TS_CORR($close, SEQUENCE(10), 10), 10) - TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 5) + 1e-8), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR($close, SEQUENCE(10), 10), 10) - TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 5) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Linearity_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the institutional absorption hypothesis that uses Z-scored price trend linearity and inverse volatility. It focuses on the statistical significance of the 'smoothness' of the price path relative to the intensity of price fluctuations per unit of volume.",
      "factor_formulation": "Linearity = TS\\_CORR(close, SEQUENCE(10), 10), RangeVol = \\frac{high-low}{TS\\_MEAN(volume, 5)}, Factor = TS\\_ZSCORE(Linearity, 10) - TS\\_ZSCORE(RangeVol, 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "f342699c166b",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor, defined as the product of the 10-day price trend linearity (RSQR10) and the inverse of the 5-day volume-weighted price volatility (WVMA5), predicts positive future returns by identifying stealthy accumulation phases.\n                Concise Observation: Market participants often overlook steady, low-volatility price trends in favor of high-volume breakouts, yet these 'quiet' trends frequently represent more sustainable buying pressure from informed actors.\n                Concise Justification: Institutional investors use execution algorithms to minimize market impact, leading to price paths that are statistically 'smoother' (high RSQR) and less volatile relative to volume (low WVMA) than retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits a highly linear price increase (high R-squared) while simultaneously maintaining low volume-weighted volatility, it signifies institutional accumulation that avoids triggering liquidity-seeking algorithms; such periods often precede further price appreciation as supply is absorbed.\n                concise Specification: Calculate RSQR10 as the R-squared of $close over a 10-day linear regression against time, and WVMA5 as the 5-day moving average of the ratio between (high-low)/close and volume; the final factor is RSQR10 divided by (1 + WVMA5).\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T22:02:53.274315"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1156092444232029,
        "ICIR": 0.0427503408864524,
        "1day.excess_return_without_cost.std": 0.0046946942750529,
        "1day.excess_return_with_cost.annualized_return": -0.0016267993637364,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001920442455047,
        "1day.excess_return_without_cost.annualized_return": 0.0457065304301312,
        "1day.excess_return_with_cost.std": 0.0046972723110519,
        "Rank IC": 0.0248104417101632,
        "IC": 0.0064235342383618,
        "1day.excess_return_without_cost.max_drawdown": -0.098395177543724,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6310771581633398,
        "1day.pa": 0.0,
        "l2.valid": 0.9963454906016967,
        "Rank ICIR": 0.1691871762746937,
        "l2.train": 0.9937834605149448,
        "1day.excess_return_with_cost.information_ratio": -0.0224491435713705,
        "1day.excess_return_with_cost.mean": -6.83529144427091e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption' hypothesis. The current results show a significant improvement in the Information Coefficient (IC) reaching 0.006424, which is higher than the SOTA result of 0.005798. However, the risk-adjusted returns (Information Ratio) and the Max Drawdown have deteriorated compared to the SOTA. This suggests that while the signal's predictive correlation with future returns has improved, the stability and tail risk of the resulting portfolio have worsened, likely due to the increased noise or volatility in the current factor implementations.",
        "hypothesis_evaluation": "The hypothesis that price trend linearity (RSQR) combined with low volume-weighted volatility predicts positive returns is partially supported by the improved IC. However, the deterioration in Information Ratio (0.631 vs 0.972) and Max Drawdown (-0.098 vs -0.072) suggests that the current mathematical formulations (specifically the division by volume or the raw Z-score subtraction) might be introducing instability. The 'Institutional_Smoothness_Index' and 'Stealth_Accumulation_Linearity_Z' involve multiple raw features (close, high, low, volume), approaching the complexity limit (ER=4), and the linear combination of Z-scores may be too simplistic for the underlying non-linear distribution of volume.",
        "decision": false,
        "reason": "The current factors suffer from high drawdown, possibly because dividing by volume or using raw volume in the denominator creates extreme values during low-liquidity periods. By shifting to 'Path Efficiency' (e.g., Abs(Close-Close[10]) / Sum(Abs(Close-Close[1]))) and using a rank-based or capped volume adjustment, we can capture the 'stealth' nature of the trend without the mathematical instability of the current formulations. This maintains the core concept of 'smooth trends' while improving the Information Ratio and reducing drawdown through better complexity control and normalization."
      }
    },
    "6f62f68be5d1ff49": {
      "factor_id": "6f62f68be5d1ff49",
      "factor_name": "Institutional_Smoothness_Index",
      "factor_expression": "REGBETA($close, SEQUENCE(10), 10) / (TS_MEAN(($high - $low) / ($close + 1e-8), 10) * TS_MEAN($volume, 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGBETA($close, SEQUENCE(10), 10) / (TS_MEAN(($high - $low) / ($close + 1e-8), 10) * TS_MEAN($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Smoothness_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the ratio of trend strength (captured by the regression beta of price against time) to the average intraday volatility, adjusted for volume. High values suggest a strong, controlled trend characteristic of algorithmic execution.",
      "factor_formulation": "Trend = REGBETA(close, SEQUENCE(10), 10), Volatility = TS\\_MEAN(\\frac{high-low}{close}, 10), Factor = \\frac{Trend}{Volatility \\cdot TS\\_MEAN(volume, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "f342699c166b",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor, defined as the product of the 10-day price trend linearity (RSQR10) and the inverse of the 5-day volume-weighted price volatility (WVMA5), predicts positive future returns by identifying stealthy accumulation phases.\n                Concise Observation: Market participants often overlook steady, low-volatility price trends in favor of high-volume breakouts, yet these 'quiet' trends frequently represent more sustainable buying pressure from informed actors.\n                Concise Justification: Institutional investors use execution algorithms to minimize market impact, leading to price paths that are statistically 'smoother' (high RSQR) and less volatile relative to volume (low WVMA) than retail-driven speculative spikes.\n                Concise Knowledge: If a stock exhibits a highly linear price increase (high R-squared) while simultaneously maintaining low volume-weighted volatility, it signifies institutional accumulation that avoids triggering liquidity-seeking algorithms; such periods often precede further price appreciation as supply is absorbed.\n                concise Specification: Calculate RSQR10 as the R-squared of $close over a 10-day linear regression against time, and WVMA5 as the 5-day moving average of the ratio between (high-low)/close and volume; the final factor is RSQR10 divided by (1 + WVMA5).\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T22:02:53.274315"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1156092444232029,
        "ICIR": 0.0427503408864524,
        "1day.excess_return_without_cost.std": 0.0046946942750529,
        "1day.excess_return_with_cost.annualized_return": -0.0016267993637364,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001920442455047,
        "1day.excess_return_without_cost.annualized_return": 0.0457065304301312,
        "1day.excess_return_with_cost.std": 0.0046972723110519,
        "Rank IC": 0.0248104417101632,
        "IC": 0.0064235342383618,
        "1day.excess_return_without_cost.max_drawdown": -0.098395177543724,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6310771581633398,
        "1day.pa": 0.0,
        "l2.valid": 0.9963454906016967,
        "Rank ICIR": 0.1691871762746937,
        "l2.train": 0.9937834605149448,
        "1day.excess_return_with_cost.information_ratio": -0.0224491435713705,
        "1day.excess_return_with_cost.mean": -6.83529144427091e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption' hypothesis. The current results show a significant improvement in the Information Coefficient (IC) reaching 0.006424, which is higher than the SOTA result of 0.005798. However, the risk-adjusted returns (Information Ratio) and the Max Drawdown have deteriorated compared to the SOTA. This suggests that while the signal's predictive correlation with future returns has improved, the stability and tail risk of the resulting portfolio have worsened, likely due to the increased noise or volatility in the current factor implementations.",
        "hypothesis_evaluation": "The hypothesis that price trend linearity (RSQR) combined with low volume-weighted volatility predicts positive returns is partially supported by the improved IC. However, the deterioration in Information Ratio (0.631 vs 0.972) and Max Drawdown (-0.098 vs -0.072) suggests that the current mathematical formulations (specifically the division by volume or the raw Z-score subtraction) might be introducing instability. The 'Institutional_Smoothness_Index' and 'Stealth_Accumulation_Linearity_Z' involve multiple raw features (close, high, low, volume), approaching the complexity limit (ER=4), and the linear combination of Z-scores may be too simplistic for the underlying non-linear distribution of volume.",
        "decision": false,
        "reason": "The current factors suffer from high drawdown, possibly because dividing by volume or using raw volume in the denominator creates extreme values during low-liquidity periods. By shifting to 'Path Efficiency' (e.g., Abs(Close-Close[10]) / Sum(Abs(Close-Close[1]))) and using a rank-based or capped volume adjustment, we can capture the 'stealth' nature of the trend without the mathematical instability of the current formulations. This maintains the core concept of 'smooth trends' while improving the Information Ratio and reducing drawdown through better complexity control and normalization."
      }
    },
    "a5e4b57cf039c770": {
      "factor_id": "a5e4b57cf039c770",
      "factor_name": "Capitulation_Index_60D_5D",
      "factor_expression": "TS_PCTCHANGE($close, 60) * TS_MEAN((MIN($open, $close) - $low) / ($close + 1e-8), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 60) * TS_MEAN((MIN($open, $close) - $low) / ($close + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Index_60D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies market bottoms by multiplying the 60-day price rate of change with the 5-day moving average of the lower shadow ratio. A highly negative ROC combined with a large lower shadow (rejection of lows) suggests selling exhaustion and potential mean reversion.",
      "factor_formulation": "\\text{ROC}_{60} \\times \\text{TS\\_MEAN}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{close} + 1e-8}, 5\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "a9875f792160",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Capitulation Index' defined as the product of the 60-day rate of change (ROC60) and the 5-day moving average of the lower shadow relative to the price (KLOW) identifies durable market bottoms when both price momentum is severely negative and intraday rejection of lows is increasing.\n                Concise Observation: Market participants often panic during extended drawdowns, but the presence of lower shadows (the difference between the low and the minimum of open/close) suggests that buyers are stepping in to absorb liquidity at extreme lows.\n                Concise Justification: Combining long-term momentum (ROC60) with intraday price action (KLOW) filters out falling knives that lack support, focusing instead on assets where the downward trend is losing conviction through price rejection.\n                Concise Knowledge: If a security experiences a significant multi-month price decline while simultaneously exhibiting lengthening lower shadows, it indicates that selling exhaustion is being met by strong support, signaling a high-probability mean-reversion entry point.\n                concise Specification: The factor is calculated by multiplying the 60-day price return (ROC60) by the 5-day simple moving average of the ratio ((min(open, close) - low) / close), where more negative ROC and higher KLOW produce a distinct reversal signal.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T22:06:33.771717"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1077455628141888,
        "ICIR": 0.0350003762893779,
        "1day.excess_return_without_cost.std": 0.0040989804566181,
        "1day.excess_return_with_cost.annualized_return": 0.0243798775350599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002995655918197,
        "1day.excess_return_without_cost.annualized_return": 0.071296610853103,
        "1day.excess_return_with_cost.std": 0.0040997598063585,
        "Rank IC": 0.0208734368659706,
        "IC": 0.0047275620899829,
        "1day.excess_return_without_cost.max_drawdown": -0.088094950291361,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1274688698994244,
        "1day.pa": 0.0,
        "l2.valid": 0.9963161939029906,
        "Rank ICIR": 0.1589016914959304,
        "l2.train": 0.9936085099618226,
        "1day.excess_return_with_cost.information_ratio": 0.3854647136513174,
        "1day.excess_return_with_cost.mean": 0.0001024364602313
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Capitulation Index' hypothesis. The results show a significant improvement in risk-adjusted returns (Information Ratio) and total returns (Annualized Return) compared to the previous SOTA, although the IC and Max Drawdown slightly deteriorated. The 'ZScore_Capitulation_Reversal' and 'Ranked_Capitulation_Signal' variations successfully captured the statistical significance and relative extremity of market exhaustion. The improvement in Annualized Return from 5.2% to 7.1% suggests that the interaction between long-term price decline and short-term intraday rejection is a robust predictor of mean reversion.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that a 'Capitulation Index' combining 60-day momentum with lower shadow characteristics identifies profitable reversal points. Specifically, using a Z-score or a cross-sectional rank to normalize the 'rejection' signal (lower shadow) appears more effective than using a raw moving average, as it better captures the 'extremity' required for a durable bottom.",
        "decision": true,
        "reason": "While the current factors work well, they do not distinguish between low-volume price drifting and high-volume 'climax' selling. Incorporating volume (e.g., volume relative to its 20-day average) should filter out false signals. Additionally, normalizing the 60-day price drop by volatility will ensure the 'capitulation' is relative to the stock's specific risk profile, reducing the symbol length and complexity by using more standard technical building blocks."
      }
    },
    "482301502aa93e53": {
      "factor_id": "482301502aa93e53",
      "factor_name": "Ranked_Capitulation_Signal",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-TS_PCTCHANGE($close, 60)) * RANK(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Capitulation_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the capitulation logic. it targets stocks with the most extreme negative 60-day momentum and the highest 10-day average lower shadow relative to their daily range, identifying relative exhaustion within the universe.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_PCTCHANGE}(\\text{close}, 60)) \\times \\text{RANK}(\\text{TS\\_MEAN}(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{high} - \\text{low} + 1e-8}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "a9875f792160",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Capitulation Index' defined as the product of the 60-day rate of change (ROC60) and the 5-day moving average of the lower shadow relative to the price (KLOW) identifies durable market bottoms when both price momentum is severely negative and intraday rejection of lows is increasing.\n                Concise Observation: Market participants often panic during extended drawdowns, but the presence of lower shadows (the difference between the low and the minimum of open/close) suggests that buyers are stepping in to absorb liquidity at extreme lows.\n                Concise Justification: Combining long-term momentum (ROC60) with intraday price action (KLOW) filters out falling knives that lack support, focusing instead on assets where the downward trend is losing conviction through price rejection.\n                Concise Knowledge: If a security experiences a significant multi-month price decline while simultaneously exhibiting lengthening lower shadows, it indicates that selling exhaustion is being met by strong support, signaling a high-probability mean-reversion entry point.\n                concise Specification: The factor is calculated by multiplying the 60-day price return (ROC60) by the 5-day simple moving average of the ratio ((min(open, close) - low) / close), where more negative ROC and higher KLOW produce a distinct reversal signal.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T22:06:33.771717"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1077455628141888,
        "ICIR": 0.0350003762893779,
        "1day.excess_return_without_cost.std": 0.0040989804566181,
        "1day.excess_return_with_cost.annualized_return": 0.0243798775350599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002995655918197,
        "1day.excess_return_without_cost.annualized_return": 0.071296610853103,
        "1day.excess_return_with_cost.std": 0.0040997598063585,
        "Rank IC": 0.0208734368659706,
        "IC": 0.0047275620899829,
        "1day.excess_return_without_cost.max_drawdown": -0.088094950291361,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1274688698994244,
        "1day.pa": 0.0,
        "l2.valid": 0.9963161939029906,
        "Rank ICIR": 0.1589016914959304,
        "l2.train": 0.9936085099618226,
        "1day.excess_return_with_cost.information_ratio": 0.3854647136513174,
        "1day.excess_return_with_cost.mean": 0.0001024364602313
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Capitulation Index' hypothesis. The results show a significant improvement in risk-adjusted returns (Information Ratio) and total returns (Annualized Return) compared to the previous SOTA, although the IC and Max Drawdown slightly deteriorated. The 'ZScore_Capitulation_Reversal' and 'Ranked_Capitulation_Signal' variations successfully captured the statistical significance and relative extremity of market exhaustion. The improvement in Annualized Return from 5.2% to 7.1% suggests that the interaction between long-term price decline and short-term intraday rejection is a robust predictor of mean reversion.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that a 'Capitulation Index' combining 60-day momentum with lower shadow characteristics identifies profitable reversal points. Specifically, using a Z-score or a cross-sectional rank to normalize the 'rejection' signal (lower shadow) appears more effective than using a raw moving average, as it better captures the 'extremity' required for a durable bottom.",
        "decision": true,
        "reason": "While the current factors work well, they do not distinguish between low-volume price drifting and high-volume 'climax' selling. Incorporating volume (e.g., volume relative to its 20-day average) should filter out false signals. Additionally, normalizing the 60-day price drop by volatility will ensure the 'capitulation' is relative to the stock's specific risk profile, reducing the symbol length and complexity by using more standard technical building blocks."
      }
    },
    "98c70ac72d3298b5": {
      "factor_id": "98c70ac72d3298b5",
      "factor_name": "ZScore_Capitulation_Reversal",
      "factor_expression": "TS_PCTCHANGE($close, 60) * TS_ZSCORE((MIN($open, $close) - $low) / ($close + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 60) * TS_ZSCORE((MIN($open, $close) - $low) / ($close + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Capitulation_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor uses time-series Z-scores to identify when the lower shadow (rejection) is significantly higher than its own history while the price is in a long-term downtrend. It focuses on the statistical significance of the 'rejection' tail.",
      "factor_formulation": "\\text{TS\\_PCTCHANGE}(\\text{close}, 60) \\times \\text{TS\\_ZSCORE}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{close} + 1e-8}, 20\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "a9875f792160",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: A 'Capitulation Index' defined as the product of the 60-day rate of change (ROC60) and the 5-day moving average of the lower shadow relative to the price (KLOW) identifies durable market bottoms when both price momentum is severely negative and intraday rejection of lows is increasing.\n                Concise Observation: Market participants often panic during extended drawdowns, but the presence of lower shadows (the difference between the low and the minimum of open/close) suggests that buyers are stepping in to absorb liquidity at extreme lows.\n                Concise Justification: Combining long-term momentum (ROC60) with intraday price action (KLOW) filters out falling knives that lack support, focusing instead on assets where the downward trend is losing conviction through price rejection.\n                Concise Knowledge: If a security experiences a significant multi-month price decline while simultaneously exhibiting lengthening lower shadows, it indicates that selling exhaustion is being met by strong support, signaling a high-probability mean-reversion entry point.\n                concise Specification: The factor is calculated by multiplying the 60-day price return (ROC60) by the 5-day simple moving average of the ratio ((min(open, close) - low) / close), where more negative ROC and higher KLOW produce a distinct reversal signal.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T22:06:33.771717"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1077455628141888,
        "ICIR": 0.0350003762893779,
        "1day.excess_return_without_cost.std": 0.0040989804566181,
        "1day.excess_return_with_cost.annualized_return": 0.0243798775350599,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002995655918197,
        "1day.excess_return_without_cost.annualized_return": 0.071296610853103,
        "1day.excess_return_with_cost.std": 0.0040997598063585,
        "Rank IC": 0.0208734368659706,
        "IC": 0.0047275620899829,
        "1day.excess_return_without_cost.max_drawdown": -0.088094950291361,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1274688698994244,
        "1day.pa": 0.0,
        "l2.valid": 0.9963161939029906,
        "Rank ICIR": 0.1589016914959304,
        "l2.train": 0.9936085099618226,
        "1day.excess_return_with_cost.information_ratio": 0.3854647136513174,
        "1day.excess_return_with_cost.mean": 0.0001024364602313
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Capitulation Index' hypothesis. The results show a significant improvement in risk-adjusted returns (Information Ratio) and total returns (Annualized Return) compared to the previous SOTA, although the IC and Max Drawdown slightly deteriorated. The 'ZScore_Capitulation_Reversal' and 'Ranked_Capitulation_Signal' variations successfully captured the statistical significance and relative extremity of market exhaustion. The improvement in Annualized Return from 5.2% to 7.1% suggests that the interaction between long-term price decline and short-term intraday rejection is a robust predictor of mean reversion.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that a 'Capitulation Index' combining 60-day momentum with lower shadow characteristics identifies profitable reversal points. Specifically, using a Z-score or a cross-sectional rank to normalize the 'rejection' signal (lower shadow) appears more effective than using a raw moving average, as it better captures the 'extremity' required for a durable bottom.",
        "decision": true,
        "reason": "While the current factors work well, they do not distinguish between low-volume price drifting and high-volume 'climax' selling. Incorporating volume (e.g., volume relative to its 20-day average) should filter out false signals. Additionally, normalizing the 60-day price drop by volatility will ensure the 'capitulation' is relative to the stock's specific risk profile, reducing the symbol length and complexity by using more standard technical building blocks."
      }
    },
    "314d882053c7ab3b": {
      "factor_id": "314d882053c7ab3b",
      "factor_name": "Trend_Exhaustion_Divergence_20D",
      "factor_expression": "(1 - TS_CORR($close, $volume, 20)) * (POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8))",
      "factor_implementation_code": "",
      "factor_description": "This factor identifies potential trend exhaustion by multiplying price linearity (R-squared of price vs. time) with the lack of price-volume synchronization. A high value suggests a strong price trend that is no longer supported by volume, signaling a potential mean-reversion.",
      "factor_formulation": "RSQR10 = \\frac{REGBETA(close, SEQUENCE(10), 10)^2 \\times TS\\_VAR(SEQUENCE(10), 10)}{TS\\_VAR(close, 10)}, \\\\ Factor = (1 - TS\\_CORR(close, volume, 20)) \\times RSQR10",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "b100bbf3cd8d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 10-day price trend linearity (RSQR10) identifies trend exhaustion: specifically, when a highly linear price trend (high RSQR10) is accompanied by a breakdown in price-volume synchronization (low CORR20), the asset is likely to experience a mean-reverting return.\n                Concise Observation: In daily price-volume data, strong trends often show high R-squared values relative to time, but the most sustainable moves typically maintain a consistent correlation with volume; divergence between these two often appears at local price peaks or troughs.\n                Concise Justification: Volume serves as the 'fuel' for price trends; a high R-squared indicates a persistent directional move, but if the correlation with volume drops, it suggests that the price is moving on thinning liquidity or lack of conviction, signaling a potential 'blow-off top' or 'exhaustion gap'.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but loses its correlation with trading volume, the trend's structural strength is weakening; when these two metrics diverge, the probability of a price reversal increases as the move is no longer supported by broad market participation.\n                concise Specification: Define the factor as the product of (1 - CORR(close, volume, 20)) and RSQR(close, 10), where RSQR is the coefficient of determination of close price against a time index, expected to negatively predict returns over the subsequent 5-day horizon.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T22:16:16.565911"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2156576192923504,
        "ICIR": 0.0493727867878478,
        "1day.excess_return_without_cost.std": 0.0047532393251851,
        "1day.excess_return_with_cost.annualized_return": -0.008842355672347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001643956712425,
        "1day.excess_return_without_cost.annualized_return": 0.0391261697557351,
        "1day.excess_return_with_cost.std": 0.0047538275949012,
        "Rank IC": 0.0229610774285775,
        "IC": 0.0073300758738927,
        "1day.excess_return_without_cost.max_drawdown": -0.1657612411577176,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5335672620063892,
        "1day.pa": 0.0,
        "l2.valid": 0.9967935904302332,
        "Rank ICIR": 0.1553216019531143,
        "l2.train": 0.9942025786074422,
        "1day.excess_return_with_cost.information_ratio": -0.1205691152522126,
        "1day.excess_return_with_cost.mean": -3.715275492582812e-05
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the trend exhaustion hypothesis: 'Linear_Trend_Volume_Decoupling_Z' and 'Volume_Supported_Trend_Efficiency'. The current results show a significant improvement in the Information Coefficient (IC) (0.0073 vs 0.0058), suggesting that the interaction between price linearity and volume decoupling has stronger predictive power for cross-sectional returns than previous iterations. However, the risk-adjusted metrics (Information Ratio) and drawdown (Max Drawdown) have deteriorated significantly compared to the SOTA, indicating that while the signal is more accurate on average, it may be more volatile or prone to extreme errors in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that the interaction between high price linearity (RSQR10) and low price-volume synchronization (CORR20) identifies mean-reversion is partially supported by the increased IC. The 'Linear_Trend_Volume_Decoupling_Z' approach, which uses Z-scores to isolate the divergence, appears to capture the signal better than simple ratios. However, the poor annualized return and high drawdown suggest that the 'exhaustion' signal might be premature or that the 1-day holding period is too short to capture the full mean-reversion effect.",
        "decision": false,
        "reason": "The current factors focus on the shape of the trend (linearity) and its support (volume), but ignore the magnitude of the move. A highly linear trend with low volume support might not reverse if the total price move is small. By incorporating a volatility-normalized range (e.g., (High-Low)/StdDev), we can identify 'stretched' trends where exhaustion is more likely to lead to a profitable mean-reversion. Additionally, simplifying the expression by using a direct subtraction of ranks or Z-scores (as seen in the current iteration) is preferred over complex ratios to maintain complexity control."
      }
    },
    "9f68be1d0cebfad6": {
      "factor_id": "9f68be1d0cebfad6",
      "factor_name": "Linear_Trend_Volume_Decoupling_Z",
      "factor_expression": "ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2) / (TS_VAR($close, 10) + 1e-8)) - ZSCORE(TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(REGBETA($close, SEQUENCE(10), 10), 2) / (TS_VAR($close, 10) + 1e-8)) - ZSCORE(TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Volume_Decoupling_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the divergence between price trend linearity and volume support using Z-scored components. It specifically looks for instances where the 10-day price trend is exceptionally linear but the 20-day price-volume correlation is declining, normalized cross-sectionally.",
      "factor_formulation": "Linearity = \\frac{REGBETA(close, SEQUENCE(10), 10)^2}{TS\\_VAR(close, 10)}, \\\\ Factor = ZSCORE(Linearity) - ZSCORE(TS\\_CORR(close, volume, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "b100bbf3cd8d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 10-day price trend linearity (RSQR10) identifies trend exhaustion: specifically, when a highly linear price trend (high RSQR10) is accompanied by a breakdown in price-volume synchronization (low CORR20), the asset is likely to experience a mean-reverting return.\n                Concise Observation: In daily price-volume data, strong trends often show high R-squared values relative to time, but the most sustainable moves typically maintain a consistent correlation with volume; divergence between these two often appears at local price peaks or troughs.\n                Concise Justification: Volume serves as the 'fuel' for price trends; a high R-squared indicates a persistent directional move, but if the correlation with volume drops, it suggests that the price is moving on thinning liquidity or lack of conviction, signaling a potential 'blow-off top' or 'exhaustion gap'.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but loses its correlation with trading volume, the trend's structural strength is weakening; when these two metrics diverge, the probability of a price reversal increases as the move is no longer supported by broad market participation.\n                concise Specification: Define the factor as the product of (1 - CORR(close, volume, 20)) and RSQR(close, 10), where RSQR is the coefficient of determination of close price against a time index, expected to negatively predict returns over the subsequent 5-day horizon.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T22:16:16.565911"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2156576192923504,
        "ICIR": 0.0493727867878478,
        "1day.excess_return_without_cost.std": 0.0047532393251851,
        "1day.excess_return_with_cost.annualized_return": -0.008842355672347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001643956712425,
        "1day.excess_return_without_cost.annualized_return": 0.0391261697557351,
        "1day.excess_return_with_cost.std": 0.0047538275949012,
        "Rank IC": 0.0229610774285775,
        "IC": 0.0073300758738927,
        "1day.excess_return_without_cost.max_drawdown": -0.1657612411577176,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5335672620063892,
        "1day.pa": 0.0,
        "l2.valid": 0.9967935904302332,
        "Rank ICIR": 0.1553216019531143,
        "l2.train": 0.9942025786074422,
        "1day.excess_return_with_cost.information_ratio": -0.1205691152522126,
        "1day.excess_return_with_cost.mean": -3.715275492582812e-05
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the trend exhaustion hypothesis: 'Linear_Trend_Volume_Decoupling_Z' and 'Volume_Supported_Trend_Efficiency'. The current results show a significant improvement in the Information Coefficient (IC) (0.0073 vs 0.0058), suggesting that the interaction between price linearity and volume decoupling has stronger predictive power for cross-sectional returns than previous iterations. However, the risk-adjusted metrics (Information Ratio) and drawdown (Max Drawdown) have deteriorated significantly compared to the SOTA, indicating that while the signal is more accurate on average, it may be more volatile or prone to extreme errors in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that the interaction between high price linearity (RSQR10) and low price-volume synchronization (CORR20) identifies mean-reversion is partially supported by the increased IC. The 'Linear_Trend_Volume_Decoupling_Z' approach, which uses Z-scores to isolate the divergence, appears to capture the signal better than simple ratios. However, the poor annualized return and high drawdown suggest that the 'exhaustion' signal might be premature or that the 1-day holding period is too short to capture the full mean-reversion effect.",
        "decision": false,
        "reason": "The current factors focus on the shape of the trend (linearity) and its support (volume), but ignore the magnitude of the move. A highly linear trend with low volume support might not reverse if the total price move is small. By incorporating a volatility-normalized range (e.g., (High-Low)/StdDev), we can identify 'stretched' trends where exhaustion is more likely to lead to a profitable mean-reversion. Additionally, simplifying the expression by using a direct subtraction of ranks or Z-scores (as seen in the current iteration) is preferred over complex ratios to maintain complexity control."
      }
    },
    "30f54cd75db05a27": {
      "factor_id": "30f54cd75db05a27",
      "factor_name": "Volume_Supported_Trend_Efficiency",
      "factor_expression": "ABS(REGBETA($close, SEQUENCE(10), 10)) / (TS_CORR($close, $volume, 20) + 1.1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS(REGBETA($close, SEQUENCE(10), 10)) / (TS_CORR($close, $volume, 20) + 1.1)\" # Your output factor expression will be filled in here\n    name = \"Volume_Supported_Trend_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified measure of trend sustainability. It calculates the ratio of price linearity to price-volume correlation. High values indicate 'inefficient' trends where price moves linearly without corresponding volume confirmation, often preceding a reversal.",
      "factor_formulation": "Factor = \\frac{ABS(REGBETA(close, SEQUENCE(10), 10))}{TS\\_CORR(close, volume, 20) + 1.1}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 0,
        "evolution_phase": "original",
        "trajectory_id": "b100bbf3cd8d",
        "parent_trajectory_ids": [],
        "hypothesis": "Hypothesis: The interaction between the 20-day price-volume correlation (CORR20) and the 10-day price trend linearity (RSQR10) identifies trend exhaustion: specifically, when a highly linear price trend (high RSQR10) is accompanied by a breakdown in price-volume synchronization (low CORR20), the asset is likely to experience a mean-reverting return.\n                Concise Observation: In daily price-volume data, strong trends often show high R-squared values relative to time, but the most sustainable moves typically maintain a consistent correlation with volume; divergence between these two often appears at local price peaks or troughs.\n                Concise Justification: Volume serves as the 'fuel' for price trends; a high R-squared indicates a persistent directional move, but if the correlation with volume drops, it suggests that the price is moving on thinning liquidity or lack of conviction, signaling a potential 'blow-off top' or 'exhaustion gap'.\n                Concise Knowledge: If a price trend exhibits high statistical linearity but loses its correlation with trading volume, the trend's structural strength is weakening; when these two metrics diverge, the probability of a price reversal increases as the move is no longer supported by broad market participation.\n                concise Specification: Define the factor as the product of (1 - CORR(close, volume, 20)) and RSQR(close, 10), where RSQR is the coefficient of determination of close price against a time index, expected to negatively predict returns over the subsequent 5-day horizon.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T22:16:16.565911"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2156576192923504,
        "ICIR": 0.0493727867878478,
        "1day.excess_return_without_cost.std": 0.0047532393251851,
        "1day.excess_return_with_cost.annualized_return": -0.008842355672347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001643956712425,
        "1day.excess_return_without_cost.annualized_return": 0.0391261697557351,
        "1day.excess_return_with_cost.std": 0.0047538275949012,
        "Rank IC": 0.0229610774285775,
        "IC": 0.0073300758738927,
        "1day.excess_return_without_cost.max_drawdown": -0.1657612411577176,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5335672620063892,
        "1day.pa": 0.0,
        "l2.valid": 0.9967935904302332,
        "Rank ICIR": 0.1553216019531143,
        "l2.train": 0.9942025786074422,
        "1day.excess_return_with_cost.information_ratio": -0.1205691152522126,
        "1day.excess_return_with_cost.mean": -3.715275492582812e-05
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the trend exhaustion hypothesis: 'Linear_Trend_Volume_Decoupling_Z' and 'Volume_Supported_Trend_Efficiency'. The current results show a significant improvement in the Information Coefficient (IC) (0.0073 vs 0.0058), suggesting that the interaction between price linearity and volume decoupling has stronger predictive power for cross-sectional returns than previous iterations. However, the risk-adjusted metrics (Information Ratio) and drawdown (Max Drawdown) have deteriorated significantly compared to the SOTA, indicating that while the signal is more accurate on average, it may be more volatile or prone to extreme errors in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that the interaction between high price linearity (RSQR10) and low price-volume synchronization (CORR20) identifies mean-reversion is partially supported by the increased IC. The 'Linear_Trend_Volume_Decoupling_Z' approach, which uses Z-scores to isolate the divergence, appears to capture the signal better than simple ratios. However, the poor annualized return and high drawdown suggest that the 'exhaustion' signal might be premature or that the 1-day holding period is too short to capture the full mean-reversion effect.",
        "decision": false,
        "reason": "The current factors focus on the shape of the trend (linearity) and its support (volume), but ignore the magnitude of the move. A highly linear trend with low volume support might not reverse if the total price move is small. By incorporating a volatility-normalized range (e.g., (High-Low)/StdDev), we can identify 'stretched' trends where exhaustion is more likely to lead to a profitable mean-reversion. Additionally, simplifying the expression by using a direct subtraction of ranks or Z-scores (as seen in the current iteration) is preferred over complex ratios to maintain complexity control."
      }
    },
    "58f8d9cd2ec0990a": {
      "factor_id": "58f8d9cd2ec0990a",
      "factor_name": "Liquidity_Absorption_Anchor_5D",
      "factor_expression": "TS_SUM($volume, 5) / ((TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8) * (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($volume, 5) / ((TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8) * (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Absorption_Anchor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional accumulation by measuring the ratio of cumulative volume to the price range over a 5-day window, further normalized by the inverse of price volatility. High values indicate significant liquidity absorption within a narrow price band, suggesting a potential breakout.",
      "factor_formulation": "LAA_{5D} = \\frac{\\sum_{i=1}^{5} \\text{volume}_i}{(\\max(\\text{high}, 5) - \\min(\\text{low}, 5)) \\cdot \\text{STD}(\\text{close}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7b283fae7af",
        "parent_trajectory_ids": [
          "d83151c7b709"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Anchor factor, defined as the ratio of the 5-day cumulative volume to the 5-day price range (High-Low) normalized by turnover, predicts positive future returns because high volume concentrated in a narrow price range indicates institutional accumulation and supply exhaustion.\n                Concise Observation: The parent strategy focused on high-volatility price 'blow-offs' (momentum exhaustion), but market data also shows periods of high-volume 'flatness' where significant liquidity is exchanged without trend formation, often preceding a breakout.\n                Concise Justification: A high volume-to-range ratio identifies 'hidden' liquidity demand; by using the inverse of the price spread as a multiplier for volume, we isolate stocks where price discovery is temporarily suppressed by absorption, creating a coiled-spring effect for future returns.\n                Concise Knowledge: If high trading volume occurs within a restricted price range (low volatility), it suggests institutional 'anchoring' where large orders are absorbed without triggering price slippage; when this absorption phase concludes, the reduced float often leads to upward price movement.\n                concise Specification: The factor is calculated as the 5-day sum of volume divided by the 5-day maximum high minus minimum low, then multiplied by the inverse of the 5-day price standard deviation to ensure the price 'anchor' is stable.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T22:20:21.335893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1327944542270414,
        "ICIR": 0.0293905713266055,
        "1day.excess_return_without_cost.std": 0.0039346209617395,
        "1day.excess_return_with_cost.annualized_return": -0.0058109314916075,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001727059221079,
        "1day.excess_return_without_cost.annualized_return": 0.0411040094616914,
        "1day.excess_return_with_cost.std": 0.0039357400880281,
        "Rank IC": 0.0190409287293116,
        "IC": 0.0039128161042539,
        "1day.excess_return_without_cost.max_drawdown": -0.1029331851338946,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6771623555376096,
        "1day.pa": 0.0,
        "l2.valid": 0.996440990388684,
        "Rank ICIR": 0.1452420674114618,
        "l2.train": 0.994147481401462,
        "1day.excess_return_with_cost.information_ratio": -0.0957041711576469,
        "1day.excess_return_with_cost.mean": -2.4415678536166333e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Absorption' hypothesis using different window sizes (5D, 10D) and normalization techniques (Standard Deviation, Cross-sectional Rank). While the core concept—that high volume in a narrow price range indicates institutional accumulation—remains theoretically sound, the current implementations (LAA_5D, CSAR_5D, NVC_10D) failed to outperform the existing SOTA result across all key metrics. Specifically, the Information Ratio (0.677 vs 0.972) and IC (0.0039 vs 0.0057) showed significant deterioration, suggesting that the current mathematical formulations might be capturing noise or are improperly scaled for the target return horizon.",
        "hypothesis_evaluation": "The hypothesis that liquidity absorption predicts positive returns is partially supported by the positive IC and annualized return, but the current construction is suboptimal. The 5-day window might be too short to capture true institutional 'accumulation,' or the denominator (Price Range * STD) may be creating extreme values that dilute the signal. The 'Cross-Sectional Rank' approach was a good attempt at robustness, but the lack of improvement suggests the underlying raw signal needs refinement before ranking.",
        "decision": false,
        "reason": "The current factors use raw volume or simple means, which are heavily influenced by the stock's liquidity profile. By using 'Abnormal Volume' (Volume / 20-day Mean Volume) and dividing it by the 'Relative Range' (High-Low / Close), we can better identify periods where trading activity is disproportionately high relative to price movement. Extending the window to 10 days and using a 20-day baseline for volume normalization should reduce noise and improve the Information Ratio. This maintains a low symbol length and low base feature count to avoid overfitting."
      }
    },
    "f8cc9c732ba39fbd": {
      "factor_id": "f8cc9c732ba39fbd",
      "factor_name": "Cross_Sectional_Absorption_Rank_5D",
      "factor_expression": "RANK(TS_MEAN($volume, 5) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume, 5) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Absorption_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the liquidity absorption hypothesis. It calculates the intensity of volume relative to the price spread over 5 days, then applies a cross-sectional rank to ensure the factor is robust against market-wide volume fluctuations.",
      "factor_formulation": "CSAR_{5D} = \\text{RANK}\\left(\\frac{\\text{TS_MEAN}(\\text{volume}, 5)}{\\text{TS_MAX}(\\text{high}, 5) - \\text{TS_MIN}(\\text{low}, 5)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7b283fae7af",
        "parent_trajectory_ids": [
          "d83151c7b709"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Anchor factor, defined as the ratio of the 5-day cumulative volume to the 5-day price range (High-Low) normalized by turnover, predicts positive future returns because high volume concentrated in a narrow price range indicates institutional accumulation and supply exhaustion.\n                Concise Observation: The parent strategy focused on high-volatility price 'blow-offs' (momentum exhaustion), but market data also shows periods of high-volume 'flatness' where significant liquidity is exchanged without trend formation, often preceding a breakout.\n                Concise Justification: A high volume-to-range ratio identifies 'hidden' liquidity demand; by using the inverse of the price spread as a multiplier for volume, we isolate stocks where price discovery is temporarily suppressed by absorption, creating a coiled-spring effect for future returns.\n                Concise Knowledge: If high trading volume occurs within a restricted price range (low volatility), it suggests institutional 'anchoring' where large orders are absorbed without triggering price slippage; when this absorption phase concludes, the reduced float often leads to upward price movement.\n                concise Specification: The factor is calculated as the 5-day sum of volume divided by the 5-day maximum high minus minimum low, then multiplied by the inverse of the 5-day price standard deviation to ensure the price 'anchor' is stable.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T22:20:21.335893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1327944542270414,
        "ICIR": 0.0293905713266055,
        "1day.excess_return_without_cost.std": 0.0039346209617395,
        "1day.excess_return_with_cost.annualized_return": -0.0058109314916075,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001727059221079,
        "1day.excess_return_without_cost.annualized_return": 0.0411040094616914,
        "1day.excess_return_with_cost.std": 0.0039357400880281,
        "Rank IC": 0.0190409287293116,
        "IC": 0.0039128161042539,
        "1day.excess_return_without_cost.max_drawdown": -0.1029331851338946,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6771623555376096,
        "1day.pa": 0.0,
        "l2.valid": 0.996440990388684,
        "Rank ICIR": 0.1452420674114618,
        "l2.train": 0.994147481401462,
        "1day.excess_return_with_cost.information_ratio": -0.0957041711576469,
        "1day.excess_return_with_cost.mean": -2.4415678536166333e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Absorption' hypothesis using different window sizes (5D, 10D) and normalization techniques (Standard Deviation, Cross-sectional Rank). While the core concept—that high volume in a narrow price range indicates institutional accumulation—remains theoretically sound, the current implementations (LAA_5D, CSAR_5D, NVC_10D) failed to outperform the existing SOTA result across all key metrics. Specifically, the Information Ratio (0.677 vs 0.972) and IC (0.0039 vs 0.0057) showed significant deterioration, suggesting that the current mathematical formulations might be capturing noise or are improperly scaled for the target return horizon.",
        "hypothesis_evaluation": "The hypothesis that liquidity absorption predicts positive returns is partially supported by the positive IC and annualized return, but the current construction is suboptimal. The 5-day window might be too short to capture true institutional 'accumulation,' or the denominator (Price Range * STD) may be creating extreme values that dilute the signal. The 'Cross-Sectional Rank' approach was a good attempt at robustness, but the lack of improvement suggests the underlying raw signal needs refinement before ranking.",
        "decision": false,
        "reason": "The current factors use raw volume or simple means, which are heavily influenced by the stock's liquidity profile. By using 'Abnormal Volume' (Volume / 20-day Mean Volume) and dividing it by the 'Relative Range' (High-Low / Close), we can better identify periods where trading activity is disproportionately high relative to price movement. Extending the window to 10 days and using a 20-day baseline for volume normalization should reduce noise and improve the Information Ratio. This maintains a low symbol length and low base feature count to avoid overfitting."
      }
    },
    "a8068bd3ffc03dd8": {
      "factor_id": "a8068bd3ffc03dd8",
      "factor_name": "Normalized_Volume_Concentration_10D",
      "factor_expression": "TS_MEAN($volume, 10) / (TS_STD($close, 10) + TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume, 10) / (TS_STD($close, 10) + TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Volume_Concentration_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the concentration of volume within a stable price range over a 10-day period. It uses the ratio of average volume to the price standard deviation, adjusted by the total price range to isolate 'coiled' stocks where price discovery is suppressed.",
      "factor_formulation": "NVC_{10D} = \\frac{\\text{TS_MEAN}(\\text{volume}, 10)}{\\text{TS_STD}(\\text{close}, 10) + (\\text{TS_MAX}(\\text{high}, 10) - \\text{TS_MIN}(\\text{low}, 10))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7b283fae7af",
        "parent_trajectory_ids": [
          "d83151c7b709"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Anchor factor, defined as the ratio of the 5-day cumulative volume to the 5-day price range (High-Low) normalized by turnover, predicts positive future returns because high volume concentrated in a narrow price range indicates institutional accumulation and supply exhaustion.\n                Concise Observation: The parent strategy focused on high-volatility price 'blow-offs' (momentum exhaustion), but market data also shows periods of high-volume 'flatness' where significant liquidity is exchanged without trend formation, often preceding a breakout.\n                Concise Justification: A high volume-to-range ratio identifies 'hidden' liquidity demand; by using the inverse of the price spread as a multiplier for volume, we isolate stocks where price discovery is temporarily suppressed by absorption, creating a coiled-spring effect for future returns.\n                Concise Knowledge: If high trading volume occurs within a restricted price range (low volatility), it suggests institutional 'anchoring' where large orders are absorbed without triggering price slippage; when this absorption phase concludes, the reduced float often leads to upward price movement.\n                concise Specification: The factor is calculated as the 5-day sum of volume divided by the 5-day maximum high minus minimum low, then multiplied by the inverse of the 5-day price standard deviation to ensure the price 'anchor' is stable.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-20T22:20:21.335893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1327944542270414,
        "ICIR": 0.0293905713266055,
        "1day.excess_return_without_cost.std": 0.0039346209617395,
        "1day.excess_return_with_cost.annualized_return": -0.0058109314916075,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001727059221079,
        "1day.excess_return_without_cost.annualized_return": 0.0411040094616914,
        "1day.excess_return_with_cost.std": 0.0039357400880281,
        "Rank IC": 0.0190409287293116,
        "IC": 0.0039128161042539,
        "1day.excess_return_without_cost.max_drawdown": -0.1029331851338946,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6771623555376096,
        "1day.pa": 0.0,
        "l2.valid": 0.996440990388684,
        "Rank ICIR": 0.1452420674114618,
        "l2.train": 0.994147481401462,
        "1day.excess_return_with_cost.information_ratio": -0.0957041711576469,
        "1day.excess_return_with_cost.mean": -2.4415678536166333e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Absorption' hypothesis using different window sizes (5D, 10D) and normalization techniques (Standard Deviation, Cross-sectional Rank). While the core concept—that high volume in a narrow price range indicates institutional accumulation—remains theoretically sound, the current implementations (LAA_5D, CSAR_5D, NVC_10D) failed to outperform the existing SOTA result across all key metrics. Specifically, the Information Ratio (0.677 vs 0.972) and IC (0.0039 vs 0.0057) showed significant deterioration, suggesting that the current mathematical formulations might be capturing noise or are improperly scaled for the target return horizon.",
        "hypothesis_evaluation": "The hypothesis that liquidity absorption predicts positive returns is partially supported by the positive IC and annualized return, but the current construction is suboptimal. The 5-day window might be too short to capture true institutional 'accumulation,' or the denominator (Price Range * STD) may be creating extreme values that dilute the signal. The 'Cross-Sectional Rank' approach was a good attempt at robustness, but the lack of improvement suggests the underlying raw signal needs refinement before ranking.",
        "decision": false,
        "reason": "The current factors use raw volume or simple means, which are heavily influenced by the stock's liquidity profile. By using 'Abnormal Volume' (Volume / 20-day Mean Volume) and dividing it by the 'Relative Range' (High-Low / Close), we can better identify periods where trading activity is disproportionately high relative to price movement. Extending the window to 10 days and using a 20-day baseline for volume normalization should reduce noise and improve the Information Ratio. This maintains a low symbol length and low base feature count to avoid overfitting."
      }
    },
    "61e0e80b76e0b657": {
      "factor_id": "61e0e80b76e0b657",
      "factor_name": "Liquidity_Friction_Ratio_5D",
      "factor_expression": "ABS($close - $open) / (($high - $low + 1e-8) * TS_MEAN($volume, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ABS($close - $open) / (($high - $low + 1e-8) * TS_MEAN($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Friction_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies liquidity exhaustion by calculating the ratio of price efficiency (net move) to total intraday volatility (high-low range), normalized by the recent average volume. Low values suggest high friction where high volume and volatility fail to produce a directional trend, often preceding a mean reversion.",
      "factor_formulation": "LFR_{5D} = \\frac{ABS(close - open)}{(high - low + 1e-8) \\times TS\\_MEAN(volume, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "66f86cd85e6a",
        "parent_trajectory_ids": [
          "40b954f98281"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Friction Factor' (LFF) identifies price exhaustion by measuring the ratio of price movement efficiency (Close-Open range) to total intraday volatility (High-Low range), conditioned on high volume turnover; specifically, low efficiency during high volume periods predicts short-term mean reversion.\n                Concise Observation: While high volatility with high volume typically indicates trend strength, periods where the price 'struggles' to move (small Close-Open) despite high intraday swings and high volume often precede a breakdown in momentum due to liquidity exhaustion.\n                Concise Justification: A low ratio of net price change to total price path (High-Low) during high-volume periods suggests that aggressive orders are being met by equal and opposite passive liquidity (iceberg orders), creating a 'friction' that prevents further trend extension.\n                Concise Knowledge: If price movement is small relative to the total intraday range despite high volume, then liquidity friction is high; when this 'churn' happens at local extremes, it indicates institutional absorption or exhaustion, leading to a reversal of the current trend.\n                concise Specification: The factor is defined as the ratio of the absolute difference between Open and Close to the High-Low range, inversely weighted by volume; specifically, (ABS($close - $open) / ($high - $low + 1e-8)) / TS_MEAN($volume, 5), targeting low values for reversal signals.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T22:23:11.647610"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147222745477251,
        "ICIR": 0.0210946526374636,
        "1day.excess_return_without_cost.std": 0.0044058606411376,
        "1day.excess_return_with_cost.annualized_return": -0.0124802356019821,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001477305195573,
        "1day.excess_return_without_cost.annualized_return": 0.035159863654661,
        "1day.excess_return_with_cost.std": 0.0044069294883247,
        "Rank IC": 0.0199490048403056,
        "IC": 0.0030142711784426,
        "1day.excess_return_without_cost.max_drawdown": -0.0748054199227784,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5172826922336063,
        "1day.pa": 0.0,
        "l2.valid": 0.9965861198791404,
        "Rank ICIR": 0.1413760830887571,
        "l2.train": 0.9937164008399312,
        "1day.excess_return_with_cost.information_ratio": -0.1835685188393669,
        "1day.excess_return_with_cost.mean": -5.243796471421072e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity Friction Factor' (LFF) framework show that while the theoretical concept of price efficiency vs. volatility is sound, the current implementations (LFR_5D, CSCE_10D, and SFI_20D) underperform compared to the SOTA result across all key metrics, including IC (0.0030 vs 0.0058) and Information Ratio (0.517 vs 0.972). The 'Standardized_Friction_Index_20D' attempted to capture extremes via Z-scores but likely suffered from noise by dividing two Z-scores, which can lead to extreme instability when the denominator is near zero.",
        "hypothesis_evaluation": "The hypothesis that low efficiency during high volume periods predicts mean reversion is partially supported by the positive IC, but the weak magnitude suggests the 'friction' signal is being diluted. The current formulations treat volume as a linear scaling factor or a simple rank, which may not adequately capture the 'exhaustion' threshold. The ratio approach in SFI_20D is mathematically aggressive and likely introduces significant noise.",
        "decision": false,
        "reason": "Current factors use volume as a continuous divisor or rank, which assumes a linear relationship between volume and friction. In reality, liquidity friction is an extreme-event signal. By using the 'Body/Range' ratio only when volume exceeds a certain threshold (e.g., 2 standard deviations), we can filter out low-conviction churning and focus on true institutional absorption. Additionally, reducing the complexity of the interaction (avoiding Z-score/Z-score) will improve robustness."
      }
    },
    "85f15579191a13e8": {
      "factor_id": "85f15579191a13e8",
      "factor_name": "Cross_Sectional_Churn_Efficiency_10D",
      "factor_expression": "RANK(ABS($close - $open) / ($high - $low + 1e-8)) / (RANK(TS_MEAN($volume, 10)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($close - $open) / ($high - $low + 1e-8)) / (RANK(TS_MEAN($volume, 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Churn_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the cross-sectional rank of price efficiency (body-to-range ratio) relative to volume intensity. It targets stocks where the price is 'churning' (low body, high range) on high relative volume, indicating potential institutional absorption and trend exhaustion.",
      "factor_formulation": "CSCE_{10D} = \\frac{RANK(ABS(close - open) / (high - low + 1e-8))}{RANK(TS\\_MEAN(volume, 10))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "66f86cd85e6a",
        "parent_trajectory_ids": [
          "40b954f98281"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Friction Factor' (LFF) identifies price exhaustion by measuring the ratio of price movement efficiency (Close-Open range) to total intraday volatility (High-Low range), conditioned on high volume turnover; specifically, low efficiency during high volume periods predicts short-term mean reversion.\n                Concise Observation: While high volatility with high volume typically indicates trend strength, periods where the price 'struggles' to move (small Close-Open) despite high intraday swings and high volume often precede a breakdown in momentum due to liquidity exhaustion.\n                Concise Justification: A low ratio of net price change to total price path (High-Low) during high-volume periods suggests that aggressive orders are being met by equal and opposite passive liquidity (iceberg orders), creating a 'friction' that prevents further trend extension.\n                Concise Knowledge: If price movement is small relative to the total intraday range despite high volume, then liquidity friction is high; when this 'churn' happens at local extremes, it indicates institutional absorption or exhaustion, leading to a reversal of the current trend.\n                concise Specification: The factor is defined as the ratio of the absolute difference between Open and Close to the High-Low range, inversely weighted by volume; specifically, (ABS($close - $open) / ($high - $low + 1e-8)) / TS_MEAN($volume, 5), targeting low values for reversal signals.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T22:23:11.647610"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147222745477251,
        "ICIR": 0.0210946526374636,
        "1day.excess_return_without_cost.std": 0.0044058606411376,
        "1day.excess_return_with_cost.annualized_return": -0.0124802356019821,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001477305195573,
        "1day.excess_return_without_cost.annualized_return": 0.035159863654661,
        "1day.excess_return_with_cost.std": 0.0044069294883247,
        "Rank IC": 0.0199490048403056,
        "IC": 0.0030142711784426,
        "1day.excess_return_without_cost.max_drawdown": -0.0748054199227784,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5172826922336063,
        "1day.pa": 0.0,
        "l2.valid": 0.9965861198791404,
        "Rank ICIR": 0.1413760830887571,
        "l2.train": 0.9937164008399312,
        "1day.excess_return_with_cost.information_ratio": -0.1835685188393669,
        "1day.excess_return_with_cost.mean": -5.243796471421072e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity Friction Factor' (LFF) framework show that while the theoretical concept of price efficiency vs. volatility is sound, the current implementations (LFR_5D, CSCE_10D, and SFI_20D) underperform compared to the SOTA result across all key metrics, including IC (0.0030 vs 0.0058) and Information Ratio (0.517 vs 0.972). The 'Standardized_Friction_Index_20D' attempted to capture extremes via Z-scores but likely suffered from noise by dividing two Z-scores, which can lead to extreme instability when the denominator is near zero.",
        "hypothesis_evaluation": "The hypothesis that low efficiency during high volume periods predicts mean reversion is partially supported by the positive IC, but the weak magnitude suggests the 'friction' signal is being diluted. The current formulations treat volume as a linear scaling factor or a simple rank, which may not adequately capture the 'exhaustion' threshold. The ratio approach in SFI_20D is mathematically aggressive and likely introduces significant noise.",
        "decision": false,
        "reason": "Current factors use volume as a continuous divisor or rank, which assumes a linear relationship between volume and friction. In reality, liquidity friction is an extreme-event signal. By using the 'Body/Range' ratio only when volume exceeds a certain threshold (e.g., 2 standard deviations), we can filter out low-conviction churning and focus on true institutional absorption. Additionally, reducing the complexity of the interaction (avoiding Z-score/Z-score) will improve robustness."
      }
    },
    "f860d4cbe261bc4b": {
      "factor_id": "f860d4cbe261bc4b",
      "factor_name": "Standardized_Friction_Index_20D",
      "factor_expression": "TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) / (TS_ZSCORE($volume, 20) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS($close - $open) / ($high - $low + 1e-8), 20) / (TS_ZSCORE($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Standardized_Friction_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A standardized version of the liquidity friction hypothesis that uses time-series Z-scores to identify extreme periods of price churn. It calculates the Z-score of the ratio between net price movement and total intraday range, adjusted for volume spikes.",
      "factor_formulation": "SFI_{20D} = TS\\_ZSCORE(\\frac{ABS(close - open)}{high - low + 1e-8}, 20) / TS\\_ZSCORE(volume, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "66f86cd85e6a",
        "parent_trajectory_ids": [
          "40b954f98281"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Friction Factor' (LFF) identifies price exhaustion by measuring the ratio of price movement efficiency (Close-Open range) to total intraday volatility (High-Low range), conditioned on high volume turnover; specifically, low efficiency during high volume periods predicts short-term mean reversion.\n                Concise Observation: While high volatility with high volume typically indicates trend strength, periods where the price 'struggles' to move (small Close-Open) despite high intraday swings and high volume often precede a breakdown in momentum due to liquidity exhaustion.\n                Concise Justification: A low ratio of net price change to total price path (High-Low) during high-volume periods suggests that aggressive orders are being met by equal and opposite passive liquidity (iceberg orders), creating a 'friction' that prevents further trend extension.\n                Concise Knowledge: If price movement is small relative to the total intraday range despite high volume, then liquidity friction is high; when this 'churn' happens at local extremes, it indicates institutional absorption or exhaustion, leading to a reversal of the current trend.\n                concise Specification: The factor is defined as the ratio of the absolute difference between Open and Close to the High-Low range, inversely weighted by volume; specifically, (ABS($close - $open) / ($high - $low + 1e-8)) / TS_MEAN($volume, 5), targeting low values for reversal signals.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-20T22:23:11.647610"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147222745477251,
        "ICIR": 0.0210946526374636,
        "1day.excess_return_without_cost.std": 0.0044058606411376,
        "1day.excess_return_with_cost.annualized_return": -0.0124802356019821,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001477305195573,
        "1day.excess_return_without_cost.annualized_return": 0.035159863654661,
        "1day.excess_return_with_cost.std": 0.0044069294883247,
        "Rank IC": 0.0199490048403056,
        "IC": 0.0030142711784426,
        "1day.excess_return_without_cost.max_drawdown": -0.0748054199227784,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5172826922336063,
        "1day.pa": 0.0,
        "l2.valid": 0.9965861198791404,
        "Rank ICIR": 0.1413760830887571,
        "l2.train": 0.9937164008399312,
        "1day.excess_return_with_cost.information_ratio": -0.1835685188393669,
        "1day.excess_return_with_cost.mean": -5.243796471421072e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity Friction Factor' (LFF) framework show that while the theoretical concept of price efficiency vs. volatility is sound, the current implementations (LFR_5D, CSCE_10D, and SFI_20D) underperform compared to the SOTA result across all key metrics, including IC (0.0030 vs 0.0058) and Information Ratio (0.517 vs 0.972). The 'Standardized_Friction_Index_20D' attempted to capture extremes via Z-scores but likely suffered from noise by dividing two Z-scores, which can lead to extreme instability when the denominator is near zero.",
        "hypothesis_evaluation": "The hypothesis that low efficiency during high volume periods predicts mean reversion is partially supported by the positive IC, but the weak magnitude suggests the 'friction' signal is being diluted. The current formulations treat volume as a linear scaling factor or a simple rank, which may not adequately capture the 'exhaustion' threshold. The ratio approach in SFI_20D is mathematically aggressive and likely introduces significant noise.",
        "decision": false,
        "reason": "Current factors use volume as a continuous divisor or rank, which assumes a linear relationship between volume and friction. In reality, liquidity friction is an extreme-event signal. By using the 'Body/Range' ratio only when volume exceeds a certain threshold (e.g., 2 standard deviations), we can filter out low-conviction churning and focus on true institutional absorption. Additionally, reducing the complexity of the interaction (avoiding Z-score/Z-score) will improve robustness."
      }
    },
    "5d44c8d9c98b0822": {
      "factor_id": "5d44c8d9c98b0822",
      "factor_name": "Overnight_Gap_Volume_Normalized_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (TS_MEAN($volume, 5) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Volume_Normalized_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the overnight sentiment gap normalized by the 5-day average volume. Large price gaps occurring on relatively low liquidity are hypothesized to be noise-driven and prone to mean-reversion. A higher value (positive gap with low volume) suggests a stronger reversal signal.",
      "factor_formulation": "OGVN = \\frac{($open / \\text{DELAY}($close, 1)) - 1}{\\text{TS_MEAN}($volume, 5) / $volume}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "0a41548897e3",
        "parent_trajectory_ids": [
          "7c72861cebb3"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Gap Reversion' factor, defined as the opening gap normalized by the 5-day average volume, negatively predicts future returns as liquidity-driven overnight price jumps tend to mean-revert when not supported by significant volume.\n                Concise Observation: The parent strategy focused on daily low-price support and volume stability (Support Integrity), whereas overnight gaps often exhibit short-term reversal patterns that are independent of intraday shadow formations.\n                Concise Justification: Overnight gaps represent a period of non-continuous trading where small order imbalances can cause disproportionate price moves; normalizing this gap by recent volume helps distinguish between fundamental news-driven gaps and mean-reverting sentiment noise.\n                Concise Knowledge: If a price gap occurs on low relative volume, it is likely driven by noise or retail sentiment; when such gaps are extreme relative to historical volatility, they tend to revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is calculated as the gap (Open / PrevClose - 1) divided by the 5-day rolling average volume; it expects a negative correlation with next-day returns, particularly when the gap magnitude is high and volume is low.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T22:27:43.048238"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0999026815970509,
        "ICIR": 0.0613443692253477,
        "1day.excess_return_without_cost.std": 0.004291502317299,
        "1day.excess_return_with_cost.annualized_return": 0.0205821872947682,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002837513491183,
        "1day.excess_return_without_cost.annualized_return": 0.0675328210901718,
        "1day.excess_return_with_cost.std": 0.0042927164759873,
        "Rank IC": 0.0244192754056584,
        "IC": 0.0080146497251399,
        "1day.excess_return_without_cost.max_drawdown": -0.0903249510880372,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0200396704010748,
        "1day.pa": 0.0,
        "l2.valid": 0.9962354646623854,
        "Rank ICIR": 0.1892736201080559,
        "l2.train": 0.9935016590262278,
        "1day.excess_return_with_cost.information_ratio": 0.310792723394301,
        "1day.excess_return_with_cost.mean": 8.647977854944641e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Gap Reversion' framework, testing three variations: a direct volume-normalized gap, a volatility-adjusted version, and a cross-sectional rank-based interaction. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the IC rising from 0.0058 to 0.0080. The annualized return also saw a healthy boost to 6.75%. While the Max Drawdown slightly deepened, the overall risk-adjusted performance and signal strength (IC) indicate that the interaction between price gaps and relative volume is a robust alpha source.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The 'Ranked_Overnight_Sentiment_Reversal' factor likely contributed most to the performance by isolating stocks where the price jump is most disconnected from liquidity (high rank in gap, high rank in 'low-volume intensity'). This confirms that overnight sentiment without volume support is prone to mean-reversion. The inclusion of volatility adjustment in one of the factors also likely helped in filtering out noise in high-beta stocks.",
        "decision": true,
        "reason": "Current results show that volume-normalized gaps work well. However, price action theory suggests that a 'gap-up' against a 'down-trend' (exhaustion) is more likely to revert than a 'gap-up' following a strong 'up-trend' (continuation). By incorporating the sign of the previous day's intraday return and scaling by a longer-term volatility window (e.g., 20 days), we can better distinguish between 'breakout' gaps and 'exhaustion' gaps, reducing the drawdown seen in the current iteration."
      }
    },
    "cdb1fd95589346d1": {
      "factor_id": "cdb1fd95589346d1",
      "factor_name": "Gap_Reversion_Volatility_Adjusted",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (TS_STD($return, 20) * (TS_MEAN($volume, 5) / ($volume + 1e-8)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-(($open / DELAY($close, 1)) - 1) / ((TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8) * (TS_MEAN($volume, 5) / ($volume + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Gap_Reversion_Volatility_Adjusted\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies overnight gaps that are extreme relative to historical price volatility and normalized by volume turnover. It targets mean-reversion by highlighting gaps that lack the volume support necessary to sustain the price jump.",
      "factor_formulation": "GRVA = \\frac{($open - \\text{DELAY}($close, 1)) / \\text{DELAY}($close, 1)}{\\text{TS_STD}($return, 20) * (\\text{TS_MEAN}($volume, 5) / $volume)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "0a41548897e3",
        "parent_trajectory_ids": [
          "7c72861cebb3"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Gap Reversion' factor, defined as the opening gap normalized by the 5-day average volume, negatively predicts future returns as liquidity-driven overnight price jumps tend to mean-revert when not supported by significant volume.\n                Concise Observation: The parent strategy focused on daily low-price support and volume stability (Support Integrity), whereas overnight gaps often exhibit short-term reversal patterns that are independent of intraday shadow formations.\n                Concise Justification: Overnight gaps represent a period of non-continuous trading where small order imbalances can cause disproportionate price moves; normalizing this gap by recent volume helps distinguish between fundamental news-driven gaps and mean-reverting sentiment noise.\n                Concise Knowledge: If a price gap occurs on low relative volume, it is likely driven by noise or retail sentiment; when such gaps are extreme relative to historical volatility, they tend to revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is calculated as the gap (Open / PrevClose - 1) divided by the 5-day rolling average volume; it expects a negative correlation with next-day returns, particularly when the gap magnitude is high and volume is low.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T22:27:43.048238"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0999026815970509,
        "ICIR": 0.0613443692253477,
        "1day.excess_return_without_cost.std": 0.004291502317299,
        "1day.excess_return_with_cost.annualized_return": 0.0205821872947682,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002837513491183,
        "1day.excess_return_without_cost.annualized_return": 0.0675328210901718,
        "1day.excess_return_with_cost.std": 0.0042927164759873,
        "Rank IC": 0.0244192754056584,
        "IC": 0.0080146497251399,
        "1day.excess_return_without_cost.max_drawdown": -0.0903249510880372,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0200396704010748,
        "1day.pa": 0.0,
        "l2.valid": 0.9962354646623854,
        "Rank ICIR": 0.1892736201080559,
        "l2.train": 0.9935016590262278,
        "1day.excess_return_with_cost.information_ratio": 0.310792723394301,
        "1day.excess_return_with_cost.mean": 8.647977854944641e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Gap Reversion' framework, testing three variations: a direct volume-normalized gap, a volatility-adjusted version, and a cross-sectional rank-based interaction. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the IC rising from 0.0058 to 0.0080. The annualized return also saw a healthy boost to 6.75%. While the Max Drawdown slightly deepened, the overall risk-adjusted performance and signal strength (IC) indicate that the interaction between price gaps and relative volume is a robust alpha source.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The 'Ranked_Overnight_Sentiment_Reversal' factor likely contributed most to the performance by isolating stocks where the price jump is most disconnected from liquidity (high rank in gap, high rank in 'low-volume intensity'). This confirms that overnight sentiment without volume support is prone to mean-reversion. The inclusion of volatility adjustment in one of the factors also likely helped in filtering out noise in high-beta stocks.",
        "decision": true,
        "reason": "Current results show that volume-normalized gaps work well. However, price action theory suggests that a 'gap-up' against a 'down-trend' (exhaustion) is more likely to revert than a 'gap-up' following a strong 'up-trend' (continuation). By incorporating the sign of the previous day's intraday return and scaling by a longer-term volatility window (e.g., 20 days), we can better distinguish between 'breakout' gaps and 'exhaustion' gaps, reducing the drawdown seen in the current iteration."
      }
    },
    "3825ed24e8166cb7": {
      "factor_id": "3825ed24e8166cb7",
      "factor_name": "Ranked_Overnight_Sentiment_Reversal",
      "factor_expression": "RANK(($open / DELAY($close, 1)) - 1) * RANK(TS_MEAN($volume, 5) / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1)) - 1) * RANK(TS_MEAN($volume, 5) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Overnight_Sentiment_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectional factor that ranks the overnight gap and divides it by the relative volume intensity. It identifies stocks with the most 'fragile' gaps (high price change, low relative volume) across the universe to predict short-term negative returns.",
      "factor_formulation": "ROSR = \\text{RANK}(($open / \\text{DELAY}($close, 1)) - 1) * \\text{RANK}(\\text{TS_MEAN}($volume, 5) / $volume)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "0a41548897e3",
        "parent_trajectory_ids": [
          "7c72861cebb3"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Gap Reversion' factor, defined as the opening gap normalized by the 5-day average volume, negatively predicts future returns as liquidity-driven overnight price jumps tend to mean-revert when not supported by significant volume.\n                Concise Observation: The parent strategy focused on daily low-price support and volume stability (Support Integrity), whereas overnight gaps often exhibit short-term reversal patterns that are independent of intraday shadow formations.\n                Concise Justification: Overnight gaps represent a period of non-continuous trading where small order imbalances can cause disproportionate price moves; normalizing this gap by recent volume helps distinguish between fundamental news-driven gaps and mean-reverting sentiment noise.\n                Concise Knowledge: If a price gap occurs on low relative volume, it is likely driven by noise or retail sentiment; when such gaps are extreme relative to historical volatility, they tend to revert as institutional liquidity providers stabilize the price.\n                concise Specification: The factor is calculated as the gap (Open / PrevClose - 1) divided by the 5-day rolling average volume; it expects a negative correlation with next-day returns, particularly when the gap magnitude is high and volume is low.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-20T22:27:43.048238"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0999026815970509,
        "ICIR": 0.0613443692253477,
        "1day.excess_return_without_cost.std": 0.004291502317299,
        "1day.excess_return_with_cost.annualized_return": 0.0205821872947682,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002837513491183,
        "1day.excess_return_without_cost.annualized_return": 0.0675328210901718,
        "1day.excess_return_with_cost.std": 0.0042927164759873,
        "Rank IC": 0.0244192754056584,
        "IC": 0.0080146497251399,
        "1day.excess_return_without_cost.max_drawdown": -0.0903249510880372,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0200396704010748,
        "1day.pa": 0.0,
        "l2.valid": 0.9962354646623854,
        "Rank ICIR": 0.1892736201080559,
        "l2.train": 0.9935016590262278,
        "1day.excess_return_with_cost.information_ratio": 0.310792723394301,
        "1day.excess_return_with_cost.mean": 8.647977854944641e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Gap Reversion' framework, testing three variations: a direct volume-normalized gap, a volatility-adjusted version, and a cross-sectional rank-based interaction. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the IC rising from 0.0058 to 0.0080. The annualized return also saw a healthy boost to 6.75%. While the Max Drawdown slightly deepened, the overall risk-adjusted performance and signal strength (IC) indicate that the interaction between price gaps and relative volume is a robust alpha source.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The 'Ranked_Overnight_Sentiment_Reversal' factor likely contributed most to the performance by isolating stocks where the price jump is most disconnected from liquidity (high rank in gap, high rank in 'low-volume intensity'). This confirms that overnight sentiment without volume support is prone to mean-reversion. The inclusion of volatility adjustment in one of the factors also likely helped in filtering out noise in high-beta stocks.",
        "decision": true,
        "reason": "Current results show that volume-normalized gaps work well. However, price action theory suggests that a 'gap-up' against a 'down-trend' (exhaustion) is more likely to revert than a 'gap-up' following a strong 'up-trend' (continuation). By incorporating the sign of the previous day's intraday return and scaling by a longer-term volatility window (e.g., 20 days), we can better distinguish between 'breakout' gaps and 'exhaustion' gaps, reducing the drawdown seen in the current iteration."
      }
    },
    "df6e37ea3abf9569": {
      "factor_id": "df6e37ea3abf9569",
      "factor_name": "Intraday_Conviction_Ratio_1D",
      "factor_expression": "RANK(($close - $open) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $open) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Conviction_Ratio_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the strength of intraday price movement relative to the total daily range. A high value suggests that the price moved decisively from open to close with minimal noise, indicating strong institutional conviction that often persists into the following days.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{close} - \\text{open}}{\\text{high} - \\text{low} + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "faf56bb28213",
        "parent_trajectory_ids": [
          "ee9a7812274d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Institutional Conviction' factor, defined by the ratio of the daily close to the open price scaled by the day's price range, predicts short-term momentum continuation as it reflects systematic institutional buying or selling pressure that persists beyond the market open.\n                Concise Observation: While long-term mean reversion captures retail exhaustion, many assets exhibit strong intraday trends where the 'close-open' spread relative to the 'high-low' range serves as a proxy for net institutional flow and trend quality.\n                Concise Justification: Institutional investors often execute large orders algorithmically throughout the day, leading to a steady price move from open to close; a high ratio of (Close - Open) / (High - Low) filters out noise and identifies sessions with unidirectional conviction.\n                Concise Knowledge: If a stock closes near its daily high after a positive open-to-close move, it indicates strong intraday trend persistence; when this price strength is coupled with high intraday range capture, it signals institutional conviction that likely carries over to subsequent sessions.\n                concise Specification: The factor is calculated as (Close - Open) / (High - Low + epsilon) on a daily basis; it focuses on the cross-sectional momentum of the current day's price action to predict the next 1-5 days' returns, representing a shift from 60-day reversion to 1-day trend strength.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T22:30:42.087538"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1937320928598652,
        "ICIR": 0.0376718086090483,
        "1day.excess_return_without_cost.std": 0.0050743384598521,
        "1day.excess_return_with_cost.annualized_return": 0.0333674948100559,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003408416038368,
        "1day.excess_return_without_cost.annualized_return": 0.0811203017131804,
        "1day.excess_return_with_cost.std": 0.0050771427473631,
        "Rank IC": 0.017840287616879,
        "IC": 0.005412211343772,
        "1day.excess_return_without_cost.max_drawdown": -0.1520519719090481,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.036243089462558,
        "1day.pa": 0.0,
        "l2.valid": 0.9965533964644476,
        "Rank ICIR": 0.1302193834688005,
        "l2.train": 0.9937824333167534,
        "1day.excess_return_with_cost.information_ratio": 0.4260060324819307,
        "1day.excess_return_with_cost.mean": 0.0001401995580254
      },
      "feedback": {
        "observations": "The current iteration of the 'Intraday Institutional Conviction' framework shows a significant improvement in risk-adjusted performance and total returns. Specifically, the combination of smoothed conviction with volume dynamics (Conviction_Volume_Weighted_3D) or the smoothed baseline (Smoothed_Institutional_Flow_5D) has successfully boosted the Information Ratio from 0.97 to 1.04 and the Annualized Return from 5.2% to 8.1%. However, the IC slightly decreased, and the Max Drawdown increased significantly (-15.2% vs -7.2%), suggesting that while the new factors capture higher alpha, they also introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that intraday conviction (close-open relative to range) predicts short-term returns. The improvement in Annualized Return indicates that scaling the price movement by the daily range effectively filters out noise. The success of the volume-weighted and smoothed versions suggests that institutional conviction is more predictive when it is persistent (TS_MEAN) and confirmed by trading activity (Volume DELTA).",
        "decision": true,
        "reason": "While the current 'Conviction_Volume_Weighted_3D' uses volume change, it doesn't account for whether the volume is high relative to the stock's own history (Volume Z-Score). Furthermore, a high conviction ratio on a very small daily range might be less significant than one on an expanded range. By incorporating a 'Range Volatility' component (e.g., current range vs. 20-day average range), we can identify high-conviction 'breakout' days which likely lead to stronger momentum continuation."
      }
    },
    "d7ea10572442150a": {
      "factor_id": "d7ea10572442150a",
      "factor_name": "Smoothed_Institutional_Flow_5D",
      "factor_expression": "ZSCORE(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Institutional_Flow_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A smoothed version of the intraday conviction ratio over a 5-day window. By averaging the daily 'close-to-open' efficiency, it identifies assets with consistent institutional buying or selling pressure, reducing the impact of single-day anomalies.",
      "factor_formulation": "\\text{ZSCORE}(\\text{TS_MEAN}(\\frac{\\text{close} - \\text{open}}{\\text{high} - \\text{low} + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "faf56bb28213",
        "parent_trajectory_ids": [
          "ee9a7812274d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Institutional Conviction' factor, defined by the ratio of the daily close to the open price scaled by the day's price range, predicts short-term momentum continuation as it reflects systematic institutional buying or selling pressure that persists beyond the market open.\n                Concise Observation: While long-term mean reversion captures retail exhaustion, many assets exhibit strong intraday trends where the 'close-open' spread relative to the 'high-low' range serves as a proxy for net institutional flow and trend quality.\n                Concise Justification: Institutional investors often execute large orders algorithmically throughout the day, leading to a steady price move from open to close; a high ratio of (Close - Open) / (High - Low) filters out noise and identifies sessions with unidirectional conviction.\n                Concise Knowledge: If a stock closes near its daily high after a positive open-to-close move, it indicates strong intraday trend persistence; when this price strength is coupled with high intraday range capture, it signals institutional conviction that likely carries over to subsequent sessions.\n                concise Specification: The factor is calculated as (Close - Open) / (High - Low + epsilon) on a daily basis; it focuses on the cross-sectional momentum of the current day's price action to predict the next 1-5 days' returns, representing a shift from 60-day reversion to 1-day trend strength.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T22:30:42.087538"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1937320928598652,
        "ICIR": 0.0376718086090483,
        "1day.excess_return_without_cost.std": 0.0050743384598521,
        "1day.excess_return_with_cost.annualized_return": 0.0333674948100559,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003408416038368,
        "1day.excess_return_without_cost.annualized_return": 0.0811203017131804,
        "1day.excess_return_with_cost.std": 0.0050771427473631,
        "Rank IC": 0.017840287616879,
        "IC": 0.005412211343772,
        "1day.excess_return_without_cost.max_drawdown": -0.1520519719090481,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.036243089462558,
        "1day.pa": 0.0,
        "l2.valid": 0.9965533964644476,
        "Rank ICIR": 0.1302193834688005,
        "l2.train": 0.9937824333167534,
        "1day.excess_return_with_cost.information_ratio": 0.4260060324819307,
        "1day.excess_return_with_cost.mean": 0.0001401995580254
      },
      "feedback": {
        "observations": "The current iteration of the 'Intraday Institutional Conviction' framework shows a significant improvement in risk-adjusted performance and total returns. Specifically, the combination of smoothed conviction with volume dynamics (Conviction_Volume_Weighted_3D) or the smoothed baseline (Smoothed_Institutional_Flow_5D) has successfully boosted the Information Ratio from 0.97 to 1.04 and the Annualized Return from 5.2% to 8.1%. However, the IC slightly decreased, and the Max Drawdown increased significantly (-15.2% vs -7.2%), suggesting that while the new factors capture higher alpha, they also introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that intraday conviction (close-open relative to range) predicts short-term returns. The improvement in Annualized Return indicates that scaling the price movement by the daily range effectively filters out noise. The success of the volume-weighted and smoothed versions suggests that institutional conviction is more predictive when it is persistent (TS_MEAN) and confirmed by trading activity (Volume DELTA).",
        "decision": true,
        "reason": "While the current 'Conviction_Volume_Weighted_3D' uses volume change, it doesn't account for whether the volume is high relative to the stock's own history (Volume Z-Score). Furthermore, a high conviction ratio on a very small daily range might be less significant than one on an expanded range. By incorporating a 'Range Volatility' component (e.g., current range vs. 20-day average range), we can identify high-conviction 'breakout' days which likely lead to stronger momentum continuation."
      }
    },
    "b0273d7fd77a1d0f": {
      "factor_id": "b0273d7fd77a1d0f",
      "factor_name": "Conviction_Volume_Weighted_3D",
      "factor_expression": "RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 3)) * RANK(TS_MEAN(DELTA($volume, 1), 3))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 3)) * RANK(TS_MEAN(DELTA($volume, 1), 3))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Volume_Weighted_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor combines the intraday conviction ratio with volume trends. It multiplies the 3-day average conviction ratio by the 3-day average volume change, emphasizing sessions where price efficiency is backed by increasing market participation.",
      "factor_formulation": "\\text{RANK}(\\text{TS_MEAN}(\\frac{\\text{close} - \\text{open}}{\\text{high} - \\text{low} + 1e-8}, 3)) * \\text{RANK}(\\text{TS_MEAN}(\\text{DELTA}(\\text{volume}, 1), 3))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "faf56bb28213",
        "parent_trajectory_ids": [
          "ee9a7812274d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Institutional Conviction' factor, defined by the ratio of the daily close to the open price scaled by the day's price range, predicts short-term momentum continuation as it reflects systematic institutional buying or selling pressure that persists beyond the market open.\n                Concise Observation: While long-term mean reversion captures retail exhaustion, many assets exhibit strong intraday trends where the 'close-open' spread relative to the 'high-low' range serves as a proxy for net institutional flow and trend quality.\n                Concise Justification: Institutional investors often execute large orders algorithmically throughout the day, leading to a steady price move from open to close; a high ratio of (Close - Open) / (High - Low) filters out noise and identifies sessions with unidirectional conviction.\n                Concise Knowledge: If a stock closes near its daily high after a positive open-to-close move, it indicates strong intraday trend persistence; when this price strength is coupled with high intraday range capture, it signals institutional conviction that likely carries over to subsequent sessions.\n                concise Specification: The factor is calculated as (Close - Open) / (High - Low + epsilon) on a daily basis; it focuses on the cross-sectional momentum of the current day's price action to predict the next 1-5 days' returns, representing a shift from 60-day reversion to 1-day trend strength.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-20T22:30:42.087538"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1937320928598652,
        "ICIR": 0.0376718086090483,
        "1day.excess_return_without_cost.std": 0.0050743384598521,
        "1day.excess_return_with_cost.annualized_return": 0.0333674948100559,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003408416038368,
        "1day.excess_return_without_cost.annualized_return": 0.0811203017131804,
        "1day.excess_return_with_cost.std": 0.0050771427473631,
        "Rank IC": 0.017840287616879,
        "IC": 0.005412211343772,
        "1day.excess_return_without_cost.max_drawdown": -0.1520519719090481,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.036243089462558,
        "1day.pa": 0.0,
        "l2.valid": 0.9965533964644476,
        "Rank ICIR": 0.1302193834688005,
        "l2.train": 0.9937824333167534,
        "1day.excess_return_with_cost.information_ratio": 0.4260060324819307,
        "1day.excess_return_with_cost.mean": 0.0001401995580254
      },
      "feedback": {
        "observations": "The current iteration of the 'Intraday Institutional Conviction' framework shows a significant improvement in risk-adjusted performance and total returns. Specifically, the combination of smoothed conviction with volume dynamics (Conviction_Volume_Weighted_3D) or the smoothed baseline (Smoothed_Institutional_Flow_5D) has successfully boosted the Information Ratio from 0.97 to 1.04 and the Annualized Return from 5.2% to 8.1%. However, the IC slightly decreased, and the Max Drawdown increased significantly (-15.2% vs -7.2%), suggesting that while the new factors capture higher alpha, they also introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that intraday conviction (close-open relative to range) predicts short-term returns. The improvement in Annualized Return indicates that scaling the price movement by the daily range effectively filters out noise. The success of the volume-weighted and smoothed versions suggests that institutional conviction is more predictive when it is persistent (TS_MEAN) and confirmed by trading activity (Volume DELTA).",
        "decision": true,
        "reason": "While the current 'Conviction_Volume_Weighted_3D' uses volume change, it doesn't account for whether the volume is high relative to the stock's own history (Volume Z-Score). Furthermore, a high conviction ratio on a very small daily range might be less significant than one on an expanded range. By incorporating a 'Range Volatility' component (e.g., current range vs. 20-day average range), we can identify high-conviction 'breakout' days which likely lead to stronger momentum continuation."
      }
    },
    "00cd532f100ed485": {
      "factor_id": "00cd532f100ed485",
      "factor_name": "Liquidity_Absorption_Asymmetry_10D",
      "factor_expression": "SUMIF($volume * DELTA($close, 1), 10, DELTA($close, 1) > 0) / (ABS(SUMIF($volume * DELTA($close, 1), 10, DELTA($close, 1) < 0)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SUMIF($volume * DELTA($close, 1), 10, DELTA($close, 1) > 0) / (ABS(SUMIF($volume * DELTA($close, 1), 10, DELTA($close, 1) < 0)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Absorption_Asymmetry_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor calculates the ratio of volume-weighted positive price changes to the absolute volume-weighted negative price changes over a 10-day window. It identifies institutional accumulation by detecting if volume is disproportionately concentrated on up-days compared to down-days.",
      "factor_formulation": "\\frac{\\sum_{i=1}^{10} (\\text{volume}_i \\times \\Delta \\text{close}_i) \\text{ if } \\Delta \\text{close}_i > 0}{\\text{ABS}(\\sum_{i=1}^{10} (\\text{volume}_i \\times \\Delta \\text{close}_i) \\text{ if } \\Delta \\text{close}_i < 0)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7c2ae4ea3aa",
        "parent_trajectory_ids": [
          "3812681a3ef1"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Asymmetry factor, calculated as the ratio of volume-weighted positive price changes to volume-weighted negative price changes over a 10-day window, positively predicts future returns by identifying subtle institutional accumulation.\n                Concise Observation: While price-based trend stability (like R-squared) captures the 'shape' of a move, it ignores the 'effort' (volume) required to move the price, which often reveals institutional intent before a trend becomes linear.\n                Concise Justification: Institutional investors often use limit orders to accumulate positions, causing price to tick up on high volume but allowing it to drift down on low volume; this volume-price coupling reveals demand that price-only indicators miss.\n                Concise Knowledge: If volume is disproportionately concentrated on positive price movements even when price volatility is low, it indicates strong underlying demand; when this asymmetry is high, future returns tend to be positive as supply is absorbed.\n                concise Specification: The factor is defined as the sum of ($volume * $close_change) for all positive change days divided by the absolute sum of ($volume * $close_change) for all negative change days over a 10-day lookback period.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T22:34:53.502337"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1279642055966109,
        "ICIR": 0.0427664459000318,
        "1day.excess_return_without_cost.std": 0.0050604073234227,
        "1day.excess_return_with_cost.annualized_return": 0.0211820035334379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002881738411574,
        "1day.excess_return_without_cost.annualized_return": 0.0685853741954832,
        "1day.excess_return_with_cost.std": 0.0050618437964262,
        "Rank IC": 0.0235796300771172,
        "IC": 0.006296084835859,
        "1day.excess_return_without_cost.max_drawdown": -0.0941785817586592,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8785319460145823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965444971969946,
        "Rank ICIR": 0.1647906276218121,
        "l2.train": 0.9938346929355464,
        "1day.excess_return_with_cost.information_ratio": 0.2712500447438434,
        "1day.excess_return_with_cost.mean": 8.900001484637785e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Liquidity Absorption Asymmetry hypothesis. The 'Volume_Weighted_Return_Skew_15D' and its siblings have successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0063, and the Annualized Return rose from 5.2% to 6.86%. However, this came at the cost of a higher Max Drawdown (-0.094 vs -0.072) and a slightly lower Information Ratio, suggesting that while the predictive signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The results support the hypothesis that volume-weighted price asymmetry is a valid predictor of future returns. The use of a 15-day window in the 'Volume_Weighted_Return_Skew' formulation appears more robust than the initial 10-day ratio, likely because the normalization (dividing by the sum of absolute volume-weighted returns) creates a bounded oscillator (-1 to 1) that is more stable for model training than a raw ratio of sums.",
        "decision": true,
        "reason": "While the current 'Volume_Weighted_Return_Skew_15D' is effective, it may be capturing simple momentum or size effects. By introducing a 'Volume Z-Score' or comparing the asymmetry to a longer-term baseline (e.g., 60 days), we can isolate 'unusual' institutional accumulation from standard trading activity. Furthermore, keeping the mathematical structure simple (avoiding nested Ranks or complex IF conditions) will maintain the current lead in IC while potentially smoothing the drawdown seen in this iteration."
      }
    },
    "1dca08c39affa707": {
      "factor_id": "1dca08c39affa707",
      "factor_name": "Institutional_Accumulation_Intensity_20D",
      "factor_expression": "RANK(SUMIF($volume * $return, 20, $return > 0) / (SUMIF($volume * ABS($return), 20, $return < 0) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SUMIF($volume * TS_PCTCHANGE($close, 1), 20, TS_PCTCHANGE($close, 1) > 0) / (ABS(SUMIF($volume * TS_PCTCHANGE($close, 1), 20, TS_PCTCHANGE($close, 1) < 0)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the liquidity absorption hypothesis using daily returns and cross-sectional ranking. It measures the relative intensity of volume-weighted gains versus losses over a 20-day period to capture persistent buying pressure.",
      "factor_formulation": "\\text{RANK}(\\frac{\\sum_{i=1}^{20} (\\text{volume}_i \\times \\text{return}_i) \\text{ if } \\text{return}_i > 0}{\\sum_{i=1}^{20} (\\text{volume}_i \\times \\text{ABS}(\\text{return}_i)) \\text{ if } \\text{return}_i < 0})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7c2ae4ea3aa",
        "parent_trajectory_ids": [
          "3812681a3ef1"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Asymmetry factor, calculated as the ratio of volume-weighted positive price changes to volume-weighted negative price changes over a 10-day window, positively predicts future returns by identifying subtle institutional accumulation.\n                Concise Observation: While price-based trend stability (like R-squared) captures the 'shape' of a move, it ignores the 'effort' (volume) required to move the price, which often reveals institutional intent before a trend becomes linear.\n                Concise Justification: Institutional investors often use limit orders to accumulate positions, causing price to tick up on high volume but allowing it to drift down on low volume; this volume-price coupling reveals demand that price-only indicators miss.\n                Concise Knowledge: If volume is disproportionately concentrated on positive price movements even when price volatility is low, it indicates strong underlying demand; when this asymmetry is high, future returns tend to be positive as supply is absorbed.\n                concise Specification: The factor is defined as the sum of ($volume * $close_change) for all positive change days divided by the absolute sum of ($volume * $close_change) for all negative change days over a 10-day lookback period.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T22:34:53.502337"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1279642055966109,
        "ICIR": 0.0427664459000318,
        "1day.excess_return_without_cost.std": 0.0050604073234227,
        "1day.excess_return_with_cost.annualized_return": 0.0211820035334379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002881738411574,
        "1day.excess_return_without_cost.annualized_return": 0.0685853741954832,
        "1day.excess_return_with_cost.std": 0.0050618437964262,
        "Rank IC": 0.0235796300771172,
        "IC": 0.006296084835859,
        "1day.excess_return_without_cost.max_drawdown": -0.0941785817586592,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8785319460145823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965444971969946,
        "Rank ICIR": 0.1647906276218121,
        "l2.train": 0.9938346929355464,
        "1day.excess_return_with_cost.information_ratio": 0.2712500447438434,
        "1day.excess_return_with_cost.mean": 8.900001484637785e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Liquidity Absorption Asymmetry hypothesis. The 'Volume_Weighted_Return_Skew_15D' and its siblings have successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0063, and the Annualized Return rose from 5.2% to 6.86%. However, this came at the cost of a higher Max Drawdown (-0.094 vs -0.072) and a slightly lower Information Ratio, suggesting that while the predictive signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The results support the hypothesis that volume-weighted price asymmetry is a valid predictor of future returns. The use of a 15-day window in the 'Volume_Weighted_Return_Skew' formulation appears more robust than the initial 10-day ratio, likely because the normalization (dividing by the sum of absolute volume-weighted returns) creates a bounded oscillator (-1 to 1) that is more stable for model training than a raw ratio of sums.",
        "decision": true,
        "reason": "While the current 'Volume_Weighted_Return_Skew_15D' is effective, it may be capturing simple momentum or size effects. By introducing a 'Volume Z-Score' or comparing the asymmetry to a longer-term baseline (e.g., 60 days), we can isolate 'unusual' institutional accumulation from standard trading activity. Furthermore, keeping the mathematical structure simple (avoiding nested Ranks or complex IF conditions) will maintain the current lead in IC while potentially smoothing the drawdown seen in this iteration."
      }
    },
    "79209beabdc629ca": {
      "factor_id": "79209beabdc629ca",
      "factor_name": "Volume_Weighted_Return_Skew_15D",
      "factor_expression": "TS_SUM($volume * $return, 15) / (TS_SUM($volume * ABS($return), 15) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($volume * TS_PCTCHANGE($close, 1), 15) / (TS_SUM($volume * ABS(TS_PCTCHANGE($close, 1)), 15) + 0.00000001)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Return_Skew_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the asymmetry in volume-weighted price movements by comparing the sum of volume-weighted returns to the total volume-weighted absolute returns. High values indicate that the 'effort' (volume) is resulting in more positive price progress.",
      "factor_formulation": "\\frac{\\sum_{i=1}^{15} (\\text{volume}_i \\times \\text{return}_i)}{\\sum_{i=1}^{15} (\\text{volume}_i \\times |\\text{return}_i|)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "d7c2ae4ea3aa",
        "parent_trajectory_ids": [
          "3812681a3ef1"
        ],
        "hypothesis": "Hypothesis: The Liquidity Absorption Asymmetry factor, calculated as the ratio of volume-weighted positive price changes to volume-weighted negative price changes over a 10-day window, positively predicts future returns by identifying subtle institutional accumulation.\n                Concise Observation: While price-based trend stability (like R-squared) captures the 'shape' of a move, it ignores the 'effort' (volume) required to move the price, which often reveals institutional intent before a trend becomes linear.\n                Concise Justification: Institutional investors often use limit orders to accumulate positions, causing price to tick up on high volume but allowing it to drift down on low volume; this volume-price coupling reveals demand that price-only indicators miss.\n                Concise Knowledge: If volume is disproportionately concentrated on positive price movements even when price volatility is low, it indicates strong underlying demand; when this asymmetry is high, future returns tend to be positive as supply is absorbed.\n                concise Specification: The factor is defined as the sum of ($volume * $close_change) for all positive change days divided by the absolute sum of ($volume * $close_change) for all negative change days over a 10-day lookback period.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-20T22:34:53.502337"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1279642055966109,
        "ICIR": 0.0427664459000318,
        "1day.excess_return_without_cost.std": 0.0050604073234227,
        "1day.excess_return_with_cost.annualized_return": 0.0211820035334379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002881738411574,
        "1day.excess_return_without_cost.annualized_return": 0.0685853741954832,
        "1day.excess_return_with_cost.std": 0.0050618437964262,
        "Rank IC": 0.0235796300771172,
        "IC": 0.006296084835859,
        "1day.excess_return_without_cost.max_drawdown": -0.0941785817586592,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8785319460145823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965444971969946,
        "Rank ICIR": 0.1647906276218121,
        "l2.train": 0.9938346929355464,
        "1day.excess_return_with_cost.information_ratio": 0.2712500447438434,
        "1day.excess_return_with_cost.mean": 8.900001484637785e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Liquidity Absorption Asymmetry hypothesis. The 'Volume_Weighted_Return_Skew_15D' and its siblings have successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0063, and the Annualized Return rose from 5.2% to 6.86%. However, this came at the cost of a higher Max Drawdown (-0.094 vs -0.072) and a slightly lower Information Ratio, suggesting that while the predictive signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The results support the hypothesis that volume-weighted price asymmetry is a valid predictor of future returns. The use of a 15-day window in the 'Volume_Weighted_Return_Skew' formulation appears more robust than the initial 10-day ratio, likely because the normalization (dividing by the sum of absolute volume-weighted returns) creates a bounded oscillator (-1 to 1) that is more stable for model training than a raw ratio of sums.",
        "decision": true,
        "reason": "While the current 'Volume_Weighted_Return_Skew_15D' is effective, it may be capturing simple momentum or size effects. By introducing a 'Volume Z-Score' or comparing the asymmetry to a longer-term baseline (e.g., 60 days), we can isolate 'unusual' institutional accumulation from standard trading activity. Furthermore, keeping the mathematical structure simple (avoiding nested Ranks or complex IF conditions) will maintain the current lead in IC while potentially smoothing the drawdown seen in this iteration."
      }
    },
    "b284624019b18714": {
      "factor_id": "b284624019b18714",
      "factor_name": "IAD_Momentum_Ratio_5D",
      "factor_expression": "TS_MEAN(($high - $low) / ($volume + 1e-8), 5) * TS_SUM($return, 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_PCTCHANGE($close, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IAD_Momentum_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional accumulation by measuring 'tight' price action (low high-low range) relative to volume intensity, adjusted by 5-day momentum. A lower ratio of range-to-volume during an uptrend suggests institutional absorption and high-quality trend breakouts.",
      "factor_formulation": "IAD = \\text{TS_MEAN}(\\frac{high - low}{volume + 1e-8}, 5) \\times \\text{TS_SUM}(return, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "326a1ca00c43",
        "parent_trajectory_ids": [
          "49a2f9ab207c"
        ],
        "hypothesis": "Hypothesis: The Institutional Accumulation Divergence (IAD) factor, defined as the 5-day average of the daily price range scaled by volume intensity, identifies high-quality trend breakouts where price expansion is supported by concentrated liquidity rather than speculative volatility.\n                Concise Observation: While the previous mean-reversion strategy focused on price exhaustion (residuals), market leaders often exhibit 'tight' price action on high relative volume before a major move, suggesting that the quality of volume flow is more predictive of trend than simple price deviation.\n                Concise Justification: Institutional buyers typically use execution algorithms to minimize market impact, leading to consistent volume absorption within a controlled price range; identifying this 'tightness' during upward moves separates structural accumulation from retail-driven spikes.\n                Concise Knowledge: If price appreciation occurs with a narrowing high-low range relative to volume, it indicates institutional absorption; when this 'quiet' strength persists, it signals a sustainable trend breakout rather than a mean-reversion event.\n                concise Specification: The factor will be calculated as the 5-day moving average of the ratio between the daily ($high - $low) and the $volume, further adjusted by the 5-day price momentum to ensure directionality, targeting stocks with low price-spread-to-volume ratios during uptrends.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T22:38:45.908099"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2189121422977219,
        "ICIR": 0.0219773787314308,
        "1day.excess_return_without_cost.std": 0.0047453747787826,
        "1day.excess_return_with_cost.annualized_return": -0.0209823114488982,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001127653537303,
        "1day.excess_return_without_cost.annualized_return": 0.0268381541878148,
        "1day.excess_return_with_cost.std": 0.0047471393309509,
        "Rank IC": 0.0181348695256892,
        "IC": 0.003121380896564,
        "1day.excess_return_without_cost.max_drawdown": -0.1591555184006667,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3666010017921421,
        "1day.pa": 0.0,
        "l2.valid": 0.995934526136782,
        "Rank ICIR": 0.1291475332882413,
        "l2.train": 0.9932001568986438,
        "1day.excess_return_with_cost.information_ratio": -0.2865054396282625,
        "1day.excess_return_with_cost.mean": -8.816097247436236e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the Institutional Accumulation Divergence (IAD) hypothesis: a momentum-weighted range/volume ratio, a cross-sectional rank of volume intensity relative to price spread, and a Z-scored breakout signal. While the theoretical framework of 'tight price action supported by high volume' is sound, the current implementations failed to outperform the SOTA result. The IC (0.0031 vs 0.0058) and Information Ratio (0.36 vs 0.97) show significant deterioration, suggesting that the current linear combinations or window sizes may not be capturing the signal effectively, or the interaction between volume and range is more non-linear than modeled.",
        "hypothesis_evaluation": "The hypothesis that low price range scaled by volume intensity identifies high-quality breakouts is partially supported by the positive IC, but the performance is weak. The 'Institutional_Tightness_Rank_10D' and 'ABS' factors use volume as a numerator, which is more intuitive for 'intensity', whereas the first factor used it as a denominator. The results suggest that while the 'tightness' concept is valid, the current 5-day and 10-day windows might be too short to distinguish between true institutional accumulation and simple low-volatility consolidation.",
        "decision": false,
        "reason": "The current factors compare volume/range cross-sectionally or via simple means. However, institutional accumulation is a process. By measuring the change in volume-per-unit-of-range relative to a longer-term baseline (e.g., 20 days), we can isolate 'unusual' accumulation. Furthermore, using the high-low range can be noisy; using the standard deviation of returns as a denominator for volume might provide a more robust measure of 'price effort' versus 'result'."
      }
    },
    "44c8658556a0653d": {
      "factor_id": "44c8658556a0653d",
      "factor_name": "Institutional_Tightness_Rank_10D",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Tightness_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures the inverse relationship between price volatility and volume intensity. It ranks stocks where the price spread is narrow relative to volume, specifically focusing on the consistency of this behavior over a 10-day window to identify structural accumulation.",
      "factor_formulation": "ITR = \\text{RANK}(\\text{TS_MEAN}(\\frac{volume}{high - low + 1e-8}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "326a1ca00c43",
        "parent_trajectory_ids": [
          "49a2f9ab207c"
        ],
        "hypothesis": "Hypothesis: The Institutional Accumulation Divergence (IAD) factor, defined as the 5-day average of the daily price range scaled by volume intensity, identifies high-quality trend breakouts where price expansion is supported by concentrated liquidity rather than speculative volatility.\n                Concise Observation: While the previous mean-reversion strategy focused on price exhaustion (residuals), market leaders often exhibit 'tight' price action on high relative volume before a major move, suggesting that the quality of volume flow is more predictive of trend than simple price deviation.\n                Concise Justification: Institutional buyers typically use execution algorithms to minimize market impact, leading to consistent volume absorption within a controlled price range; identifying this 'tightness' during upward moves separates structural accumulation from retail-driven spikes.\n                Concise Knowledge: If price appreciation occurs with a narrowing high-low range relative to volume, it indicates institutional absorption; when this 'quiet' strength persists, it signals a sustainable trend breakout rather than a mean-reversion event.\n                concise Specification: The factor will be calculated as the 5-day moving average of the ratio between the daily ($high - $low) and the $volume, further adjusted by the 5-day price momentum to ensure directionality, targeting stocks with low price-spread-to-volume ratios during uptrends.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T22:38:45.908099"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2189121422977219,
        "ICIR": 0.0219773787314308,
        "1day.excess_return_without_cost.std": 0.0047453747787826,
        "1day.excess_return_with_cost.annualized_return": -0.0209823114488982,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001127653537303,
        "1day.excess_return_without_cost.annualized_return": 0.0268381541878148,
        "1day.excess_return_with_cost.std": 0.0047471393309509,
        "Rank IC": 0.0181348695256892,
        "IC": 0.003121380896564,
        "1day.excess_return_without_cost.max_drawdown": -0.1591555184006667,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3666010017921421,
        "1day.pa": 0.0,
        "l2.valid": 0.995934526136782,
        "Rank ICIR": 0.1291475332882413,
        "l2.train": 0.9932001568986438,
        "1day.excess_return_with_cost.information_ratio": -0.2865054396282625,
        "1day.excess_return_with_cost.mean": -8.816097247436236e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the Institutional Accumulation Divergence (IAD) hypothesis: a momentum-weighted range/volume ratio, a cross-sectional rank of volume intensity relative to price spread, and a Z-scored breakout signal. While the theoretical framework of 'tight price action supported by high volume' is sound, the current implementations failed to outperform the SOTA result. The IC (0.0031 vs 0.0058) and Information Ratio (0.36 vs 0.97) show significant deterioration, suggesting that the current linear combinations or window sizes may not be capturing the signal effectively, or the interaction between volume and range is more non-linear than modeled.",
        "hypothesis_evaluation": "The hypothesis that low price range scaled by volume intensity identifies high-quality breakouts is partially supported by the positive IC, but the performance is weak. The 'Institutional_Tightness_Rank_10D' and 'ABS' factors use volume as a numerator, which is more intuitive for 'intensity', whereas the first factor used it as a denominator. The results suggest that while the 'tightness' concept is valid, the current 5-day and 10-day windows might be too short to distinguish between true institutional accumulation and simple low-volatility consolidation.",
        "decision": false,
        "reason": "The current factors compare volume/range cross-sectionally or via simple means. However, institutional accumulation is a process. By measuring the change in volume-per-unit-of-range relative to a longer-term baseline (e.g., 20 days), we can isolate 'unusual' accumulation. Furthermore, using the high-low range can be noisy; using the standard deviation of returns as a denominator for volume might provide a more robust measure of 'price effort' versus 'result'."
      }
    },
    "9165d63ff7dc3e94": {
      "factor_id": "9165d63ff7dc3e94",
      "factor_name": "Accumulation_Breakout_Signal_5D",
      "factor_expression": "ZSCORE($volume / ($high - $low + 1e-8)) * SIGN(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE($volume / ($high - $low + 1e-8)) * SIGN(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Breakout_Signal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A directional factor that targets stocks with low price-spread-to-volume ratios during positive momentum periods. It uses Z-score normalization to compare the 'tightness' of the price action across the market universe.",
      "factor_formulation": "ABS = \\text{ZSCORE}(\\frac{volume}{high - low + 1e-8}) \\times \\text{SIGN}(\\text{TS_PCTCHANGE}(close, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "326a1ca00c43",
        "parent_trajectory_ids": [
          "49a2f9ab207c"
        ],
        "hypothesis": "Hypothesis: The Institutional Accumulation Divergence (IAD) factor, defined as the 5-day average of the daily price range scaled by volume intensity, identifies high-quality trend breakouts where price expansion is supported by concentrated liquidity rather than speculative volatility.\n                Concise Observation: While the previous mean-reversion strategy focused on price exhaustion (residuals), market leaders often exhibit 'tight' price action on high relative volume before a major move, suggesting that the quality of volume flow is more predictive of trend than simple price deviation.\n                Concise Justification: Institutional buyers typically use execution algorithms to minimize market impact, leading to consistent volume absorption within a controlled price range; identifying this 'tightness' during upward moves separates structural accumulation from retail-driven spikes.\n                Concise Knowledge: If price appreciation occurs with a narrowing high-low range relative to volume, it indicates institutional absorption; when this 'quiet' strength persists, it signals a sustainable trend breakout rather than a mean-reversion event.\n                concise Specification: The factor will be calculated as the 5-day moving average of the ratio between the daily ($high - $low) and the $volume, further adjusted by the 5-day price momentum to ensure directionality, targeting stocks with low price-spread-to-volume ratios during uptrends.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-20T22:38:45.908099"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2189121422977219,
        "ICIR": 0.0219773787314308,
        "1day.excess_return_without_cost.std": 0.0047453747787826,
        "1day.excess_return_with_cost.annualized_return": -0.0209823114488982,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001127653537303,
        "1day.excess_return_without_cost.annualized_return": 0.0268381541878148,
        "1day.excess_return_with_cost.std": 0.0047471393309509,
        "Rank IC": 0.0181348695256892,
        "IC": 0.003121380896564,
        "1day.excess_return_without_cost.max_drawdown": -0.1591555184006667,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3666010017921421,
        "1day.pa": 0.0,
        "l2.valid": 0.995934526136782,
        "Rank ICIR": 0.1291475332882413,
        "l2.train": 0.9932001568986438,
        "1day.excess_return_with_cost.information_ratio": -0.2865054396282625,
        "1day.excess_return_with_cost.mean": -8.816097247436236e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the Institutional Accumulation Divergence (IAD) hypothesis: a momentum-weighted range/volume ratio, a cross-sectional rank of volume intensity relative to price spread, and a Z-scored breakout signal. While the theoretical framework of 'tight price action supported by high volume' is sound, the current implementations failed to outperform the SOTA result. The IC (0.0031 vs 0.0058) and Information Ratio (0.36 vs 0.97) show significant deterioration, suggesting that the current linear combinations or window sizes may not be capturing the signal effectively, or the interaction between volume and range is more non-linear than modeled.",
        "hypothesis_evaluation": "The hypothesis that low price range scaled by volume intensity identifies high-quality breakouts is partially supported by the positive IC, but the performance is weak. The 'Institutional_Tightness_Rank_10D' and 'ABS' factors use volume as a numerator, which is more intuitive for 'intensity', whereas the first factor used it as a denominator. The results suggest that while the 'tightness' concept is valid, the current 5-day and 10-day windows might be too short to distinguish between true institutional accumulation and simple low-volatility consolidation.",
        "decision": false,
        "reason": "The current factors compare volume/range cross-sectionally or via simple means. However, institutional accumulation is a process. By measuring the change in volume-per-unit-of-range relative to a longer-term baseline (e.g., 20 days), we can isolate 'unusual' accumulation. Furthermore, using the high-low range can be noisy; using the standard deviation of returns as a denominator for volume might provide a more robust measure of 'price effort' versus 'result'."
      }
    },
    "99bc44464185ef60": {
      "factor_id": "99bc44464185ef60",
      "factor_name": "Skew_Range_Efficiency_10D",
      "factor_expression": "RANK(TS_ZSCORE($return, 10) / (TS_MEAN(($high - $low) / ($close + 1e-8), 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SKEW(TS_PCTCHANGE($close, 1), 10) / (TS_MEAN(($high - $low) / $close, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Skew_Range_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the ratio of return skewness to the intraday price range over a 10-day period. High values indicate 'quiet' institutional accumulation where returns are positively skewed despite low price volatility (narrow high-low spreads), suggesting a more sustainable trend than high-volatility spikes.",
      "factor_formulation": "SRE_{10D} = \\text{RANK}\\left(\\frac{\\text{TS\\_SKEW}(\\text{return}, 10)}{\\text{TS\\_MEAN}((\\text{high} - \\text{low})/\\text{close}, 10) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "edd1bb0ae704",
        "parent_trajectory_ids": [
          "66ba76e16251"
        ],
        "hypothesis": "Hypothesis: The 10-day skewness of daily returns, when conditioned on low relative price range (High-Low), identifies subtle institutional accumulation or distribution that predicts persistent price trends better than volatility-based exhaustion signals.\n                Concise Observation: The parent strategy successfully captured mean reversion from high-volatility range spikes, but it missed 'quiet' trends where price movement is steady and distribution is skewed without expanding the daily high-low spread.\n                Concise Justification: Positive skewness in a low-volatility environment suggests that positive returns are more frequent or larger than negative ones without triggering the liquidity-exhaustion 'alarms' of high intraday ranges, signaling a sustainable shift in ownership.\n                Concise Knowledge: If a stock exhibits high return skewness while maintaining a narrow price range, it indicates asymmetric information flow; when this occurs during low-volatility regimes, the subsequent trend is more likely to persist as it reflects informed positioning rather than retail noise.\n                concise Specification: The factor will be calculated as the 10-day rolling skewness of daily returns, filtered or weighted by the inverse of the 10-day average price range, focusing on instruments where the ratio of skewness to range-volatility is maximized.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T23:12:41.972466"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0874129440562467,
        "ICIR": 0.0290913607937735,
        "1day.excess_return_without_cost.std": 0.0039016053113848,
        "1day.excess_return_with_cost.annualized_return": 0.0219342107822256,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002902820878097,
        "1day.excess_return_without_cost.annualized_return": 0.0690871368987291,
        "1day.excess_return_with_cost.std": 0.0039033270014748,
        "Rank IC": 0.0193179919955626,
        "IC": 0.0039084679916787,
        "1day.excess_return_without_cost.max_drawdown": -0.0731180590723304,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1477977861225248,
        "1day.pa": 0.0,
        "l2.valid": 0.9964646569265622,
        "Rank ICIR": 0.147124612025584,
        "l2.train": 0.9941503831086448,
        "1day.excess_return_with_cost.information_ratio": 0.3642491929793411,
        "1day.excess_return_with_cost.mean": 9.21605495051499e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the interaction between return skewness and intraday price ranges (High-Low) over a 10-day window. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 6.9%). However, the IC (Information Coefficient) dropped from 0.0058 to 0.0039, and the Max Drawdown slightly worsened. This suggests that while the current factors are better at capturing high-conviction tail events or specific regimes (leading to better IR and returns), they may have lower overall predictive consistency across the entire cross-section compared to the SOTA.",
        "hypothesis_evaluation": "The results partially support the hypothesis. The improvement in Annualized Return and Information Ratio suggests that conditioning skewness on low relative price ranges (as seen in SRE_10D and LVSP) successfully filters for higher-quality signals, likely institutional accumulation. The 'Asymmetric_Accumulation_Index' (AAI) specifically targeted the difference between mean and median (a proxy for skewness) relative to range, which appears to have enhanced the return profile. The lower IC indicates that this signal is more niche/regime-specific rather than a broad market predictor.",
        "decision": true,
        "reason": "The current factors used a static 10-day window for both skewness and range. Institutional accumulation often happens over longer cycles, but the 'quietness' (low range) is a tactical state. By using a 20-day window for skewness (to capture the trend bias) and a shorter 5-day window for the range filter, we can better identify the specific moment an instrument transitions from a 'quiet accumulation' phase to a 'trending' phase. Additionally, using TS_RANK for the range component (as in LVSP) proved effective and should be integrated into the primary SRE formulation to improve robustness against cross-sectional scale differences."
      }
    },
    "265b0a348792a4d4": {
      "factor_id": "265b0a348792a4d4",
      "factor_name": "Low_Volatility_Skew_Persistence",
      "factor_expression": "TS_ZSCORE($return, 10) * (1.0 - TS_RANK($high - $low, 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_PCTCHANGE($close, 1), 10)) * (1.0 - TS_RANK(($high - $low) / $close, 10))\" # Your output factor expression will be filled in here\n    name = \"Low_Volatility_Skew_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies instruments with positive return skewness specifically during periods of low relative range. It uses a conditional approach to amplify the signal of asymmetric information flow in low-volatility regimes, avoiding retail noise associated with large price swings.",
      "factor_formulation": "LVSP = \\text{TS\\_ZSCORE}(\\text{return}, 10) * (1 - \\text{TS\\_RANK}(\\text{high} - \\text{low}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "edd1bb0ae704",
        "parent_trajectory_ids": [
          "66ba76e16251"
        ],
        "hypothesis": "Hypothesis: The 10-day skewness of daily returns, when conditioned on low relative price range (High-Low), identifies subtle institutional accumulation or distribution that predicts persistent price trends better than volatility-based exhaustion signals.\n                Concise Observation: The parent strategy successfully captured mean reversion from high-volatility range spikes, but it missed 'quiet' trends where price movement is steady and distribution is skewed without expanding the daily high-low spread.\n                Concise Justification: Positive skewness in a low-volatility environment suggests that positive returns are more frequent or larger than negative ones without triggering the liquidity-exhaustion 'alarms' of high intraday ranges, signaling a sustainable shift in ownership.\n                Concise Knowledge: If a stock exhibits high return skewness while maintaining a narrow price range, it indicates asymmetric information flow; when this occurs during low-volatility regimes, the subsequent trend is more likely to persist as it reflects informed positioning rather than retail noise.\n                concise Specification: The factor will be calculated as the 10-day rolling skewness of daily returns, filtered or weighted by the inverse of the 10-day average price range, focusing on instruments where the ratio of skewness to range-volatility is maximized.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T23:12:41.972466"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0874129440562467,
        "ICIR": 0.0290913607937735,
        "1day.excess_return_without_cost.std": 0.0039016053113848,
        "1day.excess_return_with_cost.annualized_return": 0.0219342107822256,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002902820878097,
        "1day.excess_return_without_cost.annualized_return": 0.0690871368987291,
        "1day.excess_return_with_cost.std": 0.0039033270014748,
        "Rank IC": 0.0193179919955626,
        "IC": 0.0039084679916787,
        "1day.excess_return_without_cost.max_drawdown": -0.0731180590723304,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1477977861225248,
        "1day.pa": 0.0,
        "l2.valid": 0.9964646569265622,
        "Rank ICIR": 0.147124612025584,
        "l2.train": 0.9941503831086448,
        "1day.excess_return_with_cost.information_ratio": 0.3642491929793411,
        "1day.excess_return_with_cost.mean": 9.21605495051499e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the interaction between return skewness and intraday price ranges (High-Low) over a 10-day window. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 6.9%). However, the IC (Information Coefficient) dropped from 0.0058 to 0.0039, and the Max Drawdown slightly worsened. This suggests that while the current factors are better at capturing high-conviction tail events or specific regimes (leading to better IR and returns), they may have lower overall predictive consistency across the entire cross-section compared to the SOTA.",
        "hypothesis_evaluation": "The results partially support the hypothesis. The improvement in Annualized Return and Information Ratio suggests that conditioning skewness on low relative price ranges (as seen in SRE_10D and LVSP) successfully filters for higher-quality signals, likely institutional accumulation. The 'Asymmetric_Accumulation_Index' (AAI) specifically targeted the difference between mean and median (a proxy for skewness) relative to range, which appears to have enhanced the return profile. The lower IC indicates that this signal is more niche/regime-specific rather than a broad market predictor.",
        "decision": true,
        "reason": "The current factors used a static 10-day window for both skewness and range. Institutional accumulation often happens over longer cycles, but the 'quietness' (low range) is a tactical state. By using a 20-day window for skewness (to capture the trend bias) and a shorter 5-day window for the range filter, we can better identify the specific moment an instrument transitions from a 'quiet accumulation' phase to a 'trending' phase. Additionally, using TS_RANK for the range component (as in LVSP) proved effective and should be integrated into the primary SRE formulation to improve robustness against cross-sectional scale differences."
      }
    },
    "e7b9737865c78f8e": {
      "factor_id": "e7b9737865c78f8e",
      "factor_name": "Asymmetric_Accumulation_Index",
      "factor_expression": "RANK((TS_MEAN($return, 10) - TS_MEDIAN($return, 10)) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MEAN(TS_PCTCHANGE($close, 1), 10) - TS_MEDIAN(TS_PCTCHANGE($close, 1), 10)) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Accumulation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the intensity of positive return outliers relative to the average daily trading range. By focusing on the 10-day period, it highlights stocks where the distribution of returns is 'right-tailed' while the physical price movement (High-Low) remains constrained.",
      "factor_formulation": "AAI = \\frac{\\text{TS\\_MEAN}(\\text{return}, 10) - \\text{TS\\_MEDIAN}(\\text{return}, 10)}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 10) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "edd1bb0ae704",
        "parent_trajectory_ids": [
          "66ba76e16251"
        ],
        "hypothesis": "Hypothesis: The 10-day skewness of daily returns, when conditioned on low relative price range (High-Low), identifies subtle institutional accumulation or distribution that predicts persistent price trends better than volatility-based exhaustion signals.\n                Concise Observation: The parent strategy successfully captured mean reversion from high-volatility range spikes, but it missed 'quiet' trends where price movement is steady and distribution is skewed without expanding the daily high-low spread.\n                Concise Justification: Positive skewness in a low-volatility environment suggests that positive returns are more frequent or larger than negative ones without triggering the liquidity-exhaustion 'alarms' of high intraday ranges, signaling a sustainable shift in ownership.\n                Concise Knowledge: If a stock exhibits high return skewness while maintaining a narrow price range, it indicates asymmetric information flow; when this occurs during low-volatility regimes, the subsequent trend is more likely to persist as it reflects informed positioning rather than retail noise.\n                concise Specification: The factor will be calculated as the 10-day rolling skewness of daily returns, filtered or weighted by the inverse of the 10-day average price range, focusing on instruments where the ratio of skewness to range-volatility is maximized.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-20T23:12:41.972466"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0874129440562467,
        "ICIR": 0.0290913607937735,
        "1day.excess_return_without_cost.std": 0.0039016053113848,
        "1day.excess_return_with_cost.annualized_return": 0.0219342107822256,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002902820878097,
        "1day.excess_return_without_cost.annualized_return": 0.0690871368987291,
        "1day.excess_return_with_cost.std": 0.0039033270014748,
        "Rank IC": 0.0193179919955626,
        "IC": 0.0039084679916787,
        "1day.excess_return_without_cost.max_drawdown": -0.0731180590723304,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1477977861225248,
        "1day.pa": 0.0,
        "l2.valid": 0.9964646569265622,
        "Rank ICIR": 0.147124612025584,
        "l2.train": 0.9941503831086448,
        "1day.excess_return_with_cost.information_ratio": 0.3642491929793411,
        "1day.excess_return_with_cost.mean": 9.21605495051499e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the interaction between return skewness and intraday price ranges (High-Low) over a 10-day window. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 6.9%). However, the IC (Information Coefficient) dropped from 0.0058 to 0.0039, and the Max Drawdown slightly worsened. This suggests that while the current factors are better at capturing high-conviction tail events or specific regimes (leading to better IR and returns), they may have lower overall predictive consistency across the entire cross-section compared to the SOTA.",
        "hypothesis_evaluation": "The results partially support the hypothesis. The improvement in Annualized Return and Information Ratio suggests that conditioning skewness on low relative price ranges (as seen in SRE_10D and LVSP) successfully filters for higher-quality signals, likely institutional accumulation. The 'Asymmetric_Accumulation_Index' (AAI) specifically targeted the difference between mean and median (a proxy for skewness) relative to range, which appears to have enhanced the return profile. The lower IC indicates that this signal is more niche/regime-specific rather than a broad market predictor.",
        "decision": true,
        "reason": "The current factors used a static 10-day window for both skewness and range. Institutional accumulation often happens over longer cycles, but the 'quietness' (low range) is a tactical state. By using a 20-day window for skewness (to capture the trend bias) and a shorter 5-day window for the range filter, we can better identify the specific moment an instrument transitions from a 'quiet accumulation' phase to a 'trending' phase. Additionally, using TS_RANK for the range component (as in LVSP) proved effective and should be integrated into the primary SRE formulation to improve robustness against cross-sectional scale differences."
      }
    },
    "b685535a818cb4cf": {
      "factor_id": "b685535a818cb4cf",
      "factor_name": "Liquidity_Vacuum_Reversal_3D",
      "factor_expression": "TS_ZSCORE(ABS(TS_PCTCHANGE($close, 3)) / (TS_MEAN($volume, 3) + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS(TS_PCTCHANGE($close, 3)) / (TS_MEAN($volume, 3) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Reversal_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies price movements that lack volume support by calculating the ratio of the 3-day absolute price change to the 3-day average volume. High values indicate a 'liquidity vacuum' where price is overextended on thin volume, signaling a high probability of mean-reversion. The result is standardized over a 20-day window to identify statistical outliers.",
      "factor_formulation": "\\text{TS\\_ZSCORE}\\left(\\frac{\\text{ABS}(\\text{TS\\_PCTCHANGE}(\\text{close}, 3))}{\\text{TS\\_MEAN}(\\text{volume}, 3) + 1e-8}, 20\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "821d81e78731",
        "parent_trajectory_ids": [
          "432771960cc4"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Vacuum Reversal' factor, defined as the ratio of the 3-day absolute price velocity to the 3-day average volume (Amihud Illiquidity proxy), predicts a price mean-reversion when extreme price movements occur on thinning volume.\n                Concise Observation: While the parent strategy found success in smooth, low-volatility accumulation, we observe that sharp price spikes often coincide with declining volume, suggesting a lack of structural support and high fragility in the current price level.\n                Concise Justification: The Amihud Illiquidity ratio (Return/Volume) measures the price impact of trades; when this ratio reaches a local extreme, it indicates that price is moving too far on too little capital, signaling an overextended state that lacks the 'institutional absorption' seen in the parent strategy.\n                Concise Knowledge: If a price trend accelerates while volume-weighted liquidity (elasticity) decreases, the move is likely driven by a 'liquidity hole' rather than fundamental conviction; such moves are prone to immediate reversal as market makers return to fill the gap.\n                concise Specification: The factor targets a short-term (3-day) window to capture 'brittle' spikes. It is calculated as the 3-day absolute return divided by the 3-day mean volume, then z-scored over 20 days to identify statistical outliers in liquidity exhaustion.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T23:16:12.208789"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1843801546166575,
        "ICIR": 0.0334464425036016,
        "1day.excess_return_without_cost.std": 0.0043751202386007,
        "1day.excess_return_with_cost.annualized_return": -0.020325803321454,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001130608942307,
        "1day.excess_return_without_cost.annualized_return": 0.0269084928269297,
        "1day.excess_return_with_cost.std": 0.0043750038033008,
        "Rank IC": 0.021189607915999,
        "IC": 0.0047209678718401,
        "1day.excess_return_without_cost.max_drawdown": -0.1253913098428446,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3986675632752613,
        "1day.pa": 0.0,
        "l2.valid": 0.9965000496349992,
        "Rank ICIR": 0.1585418101995151,
        "l2.train": 0.993261203422438,
        "1day.excess_return_with_cost.information_ratio": -0.3011485701387305,
        "1day.excess_return_with_cost.mean": -8.540253496409267e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Vacuum Reversal' hypothesis: a 3-day price velocity ratio (Liquidity_Vacuum_Reversal_3D), a daily brittle spike proxy (Brittle_Price_Spike_Proxy), and a 3-day Amihud exhaustion Z-score (Amihud_Exhaustion_ZScore). While the factors successfully generated positive IC (0.0047) and positive annualized returns (2.69%), they significantly underperformed the current SOTA result across all key metrics. Specifically, the Information Ratio (0.398 vs 0.972) and Max Drawdown (-0.125 vs -0.072) indicate that the current implementation of the liquidity vacuum concept is much noisier and riskier than the existing SOTA benchmarks.",
        "hypothesis_evaluation": "The results provide weak support for the hypothesis. While the positive IC suggests that price movements on thin volume do contain some predictive power for mean reversion, the high drawdown and low IR suggest that the current 'ratio' approach is sensitive to outliers or perhaps fails to distinguish between a 'vacuum' and a genuine trend breakout. The 3-day window might be catching too much noise, or the simple division by volume is creating extreme values that degrade the signal's stability.",
        "decision": false,
        "reason": "The current factors use a simple Z-score of the ratio, which can be skewed by a single day of extremely low volume. By incorporating the volatility of the price-impact ratio (using a coefficient of variation or a double-window volatility adjustment), we can filter out 'fake' vacuums. Furthermore, the current models use a 3-day window which might be too short to establish a 'vacuum' state; extending the lookback to 5 or 10 days while normalizing by the standard deviation of the ratio should provide a more robust statistical signal and reduce the drawdown observed in the current results."
      }
    },
    "ff15f67e90da5a05": {
      "factor_id": "ff15f67e90da5a05",
      "factor_name": "Brittle_Price_Spike_Proxy",
      "factor_expression": "RANK(ABS($return) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(TS_PCTCHANGE($close, 1)) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Brittle_Price_Spike_Proxy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the liquidity exhaustion hypothesis that focuses on the daily return relative to the recent volume trend. It captures 'brittle' spikes by dividing the absolute daily return by the 5-day average volume, then applying a cross-sectional rank to identify the most fragile price movements across the universe.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{ABS}(\\text{return})}{\\text{TS\\_MEAN}(\\text{volume}, 5) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "821d81e78731",
        "parent_trajectory_ids": [
          "432771960cc4"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Vacuum Reversal' factor, defined as the ratio of the 3-day absolute price velocity to the 3-day average volume (Amihud Illiquidity proxy), predicts a price mean-reversion when extreme price movements occur on thinning volume.\n                Concise Observation: While the parent strategy found success in smooth, low-volatility accumulation, we observe that sharp price spikes often coincide with declining volume, suggesting a lack of structural support and high fragility in the current price level.\n                Concise Justification: The Amihud Illiquidity ratio (Return/Volume) measures the price impact of trades; when this ratio reaches a local extreme, it indicates that price is moving too far on too little capital, signaling an overextended state that lacks the 'institutional absorption' seen in the parent strategy.\n                Concise Knowledge: If a price trend accelerates while volume-weighted liquidity (elasticity) decreases, the move is likely driven by a 'liquidity hole' rather than fundamental conviction; such moves are prone to immediate reversal as market makers return to fill the gap.\n                concise Specification: The factor targets a short-term (3-day) window to capture 'brittle' spikes. It is calculated as the 3-day absolute return divided by the 3-day mean volume, then z-scored over 20 days to identify statistical outliers in liquidity exhaustion.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T23:16:12.208789"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1843801546166575,
        "ICIR": 0.0334464425036016,
        "1day.excess_return_without_cost.std": 0.0043751202386007,
        "1day.excess_return_with_cost.annualized_return": -0.020325803321454,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001130608942307,
        "1day.excess_return_without_cost.annualized_return": 0.0269084928269297,
        "1day.excess_return_with_cost.std": 0.0043750038033008,
        "Rank IC": 0.021189607915999,
        "IC": 0.0047209678718401,
        "1day.excess_return_without_cost.max_drawdown": -0.1253913098428446,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3986675632752613,
        "1day.pa": 0.0,
        "l2.valid": 0.9965000496349992,
        "Rank ICIR": 0.1585418101995151,
        "l2.train": 0.993261203422438,
        "1day.excess_return_with_cost.information_ratio": -0.3011485701387305,
        "1day.excess_return_with_cost.mean": -8.540253496409267e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Vacuum Reversal' hypothesis: a 3-day price velocity ratio (Liquidity_Vacuum_Reversal_3D), a daily brittle spike proxy (Brittle_Price_Spike_Proxy), and a 3-day Amihud exhaustion Z-score (Amihud_Exhaustion_ZScore). While the factors successfully generated positive IC (0.0047) and positive annualized returns (2.69%), they significantly underperformed the current SOTA result across all key metrics. Specifically, the Information Ratio (0.398 vs 0.972) and Max Drawdown (-0.125 vs -0.072) indicate that the current implementation of the liquidity vacuum concept is much noisier and riskier than the existing SOTA benchmarks.",
        "hypothesis_evaluation": "The results provide weak support for the hypothesis. While the positive IC suggests that price movements on thin volume do contain some predictive power for mean reversion, the high drawdown and low IR suggest that the current 'ratio' approach is sensitive to outliers or perhaps fails to distinguish between a 'vacuum' and a genuine trend breakout. The 3-day window might be catching too much noise, or the simple division by volume is creating extreme values that degrade the signal's stability.",
        "decision": false,
        "reason": "The current factors use a simple Z-score of the ratio, which can be skewed by a single day of extremely low volume. By incorporating the volatility of the price-impact ratio (using a coefficient of variation or a double-window volatility adjustment), we can filter out 'fake' vacuums. Furthermore, the current models use a 3-day window which might be too short to establish a 'vacuum' state; extending the lookback to 5 or 10 days while normalizing by the standard deviation of the ratio should provide a more robust statistical signal and reduce the drawdown observed in the current results."
      }
    },
    "01ec39baacfc7717": {
      "factor_id": "01ec39baacfc7717",
      "factor_name": "Amihud_Exhaustion_ZScore",
      "factor_expression": "TS_ZSCORE(TS_SUM(ABS($return), 3) / (TS_SUM($volume, 3) + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_SUM(ABS($close / DELAY($close, 1) - 1), 3) / (TS_SUM($volume, 3) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Amihud_Exhaustion_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the intensity of price impact per unit of volume over a 3-day window. It uses the sum of absolute returns divided by the sum of volume to proxy illiquidity. A high Z-score over 20 days suggests that the current price trend is exhausting its liquidity support and is likely to reverse.",
      "factor_formulation": "\\text{TS\\_ZSCORE}\\left(\\frac{\\text{TS\\_SUM}(\\text{ABS}(\\text{return}), 3)}{\\text{TS\\_SUM}(\\text{volume}, 3) + 1e-8}, 20\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "821d81e78731",
        "parent_trajectory_ids": [
          "432771960cc4"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Vacuum Reversal' factor, defined as the ratio of the 3-day absolute price velocity to the 3-day average volume (Amihud Illiquidity proxy), predicts a price mean-reversion when extreme price movements occur on thinning volume.\n                Concise Observation: While the parent strategy found success in smooth, low-volatility accumulation, we observe that sharp price spikes often coincide with declining volume, suggesting a lack of structural support and high fragility in the current price level.\n                Concise Justification: The Amihud Illiquidity ratio (Return/Volume) measures the price impact of trades; when this ratio reaches a local extreme, it indicates that price is moving too far on too little capital, signaling an overextended state that lacks the 'institutional absorption' seen in the parent strategy.\n                Concise Knowledge: If a price trend accelerates while volume-weighted liquidity (elasticity) decreases, the move is likely driven by a 'liquidity hole' rather than fundamental conviction; such moves are prone to immediate reversal as market makers return to fill the gap.\n                concise Specification: The factor targets a short-term (3-day) window to capture 'brittle' spikes. It is calculated as the 3-day absolute return divided by the 3-day mean volume, then z-scored over 20 days to identify statistical outliers in liquidity exhaustion.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-20T23:16:12.208789"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1843801546166575,
        "ICIR": 0.0334464425036016,
        "1day.excess_return_without_cost.std": 0.0043751202386007,
        "1day.excess_return_with_cost.annualized_return": -0.020325803321454,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001130608942307,
        "1day.excess_return_without_cost.annualized_return": 0.0269084928269297,
        "1day.excess_return_with_cost.std": 0.0043750038033008,
        "Rank IC": 0.021189607915999,
        "IC": 0.0047209678718401,
        "1day.excess_return_without_cost.max_drawdown": -0.1253913098428446,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3986675632752613,
        "1day.pa": 0.0,
        "l2.valid": 0.9965000496349992,
        "Rank ICIR": 0.1585418101995151,
        "l2.train": 0.993261203422438,
        "1day.excess_return_with_cost.information_ratio": -0.3011485701387305,
        "1day.excess_return_with_cost.mean": -8.540253496409267e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Vacuum Reversal' hypothesis: a 3-day price velocity ratio (Liquidity_Vacuum_Reversal_3D), a daily brittle spike proxy (Brittle_Price_Spike_Proxy), and a 3-day Amihud exhaustion Z-score (Amihud_Exhaustion_ZScore). While the factors successfully generated positive IC (0.0047) and positive annualized returns (2.69%), they significantly underperformed the current SOTA result across all key metrics. Specifically, the Information Ratio (0.398 vs 0.972) and Max Drawdown (-0.125 vs -0.072) indicate that the current implementation of the liquidity vacuum concept is much noisier and riskier than the existing SOTA benchmarks.",
        "hypothesis_evaluation": "The results provide weak support for the hypothesis. While the positive IC suggests that price movements on thin volume do contain some predictive power for mean reversion, the high drawdown and low IR suggest that the current 'ratio' approach is sensitive to outliers or perhaps fails to distinguish between a 'vacuum' and a genuine trend breakout. The 3-day window might be catching too much noise, or the simple division by volume is creating extreme values that degrade the signal's stability.",
        "decision": false,
        "reason": "The current factors use a simple Z-score of the ratio, which can be skewed by a single day of extremely low volume. By incorporating the volatility of the price-impact ratio (using a coefficient of variation or a double-window volatility adjustment), we can filter out 'fake' vacuums. Furthermore, the current models use a 3-day window which might be too short to establish a 'vacuum' state; extending the lookback to 5 or 10 days while normalizing by the standard deviation of the ratio should provide a more robust statistical signal and reduce the drawdown observed in the current results."
      }
    },
    "70e1dd0b800de0ab": {
      "factor_id": "70e1dd0b800de0ab",
      "factor_name": "Overnight_Sentiment_Persistence_5D",
      "factor_expression": "($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / DELAY($close, 1) - 1) / (TS_MEAN($high - $low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Sentiment_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor calculates the ratio of the overnight return to the average daily price range over the last 5 days. It identifies stocks where the opening gap is significant relative to recent volatility, suggesting that overnight information is the primary driver of price action and likely to persist.",
      "factor_formulation": "OSP_{5D} = \\frac{(open_t / close_{t-1}) - 1}{TS\\_MEAN(high_t - low_t, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "391003c8211b",
        "parent_trajectory_ids": [
          "836034d98a7a"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Persistence' factor, defined as the ratio of the overnight price gap to the daily price range, predicts short-term returns because moderate overnight gaps followed by low intraday volatility indicate institutional absorption of sentiment-driven information.\n                Concise Observation: The parent strategy focused on long-term mean reversion from extreme lows, but failed to capture short-term momentum shifts occurring at the market open where overnight information first impacts price discovery.\n                Concise Justification: Overnight gaps represent the accumulation of information while the market is closed; a high ratio of this gap relative to the total high-low range suggests that the opening sentiment dominated the day's price action, signaling a strong conviction that likely persists into the next trading session.\n                Concise Knowledge: If a stock opens with a gap that is small relative to its typical daily volatility, it suggests sustainable sentiment; when this gap is coupled with low intraday price dispersion, it indicates that the overnight information is being systematically integrated into the price rather than being rejected by volatility.\n                concise Specification: The factor is calculated as the overnight return (Open_t / Close_{t-1} - 1) divided by the 5-day moving average of the daily range (High - Low) to normalize for volatility, focusing on the persistence of the 'Opening Drive' over a T+1 horizon.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T23:19:04.404534"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1063373167514521,
        "ICIR": 0.0530038566796628,
        "1day.excess_return_without_cost.std": 0.0041211109342706,
        "1day.excess_return_with_cost.annualized_return": 0.0087939864620408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002357856319718,
        "1day.excess_return_without_cost.annualized_return": 0.0561169804093084,
        "1day.excess_return_with_cost.std": 0.0041204558034761,
        "Rank IC": 0.0260288324953588,
        "IC": 0.0070544291446842,
        "1day.excess_return_without_cost.max_drawdown": -0.0968841670226008,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8826560661914168,
        "1day.pa": 0.0,
        "l2.valid": 0.9963849562548254,
        "Rank ICIR": 0.1976868184220868,
        "l2.train": 0.9938662286612204,
        "1day.excess_return_with_cost.information_ratio": 0.1383413641945455,
        "1day.excess_return_with_cost.mean": 3.694952294975131e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Persistence' hypothesis by testing three variations: a 5-day moving average normalization (OSP_5D), a cross-sectional rank of daily efficiency (NODE), and a relative volatility adjustment (LVGP). The combined results show a significant improvement in Information Coefficient (IC) from 0.005798 to 0.007054 and an increase in Annualized Return from 0.052010 to 0.056117. However, the Information Ratio (IR) decreased slightly and the Max Drawdown worsened, suggesting that while the signal strength (IC) has increased, the volatility of the factor's performance has also risen.",
        "hypothesis_evaluation": "The results generally support the hypothesis that the ratio of overnight gaps to intraday volatility contains predictive power. The increase in IC suggests that the 'institutional absorption' concept (where low intraday volatility following a gap signals persistence) is a valid alpha source. The 'Low_Volatility_Gap_Persistence' (LVGP) implementation, which specifically scales the gap by the inverse of relative intraday range, likely contributed most to the IC improvement by isolating 'quiet' price discovery phases.",
        "decision": true,
        "reason": "While the current factors capture the 'efficiency' of the gap, they do not account for the context of the gap. A gap that continues a 20-day trend is more likely to represent institutional accumulation, whereas an exhausting gap at the end of a trend might lead to a reversal despite low intraday volatility. Integrating a trend filter (e.g., sign of the 20-day moving average) should improve the Information Ratio and reduce Drawdown by filtering out 'trap' gaps."
      }
    },
    "02e3ae3a61deea48": {
      "factor_id": "02e3ae3a61deea48",
      "factor_name": "Normalized_Opening_Drive_Efficiency",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Opening_Drive_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the efficiency of the opening sentiment by dividing the overnight gap by the current day's total range, cross-sectionally ranked to identify stocks where the gap represents a dominant portion of the day's volatility. High values indicate strong institutional absorption of overnight news.",
      "factor_formulation": "NODE = RANK(\\frac{open_t - close_{t-1}}{high_t - low_t + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "391003c8211b",
        "parent_trajectory_ids": [
          "836034d98a7a"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Persistence' factor, defined as the ratio of the overnight price gap to the daily price range, predicts short-term returns because moderate overnight gaps followed by low intraday volatility indicate institutional absorption of sentiment-driven information.\n                Concise Observation: The parent strategy focused on long-term mean reversion from extreme lows, but failed to capture short-term momentum shifts occurring at the market open where overnight information first impacts price discovery.\n                Concise Justification: Overnight gaps represent the accumulation of information while the market is closed; a high ratio of this gap relative to the total high-low range suggests that the opening sentiment dominated the day's price action, signaling a strong conviction that likely persists into the next trading session.\n                Concise Knowledge: If a stock opens with a gap that is small relative to its typical daily volatility, it suggests sustainable sentiment; when this gap is coupled with low intraday price dispersion, it indicates that the overnight information is being systematically integrated into the price rather than being rejected by volatility.\n                concise Specification: The factor is calculated as the overnight return (Open_t / Close_{t-1} - 1) divided by the 5-day moving average of the daily range (High - Low) to normalize for volatility, focusing on the persistence of the 'Opening Drive' over a T+1 horizon.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T23:19:04.404534"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1063373167514521,
        "ICIR": 0.0530038566796628,
        "1day.excess_return_without_cost.std": 0.0041211109342706,
        "1day.excess_return_with_cost.annualized_return": 0.0087939864620408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002357856319718,
        "1day.excess_return_without_cost.annualized_return": 0.0561169804093084,
        "1day.excess_return_with_cost.std": 0.0041204558034761,
        "Rank IC": 0.0260288324953588,
        "IC": 0.0070544291446842,
        "1day.excess_return_without_cost.max_drawdown": -0.0968841670226008,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8826560661914168,
        "1day.pa": 0.0,
        "l2.valid": 0.9963849562548254,
        "Rank ICIR": 0.1976868184220868,
        "l2.train": 0.9938662286612204,
        "1day.excess_return_with_cost.information_ratio": 0.1383413641945455,
        "1day.excess_return_with_cost.mean": 3.694952294975131e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Persistence' hypothesis by testing three variations: a 5-day moving average normalization (OSP_5D), a cross-sectional rank of daily efficiency (NODE), and a relative volatility adjustment (LVGP). The combined results show a significant improvement in Information Coefficient (IC) from 0.005798 to 0.007054 and an increase in Annualized Return from 0.052010 to 0.056117. However, the Information Ratio (IR) decreased slightly and the Max Drawdown worsened, suggesting that while the signal strength (IC) has increased, the volatility of the factor's performance has also risen.",
        "hypothesis_evaluation": "The results generally support the hypothesis that the ratio of overnight gaps to intraday volatility contains predictive power. The increase in IC suggests that the 'institutional absorption' concept (where low intraday volatility following a gap signals persistence) is a valid alpha source. The 'Low_Volatility_Gap_Persistence' (LVGP) implementation, which specifically scales the gap by the inverse of relative intraday range, likely contributed most to the IC improvement by isolating 'quiet' price discovery phases.",
        "decision": true,
        "reason": "While the current factors capture the 'efficiency' of the gap, they do not account for the context of the gap. A gap that continues a 20-day trend is more likely to represent institutional accumulation, whereas an exhausting gap at the end of a trend might lead to a reversal despite low intraday volatility. Integrating a trend filter (e.g., sign of the 20-day moving average) should improve the Information Ratio and reduce Drawdown by filtering out 'trap' gaps."
      }
    },
    "2e43bd6bbe11d39e": {
      "factor_id": "2e43bd6bbe11d39e",
      "factor_name": "Low_Volatility_Gap_Persistence",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * (TS_MEAN($high - $low, 10) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * (TS_MEAN($high - $low, 10) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Low_Volatility_Gap_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets the 'institutional absorption' hypothesis by multiplying the overnight return by the inverse of the intraday range relative to its 10-day average. It rewards stocks with a clear overnight direction and low subsequent intraday volatility.",
      "factor_formulation": "LVGP = \\frac{open_t - close_{t-1}}{close_{t-1}} * \\frac{TS\\_MEAN(high - low, 10)}{high_t - low_t + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "391003c8211b",
        "parent_trajectory_ids": [
          "836034d98a7a"
        ],
        "hypothesis": "Hypothesis: The 'Overnight Sentiment Persistence' factor, defined as the ratio of the overnight price gap to the daily price range, predicts short-term returns because moderate overnight gaps followed by low intraday volatility indicate institutional absorption of sentiment-driven information.\n                Concise Observation: The parent strategy focused on long-term mean reversion from extreme lows, but failed to capture short-term momentum shifts occurring at the market open where overnight information first impacts price discovery.\n                Concise Justification: Overnight gaps represent the accumulation of information while the market is closed; a high ratio of this gap relative to the total high-low range suggests that the opening sentiment dominated the day's price action, signaling a strong conviction that likely persists into the next trading session.\n                Concise Knowledge: If a stock opens with a gap that is small relative to its typical daily volatility, it suggests sustainable sentiment; when this gap is coupled with low intraday price dispersion, it indicates that the overnight information is being systematically integrated into the price rather than being rejected by volatility.\n                concise Specification: The factor is calculated as the overnight return (Open_t / Close_{t-1} - 1) divided by the 5-day moving average of the daily range (High - Low) to normalize for volatility, focusing on the persistence of the 'Opening Drive' over a T+1 horizon.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-20T23:19:04.404534"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1063373167514521,
        "ICIR": 0.0530038566796628,
        "1day.excess_return_without_cost.std": 0.0041211109342706,
        "1day.excess_return_with_cost.annualized_return": 0.0087939864620408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002357856319718,
        "1day.excess_return_without_cost.annualized_return": 0.0561169804093084,
        "1day.excess_return_with_cost.std": 0.0041204558034761,
        "Rank IC": 0.0260288324953588,
        "IC": 0.0070544291446842,
        "1day.excess_return_without_cost.max_drawdown": -0.0968841670226008,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8826560661914168,
        "1day.pa": 0.0,
        "l2.valid": 0.9963849562548254,
        "Rank ICIR": 0.1976868184220868,
        "l2.train": 0.9938662286612204,
        "1day.excess_return_with_cost.information_ratio": 0.1383413641945455,
        "1day.excess_return_with_cost.mean": 3.694952294975131e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Overnight Sentiment Persistence' hypothesis by testing three variations: a 5-day moving average normalization (OSP_5D), a cross-sectional rank of daily efficiency (NODE), and a relative volatility adjustment (LVGP). The combined results show a significant improvement in Information Coefficient (IC) from 0.005798 to 0.007054 and an increase in Annualized Return from 0.052010 to 0.056117. However, the Information Ratio (IR) decreased slightly and the Max Drawdown worsened, suggesting that while the signal strength (IC) has increased, the volatility of the factor's performance has also risen.",
        "hypothesis_evaluation": "The results generally support the hypothesis that the ratio of overnight gaps to intraday volatility contains predictive power. The increase in IC suggests that the 'institutional absorption' concept (where low intraday volatility following a gap signals persistence) is a valid alpha source. The 'Low_Volatility_Gap_Persistence' (LVGP) implementation, which specifically scales the gap by the inverse of relative intraday range, likely contributed most to the IC improvement by isolating 'quiet' price discovery phases.",
        "decision": true,
        "reason": "While the current factors capture the 'efficiency' of the gap, they do not account for the context of the gap. A gap that continues a 20-day trend is more likely to represent institutional accumulation, whereas an exhausting gap at the end of a trend might lead to a reversal despite low intraday volatility. Integrating a trend filter (e.g., sign of the 20-day moving average) should improve the Information Ratio and reduce Drawdown by filtering out 'trap' gaps."
      }
    },
    "e0be8288522d9b94": {
      "factor_id": "e0be8288522d9b94",
      "factor_name": "Liquidity_Absorption_Ratio_5D",
      "factor_expression": "TS_MEAN(TS_STD($return, 5) / (($high - $low) / ($close + 1e-8) + 1e-8) * SIGN($open - DELAY($close, 1)), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_STD(TS_PCTCHANGE($close, 1), 5) / (($high - $low) / ($close + 1e-8) + 1e-8) * SIGN($open - DELAY($close, 1)), 5)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Absorption_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional liquidity absorption by calculating the ratio of intraday return volatility to the daily high-low range, weighted by the direction of the overnight gap. High volatility within a narrow range suggests 'microstructure noise' and informed flow absorption. The factor uses a 5-day lookback to capture recent execution pressure.",
      "factor_formulation": "\\text{TS_MEAN}\\left(\\frac{\\text{TS_STD}(\\text{return}, 5)}{\\frac{\\text{high} - \\text{low}}{\\text{close}} + 1e-8} \\times \\text{SIGN}(\\text{open} - \\text{DELAY}(\\text{close}, 1)), 5\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "9d60c3a4557d",
        "parent_trajectory_ids": [
          "af51ae859843"
        ],
        "hypothesis": "Hypothesis: The ratio of intraday price volatility to the daily high-low range, when combined with the overnight return direction, identifies institutional liquidity absorption and predicts short-term price continuation.\n                Concise Observation: Daily price-volume models often miss the 'quality' of price movement; assets frequently show high intraday 'jitter' (noise) that doesn't expand the daily range, which often precedes a continuation of the primary trend rather than a reversal.\n                Concise Justification: Institutional traders often use VWAP or TWAP algorithms that create persistent intraday volatility without necessarily pushing the price to new extremes immediately; this 'microstructure noise' reflects informed flow being absorbed by market makers.\n                Concise Knowledge: If intraday variance is high relative to the daily range, it indicates high-frequency price discovery or institutional execution; when this occurs following a significant overnight gap, the market is likely absorbing order flow in the gap's direction, leading to momentum persistence.\n                concise Specification: The factor will be defined as the 5-day average of (Standard Deviation of Daily Returns / (High - Low Price Range)) multiplied by the sign of the overnight return (Open - Previous Close), focusing on the 5-day lookback window to capture recent execution pressure.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T23:22:41.877912"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1409981567493226,
        "ICIR": 0.0369586664123746,
        "1day.excess_return_without_cost.std": 0.0040056788757014,
        "1day.excess_return_with_cost.annualized_return": 0.002366972701385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002085186736092,
        "1day.excess_return_without_cost.annualized_return": 0.0496274443189999,
        "1day.excess_return_with_cost.std": 0.0040071944633818,
        "Rank IC": 0.0206685298510156,
        "IC": 0.0048566987125139,
        "1day.excess_return_without_cost.max_drawdown": -0.1105541971671168,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8030772110337956,
        "1day.pa": 0.0,
        "l2.valid": 0.9965480551334356,
        "Rank ICIR": 0.1621728600121771,
        "l2.train": 0.9940337228645996,
        "1day.excess_return_with_cost.information_ratio": 0.0382881472961824,
        "1day.excess_return_with_cost.mean": 9.94526345119754e-06
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Liquidity Absorption' hypothesis, focusing on the ratio of intraday volatility to price range weighted by overnight gaps. While the logic is sound, the current results (IC: 0.0048, IR: 0.803) underperform the SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Absorption_Ratio_5D' and 'Intraday_Jitter_Persistence_5D' both utilize nested rolling windows and complex ratios which might be introducing noise. The drawdown is also significantly higher (-0.11 vs -0.07), suggesting that the current formulation of 'informed flow absorption' may be capturing high-volatility regimes that are prone to reversals rather than clean continuations.",
        "hypothesis_evaluation": "The hypothesis that high intraday volatility relative to range indicates institutional absorption is partially supported by the positive IC, but the deterioration compared to SOTA suggests the 'SIGN(open - close_1)' filter might be too simplistic. The overnight gap direction alone may not sufficiently distinguish between 'exhaustion gaps' and 'breakaway gaps' when combined with intraday jitter.",
        "decision": false,
        "reason": "The current factors use 'SIGN(open - delay(close, 1))' which is a binary signal. Replacing this with a continuous measure of where the price 'settles' relative to its intraday range (e.g., (close - low)/(high - low)) provides a more granular view of whether the 'absorption' resulted in a successful price defense. Additionally, simplifying the expression by using a single lookback window for both volatility and range will reduce symbol complexity and potentially improve generalization."
      }
    },
    "19ff791db5cd2d77": {
      "factor_id": "19ff791db5cd2d77",
      "factor_name": "Intraday_Jitter_Persistence_5D",
      "factor_expression": "TS_MEAN(TS_STD($return, 5), 5) / (($high - $low) / ($open + 1e-8) + 1e-8) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_STD(TS_PCTCHANGE($close, 1), 5), 5) / (($high - $low) / ($open + 1e-8) + 1e-8) * SIGN($open / (DELAY($close, 1) + 1e-8) - 1)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Jitter_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the 'quality' of price movement by comparing intraday return standard deviation to the total daily price spread, adjusted for the overnight return direction. It targets assets where institutional algorithms (VWAP/TWAP) create high frequency discovery without immediate range expansion, signaling trend continuation.",
      "factor_formulation": "\\text{TS_MEAN}(\\text{TS_STD}(\\text{return}, 5), 5) / ((\\text{high} - \\text{low}) / \\text{open} + 1e-8) * \\text{SIGN}(\\text{open} / \\text{DELAY}(\\text{close}, 1) - 1)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "9d60c3a4557d",
        "parent_trajectory_ids": [
          "af51ae859843"
        ],
        "hypothesis": "Hypothesis: The ratio of intraday price volatility to the daily high-low range, when combined with the overnight return direction, identifies institutional liquidity absorption and predicts short-term price continuation.\n                Concise Observation: Daily price-volume models often miss the 'quality' of price movement; assets frequently show high intraday 'jitter' (noise) that doesn't expand the daily range, which often precedes a continuation of the primary trend rather than a reversal.\n                Concise Justification: Institutional traders often use VWAP or TWAP algorithms that create persistent intraday volatility without necessarily pushing the price to new extremes immediately; this 'microstructure noise' reflects informed flow being absorbed by market makers.\n                Concise Knowledge: If intraday variance is high relative to the daily range, it indicates high-frequency price discovery or institutional execution; when this occurs following a significant overnight gap, the market is likely absorbing order flow in the gap's direction, leading to momentum persistence.\n                concise Specification: The factor will be defined as the 5-day average of (Standard Deviation of Daily Returns / (High - Low Price Range)) multiplied by the sign of the overnight return (Open - Previous Close), focusing on the 5-day lookback window to capture recent execution pressure.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T23:22:41.877912"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1409981567493226,
        "ICIR": 0.0369586664123746,
        "1day.excess_return_without_cost.std": 0.0040056788757014,
        "1day.excess_return_with_cost.annualized_return": 0.002366972701385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002085186736092,
        "1day.excess_return_without_cost.annualized_return": 0.0496274443189999,
        "1day.excess_return_with_cost.std": 0.0040071944633818,
        "Rank IC": 0.0206685298510156,
        "IC": 0.0048566987125139,
        "1day.excess_return_without_cost.max_drawdown": -0.1105541971671168,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8030772110337956,
        "1day.pa": 0.0,
        "l2.valid": 0.9965480551334356,
        "Rank ICIR": 0.1621728600121771,
        "l2.train": 0.9940337228645996,
        "1day.excess_return_with_cost.information_ratio": 0.0382881472961824,
        "1day.excess_return_with_cost.mean": 9.94526345119754e-06
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Liquidity Absorption' hypothesis, focusing on the ratio of intraday volatility to price range weighted by overnight gaps. While the logic is sound, the current results (IC: 0.0048, IR: 0.803) underperform the SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Absorption_Ratio_5D' and 'Intraday_Jitter_Persistence_5D' both utilize nested rolling windows and complex ratios which might be introducing noise. The drawdown is also significantly higher (-0.11 vs -0.07), suggesting that the current formulation of 'informed flow absorption' may be capturing high-volatility regimes that are prone to reversals rather than clean continuations.",
        "hypothesis_evaluation": "The hypothesis that high intraday volatility relative to range indicates institutional absorption is partially supported by the positive IC, but the deterioration compared to SOTA suggests the 'SIGN(open - close_1)' filter might be too simplistic. The overnight gap direction alone may not sufficiently distinguish between 'exhaustion gaps' and 'breakaway gaps' when combined with intraday jitter.",
        "decision": false,
        "reason": "The current factors use 'SIGN(open - delay(close, 1))' which is a binary signal. Replacing this with a continuous measure of where the price 'settles' relative to its intraday range (e.g., (close - low)/(high - low)) provides a more granular view of whether the 'absorption' resulted in a successful price defense. Additionally, simplifying the expression by using a single lookback window for both volatility and range will reduce symbol complexity and potentially improve generalization."
      }
    },
    "25e7b4991928d2dd": {
      "factor_id": "25e7b4991928d2dd",
      "factor_name": "Institutional_Flow_Absorption_Z",
      "factor_expression": "RANK(TS_STD($return, 5) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD(TS_PCTCHANGE($close, 1), 5) / ($high - $low + 1e-8)) * SIGN($open - DELAY($close, 1))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Flow_Absorption_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the liquidity absorption hypothesis. It captures the relative intensity of intraday volatility versus range expansion, conditioned on the overnight gap direction. High values indicate stocks where price discovery is happening through volume absorption rather than range expansion.",
      "factor_formulation": "\\text{RANK}(\\text{TS_STD}(\\text{return}, 5) / (\\text{high} - \\text{low} + 1e-8)) * \\text{SIGN}(\\text{open} - \\text{DELAY}(\\text{close}, 1))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 1,
        "evolution_phase": "mutation",
        "trajectory_id": "9d60c3a4557d",
        "parent_trajectory_ids": [
          "af51ae859843"
        ],
        "hypothesis": "Hypothesis: The ratio of intraday price volatility to the daily high-low range, when combined with the overnight return direction, identifies institutional liquidity absorption and predicts short-term price continuation.\n                Concise Observation: Daily price-volume models often miss the 'quality' of price movement; assets frequently show high intraday 'jitter' (noise) that doesn't expand the daily range, which often precedes a continuation of the primary trend rather than a reversal.\n                Concise Justification: Institutional traders often use VWAP or TWAP algorithms that create persistent intraday volatility without necessarily pushing the price to new extremes immediately; this 'microstructure noise' reflects informed flow being absorbed by market makers.\n                Concise Knowledge: If intraday variance is high relative to the daily range, it indicates high-frequency price discovery or institutional execution; when this occurs following a significant overnight gap, the market is likely absorbing order flow in the gap's direction, leading to momentum persistence.\n                concise Specification: The factor will be defined as the 5-day average of (Standard Deviation of Daily Returns / (High - Low Price Range)) multiplied by the sign of the overnight return (Open - Previous Close), focusing on the 5-day lookback window to capture recent execution pressure.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-20T23:22:41.877912"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1409981567493226,
        "ICIR": 0.0369586664123746,
        "1day.excess_return_without_cost.std": 0.0040056788757014,
        "1day.excess_return_with_cost.annualized_return": 0.002366972701385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002085186736092,
        "1day.excess_return_without_cost.annualized_return": 0.0496274443189999,
        "1day.excess_return_with_cost.std": 0.0040071944633818,
        "Rank IC": 0.0206685298510156,
        "IC": 0.0048566987125139,
        "1day.excess_return_without_cost.max_drawdown": -0.1105541971671168,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8030772110337956,
        "1day.pa": 0.0,
        "l2.valid": 0.9965480551334356,
        "Rank ICIR": 0.1621728600121771,
        "l2.train": 0.9940337228645996,
        "1day.excess_return_with_cost.information_ratio": 0.0382881472961824,
        "1day.excess_return_with_cost.mean": 9.94526345119754e-06
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Liquidity Absorption' hypothesis, focusing on the ratio of intraday volatility to price range weighted by overnight gaps. While the logic is sound, the current results (IC: 0.0048, IR: 0.803) underperform the SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Absorption_Ratio_5D' and 'Intraday_Jitter_Persistence_5D' both utilize nested rolling windows and complex ratios which might be introducing noise. The drawdown is also significantly higher (-0.11 vs -0.07), suggesting that the current formulation of 'informed flow absorption' may be capturing high-volatility regimes that are prone to reversals rather than clean continuations.",
        "hypothesis_evaluation": "The hypothesis that high intraday volatility relative to range indicates institutional absorption is partially supported by the positive IC, but the deterioration compared to SOTA suggests the 'SIGN(open - close_1)' filter might be too simplistic. The overnight gap direction alone may not sufficiently distinguish between 'exhaustion gaps' and 'breakaway gaps' when combined with intraday jitter.",
        "decision": false,
        "reason": "The current factors use 'SIGN(open - delay(close, 1))' which is a binary signal. Replacing this with a continuous measure of where the price 'settles' relative to its intraday range (e.g., (close - low)/(high - low)) provides a more granular view of whether the 'absorption' resulted in a successful price defense. Additionally, simplifying the expression by using a single lookback window for both volatility and range will reduce symbol complexity and potentially improve generalization."
      }
    },
    "eedbe119c143f8ef": {
      "factor_id": "eedbe119c143f8ef",
      "factor_name": "Institutional_Gap_Linearity_10D",
      "factor_expression": "TS_MEAN(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Linearity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies stocks where overnight sentiment (gaps) is validated by institutional accumulation (trend linearity). It multiplies the 5-day average normalized overnight gap by the R-squared of the 10-day price trend. High values indicate a strong catalyst followed by a persistent, low-noise trend.",
      "factor_formulation": "\\text{TS\\_MEAN}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{high} - \\text{low} + 1e-8}, 5) \\times \\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "6a4713b851e6",
        "parent_trajectory_ids": [
          "432771960cc4",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 5-day average overnight gap (normalized by daily range) and the 10-day price trend linearity (R-squared of price against time), predicts positive returns by identifying stocks where initial sentiment is confirmed by steady institutional accumulation.\n                Concise Observation: Parent 1 (RankIC=0.0248) shows that linear trends indicate institutional quality, while Parent 2 (RankIC=0.0260) shows that overnight gaps capture sentiment; however, gaps alone can be noisy and linear trends alone can lack an immediate catalyst.\n                Concise Justification: Combining the overnight gap (sentiment trigger) with 10-day linearity (trend quality) creates a filter that isolates 'high-conviction' moves where information discovery at the open is sustained by consistent buying pressure over a multi-day horizon.\n                Concise Knowledge: If a positive overnight gap is followed by high price linearity (RSQR) and low volatility, the price movement is likely driven by institutional absorption rather than retail noise; when sentiment gaps are validated by structural trends, they are less prone to mean reversion.\n                concise Specification: The factor is defined as (Mean(Gap/Range, 5) * RSQR(Close, 10)), where Gap is (Open - Prev_Close), Range is (High - Low), and RSQR is the coefficient of determination of a linear regression of Close prices over the last 10 days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:39:19.544865"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1088123530805505,
        "ICIR": 0.064299186135433,
        "1day.excess_return_without_cost.std": 0.0041740965581993,
        "1day.excess_return_with_cost.annualized_return": 0.017557019914081,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002715694318148,
        "1day.excess_return_without_cost.annualized_return": 0.0646335247719259,
        "1day.excess_return_with_cost.std": 0.0041755587322068,
        "Rank IC": 0.0237131598883217,
        "IC": 0.0084900030832181,
        "1day.excess_return_without_cost.max_drawdown": -0.0791558124501512,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.003706810307638,
        "1day.pa": 0.0,
        "l2.valid": 0.9965092983802222,
        "Rank ICIR": 0.184805525300262,
        "l2.train": 0.9933039624693494,
        "1day.excess_return_with_cost.information_ratio": 0.2725509665330962,
        "1day.excess_return_with_cost.mean": 7.376899123563448e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a significant improvement over the SOTA in terms of Information Ratio (1.0037 vs 0.9726), Annualized Return (6.46% vs 5.20%), and Information Coefficient (0.00849 vs 0.00580). The 'Institutional_Accumulation_Signal_10D' and 'Cross_Sectional_Gap_Trend_Synergy' factors successfully captured the interaction between overnight sentiment and intra-day trend persistence. While the Max Drawdown slightly increased (-0.0791 vs -0.0725), the overall risk-adjusted return profile is substantially stronger. The use of regression-based metrics (REGBETA and R-squared) effectively filtered for 'high-quality' trends that likely represent institutional participation rather than retail noise.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The synergy between the overnight gap (initial sentiment) and trend linearity (institutional accumulation) provides a more robust signal than either component alone. Specifically, the 'Institutional_Accumulation_Signal_10D' implementation, which combines the magnitude of the gap with the slope (beta) and quality (R-squared) of the subsequent trend, appears to be the most effective representation of the core idea.",
        "decision": true,
        "reason": "While price linearity (R-squared) captures the 'smoothness' of a trend, it does not account for the 'effort' (volume) behind the move. Institutional accumulation typically involves sustained volume. By adding a volume-price correlation term (TS_CORR between close and volume) to the existing synergy factor, we can distinguish between low-liquidity drifts and high-conviction institutional buying, potentially improving the IC and reducing the drawdown observed in the current iteration."
      }
    },
    "fd9b10d2cd144dd5": {
      "factor_id": "fd9b10d2cd144dd5",
      "factor_name": "Cross_Sectional_Gap_Trend_Synergy",
      "factor_expression": "RANK(TS_MEAN(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8), 5)) * RANK(TS_CORR($close, SEQUENCE(10), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8), 5)) * RANK(TS_CORR($close, SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Gap_Trend_Synergy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the synergy between overnight gaps and trend consistency. It uses the 5-day average gap normalized by volatility and multiplies it by the 10-day price-time correlation to capture directional conviction.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_MEAN}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS\\_STD}(\\text{close}, 5) + 1e-8}, 5)) \\times \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "6a4713b851e6",
        "parent_trajectory_ids": [
          "432771960cc4",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 5-day average overnight gap (normalized by daily range) and the 10-day price trend linearity (R-squared of price against time), predicts positive returns by identifying stocks where initial sentiment is confirmed by steady institutional accumulation.\n                Concise Observation: Parent 1 (RankIC=0.0248) shows that linear trends indicate institutional quality, while Parent 2 (RankIC=0.0260) shows that overnight gaps capture sentiment; however, gaps alone can be noisy and linear trends alone can lack an immediate catalyst.\n                Concise Justification: Combining the overnight gap (sentiment trigger) with 10-day linearity (trend quality) creates a filter that isolates 'high-conviction' moves where information discovery at the open is sustained by consistent buying pressure over a multi-day horizon.\n                Concise Knowledge: If a positive overnight gap is followed by high price linearity (RSQR) and low volatility, the price movement is likely driven by institutional absorption rather than retail noise; when sentiment gaps are validated by structural trends, they are less prone to mean reversion.\n                concise Specification: The factor is defined as (Mean(Gap/Range, 5) * RSQR(Close, 10)), where Gap is (Open - Prev_Close), Range is (High - Low), and RSQR is the coefficient of determination of a linear regression of Close prices over the last 10 days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:39:19.544865"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1088123530805505,
        "ICIR": 0.064299186135433,
        "1day.excess_return_without_cost.std": 0.0041740965581993,
        "1day.excess_return_with_cost.annualized_return": 0.017557019914081,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002715694318148,
        "1day.excess_return_without_cost.annualized_return": 0.0646335247719259,
        "1day.excess_return_with_cost.std": 0.0041755587322068,
        "Rank IC": 0.0237131598883217,
        "IC": 0.0084900030832181,
        "1day.excess_return_without_cost.max_drawdown": -0.0791558124501512,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.003706810307638,
        "1day.pa": 0.0,
        "l2.valid": 0.9965092983802222,
        "Rank ICIR": 0.184805525300262,
        "l2.train": 0.9933039624693494,
        "1day.excess_return_with_cost.information_ratio": 0.2725509665330962,
        "1day.excess_return_with_cost.mean": 7.376899123563448e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a significant improvement over the SOTA in terms of Information Ratio (1.0037 vs 0.9726), Annualized Return (6.46% vs 5.20%), and Information Coefficient (0.00849 vs 0.00580). The 'Institutional_Accumulation_Signal_10D' and 'Cross_Sectional_Gap_Trend_Synergy' factors successfully captured the interaction between overnight sentiment and intra-day trend persistence. While the Max Drawdown slightly increased (-0.0791 vs -0.0725), the overall risk-adjusted return profile is substantially stronger. The use of regression-based metrics (REGBETA and R-squared) effectively filtered for 'high-quality' trends that likely represent institutional participation rather than retail noise.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The synergy between the overnight gap (initial sentiment) and trend linearity (institutional accumulation) provides a more robust signal than either component alone. Specifically, the 'Institutional_Accumulation_Signal_10D' implementation, which combines the magnitude of the gap with the slope (beta) and quality (R-squared) of the subsequent trend, appears to be the most effective representation of the core idea.",
        "decision": true,
        "reason": "While price linearity (R-squared) captures the 'smoothness' of a trend, it does not account for the 'effort' (volume) behind the move. Institutional accumulation typically involves sustained volume. By adding a volume-price correlation term (TS_CORR between close and volume) to the existing synergy factor, we can distinguish between low-liquidity drifts and high-conviction institutional buying, potentially improving the IC and reducing the drawdown observed in the current iteration."
      }
    },
    "d6ce1f94b3219378": {
      "factor_id": "d6ce1f94b3219378",
      "factor_name": "Institutional_Accumulation_Signal_10D",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * REGBETA($close, SEQUENCE(10), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * REGBETA($close, SEQUENCE(10), 10) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Signal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor focuses on the persistence of the trend following a gap. It uses the regression beta of price against time (trend strength) scaled by the R-squared (trend quality) and the recent gap magnitude.",
      "factor_formulation": "\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{DELAY}(\\text{close}, 1)} \\times \\text{REGBETA}(\\text{close}, \\text{SEQUENCE}(10), 10) \\times \\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "6a4713b851e6",
        "parent_trajectory_ids": [
          "432771960cc4",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 5-day average overnight gap (normalized by daily range) and the 10-day price trend linearity (R-squared of price against time), predicts positive returns by identifying stocks where initial sentiment is confirmed by steady institutional accumulation.\n                Concise Observation: Parent 1 (RankIC=0.0248) shows that linear trends indicate institutional quality, while Parent 2 (RankIC=0.0260) shows that overnight gaps capture sentiment; however, gaps alone can be noisy and linear trends alone can lack an immediate catalyst.\n                Concise Justification: Combining the overnight gap (sentiment trigger) with 10-day linearity (trend quality) creates a filter that isolates 'high-conviction' moves where information discovery at the open is sustained by consistent buying pressure over a multi-day horizon.\n                Concise Knowledge: If a positive overnight gap is followed by high price linearity (RSQR) and low volatility, the price movement is likely driven by institutional absorption rather than retail noise; when sentiment gaps are validated by structural trends, they are less prone to mean reversion.\n                concise Specification: The factor is defined as (Mean(Gap/Range, 5) * RSQR(Close, 10)), where Gap is (Open - Prev_Close), Range is (High - Low), and RSQR is the coefficient of determination of a linear regression of Close prices over the last 10 days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:39:19.544865"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1088123530805505,
        "ICIR": 0.064299186135433,
        "1day.excess_return_without_cost.std": 0.0041740965581993,
        "1day.excess_return_with_cost.annualized_return": 0.017557019914081,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002715694318148,
        "1day.excess_return_without_cost.annualized_return": 0.0646335247719259,
        "1day.excess_return_with_cost.std": 0.0041755587322068,
        "Rank IC": 0.0237131598883217,
        "IC": 0.0084900030832181,
        "1day.excess_return_without_cost.max_drawdown": -0.0791558124501512,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.003706810307638,
        "1day.pa": 0.0,
        "l2.valid": 0.9965092983802222,
        "Rank ICIR": 0.184805525300262,
        "l2.train": 0.9933039624693494,
        "1day.excess_return_with_cost.information_ratio": 0.2725509665330962,
        "1day.excess_return_with_cost.mean": 7.376899123563448e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a significant improvement over the SOTA in terms of Information Ratio (1.0037 vs 0.9726), Annualized Return (6.46% vs 5.20%), and Information Coefficient (0.00849 vs 0.00580). The 'Institutional_Accumulation_Signal_10D' and 'Cross_Sectional_Gap_Trend_Synergy' factors successfully captured the interaction between overnight sentiment and intra-day trend persistence. While the Max Drawdown slightly increased (-0.0791 vs -0.0725), the overall risk-adjusted return profile is substantially stronger. The use of regression-based metrics (REGBETA and R-squared) effectively filtered for 'high-quality' trends that likely represent institutional participation rather than retail noise.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The synergy between the overnight gap (initial sentiment) and trend linearity (institutional accumulation) provides a more robust signal than either component alone. Specifically, the 'Institutional_Accumulation_Signal_10D' implementation, which combines the magnitude of the gap with the slope (beta) and quality (R-squared) of the subsequent trend, appears to be the most effective representation of the core idea.",
        "decision": true,
        "reason": "While price linearity (R-squared) captures the 'smoothness' of a trend, it does not account for the 'effort' (volume) behind the move. Institutional accumulation typically involves sustained volume. By adding a volume-price correlation term (TS_CORR between close and volume) to the existing synergy factor, we can distinguish between low-liquidity drifts and high-conviction institutional buying, potentially improving the IC and reducing the drawdown observed in the current iteration."
      }
    },
    "ee450796c17f4bb2": {
      "factor_id": "ee450796c17f4bb2",
      "factor_name": "Institutional_Gap_Resonance_V1",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 5) + 1e-8)) * RANK(TS_MEAN($volume * ($close - $low) / ($high - $low + 1e-8), 5) / (TS_MEAN($volume * ($close - $low) / ($high - $low + 1e-8), 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 5) + 1e-8)) * RANK(TS_MEAN($volume * ($close - $low) / ($high - $low + 1e-8), 5) / (TS_MEAN($volume * ($close - $low) / ($high - $low + 1e-8), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Resonance_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'Institutional Gap Resonance' by multiplying the rank of the overnight gap (normalized by the 5-day average true range) with the rank of the volume-price resonance. The resonance component measures the 5-day volume-weighted price position relative to its 20-day baseline, identifying gaps supported by institutional conviction.",
      "factor_formulation": "\\text{Rank}\\left(\\frac{|\\text{open} - \\text{close}_{prev}|}{\\text{ATR5}}\\right) \\times \\text{Rank}\\left(\\frac{\\text{TS\\_MEAN}(\\text{Resonance}, 5)}{\\text{TS\\_MEAN}(\\text{Resonance}, 20)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "cd1b88f28a6f",
        "parent_trajectory_ids": [
          "40b954f98281",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Resonance' factor, calculated as the product of the overnight price gap (normalized by the 5-day average true range) and the 5-day weighted volume moving average (WVMA5) relative to its 20-day baseline, predicts positive returns by identifying overnight sentiment that is confirmed by high-conviction intraday volume support.\n                Concise Observation: Parent 1 showed that volume-weighted intraday ranges capture quality volatility (RankIC 0.024), while Parent 2 showed that overnight gaps normalized by daily ranges capture sentiment persistence (RankIC 0.026).\n                Concise Justification: Combining the overnight gap with a volume-weighted liquidity measure ensures that only sentiment-driven moves supported by actual capital commitment are flagged as trend-initiating signals, filtering out low-liquidity price jumps.\n                Concise Knowledge: If an overnight price gap is accompanied by high volume-weighted price resonance, it indicates institutional conviction; when such gaps occur with low volume, they are likely speculative noise prone to mean reversion.\n                concise Specification: The factor is the product of the Rank of the Overnight Gap (abs(Open - Close_prev) / ATR5) and the Rank of the Volume-Price Resonance (WVMA5 / WVMA20), where WVMA is the 5-day moving average of (Volume * (Close - Low) / (High - Low)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:44:07.804935"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1325404438268687,
        "ICIR": 0.0318718980514855,
        "1day.excess_return_without_cost.std": 0.004471736688651,
        "1day.excess_return_with_cost.annualized_return": 0.0131421195969717,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002526576288307,
        "1day.excess_return_without_cost.annualized_return": 0.0601325156617199,
        "1day.excess_return_with_cost.std": 0.004473815324613,
        "Rank IC": 0.0213307863815739,
        "IC": 0.0043381728338697,
        "1day.excess_return_without_cost.max_drawdown": -0.0970172958234188,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.871655092246583,
        "1day.pa": 0.0,
        "l2.valid": 0.9964954150425324,
        "Rank ICIR": 0.1646895268574646,
        "l2.train": 0.993457278056624,
        "1day.excess_return_with_cost.information_ratio": 0.1904140032615635,
        "1day.excess_return_with_cost.mean": 5.521898990324279e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Gap Resonance' hypothesis. The current results show an improvement in the '1day.excess_return_without_cost.annualized_return' (0.0601 vs 0.0520), although the Information Ratio and IC remain slightly below the previous SOTA. This suggests that while the resonance between overnight gaps and volume-weighted pressure captures higher-magnitude return events, the overall signal consistency (IC) and risk-adjusted performance (IR) have slightly deteriorated, likely due to increased volatility or drawdown (-0.097 vs -0.072).",
        "hypothesis_evaluation": "The hypothesis that overnight gaps confirmed by volume support predict positive returns is partially supported by the increase in annualized returns. However, the lower IC suggests that the 'resonance' component might be too noisy or that the interaction between the gap and volume is non-linear and not perfectly captured by simple multiplication of ranks or Z-scores. The 'Institutional_Gap_Resonance_V1' and 'Volume_Confirmed_Gap_Persistence' both use rank-based products, which can be sensitive to outliers in either the gap or the volume component.",
        "decision": true,
        "reason": "The current results improved the return but increased the drawdown. By switching from a symmetric rank-product to a volatility-normalized gap scaled by relative volume strength, we can filter out 'exhaustion gaps' (high volume but low price progress). Using a 20-day volatility anchor for the gap normalization (instead of 5-day ATR or STD) should provide a more stable baseline, reducing the noise that led to the lower IC and higher drawdown in the current iteration."
      }
    },
    "c7cdee625a8190b1": {
      "factor_id": "c7cdee625a8190b1",
      "factor_name": "Simplified_Gap_Conviction_Factor",
      "factor_expression": "ZSCORE(($open / DELAY($close, 1) - 1) / (TS_STD($return, 5) + 1e-8)) + ZSCORE(WMA($volume * ($close - $low) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open / DELAY($close, 1) - 1) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-08)) + ZSCORE(WMA($volume * ($close - $low) / ($high - $low + 1e-08), 5))\" # Your output factor expression will be filled in here\n    name = \"Simplified_Gap_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Institutional Gap Resonance hypothesis. It focuses on the interaction between the overnight price jump and the recent trend in volume-weighted intraday price strength. It uses a 5-day window for both the gap normalization and the volume-price resonance to capture short-term institutional momentum.",
      "factor_formulation": "\\text{ZSCORE}(\\text{Gap} / \\text{TS\\_STD}(\\text{Return}, 5)) + \\text{ZSCORE}(\\text{WMA}(\\text{Volume-Price Resonance}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "cd1b88f28a6f",
        "parent_trajectory_ids": [
          "40b954f98281",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Resonance' factor, calculated as the product of the overnight price gap (normalized by the 5-day average true range) and the 5-day weighted volume moving average (WVMA5) relative to its 20-day baseline, predicts positive returns by identifying overnight sentiment that is confirmed by high-conviction intraday volume support.\n                Concise Observation: Parent 1 showed that volume-weighted intraday ranges capture quality volatility (RankIC 0.024), while Parent 2 showed that overnight gaps normalized by daily ranges capture sentiment persistence (RankIC 0.026).\n                Concise Justification: Combining the overnight gap with a volume-weighted liquidity measure ensures that only sentiment-driven moves supported by actual capital commitment are flagged as trend-initiating signals, filtering out low-liquidity price jumps.\n                Concise Knowledge: If an overnight price gap is accompanied by high volume-weighted price resonance, it indicates institutional conviction; when such gaps occur with low volume, they are likely speculative noise prone to mean reversion.\n                concise Specification: The factor is the product of the Rank of the Overnight Gap (abs(Open - Close_prev) / ATR5) and the Rank of the Volume-Price Resonance (WVMA5 / WVMA20), where WVMA is the 5-day moving average of (Volume * (Close - Low) / (High - Low)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:44:07.804935"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1325404438268687,
        "ICIR": 0.0318718980514855,
        "1day.excess_return_without_cost.std": 0.004471736688651,
        "1day.excess_return_with_cost.annualized_return": 0.0131421195969717,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002526576288307,
        "1day.excess_return_without_cost.annualized_return": 0.0601325156617199,
        "1day.excess_return_with_cost.std": 0.004473815324613,
        "Rank IC": 0.0213307863815739,
        "IC": 0.0043381728338697,
        "1day.excess_return_without_cost.max_drawdown": -0.0970172958234188,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.871655092246583,
        "1day.pa": 0.0,
        "l2.valid": 0.9964954150425324,
        "Rank ICIR": 0.1646895268574646,
        "l2.train": 0.993457278056624,
        "1day.excess_return_with_cost.information_ratio": 0.1904140032615635,
        "1day.excess_return_with_cost.mean": 5.521898990324279e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Gap Resonance' hypothesis. The current results show an improvement in the '1day.excess_return_without_cost.annualized_return' (0.0601 vs 0.0520), although the Information Ratio and IC remain slightly below the previous SOTA. This suggests that while the resonance between overnight gaps and volume-weighted pressure captures higher-magnitude return events, the overall signal consistency (IC) and risk-adjusted performance (IR) have slightly deteriorated, likely due to increased volatility or drawdown (-0.097 vs -0.072).",
        "hypothesis_evaluation": "The hypothesis that overnight gaps confirmed by volume support predict positive returns is partially supported by the increase in annualized returns. However, the lower IC suggests that the 'resonance' component might be too noisy or that the interaction between the gap and volume is non-linear and not perfectly captured by simple multiplication of ranks or Z-scores. The 'Institutional_Gap_Resonance_V1' and 'Volume_Confirmed_Gap_Persistence' both use rank-based products, which can be sensitive to outliers in either the gap or the volume component.",
        "decision": true,
        "reason": "The current results improved the return but increased the drawdown. By switching from a symmetric rank-product to a volatility-normalized gap scaled by relative volume strength, we can filter out 'exhaustion gaps' (high volume but low price progress). Using a 20-day volatility anchor for the gap normalization (instead of 5-day ATR or STD) should provide a more stable baseline, reducing the noise that led to the lower IC and higher drawdown in the current iteration."
      }
    },
    "0a973fddec189238": {
      "factor_id": "0a973fddec189238",
      "factor_name": "Volume_Confirmed_Gap_Persistence",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 10) + 1e-8)) * RANK(TS_MEAN($volume * ($close - $open) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_MEDIAN($high - $low, 10) + 1e-8)) * RANK(TS_MEAN($volume * ($close - $open) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Confirmed_Gap_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction overnight moves by calculating the ratio of the current overnight gap to the 10-day median range, multiplied by the relative intensity of volume-weighted buying pressure over the last 5 days.",
      "factor_formulation": "\\text{RANK}(\\text{Gap} / \\text{TS\\_MEDIAN}(\\text{High-Low}, 10)) \\times \\text{RANK}(\\text{TS\\_MEAN}(\\text{Buying Pressure}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "cd1b88f28a6f",
        "parent_trajectory_ids": [
          "40b954f98281",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Resonance' factor, calculated as the product of the overnight price gap (normalized by the 5-day average true range) and the 5-day weighted volume moving average (WVMA5) relative to its 20-day baseline, predicts positive returns by identifying overnight sentiment that is confirmed by high-conviction intraday volume support.\n                Concise Observation: Parent 1 showed that volume-weighted intraday ranges capture quality volatility (RankIC 0.024), while Parent 2 showed that overnight gaps normalized by daily ranges capture sentiment persistence (RankIC 0.026).\n                Concise Justification: Combining the overnight gap with a volume-weighted liquidity measure ensures that only sentiment-driven moves supported by actual capital commitment are flagged as trend-initiating signals, filtering out low-liquidity price jumps.\n                Concise Knowledge: If an overnight price gap is accompanied by high volume-weighted price resonance, it indicates institutional conviction; when such gaps occur with low volume, they are likely speculative noise prone to mean reversion.\n                concise Specification: The factor is the product of the Rank of the Overnight Gap (abs(Open - Close_prev) / ATR5) and the Rank of the Volume-Price Resonance (WVMA5 / WVMA20), where WVMA is the 5-day moving average of (Volume * (Close - Low) / (High - Low)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:44:07.804935"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1325404438268687,
        "ICIR": 0.0318718980514855,
        "1day.excess_return_without_cost.std": 0.004471736688651,
        "1day.excess_return_with_cost.annualized_return": 0.0131421195969717,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002526576288307,
        "1day.excess_return_without_cost.annualized_return": 0.0601325156617199,
        "1day.excess_return_with_cost.std": 0.004473815324613,
        "Rank IC": 0.0213307863815739,
        "IC": 0.0043381728338697,
        "1day.excess_return_without_cost.max_drawdown": -0.0970172958234188,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.871655092246583,
        "1day.pa": 0.0,
        "l2.valid": 0.9964954150425324,
        "Rank ICIR": 0.1646895268574646,
        "l2.train": 0.993457278056624,
        "1day.excess_return_with_cost.information_ratio": 0.1904140032615635,
        "1day.excess_return_with_cost.mean": 5.521898990324279e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Gap Resonance' hypothesis. The current results show an improvement in the '1day.excess_return_without_cost.annualized_return' (0.0601 vs 0.0520), although the Information Ratio and IC remain slightly below the previous SOTA. This suggests that while the resonance between overnight gaps and volume-weighted pressure captures higher-magnitude return events, the overall signal consistency (IC) and risk-adjusted performance (IR) have slightly deteriorated, likely due to increased volatility or drawdown (-0.097 vs -0.072).",
        "hypothesis_evaluation": "The hypothesis that overnight gaps confirmed by volume support predict positive returns is partially supported by the increase in annualized returns. However, the lower IC suggests that the 'resonance' component might be too noisy or that the interaction between the gap and volume is non-linear and not perfectly captured by simple multiplication of ranks or Z-scores. The 'Institutional_Gap_Resonance_V1' and 'Volume_Confirmed_Gap_Persistence' both use rank-based products, which can be sensitive to outliers in either the gap or the volume component.",
        "decision": true,
        "reason": "The current results improved the return but increased the drawdown. By switching from a symmetric rank-product to a volatility-normalized gap scaled by relative volume strength, we can filter out 'exhaustion gaps' (high volume but low price progress). Using a 20-day volatility anchor for the gap normalization (instead of 5-day ATR or STD) should provide a more stable baseline, reducing the noise that led to the lower IC and higher drawdown in the current iteration."
      }
    },
    "1bf8ab82e701e97c": {
      "factor_id": "1bf8ab82e701e97c",
      "factor_name": "Inst_Capitulation_Absorption_V1",
      "factor_expression": "(ZSCORE(TS_PCTCHANGE($close, 60)) * -1) * (ZSCORE(TS_CORR($close, $volume, 20)) * -1) * (($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_PCTCHANGE($close, 60)) * -1) * (ZSCORE(TS_CORR($close, $volume, 20)) * -1) * (($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Inst_Capitulation_Absorption_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Identifies reversal opportunities by combining long-term price-volume exhaustion with short-term sentiment shifts. It multiplies the inverse 60-day price return and inverse 20-day price-volume correlation (capturing capitulation) by the overnight gap normalized by recent volatility.",
      "factor_formulation": "ICA_{V1} = ZSCORE(TS\\_PCTCHANGE(close, 60)) * -1 * ZSCORE(TS\\_CORR(close, volume, 20)) * -1 * \\frac{open - DELAY(close, 1)}{TS\\_MEAN(high - low, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "c197cb308ff5",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Capitulation Absorption' factor identifies high-alpha reversal opportunities by multiplying a 60-day capitulation signal (negative ROC60 and negative price-volume correlation) with a 1-day sentiment efficiency signal (overnight gap normalized by the 5-day average true range).\n                Concise Observation: Parent 1 (RankIC 0.0234) identifies structural oversold conditions but suffers from 'falling knives', while Parent 2 (RankIC 0.0260) captures short-term sentiment but lacks context on whether the gap represents a trend continuation or a reversal.\n                Concise Justification: Combining long-term capitulation metrics with short-term gap efficiency ensures that mean-reversion entries are timed with a shift in sentiment, filtering out assets that continue to decline due to lack of buying interest.\n                Concise Knowledge: If a long-term price decline is accompanied by negative price-volume correlation, it indicates exhaustive selling; when this state is followed by a significant overnight gap relative to recent volatility, it signals institutional absorption of retail panic.\n                concise Specification: The factor is defined as: [Z-score(ROC(close, 60)) * -1] * [Z-score(Correlation(close, volume, 20)) * -1] * [(open - delay(close, 1)) / Mean(High - Low, 5)]. All components are calculated using daily price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:50:18.738394"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1135943270413567,
        "ICIR": 0.0199400982564705,
        "1day.excess_return_without_cost.std": 0.004148365084756,
        "1day.excess_return_with_cost.annualized_return": 0.0112629545756962,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002458729282759,
        "1day.excess_return_without_cost.annualized_return": 0.0585177569296795,
        "1day.excess_return_with_cost.std": 0.0041502982269425,
        "Rank IC": 0.0169856049080842,
        "IC": 0.0027129963800472,
        "1day.excess_return_without_cost.max_drawdown": -0.0874074396263082,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9143705329872028,
        "1day.pa": 0.0,
        "l2.valid": 0.996904897781705,
        "Rank ICIR": 0.1264913538529346,
        "l2.train": 0.993610084400336,
        "1day.excess_return_with_cost.information_ratio": 0.175907578081286,
        "1day.excess_return_with_cost.mean": 4.732333855334561e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Capitulation Absorption' hypothesis. The current best performer among the new factors (Inst_Capitulation_Absorption_V1 and its derivatives) achieved a higher annualized return (0.0585 vs 0.0520) compared to the SOTA, although it suffered from a lower Information Ratio (0.914 vs 0.972) and a deeper Max Drawdown (-0.087 vs -0.072). The IC also saw a significant drop, suggesting that while the factor captures high-magnitude reversal events effectively, its overall predictive consistency across the entire cross-section is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining long-term capitulation (ROC60 + Price-Volume Correlation) with short-term sentiment efficiency (Overnight Gap) yields alpha is supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the current mathematical formulation—specifically the multiplication of multiple Z-scored or ranked components—might be creating a 'noisy' signal that only triggers effectively on extreme outliers, leading to higher volatility and drawdown.",
        "decision": true,
        "reason": "Multiplicative factors (A * B * C) often suffer from extreme values and low IC because one near-zero component nullifies the others. By using a conditional approach (e.g., only calculating the gap efficiency when the capitulation signal is below a certain threshold) or a weighted additive combination of Z-scores, we can improve the Information Ratio. Additionally, the current 5-day normalization for the gap is highly sensitive to short-term noise; extending this window to 20 days will provide a more stable 'efficiency' metric, likely reducing the Max Drawdown observed in the current results."
      }
    },
    "57171e797a2909c6": {
      "factor_id": "57171e797a2909c6",
      "factor_name": "Capitulation_Rebound_Efficiency",
      "factor_expression": "(1 - TS_RANK($close, 60)) * (($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(1 - TS_RANK($close, 60)) * (($open - DELAY($close, 1)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Capitulation_Rebound_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Institutional Capitulation hypothesis focusing on the interaction between long-term oversold ranking and the efficiency of the overnight price gap. It uses TS_RANK for robustness against outliers in the capitulation phase.",
      "factor_formulation": "CRE = (1 - TS\\_RANK(close, 60)) * \\frac{open - DELAY(close, 1)}{TS\\_STD(close, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "c197cb308ff5",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Capitulation Absorption' factor identifies high-alpha reversal opportunities by multiplying a 60-day capitulation signal (negative ROC60 and negative price-volume correlation) with a 1-day sentiment efficiency signal (overnight gap normalized by the 5-day average true range).\n                Concise Observation: Parent 1 (RankIC 0.0234) identifies structural oversold conditions but suffers from 'falling knives', while Parent 2 (RankIC 0.0260) captures short-term sentiment but lacks context on whether the gap represents a trend continuation or a reversal.\n                Concise Justification: Combining long-term capitulation metrics with short-term gap efficiency ensures that mean-reversion entries are timed with a shift in sentiment, filtering out assets that continue to decline due to lack of buying interest.\n                Concise Knowledge: If a long-term price decline is accompanied by negative price-volume correlation, it indicates exhaustive selling; when this state is followed by a significant overnight gap relative to recent volatility, it signals institutional absorption of retail panic.\n                concise Specification: The factor is defined as: [Z-score(ROC(close, 60)) * -1] * [Z-score(Correlation(close, volume, 20)) * -1] * [(open - delay(close, 1)) / Mean(High - Low, 5)]. All components are calculated using daily price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:50:18.738394"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1135943270413567,
        "ICIR": 0.0199400982564705,
        "1day.excess_return_without_cost.std": 0.004148365084756,
        "1day.excess_return_with_cost.annualized_return": 0.0112629545756962,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002458729282759,
        "1day.excess_return_without_cost.annualized_return": 0.0585177569296795,
        "1day.excess_return_with_cost.std": 0.0041502982269425,
        "Rank IC": 0.0169856049080842,
        "IC": 0.0027129963800472,
        "1day.excess_return_without_cost.max_drawdown": -0.0874074396263082,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9143705329872028,
        "1day.pa": 0.0,
        "l2.valid": 0.996904897781705,
        "Rank ICIR": 0.1264913538529346,
        "l2.train": 0.993610084400336,
        "1day.excess_return_with_cost.information_ratio": 0.175907578081286,
        "1day.excess_return_with_cost.mean": 4.732333855334561e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Capitulation Absorption' hypothesis. The current best performer among the new factors (Inst_Capitulation_Absorption_V1 and its derivatives) achieved a higher annualized return (0.0585 vs 0.0520) compared to the SOTA, although it suffered from a lower Information Ratio (0.914 vs 0.972) and a deeper Max Drawdown (-0.087 vs -0.072). The IC also saw a significant drop, suggesting that while the factor captures high-magnitude reversal events effectively, its overall predictive consistency across the entire cross-section is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining long-term capitulation (ROC60 + Price-Volume Correlation) with short-term sentiment efficiency (Overnight Gap) yields alpha is supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the current mathematical formulation—specifically the multiplication of multiple Z-scored or ranked components—might be creating a 'noisy' signal that only triggers effectively on extreme outliers, leading to higher volatility and drawdown.",
        "decision": true,
        "reason": "Multiplicative factors (A * B * C) often suffer from extreme values and low IC because one near-zero component nullifies the others. By using a conditional approach (e.g., only calculating the gap efficiency when the capitulation signal is below a certain threshold) or a weighted additive combination of Z-scores, we can improve the Information Ratio. Additionally, the current 5-day normalization for the gap is highly sensitive to short-term noise; extending this window to 20 days will provide a more stable 'efficiency' metric, likely reducing the Max Drawdown observed in the current results."
      }
    },
    "e80e42cb23ce9662": {
      "factor_id": "e80e42cb23ce9662",
      "factor_name": "Exhaustion_Gap_Factor",
      "factor_expression": "RANK(DELTA($close, 60)) * RANK(TS_CORR($close, $volume, 20)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_PCTCHANGE($close, 60) < 0) && (TS_CORR($close, $volume, 20) < 0)) ? (($open - DELAY($close, 1)) / ($high - $low + 1e-8)) : 0\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures institutional absorption by identifying days where a long-term decline (negative ROC) and volume-price divergence (negative correlation) are met with a positive overnight gap relative to the daily range.",
      "factor_formulation": "EGF = RANK(DELTA(close, 60)) * RANK(TS\\_CORR(close, volume, 20)) * ((open - DELAY(close, 1)) / (high - low + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "c197cb308ff5",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Capitulation Absorption' factor identifies high-alpha reversal opportunities by multiplying a 60-day capitulation signal (negative ROC60 and negative price-volume correlation) with a 1-day sentiment efficiency signal (overnight gap normalized by the 5-day average true range).\n                Concise Observation: Parent 1 (RankIC 0.0234) identifies structural oversold conditions but suffers from 'falling knives', while Parent 2 (RankIC 0.0260) captures short-term sentiment but lacks context on whether the gap represents a trend continuation or a reversal.\n                Concise Justification: Combining long-term capitulation metrics with short-term gap efficiency ensures that mean-reversion entries are timed with a shift in sentiment, filtering out assets that continue to decline due to lack of buying interest.\n                Concise Knowledge: If a long-term price decline is accompanied by negative price-volume correlation, it indicates exhaustive selling; when this state is followed by a significant overnight gap relative to recent volatility, it signals institutional absorption of retail panic.\n                concise Specification: The factor is defined as: [Z-score(ROC(close, 60)) * -1] * [Z-score(Correlation(close, volume, 20)) * -1] * [(open - delay(close, 1)) / Mean(High - Low, 5)]. All components are calculated using daily price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-20T23:50:18.738394"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1135943270413567,
        "ICIR": 0.0199400982564705,
        "1day.excess_return_without_cost.std": 0.004148365084756,
        "1day.excess_return_with_cost.annualized_return": 0.0112629545756962,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002458729282759,
        "1day.excess_return_without_cost.annualized_return": 0.0585177569296795,
        "1day.excess_return_with_cost.std": 0.0041502982269425,
        "Rank IC": 0.0169856049080842,
        "IC": 0.0027129963800472,
        "1day.excess_return_without_cost.max_drawdown": -0.0874074396263082,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9143705329872028,
        "1day.pa": 0.0,
        "l2.valid": 0.996904897781705,
        "Rank ICIR": 0.1264913538529346,
        "l2.train": 0.993610084400336,
        "1day.excess_return_with_cost.information_ratio": 0.175907578081286,
        "1day.excess_return_with_cost.mean": 4.732333855334561e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Capitulation Absorption' hypothesis. The current best performer among the new factors (Inst_Capitulation_Absorption_V1 and its derivatives) achieved a higher annualized return (0.0585 vs 0.0520) compared to the SOTA, although it suffered from a lower Information Ratio (0.914 vs 0.972) and a deeper Max Drawdown (-0.087 vs -0.072). The IC also saw a significant drop, suggesting that while the factor captures high-magnitude reversal events effectively, its overall predictive consistency across the entire cross-section is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining long-term capitulation (ROC60 + Price-Volume Correlation) with short-term sentiment efficiency (Overnight Gap) yields alpha is supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the current mathematical formulation—specifically the multiplication of multiple Z-scored or ranked components—might be creating a 'noisy' signal that only triggers effectively on extreme outliers, leading to higher volatility and drawdown.",
        "decision": true,
        "reason": "Multiplicative factors (A * B * C) often suffer from extreme values and low IC because one near-zero component nullifies the others. By using a conditional approach (e.g., only calculating the gap efficiency when the capitulation signal is below a certain threshold) or a weighted additive combination of Z-scores, we can improve the Information Ratio. Additionally, the current 5-day normalization for the gap is highly sensitive to short-term noise; extending this window to 20 days will provide a more stable 'efficiency' metric, likely reducing the Max Drawdown observed in the current results."
      }
    },
    "9fbc213ac8680a3b": {
      "factor_id": "9fbc213ac8680a3b",
      "factor_name": "Institutional_Gap_Synergy_10D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_MEAN(TS_STD($close, 5) * $volume, 5) + 1e-8) * ($open / (DELAY($close, 1) + 1e-8) - 1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_MEAN(TS_STD($close, 5) * $volume, 5) + 1e-8) * ($open / (DELAY($close, 1) + 1e-8) - 1))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Synergy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the interaction between institutional accumulation quality (proxied by trend linearity) and overnight sentiment shocks. It multiplies the square of the price-time correlation (RSQR) by the overnight gap, normalized by volume-weighted volatility. High values suggest a gap aligned with a stable institutional trend.",
      "factor_formulation": "Factor = RANK(TS\\_CORR(close, SEQUENCE(10), 10)^2 / (TS\\_MEAN(TS\\_STD(close, 5) * volume, 5) + 1e-8) * (open / DELAY(close, 1) - 1))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "aa58d7c50e70",
        "parent_trajectory_ids": [
          "432771960cc4",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 10-day price trend linearity (RSQR10) and the overnight gap (Open/Close_prev - 1) divided by the 5-day volume-weighted volatility (WVMA5), predicts that overnight gaps aligned with high-quality institutional accumulation lead to persistent returns, while gaps in low-linearity regimes revert.\n                Concise Observation: Parent 1 (Institutional Absorption) identifies stable accumulation phases with a RankIC of 0.0248, while Parent 2 (Overnight Gap) captures sentiment shocks with a RankIC of 0.0244; combining them addresses the failure of gap reversion during strong, stealthy institutional trends.\n                Concise Justification: Institutional investors prefer 'stealth' accumulation (high R-squared, low volatility) to minimize market impact; an overnight gap during such a phase indicates a shift from stealth to urgency that the market has yet to fully price in, creating a momentum signal rather than a reversion one.\n                Concise Knowledge: If a price gap occurs within a regime of high trend linearity and low volatility, it signifies institutional validation and trend continuation; conversely, if a gap occurs in a high-volatility or low-linearity environment, it is likely a liquidity-driven noise event prone to mean reversion.\n                concise Specification: Define the factor as (RSQR(close, 10) / MovingAverage(StdDev(close, 5) * volume, 5)) * (Open / Close_prev - 1). High positive values indicate validated upward momentum, while negative or low values indicate noise or reversion signals, specifically targeting the interaction between 10-day structural quality and 1-day price jumps.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:00:27.456038"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0894216258709554,
        "ICIR": 0.0434326334253466,
        "1day.excess_return_without_cost.std": 0.0038800324364112,
        "1day.excess_return_with_cost.annualized_return": 0.0143204304626745,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002582011635325,
        "1day.excess_return_without_cost.annualized_return": 0.0614518769207539,
        "1day.excess_return_with_cost.std": 0.0038803283255336,
        "Rank IC": 0.0201478136889289,
        "IC": 0.0055701850485304,
        "1day.excess_return_without_cost.max_drawdown": -0.0806394701939194,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0266237742111584,
        "1day.pa": 0.0,
        "l2.valid": 0.9966927109797544,
        "Rank ICIR": 0.159113853179747,
        "l2.train": 0.993925568745296,
        "1day.excess_return_with_cost.information_ratio": 0.2392209001411968,
        "1day.excess_return_with_cost.mean": 6.016987589359073e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Gap-Trend Synergy' hypothesis, testing three variations that combine trend linearity (via RSQR or regression residuals) with overnight gaps. The results show a significant improvement in risk-adjusted performance (Information Ratio increased from 0.97 to 1.02) and annualized return (from 5.2% to 6.1%), although the IC slightly decreased and the Max Drawdown deepened. The 'Institutional_Gap_Synergy_10D' factor appears to be the primary driver of this improvement, successfully capturing the synergy between institutional trend quality and price shocks.",
        "hypothesis_evaluation": "The hypothesis that overnight gaps aligned with high-quality institutional accumulation (linearity) lead to persistent returns is strongly supported by the improvement in Information Ratio and Annualized Return. The use of TS_CORR^2 (RSQR) as a proxy for linearity, when coupled with a volatility-normalized gap, provides a more robust signal than simple momentum. However, the slight increase in Max Drawdown suggests that while the 'quality' of the trend is captured, the factor may still be sensitive to broader market regime shifts or tail events in volatility.",
        "decision": true,
        "reason": "Current factors use raw price correlation (TS_CORR) which can be skewed by low-volume price drifting. By incorporating volume into the linearity measure (e.g., TS_CORR of price and cumulative volume), we can better identify true institutional 'accumulation' rather than just price movement. Additionally, the current volatility normalization (TS_STD * volume) might be too aggressive; using a relative range (High-Low) normalized by its own moving average (ATR-like) may provide a more stable scaling factor for the overnight gap."
      }
    },
    "16db23683ed297a9": {
      "factor_id": "16db23683ed297a9",
      "factor_name": "Stealth_Accumulation_Gap_V1",
      "factor_expression": "TS_RANK($close, 10) * ($open - DELAY($close, 1)) / (TS_MEAN(($high - $low) * $volume, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK($close, 10) * ($open - DELAY($close, 1)) / (TS_MEAN(($high - $low) * $volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Gap_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Institutional Gap-Trend Synergy hypothesis. It uses the 10-day time-series rank of returns to proxy for trend quality and scales the overnight gap by the 5-day average range-volume product. This identifies if a gap occurs during a period of consistent price appreciation and low relative volatility.",
      "factor_formulation": "Factor = TS\\_RANK(close, 10) * (open - DELAY(close, 1)) / (TS\\_MEAN((high - low) * volume, 5) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "aa58d7c50e70",
        "parent_trajectory_ids": [
          "432771960cc4",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 10-day price trend linearity (RSQR10) and the overnight gap (Open/Close_prev - 1) divided by the 5-day volume-weighted volatility (WVMA5), predicts that overnight gaps aligned with high-quality institutional accumulation lead to persistent returns, while gaps in low-linearity regimes revert.\n                Concise Observation: Parent 1 (Institutional Absorption) identifies stable accumulation phases with a RankIC of 0.0248, while Parent 2 (Overnight Gap) captures sentiment shocks with a RankIC of 0.0244; combining them addresses the failure of gap reversion during strong, stealthy institutional trends.\n                Concise Justification: Institutional investors prefer 'stealth' accumulation (high R-squared, low volatility) to minimize market impact; an overnight gap during such a phase indicates a shift from stealth to urgency that the market has yet to fully price in, creating a momentum signal rather than a reversion one.\n                Concise Knowledge: If a price gap occurs within a regime of high trend linearity and low volatility, it signifies institutional validation and trend continuation; conversely, if a gap occurs in a high-volatility or low-linearity environment, it is likely a liquidity-driven noise event prone to mean reversion.\n                concise Specification: Define the factor as (RSQR(close, 10) / MovingAverage(StdDev(close, 5) * volume, 5)) * (Open / Close_prev - 1). High positive values indicate validated upward momentum, while negative or low values indicate noise or reversion signals, specifically targeting the interaction between 10-day structural quality and 1-day price jumps.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:00:27.456038"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0894216258709554,
        "ICIR": 0.0434326334253466,
        "1day.excess_return_without_cost.std": 0.0038800324364112,
        "1day.excess_return_with_cost.annualized_return": 0.0143204304626745,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002582011635325,
        "1day.excess_return_without_cost.annualized_return": 0.0614518769207539,
        "1day.excess_return_with_cost.std": 0.0038803283255336,
        "Rank IC": 0.0201478136889289,
        "IC": 0.0055701850485304,
        "1day.excess_return_without_cost.max_drawdown": -0.0806394701939194,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0266237742111584,
        "1day.pa": 0.0,
        "l2.valid": 0.9966927109797544,
        "Rank ICIR": 0.159113853179747,
        "l2.train": 0.993925568745296,
        "1day.excess_return_with_cost.information_ratio": 0.2392209001411968,
        "1day.excess_return_with_cost.mean": 6.016987589359073e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Gap-Trend Synergy' hypothesis, testing three variations that combine trend linearity (via RSQR or regression residuals) with overnight gaps. The results show a significant improvement in risk-adjusted performance (Information Ratio increased from 0.97 to 1.02) and annualized return (from 5.2% to 6.1%), although the IC slightly decreased and the Max Drawdown deepened. The 'Institutional_Gap_Synergy_10D' factor appears to be the primary driver of this improvement, successfully capturing the synergy between institutional trend quality and price shocks.",
        "hypothesis_evaluation": "The hypothesis that overnight gaps aligned with high-quality institutional accumulation (linearity) lead to persistent returns is strongly supported by the improvement in Information Ratio and Annualized Return. The use of TS_CORR^2 (RSQR) as a proxy for linearity, when coupled with a volatility-normalized gap, provides a more robust signal than simple momentum. However, the slight increase in Max Drawdown suggests that while the 'quality' of the trend is captured, the factor may still be sensitive to broader market regime shifts or tail events in volatility.",
        "decision": true,
        "reason": "Current factors use raw price correlation (TS_CORR) which can be skewed by low-volume price drifting. By incorporating volume into the linearity measure (e.g., TS_CORR of price and cumulative volume), we can better identify true institutional 'accumulation' rather than just price movement. Additionally, the current volatility normalization (TS_STD * volume) might be too aggressive; using a relative range (High-Low) normalized by its own moving average (ATR-like) may provide a more stable scaling factor for the overnight gap."
      }
    },
    "77711d0c9906ec3a": {
      "factor_id": "77711d0c9906ec3a",
      "factor_name": "Linear_Trend_Volatility_Gap",
      "factor_expression": "($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_VAR(REGRESI($close, SEQUENCE(10), 10), 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_VAR(REGRESI($close, SEQUENCE(10), 10), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Linear_Trend_Volatility_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-quality trends using the inverse of the residual variance from a linear regression of price on time. It then weights the overnight gap by this linearity measure, effectively filtering for gaps that occur in 'stealth' institutional regimes rather than volatile retail-driven ones.",
      "factor_formulation": "Factor = (open / DELAY(close, 1) - 1) / (TS\\_VAR(REGRESI(close, SEQUENCE(10), 10), 10) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "aa58d7c50e70",
        "parent_trajectory_ids": [
          "432771960cc4",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap-Trend Synergy' factor, calculated as the product of the 10-day price trend linearity (RSQR10) and the overnight gap (Open/Close_prev - 1) divided by the 5-day volume-weighted volatility (WVMA5), predicts that overnight gaps aligned with high-quality institutional accumulation lead to persistent returns, while gaps in low-linearity regimes revert.\n                Concise Observation: Parent 1 (Institutional Absorption) identifies stable accumulation phases with a RankIC of 0.0248, while Parent 2 (Overnight Gap) captures sentiment shocks with a RankIC of 0.0244; combining them addresses the failure of gap reversion during strong, stealthy institutional trends.\n                Concise Justification: Institutional investors prefer 'stealth' accumulation (high R-squared, low volatility) to minimize market impact; an overnight gap during such a phase indicates a shift from stealth to urgency that the market has yet to fully price in, creating a momentum signal rather than a reversion one.\n                Concise Knowledge: If a price gap occurs within a regime of high trend linearity and low volatility, it signifies institutional validation and trend continuation; conversely, if a gap occurs in a high-volatility or low-linearity environment, it is likely a liquidity-driven noise event prone to mean reversion.\n                concise Specification: Define the factor as (RSQR(close, 10) / MovingAverage(StdDev(close, 5) * volume, 5)) * (Open / Close_prev - 1). High positive values indicate validated upward momentum, while negative or low values indicate noise or reversion signals, specifically targeting the interaction between 10-day structural quality and 1-day price jumps.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:00:27.456038"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0894216258709554,
        "ICIR": 0.0434326334253466,
        "1day.excess_return_without_cost.std": 0.0038800324364112,
        "1day.excess_return_with_cost.annualized_return": 0.0143204304626745,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002582011635325,
        "1day.excess_return_without_cost.annualized_return": 0.0614518769207539,
        "1day.excess_return_with_cost.std": 0.0038803283255336,
        "Rank IC": 0.0201478136889289,
        "IC": 0.0055701850485304,
        "1day.excess_return_without_cost.max_drawdown": -0.0806394701939194,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0266237742111584,
        "1day.pa": 0.0,
        "l2.valid": 0.9966927109797544,
        "Rank ICIR": 0.159113853179747,
        "l2.train": 0.993925568745296,
        "1day.excess_return_with_cost.information_ratio": 0.2392209001411968,
        "1day.excess_return_with_cost.mean": 6.016987589359073e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Gap-Trend Synergy' hypothesis, testing three variations that combine trend linearity (via RSQR or regression residuals) with overnight gaps. The results show a significant improvement in risk-adjusted performance (Information Ratio increased from 0.97 to 1.02) and annualized return (from 5.2% to 6.1%), although the IC slightly decreased and the Max Drawdown deepened. The 'Institutional_Gap_Synergy_10D' factor appears to be the primary driver of this improvement, successfully capturing the synergy between institutional trend quality and price shocks.",
        "hypothesis_evaluation": "The hypothesis that overnight gaps aligned with high-quality institutional accumulation (linearity) lead to persistent returns is strongly supported by the improvement in Information Ratio and Annualized Return. The use of TS_CORR^2 (RSQR) as a proxy for linearity, when coupled with a volatility-normalized gap, provides a more robust signal than simple momentum. However, the slight increase in Max Drawdown suggests that while the 'quality' of the trend is captured, the factor may still be sensitive to broader market regime shifts or tail events in volatility.",
        "decision": true,
        "reason": "Current factors use raw price correlation (TS_CORR) which can be skewed by low-volume price drifting. By incorporating volume into the linearity measure (e.g., TS_CORR of price and cumulative volume), we can better identify true institutional 'accumulation' rather than just price movement. Additionally, the current volatility normalization (TS_STD * volume) might be too aggressive; using a relative range (High-Low) normalized by its own moving average (ATR-like) may provide a more stable scaling factor for the overnight gap."
      }
    },
    "f817fc208830e195": {
      "factor_id": "f817fc208830e195",
      "factor_name": "Institutional_Exhaustion_Pivot_10_20",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (1 - TS_CORR($close, $volume, 20)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (1 - TS_CORR($close, $volume, 20)) * (($open - DELAY($close, 1)) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Exhaustion_Pivot_10_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction reversals by detecting 'hollow' price trends. It combines 10-day price linearity (proxied by the square of correlation with time) and the decoupling of price and volume (inverse of 20-day correlation). This signal is weighted by the ratio of the overnight gap to the intraday range to capture institutional sentiment shifts.",
      "factor_formulation": "\\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times (1 - \\text{TS\\_CORR}(\\text{close}, \\text{volume}, 20)) \\times \\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{high} - \\text{low} + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "20b0dc7bace0",
        "parent_trajectory_ids": [
          "af51ae859843",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Exhaustion Pivot' factor identifies high-conviction reversals by multiplying the 10-day price linearity (RSQR10) with the inverse of the 20-day price-volume correlation (1-CORR20), then scaling this exhaustion signal by the ratio of the overnight gap to the total daily range.\n                Concise Observation: Parent 1 (RankIC 0.023) captures trend fatigue through price-volume decoupling, while Parent 2 (RankIC 0.026) captures sentiment through overnight gaps; combining them filters out false exhaustion signals that lack immediate sentiment triggers.\n                Concise Justification: Linear trends (high RSQR) that decouple from volume (low CORR) represent 'hollow' moves; applying an overnight gap weight ensures the factor captures the exact moment institutional sentiment shifts to exploit that hollow structure.\n                Concise Knowledge: If a price trend is highly linear but loses volume support, it is prone to reversal; when such structural exhaustion is met with a significant overnight gap relative to intraday volatility, it signals institutional re-pricing rather than retail noise.\n                concise Specification: Calculate RSQR of close prices over 10 days, CORR of close and volume over 20 days, and the ratio of (Open_t - Close_{t-1}) to (High_t - Low_t); the final factor is (RSQR10 * (1 - CORR20) * (Gap / Range)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:16:28.913658"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1163587196473948,
        "ICIR": 0.0389059651700415,
        "1day.excess_return_without_cost.std": 0.0043681538699438,
        "1day.excess_return_with_cost.annualized_return": -0.0087864077562177,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000160394713943,
        "1day.excess_return_without_cost.annualized_return": 0.0381739419184472,
        "1day.excess_return_with_cost.std": 0.0043685353569449,
        "Rank IC": 0.0206623476066447,
        "IC": 0.0052797753923496,
        "1day.excess_return_without_cost.max_drawdown": -0.1058284585823001,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.566474809059768,
        "1day.pa": 0.0,
        "l2.valid": 0.9964856836071614,
        "Rank ICIR": 0.1574860926185051,
        "l2.train": 0.9942890505815052,
        "1day.excess_return_with_cost.information_ratio": -0.1303728082496492,
        "1day.excess_return_with_cost.mean": -3.6917679647973926e-05
      },
      "feedback": {
        "observations": "The current iteration explored the 'Institutional Exhaustion Pivot' framework by combining price linearity, price-volume decoupling, and overnight gap dynamics. While the theoretical construction is sound, the performance metrics (IC: 0.0053, IR: 0.566) significantly underperform compared to the SOTA (IC: 0.0058, IR: 0.972). The 'Institutional_Exhaustion_Pivot_10_20' factor, despite its logical complexity, failed to capture the expected reversal alpha, and the 'Hollow_Trend_Reversal_ZScore' showed that cross-sectional ranking of these components did not bridge the gap to SOTA. The drawdown is also notably higher (-0.1058 vs -0.0726).",
        "hypothesis_evaluation": "The hypothesis that multiplying linearity, volume decoupling, and gap ratios identifies high-conviction reversals is partially refuted by the current results. The interaction between these three distinct signals appears to be too restrictive or 'noisy'. Specifically, the 'open - delay(close, 1)' component might be introducing excessive volatility rather than acting as a clean scaling factor. The complexity of the primary factor (using 5 base features and multiple nested functions) may be leading to poor generalization.",
        "decision": false,
        "reason": "The current factors are over-engineered (high base feature count and complex scaling). By shifting the focus to the divergence between price direction and volume support (using a rolling Z-score of the correlation), we reduce the noise introduced by the overnight gap. Simplifying the denominator from 'high - low' to a more stable rolling volatility measure (like TS_STD) should also improve the Information Ratio by smoothing the signal."
      }
    },
    "af6838f96c52da1a": {
      "factor_id": "af6838f96c52da1a",
      "factor_name": "Hollow_Trend_Reversal_ZScore",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(1 - TS_CORR($close, $volume, 10)) * (($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(1 - TS_CORR($close, $volume, 10)) * (($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Trend_Reversal_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the exhaustion pivot focusing on the cross-sectional rank of trend linearity and volume decoupling. It measures the divergence between price direction and volume support, scaled by the relative magnitude of the overnight gap compared to the 5-day average range.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)) \\times \\text{RANK}(1 - \\text{TS\\_CORR}(\\text{close}, \\text{volume}, 10)) \\times \\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "20b0dc7bace0",
        "parent_trajectory_ids": [
          "af51ae859843",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Exhaustion Pivot' factor identifies high-conviction reversals by multiplying the 10-day price linearity (RSQR10) with the inverse of the 20-day price-volume correlation (1-CORR20), then scaling this exhaustion signal by the ratio of the overnight gap to the total daily range.\n                Concise Observation: Parent 1 (RankIC 0.023) captures trend fatigue through price-volume decoupling, while Parent 2 (RankIC 0.026) captures sentiment through overnight gaps; combining them filters out false exhaustion signals that lack immediate sentiment triggers.\n                Concise Justification: Linear trends (high RSQR) that decouple from volume (low CORR) represent 'hollow' moves; applying an overnight gap weight ensures the factor captures the exact moment institutional sentiment shifts to exploit that hollow structure.\n                Concise Knowledge: If a price trend is highly linear but loses volume support, it is prone to reversal; when such structural exhaustion is met with a significant overnight gap relative to intraday volatility, it signals institutional re-pricing rather than retail noise.\n                concise Specification: Calculate RSQR of close prices over 10 days, CORR of close and volume over 20 days, and the ratio of (Open_t - Close_{t-1}) to (High_t - Low_t); the final factor is (RSQR10 * (1 - CORR20) * (Gap / Range)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:16:28.913658"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1163587196473948,
        "ICIR": 0.0389059651700415,
        "1day.excess_return_without_cost.std": 0.0043681538699438,
        "1day.excess_return_with_cost.annualized_return": -0.0087864077562177,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000160394713943,
        "1day.excess_return_without_cost.annualized_return": 0.0381739419184472,
        "1day.excess_return_with_cost.std": 0.0043685353569449,
        "Rank IC": 0.0206623476066447,
        "IC": 0.0052797753923496,
        "1day.excess_return_without_cost.max_drawdown": -0.1058284585823001,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.566474809059768,
        "1day.pa": 0.0,
        "l2.valid": 0.9964856836071614,
        "Rank ICIR": 0.1574860926185051,
        "l2.train": 0.9942890505815052,
        "1day.excess_return_with_cost.information_ratio": -0.1303728082496492,
        "1day.excess_return_with_cost.mean": -3.6917679647973926e-05
      },
      "feedback": {
        "observations": "The current iteration explored the 'Institutional Exhaustion Pivot' framework by combining price linearity, price-volume decoupling, and overnight gap dynamics. While the theoretical construction is sound, the performance metrics (IC: 0.0053, IR: 0.566) significantly underperform compared to the SOTA (IC: 0.0058, IR: 0.972). The 'Institutional_Exhaustion_Pivot_10_20' factor, despite its logical complexity, failed to capture the expected reversal alpha, and the 'Hollow_Trend_Reversal_ZScore' showed that cross-sectional ranking of these components did not bridge the gap to SOTA. The drawdown is also notably higher (-0.1058 vs -0.0726).",
        "hypothesis_evaluation": "The hypothesis that multiplying linearity, volume decoupling, and gap ratios identifies high-conviction reversals is partially refuted by the current results. The interaction between these three distinct signals appears to be too restrictive or 'noisy'. Specifically, the 'open - delay(close, 1)' component might be introducing excessive volatility rather than acting as a clean scaling factor. The complexity of the primary factor (using 5 base features and multiple nested functions) may be leading to poor generalization.",
        "decision": false,
        "reason": "The current factors are over-engineered (high base feature count and complex scaling). By shifting the focus to the divergence between price direction and volume support (using a rolling Z-score of the correlation), we reduce the noise introduced by the overnight gap. Simplifying the denominator from 'high - low' to a more stable rolling volatility measure (like TS_STD) should also improve the Information Ratio by smoothing the signal."
      }
    },
    "22a87c94cf225d66": {
      "factor_id": "22a87c94cf225d66",
      "factor_name": "Institutional_Gap_Exhaustion_V2",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * (1 - TS_CORR($close, $volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * (1 - TS_CORR($close, $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Exhaustion_V2\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures institutional re-pricing by identifying days where the overnight gap is significant relative to the intraday volatility, specifically when the preceding 20-day price-volume relationship shows signs of weakening (low correlation).",
      "factor_formulation": "\\frac{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1))}{\\text{high} - \\text{low} + 1e-8} \\times (1 - \\text{TS\\_CORR}(\\text{close}, \\text{volume}, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "20b0dc7bace0",
        "parent_trajectory_ids": [
          "af51ae859843",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Exhaustion Pivot' factor identifies high-conviction reversals by multiplying the 10-day price linearity (RSQR10) with the inverse of the 20-day price-volume correlation (1-CORR20), then scaling this exhaustion signal by the ratio of the overnight gap to the total daily range.\n                Concise Observation: Parent 1 (RankIC 0.023) captures trend fatigue through price-volume decoupling, while Parent 2 (RankIC 0.026) captures sentiment through overnight gaps; combining them filters out false exhaustion signals that lack immediate sentiment triggers.\n                Concise Justification: Linear trends (high RSQR) that decouple from volume (low CORR) represent 'hollow' moves; applying an overnight gap weight ensures the factor captures the exact moment institutional sentiment shifts to exploit that hollow structure.\n                Concise Knowledge: If a price trend is highly linear but loses volume support, it is prone to reversal; when such structural exhaustion is met with a significant overnight gap relative to intraday volatility, it signals institutional re-pricing rather than retail noise.\n                concise Specification: Calculate RSQR of close prices over 10 days, CORR of close and volume over 20 days, and the ratio of (Open_t - Close_{t-1}) to (High_t - Low_t); the final factor is (RSQR10 * (1 - CORR20) * (Gap / Range)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:16:28.913658"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1163587196473948,
        "ICIR": 0.0389059651700415,
        "1day.excess_return_without_cost.std": 0.0043681538699438,
        "1day.excess_return_with_cost.annualized_return": -0.0087864077562177,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000160394713943,
        "1day.excess_return_without_cost.annualized_return": 0.0381739419184472,
        "1day.excess_return_with_cost.std": 0.0043685353569449,
        "Rank IC": 0.0206623476066447,
        "IC": 0.0052797753923496,
        "1day.excess_return_without_cost.max_drawdown": -0.1058284585823001,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.566474809059768,
        "1day.pa": 0.0,
        "l2.valid": 0.9964856836071614,
        "Rank ICIR": 0.1574860926185051,
        "l2.train": 0.9942890505815052,
        "1day.excess_return_with_cost.information_ratio": -0.1303728082496492,
        "1day.excess_return_with_cost.mean": -3.6917679647973926e-05
      },
      "feedback": {
        "observations": "The current iteration explored the 'Institutional Exhaustion Pivot' framework by combining price linearity, price-volume decoupling, and overnight gap dynamics. While the theoretical construction is sound, the performance metrics (IC: 0.0053, IR: 0.566) significantly underperform compared to the SOTA (IC: 0.0058, IR: 0.972). The 'Institutional_Exhaustion_Pivot_10_20' factor, despite its logical complexity, failed to capture the expected reversal alpha, and the 'Hollow_Trend_Reversal_ZScore' showed that cross-sectional ranking of these components did not bridge the gap to SOTA. The drawdown is also notably higher (-0.1058 vs -0.0726).",
        "hypothesis_evaluation": "The hypothesis that multiplying linearity, volume decoupling, and gap ratios identifies high-conviction reversals is partially refuted by the current results. The interaction between these three distinct signals appears to be too restrictive or 'noisy'. Specifically, the 'open - delay(close, 1)' component might be introducing excessive volatility rather than acting as a clean scaling factor. The complexity of the primary factor (using 5 base features and multiple nested functions) may be leading to poor generalization.",
        "decision": false,
        "reason": "The current factors are over-engineered (high base feature count and complex scaling). By shifting the focus to the divergence between price direction and volume support (using a rolling Z-score of the correlation), we reduce the noise introduced by the overnight gap. Simplifying the denominator from 'high - low' to a more stable rolling volatility measure (like TS_STD) should also improve the Information Ratio by smoothing the signal."
      }
    },
    "3af9a14e98e89f30": {
      "factor_id": "3af9a14e98e89f30",
      "factor_name": "Liquidity_Validated_Resonance_5D",
      "factor_expression": "(($high - $low) / $close * TS_MEAN($volume, 5)) / (ABS($open - DELAY($close, 1)) / TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / $close * TS_MEAN($volume, 5)) / (ABS($open - DELAY($close, 1)) / TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Resonance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor calculates the ratio of intraday price-volume resonance to the volume-normalized overnight gap. It identifies institutional conviction by rewarding price discovery occurring during high-volume intraday trading while penalizing gaps that occur on low relative liquidity, which often signal sentiment exhaustion.",
      "factor_formulation": "LVR_\\text{5D} = \\frac{((\\text{high} - \\text{low}) / \\text{close}) \\times \\text{TS_MEAN}(\\text{volume}, 5)}{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / \\text{TS_MEAN}(\\text{volume}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "35b14ca72a83",
        "parent_trajectory_ids": [
          "40b954f98281",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Volatility Resonance' factor, calculated as the ratio of the 5-day Intraday Range-Volume Resonance to the 5-day Volume-Normalized Overnight Gap, positively predicts future returns by identifying institutional conviction while filtering out overnight sentiment exhaustion.\n                Concise Observation: Parent 1 captures trend strength via intraday range and volume (RankIC 0.0240), while Parent 2 identifies mean-reversion from overnight gaps (RankIC 0.0244); combining them addresses the failure of trend signals during liquidity-driven exhaustion phases.\n                Concise Justification: By dividing the intraday resonance (KLEN * WVMA) by the normalized gap, we amplify signals where price discovery is supported by continuous trading volume and penalize stocks where the price jump occurred in a low-liquidity overnight environment.\n                Concise Knowledge: If intraday price-volume resonance is high and the overnight gap is small relative to historical volume, then the price move is likely driven by institutional conviction; conversely, if a large overnight gap occurs on low volume, it represents sentiment exhaustion and mean-reversion risk.\n                concise Specification: The factor is defined as ((High - Low) / Close * SMA(Volume, 5)) / (abs(Open - Prev_Close) / SMA(Volume, 5)). All components use a 5-day lookback period to ensure temporal alignment between the volatility and liquidity metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:19:43.778999"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1127947224378989,
        "ICIR": 0.0394922326806911,
        "1day.excess_return_without_cost.std": 0.0039921219556271,
        "1day.excess_return_with_cost.annualized_return": -0.0082360315181751,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000162302941731,
        "1day.excess_return_without_cost.annualized_return": 0.0386281001319865,
        "1day.excess_return_with_cost.std": 0.0039940985561356,
        "Rank IC": 0.0222599888069993,
        "IC": 0.0055118617922671,
        "1day.excess_return_without_cost.max_drawdown": -0.0917397977637186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6272072501193354,
        "1day.pa": 0.0,
        "l2.valid": 0.9964019623273406,
        "Rank ICIR": 0.1633104610682,
        "l2.train": 0.9939345022610504,
        "1day.excess_return_with_cost.information_ratio": -0.1336628583982484,
        "1day.excess_return_with_cost.mean": -3.4605174446114094e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Volatility Resonance' hypothesis. While all three factors were successfully implemented, the collective performance (IC: 0.0055, IR: 0.627) failed to surpass the current SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Validated_Resonance_5D' and its variants aimed to capture institutional conviction by scaling intraday range by volume and penalizing overnight gaps. However, the current formulations appear to have higher drawdown (-0.0917 vs -0.0725) and lower risk-adjusted returns than the SOTA, suggesting that the interaction between volume and the overnight gap might be too noisy or improperly scaled in the current linear ratio format.",
        "hypothesis_evaluation": "The hypothesis that the ratio of intraday resonance to overnight gaps predicts returns is partially supported by the positive IC, but the current mathematical implementation is suboptimal. The use of 'TS_MEAN(volume, 5)' in both the numerator and denominator of the first factor (LVR_5D) essentially cancels out the volume effect, reducing it to a price-only ratio of (Intraday Range / Overnight Gap). This negates the 'Liquidity-Validated' aspect of the hypothesis. Furthermore, the high drawdown suggests that the factor may be sensitive to extreme price gaps that do not necessarily represent sentiment exhaustion.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address the 'volume cancellation' issue. Instead of a simple ratio of means, we should calculate a daily 'Intensity' score and then average it. By using (Intraday Range / (Overnight Gap + Average True Range)) weighted by (Daily Volume / 5-day Average Volume), we ensure that the liquidity validation is applied at the daily level before aggregation. This prevents a single high-volume day from distorting the 5-day mean and provides a more robust measure of 'conviction' versus 'noise'."
      }
    },
    "2a14c2d6aeb23110": {
      "factor_id": "2a14c2d6aeb23110",
      "factor_name": "Resonance_Gap_Efficiency_Rank_5D",
      "factor_expression": "RANK((($high - $low) * POW(TS_MEAN($volume, 5), 2)) / (ABS($open - DELAY($close, 1)) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) * POW(TS_MEAN($volume, 5), 2)) / (ABS($open - DELAY($close, 1)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Resonance_Gap_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the resonance-to-gap ratio. It measures the efficiency of price movement by comparing the intraday range (scaled by volume) against the overnight gap (normalized by volume). High values indicate strong intraday trend persistence supported by liquidity.",
      "factor_formulation": "RGER_\\text{5D} = \\text{RANK}\\left(\\frac{(\\text{high} - \\text{low}) \\times \\text{TS_MEAN}(\\text{volume}, 5)^2}{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "35b14ca72a83",
        "parent_trajectory_ids": [
          "40b954f98281",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Volatility Resonance' factor, calculated as the ratio of the 5-day Intraday Range-Volume Resonance to the 5-day Volume-Normalized Overnight Gap, positively predicts future returns by identifying institutional conviction while filtering out overnight sentiment exhaustion.\n                Concise Observation: Parent 1 captures trend strength via intraday range and volume (RankIC 0.0240), while Parent 2 identifies mean-reversion from overnight gaps (RankIC 0.0244); combining them addresses the failure of trend signals during liquidity-driven exhaustion phases.\n                Concise Justification: By dividing the intraday resonance (KLEN * WVMA) by the normalized gap, we amplify signals where price discovery is supported by continuous trading volume and penalize stocks where the price jump occurred in a low-liquidity overnight environment.\n                Concise Knowledge: If intraday price-volume resonance is high and the overnight gap is small relative to historical volume, then the price move is likely driven by institutional conviction; conversely, if a large overnight gap occurs on low volume, it represents sentiment exhaustion and mean-reversion risk.\n                concise Specification: The factor is defined as ((High - Low) / Close * SMA(Volume, 5)) / (abs(Open - Prev_Close) / SMA(Volume, 5)). All components use a 5-day lookback period to ensure temporal alignment between the volatility and liquidity metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:19:43.778999"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1127947224378989,
        "ICIR": 0.0394922326806911,
        "1day.excess_return_without_cost.std": 0.0039921219556271,
        "1day.excess_return_with_cost.annualized_return": -0.0082360315181751,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000162302941731,
        "1day.excess_return_without_cost.annualized_return": 0.0386281001319865,
        "1day.excess_return_with_cost.std": 0.0039940985561356,
        "Rank IC": 0.0222599888069993,
        "IC": 0.0055118617922671,
        "1day.excess_return_without_cost.max_drawdown": -0.0917397977637186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6272072501193354,
        "1day.pa": 0.0,
        "l2.valid": 0.9964019623273406,
        "Rank ICIR": 0.1633104610682,
        "l2.train": 0.9939345022610504,
        "1day.excess_return_with_cost.information_ratio": -0.1336628583982484,
        "1day.excess_return_with_cost.mean": -3.4605174446114094e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Volatility Resonance' hypothesis. While all three factors were successfully implemented, the collective performance (IC: 0.0055, IR: 0.627) failed to surpass the current SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Validated_Resonance_5D' and its variants aimed to capture institutional conviction by scaling intraday range by volume and penalizing overnight gaps. However, the current formulations appear to have higher drawdown (-0.0917 vs -0.0725) and lower risk-adjusted returns than the SOTA, suggesting that the interaction between volume and the overnight gap might be too noisy or improperly scaled in the current linear ratio format.",
        "hypothesis_evaluation": "The hypothesis that the ratio of intraday resonance to overnight gaps predicts returns is partially supported by the positive IC, but the current mathematical implementation is suboptimal. The use of 'TS_MEAN(volume, 5)' in both the numerator and denominator of the first factor (LVR_5D) essentially cancels out the volume effect, reducing it to a price-only ratio of (Intraday Range / Overnight Gap). This negates the 'Liquidity-Validated' aspect of the hypothesis. Furthermore, the high drawdown suggests that the factor may be sensitive to extreme price gaps that do not necessarily represent sentiment exhaustion.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address the 'volume cancellation' issue. Instead of a simple ratio of means, we should calculate a daily 'Intensity' score and then average it. By using (Intraday Range / (Overnight Gap + Average True Range)) weighted by (Daily Volume / 5-day Average Volume), we ensure that the liquidity validation is applied at the daily level before aggregation. This prevents a single high-volume day from distorting the 5-day mean and provides a more robust measure of 'conviction' versus 'noise'."
      }
    },
    "50c55e21c72c5349": {
      "factor_id": "50c55e21c72c5349",
      "factor_name": "Intraday_Conviction_ZScore_5D",
      "factor_expression": "ZSCORE((($high - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) / (ABS($open - DELAY($close, 1)) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($high - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) / (ABS($open - DELAY($close, 1)) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Conviction_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor standardizes the intraday volatility-liquidity resonance relative to the overnight shock. It uses Z-score to identify stocks where the intraday participation significantly outweighs the overnight sentiment-driven gap, suggesting a more sustainable trend.",
      "factor_formulation": "ICZ_\\text{5D} = \\text{ZSCORE}\\left(\\frac{(\\text{high} - \\text{low}) / \\text{TS_MEAN}(\\text{high} - \\text{low}, 5)}{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / \\text{TS_MEAN}(\\text{volume}, 5) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "35b14ca72a83",
        "parent_trajectory_ids": [
          "40b954f98281",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Volatility Resonance' factor, calculated as the ratio of the 5-day Intraday Range-Volume Resonance to the 5-day Volume-Normalized Overnight Gap, positively predicts future returns by identifying institutional conviction while filtering out overnight sentiment exhaustion.\n                Concise Observation: Parent 1 captures trend strength via intraday range and volume (RankIC 0.0240), while Parent 2 identifies mean-reversion from overnight gaps (RankIC 0.0244); combining them addresses the failure of trend signals during liquidity-driven exhaustion phases.\n                Concise Justification: By dividing the intraday resonance (KLEN * WVMA) by the normalized gap, we amplify signals where price discovery is supported by continuous trading volume and penalize stocks where the price jump occurred in a low-liquidity overnight environment.\n                Concise Knowledge: If intraday price-volume resonance is high and the overnight gap is small relative to historical volume, then the price move is likely driven by institutional conviction; conversely, if a large overnight gap occurs on low volume, it represents sentiment exhaustion and mean-reversion risk.\n                concise Specification: The factor is defined as ((High - Low) / Close * SMA(Volume, 5)) / (abs(Open - Prev_Close) / SMA(Volume, 5)). All components use a 5-day lookback period to ensure temporal alignment between the volatility and liquidity metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:19:43.778999"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1127947224378989,
        "ICIR": 0.0394922326806911,
        "1day.excess_return_without_cost.std": 0.0039921219556271,
        "1day.excess_return_with_cost.annualized_return": -0.0082360315181751,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000162302941731,
        "1day.excess_return_without_cost.annualized_return": 0.0386281001319865,
        "1day.excess_return_with_cost.std": 0.0039940985561356,
        "Rank IC": 0.0222599888069993,
        "IC": 0.0055118617922671,
        "1day.excess_return_without_cost.max_drawdown": -0.0917397977637186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6272072501193354,
        "1day.pa": 0.0,
        "l2.valid": 0.9964019623273406,
        "Rank ICIR": 0.1633104610682,
        "l2.train": 0.9939345022610504,
        "1day.excess_return_with_cost.information_ratio": -0.1336628583982484,
        "1day.excess_return_with_cost.mean": -3.4605174446114094e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Volatility Resonance' hypothesis. While all three factors were successfully implemented, the collective performance (IC: 0.0055, IR: 0.627) failed to surpass the current SOTA (IC: 0.0058, IR: 0.972). The 'Liquidity_Validated_Resonance_5D' and its variants aimed to capture institutional conviction by scaling intraday range by volume and penalizing overnight gaps. However, the current formulations appear to have higher drawdown (-0.0917 vs -0.0725) and lower risk-adjusted returns than the SOTA, suggesting that the interaction between volume and the overnight gap might be too noisy or improperly scaled in the current linear ratio format.",
        "hypothesis_evaluation": "The hypothesis that the ratio of intraday resonance to overnight gaps predicts returns is partially supported by the positive IC, but the current mathematical implementation is suboptimal. The use of 'TS_MEAN(volume, 5)' in both the numerator and denominator of the first factor (LVR_5D) essentially cancels out the volume effect, reducing it to a price-only ratio of (Intraday Range / Overnight Gap). This negates the 'Liquidity-Validated' aspect of the hypothesis. Furthermore, the high drawdown suggests that the factor may be sensitive to extreme price gaps that do not necessarily represent sentiment exhaustion.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address the 'volume cancellation' issue. Instead of a simple ratio of means, we should calculate a daily 'Intensity' score and then average it. By using (Intraday Range / (Overnight Gap + Average True Range)) weighted by (Daily Volume / 5-day Average Volume), we ensure that the liquidity validation is applied at the daily level before aggregation. This prevents a single high-volume day from distorting the 5-day mean and provides a more robust measure of 'conviction' versus 'noise'."
      }
    },
    "da196f502510c5ff": {
      "factor_id": "da196f502510c5ff",
      "factor_name": "Stealth_Institutional_Accumulation_15D",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_STD($return, 5) + 1e-8)) * (TS_SUM(($return > 0 ? $volume * $return : 0), 15) / (TS_SUM($volume * ABS($return), 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(15), 15), 2) / (TS_STD($close / DELAY($close, 1) - 1, 15) + 1e-8)) * (TS_SUM((($close / DELAY($close, 1) - 1) > 0 ? $volume * ($close / DELAY($close, 1) - 1) : 0), 15) / (TS_SUM($volume * ABS($close / DELAY($close, 1) - 1), 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Stealth_Institutional_Accumulation_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional accumulation by combining price trend linearity (R-squared) with volume-weighted upside intensity, normalized by short-term volatility. High linearity and volume-weighted upside indicate high-conviction buying, while low volatility ensures the trend is 'efficient' and not driven by noise.",
      "factor_formulation": "\\text{Factor} = \\frac{\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2}{\\text{TS\\_STD}(\\text{return}, 5) + 1e-8} \\times \\frac{\\text{TS\\_SUM}(\\text{volume} \\times (\\text{return} > 0 ? \\text{return} : 0), 15)}{\\text{TS\\_SUM}(\\text{volume} \\times \\text{ABS}(\\text{return}), 15) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "a76cc6a74dee",
        "parent_trajectory_ids": [
          "432771960cc4",
          "0144c84c5654"
        ],
        "hypothesis": "Hypothesis: The 'Stealth Institutional Convergence' factor, calculated as the product of a 10-day price trend linearity (R-squared) and a 15-day volume-weighted upside intensity ratio, normalized by 5-day price volatility, positively predicts future returns by identifying high-conviction institutional accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0248) suggests that linear price trends are reliable, while Parent 2 (RankIC 0.0236) indicates that volume-weighted upside bias captures liquidity absorption, but both suffer from false positives when used in isolation.\n                Concise Justification: By multiplying price linearity with volume-weighted upside intensity and dividing by volatility, we isolate 'efficient' accumulation where institutions move prices steadily with conviction, filtering out speculative volatility that lacks structural volume support.\n                Concise Knowledge: If a price trend exhibits high linearity and low volatility while being supported by asymmetric volume-weighted positive returns, it indicates institutional accumulation; conversely, high volume asymmetry with erratic price movement often reflects retail-driven noise or low-liquidity manipulation.\n                concise Specification: The factor is defined as [RSQR(close, 10) / Std(returns, 5)] * [Sum(volume * (returns > 0 ? returns : 0), 15) / Sum(volume * abs(returns), 15)], where RSQR measures the coefficient of determination of price against a time trend over 10 days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:32:36.121847"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.099204283348859,
        "ICIR": 0.0492083409215249,
        "1day.excess_return_without_cost.std": 0.0040270458213739,
        "1day.excess_return_with_cost.annualized_return": 0.0456408573360667,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003890867888525,
        "1day.excess_return_without_cost.annualized_return": 0.0926026557468963,
        "1day.excess_return_with_cost.std": 0.0040277887286513,
        "Rank IC": 0.0228458259311759,
        "IC": 0.0066265005394101,
        "1day.excess_return_without_cost.max_drawdown": -0.0866459789358339,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4905563266096065,
        "1day.pa": 0.0,
        "l2.valid": 0.9966126029926172,
        "Rank ICIR": 0.1733592309023739,
        "l2.train": 0.9943552323771646,
        "1day.excess_return_with_cost.information_ratio": 0.7345115562021487,
        "1day.excess_return_with_cost.mean": 0.0001917683081347
      },
      "feedback": {
        "observations": "The experiment results demonstrate a significant improvement over the SOTA result. The 'Linear_Upside_Efficiency_Factor' and 'Stealth_Institutional_Accumulation_15D' implementations have successfully captured alpha, with the Information Ratio (IR) increasing from 0.97 to 1.49 and the Annualized Return nearly doubling from 5.2% to 9.26%. The IC also showed a healthy improvement to 0.0066. However, the Max Drawdown slightly worsened (-0.086 vs -0.072), suggesting that while the signal is stronger, it may introduce specific period risks or higher volatility in the long-short portfolio.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining price trend linearity (R-squared) with volume-weighted upside intensity identifies high-conviction institutional movement. The use of RANK in the 'Linear_Upside_Efficiency_Factor' likely contributed to the robustness of the signal by neutralizing the scale differences between the linearity component and the volume-weighted component. The normalization by volatility effectively filters out 'noisy' price action, confirming that 'efficient' trends are more predictive of institutional accumulation.",
        "decision": true,
        "reason": "While the current linearity (R-squared) is effective, institutional accumulation is often better characterized by price and volume moving in tandem. Using price-volume correlation as a proxy for 'conviction' and switching to downside deviation (Sortino-style risk) instead of standard deviation (Sharpe-style risk) allows the factor to remain high during strong, low-noise rallies even if volatility is high, as long as that volatility is primarily on the upside. This should improve the Information Ratio and potentially reduce the Max Drawdown observed in the current iteration."
      }
    },
    "cb50e412f0da1733": {
      "factor_id": "cb50e412f0da1733",
      "factor_name": "Linear_Upside_Efficiency_Factor",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10) / (TS_STD($return, 10) + 1e-8)) * RANK(TS_SUM($return * $volume, 10) / (TS_SUM(ABS($return) * $volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)) * RANK(TS_SUM(TS_PCTCHANGE($close, 1) * $volume, 10) / (TS_SUM(ABS(TS_PCTCHANGE($close, 1)) * $volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Linear_Upside_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the institutional convergence hypothesis. It focuses on the ratio of price trend linearity to volatility, scaled by the relative volume-weighted strength of positive returns. This helps isolate steady, volume-supported price appreciation.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}\\left(\\frac{\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)}{\\text{TS\\_STD}(\\text{return}, 10) + 1e-8}\\right) \\times \\text{RANK}\\left(\\frac{\\text{TS\\_SUM}(\\text{return} \\times \\text{volume}, 10)}{\\text{TS\\_SUM}(\\text{ABS}(\\text{return}) \\times \\text{volume}, 10) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "a76cc6a74dee",
        "parent_trajectory_ids": [
          "432771960cc4",
          "0144c84c5654"
        ],
        "hypothesis": "Hypothesis: The 'Stealth Institutional Convergence' factor, calculated as the product of a 10-day price trend linearity (R-squared) and a 15-day volume-weighted upside intensity ratio, normalized by 5-day price volatility, positively predicts future returns by identifying high-conviction institutional accumulation.\n                Concise Observation: Parent 1 (RankIC 0.0248) suggests that linear price trends are reliable, while Parent 2 (RankIC 0.0236) indicates that volume-weighted upside bias captures liquidity absorption, but both suffer from false positives when used in isolation.\n                Concise Justification: By multiplying price linearity with volume-weighted upside intensity and dividing by volatility, we isolate 'efficient' accumulation where institutions move prices steadily with conviction, filtering out speculative volatility that lacks structural volume support.\n                Concise Knowledge: If a price trend exhibits high linearity and low volatility while being supported by asymmetric volume-weighted positive returns, it indicates institutional accumulation; conversely, high volume asymmetry with erratic price movement often reflects retail-driven noise or low-liquidity manipulation.\n                concise Specification: The factor is defined as [RSQR(close, 10) / Std(returns, 5)] * [Sum(volume * (returns > 0 ? returns : 0), 15) / Sum(volume * abs(returns), 15)], where RSQR measures the coefficient of determination of price against a time trend over 10 days.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:32:36.121847"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.099204283348859,
        "ICIR": 0.0492083409215249,
        "1day.excess_return_without_cost.std": 0.0040270458213739,
        "1day.excess_return_with_cost.annualized_return": 0.0456408573360667,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003890867888525,
        "1day.excess_return_without_cost.annualized_return": 0.0926026557468963,
        "1day.excess_return_with_cost.std": 0.0040277887286513,
        "Rank IC": 0.0228458259311759,
        "IC": 0.0066265005394101,
        "1day.excess_return_without_cost.max_drawdown": -0.0866459789358339,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4905563266096065,
        "1day.pa": 0.0,
        "l2.valid": 0.9966126029926172,
        "Rank ICIR": 0.1733592309023739,
        "l2.train": 0.9943552323771646,
        "1day.excess_return_with_cost.information_ratio": 0.7345115562021487,
        "1day.excess_return_with_cost.mean": 0.0001917683081347
      },
      "feedback": {
        "observations": "The experiment results demonstrate a significant improvement over the SOTA result. The 'Linear_Upside_Efficiency_Factor' and 'Stealth_Institutional_Accumulation_15D' implementations have successfully captured alpha, with the Information Ratio (IR) increasing from 0.97 to 1.49 and the Annualized Return nearly doubling from 5.2% to 9.26%. The IC also showed a healthy improvement to 0.0066. However, the Max Drawdown slightly worsened (-0.086 vs -0.072), suggesting that while the signal is stronger, it may introduce specific period risks or higher volatility in the long-short portfolio.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining price trend linearity (R-squared) with volume-weighted upside intensity identifies high-conviction institutional movement. The use of RANK in the 'Linear_Upside_Efficiency_Factor' likely contributed to the robustness of the signal by neutralizing the scale differences between the linearity component and the volume-weighted component. The normalization by volatility effectively filters out 'noisy' price action, confirming that 'efficient' trends are more predictive of institutional accumulation.",
        "decision": true,
        "reason": "While the current linearity (R-squared) is effective, institutional accumulation is often better characterized by price and volume moving in tandem. Using price-volume correlation as a proxy for 'conviction' and switching to downside deviation (Sortino-style risk) instead of standard deviation (Sharpe-style risk) allows the factor to remain high during strong, low-noise rallies even if volatility is high, as long as that volatility is primarily on the upside. This should improve the Information Ratio and potentially reduce the Max Drawdown observed in the current iteration."
      }
    },
    "b409759f81e6ef4e": {
      "factor_id": "b409759f81e6ef4e",
      "factor_name": "Liquidity_Exhaustion_Reversal_60D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 20)) * (-ZSCORE(($open / ($DELAY($close, 1) + 1e-8) - 1) / (TS_MEAN($volume, 5) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 60)) * (-ZSCORE(($open / DELAY($close, 1) - 1) / (TS_MEAN($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction reversal points by combining long-term price-volume capitulation with short-term sentiment exhaustion. Capitulation is defined by a 60-day price decline correlated with volume, while exhaustion is captured by a volume-normalized overnight gap. The factor targets assets where selling pressure has likely peaked across multiple participant scales.",
      "factor_formulation": "Capitulation = ZSCORE(TS\\_PCTCHANGE(close, 60) * TS\\_CORR(close, volume, 20)) \\\\ Exhaustion = ZSCORE((open / DELAY(close, 1) - 1) / (TS\\_MEAN(volume, 5) + 1e-8)) \\\\ Factor = Capitulation * (-Exhaustion)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "2e2ad860588f",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Multi-Scale Liquidity Exhaustion Reversal' factor captures high-conviction turning points by multiplying a 60-day price-volume capitulation signal (ROC60 * Correlation(Price, Volume, 20)) with a volume-normalized overnight gap measure, identifying assets where both institutional selling and retail sentiment have reached exhaustion.\n                Concise Observation: Parent 1 (RankIC=0.0234) identifies long-term oversold conditions but lacks timing, while Parent 2 (RankIC=0.0244) captures short-term sentiment gaps; combining them addresses the 'falling knife' risk by requiring a specific tactical gap to trigger the entry.\n                Concise Justification: Long-term price-volume divergence indicates institutional capitulation, while a volume-normalized overnight gap represents retail sentiment exhaustion; their product isolates assets where liquidity-driven selling is most likely to reverse into a recovery phase.\n                Concise Knowledge: If long-term structural price declines are validated by negative price-volume correlations and then followed by a low-volume overnight gap, the probability of a mean-reversion event increases due to the exhaustion of selling pressure across multiple participant scales.\n                concise Specification: Define Capitulation as (ROC_60 * Correlation(Close, Volume, 20)); define Gap_Exhaustion as (Open / Close_prev - 1) / (SMA(Volume, 5)); the final factor is the product of the Z-scored Capitulation and the negative Z-scored Gap_Exhaustion to signal long-term oversold assets with short-term exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:40:19.290573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1247784976581043,
        "ICIR": 0.0284891380433587,
        "1day.excess_return_without_cost.std": 0.0043147995375779,
        "1day.excess_return_with_cost.annualized_return": 0.0001693268239725,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001999104870992,
        "1day.excess_return_without_cost.annualized_return": 0.0475786959296192,
        "1day.excess_return_with_cost.std": 0.0043145102068784,
        "Rank IC": 0.0223170990384345,
        "IC": 0.0039465506394682,
        "1day.excess_return_without_cost.max_drawdown": -0.1100803283902266,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.71476525374449,
        "1day.pa": 0.0,
        "l2.valid": 0.9966159004264684,
        "Rank ICIR": 0.1633604956068002,
        "l2.train": 0.9939830035527862,
        "1day.excess_return_with_cost.information_ratio": 0.002543933668793,
        "1day.excess_return_with_cost.mean": 7.114572435823057e-07
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity Exhaustion' hypothesis. While the factors successfully implemented the logic of combining long-term price-volume correlation with short-term gap signals, the overall performance (IC: 0.0039, IR: 0.71) failed to surpass the current SOTA (IC: 0.0058, IR: 0.97). The 'Liquidity_Exhaustion_Reversal_60D' factor used a multiplicative approach with Z-scores, which may have introduced noise due to the compounding of outliers. The 'Structural_Capitulation_Timing_Factor' utilized ranks to handle outliers but likely lost signal intensity. The 'Retail_Institutional_Exhaustion_Index' focused on volume volatility but might have missed the directional 'capitulation' aspect by using absolute values of the gap.",
        "hypothesis_evaluation": "The hypothesis that multiplying long-term capitulation with short-term exhaustion identifies high-conviction turning points is partially supported by the positive IC, but the implementation is currently too noisy. The use of volume as a denominator in 'Exhaustion' (volume-normalized gap) shows promise but needs a more robust normalization method than simple volume or volume standard deviation, as extreme low-volume days can create artificial signal spikes.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors used up to 5-6 base features; the new approach will simplify the interaction by using price volatility as the primary normalizer for gaps rather than raw volume. 2. Robustness: Replacing the product of Z-scores with a conditional logic or a more stable 'Relative Volume' multiplier will reduce the impact of extreme outliers. 3. Theoretical Alignment: True exhaustion occurs when price moves sharply on high relative volume, suggesting a climax; the current factors may be capturing low-liquidity noise instead of high-conviction exhaustion."
      }
    },
    "242807086d6f1e45": {
      "factor_id": "242807086d6f1e45",
      "factor_name": "Structural_Capitulation_Timing_Factor",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 20)) + RANK(-($open - $DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 20)) + RANK(-($open - DELAY($close, 1)) / (TS_MEAN($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Capitulation_Timing_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the liquidity exhaustion hypothesis focusing on the interaction between long-term structural decline and short-term liquidity shocks. It uses the rank of price-volume divergence multiplied by the rank of the overnight gap relative to recent volume to isolate stocks with the highest probability of a mean-reversion event.",
      "factor_formulation": "Factor = RANK(TS\\_PCTCHANGE(close, 60) * TS\\_CORR(close, volume, 20)) + RANK(-(open - DELAY(close, 1)) / (TS\\_MEAN(volume, 10) + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "2e2ad860588f",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Multi-Scale Liquidity Exhaustion Reversal' factor captures high-conviction turning points by multiplying a 60-day price-volume capitulation signal (ROC60 * Correlation(Price, Volume, 20)) with a volume-normalized overnight gap measure, identifying assets where both institutional selling and retail sentiment have reached exhaustion.\n                Concise Observation: Parent 1 (RankIC=0.0234) identifies long-term oversold conditions but lacks timing, while Parent 2 (RankIC=0.0244) captures short-term sentiment gaps; combining them addresses the 'falling knife' risk by requiring a specific tactical gap to trigger the entry.\n                Concise Justification: Long-term price-volume divergence indicates institutional capitulation, while a volume-normalized overnight gap represents retail sentiment exhaustion; their product isolates assets where liquidity-driven selling is most likely to reverse into a recovery phase.\n                Concise Knowledge: If long-term structural price declines are validated by negative price-volume correlations and then followed by a low-volume overnight gap, the probability of a mean-reversion event increases due to the exhaustion of selling pressure across multiple participant scales.\n                concise Specification: Define Capitulation as (ROC_60 * Correlation(Close, Volume, 20)); define Gap_Exhaustion as (Open / Close_prev - 1) / (SMA(Volume, 5)); the final factor is the product of the Z-scored Capitulation and the negative Z-scored Gap_Exhaustion to signal long-term oversold assets with short-term exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:40:19.290573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1247784976581043,
        "ICIR": 0.0284891380433587,
        "1day.excess_return_without_cost.std": 0.0043147995375779,
        "1day.excess_return_with_cost.annualized_return": 0.0001693268239725,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001999104870992,
        "1day.excess_return_without_cost.annualized_return": 0.0475786959296192,
        "1day.excess_return_with_cost.std": 0.0043145102068784,
        "Rank IC": 0.0223170990384345,
        "IC": 0.0039465506394682,
        "1day.excess_return_without_cost.max_drawdown": -0.1100803283902266,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.71476525374449,
        "1day.pa": 0.0,
        "l2.valid": 0.9966159004264684,
        "Rank ICIR": 0.1633604956068002,
        "l2.train": 0.9939830035527862,
        "1day.excess_return_with_cost.information_ratio": 0.002543933668793,
        "1day.excess_return_with_cost.mean": 7.114572435823057e-07
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity Exhaustion' hypothesis. While the factors successfully implemented the logic of combining long-term price-volume correlation with short-term gap signals, the overall performance (IC: 0.0039, IR: 0.71) failed to surpass the current SOTA (IC: 0.0058, IR: 0.97). The 'Liquidity_Exhaustion_Reversal_60D' factor used a multiplicative approach with Z-scores, which may have introduced noise due to the compounding of outliers. The 'Structural_Capitulation_Timing_Factor' utilized ranks to handle outliers but likely lost signal intensity. The 'Retail_Institutional_Exhaustion_Index' focused on volume volatility but might have missed the directional 'capitulation' aspect by using absolute values of the gap.",
        "hypothesis_evaluation": "The hypothesis that multiplying long-term capitulation with short-term exhaustion identifies high-conviction turning points is partially supported by the positive IC, but the implementation is currently too noisy. The use of volume as a denominator in 'Exhaustion' (volume-normalized gap) shows promise but needs a more robust normalization method than simple volume or volume standard deviation, as extreme low-volume days can create artificial signal spikes.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors used up to 5-6 base features; the new approach will simplify the interaction by using price volatility as the primary normalizer for gaps rather than raw volume. 2. Robustness: Replacing the product of Z-scores with a conditional logic or a more stable 'Relative Volume' multiplier will reduce the impact of extreme outliers. 3. Theoretical Alignment: True exhaustion occurs when price moves sharply on high relative volume, suggesting a climax; the current factors may be capturing low-liquidity noise instead of high-conviction exhaustion."
      }
    },
    "4faa6182086b5ca2": {
      "factor_id": "4faa6182086b5ca2",
      "factor_name": "Retail_Institutional_Exhaustion_Index",
      "factor_expression": "ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(ABS($open - $DELAY($close, 1)) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, $volume, 20)) * ZSCORE(ABS($open - DELAY($close, 1)) / (TS_STD($volume, 20) + 0.00000001))\" # Your output factor expression will be filled in here\n    name = \"Retail_Institutional_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the divergence between institutional selling (long-term price-volume trend) and retail panic (short-term gap volatility). By normalizing the overnight gap with the 20-day volume standard deviation, it identifies where price gaps are disproportionately large relative to recent liquidity, signaling a climax in selling pressure.",
      "factor_formulation": "Factor = ZSCORE(TS\\_CORR(close, volume, 20)) * ZSCORE(ABS(open - DELAY(close, 1)) / (TS\\_STD(volume, 20) + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "2e2ad860588f",
        "parent_trajectory_ids": [
          "ee9a7812274d",
          "ac0ab75c4337"
        ],
        "hypothesis": "Hypothesis: The 'Multi-Scale Liquidity Exhaustion Reversal' factor captures high-conviction turning points by multiplying a 60-day price-volume capitulation signal (ROC60 * Correlation(Price, Volume, 20)) with a volume-normalized overnight gap measure, identifying assets where both institutional selling and retail sentiment have reached exhaustion.\n                Concise Observation: Parent 1 (RankIC=0.0234) identifies long-term oversold conditions but lacks timing, while Parent 2 (RankIC=0.0244) captures short-term sentiment gaps; combining them addresses the 'falling knife' risk by requiring a specific tactical gap to trigger the entry.\n                Concise Justification: Long-term price-volume divergence indicates institutional capitulation, while a volume-normalized overnight gap represents retail sentiment exhaustion; their product isolates assets where liquidity-driven selling is most likely to reverse into a recovery phase.\n                Concise Knowledge: If long-term structural price declines are validated by negative price-volume correlations and then followed by a low-volume overnight gap, the probability of a mean-reversion event increases due to the exhaustion of selling pressure across multiple participant scales.\n                concise Specification: Define Capitulation as (ROC_60 * Correlation(Close, Volume, 20)); define Gap_Exhaustion as (Open / Close_prev - 1) / (SMA(Volume, 5)); the final factor is the product of the Z-scored Capitulation and the negative Z-scored Gap_Exhaustion to signal long-term oversold assets with short-term exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:40:19.290573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1247784976581043,
        "ICIR": 0.0284891380433587,
        "1day.excess_return_without_cost.std": 0.0043147995375779,
        "1day.excess_return_with_cost.annualized_return": 0.0001693268239725,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001999104870992,
        "1day.excess_return_without_cost.annualized_return": 0.0475786959296192,
        "1day.excess_return_with_cost.std": 0.0043145102068784,
        "Rank IC": 0.0223170990384345,
        "IC": 0.0039465506394682,
        "1day.excess_return_without_cost.max_drawdown": -0.1100803283902266,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.71476525374449,
        "1day.pa": 0.0,
        "l2.valid": 0.9966159004264684,
        "Rank ICIR": 0.1633604956068002,
        "l2.train": 0.9939830035527862,
        "1day.excess_return_with_cost.information_ratio": 0.002543933668793,
        "1day.excess_return_with_cost.mean": 7.114572435823057e-07
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity Exhaustion' hypothesis. While the factors successfully implemented the logic of combining long-term price-volume correlation with short-term gap signals, the overall performance (IC: 0.0039, IR: 0.71) failed to surpass the current SOTA (IC: 0.0058, IR: 0.97). The 'Liquidity_Exhaustion_Reversal_60D' factor used a multiplicative approach with Z-scores, which may have introduced noise due to the compounding of outliers. The 'Structural_Capitulation_Timing_Factor' utilized ranks to handle outliers but likely lost signal intensity. The 'Retail_Institutional_Exhaustion_Index' focused on volume volatility but might have missed the directional 'capitulation' aspect by using absolute values of the gap.",
        "hypothesis_evaluation": "The hypothesis that multiplying long-term capitulation with short-term exhaustion identifies high-conviction turning points is partially supported by the positive IC, but the implementation is currently too noisy. The use of volume as a denominator in 'Exhaustion' (volume-normalized gap) shows promise but needs a more robust normalization method than simple volume or volume standard deviation, as extreme low-volume days can create artificial signal spikes.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors used up to 5-6 base features; the new approach will simplify the interaction by using price volatility as the primary normalizer for gaps rather than raw volume. 2. Robustness: Replacing the product of Z-scores with a conditional logic or a more stable 'Relative Volume' multiplier will reduce the impact of extreme outliers. 3. Theoretical Alignment: True exhaustion occurs when price moves sharply on high relative volume, suggesting a climax; the current factors may be capturing low-liquidity noise instead of high-conviction exhaustion."
      }
    },
    "9ba52248ff595679": {
      "factor_id": "9ba52248ff595679",
      "factor_name": "Inst_Gap_Stability_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Inst_Gap_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies sentiment-driven price jumps supported by intraday price floors. It combines the overnight gap (normalized by the day's range) with the lower shadow length adjusted by the 5-day volume volatility. A high value suggests that an upward gap is being defended by buyers with stable volume support.",
      "factor_formulation": "\\text{GapRatio} = \\frac{\\text{open} - \\text{delay}(\\text{close}, 1)}{\\text{high} - \\text{low} + 1e-8}, \\text{Support} = \\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{TS\\_STD}(\\text{volume}, 5) + 1e-8}, \\text{Factor} = \\text{GapRatio} \\times \\text{Support}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "ace9ffb9ea95",
        "parent_trajectory_ids": [
          "7c72861cebb3",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Stability' factor, calculated as the product of the overnight gap ratio and the ratio of lower shadow length to 5-day volume volatility, positively predicts returns by identifying sentiment-driven price jumps that are structurally supported by intraday price floors.\n                Concise Observation: Parent 1 (RankIC 0.0217) shows that lower shadow integrity relative to volume churn signals price floors, while Parent 2 (RankIC 0.0260) shows that overnight gaps capture sentiment; combining them addresses the weakness of gaps failing due to lack of intraday support.\n                Concise Justification: The overnight gap represents the initial sentiment shock, while the 'Support Integrity' component acts as a confirmation signal that the new price level is being defended by buyers, filtering out 'hollow' gaps that lack structural backing.\n                Concise Knowledge: If an overnight price gap is followed by a trading session where the lower shadow is large relative to volume volatility, then the gap is likely driven by institutional absorption rather than retail exhaustion; when volume volatility is low, price support levels are more reliable indicators of trend persistence.\n                concise Specification: The factor is defined as [(Open - Prev_Close) / (High - Low + epsilon)] * [ (min(Open, Close) - Low) / (StdDev(Volume, 5) + epsilon) ], where the first term captures normalized gap sentiment and the second term captures volatility-adjusted support integrity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:44:04.816332"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0832111906411441,
        "ICIR": 0.0626501831897188,
        "1day.excess_return_without_cost.std": 0.0039203208856371,
        "1day.excess_return_with_cost.annualized_return": 0.0254192231282865,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003043158033165,
        "1day.excess_return_without_cost.annualized_return": 0.0724271611893351,
        "1day.excess_return_with_cost.std": 0.0039213971624383,
        "Rank IC": 0.024265989738822,
        "IC": 0.0080450223217622,
        "1day.excess_return_without_cost.max_drawdown": -0.0714717535346067,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1975436944777005,
        "1day.pa": 0.0,
        "l2.valid": 0.9964330725614846,
        "Rank ICIR": 0.1929867599511263,
        "l2.train": 0.9934493153689355,
        "1day.excess_return_with_cost.information_ratio": 0.4201776662508015,
        "1day.excess_return_with_cost.mean": 0.0001068034585222
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Institutional Gap Stability' hypothesis by testing different normalization techniques (Day Range normalization, Cross-sectional Ranking, and Z-scoring) and varying the look-back period for volume volatility. The results show a significant improvement across all key performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.19, and the Annualized Return rose from 5.2% to 7.2%. The IC also improved from 0.0058 to 0.0080. The ZScored_Institutional_Absorption_5D and Ranked_Gap_Support_Integrity_10D variations appear to have better-captured market-relative sentiment compared to the raw product formulation.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight sentiment (gaps) with intraday support (lower shadows) relative to volume volatility predicts future returns. The improvement in metrics suggests that the 'Support' component (lower shadow / volume volatility) acts as an effective filter for identifying high-conviction institutional entries. The transition from a product-based formulation to ranked/z-scored additive structures improved the signal-to-noise ratio, indicating that the relative magnitude of these features across the universe is more predictive than their absolute values.",
        "decision": true,
        "reason": "While the current factors use volume volatility as a denominator to normalize the shadow, the theory of 'absorption' suggests that price support is strongest when volatility is contracting (stabilization). By replacing the raw gap with a volatility-adjusted gap (Gap/ATR) and refining the support measure to penalize high-volatility regimes more strictly, we can better isolate structural floors from random price noise. Additionally, maintaining a low complexity (ER < 6) remains a priority to ensure the 2% gain in annualized return is robust."
      }
    },
    "33c7cc36d38d0eb1": {
      "factor_id": "33c7cc36d38d0eb1",
      "factor_name": "Ranked_Gap_Support_Integrity_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK((MIN($open, $close) - $low) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK((MIN($open, $close) - $low) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Gap_Support_Integrity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the gap stability hypothesis. It measures the relative strength of the overnight sentiment shock and the integrity of the intraday price floor, using a 10-day window for volume volatility to ensure more stable institutional signature detection.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}\\left(\\frac{\\text{open} - \\text{delay}(\\text{close}, 1)}{\\text{delay}(\\text{close}, 1)}\\right) \\times \\text{RANK}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{TS\\_STD}(\\text{volume}, 10) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "ace9ffb9ea95",
        "parent_trajectory_ids": [
          "7c72861cebb3",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Stability' factor, calculated as the product of the overnight gap ratio and the ratio of lower shadow length to 5-day volume volatility, positively predicts returns by identifying sentiment-driven price jumps that are structurally supported by intraday price floors.\n                Concise Observation: Parent 1 (RankIC 0.0217) shows that lower shadow integrity relative to volume churn signals price floors, while Parent 2 (RankIC 0.0260) shows that overnight gaps capture sentiment; combining them addresses the weakness of gaps failing due to lack of intraday support.\n                Concise Justification: The overnight gap represents the initial sentiment shock, while the 'Support Integrity' component acts as a confirmation signal that the new price level is being defended by buyers, filtering out 'hollow' gaps that lack structural backing.\n                Concise Knowledge: If an overnight price gap is followed by a trading session where the lower shadow is large relative to volume volatility, then the gap is likely driven by institutional absorption rather than retail exhaustion; when volume volatility is low, price support levels are more reliable indicators of trend persistence.\n                concise Specification: The factor is defined as [(Open - Prev_Close) / (High - Low + epsilon)] * [ (min(Open, Close) - Low) / (StdDev(Volume, 5) + epsilon) ], where the first term captures normalized gap sentiment and the second term captures volatility-adjusted support integrity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:44:04.816332"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0832111906411441,
        "ICIR": 0.0626501831897188,
        "1day.excess_return_without_cost.std": 0.0039203208856371,
        "1day.excess_return_with_cost.annualized_return": 0.0254192231282865,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003043158033165,
        "1day.excess_return_without_cost.annualized_return": 0.0724271611893351,
        "1day.excess_return_with_cost.std": 0.0039213971624383,
        "Rank IC": 0.024265989738822,
        "IC": 0.0080450223217622,
        "1day.excess_return_without_cost.max_drawdown": -0.0714717535346067,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1975436944777005,
        "1day.pa": 0.0,
        "l2.valid": 0.9964330725614846,
        "Rank ICIR": 0.1929867599511263,
        "l2.train": 0.9934493153689355,
        "1day.excess_return_with_cost.information_ratio": 0.4201776662508015,
        "1day.excess_return_with_cost.mean": 0.0001068034585222
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Institutional Gap Stability' hypothesis by testing different normalization techniques (Day Range normalization, Cross-sectional Ranking, and Z-scoring) and varying the look-back period for volume volatility. The results show a significant improvement across all key performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.19, and the Annualized Return rose from 5.2% to 7.2%. The IC also improved from 0.0058 to 0.0080. The ZScored_Institutional_Absorption_5D and Ranked_Gap_Support_Integrity_10D variations appear to have better-captured market-relative sentiment compared to the raw product formulation.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight sentiment (gaps) with intraday support (lower shadows) relative to volume volatility predicts future returns. The improvement in metrics suggests that the 'Support' component (lower shadow / volume volatility) acts as an effective filter for identifying high-conviction institutional entries. The transition from a product-based formulation to ranked/z-scored additive structures improved the signal-to-noise ratio, indicating that the relative magnitude of these features across the universe is more predictive than their absolute values.",
        "decision": true,
        "reason": "While the current factors use volume volatility as a denominator to normalize the shadow, the theory of 'absorption' suggests that price support is strongest when volatility is contracting (stabilization). By replacing the raw gap with a volatility-adjusted gap (Gap/ATR) and refining the support measure to penalize high-volatility regimes more strictly, we can better isolate structural floors from random price noise. Additionally, maintaining a low complexity (ER < 6) remains a priority to ensure the 2% gain in annualized return is robust."
      }
    },
    "deeab16e9e5cce30": {
      "factor_id": "deeab16e9e5cce30",
      "factor_name": "ZScored_Institutional_Absorption_5D",
      "factor_expression": "ZSCORE($open - DELAY($close, 1)) + ZSCORE((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE($open - DELAY($close, 1)) + ZSCORE((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Institutional_Absorption_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor standardizes the gap sentiment and the lower shadow support using cross-sectional Z-scores. It focuses on identifying stocks where the gap is significant and the lower shadow is unusually large relative to volume churn compared to the rest of the market.",
      "factor_formulation": "\\text{Factor} = \\text{ZSCORE}(\\text{open} - \\text{delay}(\\text{close}, 1)) + \\text{ZSCORE}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{TS\\_STD}(\\text{volume}, 5) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "ace9ffb9ea95",
        "parent_trajectory_ids": [
          "7c72861cebb3",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Gap Stability' factor, calculated as the product of the overnight gap ratio and the ratio of lower shadow length to 5-day volume volatility, positively predicts returns by identifying sentiment-driven price jumps that are structurally supported by intraday price floors.\n                Concise Observation: Parent 1 (RankIC 0.0217) shows that lower shadow integrity relative to volume churn signals price floors, while Parent 2 (RankIC 0.0260) shows that overnight gaps capture sentiment; combining them addresses the weakness of gaps failing due to lack of intraday support.\n                Concise Justification: The overnight gap represents the initial sentiment shock, while the 'Support Integrity' component acts as a confirmation signal that the new price level is being defended by buyers, filtering out 'hollow' gaps that lack structural backing.\n                Concise Knowledge: If an overnight price gap is followed by a trading session where the lower shadow is large relative to volume volatility, then the gap is likely driven by institutional absorption rather than retail exhaustion; when volume volatility is low, price support levels are more reliable indicators of trend persistence.\n                concise Specification: The factor is defined as [(Open - Prev_Close) / (High - Low + epsilon)] * [ (min(Open, Close) - Low) / (StdDev(Volume, 5) + epsilon) ], where the first term captures normalized gap sentiment and the second term captures volatility-adjusted support integrity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:44:04.816332"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0832111906411441,
        "ICIR": 0.0626501831897188,
        "1day.excess_return_without_cost.std": 0.0039203208856371,
        "1day.excess_return_with_cost.annualized_return": 0.0254192231282865,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003043158033165,
        "1day.excess_return_without_cost.annualized_return": 0.0724271611893351,
        "1day.excess_return_with_cost.std": 0.0039213971624383,
        "Rank IC": 0.024265989738822,
        "IC": 0.0080450223217622,
        "1day.excess_return_without_cost.max_drawdown": -0.0714717535346067,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1975436944777005,
        "1day.pa": 0.0,
        "l2.valid": 0.9964330725614846,
        "Rank ICIR": 0.1929867599511263,
        "l2.train": 0.9934493153689355,
        "1day.excess_return_with_cost.information_ratio": 0.4201776662508015,
        "1day.excess_return_with_cost.mean": 0.0001068034585222
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Institutional Gap Stability' hypothesis by testing different normalization techniques (Day Range normalization, Cross-sectional Ranking, and Z-scoring) and varying the look-back period for volume volatility. The results show a significant improvement across all key performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.19, and the Annualized Return rose from 5.2% to 7.2%. The IC also improved from 0.0058 to 0.0080. The ZScored_Institutional_Absorption_5D and Ranked_Gap_Support_Integrity_10D variations appear to have better-captured market-relative sentiment compared to the raw product formulation.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight sentiment (gaps) with intraday support (lower shadows) relative to volume volatility predicts future returns. The improvement in metrics suggests that the 'Support' component (lower shadow / volume volatility) acts as an effective filter for identifying high-conviction institutional entries. The transition from a product-based formulation to ranked/z-scored additive structures improved the signal-to-noise ratio, indicating that the relative magnitude of these features across the universe is more predictive than their absolute values.",
        "decision": true,
        "reason": "While the current factors use volume volatility as a denominator to normalize the shadow, the theory of 'absorption' suggests that price support is strongest when volatility is contracting (stabilization). By replacing the raw gap with a volatility-adjusted gap (Gap/ATR) and refining the support measure to penalize high-volatility regimes more strictly, we can better isolate structural floors from random price noise. Additionally, maintaining a low complexity (ER < 6) remains a priority to ensure the 2% gain in annualized return is robust."
      }
    },
    "00d7c3ca6ef7a5a9": {
      "factor_id": "00d7c3ca6ef7a5a9",
      "factor_name": "Liquidity_Adjusted_Sentiment_Persistence_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (($high - $low + 1e-8) / (TS_STD($return, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / ((($high - $low) + 1e-8) / TS_STD(TS_PCTCHANGE($close, 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Sentiment_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction institutional moves by calculating the ratio of the overnight gap to the intraday range, normalized by the 5-day return volatility. A high value suggests that overnight sentiment is being absorbed efficiently with low intraday volatility, indicating institutional support.",
      "factor_formulation": "\\frac{(\\text{open}_t / \\text{close}_{t-1} - 1)}{(\\text{high}_t - \\text{low}_t + 1e-8) / \\text{TS_STD}(\\text{return}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "60137bf494c1",
        "parent_trajectory_ids": [
          "66ba76e16251",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Sentiment Persistence' factor, calculated as the ratio of the overnight gap (Open/Prev_Close - 1) to the intraday range (High-Low) normalized by the 5-day return volatility, identifies high-conviction institutional moves and predicts positive short-term returns.\n                Concise Observation: Parent 1 showed that volatility-normalized ranges identify liquidity consumption (RankIC 0.0217), while Parent 2 showed that overnight gaps relative to daily ranges capture sentiment (RankIC 0.0260); combining them addresses the 'quality' of the price gap.\n                Concise Justification: Normalizing the overnight sentiment signal by the intraday liquidity consumption ratio filters out 'noisy' gaps caused by retail speculation, isolating moves where institutional liquidity provides a stable floor for continued price action.\n                Concise Knowledge: If an overnight price gap is supported by low intraday volatility relative to historical norms, it indicates institutional absorption and trend persistence; conversely, if a gap is accompanied by an excessive intraday range, it suggests liquidity exhaustion and potential mean reversion.\n                concise Specification: Factor = (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / StdDev(Returns_{t-5 to t-1})). High positive values indicate efficient sentiment absorption (Trend), while extremely low or negative values suggest volatility-induced exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:49:18.582609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0884514951345944,
        "ICIR": 0.0461274843140295,
        "1day.excess_return_without_cost.std": 0.0040037970190565,
        "1day.excess_return_with_cost.annualized_return": 0.0223958770826902,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002933877602128,
        "1day.excess_return_without_cost.annualized_return": 0.0698262869306477,
        "1day.excess_return_with_cost.std": 0.0040055387577805,
        "Rank IC": 0.0214461225924825,
        "IC": 0.0059172305045694,
        "1day.excess_return_without_cost.max_drawdown": -0.072267965256329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1304683772638806,
        "1day.pa": 0.0,
        "l2.valid": 0.9963965669860448,
        "Rank ICIR": 0.1691347030432725,
        "l2.train": 0.9935940764971378,
        "1day.excess_return_with_cost.information_ratio": 0.3624254262680068,
        "1day.excess_return_with_cost.mean": 9.410032387684988e-05
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Liquidity-Adjusted Sentiment Persistence' hypothesis by testing different normalization techniques (volatility vs. historical range) and ranking methods. The 'Institutional_Gap_Quality_Index' and its counterparts successfully improved the Information Ratio from 0.97 to 1.13 and the Annualized Return from 5.2% to 6.98%. The IC also saw a marginal increase. These results suggest that the ratio of the overnight gap to intraday volatility/range is a robust predictor of short-term returns.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. Normalizing the overnight gap by the intraday range (a proxy for liquidity and absorption) effectively filters out 'noisy' gaps. The inclusion of TS_ZSCORE and TS_MEDIAN in the Institutional_Gap_Quality_Index likely contributed to the improved stability (Information Ratio) by handling outliers and market regime shifts more effectively than simple division.",
        "decision": true,
        "reason": "While the current factors use price range as a proxy for liquidity, incorporating actual volume data provides a more direct measure of institutional activity. A gap occurring on high relative volume compared to its subsequent intraday range suggests 'exhaustion' of counter-trend liquidity, leading to stronger persistence. We will also simplify the mathematical structure to ensure we stay well below complexity limits (SL < 300)."
      }
    },
    "f53150fe1db4a458": {
      "factor_id": "f53150fe1db4a458",
      "factor_name": "Cross_Sectional_Sentiment_Efficiency_10D",
      "factor_expression": "RANK((($open / DELAY($close, 1)) - 1) / (TS_MEAN($high - $low, 10) / (TS_STD($return, 10) + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($open / DELAY($close, 1)) - 1) / (TS_MEAN($high - $low, 10) / TS_STD(TS_PCTCHANGE($close, 1), 10)))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Sentiment_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the sentiment-to-liquidity ratio. It measures the overnight gap relative to the 10-day historical intraday range, normalized by the volatility of returns, to identify stocks where price gaps are most likely to persist.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\text{open}_t / \\text{close}_{t-1} - 1}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 10) / \\text{TS_STD}(\\text{return}, 10)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "60137bf494c1",
        "parent_trajectory_ids": [
          "66ba76e16251",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Sentiment Persistence' factor, calculated as the ratio of the overnight gap (Open/Prev_Close - 1) to the intraday range (High-Low) normalized by the 5-day return volatility, identifies high-conviction institutional moves and predicts positive short-term returns.\n                Concise Observation: Parent 1 showed that volatility-normalized ranges identify liquidity consumption (RankIC 0.0217), while Parent 2 showed that overnight gaps relative to daily ranges capture sentiment (RankIC 0.0260); combining them addresses the 'quality' of the price gap.\n                Concise Justification: Normalizing the overnight sentiment signal by the intraday liquidity consumption ratio filters out 'noisy' gaps caused by retail speculation, isolating moves where institutional liquidity provides a stable floor for continued price action.\n                Concise Knowledge: If an overnight price gap is supported by low intraday volatility relative to historical norms, it indicates institutional absorption and trend persistence; conversely, if a gap is accompanied by an excessive intraday range, it suggests liquidity exhaustion and potential mean reversion.\n                concise Specification: Factor = (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / StdDev(Returns_{t-5 to t-1})). High positive values indicate efficient sentiment absorption (Trend), while extremely low or negative values suggest volatility-induced exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:49:18.582609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0884514951345944,
        "ICIR": 0.0461274843140295,
        "1day.excess_return_without_cost.std": 0.0040037970190565,
        "1day.excess_return_with_cost.annualized_return": 0.0223958770826902,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002933877602128,
        "1day.excess_return_without_cost.annualized_return": 0.0698262869306477,
        "1day.excess_return_with_cost.std": 0.0040055387577805,
        "Rank IC": 0.0214461225924825,
        "IC": 0.0059172305045694,
        "1day.excess_return_without_cost.max_drawdown": -0.072267965256329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1304683772638806,
        "1day.pa": 0.0,
        "l2.valid": 0.9963965669860448,
        "Rank ICIR": 0.1691347030432725,
        "l2.train": 0.9935940764971378,
        "1day.excess_return_with_cost.information_ratio": 0.3624254262680068,
        "1day.excess_return_with_cost.mean": 9.410032387684988e-05
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Liquidity-Adjusted Sentiment Persistence' hypothesis by testing different normalization techniques (volatility vs. historical range) and ranking methods. The 'Institutional_Gap_Quality_Index' and its counterparts successfully improved the Information Ratio from 0.97 to 1.13 and the Annualized Return from 5.2% to 6.98%. The IC also saw a marginal increase. These results suggest that the ratio of the overnight gap to intraday volatility/range is a robust predictor of short-term returns.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. Normalizing the overnight gap by the intraday range (a proxy for liquidity and absorption) effectively filters out 'noisy' gaps. The inclusion of TS_ZSCORE and TS_MEDIAN in the Institutional_Gap_Quality_Index likely contributed to the improved stability (Information Ratio) by handling outliers and market regime shifts more effectively than simple division.",
        "decision": true,
        "reason": "While the current factors use price range as a proxy for liquidity, incorporating actual volume data provides a more direct measure of institutional activity. A gap occurring on high relative volume compared to its subsequent intraday range suggests 'exhaustion' of counter-trend liquidity, leading to stronger persistence. We will also simplify the mathematical structure to ensure we stay well below complexity limits (SL < 300)."
      }
    },
    "20ef801f5d66bbf4": {
      "factor_id": "20ef801f5d66bbf4",
      "factor_name": "Institutional_Gap_Quality_Index",
      "factor_expression": "TS_ZSCORE((($open / DELAY($close, 1)) - 1) / (($high - $low + 1e-8) / (TS_MEDIAN($high - $low, 5) + 1e-8)), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((($open / DELAY($close, 1)) - 1) / ((($high - $low) + 0.0001) / (TS_MEDIAN($high - $low, 5) + 0.0001)), 20)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Gap_Quality_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor refines the gap quality by comparing the current overnight gap to the median intraday range of the last 5 days, scaled by the volatility-adjusted range. It uses Z-scoring to ensure the signal is comparable across different market regimes.",
      "factor_formulation": "\\text{TS_ZSCORE}((\\text{open} / \\text{DELAY}(\\text{close}, 1) - 1) / ((\\text{high} - \\text{low}) / \\text{TS_MEDIAN}(\\text{high} - \\text{low}, 5)), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 2,
        "evolution_phase": "crossover",
        "trajectory_id": "60137bf494c1",
        "parent_trajectory_ids": [
          "66ba76e16251",
          "8ab08cc6ed35"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Sentiment Persistence' factor, calculated as the ratio of the overnight gap (Open/Prev_Close - 1) to the intraday range (High-Low) normalized by the 5-day return volatility, identifies high-conviction institutional moves and predicts positive short-term returns.\n                Concise Observation: Parent 1 showed that volatility-normalized ranges identify liquidity consumption (RankIC 0.0217), while Parent 2 showed that overnight gaps relative to daily ranges capture sentiment (RankIC 0.0260); combining them addresses the 'quality' of the price gap.\n                Concise Justification: Normalizing the overnight sentiment signal by the intraday liquidity consumption ratio filters out 'noisy' gaps caused by retail speculation, isolating moves where institutional liquidity provides a stable floor for continued price action.\n                Concise Knowledge: If an overnight price gap is supported by low intraday volatility relative to historical norms, it indicates institutional absorption and trend persistence; conversely, if a gap is accompanied by an excessive intraday range, it suggests liquidity exhaustion and potential mean reversion.\n                concise Specification: Factor = (Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / StdDev(Returns_{t-5 to t-1})). High positive values indicate efficient sentiment absorption (Trend), while extremely low or negative values suggest volatility-induced exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T00:49:18.582609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0884514951345944,
        "ICIR": 0.0461274843140295,
        "1day.excess_return_without_cost.std": 0.0040037970190565,
        "1day.excess_return_with_cost.annualized_return": 0.0223958770826902,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002933877602128,
        "1day.excess_return_without_cost.annualized_return": 0.0698262869306477,
        "1day.excess_return_with_cost.std": 0.0040055387577805,
        "Rank IC": 0.0214461225924825,
        "IC": 0.0059172305045694,
        "1day.excess_return_without_cost.max_drawdown": -0.072267965256329,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1304683772638806,
        "1day.pa": 0.0,
        "l2.valid": 0.9963965669860448,
        "Rank ICIR": 0.1691347030432725,
        "l2.train": 0.9935940764971378,
        "1day.excess_return_with_cost.information_ratio": 0.3624254262680068,
        "1day.excess_return_with_cost.mean": 9.410032387684988e-05
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Liquidity-Adjusted Sentiment Persistence' hypothesis by testing different normalization techniques (volatility vs. historical range) and ranking methods. The 'Institutional_Gap_Quality_Index' and its counterparts successfully improved the Information Ratio from 0.97 to 1.13 and the Annualized Return from 5.2% to 6.98%. The IC also saw a marginal increase. These results suggest that the ratio of the overnight gap to intraday volatility/range is a robust predictor of short-term returns.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. Normalizing the overnight gap by the intraday range (a proxy for liquidity and absorption) effectively filters out 'noisy' gaps. The inclusion of TS_ZSCORE and TS_MEDIAN in the Institutional_Gap_Quality_Index likely contributed to the improved stability (Information Ratio) by handling outliers and market regime shifts more effectively than simple division.",
        "decision": true,
        "reason": "While the current factors use price range as a proxy for liquidity, incorporating actual volume data provides a more direct measure of institutional activity. A gap occurring on high relative volume compared to its subsequent intraday range suggests 'exhaustion' of counter-trend liquidity, leading to stronger persistence. We will also simplify the mathematical structure to ensure we stay well below complexity limits (SL < 300)."
      }
    },
    "2e455b91fc94e600": {
      "factor_id": "2e455b91fc94e600",
      "factor_name": "Liquidity_Exhaustion_Reversal_5D",
      "factor_expression": "TS_MEAN(($high - $low) / ($volume + 1e-8), 5) * RANK(TS_MEAN(($close - $open) - ($high - $low), 3))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($high - $low) / ($volume + 1e-8), 5) * RANK(TS_MEAN(($close - $open) - ($high - $low), 3))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'liquidity holes' by multiplying the 5-day average Amihud Illiquidity (price range per unit volume) with the 3-day rank of price-move skewness. High values indicate price movements are occurring on low volume with extreme directional bias, signaling an unsustainable exhaustion phase prone to mean reversion.",
      "factor_formulation": "\\text{TS_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{volume} + 1e-8}, 5) \\times \\text{RANK}(\\text{TS_MEAN}((\\text{close} - \\text{open}) - (\\text{high} - \\text{low}), 3))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "1f9a6895026f",
        "parent_trajectory_ids": [
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Exhaustion' factor, defined as the product of the 5-day Amihud Illiquidity spike and the 3-day negative skewness of intraday price moves, predicts a price reversal by identifying 'liquidity holes' where extreme price impact occurs on diminishing volume.\n                Concise Observation: The parent strategy successfully captured linear institutional trends (high R-squared), but failed to account for volatile, non-linear exhaustion phases where high price impact on low volume signals a trend climax.\n                Concise Justification: High Amihud illiquidity values indicate that price is moving with little resistance (volume), which is unsustainable; combining this with intraday skewness identifies whether the exhaustion is driven by a panic spike or a blow-off top, both of which are prone to reversal.\n                Concise Knowledge: If a stock experiences a sharp increase in price impact (high range per unit volume) alongside extreme intraday return skewness, then the current price trend is likely driven by liquidity exhaustion rather than fundamental accumulation; When liquidity is depleted, even small orders cause large price swings, leading to imminent mean reversion.\n                concise Specification: The factor is calculated by multiplying the 5-day average of (High-Low)/Volume (Amihud Illiquidity) by the 3-day cross-sectional rank of the difference between (Close-Open) and (High-Low), focused on identifying the top and bottom deciles of price-volume divergence.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T00:52:10.878486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.106851988486651,
        "ICIR": 0.0518391002221613,
        "1day.excess_return_without_cost.std": 0.0043105468268725,
        "1day.excess_return_with_cost.annualized_return": 0.0223127153066194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002920736228151,
        "1day.excess_return_without_cost.annualized_return": 0.0695135222300141,
        "1day.excess_return_with_cost.std": 0.0043110089652004,
        "Rank IC": 0.0290231985222443,
        "IC": 0.0075625015355698,
        "1day.excess_return_without_cost.max_drawdown": -0.0960676329713959,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.045318047952014,
        "1day.pa": 0.0,
        "l2.valid": 0.9965456526037726,
        "Rank ICIR": 0.1999253123015704,
        "l2.train": 0.9937230665674384,
        "1day.excess_return_with_cost.information_ratio": 0.3354942024259427,
        "1day.excess_return_with_cost.mean": 9.37509046496614e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Exhaustion' framework, testing three variations: a product of Amihud illiquidity and price-move skewness, a Z-scored divergence model, and a time-series rank-based spike index. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.04 and the Annualized Return rising from 5.2% to 6.95%. The IC also improved to 0.0075. However, this came at the cost of a higher Max Drawdown (-0.096 vs -0.072), suggesting that while the signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that 'liquidity holes' (high price impact on low volume) signal mean reversion is strongly supported by the improved IC and Annualized Return. Specifically, the 'Exhaustion_Spike_Index_10D' approach, which uses TS_RANK to normalize illiquidity, appears to be a robust way to isolate extreme events. The use of price-range skewness as a secondary filter effectively separates sustainable trends from exhausted 'spikes'.",
        "decision": true,
        "reason": "While the current iteration successfully used raw price ranges, it did not account for the baseline volatility environment. By normalizing the Amihud Illiquidity by a measure of volatility (like a 10-day ATR or standard deviation), we can better distinguish between a stock moving because of high market volatility versus a stock moving because of a genuine 'liquidity hole'. This should help reduce the Max Drawdown observed in the current SOTA by filtering out high-beta noise."
      }
    },
    "878ab4273913229b": {
      "factor_id": "878ab4273913229b",
      "factor_name": "Amihud_Skew_Divergence_8D",
      "factor_expression": "ZSCORE(TS_MEAN(($high - $low) / ($volume + 1e-8), 8)) * ZSCORE(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($high - $low) / ($volume + 1e-8), 8)) * ZSCORE(TS_MEAN(($close - $open) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Skew_Divergence_8D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the liquidity exhaustion hypothesis focusing on the divergence between price impact and volume-weighted movement. It uses a longer 8-day window for illiquidity and a 5-day window for price-range skewness to capture slower-building exhaustion phases in larger-cap instruments.",
      "factor_formulation": "\\text{ZSCORE}(\\text{TS_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{volume} + 1e-8}, 8)) \\times \\text{ZSCORE}(\\text{TS_MEAN}(\\frac{\\text{close} - \\text{open}}{\\text{high} - \\text{low} + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "1f9a6895026f",
        "parent_trajectory_ids": [
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Exhaustion' factor, defined as the product of the 5-day Amihud Illiquidity spike and the 3-day negative skewness of intraday price moves, predicts a price reversal by identifying 'liquidity holes' where extreme price impact occurs on diminishing volume.\n                Concise Observation: The parent strategy successfully captured linear institutional trends (high R-squared), but failed to account for volatile, non-linear exhaustion phases where high price impact on low volume signals a trend climax.\n                Concise Justification: High Amihud illiquidity values indicate that price is moving with little resistance (volume), which is unsustainable; combining this with intraday skewness identifies whether the exhaustion is driven by a panic spike or a blow-off top, both of which are prone to reversal.\n                Concise Knowledge: If a stock experiences a sharp increase in price impact (high range per unit volume) alongside extreme intraday return skewness, then the current price trend is likely driven by liquidity exhaustion rather than fundamental accumulation; When liquidity is depleted, even small orders cause large price swings, leading to imminent mean reversion.\n                concise Specification: The factor is calculated by multiplying the 5-day average of (High-Low)/Volume (Amihud Illiquidity) by the 3-day cross-sectional rank of the difference between (Close-Open) and (High-Low), focused on identifying the top and bottom deciles of price-volume divergence.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T00:52:10.878486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.106851988486651,
        "ICIR": 0.0518391002221613,
        "1day.excess_return_without_cost.std": 0.0043105468268725,
        "1day.excess_return_with_cost.annualized_return": 0.0223127153066194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002920736228151,
        "1day.excess_return_without_cost.annualized_return": 0.0695135222300141,
        "1day.excess_return_with_cost.std": 0.0043110089652004,
        "Rank IC": 0.0290231985222443,
        "IC": 0.0075625015355698,
        "1day.excess_return_without_cost.max_drawdown": -0.0960676329713959,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.045318047952014,
        "1day.pa": 0.0,
        "l2.valid": 0.9965456526037726,
        "Rank ICIR": 0.1999253123015704,
        "l2.train": 0.9937230665674384,
        "1day.excess_return_with_cost.information_ratio": 0.3354942024259427,
        "1day.excess_return_with_cost.mean": 9.37509046496614e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Exhaustion' framework, testing three variations: a product of Amihud illiquidity and price-move skewness, a Z-scored divergence model, and a time-series rank-based spike index. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.04 and the Annualized Return rising from 5.2% to 6.95%. The IC also improved to 0.0075. However, this came at the cost of a higher Max Drawdown (-0.096 vs -0.072), suggesting that while the signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that 'liquidity holes' (high price impact on low volume) signal mean reversion is strongly supported by the improved IC and Annualized Return. Specifically, the 'Exhaustion_Spike_Index_10D' approach, which uses TS_RANK to normalize illiquidity, appears to be a robust way to isolate extreme events. The use of price-range skewness as a secondary filter effectively separates sustainable trends from exhausted 'spikes'.",
        "decision": true,
        "reason": "While the current iteration successfully used raw price ranges, it did not account for the baseline volatility environment. By normalizing the Amihud Illiquidity by a measure of volatility (like a 10-day ATR or standard deviation), we can better distinguish between a stock moving because of high market volatility versus a stock moving because of a genuine 'liquidity hole'. This should help reduce the Max Drawdown observed in the current SOTA by filtering out high-beta noise."
      }
    },
    "819998aa99966a39": {
      "factor_id": "819998aa99966a39",
      "factor_name": "Exhaustion_Spike_Index_10D",
      "factor_expression": "TS_RANK(($high - $low) / ($volume + 1e-8), 10) * RANK(($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / ($volume + 1e-8), 10) * RANK(($high - $low) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Spike_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures extreme liquidity exhaustion by comparing the current Amihud Illiquidity to its 10-day historical range, weighted by the cross-sectional rank of the intraday price range. It isolates stocks where the price impact per unit of volume is at a recent extreme.",
      "factor_formulation": "\\text{TS_RANK}(\\frac{\\text{high} - \\text{low}}{\\text{volume} + 1e-8}, 10) \\times \\text{RANK}(\\frac{\\text{high} - \\text{low}}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 10)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "1f9a6895026f",
        "parent_trajectory_ids": [
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Exhaustion' factor, defined as the product of the 5-day Amihud Illiquidity spike and the 3-day negative skewness of intraday price moves, predicts a price reversal by identifying 'liquidity holes' where extreme price impact occurs on diminishing volume.\n                Concise Observation: The parent strategy successfully captured linear institutional trends (high R-squared), but failed to account for volatile, non-linear exhaustion phases where high price impact on low volume signals a trend climax.\n                Concise Justification: High Amihud illiquidity values indicate that price is moving with little resistance (volume), which is unsustainable; combining this with intraday skewness identifies whether the exhaustion is driven by a panic spike or a blow-off top, both of which are prone to reversal.\n                Concise Knowledge: If a stock experiences a sharp increase in price impact (high range per unit volume) alongside extreme intraday return skewness, then the current price trend is likely driven by liquidity exhaustion rather than fundamental accumulation; When liquidity is depleted, even small orders cause large price swings, leading to imminent mean reversion.\n                concise Specification: The factor is calculated by multiplying the 5-day average of (High-Low)/Volume (Amihud Illiquidity) by the 3-day cross-sectional rank of the difference between (Close-Open) and (High-Low), focused on identifying the top and bottom deciles of price-volume divergence.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T00:52:10.878486"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.106851988486651,
        "ICIR": 0.0518391002221613,
        "1day.excess_return_without_cost.std": 0.0043105468268725,
        "1day.excess_return_with_cost.annualized_return": 0.0223127153066194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002920736228151,
        "1day.excess_return_without_cost.annualized_return": 0.0695135222300141,
        "1day.excess_return_with_cost.std": 0.0043110089652004,
        "Rank IC": 0.0290231985222443,
        "IC": 0.0075625015355698,
        "1day.excess_return_without_cost.max_drawdown": -0.0960676329713959,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.045318047952014,
        "1day.pa": 0.0,
        "l2.valid": 0.9965456526037726,
        "Rank ICIR": 0.1999253123015704,
        "l2.train": 0.9937230665674384,
        "1day.excess_return_with_cost.information_ratio": 0.3354942024259427,
        "1day.excess_return_with_cost.mean": 9.37509046496614e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Exhaustion' framework, testing three variations: a product of Amihud illiquidity and price-move skewness, a Z-scored divergence model, and a time-series rank-based spike index. The results show a significant improvement in predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.04 and the Annualized Return rising from 5.2% to 6.95%. The IC also improved to 0.0075. However, this came at the cost of a higher Max Drawdown (-0.096 vs -0.072), suggesting that while the signal is stronger, it may be more volatile or concentrated in specific market regimes.",
        "hypothesis_evaluation": "The hypothesis that 'liquidity holes' (high price impact on low volume) signal mean reversion is strongly supported by the improved IC and Annualized Return. Specifically, the 'Exhaustion_Spike_Index_10D' approach, which uses TS_RANK to normalize illiquidity, appears to be a robust way to isolate extreme events. The use of price-range skewness as a secondary filter effectively separates sustainable trends from exhausted 'spikes'.",
        "decision": true,
        "reason": "While the current iteration successfully used raw price ranges, it did not account for the baseline volatility environment. By normalizing the Amihud Illiquidity by a measure of volatility (like a 10-day ATR or standard deviation), we can better distinguish between a stock moving because of high market volatility versus a stock moving because of a genuine 'liquidity hole'. This should help reduce the Max Drawdown observed in the current SOTA by filtering out high-beta noise."
      }
    },
    "b14dfd17ba39b38a": {
      "factor_id": "b14dfd17ba39b38a",
      "factor_name": "Liquidity_Vacuum_RVR_10D",
      "factor_expression": "TS_RANK(($high - $low) / (WMA($volume, 5) + 1e-8), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / (WMA($volume, 5) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_RVR_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'hollow' price moves by calculating the ratio of the daily high-low range to the 5-day weighted volume moving average. High values indicate price discovery occurring on low relative liquidity, which is prone to mean-reversion. The result is ranked over a 10-day window to capture extreme liquidity gaps.",
      "factor_formulation": "\\text{TS_RANK}(\\frac{\\text{high} - \\text{low}}{\\text{WMA}(\\text{volume}, 5)}, 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "b3debaa6ebd8",
        "parent_trajectory_ids": [
          "849c0b2b23a0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the daily high-low range to the 5-day weighted volume moving average, identifies price moves driven by liquidity gaps that are likely to mean-revert due to lack of institutional support.\n                Concise Observation: While the parent strategy found success in volume-confirmed gaps, market data shows that extreme price dispersion (High-Low) without corresponding volume peaks often leads to immediate price retracement rather than trend continuation.\n                Concise Justification: Price discovery requires volume to validate new levels; a high Range-to-Volume Ratio (RVR) signifies high transaction costs and low depth, suggesting the price move is a transient noise event rather than a structural shift.\n                Concise Knowledge: If a wide intraday price range occurs on declining or low relative volume, it indicates a liquidity vacuum where small trades cause large price shifts; such 'hollow' volatility typically reverts as market makers stabilize the spread.\n                concise Specification: The factor is calculated as the daily ($high - $low) divided by the 5-day WMA of $volume, then transformed via a 10-day descending rank to capture the most 'hollow' price expansions for mean-reversion prediction.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T00:55:39.379050"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147655005400539,
        "ICIR": 0.0433370589635048,
        "1day.excess_return_without_cost.std": 0.0040708890250533,
        "1day.excess_return_with_cost.annualized_return": 0.0116254462492635,
        "1day.ffr": 0.9998945481387748,
        "1day.excess_return_without_cost.mean": 0.0002466588309439,
        "1day.excess_return_without_cost.annualized_return": 0.0587048017646532,
        "1day.excess_return_with_cost.std": 0.0040710037306153,
        "Rank IC": 0.0266563656043839,
        "IC": 0.0061719608470284,
        "1day.excess_return_without_cost.max_drawdown": -0.0859844045825237,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9347508826709212,
        "1day.pa": 0.0,
        "l2.valid": 0.9964702388668738,
        "Rank ICIR": 0.1925215625082049,
        "l2.train": 0.9932514352244038,
        "1day.excess_return_with_cost.information_ratio": 0.1851056409026963,
        "1day.excess_return_with_cost.mean": 4.884641281203189e-05
      },
      "feedback": {
        "observations": "The current experiment iteration shows an improvement in both the Information Coefficient (IC) and the Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.005798 to 0.006172, and the Annualized Return rose from 0.052010 to 0.058705. However, the Information Ratio (IR) slightly decreased, and the Max Drawdown (MDD) worsened from -0.072585 to -0.085984. The factors tested—particularly the 'Decay_Weighted_Liquidity_Gap' and 'Cross_Sectional_Hollow_Volatility'—successfully captured the 'hollow' price moves described in the hypothesis. The improvement in IC suggests that the relationship between liquidity-deprived price expansion and subsequent returns is statistically significant.",
        "hypothesis_evaluation": "The results support the 'Mean-Reverting Liquidity Vacuum' hypothesis. The use of a decay-weighted volume (DECAYLINEAR) and cross-sectional normalization (ZSCORE) appears to be more effective than a simple time-series rank (TS_RANK). The increase in IC indicates that the divergence between price range and volume is a valid predictor of short-term returns. However, the increased drawdown suggests that while the signal is more predictive on average, it may be subject to higher volatility or 'tail risk' during specific market regimes where liquidity gaps do not immediately mean-revert.",
        "decision": true,
        "reason": "The current SOTA uses a 20-day standard deviation of the range for normalization, which helped improve the annualized return. To further refine this, we should consider that a 'liquidity vacuum' is most meaningful relative to the stock's own historical 'normal' liquidity-to-volatility ratio. By incorporating a double-normalization (normalizing the range by volume, then normalizing that ratio by its own historical volatility), we can better isolate truly anomalous 'hollow' moves from standard high-volatility trading. This should help reduce the Max Drawdown observed in the current iteration."
      }
    },
    "b128705915ddff0d": {
      "factor_id": "b128705915ddff0d",
      "factor_name": "Cross_Sectional_Hollow_Volatility",
      "factor_expression": "ZSCORE(($high - $low) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Hollow_Volatility\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the cross-sectional intensity of price expansion relative to volume support. By taking the Z-score of the range-to-volume ratio, it identifies stocks experiencing abnormal price dispersion without institutional volume backing, signaling a potential mean-reverting liquidity vacuum.",
      "factor_formulation": "\\text{ZSCORE}(\\frac{\\text{high} - \\text{low}}{\\text{TS_MEAN}(\\text{volume}, 5)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "b3debaa6ebd8",
        "parent_trajectory_ids": [
          "849c0b2b23a0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the daily high-low range to the 5-day weighted volume moving average, identifies price moves driven by liquidity gaps that are likely to mean-revert due to lack of institutional support.\n                Concise Observation: While the parent strategy found success in volume-confirmed gaps, market data shows that extreme price dispersion (High-Low) without corresponding volume peaks often leads to immediate price retracement rather than trend continuation.\n                Concise Justification: Price discovery requires volume to validate new levels; a high Range-to-Volume Ratio (RVR) signifies high transaction costs and low depth, suggesting the price move is a transient noise event rather than a structural shift.\n                Concise Knowledge: If a wide intraday price range occurs on declining or low relative volume, it indicates a liquidity vacuum where small trades cause large price shifts; such 'hollow' volatility typically reverts as market makers stabilize the spread.\n                concise Specification: The factor is calculated as the daily ($high - $low) divided by the 5-day WMA of $volume, then transformed via a 10-day descending rank to capture the most 'hollow' price expansions for mean-reversion prediction.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T00:55:39.379050"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147655005400539,
        "ICIR": 0.0433370589635048,
        "1day.excess_return_without_cost.std": 0.0040708890250533,
        "1day.excess_return_with_cost.annualized_return": 0.0116254462492635,
        "1day.ffr": 0.9998945481387748,
        "1day.excess_return_without_cost.mean": 0.0002466588309439,
        "1day.excess_return_without_cost.annualized_return": 0.0587048017646532,
        "1day.excess_return_with_cost.std": 0.0040710037306153,
        "Rank IC": 0.0266563656043839,
        "IC": 0.0061719608470284,
        "1day.excess_return_without_cost.max_drawdown": -0.0859844045825237,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9347508826709212,
        "1day.pa": 0.0,
        "l2.valid": 0.9964702388668738,
        "Rank ICIR": 0.1925215625082049,
        "l2.train": 0.9932514352244038,
        "1day.excess_return_with_cost.information_ratio": 0.1851056409026963,
        "1day.excess_return_with_cost.mean": 4.884641281203189e-05
      },
      "feedback": {
        "observations": "The current experiment iteration shows an improvement in both the Information Coefficient (IC) and the Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.005798 to 0.006172, and the Annualized Return rose from 0.052010 to 0.058705. However, the Information Ratio (IR) slightly decreased, and the Max Drawdown (MDD) worsened from -0.072585 to -0.085984. The factors tested—particularly the 'Decay_Weighted_Liquidity_Gap' and 'Cross_Sectional_Hollow_Volatility'—successfully captured the 'hollow' price moves described in the hypothesis. The improvement in IC suggests that the relationship between liquidity-deprived price expansion and subsequent returns is statistically significant.",
        "hypothesis_evaluation": "The results support the 'Mean-Reverting Liquidity Vacuum' hypothesis. The use of a decay-weighted volume (DECAYLINEAR) and cross-sectional normalization (ZSCORE) appears to be more effective than a simple time-series rank (TS_RANK). The increase in IC indicates that the divergence between price range and volume is a valid predictor of short-term returns. However, the increased drawdown suggests that while the signal is more predictive on average, it may be subject to higher volatility or 'tail risk' during specific market regimes where liquidity gaps do not immediately mean-revert.",
        "decision": true,
        "reason": "The current SOTA uses a 20-day standard deviation of the range for normalization, which helped improve the annualized return. To further refine this, we should consider that a 'liquidity vacuum' is most meaningful relative to the stock's own historical 'normal' liquidity-to-volatility ratio. By incorporating a double-normalization (normalizing the range by volume, then normalizing that ratio by its own historical volatility), we can better isolate truly anomalous 'hollow' moves from standard high-volatility trading. This should help reduce the Max Drawdown observed in the current iteration."
      }
    },
    "84e7270f720d91fc": {
      "factor_id": "84e7270f720d91fc",
      "factor_name": "Decay_Weighted_Liquidity_Gap",
      "factor_expression": "(($high - $low) / (DECAYLINEAR($volume, 5) + 1e-8)) / (TS_STD($high - $low, 20) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (DECAYLINEAR($volume, 5) + 1e-8)) / (TS_STD($high - $low, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Decay_Weighted_Liquidity_Gap\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the liquidity vacuum hypothesis using a linearly decaying volume weight to emphasize recent volume trends. It captures the divergence between price volatility (High-Low) and recent volume depth, normalized by the 20-day standard deviation of the range.",
      "factor_formulation": "\\frac{(\\text{high} - \\text{low}) / \\text{DECAYLINEAR}(\\text{volume}, 5)}{\\text{TS_STD}(\\text{high} - \\text{low}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "b3debaa6ebd8",
        "parent_trajectory_ids": [
          "849c0b2b23a0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the daily high-low range to the 5-day weighted volume moving average, identifies price moves driven by liquidity gaps that are likely to mean-revert due to lack of institutional support.\n                Concise Observation: While the parent strategy found success in volume-confirmed gaps, market data shows that extreme price dispersion (High-Low) without corresponding volume peaks often leads to immediate price retracement rather than trend continuation.\n                Concise Justification: Price discovery requires volume to validate new levels; a high Range-to-Volume Ratio (RVR) signifies high transaction costs and low depth, suggesting the price move is a transient noise event rather than a structural shift.\n                Concise Knowledge: If a wide intraday price range occurs on declining or low relative volume, it indicates a liquidity vacuum where small trades cause large price shifts; such 'hollow' volatility typically reverts as market makers stabilize the spread.\n                concise Specification: The factor is calculated as the daily ($high - $low) divided by the 5-day WMA of $volume, then transformed via a 10-day descending rank to capture the most 'hollow' price expansions for mean-reversion prediction.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T00:55:39.379050"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1147655005400539,
        "ICIR": 0.0433370589635048,
        "1day.excess_return_without_cost.std": 0.0040708890250533,
        "1day.excess_return_with_cost.annualized_return": 0.0116254462492635,
        "1day.ffr": 0.9998945481387748,
        "1day.excess_return_without_cost.mean": 0.0002466588309439,
        "1day.excess_return_without_cost.annualized_return": 0.0587048017646532,
        "1day.excess_return_with_cost.std": 0.0040710037306153,
        "Rank IC": 0.0266563656043839,
        "IC": 0.0061719608470284,
        "1day.excess_return_without_cost.max_drawdown": -0.0859844045825237,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9347508826709212,
        "1day.pa": 0.0,
        "l2.valid": 0.9964702388668738,
        "Rank ICIR": 0.1925215625082049,
        "l2.train": 0.9932514352244038,
        "1day.excess_return_with_cost.information_ratio": 0.1851056409026963,
        "1day.excess_return_with_cost.mean": 4.884641281203189e-05
      },
      "feedback": {
        "observations": "The current experiment iteration shows an improvement in both the Information Coefficient (IC) and the Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.005798 to 0.006172, and the Annualized Return rose from 0.052010 to 0.058705. However, the Information Ratio (IR) slightly decreased, and the Max Drawdown (MDD) worsened from -0.072585 to -0.085984. The factors tested—particularly the 'Decay_Weighted_Liquidity_Gap' and 'Cross_Sectional_Hollow_Volatility'—successfully captured the 'hollow' price moves described in the hypothesis. The improvement in IC suggests that the relationship between liquidity-deprived price expansion and subsequent returns is statistically significant.",
        "hypothesis_evaluation": "The results support the 'Mean-Reverting Liquidity Vacuum' hypothesis. The use of a decay-weighted volume (DECAYLINEAR) and cross-sectional normalization (ZSCORE) appears to be more effective than a simple time-series rank (TS_RANK). The increase in IC indicates that the divergence between price range and volume is a valid predictor of short-term returns. However, the increased drawdown suggests that while the signal is more predictive on average, it may be subject to higher volatility or 'tail risk' during specific market regimes where liquidity gaps do not immediately mean-revert.",
        "decision": true,
        "reason": "The current SOTA uses a 20-day standard deviation of the range for normalization, which helped improve the annualized return. To further refine this, we should consider that a 'liquidity vacuum' is most meaningful relative to the stock's own historical 'normal' liquidity-to-volatility ratio. By incorporating a double-normalization (normalizing the range by volume, then normalizing that ratio by its own historical volatility), we can better isolate truly anomalous 'hollow' moves from standard high-volatility trading. This should help reduce the Max Drawdown observed in the current iteration."
      }
    },
    "4cc042c1753137dd": {
      "factor_id": "4cc042c1753137dd",
      "factor_name": "Intraday_Liquidity_Density_5D",
      "factor_expression": "RANK(TS_MEAN($volume / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($volume / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Liquidity_Density_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies passive institutional accumulation by measuring the volume absorbed within a narrow price range. A high ratio of volume to the high-low spread indicates 'thick' liquidity where large orders are filled with minimal price impact, suggesting trend persistence.",
      "factor_formulation": "\\text{RANK}(\\text{TS_MEAN}(\\frac{\\text{volume}}{(\\text{high} - \\text{low}) + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "e577188a4605",
        "parent_trajectory_ids": [
          "e9d36ddaaa29"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Density' factor predicts positive alpha by identifying stocks where high volume is absorbed within a narrow price range, calculated as the ratio of daily volume to the intraday high-low spread, signaling passive institutional accumulation.\n                Concise Observation: The parent strategy focused on high-volatility capitulation and gaps (RankIC 0.0170), but failed to capture 'quiet' accumulation phases where price remains stable despite high turnover, leading to missed opportunities in steady uptrends.\n                Concise Justification: Passive buyers (institutions) often use algorithms to minimize market impact, resulting in high volume at specific price levels; a high ratio of volume to the high-low range (Illiquidity Inverse) quantifies this absorption capacity, distinguishing it from volatile retail-driven price moves.\n                Concise Knowledge: If a stock maintains a high volume-to-range ratio (Liquidity Density), it indicates that large orders are being filled without significant price impact; when this density increases, it suggests a 'thick' liquidity environment that supports trend persistence rather than mean reversion.\n                concise Specification: The factor is defined as the daily $volume divided by the difference between $high and $low (plus a small epsilon), smoothed over a 5-day moving average to ensure the persistence of the liquidity density signal.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T00:58:32.913525"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1362601306661477,
        "ICIR": 0.0502080951274213,
        "1day.excess_return_without_cost.std": 0.0041010451510472,
        "1day.excess_return_with_cost.annualized_return": -0.0037783411027358,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000183432131502,
        "1day.excess_return_without_cost.annualized_return": 0.04365684729748,
        "1day.excess_return_with_cost.std": 0.0041025974131203,
        "Rank IC": 0.0249574479872754,
        "IC": 0.0071448048450948,
        "1day.excess_return_without_cost.max_drawdown": -0.0950145060273637,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900321731290484,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339789122232,
        "Rank ICIR": 0.1809935552467677,
        "l2.train": 0.9928669595623976,
        "1day.excess_return_with_cost.information_ratio": -0.0596971753506952,
        "1day.excess_return_with_cost.mean": -1.5875382784604286e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Density' and its variations. While the IC (Information Coefficient) improved from 0.005798 to 0.007145, indicating a stronger linear relationship between the factor and future returns, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) underperformed compared to the SOTA. Specifically, the Annualized Return dropped from 5.2% to 4.37%, and the Information Ratio saw a significant decline. This suggests that while the raw predictive power (IC) increased, the signal's stability or its interaction with the tail of the distribution (which drives portfolio performance) weakened.",
        "hypothesis_evaluation": "The hypothesis that high volume absorbed in a narrow range signals institutional accumulation is partially supported by the improved IC. However, the 'Density_Weighted_Return_Momentum_5D' and 'Relative_Liquidity_Absorption_10D' might be introducing noise or overfitting to short-term volatility. The current implementation of 'Liquidity Density' (volume/spread) is sensitive to price levels; a stock with a low price will naturally have a smaller absolute spread, potentially biasing the factor toward low-priced stocks rather than actual 'thick' liquidity.",
        "decision": false,
        "reason": "1. **Price Level Neutrality**: Dividing (High-Low) by the Open price ensures the 'spread' is relative, preventing bias toward low-priced stocks. 2. **Robustness**: Using TS_MEDIAN instead of TS_MEAN or TS_ZSCORE reduces the influence of extreme single-day outliers (e.g., flash crashes or news-driven volume spikes) that don't represent sustained institutional accumulation. 3. **Complexity Control**: The current factors use 4-5 base features; the new approach maintains this efficiency while improving the mathematical representation of 'density'. 4. **Directionality**: Pure density is directionless; multiplying by the sign of the daily return or a short-term trend ensures we capture 'accumulation' rather than 'distribution' at high density."
      }
    },
    "afb49baadf5af4e9": {
      "factor_id": "afb49baadf5af4e9",
      "factor_name": "Relative_Liquidity_Absorption_10D",
      "factor_expression": "RANK(TS_ZSCORE($volume / ($high - $low + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($volume / ($high - $low + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Liquidity_Absorption_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor refines the liquidity density concept by comparing the current volume-to-range ratio against its historical 10-day volatility. It highlights periods where volume is significantly higher than usual relative to the price movement, signaling a shift toward passive accumulation.",
      "factor_formulation": "\\text{RANK}(\\text{TS_ZSCORE}(\\frac{\\text{volume}}{(\\text{high} - \\text{low}) + 1e-8}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "e577188a4605",
        "parent_trajectory_ids": [
          "e9d36ddaaa29"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Density' factor predicts positive alpha by identifying stocks where high volume is absorbed within a narrow price range, calculated as the ratio of daily volume to the intraday high-low spread, signaling passive institutional accumulation.\n                Concise Observation: The parent strategy focused on high-volatility capitulation and gaps (RankIC 0.0170), but failed to capture 'quiet' accumulation phases where price remains stable despite high turnover, leading to missed opportunities in steady uptrends.\n                Concise Justification: Passive buyers (institutions) often use algorithms to minimize market impact, resulting in high volume at specific price levels; a high ratio of volume to the high-low range (Illiquidity Inverse) quantifies this absorption capacity, distinguishing it from volatile retail-driven price moves.\n                Concise Knowledge: If a stock maintains a high volume-to-range ratio (Liquidity Density), it indicates that large orders are being filled without significant price impact; when this density increases, it suggests a 'thick' liquidity environment that supports trend persistence rather than mean reversion.\n                concise Specification: The factor is defined as the daily $volume divided by the difference between $high and $low (plus a small epsilon), smoothed over a 5-day moving average to ensure the persistence of the liquidity density signal.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T00:58:32.913525"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1362601306661477,
        "ICIR": 0.0502080951274213,
        "1day.excess_return_without_cost.std": 0.0041010451510472,
        "1day.excess_return_with_cost.annualized_return": -0.0037783411027358,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000183432131502,
        "1day.excess_return_without_cost.annualized_return": 0.04365684729748,
        "1day.excess_return_with_cost.std": 0.0041025974131203,
        "Rank IC": 0.0249574479872754,
        "IC": 0.0071448048450948,
        "1day.excess_return_without_cost.max_drawdown": -0.0950145060273637,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900321731290484,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339789122232,
        "Rank ICIR": 0.1809935552467677,
        "l2.train": 0.9928669595623976,
        "1day.excess_return_with_cost.information_ratio": -0.0596971753506952,
        "1day.excess_return_with_cost.mean": -1.5875382784604286e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Density' and its variations. While the IC (Information Coefficient) improved from 0.005798 to 0.007145, indicating a stronger linear relationship between the factor and future returns, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) underperformed compared to the SOTA. Specifically, the Annualized Return dropped from 5.2% to 4.37%, and the Information Ratio saw a significant decline. This suggests that while the raw predictive power (IC) increased, the signal's stability or its interaction with the tail of the distribution (which drives portfolio performance) weakened.",
        "hypothesis_evaluation": "The hypothesis that high volume absorbed in a narrow range signals institutional accumulation is partially supported by the improved IC. However, the 'Density_Weighted_Return_Momentum_5D' and 'Relative_Liquidity_Absorption_10D' might be introducing noise or overfitting to short-term volatility. The current implementation of 'Liquidity Density' (volume/spread) is sensitive to price levels; a stock with a low price will naturally have a smaller absolute spread, potentially biasing the factor toward low-priced stocks rather than actual 'thick' liquidity.",
        "decision": false,
        "reason": "1. **Price Level Neutrality**: Dividing (High-Low) by the Open price ensures the 'spread' is relative, preventing bias toward low-priced stocks. 2. **Robustness**: Using TS_MEDIAN instead of TS_MEAN or TS_ZSCORE reduces the influence of extreme single-day outliers (e.g., flash crashes or news-driven volume spikes) that don't represent sustained institutional accumulation. 3. **Complexity Control**: The current factors use 4-5 base features; the new approach maintains this efficiency while improving the mathematical representation of 'density'. 4. **Directionality**: Pure density is directionless; multiplying by the sign of the daily return or a short-term trend ensures we capture 'accumulation' rather than 'distribution' at high density."
      }
    },
    "c69664fdb082f11b": {
      "factor_id": "c69664fdb082f11b",
      "factor_name": "Density_Weighted_Return_Momentum_5D",
      "factor_expression": "TS_SUM($return * ($volume / ($high - $low + 1e-8)), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM((($close / DELAY($close, 1)) - 1) * ($volume / ($high - $low + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Density_Weighted_Return_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor combines liquidity density with price direction. It weights the daily return by the liquidity density (volume/range), emphasizing price moves that occur during high-absorption phases, which are more likely to be driven by institutional flow than retail volatility.",
      "factor_formulation": "\\text{TS_SUM}(\\text{return} * \\frac{\\text{volume}}{(\\text{high} - \\text{low}) + 1e-8}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "e577188a4605",
        "parent_trajectory_ids": [
          "e9d36ddaaa29"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Density' factor predicts positive alpha by identifying stocks where high volume is absorbed within a narrow price range, calculated as the ratio of daily volume to the intraday high-low spread, signaling passive institutional accumulation.\n                Concise Observation: The parent strategy focused on high-volatility capitulation and gaps (RankIC 0.0170), but failed to capture 'quiet' accumulation phases where price remains stable despite high turnover, leading to missed opportunities in steady uptrends.\n                Concise Justification: Passive buyers (institutions) often use algorithms to minimize market impact, resulting in high volume at specific price levels; a high ratio of volume to the high-low range (Illiquidity Inverse) quantifies this absorption capacity, distinguishing it from volatile retail-driven price moves.\n                Concise Knowledge: If a stock maintains a high volume-to-range ratio (Liquidity Density), it indicates that large orders are being filled without significant price impact; when this density increases, it suggests a 'thick' liquidity environment that supports trend persistence rather than mean reversion.\n                concise Specification: The factor is defined as the daily $volume divided by the difference between $high and $low (plus a small epsilon), smoothed over a 5-day moving average to ensure the persistence of the liquidity density signal.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T00:58:32.913525"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1362601306661477,
        "ICIR": 0.0502080951274213,
        "1day.excess_return_without_cost.std": 0.0041010451510472,
        "1day.excess_return_with_cost.annualized_return": -0.0037783411027358,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000183432131502,
        "1day.excess_return_without_cost.annualized_return": 0.04365684729748,
        "1day.excess_return_with_cost.std": 0.0041025974131203,
        "Rank IC": 0.0249574479872754,
        "IC": 0.0071448048450948,
        "1day.excess_return_without_cost.max_drawdown": -0.0950145060273637,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900321731290484,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339789122232,
        "Rank ICIR": 0.1809935552467677,
        "l2.train": 0.9928669595623976,
        "1day.excess_return_with_cost.information_ratio": -0.0596971753506952,
        "1day.excess_return_with_cost.mean": -1.5875382784604286e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Density' and its variations. While the IC (Information Coefficient) improved from 0.005798 to 0.007145, indicating a stronger linear relationship between the factor and future returns, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) underperformed compared to the SOTA. Specifically, the Annualized Return dropped from 5.2% to 4.37%, and the Information Ratio saw a significant decline. This suggests that while the raw predictive power (IC) increased, the signal's stability or its interaction with the tail of the distribution (which drives portfolio performance) weakened.",
        "hypothesis_evaluation": "The hypothesis that high volume absorbed in a narrow range signals institutional accumulation is partially supported by the improved IC. However, the 'Density_Weighted_Return_Momentum_5D' and 'Relative_Liquidity_Absorption_10D' might be introducing noise or overfitting to short-term volatility. The current implementation of 'Liquidity Density' (volume/spread) is sensitive to price levels; a stock with a low price will naturally have a smaller absolute spread, potentially biasing the factor toward low-priced stocks rather than actual 'thick' liquidity.",
        "decision": false,
        "reason": "1. **Price Level Neutrality**: Dividing (High-Low) by the Open price ensures the 'spread' is relative, preventing bias toward low-priced stocks. 2. **Robustness**: Using TS_MEDIAN instead of TS_MEAN or TS_ZSCORE reduces the influence of extreme single-day outliers (e.g., flash crashes or news-driven volume spikes) that don't represent sustained institutional accumulation. 3. **Complexity Control**: The current factors use 4-5 base features; the new approach maintains this efficiency while improving the mathematical representation of 'density'. 4. **Directionality**: Pure density is directionless; multiplying by the sign of the daily return or a short-term trend ensures we capture 'accumulation' rather than 'distribution' at high density."
      }
    },
    "cf6fbde2e129deb6": {
      "factor_id": "cf6fbde2e129deb6",
      "factor_name": "Liquidity_Exhaustion_Reversal_5D",
      "factor_expression": "($close / (($high + $low + $close) / 3.0) - 1.0) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close / (($high + $low + $close) / 3.0) - 1.0) / (TS_STD(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by measuring the distance of the close price from the day's typical price (as a proxy for VWAP) relative to recent volume-weighted volatility. High values indicate price 'stretch' on potentially weak liquidity, suggesting a mean-reversion in the next session.",
      "factor_formulation": "LER = \\frac{close / ((high + low + close) / 3) - 1}{TS\\_STD(return, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "3f25ef21e05c",
        "parent_trajectory_ids": [
          "5e79f12cb57c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the day's close-to-VWAP distance to the trailing volume-weighted volatility, predicts that price extremes reached on declining relative volume at the market close represent liquidity-driven noise that will mean-revert in the next session.\n                Concise Observation: The parent strategy focused on institutional trend persistence via overnight gaps, but market closes often exhibit price-volume divergence where high prices on low volume signal a temporary liquidity vacuum rather than a sustainable trend.\n                Concise Justification: Passive rebalancing and late-day margin liquidations often push prices to extremes that are not supported by fundamental order flow, creating a 'stretch' relative to the volume-weighted average price (VWAP) that is statistically prone to reversal.\n                Concise Knowledge: If a price reaches a daily extreme while volume intensity is significantly lower than the daily average, it likely reflects a lack of institutional conviction; when such 'exhaustion' occurs, the price tends to revert toward the mean as liquidity stabilizes.\n                concise Specification: The factor is calculated as ($close / VWAP - 1) divided by the 5-day standard deviation of volume-weighted returns; it targets assets where the close price is at a multi-day high/low but late-day volume is decreasing relative to the day's median volume.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T01:05:24.242073"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1702048688679466,
        "ICIR": 0.0123242547872574,
        "1day.excess_return_without_cost.std": 0.0061283320797915,
        "1day.excess_return_with_cost.annualized_return": 0.0295496942936394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003249844645108,
        "1day.excess_return_without_cost.annualized_return": 0.0773463025535762,
        "1day.excess_return_with_cost.std": 0.0061298155095204,
        "Rank IC": 0.0150640055549897,
        "IC": 0.0018354687496487,
        "1day.excess_return_without_cost.max_drawdown": -0.1432050515773104,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8181045130296813,
        "1day.pa": 0.0,
        "l2.valid": 0.9966619427126752,
        "Rank ICIR": 0.0994800527474677,
        "l2.train": 0.9936973647909414,
        "1day.excess_return_with_cost.information_ratio": 0.3124763190868643,
        "1day.excess_return_with_cost.mean": 0.000124158379385
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Exhaustion' using price-to-VWAP proxies and volume-weighted volatility. While the current result achieved a higher annualized return (7.73% vs. 5.20%) compared to the SOTA, it suffered from a significantly higher maximum drawdown (-0.143 vs. -0.072) and a lower Information Ratio (0.818 vs. 0.972). The IC is also notably lower (0.0018 vs. 0.0057), suggesting that while the factor captures some high-magnitude return events, its overall predictive consistency is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes on declining relative volume represent mean-reverting noise is partially supported by the improvement in annualized returns. However, the poor IC and IR suggest that the current mathematical formulations (especially the 5-day and 10-day windows) might be too noisy or sensitive to outliers. The 'Volume_Divergence_Stretch_10D' and 'ZScore_VWAP_Exhaustion_20D' use cross-sectional ranking which helps, but the 'LER' factor's denominator (TS_STD of returns) might be conflating volatility with exhaustion, leading to the observed drawdown.",
        "decision": true,
        "reason": "The current LER factor uses TS_STD(return, 5), which can spike during high-momentum trends, causing false reversal signals. By using a longer-term ATR (e.g., 20 days) for normalization and ensuring the volume is strictly lower than its recent average (rather than just using a rank), we can better isolate 'exhaustion' from 'breakouts'. Additionally, keeping the symbol length low and using fewer base features will improve the generalization which is currently lacking as evidenced by the high drawdown."
      }
    },
    "d43aa2728b2849df": {
      "factor_id": "d43aa2728b2849df",
      "factor_name": "Volume_Divergence_Stretch_10D",
      "factor_expression": "TS_RANK($close, 10) * (1.0 - RANK($volume / (TS_MEDIAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_RANK($close, 10) - 0.5) * RANK(INV($volume / (TS_MEDIAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Divergence_Stretch_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures price-volume divergence by comparing the current day's price relative to its 10-day range against the current day's volume relative to its 10-day median. It highlights cases where prices reach extremes on declining volume, signaling exhaustion.",
      "factor_formulation": "VDS = TS\\_RANK(close, 10) * (1.0 - RANK(volume / TS\\_MEDIAN(volume, 10)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "3f25ef21e05c",
        "parent_trajectory_ids": [
          "5e79f12cb57c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the day's close-to-VWAP distance to the trailing volume-weighted volatility, predicts that price extremes reached on declining relative volume at the market close represent liquidity-driven noise that will mean-revert in the next session.\n                Concise Observation: The parent strategy focused on institutional trend persistence via overnight gaps, but market closes often exhibit price-volume divergence where high prices on low volume signal a temporary liquidity vacuum rather than a sustainable trend.\n                Concise Justification: Passive rebalancing and late-day margin liquidations often push prices to extremes that are not supported by fundamental order flow, creating a 'stretch' relative to the volume-weighted average price (VWAP) that is statistically prone to reversal.\n                Concise Knowledge: If a price reaches a daily extreme while volume intensity is significantly lower than the daily average, it likely reflects a lack of institutional conviction; when such 'exhaustion' occurs, the price tends to revert toward the mean as liquidity stabilizes.\n                concise Specification: The factor is calculated as ($close / VWAP - 1) divided by the 5-day standard deviation of volume-weighted returns; it targets assets where the close price is at a multi-day high/low but late-day volume is decreasing relative to the day's median volume.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T01:05:24.242073"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1702048688679466,
        "ICIR": 0.0123242547872574,
        "1day.excess_return_without_cost.std": 0.0061283320797915,
        "1day.excess_return_with_cost.annualized_return": 0.0295496942936394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003249844645108,
        "1day.excess_return_without_cost.annualized_return": 0.0773463025535762,
        "1day.excess_return_with_cost.std": 0.0061298155095204,
        "Rank IC": 0.0150640055549897,
        "IC": 0.0018354687496487,
        "1day.excess_return_without_cost.max_drawdown": -0.1432050515773104,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8181045130296813,
        "1day.pa": 0.0,
        "l2.valid": 0.9966619427126752,
        "Rank ICIR": 0.0994800527474677,
        "l2.train": 0.9936973647909414,
        "1day.excess_return_with_cost.information_ratio": 0.3124763190868643,
        "1day.excess_return_with_cost.mean": 0.000124158379385
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Exhaustion' using price-to-VWAP proxies and volume-weighted volatility. While the current result achieved a higher annualized return (7.73% vs. 5.20%) compared to the SOTA, it suffered from a significantly higher maximum drawdown (-0.143 vs. -0.072) and a lower Information Ratio (0.818 vs. 0.972). The IC is also notably lower (0.0018 vs. 0.0057), suggesting that while the factor captures some high-magnitude return events, its overall predictive consistency is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes on declining relative volume represent mean-reverting noise is partially supported by the improvement in annualized returns. However, the poor IC and IR suggest that the current mathematical formulations (especially the 5-day and 10-day windows) might be too noisy or sensitive to outliers. The 'Volume_Divergence_Stretch_10D' and 'ZScore_VWAP_Exhaustion_20D' use cross-sectional ranking which helps, but the 'LER' factor's denominator (TS_STD of returns) might be conflating volatility with exhaustion, leading to the observed drawdown.",
        "decision": true,
        "reason": "The current LER factor uses TS_STD(return, 5), which can spike during high-momentum trends, causing false reversal signals. By using a longer-term ATR (e.g., 20 days) for normalization and ensuring the volume is strictly lower than its recent average (rather than just using a rank), we can better isolate 'exhaustion' from 'breakouts'. Additionally, keeping the symbol length low and using fewer base features will improve the generalization which is currently lacking as evidenced by the high drawdown."
      }
    },
    "6534798fa2df7c94": {
      "factor_id": "6534798fa2df7c94",
      "factor_name": "ZScore_VWAP_Exhaustion_20D",
      "factor_expression": "RANK(TS_ZSCORE($close / (($open + $close) / 2.0), 20)) * RANK(1.0 / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE($close / (($open + $close) / 2.0), 20)) * RANK(1.0 / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_VWAP_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Standardizes the intraday price deviation from the mean price using a 20-day rolling window. It focuses on the cross-sectional rank of assets that are 'stretched' relative to their typical intraday price level, adjusted for volume intensity.",
      "factor_formulation": "ZVE = RANK(TS\\_ZSCORE(close / ((open + close) / 2.0), 20)) * RANK(INV(volume))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "3f25ef21e05c",
        "parent_trajectory_ids": [
          "5e79f12cb57c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' factor, defined as the ratio of the day's close-to-VWAP distance to the trailing volume-weighted volatility, predicts that price extremes reached on declining relative volume at the market close represent liquidity-driven noise that will mean-revert in the next session.\n                Concise Observation: The parent strategy focused on institutional trend persistence via overnight gaps, but market closes often exhibit price-volume divergence where high prices on low volume signal a temporary liquidity vacuum rather than a sustainable trend.\n                Concise Justification: Passive rebalancing and late-day margin liquidations often push prices to extremes that are not supported by fundamental order flow, creating a 'stretch' relative to the volume-weighted average price (VWAP) that is statistically prone to reversal.\n                Concise Knowledge: If a price reaches a daily extreme while volume intensity is significantly lower than the daily average, it likely reflects a lack of institutional conviction; when such 'exhaustion' occurs, the price tends to revert toward the mean as liquidity stabilizes.\n                concise Specification: The factor is calculated as ($close / VWAP - 1) divided by the 5-day standard deviation of volume-weighted returns; it targets assets where the close price is at a multi-day high/low but late-day volume is decreasing relative to the day's median volume.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T01:05:24.242073"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1702048688679466,
        "ICIR": 0.0123242547872574,
        "1day.excess_return_without_cost.std": 0.0061283320797915,
        "1day.excess_return_with_cost.annualized_return": 0.0295496942936394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003249844645108,
        "1day.excess_return_without_cost.annualized_return": 0.0773463025535762,
        "1day.excess_return_with_cost.std": 0.0061298155095204,
        "Rank IC": 0.0150640055549897,
        "IC": 0.0018354687496487,
        "1day.excess_return_without_cost.max_drawdown": -0.1432050515773104,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8181045130296813,
        "1day.pa": 0.0,
        "l2.valid": 0.9966619427126752,
        "Rank ICIR": 0.0994800527474677,
        "l2.train": 0.9936973647909414,
        "1day.excess_return_with_cost.information_ratio": 0.3124763190868643,
        "1day.excess_return_with_cost.mean": 0.000124158379385
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Liquidity Exhaustion' using price-to-VWAP proxies and volume-weighted volatility. While the current result achieved a higher annualized return (7.73% vs. 5.20%) compared to the SOTA, it suffered from a significantly higher maximum drawdown (-0.143 vs. -0.072) and a lower Information Ratio (0.818 vs. 0.972). The IC is also notably lower (0.0018 vs. 0.0057), suggesting that while the factor captures some high-magnitude return events, its overall predictive consistency is weaker than the previous SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes on declining relative volume represent mean-reverting noise is partially supported by the improvement in annualized returns. However, the poor IC and IR suggest that the current mathematical formulations (especially the 5-day and 10-day windows) might be too noisy or sensitive to outliers. The 'Volume_Divergence_Stretch_10D' and 'ZScore_VWAP_Exhaustion_20D' use cross-sectional ranking which helps, but the 'LER' factor's denominator (TS_STD of returns) might be conflating volatility with exhaustion, leading to the observed drawdown.",
        "decision": true,
        "reason": "The current LER factor uses TS_STD(return, 5), which can spike during high-momentum trends, causing false reversal signals. By using a longer-term ATR (e.g., 20 days) for normalization and ensuring the volume is strictly lower than its recent average (rather than just using a rank), we can better isolate 'exhaustion' from 'breakouts'. Additionally, keeping the symbol length low and using fewer base features will improve the generalization which is currently lacking as evidenced by the high drawdown."
      }
    },
    "46049e04510f71b8": {
      "factor_id": "46049e04510f71b8",
      "factor_name": "Trend_Fragility_Index_5_10",
      "factor_expression": "TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by calculating the ratio of short-term volatility to medium-term trend linearity. A high ratio suggests that price noise is destabilizing the established trend. Linearity is measured by the square of the correlation between price and a time sequence (R-squared).",
      "factor_formulation": "\\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "cae91ef94d98",
        "parent_trajectory_ids": [
          "5085d64cf66b"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term volatility (STD5) to medium-term trend linearity (RSQR10), where a high ratio signifies that price noise is destabilizing the established trend structure.\n                Concise Observation: Previous factors focused on price-volume decoupling (RankIC 0.02) and overnight gaps, but ignored the internal 'friction' or noise within a trend; high-linearity trends often fail abruptly when short-term volatility spikes relative to the trend's historical stability.\n                Concise Justification: A stable trend requires low variance relative to its trajectory; as the ratio of standard deviation to trend-fit (RSQR) rises, it indicates that the 'signal' (trend) is being overwhelmed by 'noise' (volatility), suggesting a loss of consensus among market participants.\n                Concise Knowledge: If short-term price variance increases while the medium-term R-squared (linearity) remains high or begins to decay, the trend is likely entering a 'fragile' state; When volatility exceeds the explanatory power of the trend line, a structural break or mean-reversion is statistically imminent.\n                concise Specification: The factor is defined as the 5-day standard deviation of close prices divided by the square of the 10-day Pearson correlation between close prices and a time sequence (RSQR10), constrained to periods where the trend is still nominally intact.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T01:23:30.362319"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1268054049537387,
        "ICIR": 0.0170800221112406,
        "1day.excess_return_without_cost.std": 0.0038681668315583,
        "1day.excess_return_with_cost.annualized_return": -0.0095145830866645,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001587308185563,
        "1day.excess_return_without_cost.annualized_return": 0.037777934816407,
        "1day.excess_return_with_cost.std": 0.0038704401364704,
        "Rank IC": 0.0138424323941432,
        "IC": 0.0022198914931345,
        "1day.excess_return_without_cost.max_drawdown": -0.080245327060063,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6330595106788753,
        "1day.pa": 0.0,
        "l2.valid": 0.996944061273624,
        "Rank ICIR": 0.1058711411446404,
        "l2.train": 0.9943381391560736,
        "1day.excess_return_with_cost.information_ratio": -0.1593459133163731,
        "1day.excess_return_with_cost.mean": -3.997723985993493e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility Index' framework. While the core concept of comparing short-term noise to trend linearity is theoretically sound, the current implementations (Trend_Fragility_Index_5_10, Fragility_ZScore_Momentum, and Relative_Noise_Trend_Ratio) failed to outperform the existing SOTA result across all key metrics, including IC (0.0022 vs 0.0058) and Information Ratio (0.633 vs 0.972). The use of R-squared (POW of CORR) as a denominator likely introduces extreme values and instability when the correlation is near zero, which may be degrading the predictive signal.",
        "hypothesis_evaluation": "The results partially support the hypothesis that noise-to-trend ratios contain information, but the current mathematical formulations are likely too unstable. The 'Relative_Noise_Trend_Ratio' introduced additional complexity by using high-low ranges, yet the overall performance remained below SOTA. The fragility concept needs a more robust denominator or a 'softened' transition to prevent the factor from being dominated by outliers when trend linearity is low.",
        "decision": false,
        "reason": "The current factors suffer from high sensitivity when the denominator (TS_CORR^2) approaches zero, leading to extreme factor values that likely represent noise rather than true fragility. By using a '1 + Correlation' structure or a rank-based denominator, we can maintain the logic of the ratio while ensuring numerical stability. Additionally, incorporating volume into the noise proxy (numerator) can help distinguish between high-volatility price discovery and true destabilizing noise."
      }
    },
    "1c236b69e660a75e": {
      "factor_id": "1c236b69e660a75e",
      "factor_name": "Fragility_ZScore_Momentum",
      "factor_expression": "RANK(TS_STD($close, 5) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($close, 5) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Fragility_ZScore_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A standardized version of trend fragility that measures the cross-sectional rank of short-term price noise relative to the stability of the 20-day trend. It focuses on identifying stocks where the current 5-day volatility is abnormally high compared to its 20-day linear trend fit.",
      "factor_formulation": "RANK(TS\\_STD(close, 5) / ABS(TS\\_CORR(close, SEQUENCE(20), 20)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "cae91ef94d98",
        "parent_trajectory_ids": [
          "5085d64cf66b"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term volatility (STD5) to medium-term trend linearity (RSQR10), where a high ratio signifies that price noise is destabilizing the established trend structure.\n                Concise Observation: Previous factors focused on price-volume decoupling (RankIC 0.02) and overnight gaps, but ignored the internal 'friction' or noise within a trend; high-linearity trends often fail abruptly when short-term volatility spikes relative to the trend's historical stability.\n                Concise Justification: A stable trend requires low variance relative to its trajectory; as the ratio of standard deviation to trend-fit (RSQR) rises, it indicates that the 'signal' (trend) is being overwhelmed by 'noise' (volatility), suggesting a loss of consensus among market participants.\n                Concise Knowledge: If short-term price variance increases while the medium-term R-squared (linearity) remains high or begins to decay, the trend is likely entering a 'fragile' state; When volatility exceeds the explanatory power of the trend line, a structural break or mean-reversion is statistically imminent.\n                concise Specification: The factor is defined as the 5-day standard deviation of close prices divided by the square of the 10-day Pearson correlation between close prices and a time sequence (RSQR10), constrained to periods where the trend is still nominally intact.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T01:23:30.362319"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1268054049537387,
        "ICIR": 0.0170800221112406,
        "1day.excess_return_without_cost.std": 0.0038681668315583,
        "1day.excess_return_with_cost.annualized_return": -0.0095145830866645,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001587308185563,
        "1day.excess_return_without_cost.annualized_return": 0.037777934816407,
        "1day.excess_return_with_cost.std": 0.0038704401364704,
        "Rank IC": 0.0138424323941432,
        "IC": 0.0022198914931345,
        "1day.excess_return_without_cost.max_drawdown": -0.080245327060063,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6330595106788753,
        "1day.pa": 0.0,
        "l2.valid": 0.996944061273624,
        "Rank ICIR": 0.1058711411446404,
        "l2.train": 0.9943381391560736,
        "1day.excess_return_with_cost.information_ratio": -0.1593459133163731,
        "1day.excess_return_with_cost.mean": -3.997723985993493e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility Index' framework. While the core concept of comparing short-term noise to trend linearity is theoretically sound, the current implementations (Trend_Fragility_Index_5_10, Fragility_ZScore_Momentum, and Relative_Noise_Trend_Ratio) failed to outperform the existing SOTA result across all key metrics, including IC (0.0022 vs 0.0058) and Information Ratio (0.633 vs 0.972). The use of R-squared (POW of CORR) as a denominator likely introduces extreme values and instability when the correlation is near zero, which may be degrading the predictive signal.",
        "hypothesis_evaluation": "The results partially support the hypothesis that noise-to-trend ratios contain information, but the current mathematical formulations are likely too unstable. The 'Relative_Noise_Trend_Ratio' introduced additional complexity by using high-low ranges, yet the overall performance remained below SOTA. The fragility concept needs a more robust denominator or a 'softened' transition to prevent the factor from being dominated by outliers when trend linearity is low.",
        "decision": false,
        "reason": "The current factors suffer from high sensitivity when the denominator (TS_CORR^2) approaches zero, leading to extreme factor values that likely represent noise rather than true fragility. By using a '1 + Correlation' structure or a rank-based denominator, we can maintain the logic of the ratio while ensuring numerical stability. Additionally, incorporating volume into the noise proxy (numerator) can help distinguish between high-volatility price discovery and true destabilizing noise."
      }
    },
    "8764ebd02e272375": {
      "factor_id": "8764ebd02e272375",
      "factor_name": "Relative_Noise_Trend_Ratio",
      "factor_expression": "TS_MEAN($high - $low, 10) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($high - $low, 10) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Noise_Trend_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures 'trend friction' by comparing the 10-day price range (noise proxy) to the strength of the linear trend. It uses the inverse of the R-squared to amplify signals where the trend linearity is decaying while price swings (high-low) remain wide.",
      "factor_formulation": "\\frac{TS\\_MEAN(high - low, 10)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "cae91ef94d98",
        "parent_trajectory_ids": [
          "5085d64cf66b"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term volatility (STD5) to medium-term trend linearity (RSQR10), where a high ratio signifies that price noise is destabilizing the established trend structure.\n                Concise Observation: Previous factors focused on price-volume decoupling (RankIC 0.02) and overnight gaps, but ignored the internal 'friction' or noise within a trend; high-linearity trends often fail abruptly when short-term volatility spikes relative to the trend's historical stability.\n                Concise Justification: A stable trend requires low variance relative to its trajectory; as the ratio of standard deviation to trend-fit (RSQR) rises, it indicates that the 'signal' (trend) is being overwhelmed by 'noise' (volatility), suggesting a loss of consensus among market participants.\n                Concise Knowledge: If short-term price variance increases while the medium-term R-squared (linearity) remains high or begins to decay, the trend is likely entering a 'fragile' state; When volatility exceeds the explanatory power of the trend line, a structural break or mean-reversion is statistically imminent.\n                concise Specification: The factor is defined as the 5-day standard deviation of close prices divided by the square of the 10-day Pearson correlation between close prices and a time sequence (RSQR10), constrained to periods where the trend is still nominally intact.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T01:23:30.362319"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1268054049537387,
        "ICIR": 0.0170800221112406,
        "1day.excess_return_without_cost.std": 0.0038681668315583,
        "1day.excess_return_with_cost.annualized_return": -0.0095145830866645,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001587308185563,
        "1day.excess_return_without_cost.annualized_return": 0.037777934816407,
        "1day.excess_return_with_cost.std": 0.0038704401364704,
        "Rank IC": 0.0138424323941432,
        "IC": 0.0022198914931345,
        "1day.excess_return_without_cost.max_drawdown": -0.080245327060063,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6330595106788753,
        "1day.pa": 0.0,
        "l2.valid": 0.996944061273624,
        "Rank ICIR": 0.1058711411446404,
        "l2.train": 0.9943381391560736,
        "1day.excess_return_with_cost.information_ratio": -0.1593459133163731,
        "1day.excess_return_with_cost.mean": -3.997723985993493e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Trend Fragility Index' framework. While the core concept of comparing short-term noise to trend linearity is theoretically sound, the current implementations (Trend_Fragility_Index_5_10, Fragility_ZScore_Momentum, and Relative_Noise_Trend_Ratio) failed to outperform the existing SOTA result across all key metrics, including IC (0.0022 vs 0.0058) and Information Ratio (0.633 vs 0.972). The use of R-squared (POW of CORR) as a denominator likely introduces extreme values and instability when the correlation is near zero, which may be degrading the predictive signal.",
        "hypothesis_evaluation": "The results partially support the hypothesis that noise-to-trend ratios contain information, but the current mathematical formulations are likely too unstable. The 'Relative_Noise_Trend_Ratio' introduced additional complexity by using high-low ranges, yet the overall performance remained below SOTA. The fragility concept needs a more robust denominator or a 'softened' transition to prevent the factor from being dominated by outliers when trend linearity is low.",
        "decision": false,
        "reason": "The current factors suffer from high sensitivity when the denominator (TS_CORR^2) approaches zero, leading to extreme factor values that likely represent noise rather than true fragility. By using a '1 + Correlation' structure or a rank-based denominator, we can maintain the logic of the ratio while ensuring numerical stability. Additionally, incorporating volume into the noise proxy (numerator) can help distinguish between high-volatility price discovery and true destabilizing noise."
      }
    },
    "e06ec02ad7100883": {
      "factor_id": "e06ec02ad7100883",
      "factor_name": "Liquidity_Adj_Residual_Rebound_5D",
      "factor_expression": "REGRESI($close, SEQUENCE(5), 5) / (TS_STD($volume, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, SEQUENCE(5), 5) / (TS_STD($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adj_Residual_Rebound_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies mean-reversion opportunities by calculating the residual of a 5-day linear regression of close prices against time, normalized by the 5-day standard deviation of volume. It targets 'orderly' price exhaustion where deep negative residuals occur under stable liquidity conditions.",
      "factor_formulation": "\\frac{\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(5), 5)}{\\text{TS\\_STD}(\\text{volume}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "5dfec909e9a0",
        "parent_trajectory_ids": [
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Residual Rebound' factor, defined as the 5-day price residual from a linear trend normalized by the 5-day volume standard deviation, identifies high-probability mean-reversion opportunities where price exhaustion occurs under stable liquidity conditions.\n                Concise Observation: The parent strategy focused on the resonance between intraday ranges and overnight gaps (macro-volatility), but failed to account for the 'quality' of the price move; specifically, extreme price residuals often lead to reversals if they are not accompanied by erratic volume spikes.\n                Concise Justification: A deep negative residual from a 5-day trend represents a short-term 'oversold' state; by dividing this by the standard deviation of volume (VSTD5), we filter out high-volatility 'falling knives' (where liquidity is chaotic) and isolate assets where the sell-off is structured and likely to find support.\n                Concise Knowledge: If a significant price deviation (residual) occurs with low volume volatility, it indicates an orderly distribution or accumulation phase; when such residuals are deeply negative despite stable liquidity, the probability of a technical rebound increases as selling pressure is exhausted without panic.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing it by the 5-day standard deviation of $volume. Deep negative values are expected to positively predict returns over the next 1-5 days.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T01:28:48.018614"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105855136782734,
        "ICIR": 0.0325257595112503,
        "1day.excess_return_without_cost.std": 0.0044483988958076,
        "1day.excess_return_with_cost.annualized_return": 0.0313873725661481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302485434404,
        "1day.excess_return_without_cost.annualized_return": 0.0785991533388339,
        "1day.excess_return_with_cost.std": 0.0044495549476525,
        "Rank IC": 0.0209098654515188,
        "IC": 0.0045621960948891,
        "1day.excess_return_without_cost.max_drawdown": -0.0930634458766356,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1453168894160073,
        "1day.pa": 0.0,
        "l2.valid": 0.9966316508178462,
        "Rank ICIR": 0.1520133690268346,
        "l2.train": 0.9945963623200476,
        "1day.excess_return_with_cost.information_ratio": 0.4572459944703024,
        "1day.excess_return_with_cost.mean": 0.0001318797166644
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Liquidity-Adjusted Residual Rebound' framework. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 7.86%), although the IC slightly decreased and the Max Drawdown deepened. The core mechanism of using price residuals from a linear trend normalized by volume volatility appears to capture meaningful mean-reversion signals. Specifically, the 'Oversold_Residual_Volume_Filter_10D' and 'Ranked_Residual_Stability_Ratio_5D' variations suggest that both time-series normalization (Z-score) and cross-sectional ranking are effective ways to refine the raw residual signal.",
        "hypothesis_evaluation": "The results generally support the hypothesis. Normalizing price residuals by volume standard deviation helps isolate price exhaustion occurring under 'stable' liquidity, which leads to higher quality mean-reversion signals. The improvement in Information Ratio suggests that the 'liquidity-adjusted' component effectively filters out high-volatility noise that typically plagues simple residual factors. However, the slightly lower IC suggests that while the signal is higher quality (better IR), its raw predictive correlation across the entire universe might be weaker than the SOTA, potentially acting more as a tail-event indicator.",
        "decision": true,
        "reason": "While the current 'TS_STD(volume, n)' effectively measures stability, it doesn't distinguish between high-volume stability and low-volume stability. A mean-reversion signal is often more robust when price reaches a limit on low or average volume (exhaustion) rather than high volume (breakdown). By integrating a volume percentile or a 'Volume Intensity' filter, we can refine the denominator of the current factor to better capture the 'orderly' nature of the price exhaustion."
      }
    },
    "80125e44729836d6": {
      "factor_id": "80125e44729836d6",
      "factor_name": "Ranked_Residual_Stability_Ratio_5D",
      "factor_expression": "RANK(REGRESI($close, SEQUENCE(5), 5)) / (RANK(TS_STD($volume, 5)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, SEQUENCE(5), 5)) / (RANK(TS_STD($volume, 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Residual_Stability_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the liquidity-adjusted residual. It measures the relative magnitude of price deviation from its 5-day trend compared to the stability of volume, identifying assets with the most structured oversold conditions relative to the market.",
      "factor_formulation": "\\text{RANK}(\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(5), 5)) / \\text{RANK}(TS\\_STD(\\text{volume}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "5dfec909e9a0",
        "parent_trajectory_ids": [
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Residual Rebound' factor, defined as the 5-day price residual from a linear trend normalized by the 5-day volume standard deviation, identifies high-probability mean-reversion opportunities where price exhaustion occurs under stable liquidity conditions.\n                Concise Observation: The parent strategy focused on the resonance between intraday ranges and overnight gaps (macro-volatility), but failed to account for the 'quality' of the price move; specifically, extreme price residuals often lead to reversals if they are not accompanied by erratic volume spikes.\n                Concise Justification: A deep negative residual from a 5-day trend represents a short-term 'oversold' state; by dividing this by the standard deviation of volume (VSTD5), we filter out high-volatility 'falling knives' (where liquidity is chaotic) and isolate assets where the sell-off is structured and likely to find support.\n                Concise Knowledge: If a significant price deviation (residual) occurs with low volume volatility, it indicates an orderly distribution or accumulation phase; when such residuals are deeply negative despite stable liquidity, the probability of a technical rebound increases as selling pressure is exhausted without panic.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing it by the 5-day standard deviation of $volume. Deep negative values are expected to positively predict returns over the next 1-5 days.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T01:28:48.018614"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105855136782734,
        "ICIR": 0.0325257595112503,
        "1day.excess_return_without_cost.std": 0.0044483988958076,
        "1day.excess_return_with_cost.annualized_return": 0.0313873725661481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302485434404,
        "1day.excess_return_without_cost.annualized_return": 0.0785991533388339,
        "1day.excess_return_with_cost.std": 0.0044495549476525,
        "Rank IC": 0.0209098654515188,
        "IC": 0.0045621960948891,
        "1day.excess_return_without_cost.max_drawdown": -0.0930634458766356,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1453168894160073,
        "1day.pa": 0.0,
        "l2.valid": 0.9966316508178462,
        "Rank ICIR": 0.1520133690268346,
        "l2.train": 0.9945963623200476,
        "1day.excess_return_with_cost.information_ratio": 0.4572459944703024,
        "1day.excess_return_with_cost.mean": 0.0001318797166644
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Liquidity-Adjusted Residual Rebound' framework. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 7.86%), although the IC slightly decreased and the Max Drawdown deepened. The core mechanism of using price residuals from a linear trend normalized by volume volatility appears to capture meaningful mean-reversion signals. Specifically, the 'Oversold_Residual_Volume_Filter_10D' and 'Ranked_Residual_Stability_Ratio_5D' variations suggest that both time-series normalization (Z-score) and cross-sectional ranking are effective ways to refine the raw residual signal.",
        "hypothesis_evaluation": "The results generally support the hypothesis. Normalizing price residuals by volume standard deviation helps isolate price exhaustion occurring under 'stable' liquidity, which leads to higher quality mean-reversion signals. The improvement in Information Ratio suggests that the 'liquidity-adjusted' component effectively filters out high-volatility noise that typically plagues simple residual factors. However, the slightly lower IC suggests that while the signal is higher quality (better IR), its raw predictive correlation across the entire universe might be weaker than the SOTA, potentially acting more as a tail-event indicator.",
        "decision": true,
        "reason": "While the current 'TS_STD(volume, n)' effectively measures stability, it doesn't distinguish between high-volume stability and low-volume stability. A mean-reversion signal is often more robust when price reaches a limit on low or average volume (exhaustion) rather than high volume (breakdown). By integrating a volume percentile or a 'Volume Intensity' filter, we can refine the denominator of the current factor to better capture the 'orderly' nature of the price exhaustion."
      }
    },
    "f11b8ea2b17e97d0": {
      "factor_id": "f11b8ea2b17e97d0",
      "factor_name": "Oversold_Residual_Volume_Filter_10D",
      "factor_expression": "TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 10) / (TS_STD($volume, 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 10) / (TS_STD($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Oversold_Residual_Volume_Filter_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor focuses on the interaction between price residuals and volume volatility over a slightly longer 10-day window. It uses the Z-score of the price residual divided by the volume standard deviation to isolate statistical outliers in price that are not driven by volume shocks.",
      "factor_formulation": "\\frac{\\text{TS\\_ZSCORE}(\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(10), 10), 10)}{\\text{TS\\_STD}(\\text{volume}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "5dfec909e9a0",
        "parent_trajectory_ids": [
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Residual Rebound' factor, defined as the 5-day price residual from a linear trend normalized by the 5-day volume standard deviation, identifies high-probability mean-reversion opportunities where price exhaustion occurs under stable liquidity conditions.\n                Concise Observation: The parent strategy focused on the resonance between intraday ranges and overnight gaps (macro-volatility), but failed to account for the 'quality' of the price move; specifically, extreme price residuals often lead to reversals if they are not accompanied by erratic volume spikes.\n                Concise Justification: A deep negative residual from a 5-day trend represents a short-term 'oversold' state; by dividing this by the standard deviation of volume (VSTD5), we filter out high-volatility 'falling knives' (where liquidity is chaotic) and isolate assets where the sell-off is structured and likely to find support.\n                Concise Knowledge: If a significant price deviation (residual) occurs with low volume volatility, it indicates an orderly distribution or accumulation phase; when such residuals are deeply negative despite stable liquidity, the probability of a technical rebound increases as selling pressure is exhausted without panic.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close price against time, then dividing it by the 5-day standard deviation of $volume. Deep negative values are expected to positively predict returns over the next 1-5 days.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T01:28:48.018614"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1105855136782734,
        "ICIR": 0.0325257595112503,
        "1day.excess_return_without_cost.std": 0.0044483988958076,
        "1day.excess_return_with_cost.annualized_return": 0.0313873725661481,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003302485434404,
        "1day.excess_return_without_cost.annualized_return": 0.0785991533388339,
        "1day.excess_return_with_cost.std": 0.0044495549476525,
        "Rank IC": 0.0209098654515188,
        "IC": 0.0045621960948891,
        "1day.excess_return_without_cost.max_drawdown": -0.0930634458766356,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1453168894160073,
        "1day.pa": 0.0,
        "l2.valid": 0.9966316508178462,
        "Rank ICIR": 0.1520133690268346,
        "l2.train": 0.9945963623200476,
        "1day.excess_return_with_cost.information_ratio": 0.4572459944703024,
        "1day.excess_return_with_cost.mean": 0.0001318797166644
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Liquidity-Adjusted Residual Rebound' framework. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.15) and Annualized Return (increased from 5.2% to 7.86%), although the IC slightly decreased and the Max Drawdown deepened. The core mechanism of using price residuals from a linear trend normalized by volume volatility appears to capture meaningful mean-reversion signals. Specifically, the 'Oversold_Residual_Volume_Filter_10D' and 'Ranked_Residual_Stability_Ratio_5D' variations suggest that both time-series normalization (Z-score) and cross-sectional ranking are effective ways to refine the raw residual signal.",
        "hypothesis_evaluation": "The results generally support the hypothesis. Normalizing price residuals by volume standard deviation helps isolate price exhaustion occurring under 'stable' liquidity, which leads to higher quality mean-reversion signals. The improvement in Information Ratio suggests that the 'liquidity-adjusted' component effectively filters out high-volatility noise that typically plagues simple residual factors. However, the slightly lower IC suggests that while the signal is higher quality (better IR), its raw predictive correlation across the entire universe might be weaker than the SOTA, potentially acting more as a tail-event indicator.",
        "decision": true,
        "reason": "While the current 'TS_STD(volume, n)' effectively measures stability, it doesn't distinguish between high-volume stability and low-volume stability. A mean-reversion signal is often more robust when price reaches a limit on low or average volume (exhaustion) rather than high volume (breakdown). By integrating a volume percentile or a 'Volume Intensity' filter, we can refine the denominator of the current factor to better capture the 'orderly' nature of the price exhaustion."
      }
    },
    "edb6973ddd5760f8": {
      "factor_id": "edb6973ddd5760f8",
      "factor_name": "Liquidity_Vacuum_Reversal_20D",
      "factor_expression": "(TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * ($close / TS_MEAN($close, 20) - 1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * ($close / TS_MEAN($close, 20) - 1)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'hollow' price movements where the intraday range expands without significant volume support, indicating a liquidity vacuum. It multiplies this liquidity gap by the 5-day price deviation from its 20-day mean to predict mean reversion. High values suggest an overextended trend likely to reverse.",
      "factor_formulation": "LVR = \\frac{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 3)}{\\text{TS\\_MEAN}(\\text{volume}, 20) + 1e-8} \\times \\left(\\frac{\\text{close}}{\\text{TS\\_MEAN}(\\text{close}, 20)} - 1\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "f3ed5e2305aa",
        "parent_trajectory_ids": [
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the 3-day average price range to the 20-day average volume, multiplied by the 5-day price reversal magnitude, negatively predicts future returns by identifying trend exhaustion caused by liquidity gaps.\n                Concise Observation: While the parent strategy successfully captured alpha through linear, volume-supported trends (IR 1.49), it fails to account for 'hollow' volatility spikes where price range expands without corresponding turnover, often preceding sharp reversals.\n                Concise Justification: High intraday dispersion (High-Low) relative to historical volume suggests that price discovery is being driven by a lack of liquidity rather than high-conviction trading, creating an unstable price level that is susceptible to mean reversion.\n                Concise Knowledge: If a price move occurs with expanding intraday ranges but diminishing volume support, it indicates a liquidity vacuum; when such exhaustion is detected, the price is likely to mean-revert to its 20-day moving average as the trend lacks institutional participation.\n                concise Specification: The factor is calculated as (TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * ($close / TS_MEAN($close, 20) - 1), where a high positive value indicates an overextended 'hollow' uptrend ripe for a downward reversal.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T01:32:01.719967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.154347233377052,
        "ICIR": 0.0573915026876882,
        "1day.excess_return_without_cost.std": 0.0046124234505751,
        "1day.excess_return_with_cost.annualized_return": 0.0066816040760919,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002294108373371,
        "1day.excess_return_without_cost.annualized_return": 0.0545997792862316,
        "1day.excess_return_with_cost.std": 0.004613250179658,
        "Rank IC": 0.0255656317314589,
        "IC": 0.0082447314136444,
        "1day.excess_return_without_cost.max_drawdown": -0.1214971840253457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7673142029933999,
        "1day.pa": 0.0,
        "l2.valid": 0.9961831118823028,
        "Rank ICIR": 0.1815980226732771,
        "l2.train": 0.9928342635614305,
        "1day.excess_return_with_cost.information_ratio": 0.0938826309598739,
        "1day.excess_return_with_cost.mean": 2.807396670626852e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Vacuum' hypothesis by testing three variations: a raw ratio interaction (LVR), a cross-sectional rank interaction (RHVE), and a time-series Z-score approach (ZLGM). The results show a notable improvement in predictive accuracy (IC increased from 0.0058 to 0.0082) and a slight increase in annualized return (0.0546 vs 0.0520). However, the Information Ratio (IR) decreased and the Max Drawdown (MDD) significantly worsened (-0.121 vs -0.072), suggesting that while the signal strength is higher, the volatility or tail risk of the factor has increased.",
        "hypothesis_evaluation": "The hypothesis that liquidity gaps (high range/low volume) coupled with price overextension predict reversals is supported by the improved IC and annualized return. The 'ZScored_Liquidity_Gap_Momentum' and 'Ranked_Hollow_Volatility_Exhaustion' implementations likely contributed to the higher signal capture. The deterioration in MDD suggests that the 'vacuum' effect might be prone to 'gap-and-go' scenarios where the trend continues despite thin liquidity, leading to sharp drawdowns in a mean-reversion strategy.",
        "decision": true,
        "reason": "The current results show high signal (IC) but poor risk-adjusted stability (MDD/IR). By replacing the raw 'high-low' with a volatility-normalized measure, we can better distinguish between a genuine 'liquidity vacuum' and standard high-volatility regimes. Additionally, shortening the volume lookback from 20 days to 5 days will make the factor more responsive to sudden shifts in market depth, potentially reducing the drawdown by exiting or entering positions closer to the actual exhaustion point."
      }
    },
    "0543469557de0c6c": {
      "factor_id": "0543469557de0c6c",
      "factor_name": "Ranked_Hollow_Volatility_Exhaustion",
      "factor_expression": "RANK(TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * RANK(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Hollow_Volatility_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the liquidity vacuum hypothesis. It measures the intensity of price range expansion relative to volume turnover, weighted by the recent price momentum relative to its 20-day average. It targets stocks where price discovery is thin and likely to snap back.",
      "factor_formulation": "RHVE = \\text{RANK}\\left(\\frac{TS\\_MEAN(high - low, 3)}{TS\\_MEAN(volume, 20) + 1e-8}\\right) \\times \\text{RANK}(TS\\_PCTCHANGE(close, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "f3ed5e2305aa",
        "parent_trajectory_ids": [
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the 3-day average price range to the 20-day average volume, multiplied by the 5-day price reversal magnitude, negatively predicts future returns by identifying trend exhaustion caused by liquidity gaps.\n                Concise Observation: While the parent strategy successfully captured alpha through linear, volume-supported trends (IR 1.49), it fails to account for 'hollow' volatility spikes where price range expands without corresponding turnover, often preceding sharp reversals.\n                Concise Justification: High intraday dispersion (High-Low) relative to historical volume suggests that price discovery is being driven by a lack of liquidity rather than high-conviction trading, creating an unstable price level that is susceptible to mean reversion.\n                Concise Knowledge: If a price move occurs with expanding intraday ranges but diminishing volume support, it indicates a liquidity vacuum; when such exhaustion is detected, the price is likely to mean-revert to its 20-day moving average as the trend lacks institutional participation.\n                concise Specification: The factor is calculated as (TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * ($close / TS_MEAN($close, 20) - 1), where a high positive value indicates an overextended 'hollow' uptrend ripe for a downward reversal.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T01:32:01.719967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.154347233377052,
        "ICIR": 0.0573915026876882,
        "1day.excess_return_without_cost.std": 0.0046124234505751,
        "1day.excess_return_with_cost.annualized_return": 0.0066816040760919,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002294108373371,
        "1day.excess_return_without_cost.annualized_return": 0.0545997792862316,
        "1day.excess_return_with_cost.std": 0.004613250179658,
        "Rank IC": 0.0255656317314589,
        "IC": 0.0082447314136444,
        "1day.excess_return_without_cost.max_drawdown": -0.1214971840253457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7673142029933999,
        "1day.pa": 0.0,
        "l2.valid": 0.9961831118823028,
        "Rank ICIR": 0.1815980226732771,
        "l2.train": 0.9928342635614305,
        "1day.excess_return_with_cost.information_ratio": 0.0938826309598739,
        "1day.excess_return_with_cost.mean": 2.807396670626852e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Vacuum' hypothesis by testing three variations: a raw ratio interaction (LVR), a cross-sectional rank interaction (RHVE), and a time-series Z-score approach (ZLGM). The results show a notable improvement in predictive accuracy (IC increased from 0.0058 to 0.0082) and a slight increase in annualized return (0.0546 vs 0.0520). However, the Information Ratio (IR) decreased and the Max Drawdown (MDD) significantly worsened (-0.121 vs -0.072), suggesting that while the signal strength is higher, the volatility or tail risk of the factor has increased.",
        "hypothesis_evaluation": "The hypothesis that liquidity gaps (high range/low volume) coupled with price overextension predict reversals is supported by the improved IC and annualized return. The 'ZScored_Liquidity_Gap_Momentum' and 'Ranked_Hollow_Volatility_Exhaustion' implementations likely contributed to the higher signal capture. The deterioration in MDD suggests that the 'vacuum' effect might be prone to 'gap-and-go' scenarios where the trend continues despite thin liquidity, leading to sharp drawdowns in a mean-reversion strategy.",
        "decision": true,
        "reason": "The current results show high signal (IC) but poor risk-adjusted stability (MDD/IR). By replacing the raw 'high-low' with a volatility-normalized measure, we can better distinguish between a genuine 'liquidity vacuum' and standard high-volatility regimes. Additionally, shortening the volume lookback from 20 days to 5 days will make the factor more responsive to sudden shifts in market depth, potentially reducing the drawdown by exiting or entering positions closer to the actual exhaustion point."
      }
    },
    "4325619929762978": {
      "factor_id": "4325619929762978",
      "factor_name": "ZScored_Liquidity_Gap_Momentum",
      "factor_expression": "TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 20) + 1e-8), 10) * TS_ZSCORE($close, 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / (TS_MEAN($volume, 20) + 1e-8), 10) * TS_ZSCORE($close, 20)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Liquidity_Gap_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor standardizes the ratio of intraday volatility to volume and interacts it with the 20-day price Z-score. It captures extreme price levels that lack institutional volume support, signaling a high probability of trend exhaustion and subsequent reversal.",
      "factor_formulation": "ZLGM = \\text{TS\\_ZSCORE}\\left(\\frac{high - low}{TS\\_MEAN(volume, 20) + 1e-8}, 10\\right) \\times \\text{TS\\_ZSCORE}(close, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "f3ed5e2305aa",
        "parent_trajectory_ids": [
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' factor, defined as the ratio of the 3-day average price range to the 20-day average volume, multiplied by the 5-day price reversal magnitude, negatively predicts future returns by identifying trend exhaustion caused by liquidity gaps.\n                Concise Observation: While the parent strategy successfully captured alpha through linear, volume-supported trends (IR 1.49), it fails to account for 'hollow' volatility spikes where price range expands without corresponding turnover, often preceding sharp reversals.\n                Concise Justification: High intraday dispersion (High-Low) relative to historical volume suggests that price discovery is being driven by a lack of liquidity rather than high-conviction trading, creating an unstable price level that is susceptible to mean reversion.\n                Concise Knowledge: If a price move occurs with expanding intraday ranges but diminishing volume support, it indicates a liquidity vacuum; when such exhaustion is detected, the price is likely to mean-revert to its 20-day moving average as the trend lacks institutional participation.\n                concise Specification: The factor is calculated as (TS_MEAN($high - $low, 3) / (TS_MEAN($volume, 20) + 1e-8)) * ($close / TS_MEAN($close, 20) - 1), where a high positive value indicates an overextended 'hollow' uptrend ripe for a downward reversal.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T01:32:01.719967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.154347233377052,
        "ICIR": 0.0573915026876882,
        "1day.excess_return_without_cost.std": 0.0046124234505751,
        "1day.excess_return_with_cost.annualized_return": 0.0066816040760919,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002294108373371,
        "1day.excess_return_without_cost.annualized_return": 0.0545997792862316,
        "1day.excess_return_with_cost.std": 0.004613250179658,
        "Rank IC": 0.0255656317314589,
        "IC": 0.0082447314136444,
        "1day.excess_return_without_cost.max_drawdown": -0.1214971840253457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7673142029933999,
        "1day.pa": 0.0,
        "l2.valid": 0.9961831118823028,
        "Rank ICIR": 0.1815980226732771,
        "l2.train": 0.9928342635614305,
        "1day.excess_return_with_cost.information_ratio": 0.0938826309598739,
        "1day.excess_return_with_cost.mean": 2.807396670626852e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Mean-Reverting Liquidity Vacuum' hypothesis by testing three variations: a raw ratio interaction (LVR), a cross-sectional rank interaction (RHVE), and a time-series Z-score approach (ZLGM). The results show a notable improvement in predictive accuracy (IC increased from 0.0058 to 0.0082) and a slight increase in annualized return (0.0546 vs 0.0520). However, the Information Ratio (IR) decreased and the Max Drawdown (MDD) significantly worsened (-0.121 vs -0.072), suggesting that while the signal strength is higher, the volatility or tail risk of the factor has increased.",
        "hypothesis_evaluation": "The hypothesis that liquidity gaps (high range/low volume) coupled with price overextension predict reversals is supported by the improved IC and annualized return. The 'ZScored_Liquidity_Gap_Momentum' and 'Ranked_Hollow_Volatility_Exhaustion' implementations likely contributed to the higher signal capture. The deterioration in MDD suggests that the 'vacuum' effect might be prone to 'gap-and-go' scenarios where the trend continues despite thin liquidity, leading to sharp drawdowns in a mean-reversion strategy.",
        "decision": true,
        "reason": "The current results show high signal (IC) but poor risk-adjusted stability (MDD/IR). By replacing the raw 'high-low' with a volatility-normalized measure, we can better distinguish between a genuine 'liquidity vacuum' and standard high-volatility regimes. Additionally, shortening the volume lookback from 20 days to 5 days will make the factor more responsive to sudden shifts in market depth, potentially reducing the drawdown by exiting or entering positions closer to the actual exhaustion point."
      }
    },
    "7795d8db490b2597": {
      "factor_id": "7795d8db490b2597",
      "factor_name": "Institutional_Absorption_Linearity_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(-TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(-TS_MEAN(($high - $low) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Linearity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional 'stealth' accumulation by combining high price trend linearity (R-squared) with low volume-weighted price variance. High linearity suggests a persistent trend, while low price range relative to volume suggests efficient absorption of liquidity without significant price disruption.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2) \\times \\text{RANK}(-\\text{TS\\_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{volume} + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "73b597195b6e",
        "parent_trajectory_ids": [
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor identifies high-conviction accumulation by detecting assets with high price-trend linearity (RSQR10) coupled with low volume-weighted price variance (WVMA5), signaling efficient, non-disruptive buying regimes.\n                Concise Observation: The parent strategy focused on high-volume capitulation and overnight gaps for mean-reversion, whereas many high-performing assets exhibit 'quiet' intraday drift with low noise and steady price discovery during the continuous session.\n                Concise Justification: Institutional investors often use algorithms (like VWAP or TWAP) to absorb liquidity without moving the market significantly; this results in a high degree of trend linearity (high RSQR) and suppressed volatility relative to volume (low WVMA), preceding a breakout.\n                Concise Knowledge: If a stock exhibits high R-squared in its price trend while maintaining low volume-weighted volatility, it suggests institutional 'stealth' accumulation; when price climbs steadily without volume-induced spikes, it indicates a lack of selling pressure and high-quality trend persistence.\n                concise Specification: Define RSQR10 as the R-squared of $close against a time index over 10 days; define WVMA5 as the 5-day moving average of (High-Low)/Volume; the factor is the product of RANK(RSQR10) and RANK(-WVMA5) to capture the intersection of linearity and absorption.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T01:50:26.364243"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0904433804627169,
        "ICIR": 0.0362042504417642,
        "1day.excess_return_without_cost.std": 0.0041275073816727,
        "1day.excess_return_with_cost.annualized_return": 0.0175996427758389,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002710795218675,
        "1day.excess_return_without_cost.annualized_return": 0.0645169262044669,
        "1day.excess_return_with_cost.std": 0.004128263845032,
        "Rank IC": 0.0214120776352466,
        "IC": 0.0049821618834091,
        "1day.excess_return_without_cost.max_drawdown": -0.0831702281547032,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0132050152973342,
        "1day.pa": 0.0,
        "l2.valid": 0.9964855137421704,
        "Rank ICIR": 0.1598612677269071,
        "l2.train": 0.9946176302418914,
        "1day.excess_return_with_cost.information_ratio": 0.2763426565919577,
        "1day.excess_return_with_cost.mean": 7.394807889007978e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Institutional Absorption' framework has yielded a significant improvement in risk-adjusted returns. Specifically, the 'Linear_Drift_Absorption_Index' and its variants have increased the Information Ratio from 0.97 to 1.01 and the Annualized Return from 5.2% to 6.45%. Although the IC is slightly lower (0.0050 vs 0.0058) and the Max Drawdown has deepened, the substantial gain in excess return indicates that the combination of price linearity and volume-normalized volatility effectively captures alpha. The use of R-squared (via TS_CORR squared) to measure trend quality appears to be a robust signal when paired with liquidity-adjusted volatility measures.",
        "hypothesis_evaluation": "The results support the hypothesis that high-conviction accumulation can be identified by combining price-trend linearity with low volume-weighted variance. The 'Linear_Drift_Absorption_Index' implementation, which uses the standard deviation of the price range normalized by average volume, proved more effective than simple daily ratios. This suggests that 'efficiency' is better captured over a look-back window (10 days) rather than on a single-day basis, as it filters out idiosyncratic noise.",
        "decision": true,
        "reason": "While the current SOTA uses a 10-day window for both linearity and volatility, the interaction between volume and price range can be further refined. By incorporating the 'Efficiency Ratio' (the net change divided by the sum of absolute changes), we can better distinguish between a 'purposeful' institutional trend and a 'volatile' retail-driven trend. Additionally, the current symbol length is approaching complexity limits; simplifying the denominator by using a direct ratio of volatility to volume (rather than nested ranks) may improve generalization and reduce the risk of overfitting observed in the increased drawdown."
      }
    },
    "a280dc6aabfe6e69": {
      "factor_id": "a280dc6aabfe6e69",
      "factor_name": "Stealth_Accumulation_Efficiency_10D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) / (RANK(TS_MEAN(($high - $low) / ($close * $volume + 1e-8), 10)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) / (RANK(TS_MEAN(($high - $low) / ($close * $volume + 1e-8), 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Accumulation_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'quiet intraday drift' characteristic of institutional buying. It measures the ratio of trend strength (using R-squared) to the average relative price spread. A higher value indicates a stock that is trending linearly with minimal volatility per unit of volume, signaling non-disruptive accumulation.",
      "factor_formulation": "\\frac{\\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2)}{\\text{RANK}(\\text{TS\\_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{close} \\times (\\text{volume} + 1e-8)}, 10))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "73b597195b6e",
        "parent_trajectory_ids": [
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor identifies high-conviction accumulation by detecting assets with high price-trend linearity (RSQR10) coupled with low volume-weighted price variance (WVMA5), signaling efficient, non-disruptive buying regimes.\n                Concise Observation: The parent strategy focused on high-volume capitulation and overnight gaps for mean-reversion, whereas many high-performing assets exhibit 'quiet' intraday drift with low noise and steady price discovery during the continuous session.\n                Concise Justification: Institutional investors often use algorithms (like VWAP or TWAP) to absorb liquidity without moving the market significantly; this results in a high degree of trend linearity (high RSQR) and suppressed volatility relative to volume (low WVMA), preceding a breakout.\n                Concise Knowledge: If a stock exhibits high R-squared in its price trend while maintaining low volume-weighted volatility, it suggests institutional 'stealth' accumulation; when price climbs steadily without volume-induced spikes, it indicates a lack of selling pressure and high-quality trend persistence.\n                concise Specification: Define RSQR10 as the R-squared of $close against a time index over 10 days; define WVMA5 as the 5-day moving average of (High-Low)/Volume; the factor is the product of RANK(RSQR10) and RANK(-WVMA5) to capture the intersection of linearity and absorption.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T01:50:26.364243"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0904433804627169,
        "ICIR": 0.0362042504417642,
        "1day.excess_return_without_cost.std": 0.0041275073816727,
        "1day.excess_return_with_cost.annualized_return": 0.0175996427758389,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002710795218675,
        "1day.excess_return_without_cost.annualized_return": 0.0645169262044669,
        "1day.excess_return_with_cost.std": 0.004128263845032,
        "Rank IC": 0.0214120776352466,
        "IC": 0.0049821618834091,
        "1day.excess_return_without_cost.max_drawdown": -0.0831702281547032,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0132050152973342,
        "1day.pa": 0.0,
        "l2.valid": 0.9964855137421704,
        "Rank ICIR": 0.1598612677269071,
        "l2.train": 0.9946176302418914,
        "1day.excess_return_with_cost.information_ratio": 0.2763426565919577,
        "1day.excess_return_with_cost.mean": 7.394807889007978e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Institutional Absorption' framework has yielded a significant improvement in risk-adjusted returns. Specifically, the 'Linear_Drift_Absorption_Index' and its variants have increased the Information Ratio from 0.97 to 1.01 and the Annualized Return from 5.2% to 6.45%. Although the IC is slightly lower (0.0050 vs 0.0058) and the Max Drawdown has deepened, the substantial gain in excess return indicates that the combination of price linearity and volume-normalized volatility effectively captures alpha. The use of R-squared (via TS_CORR squared) to measure trend quality appears to be a robust signal when paired with liquidity-adjusted volatility measures.",
        "hypothesis_evaluation": "The results support the hypothesis that high-conviction accumulation can be identified by combining price-trend linearity with low volume-weighted variance. The 'Linear_Drift_Absorption_Index' implementation, which uses the standard deviation of the price range normalized by average volume, proved more effective than simple daily ratios. This suggests that 'efficiency' is better captured over a look-back window (10 days) rather than on a single-day basis, as it filters out idiosyncratic noise.",
        "decision": true,
        "reason": "While the current SOTA uses a 10-day window for both linearity and volatility, the interaction between volume and price range can be further refined. By incorporating the 'Efficiency Ratio' (the net change divided by the sum of absolute changes), we can better distinguish between a 'purposeful' institutional trend and a 'volatile' retail-driven trend. Additionally, the current symbol length is approaching complexity limits; simplifying the denominator by using a direct ratio of volatility to volume (rather than nested ranks) may improve generalization and reduce the risk of overfitting observed in the increased drawdown."
      }
    },
    "3e1d1911b077a39c": {
      "factor_id": "3e1d1911b077a39c",
      "factor_name": "Linear_Drift_Absorption_Index",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(INV(TS_STD($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(INV(TS_STD($high - $low, 10) / (TS_MEAN($volume, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Linear_Drift_Absorption_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Focuses on identifying assets where price discovery is steady and lacks noise. It combines the cross-sectional rank of price linearity (10-day R-squared) and the inverse rank of price volatility normalized by volume, highlighting stocks with high-quality trend persistence.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2) + \\text{RANK}(\\text{INV}(\\text{TS\\_STD}(\\text{high} - \\text{low}, 10) / (\\text{TS\\_MEAN}(\\text{volume}, 10) + 1e-8)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "73b597195b6e",
        "parent_trajectory_ids": [
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption' factor identifies high-conviction accumulation by detecting assets with high price-trend linearity (RSQR10) coupled with low volume-weighted price variance (WVMA5), signaling efficient, non-disruptive buying regimes.\n                Concise Observation: The parent strategy focused on high-volume capitulation and overnight gaps for mean-reversion, whereas many high-performing assets exhibit 'quiet' intraday drift with low noise and steady price discovery during the continuous session.\n                Concise Justification: Institutional investors often use algorithms (like VWAP or TWAP) to absorb liquidity without moving the market significantly; this results in a high degree of trend linearity (high RSQR) and suppressed volatility relative to volume (low WVMA), preceding a breakout.\n                Concise Knowledge: If a stock exhibits high R-squared in its price trend while maintaining low volume-weighted volatility, it suggests institutional 'stealth' accumulation; when price climbs steadily without volume-induced spikes, it indicates a lack of selling pressure and high-quality trend persistence.\n                concise Specification: Define RSQR10 as the R-squared of $close against a time index over 10 days; define WVMA5 as the 5-day moving average of (High-Low)/Volume; the factor is the product of RANK(RSQR10) and RANK(-WVMA5) to capture the intersection of linearity and absorption.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T01:50:26.364243"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0904433804627169,
        "ICIR": 0.0362042504417642,
        "1day.excess_return_without_cost.std": 0.0041275073816727,
        "1day.excess_return_with_cost.annualized_return": 0.0175996427758389,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002710795218675,
        "1day.excess_return_without_cost.annualized_return": 0.0645169262044669,
        "1day.excess_return_with_cost.std": 0.004128263845032,
        "Rank IC": 0.0214120776352466,
        "IC": 0.0049821618834091,
        "1day.excess_return_without_cost.max_drawdown": -0.0831702281547032,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0132050152973342,
        "1day.pa": 0.0,
        "l2.valid": 0.9964855137421704,
        "Rank ICIR": 0.1598612677269071,
        "l2.train": 0.9946176302418914,
        "1day.excess_return_with_cost.information_ratio": 0.2763426565919577,
        "1day.excess_return_with_cost.mean": 7.394807889007978e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Institutional Absorption' framework has yielded a significant improvement in risk-adjusted returns. Specifically, the 'Linear_Drift_Absorption_Index' and its variants have increased the Information Ratio from 0.97 to 1.01 and the Annualized Return from 5.2% to 6.45%. Although the IC is slightly lower (0.0050 vs 0.0058) and the Max Drawdown has deepened, the substantial gain in excess return indicates that the combination of price linearity and volume-normalized volatility effectively captures alpha. The use of R-squared (via TS_CORR squared) to measure trend quality appears to be a robust signal when paired with liquidity-adjusted volatility measures.",
        "hypothesis_evaluation": "The results support the hypothesis that high-conviction accumulation can be identified by combining price-trend linearity with low volume-weighted variance. The 'Linear_Drift_Absorption_Index' implementation, which uses the standard deviation of the price range normalized by average volume, proved more effective than simple daily ratios. This suggests that 'efficiency' is better captured over a look-back window (10 days) rather than on a single-day basis, as it filters out idiosyncratic noise.",
        "decision": true,
        "reason": "While the current SOTA uses a 10-day window for both linearity and volatility, the interaction between volume and price range can be further refined. By incorporating the 'Efficiency Ratio' (the net change divided by the sum of absolute changes), we can better distinguish between a 'purposeful' institutional trend and a 'volatile' retail-driven trend. Additionally, the current symbol length is approaching complexity limits; simplifying the denominator by using a direct ratio of volatility to volume (rather than nested ranks) may improve generalization and reduce the risk of overfitting observed in the increased drawdown."
      }
    },
    "354da4b56dedf80f": {
      "factor_id": "354da4b56dedf80f",
      "factor_name": "Intraday_Volume_Skew_Exhaustion_20D",
      "factor_expression": "(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $close) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Volume_Skew_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price exhaustion by measuring the proximity of the closing price to the daily high, scaled by the relative volume intensity. High values suggest aggressive buying near the high that may lead to mean reversion.",
      "factor_formulation": "IVSE_{20D} = \\frac{close - low}{high - low + 1e-8} \\times \\frac{volume}{TS\\_MEAN(volume, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "4ecac277217d",
        "parent_trajectory_ids": [
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Range-Volume Skew' factor, defined as the ratio of volume-weighted price distance from the low to the total daily range, negatively predicts returns as high volume concentration near the daily high indicates liquidity exhaustion and mean-reversion risk.\n                Concise Observation: The parent strategy successfully utilized lower shadows and gaps for momentum, but failed to capture reversals; stocks with high volume at price extremes often show price-volume divergence where the 'cost' of pushing price higher increases, leading to a late-session exhaustion.\n                Concise Justification: Aggressive execution at the end of the day creates temporary price dislocations; by measuring where volume sits relative to the $high and $low, we can identify whether the closing price is supported by broad value or driven by 'urgent' buy-side friction that will dissipate.\n                Concise Knowledge: If volume is heavily concentrated near the upper bound of the daily price range, it often signals aggressive liquidity demand that has exhausted immediate buying power; when this occurs without a supporting overnight gap, the price is likely to mean-revert due to market-maker rebalancing.\n                concise Specification: The factor is calculated as ($close - $low) / ($high - $low + 1e-8) multiplied by the ratio of current volume to its 20-day moving average to highlight liquidity-driven overextensions, specifically targeting a 1-day mean reversion effect.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T01:55:02.201694"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0872325695832066,
        "ICIR": 0.0434597601849905,
        "1day.excess_return_without_cost.std": 0.0041773969144495,
        "1day.excess_return_with_cost.annualized_return": 0.0263849411432272,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003088296466378,
        "1day.excess_return_without_cost.annualized_return": 0.0735014558997976,
        "1day.excess_return_with_cost.std": 0.0041784545874664,
        "Rank IC": 0.0212081709050934,
        "IC": 0.0057732838546922,
        "1day.excess_return_without_cost.max_drawdown": -0.0748106207391886,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.140516890697049,
        "1day.pa": 0.0,
        "l2.valid": 0.9963576978395672,
        "Rank ICIR": 0.1614348738617749,
        "l2.train": 0.9936411602423092,
        "1day.excess_return_with_cost.information_ratio": 0.4093096319880016,
        "1day.excess_return_with_cost.mean": 0.0001108610972404
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Intraday Range-Volume Skew' hypothesis by testing three variations: a simple volume-scaled range position (IVSE_20D), a cross-sectional rank-based divergence (RRVD_10D), and a volatility-normalized exhaustion signal (ERS_15D). The results show a significant improvement in the Information Ratio (1.14 vs 0.97) and Annualized Return (0.0735 vs 0.0520) compared to the SOTA, although the IC remained nearly identical and the Max Drawdown slightly increased.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that high volume concentration near the daily high (indicated by high values in the tested factors) serves as a signal for mean-reversion or exhaustion. The substantial increase in the Information Ratio suggests that incorporating volume intensity into the intraday price range provides a more stable risk-adjusted return than previous iterations. The ERS_15D factor, specifically, likely contributed to the stability by normalizing the range by historical volatility.",
        "decision": true,
        "reason": "While the current results are strong, the slight increase in Max Drawdown suggests that the signal might be noisy during certain market regimes. By incorporating a more robust 'Volume Surprise' metric (e.g., volume relative to a longer-term median to handle outliers) and ensuring the price range is significant relative to historical volatility, we can better isolate true 'exhaustion' from standard trend continuation. Simplifying the interaction between volume and price position will also ensure the factor remains robust."
      }
    },
    "9d189634247eeaa8": {
      "factor_id": "9d189634247eeaa8",
      "factor_name": "Ranked_Range_Volume_Divergence_10D",
      "factor_expression": "RANK(($close - $low) / ($high - $low + 1e-8)) * RANK(TS_ZSCORE($volume, 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $low) / ($high - $low + 1e-8)) * RANK(TS_ZSCORE($volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Range_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectional factor that captures overextended price action by ranking the intraday price position and multiplying it by the rank of volume surge. It targets stocks where late-session buying pressure is statistically extreme relative to the market.",
      "factor_formulation": "RRVD_{10D} = RANK(\\frac{close - low}{high - low + 1e-8}) \\times RANK(TS\\_ZSCORE(volume, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "4ecac277217d",
        "parent_trajectory_ids": [
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Range-Volume Skew' factor, defined as the ratio of volume-weighted price distance from the low to the total daily range, negatively predicts returns as high volume concentration near the daily high indicates liquidity exhaustion and mean-reversion risk.\n                Concise Observation: The parent strategy successfully utilized lower shadows and gaps for momentum, but failed to capture reversals; stocks with high volume at price extremes often show price-volume divergence where the 'cost' of pushing price higher increases, leading to a late-session exhaustion.\n                Concise Justification: Aggressive execution at the end of the day creates temporary price dislocations; by measuring where volume sits relative to the $high and $low, we can identify whether the closing price is supported by broad value or driven by 'urgent' buy-side friction that will dissipate.\n                Concise Knowledge: If volume is heavily concentrated near the upper bound of the daily price range, it often signals aggressive liquidity demand that has exhausted immediate buying power; when this occurs without a supporting overnight gap, the price is likely to mean-revert due to market-maker rebalancing.\n                concise Specification: The factor is calculated as ($close - $low) / ($high - $low + 1e-8) multiplied by the ratio of current volume to its 20-day moving average to highlight liquidity-driven overextensions, specifically targeting a 1-day mean reversion effect.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T01:55:02.201694"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0872325695832066,
        "ICIR": 0.0434597601849905,
        "1day.excess_return_without_cost.std": 0.0041773969144495,
        "1day.excess_return_with_cost.annualized_return": 0.0263849411432272,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003088296466378,
        "1day.excess_return_without_cost.annualized_return": 0.0735014558997976,
        "1day.excess_return_with_cost.std": 0.0041784545874664,
        "Rank IC": 0.0212081709050934,
        "IC": 0.0057732838546922,
        "1day.excess_return_without_cost.max_drawdown": -0.0748106207391886,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.140516890697049,
        "1day.pa": 0.0,
        "l2.valid": 0.9963576978395672,
        "Rank ICIR": 0.1614348738617749,
        "l2.train": 0.9936411602423092,
        "1day.excess_return_with_cost.information_ratio": 0.4093096319880016,
        "1day.excess_return_with_cost.mean": 0.0001108610972404
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Intraday Range-Volume Skew' hypothesis by testing three variations: a simple volume-scaled range position (IVSE_20D), a cross-sectional rank-based divergence (RRVD_10D), and a volatility-normalized exhaustion signal (ERS_15D). The results show a significant improvement in the Information Ratio (1.14 vs 0.97) and Annualized Return (0.0735 vs 0.0520) compared to the SOTA, although the IC remained nearly identical and the Max Drawdown slightly increased.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that high volume concentration near the daily high (indicated by high values in the tested factors) serves as a signal for mean-reversion or exhaustion. The substantial increase in the Information Ratio suggests that incorporating volume intensity into the intraday price range provides a more stable risk-adjusted return than previous iterations. The ERS_15D factor, specifically, likely contributed to the stability by normalizing the range by historical volatility.",
        "decision": true,
        "reason": "While the current results are strong, the slight increase in Max Drawdown suggests that the signal might be noisy during certain market regimes. By incorporating a more robust 'Volume Surprise' metric (e.g., volume relative to a longer-term median to handle outliers) and ensuring the price range is significant relative to historical volatility, we can better isolate true 'exhaustion' from standard trend continuation. Simplifying the interaction between volume and price position will also ensure the factor remains robust."
      }
    },
    "3bf1f91f72a2b763": {
      "factor_id": "3bf1f91f72a2b763",
      "factor_name": "Exhaustion_Reversal_Signal_15D",
      "factor_expression": "EMA((($close - $low) / (TS_STD($high - $low, 15) + 1e-8)) * ($volume / (TS_MEAN($volume, 15) + 1e-8)), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA((($close - $low) / (TS_STD($high - $low, 15) + 1e-8)) * ($volume / (TS_MEAN($volume, 15) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Signal_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the intensity of price movement toward the daily high relative to its 15-day average volatility, weighted by volume. It aims to detect 'urgent' buy-side friction likely to dissipate.",
      "factor_formulation": "ERS_{15D} = EMA(\\frac{close - low}{TS\\_STD(high - low, 15) + 1e-8} \\times \\frac{volume}{TS\\_MEAN(volume, 15)}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "4ecac277217d",
        "parent_trajectory_ids": [
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Range-Volume Skew' factor, defined as the ratio of volume-weighted price distance from the low to the total daily range, negatively predicts returns as high volume concentration near the daily high indicates liquidity exhaustion and mean-reversion risk.\n                Concise Observation: The parent strategy successfully utilized lower shadows and gaps for momentum, but failed to capture reversals; stocks with high volume at price extremes often show price-volume divergence where the 'cost' of pushing price higher increases, leading to a late-session exhaustion.\n                Concise Justification: Aggressive execution at the end of the day creates temporary price dislocations; by measuring where volume sits relative to the $high and $low, we can identify whether the closing price is supported by broad value or driven by 'urgent' buy-side friction that will dissipate.\n                Concise Knowledge: If volume is heavily concentrated near the upper bound of the daily price range, it often signals aggressive liquidity demand that has exhausted immediate buying power; when this occurs without a supporting overnight gap, the price is likely to mean-revert due to market-maker rebalancing.\n                concise Specification: The factor is calculated as ($close - $low) / ($high - $low + 1e-8) multiplied by the ratio of current volume to its 20-day moving average to highlight liquidity-driven overextensions, specifically targeting a 1-day mean reversion effect.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T01:55:02.201694"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0872325695832066,
        "ICIR": 0.0434597601849905,
        "1day.excess_return_without_cost.std": 0.0041773969144495,
        "1day.excess_return_with_cost.annualized_return": 0.0263849411432272,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003088296466378,
        "1day.excess_return_without_cost.annualized_return": 0.0735014558997976,
        "1day.excess_return_with_cost.std": 0.0041784545874664,
        "Rank IC": 0.0212081709050934,
        "IC": 0.0057732838546922,
        "1day.excess_return_without_cost.max_drawdown": -0.0748106207391886,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.140516890697049,
        "1day.pa": 0.0,
        "l2.valid": 0.9963576978395672,
        "Rank ICIR": 0.1614348738617749,
        "l2.train": 0.9936411602423092,
        "1day.excess_return_with_cost.information_ratio": 0.4093096319880016,
        "1day.excess_return_with_cost.mean": 0.0001108610972404
      },
      "feedback": {
        "observations": "The current iteration focused on refining the 'Intraday Range-Volume Skew' hypothesis by testing three variations: a simple volume-scaled range position (IVSE_20D), a cross-sectional rank-based divergence (RRVD_10D), and a volatility-normalized exhaustion signal (ERS_15D). The results show a significant improvement in the Information Ratio (1.14 vs 0.97) and Annualized Return (0.0735 vs 0.0520) compared to the SOTA, although the IC remained nearly identical and the Max Drawdown slightly increased.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that high volume concentration near the daily high (indicated by high values in the tested factors) serves as a signal for mean-reversion or exhaustion. The substantial increase in the Information Ratio suggests that incorporating volume intensity into the intraday price range provides a more stable risk-adjusted return than previous iterations. The ERS_15D factor, specifically, likely contributed to the stability by normalizing the range by historical volatility.",
        "decision": true,
        "reason": "While the current results are strong, the slight increase in Max Drawdown suggests that the signal might be noisy during certain market regimes. By incorporating a more robust 'Volume Surprise' metric (e.g., volume relative to a longer-term median to handle outliers) and ensuring the price range is significant relative to historical volatility, we can better isolate true 'exhaustion' from standard trend continuation. Simplifying the interaction between volume and price position will also ensure the factor remains robust."
      }
    },
    "00087213527f6415": {
      "factor_id": "00087213527f6415",
      "factor_name": "Price_Trend_Volume_Divergence_10_20",
      "factor_expression": "(POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8)) * (-1 * TS_CORR(DELTA($close, 1), DELTA($volume, 1), 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * (-1 * TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Price_Trend_Volume_Divergence_10_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies trend exhaustion by multiplying the 10-day R-squared of price trends (linear persistence) with the negative correlation between price changes and volume changes over 20 days. High values suggest a 'hollowing out' where price continues to move despite thinning volume synchronization, signaling a potential mean-reverting reversal.",
      "factor_formulation": "\\text{R2} = \\frac{\\text{REGBETA}(\\text{close}, \\text{SEQ}(10), 10)^2 \\times \\text{TS\\_VAR}(\\text{SEQ}(10), 10)}{\\text{TS\\_VAR}(\\text{close}, 10)}, \\text{Factor} = \\text{R2} \\times (-\\text{TS\\_CORR}(\\text{DELTA}(\\text{close}, 1), \\text{DELTA}(\\text{volume}, 1), 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "26decffb305f",
        "parent_trajectory_ids": [
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Convexity' factor, calculated as the interaction between the 10-day R-squared of price trends and the 20-day correlation between price and volume, identifies trend exhaustion where high price-trend persistence coupled with declining volume synchronization predicts a mean-reverting reversal.\n                Concise Observation: While overnight gaps and daily ranges capture sentiment persistence, they fail to identify the 'hollowing out' of a trend where price continues to move on thinning volume, a classic signal of intraday micro-structure fragility.\n                Concise Justification: High R-squared indicates a 'crowded' consensus trend, but if the correlation with volume drops, it suggests that aggressive market participants are no longer supporting the move, leading to a price-volume divergence that precedes a snapback.\n                Concise Knowledge: If a price trend maintains high linear persistence (R-squared) while its correlation with volume (CORR) diminishes, the trend is likely driven by liquidity exhaustion rather than fundamental conviction; When these two metrics diverge, a mean-reversion event is more probable than trend continuation.\n                concise Specification: The factor is defined as the product of the 10-day R-squared of daily close prices and the negative of the 20-day correlation between daily price changes and volume changes, targeting stocks in the tails of the distribution for reversal trading.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T02:10:37.186892"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0935860491614755,
        "ICIR": 0.0594403241815171,
        "1day.excess_return_without_cost.std": 0.004610138450364,
        "1day.excess_return_with_cost.annualized_return": 0.035880373183991,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003484822065891,
        "1day.excess_return_without_cost.annualized_return": 0.0829387651682274,
        "1day.excess_return_with_cost.std": 0.0046099594242177,
        "Rank IC": 0.0267266356796945,
        "IC": 0.0085134675652138,
        "1day.excess_return_without_cost.max_drawdown": -0.0823575250518681,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.166151884323961,
        "1day.pa": 0.0,
        "l2.valid": 0.9966177286820284,
        "Rank ICIR": 0.1902967834545223,
        "l2.train": 0.9935286608601288,
        "1day.excess_return_with_cost.information_ratio": 0.5045118483716564,
        "1day.excess_return_with_cost.mean": 0.0001507578705209
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Volume-Price Convexity' hypothesis by testing three variations of price-trend persistence and volume divergence. The results show a significant improvement over the previous SOTA, particularly in the Information Ratio (1.166 vs 0.973) and Annualized Return (0.0829 vs 0.0520). The IC also improved from 0.0058 to 0.0085. While the Max Drawdown slightly increased, the overall risk-adjusted performance (IR) is substantially higher, suggesting that capturing the 'hollowing out' of price trends with volume divergence is a robust alpha source.",
        "hypothesis_evaluation": "The hypothesis that high price-trend persistence coupled with declining volume synchronization predicts mean-reversion is strongly supported. The 'Trend_Persistence_Volume_Decay' and 'Price_Trend_Volume_Divergence_10_20' implementations effectively capture the exhaustion phase. Specifically, using R-squared or TS_RANK to define the 'strength' of the trend and multiplying it by a negative correlation with volume successfully identifies fragile price moves. The success of the simpler 'Trend_Persistence_Volume_Decay' suggests that rank-based persistence is more robust than raw regression-based R-squared.",
        "decision": true,
        "reason": "Current results show that volume divergence is key. However, price trends often end with a 'blow-off top' or 'panic bottom' characterized by increased volatility. By incorporating the ratio of Volatility to Volume Growth into the existing trend-persistence framework, we can better distinguish between a healthy consolidation and a true exhaustion. This follows the principle of maintaining low complexity (few base features) while refining the mathematical representation of 'fragility'."
      }
    },
    "4216ba35ab3fa4b2": {
      "factor_id": "4216ba35ab3fa4b2",
      "factor_name": "Volume_Exhaustion_Convexity_Z",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(-1 * TS_CORR(TS_STD($close, 5), TS_PCTCHANGE($volume, 1), 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(-1 * TS_CORR(TS_STD($close, 5), TS_PCTCHANGE($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Exhaustion_Convexity_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the price-volume convexity hypothesis. It measures the product of price trend strength (via 10-day price-time correlation) and the 20-day inverse relationship between price volatility and volume growth. It aims to capture micro-structure fragility when price volatility increases but volume support wanes.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQ}(10), 10)) \\times \\text{RANK}(-\\text{TS\\_CORR}(\\text{TS\\_STD}(\\text{close}, 5), \\text{TS\\_PCTCHANGE}(\\text{volume}, 1), 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "26decffb305f",
        "parent_trajectory_ids": [
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Convexity' factor, calculated as the interaction between the 10-day R-squared of price trends and the 20-day correlation between price and volume, identifies trend exhaustion where high price-trend persistence coupled with declining volume synchronization predicts a mean-reverting reversal.\n                Concise Observation: While overnight gaps and daily ranges capture sentiment persistence, they fail to identify the 'hollowing out' of a trend where price continues to move on thinning volume, a classic signal of intraday micro-structure fragility.\n                Concise Justification: High R-squared indicates a 'crowded' consensus trend, but if the correlation with volume drops, it suggests that aggressive market participants are no longer supporting the move, leading to a price-volume divergence that precedes a snapback.\n                Concise Knowledge: If a price trend maintains high linear persistence (R-squared) while its correlation with volume (CORR) diminishes, the trend is likely driven by liquidity exhaustion rather than fundamental conviction; When these two metrics diverge, a mean-reversion event is more probable than trend continuation.\n                concise Specification: The factor is defined as the product of the 10-day R-squared of daily close prices and the negative of the 20-day correlation between daily price changes and volume changes, targeting stocks in the tails of the distribution for reversal trading.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T02:10:37.186892"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0935860491614755,
        "ICIR": 0.0594403241815171,
        "1day.excess_return_without_cost.std": 0.004610138450364,
        "1day.excess_return_with_cost.annualized_return": 0.035880373183991,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003484822065891,
        "1day.excess_return_without_cost.annualized_return": 0.0829387651682274,
        "1day.excess_return_with_cost.std": 0.0046099594242177,
        "Rank IC": 0.0267266356796945,
        "IC": 0.0085134675652138,
        "1day.excess_return_without_cost.max_drawdown": -0.0823575250518681,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.166151884323961,
        "1day.pa": 0.0,
        "l2.valid": 0.9966177286820284,
        "Rank ICIR": 0.1902967834545223,
        "l2.train": 0.9935286608601288,
        "1day.excess_return_with_cost.information_ratio": 0.5045118483716564,
        "1day.excess_return_with_cost.mean": 0.0001507578705209
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Volume-Price Convexity' hypothesis by testing three variations of price-trend persistence and volume divergence. The results show a significant improvement over the previous SOTA, particularly in the Information Ratio (1.166 vs 0.973) and Annualized Return (0.0829 vs 0.0520). The IC also improved from 0.0058 to 0.0085. While the Max Drawdown slightly increased, the overall risk-adjusted performance (IR) is substantially higher, suggesting that capturing the 'hollowing out' of price trends with volume divergence is a robust alpha source.",
        "hypothesis_evaluation": "The hypothesis that high price-trend persistence coupled with declining volume synchronization predicts mean-reversion is strongly supported. The 'Trend_Persistence_Volume_Decay' and 'Price_Trend_Volume_Divergence_10_20' implementations effectively capture the exhaustion phase. Specifically, using R-squared or TS_RANK to define the 'strength' of the trend and multiplying it by a negative correlation with volume successfully identifies fragile price moves. The success of the simpler 'Trend_Persistence_Volume_Decay' suggests that rank-based persistence is more robust than raw regression-based R-squared.",
        "decision": true,
        "reason": "Current results show that volume divergence is key. However, price trends often end with a 'blow-off top' or 'panic bottom' characterized by increased volatility. By incorporating the ratio of Volatility to Volume Growth into the existing trend-persistence framework, we can better distinguish between a healthy consolidation and a true exhaustion. This follows the principle of maintaining low complexity (few base features) while refining the mathematical representation of 'fragility'."
      }
    },
    "c5c4e4a9eded132c": {
      "factor_id": "c5c4e4a9eded132c",
      "factor_name": "Trend_Persistence_Volume_Decay",
      "factor_expression": "TS_RANK($close, 10) * (-1 * TS_CORR($return, $volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK($close, 10) * (-1 * TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Trend_Persistence_Volume_Decay\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets stocks where price momentum is high but volume-weighted support is declining. It uses the 10-day time-series rank of price to define trend persistence and multiplies it by the negative 20-day correlation between price returns and volume to identify divergence.",
      "factor_formulation": "\\text{Factor} = \\text{TS\\_RANK}(\\text{close}, 10) \\times (-\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 3,
        "evolution_phase": "mutation",
        "trajectory_id": "26decffb305f",
        "parent_trajectory_ids": [
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Convexity' factor, calculated as the interaction between the 10-day R-squared of price trends and the 20-day correlation between price and volume, identifies trend exhaustion where high price-trend persistence coupled with declining volume synchronization predicts a mean-reverting reversal.\n                Concise Observation: While overnight gaps and daily ranges capture sentiment persistence, they fail to identify the 'hollowing out' of a trend where price continues to move on thinning volume, a classic signal of intraday micro-structure fragility.\n                Concise Justification: High R-squared indicates a 'crowded' consensus trend, but if the correlation with volume drops, it suggests that aggressive market participants are no longer supporting the move, leading to a price-volume divergence that precedes a snapback.\n                Concise Knowledge: If a price trend maintains high linear persistence (R-squared) while its correlation with volume (CORR) diminishes, the trend is likely driven by liquidity exhaustion rather than fundamental conviction; When these two metrics diverge, a mean-reversion event is more probable than trend continuation.\n                concise Specification: The factor is defined as the product of the 10-day R-squared of daily close prices and the negative of the 20-day correlation between daily price changes and volume changes, targeting stocks in the tails of the distribution for reversal trading.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T02:10:37.186892"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0935860491614755,
        "ICIR": 0.0594403241815171,
        "1day.excess_return_without_cost.std": 0.004610138450364,
        "1day.excess_return_with_cost.annualized_return": 0.035880373183991,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003484822065891,
        "1day.excess_return_without_cost.annualized_return": 0.0829387651682274,
        "1day.excess_return_with_cost.std": 0.0046099594242177,
        "Rank IC": 0.0267266356796945,
        "IC": 0.0085134675652138,
        "1day.excess_return_without_cost.max_drawdown": -0.0823575250518681,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.166151884323961,
        "1day.pa": 0.0,
        "l2.valid": 0.9966177286820284,
        "Rank ICIR": 0.1902967834545223,
        "l2.train": 0.9935286608601288,
        "1day.excess_return_with_cost.information_ratio": 0.5045118483716564,
        "1day.excess_return_with_cost.mean": 0.0001507578705209
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Volume-Price Convexity' hypothesis by testing three variations of price-trend persistence and volume divergence. The results show a significant improvement over the previous SOTA, particularly in the Information Ratio (1.166 vs 0.973) and Annualized Return (0.0829 vs 0.0520). The IC also improved from 0.0058 to 0.0085. While the Max Drawdown slightly increased, the overall risk-adjusted performance (IR) is substantially higher, suggesting that capturing the 'hollowing out' of price trends with volume divergence is a robust alpha source.",
        "hypothesis_evaluation": "The hypothesis that high price-trend persistence coupled with declining volume synchronization predicts mean-reversion is strongly supported. The 'Trend_Persistence_Volume_Decay' and 'Price_Trend_Volume_Divergence_10_20' implementations effectively capture the exhaustion phase. Specifically, using R-squared or TS_RANK to define the 'strength' of the trend and multiplying it by a negative correlation with volume successfully identifies fragile price moves. The success of the simpler 'Trend_Persistence_Volume_Decay' suggests that rank-based persistence is more robust than raw regression-based R-squared.",
        "decision": true,
        "reason": "Current results show that volume divergence is key. However, price trends often end with a 'blow-off top' or 'panic bottom' characterized by increased volatility. By incorporating the ratio of Volatility to Volume Growth into the existing trend-persistence framework, we can better distinguish between a healthy consolidation and a true exhaustion. This follows the principle of maintaining low complexity (few base features) while refining the mathematical representation of 'fragility'."
      }
    },
    "02201a85dc09f148": {
      "factor_id": "02201a85dc09f148",
      "factor_name": "Liquidity_Buffered_Gap_Reversal_V1",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * (($low - MIN($open, $close)) / ($close + 1e-8)) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (TS_STD($return, 3) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * (($low - MIN($open, $close)) / $close) / (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * TS_STD(TS_PCTCHANGE($close, 1), 3) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Buffered_Gap_Reversal_V1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies mean-reversion opportunities by combining the overnight gap ratio with intraday support (lower shadow) normalized by market illiquidity and return skewness. It targets scenarios where price gaps are met with physical support in low-liquidity environments.",
      "factor_formulation": "\\frac{(\\frac{Open - PrevClose}{PrevClose}) \\times (\\frac{Low - \\min(Open, Close)}{Close})}{\\text{TS_MEAN}(\\frac{|Return|}{Volume}, 5) \\times \\text{TS_STD}(Return, 3)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "074cc2e8b1ac",
        "parent_trajectory_ids": [
          "85552c59600c",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Buffered Gap Reversal' factor, defined as the product of the overnight gap ratio and the lower shadow length, divided by the product of the 5-day Amihud Illiquidity and the 3-day intraday price skewness, predicts positive returns by identifying price floors in illiquid mean-reversion scenarios.\n                Concise Observation: Parent 1 showed that illiquidity spikes and skewness predict reversals (RankIC 0.029), while Parent 2 showed that overnight gaps and shadow stability provide structural entry points (RankIC 0.024).\n                Concise Justification: Combining the 'trigger' (overnight gap) with 'structural support' (lower shadow) and 'liquidity context' (Amihud and Skewness) ensures that mean-reversion signals are only captured when price action suggests a physical limit to the liquidity-driven move has been reached.\n                Concise Knowledge: If an overnight gap occurs in a high-illiquidity environment and is met with intraday price support (lower shadows) and selling exhaustion (negative skewness), then the probability of a structural mean-reversion increase; when liquidity is scarce, small institutional imbalances create significant price dislocations that are easily reversed once a floor is established.\n                concise Specification: The factor is calculated as: ([(Open - Prev_Close) / Prev_Close] * [(Low - Min(Open, Close)) / Close]) / (SMA(Abs(Return)/Volume, 5) * Skew(Intraday_Move, 3)). High values indicate high-conviction reversal setups where gaps are supported by intraday floors despite low liquidity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T02:47:33.597339"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.219689227517084,
        "ICIR": 0.0158519928729444,
        "1day.excess_return_without_cost.std": 0.0046152889679496,
        "1day.excess_return_with_cost.annualized_return": -0.0412956026981716,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 2.542087247466616e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0060501676489705,
        "1day.excess_return_with_cost.std": 0.0046161686961693,
        "Rank IC": 0.0168385387637334,
        "IC": 0.0022383707339434,
        "1day.excess_return_without_cost.max_drawdown": -0.1121351027130839,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.0849728202375112,
        "1day.pa": 0.0,
        "l2.valid": 0.9966185173746108,
        "Rank ICIR": 0.1215113250042205,
        "l2.train": 0.9940040819231064,
        "1day.excess_return_with_cost.information_ratio": -0.5798740296796033,
        "1day.excess_return_with_cost.mean": -0.0001735109357066
      },
      "feedback": {
        "observations": "The current iteration of factors based on the 'Liquidity-Buffered Gap Reversal' hypothesis shows significantly weaker performance compared to the SOTA result. The best IC achieved in this run (0.0022) is less than half of the SOTA (0.0058), and the Information Ratio (0.085) is substantially lower than the SOTA (0.972). The 'Liquidity_Buffered_Gap_Reversal_V1' attempted to synthesize four distinct concepts (Gap, Shadow, Amihud Illiquidity, and Volatility), but the resulting signal appears diluted or noisy. The 'Illiquid_Shadow_Reversal_Rank' used a multiplicative rank approach which, while robust, may have lost the specific physical magnitude required to identify true 'liquidity buffers'. The complexity of the V1 factor is high, involving multiple raw features and rolling windows, which might be contributing to poor generalization.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with lower shadows in illiquid environments predicts returns is not strongly supported by the current implementations. While the theoretical link between physical support (shadows) and illiquidity is sound, the mathematical formulation in V1 (dividing by mean illiquidity and return volatility) might be creating extreme values or unstable denominators. The 'Skew_Adjusted_Gap_Support' performed poorly, suggesting that using standard deviation as a proxy for skewness/pressure in the denominator is insufficient. The interaction between gap and shadow needs a more focused representation rather than a multi-component product/ratio.",
        "decision": false,
        "reason": "The previous attempt failed by over-complicating the denominator with Amihud and Volatility. A more robust approach is to focus on the 'Relative Shadow' (shadow length relative to the daily range) and its interaction with 'Relative Volume'. By filtering for negative gaps (selling exhaustion) and high relative volume on the shadow, we isolate high-conviction 'floor' signals. Reducing the number of base features and using simple ratios instead of complex rolling statistics in the denominator should improve the Information Ratio and reduce overfitting risk."
      }
    },
    "02ba4bbf8c5f81cc": {
      "factor_id": "02ba4bbf8c5f81cc",
      "factor_name": "Illiquid_Shadow_Reversal_Rank",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(($low - MIN($open, $close)) / ($close + 1e-8)) * RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(($low - MIN($open, $close)) / $close) * RANK(TS_MEAN(ABS(($close - DELAY($close, 1)) / DELAY($close, 1)) / ($volume + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Illiquid_Shadow_Reversal_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the liquidity-buffered gap hypothesis focusing on the interaction between the overnight gap and the lower shadow, cross-sectionally ranked against the Amihud illiquidity measure to find high-conviction reversal floors.",
      "factor_formulation": "\\text{RANK}(\\frac{Open - DELAY(Close, 1)}{DELAY(Close, 1)}) \\times \\text{RANK}(\\frac{Low - \\min(Open, Close)}{Close}) \\times \\text{RANK}(\\text{TS_MEAN}(\\frac{|Return|}{Volume}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "074cc2e8b1ac",
        "parent_trajectory_ids": [
          "85552c59600c",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Buffered Gap Reversal' factor, defined as the product of the overnight gap ratio and the lower shadow length, divided by the product of the 5-day Amihud Illiquidity and the 3-day intraday price skewness, predicts positive returns by identifying price floors in illiquid mean-reversion scenarios.\n                Concise Observation: Parent 1 showed that illiquidity spikes and skewness predict reversals (RankIC 0.029), while Parent 2 showed that overnight gaps and shadow stability provide structural entry points (RankIC 0.024).\n                Concise Justification: Combining the 'trigger' (overnight gap) with 'structural support' (lower shadow) and 'liquidity context' (Amihud and Skewness) ensures that mean-reversion signals are only captured when price action suggests a physical limit to the liquidity-driven move has been reached.\n                Concise Knowledge: If an overnight gap occurs in a high-illiquidity environment and is met with intraday price support (lower shadows) and selling exhaustion (negative skewness), then the probability of a structural mean-reversion increase; when liquidity is scarce, small institutional imbalances create significant price dislocations that are easily reversed once a floor is established.\n                concise Specification: The factor is calculated as: ([(Open - Prev_Close) / Prev_Close] * [(Low - Min(Open, Close)) / Close]) / (SMA(Abs(Return)/Volume, 5) * Skew(Intraday_Move, 3)). High values indicate high-conviction reversal setups where gaps are supported by intraday floors despite low liquidity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T02:47:33.597339"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.219689227517084,
        "ICIR": 0.0158519928729444,
        "1day.excess_return_without_cost.std": 0.0046152889679496,
        "1day.excess_return_with_cost.annualized_return": -0.0412956026981716,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 2.542087247466616e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0060501676489705,
        "1day.excess_return_with_cost.std": 0.0046161686961693,
        "Rank IC": 0.0168385387637334,
        "IC": 0.0022383707339434,
        "1day.excess_return_without_cost.max_drawdown": -0.1121351027130839,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.0849728202375112,
        "1day.pa": 0.0,
        "l2.valid": 0.9966185173746108,
        "Rank ICIR": 0.1215113250042205,
        "l2.train": 0.9940040819231064,
        "1day.excess_return_with_cost.information_ratio": -0.5798740296796033,
        "1day.excess_return_with_cost.mean": -0.0001735109357066
      },
      "feedback": {
        "observations": "The current iteration of factors based on the 'Liquidity-Buffered Gap Reversal' hypothesis shows significantly weaker performance compared to the SOTA result. The best IC achieved in this run (0.0022) is less than half of the SOTA (0.0058), and the Information Ratio (0.085) is substantially lower than the SOTA (0.972). The 'Liquidity_Buffered_Gap_Reversal_V1' attempted to synthesize four distinct concepts (Gap, Shadow, Amihud Illiquidity, and Volatility), but the resulting signal appears diluted or noisy. The 'Illiquid_Shadow_Reversal_Rank' used a multiplicative rank approach which, while robust, may have lost the specific physical magnitude required to identify true 'liquidity buffers'. The complexity of the V1 factor is high, involving multiple raw features and rolling windows, which might be contributing to poor generalization.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with lower shadows in illiquid environments predicts returns is not strongly supported by the current implementations. While the theoretical link between physical support (shadows) and illiquidity is sound, the mathematical formulation in V1 (dividing by mean illiquidity and return volatility) might be creating extreme values or unstable denominators. The 'Skew_Adjusted_Gap_Support' performed poorly, suggesting that using standard deviation as a proxy for skewness/pressure in the denominator is insufficient. The interaction between gap and shadow needs a more focused representation rather than a multi-component product/ratio.",
        "decision": false,
        "reason": "The previous attempt failed by over-complicating the denominator with Amihud and Volatility. A more robust approach is to focus on the 'Relative Shadow' (shadow length relative to the daily range) and its interaction with 'Relative Volume'. By filtering for negative gaps (selling exhaustion) and high relative volume on the shadow, we isolate high-conviction 'floor' signals. Reducing the number of base features and using simple ratios instead of complex rolling statistics in the denominator should improve the Information Ratio and reduce overfitting risk."
      }
    },
    "3ad0d91518dcb4bf": {
      "factor_id": "3ad0d91518dcb4bf",
      "factor_name": "Skew_Adjusted_Gap_Support",
      "factor_expression": "(($open - DELAY($close, 1)) * ($low - MIN($open, $close))) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) * ($low - MIN($open, $close))) / (TS_SKEW(TS_PCTCHANGE($close, 1), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Skew_Adjusted_Gap_Support\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the structural support of a gap reversal by dividing the product of the gap and shadow length by the rolling 5-day return skewness, emphasizing reversals in stocks with asymmetric selling pressure.",
      "factor_formulation": "\\frac{(Open - DELAY(Close, 1)) \\times (Low - \\min(Open, Close))}{TS\\_STD(Return, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "074cc2e8b1ac",
        "parent_trajectory_ids": [
          "85552c59600c",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Buffered Gap Reversal' factor, defined as the product of the overnight gap ratio and the lower shadow length, divided by the product of the 5-day Amihud Illiquidity and the 3-day intraday price skewness, predicts positive returns by identifying price floors in illiquid mean-reversion scenarios.\n                Concise Observation: Parent 1 showed that illiquidity spikes and skewness predict reversals (RankIC 0.029), while Parent 2 showed that overnight gaps and shadow stability provide structural entry points (RankIC 0.024).\n                Concise Justification: Combining the 'trigger' (overnight gap) with 'structural support' (lower shadow) and 'liquidity context' (Amihud and Skewness) ensures that mean-reversion signals are only captured when price action suggests a physical limit to the liquidity-driven move has been reached.\n                Concise Knowledge: If an overnight gap occurs in a high-illiquidity environment and is met with intraday price support (lower shadows) and selling exhaustion (negative skewness), then the probability of a structural mean-reversion increase; when liquidity is scarce, small institutional imbalances create significant price dislocations that are easily reversed once a floor is established.\n                concise Specification: The factor is calculated as: ([(Open - Prev_Close) / Prev_Close] * [(Low - Min(Open, Close)) / Close]) / (SMA(Abs(Return)/Volume, 5) * Skew(Intraday_Move, 3)). High values indicate high-conviction reversal setups where gaps are supported by intraday floors despite low liquidity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T02:47:33.597339"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.219689227517084,
        "ICIR": 0.0158519928729444,
        "1day.excess_return_without_cost.std": 0.0046152889679496,
        "1day.excess_return_with_cost.annualized_return": -0.0412956026981716,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 2.542087247466616e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0060501676489705,
        "1day.excess_return_with_cost.std": 0.0046161686961693,
        "Rank IC": 0.0168385387637334,
        "IC": 0.0022383707339434,
        "1day.excess_return_without_cost.max_drawdown": -0.1121351027130839,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.0849728202375112,
        "1day.pa": 0.0,
        "l2.valid": 0.9966185173746108,
        "Rank ICIR": 0.1215113250042205,
        "l2.train": 0.9940040819231064,
        "1day.excess_return_with_cost.information_ratio": -0.5798740296796033,
        "1day.excess_return_with_cost.mean": -0.0001735109357066
      },
      "feedback": {
        "observations": "The current iteration of factors based on the 'Liquidity-Buffered Gap Reversal' hypothesis shows significantly weaker performance compared to the SOTA result. The best IC achieved in this run (0.0022) is less than half of the SOTA (0.0058), and the Information Ratio (0.085) is substantially lower than the SOTA (0.972). The 'Liquidity_Buffered_Gap_Reversal_V1' attempted to synthesize four distinct concepts (Gap, Shadow, Amihud Illiquidity, and Volatility), but the resulting signal appears diluted or noisy. The 'Illiquid_Shadow_Reversal_Rank' used a multiplicative rank approach which, while robust, may have lost the specific physical magnitude required to identify true 'liquidity buffers'. The complexity of the V1 factor is high, involving multiple raw features and rolling windows, which might be contributing to poor generalization.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with lower shadows in illiquid environments predicts returns is not strongly supported by the current implementations. While the theoretical link between physical support (shadows) and illiquidity is sound, the mathematical formulation in V1 (dividing by mean illiquidity and return volatility) might be creating extreme values or unstable denominators. The 'Skew_Adjusted_Gap_Support' performed poorly, suggesting that using standard deviation as a proxy for skewness/pressure in the denominator is insufficient. The interaction between gap and shadow needs a more focused representation rather than a multi-component product/ratio.",
        "decision": false,
        "reason": "The previous attempt failed by over-complicating the denominator with Amihud and Volatility. A more robust approach is to focus on the 'Relative Shadow' (shadow length relative to the daily range) and its interaction with 'Relative Volume'. By filtering for negative gaps (selling exhaustion) and high relative volume on the shadow, we isolate high-conviction 'floor' signals. Reducing the number of base features and using simple ratios instead of complex rolling statistics in the denominator should improve the Information Ratio and reduce overfitting risk."
      }
    },
    "a2c4443bcdec7bf9": {
      "factor_id": "a2c4443bcdec7bf9",
      "factor_name": "Institutional_Liquidity_Capture_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / $volume, 5) / TS_STD(TS_PCTCHANGE($close, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Liquidity_Capture_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures assets with high-conviction structural trends experiencing tactical liquidity exhaustion. It combines price trend linearity (R-squared of close prices) with a volatility-normalized Amihud illiquidity spike. High values suggest a 'liquidity hole' in a strong trend, likely leading to price acceleration.",
      "factor_formulation": "\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\frac{\\text{TS_MEAN}(\\text{ABS}(\\text{return})/\\text{volume}, 5)}{\\text{TS_STD}(\\text{return}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "dcdcc359a6bb",
        "parent_trajectory_ids": [
          "85552c59600c",
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Capture' factor, defined as the product of a 10-day price trend linearity (R-squared) and a 5-day Amihud Illiquidity spike normalized by 20-day volatility, predicts that assets with high-conviction structural trends experiencing tactical liquidity exhaustion will see accelerated price continuation.\n                Concise Observation: Parent strategies show that while liquidity exhaustion (RankIC 0.029) and trend linearity (RankIC 0.022) are individually predictive, they often suffer from noise in low-conviction regimes or slow decay in crowded trends.\n                Concise Justification: By multiplying trend linearity with a volatility-adjusted illiquidity measure, we filter for 'efficient' trends where short-term supply-demand imbalances (illiquidity) act as a catalyst for price acceleration rather than a signal of trend breakdown.\n                Concise Knowledge: If a security exhibits high price linearity (R-squared), it indicates institutional conviction; when this is coupled with a sudden spike in the Amihud illiquidity ratio relative to historical volatility, it signifies a 'liquidity hole' that typically precedes a sharp price move in the direction of the primary trend.\n                concise Specification: The factor is calculated by: (1) 10-day R-squared of daily close prices, (2) 5-day mean of (abs(return)/volume), (3) 20-day standard deviation of returns; the final factor is (R-squared * (5-day Amihud / 20-day Volatility)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:01:49.119462"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1522132503455085,
        "ICIR": 0.0254470187340497,
        "1day.excess_return_without_cost.std": 0.0044300411925664,
        "1day.excess_return_with_cost.annualized_return": -0.0184839603015498,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001213081186613,
        "1day.excess_return_without_cost.annualized_return": 0.028871332241391,
        "1day.excess_return_with_cost.std": 0.004430647796471,
        "Rank IC": 0.0198139579591233,
        "IC": 0.0035623699914569,
        "1day.excess_return_without_cost.max_drawdown": -0.1180955543408255,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4224453960876057,
        "1day.pa": 0.0,
        "l2.valid": 0.99669178441375,
        "Rank ICIR": 0.1464530182675244,
        "l2.train": 0.9942024648162732,
        "1day.excess_return_with_cost.information_ratio": -0.2704203187398051,
        "1day.excess_return_with_cost.mean": -7.766369874600797e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Institutional Liquidity-Capture' hypothesis: a direct non-linear implementation, an EMA-based momentum stability version, and a cross-sectional ranking approach. Despite the theoretical soundness of combining trend linearity with liquidity exhaustion, the current results (IC: 0.0035, IR: 0.422) significantly underperform the SOTA (IC: 0.0058, IR: 0.972). The maximum drawdown is also notably higher (-0.118 vs -0.072), suggesting that the current formulation of 'liquidity spikes' might be introducing excessive noise or capturing late-stage reversals rather than trend accelerations.",
        "hypothesis_evaluation": "The hypothesis that liquidity exhaustion (Amihud spikes) during linear trends predicts acceleration is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'exhaustion' signal is too volatile. The use of absolute returns in the Amihud numerator might be conflating bullish and bearish liquidity gaps. Furthermore, the 10-day R-squared and 5-day Amihud window might be catching short-term mean reversion rather than institutional 'capture'.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors use multiple raw features ($close, $volume, $return) and complex nested functions (TS_CORR, POW, TS_MEAN, TS_STD). Simplifying the trend component to a sign-based consistency metric reduces sensitivity to outliers. 2. Normalization: Normalizing Amihud illiquidity by its own 20-day range (TS_MIN/MAX) rather than return volatility better isolates 'unusual' liquidity events. 3. Directionality: Using raw returns instead of absolute returns in the illiquidity measure ensures the factor distinguishes between liquidity-driven rallies and liquidity-driven crashes."
      }
    },
    "cffea32959feefa7": {
      "factor_id": "cffea32959feefa7",
      "factor_name": "Trend_Efficiency_Illiquidity_Factor",
      "factor_expression": "TS_RANK(EMA($return, 10), 20) * (EMA(ABS($return) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(EMA(TS_PCTCHANGE($close, 1), 10), 20) * (EMA(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Efficiency_Illiquidity_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the liquidity capture hypothesis focusing on the interaction between price momentum stability and relative illiquidity. It uses the time-series rank of return consistency multiplied by the ratio of short-term illiquidity to medium-term volatility to identify high-conviction institutional entries.",
      "factor_formulation": "\\text{TS_RANK}(\\text{EMA}(\\text{return}, 10), 20) \\times \\frac{\\text{EMA}(\\text{ABS}(\\text{return})/\\text{volume}, 5)}{\\text{TS_STD}(\\text{return}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "dcdcc359a6bb",
        "parent_trajectory_ids": [
          "85552c59600c",
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Capture' factor, defined as the product of a 10-day price trend linearity (R-squared) and a 5-day Amihud Illiquidity spike normalized by 20-day volatility, predicts that assets with high-conviction structural trends experiencing tactical liquidity exhaustion will see accelerated price continuation.\n                Concise Observation: Parent strategies show that while liquidity exhaustion (RankIC 0.029) and trend linearity (RankIC 0.022) are individually predictive, they often suffer from noise in low-conviction regimes or slow decay in crowded trends.\n                Concise Justification: By multiplying trend linearity with a volatility-adjusted illiquidity measure, we filter for 'efficient' trends where short-term supply-demand imbalances (illiquidity) act as a catalyst for price acceleration rather than a signal of trend breakdown.\n                Concise Knowledge: If a security exhibits high price linearity (R-squared), it indicates institutional conviction; when this is coupled with a sudden spike in the Amihud illiquidity ratio relative to historical volatility, it signifies a 'liquidity hole' that typically precedes a sharp price move in the direction of the primary trend.\n                concise Specification: The factor is calculated by: (1) 10-day R-squared of daily close prices, (2) 5-day mean of (abs(return)/volume), (3) 20-day standard deviation of returns; the final factor is (R-squared * (5-day Amihud / 20-day Volatility)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:01:49.119462"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1522132503455085,
        "ICIR": 0.0254470187340497,
        "1day.excess_return_without_cost.std": 0.0044300411925664,
        "1day.excess_return_with_cost.annualized_return": -0.0184839603015498,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001213081186613,
        "1day.excess_return_without_cost.annualized_return": 0.028871332241391,
        "1day.excess_return_with_cost.std": 0.004430647796471,
        "Rank IC": 0.0198139579591233,
        "IC": 0.0035623699914569,
        "1day.excess_return_without_cost.max_drawdown": -0.1180955543408255,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4224453960876057,
        "1day.pa": 0.0,
        "l2.valid": 0.99669178441375,
        "Rank ICIR": 0.1464530182675244,
        "l2.train": 0.9942024648162732,
        "1day.excess_return_with_cost.information_ratio": -0.2704203187398051,
        "1day.excess_return_with_cost.mean": -7.766369874600797e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Institutional Liquidity-Capture' hypothesis: a direct non-linear implementation, an EMA-based momentum stability version, and a cross-sectional ranking approach. Despite the theoretical soundness of combining trend linearity with liquidity exhaustion, the current results (IC: 0.0035, IR: 0.422) significantly underperform the SOTA (IC: 0.0058, IR: 0.972). The maximum drawdown is also notably higher (-0.118 vs -0.072), suggesting that the current formulation of 'liquidity spikes' might be introducing excessive noise or capturing late-stage reversals rather than trend accelerations.",
        "hypothesis_evaluation": "The hypothesis that liquidity exhaustion (Amihud spikes) during linear trends predicts acceleration is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'exhaustion' signal is too volatile. The use of absolute returns in the Amihud numerator might be conflating bullish and bearish liquidity gaps. Furthermore, the 10-day R-squared and 5-day Amihud window might be catching short-term mean reversion rather than institutional 'capture'.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors use multiple raw features ($close, $volume, $return) and complex nested functions (TS_CORR, POW, TS_MEAN, TS_STD). Simplifying the trend component to a sign-based consistency metric reduces sensitivity to outliers. 2. Normalization: Normalizing Amihud illiquidity by its own 20-day range (TS_MIN/MAX) rather than return volatility better isolates 'unusual' liquidity events. 3. Directionality: Using raw returns instead of absolute returns in the illiquidity measure ensures the factor distinguishes between liquidity-driven rallies and liquidity-driven crashes."
      }
    },
    "46905493dbd1bde5": {
      "factor_id": "46905493dbd1bde5",
      "factor_name": "Cross_Sectional_Liquidity_Trend_Alpha",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS($return) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Trend_Alpha\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor ranks stocks based on their trend linearity and then scales that rank by the cross-sectional Z-score of their volatility-adjusted illiquidity. This isolates stocks that are outliers in terms of liquidity exhaustion relative to the market while maintaining a linear price path.",
      "factor_formulation": "\\text{RANK}(\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)) \\times \\text{ZSCORE}(\\text{TS_MEAN}(\\text{ABS}(\\text{return})/\\text{volume}, 5) / \\text{TS_STD}(\\text{return}, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "dcdcc359a6bb",
        "parent_trajectory_ids": [
          "85552c59600c",
          "817d00660033"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Capture' factor, defined as the product of a 10-day price trend linearity (R-squared) and a 5-day Amihud Illiquidity spike normalized by 20-day volatility, predicts that assets with high-conviction structural trends experiencing tactical liquidity exhaustion will see accelerated price continuation.\n                Concise Observation: Parent strategies show that while liquidity exhaustion (RankIC 0.029) and trend linearity (RankIC 0.022) are individually predictive, they often suffer from noise in low-conviction regimes or slow decay in crowded trends.\n                Concise Justification: By multiplying trend linearity with a volatility-adjusted illiquidity measure, we filter for 'efficient' trends where short-term supply-demand imbalances (illiquidity) act as a catalyst for price acceleration rather than a signal of trend breakdown.\n                Concise Knowledge: If a security exhibits high price linearity (R-squared), it indicates institutional conviction; when this is coupled with a sudden spike in the Amihud illiquidity ratio relative to historical volatility, it signifies a 'liquidity hole' that typically precedes a sharp price move in the direction of the primary trend.\n                concise Specification: The factor is calculated by: (1) 10-day R-squared of daily close prices, (2) 5-day mean of (abs(return)/volume), (3) 20-day standard deviation of returns; the final factor is (R-squared * (5-day Amihud / 20-day Volatility)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:01:49.119462"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1522132503455085,
        "ICIR": 0.0254470187340497,
        "1day.excess_return_without_cost.std": 0.0044300411925664,
        "1day.excess_return_with_cost.annualized_return": -0.0184839603015498,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001213081186613,
        "1day.excess_return_without_cost.annualized_return": 0.028871332241391,
        "1day.excess_return_with_cost.std": 0.004430647796471,
        "Rank IC": 0.0198139579591233,
        "IC": 0.0035623699914569,
        "1day.excess_return_without_cost.max_drawdown": -0.1180955543408255,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4224453960876057,
        "1day.pa": 0.0,
        "l2.valid": 0.99669178441375,
        "Rank ICIR": 0.1464530182675244,
        "l2.train": 0.9942024648162732,
        "1day.excess_return_with_cost.information_ratio": -0.2704203187398051,
        "1day.excess_return_with_cost.mean": -7.766369874600797e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Institutional Liquidity-Capture' hypothesis: a direct non-linear implementation, an EMA-based momentum stability version, and a cross-sectional ranking approach. Despite the theoretical soundness of combining trend linearity with liquidity exhaustion, the current results (IC: 0.0035, IR: 0.422) significantly underperform the SOTA (IC: 0.0058, IR: 0.972). The maximum drawdown is also notably higher (-0.118 vs -0.072), suggesting that the current formulation of 'liquidity spikes' might be introducing excessive noise or capturing late-stage reversals rather than trend accelerations.",
        "hypothesis_evaluation": "The hypothesis that liquidity exhaustion (Amihud spikes) during linear trends predicts acceleration is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'exhaustion' signal is too volatile. The use of absolute returns in the Amihud numerator might be conflating bullish and bearish liquidity gaps. Furthermore, the 10-day R-squared and 5-day Amihud window might be catching short-term mean reversion rather than institutional 'capture'.",
        "decision": false,
        "reason": "1. Complexity Control: The current factors use multiple raw features ($close, $volume, $return) and complex nested functions (TS_CORR, POW, TS_MEAN, TS_STD). Simplifying the trend component to a sign-based consistency metric reduces sensitivity to outliers. 2. Normalization: Normalizing Amihud illiquidity by its own 20-day range (TS_MIN/MAX) rather than return volatility better isolates 'unusual' liquidity events. 3. Directionality: Using raw returns instead of absolute returns in the illiquidity measure ensures the factor distinguishes between liquidity-driven rallies and liquidity-driven crashes."
      }
    },
    "2fc81b01d52f626a": {
      "factor_id": "2fc81b01d52f626a",
      "factor_name": "Dual_Horizon_Liquidity_Exhaustion",
      "factor_expression": "TS_PCTCHANGE($close, 60) * TS_CORR($close, $volume, 60) * (ABS($return) / (TS_MEAN($volume, 5) + 1e-8)) * TS_ZSCORE(REGRESI($return, SEQUENCE(3), 3), 20)",
      "factor_implementation_code": "",
      "factor_description": "This factor identifies mean-reversion opportunities by combining a 60-day structural capitulation signal (price-volume decoupling during a downtrend) with a 5-day tactical liquidity exhaustion signal (high illiquidity and negative return skewness). It captures the 'liquidity vacuum' effect where selling pressure is exhausted in a thin order book.",
      "factor_formulation": "\\text{TS\\_PCTCHANGE}(\\text{close}, 60) \\times \\text{TS\\_CORR}(\\text{close}, \\text{volume}, 60) \\times \\frac{\\text{ABS}(\\text{return})}{\\text{TS\\_MEAN}(\\text{volume}, 5) + 1e-8} \\times \\text{TS\\_ZSCORE}(\\text{TS\\_SKEW}(\\text{return}, 3), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "6d3fb71f1729",
        "parent_trajectory_ids": [
          "85552c59600c",
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Dual-Horizon Liquidity Vacuum' factor, calculated as the product of a 60-day structural capitulation signal (ROC60 * Correlation(Price, Volume, 60)) and a 5-day tactical liquidity exhaustion signal (Amihud Illiquidity * 3-day Price Skewness), identifies high-conviction mean-reversion opportunities.\n                Concise Observation: Parent strategies show that while 60-day macro trends identify oversold regimes (RankIC 0.022) and 5-day liquidity spikes identify micro-reversals (RankIC 0.029), neither captures the full 'liquidity vacuum' effect where structural distress meets immediate execution friction.\n                Concise Justification: Combining macro-capitulation with micro-liquidity spikes ensures that mean-reversion signals are only generated when both the trend is exhausted and the market's ability to absorb further selling is depleted, minimizing 'falling knife' risks.\n                Concise Knowledge: If long-term price-volume decoupling (structural capitulation) coincides with short-term surges in illiquidity and negative returns skewness (tactical exhaustion), then the probability of a sharp price reversal increases due to the exhaustion of selling pressure in a thin order book.\n                concise Specification: The factor is defined as (Close/Close[60]-1) * Correlation(Close, Volume, 60) * (Abs(Return)/Volume_Mean5) * Skew(Return, 3). It expects a positive relationship with future returns when the combined metric reaches extreme negative values (indicating synchronized exhaustion).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:40:38.859346"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2519851770587492,
        "ICIR": 0.0146578009969735,
        "1day.excess_return_without_cost.std": 0.0049223544410473,
        "1day.excess_return_with_cost.annualized_return": -0.0207331404120095,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001121223981439,
        "1day.excess_return_without_cost.annualized_return": 0.0266851307582553,
        "1day.excess_return_with_cost.std": 0.0049234541779028,
        "Rank IC": 0.0182401281383075,
        "IC": 0.0023483241518226,
        "1day.excess_return_without_cost.max_drawdown": -0.1747620535791422,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3514050304207115,
        "1day.pa": 0.0,
        "l2.valid": 0.9968710826959228,
        "Rank ICIR": 0.1173352629461957,
        "l2.train": 0.994833649183081,
        "1day.excess_return_with_cost.information_ratio": -0.2729648399351794,
        "1day.excess_return_with_cost.mean": -8.71140353445781e-05
      },
      "feedback": {
        "observations": "The experiment focused on testing the 'Structural Capitulation Index', a component of the 'Dual-Horizon Liquidity Vacuum' hypothesis. The implemented factor utilized a 60-day price percentage change and a 60-day price-volume correlation, both cross-sectionally ranked. The results show that while the factor is positive, it significantly underperforms the current SOTA across all metrics, including IC (0.0023 vs 0.0058) and Information Ratio (0.351 vs 0.973). The high Max Drawdown (-0.174) suggests that the structural component alone lacks sufficient timing precision or risk control.",
        "hypothesis_evaluation": "The current results partially support the 'structural' part of the hypothesis (positive IC and returns), but the significant gap between this simplified version and the SOTA suggests that the 'structural capitulation' signal requires the 'tactical exhaustion' overlay to be effective. The interaction between long-term distress and short-term liquidity gaps is likely necessary to filter out 'falling knives' that continue to trend downward without immediate reversal potential.",
        "decision": false,
        "reason": "The 'Structural_Capitulation_Index' failed to reach SOTA likely because cross-sectional RANK does not capture the intensity of the capitulation for an individual asset relative to its own history. By using TS_ZSCORE on the product of ROC and Correlation, we identify extreme local deviations. Adding a volatility-adjusted volume component (Amihud-like) will help distinguish between a slow drift and a true liquidity vacuum event, which is the core of the target hypothesis."
      }
    },
    "43d03444581e7943": {
      "factor_id": "43d03444581e7943",
      "factor_name": "Structural_Capitulation_Index",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 60))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 60)) * RANK(TS_CORR($close, $volume, 60))\" # Your output factor expression will be filled in here\n    name = \"Structural_Capitulation_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the structural capitulation hypothesis, focusing on the interaction between long-term price decline and the breakdown of price-volume correlation, normalized cross-sectionally to identify the most distressed assets.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_PCTCHANGE}(\\text{close}, 60)) \\times \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{volume}, 60))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "6d3fb71f1729",
        "parent_trajectory_ids": [
          "85552c59600c",
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Dual-Horizon Liquidity Vacuum' factor, calculated as the product of a 60-day structural capitulation signal (ROC60 * Correlation(Price, Volume, 60)) and a 5-day tactical liquidity exhaustion signal (Amihud Illiquidity * 3-day Price Skewness), identifies high-conviction mean-reversion opportunities.\n                Concise Observation: Parent strategies show that while 60-day macro trends identify oversold regimes (RankIC 0.022) and 5-day liquidity spikes identify micro-reversals (RankIC 0.029), neither captures the full 'liquidity vacuum' effect where structural distress meets immediate execution friction.\n                Concise Justification: Combining macro-capitulation with micro-liquidity spikes ensures that mean-reversion signals are only generated when both the trend is exhausted and the market's ability to absorb further selling is depleted, minimizing 'falling knife' risks.\n                Concise Knowledge: If long-term price-volume decoupling (structural capitulation) coincides with short-term surges in illiquidity and negative returns skewness (tactical exhaustion), then the probability of a sharp price reversal increases due to the exhaustion of selling pressure in a thin order book.\n                concise Specification: The factor is defined as (Close/Close[60]-1) * Correlation(Close, Volume, 60) * (Abs(Return)/Volume_Mean5) * Skew(Return, 3). It expects a positive relationship with future returns when the combined metric reaches extreme negative values (indicating synchronized exhaustion).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:40:38.859346"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2519851770587492,
        "ICIR": 0.0146578009969735,
        "1day.excess_return_without_cost.std": 0.0049223544410473,
        "1day.excess_return_with_cost.annualized_return": -0.0207331404120095,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001121223981439,
        "1day.excess_return_without_cost.annualized_return": 0.0266851307582553,
        "1day.excess_return_with_cost.std": 0.0049234541779028,
        "Rank IC": 0.0182401281383075,
        "IC": 0.0023483241518226,
        "1day.excess_return_without_cost.max_drawdown": -0.1747620535791422,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3514050304207115,
        "1day.pa": 0.0,
        "l2.valid": 0.9968710826959228,
        "Rank ICIR": 0.1173352629461957,
        "l2.train": 0.994833649183081,
        "1day.excess_return_with_cost.information_ratio": -0.2729648399351794,
        "1day.excess_return_with_cost.mean": -8.71140353445781e-05
      },
      "feedback": {
        "observations": "The experiment focused on testing the 'Structural Capitulation Index', a component of the 'Dual-Horizon Liquidity Vacuum' hypothesis. The implemented factor utilized a 60-day price percentage change and a 60-day price-volume correlation, both cross-sectionally ranked. The results show that while the factor is positive, it significantly underperforms the current SOTA across all metrics, including IC (0.0023 vs 0.0058) and Information Ratio (0.351 vs 0.973). The high Max Drawdown (-0.174) suggests that the structural component alone lacks sufficient timing precision or risk control.",
        "hypothesis_evaluation": "The current results partially support the 'structural' part of the hypothesis (positive IC and returns), but the significant gap between this simplified version and the SOTA suggests that the 'structural capitulation' signal requires the 'tactical exhaustion' overlay to be effective. The interaction between long-term distress and short-term liquidity gaps is likely necessary to filter out 'falling knives' that continue to trend downward without immediate reversal potential.",
        "decision": false,
        "reason": "The 'Structural_Capitulation_Index' failed to reach SOTA likely because cross-sectional RANK does not capture the intensity of the capitulation for an individual asset relative to its own history. By using TS_ZSCORE on the product of ROC and Correlation, we identify extreme local deviations. Adding a volatility-adjusted volume component (Amihud-like) will help distinguish between a slow drift and a true liquidity vacuum event, which is the core of the target hypothesis."
      }
    },
    "43e3aa1e187fa79c": {
      "factor_id": "43e3aa1e187fa79c",
      "factor_name": "Tactical_Illiquidity_Skew",
      "factor_expression": "(ABS($return) / (TS_MEAN($volume, 5) + 1e-8)) * TS_RANK(REGRESI($return, SEQUENCE(5), 5), 10)",
      "factor_implementation_code": "",
      "factor_description": "Captures the tactical exhaustion component of the hypothesis by multiplying the Amihud-style illiquidity measure with the short-term return skewness. High values indicate price moves happening on low relative volume with asymmetric risk, often preceding a reversal.",
      "factor_formulation": "\\frac{\\text{ABS}(\\text{return})}{\\text{TS\\_MEAN}(\\text{volume}, 5) + 1e-8} \\times \\text{TS\\_RANK}(\\text{REGRESI}(\\text{return}, \\text{SEQUENCE}(5), 5), 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "6d3fb71f1729",
        "parent_trajectory_ids": [
          "85552c59600c",
          "f2896b260d5a"
        ],
        "hypothesis": "Hypothesis: The 'Dual-Horizon Liquidity Vacuum' factor, calculated as the product of a 60-day structural capitulation signal (ROC60 * Correlation(Price, Volume, 60)) and a 5-day tactical liquidity exhaustion signal (Amihud Illiquidity * 3-day Price Skewness), identifies high-conviction mean-reversion opportunities.\n                Concise Observation: Parent strategies show that while 60-day macro trends identify oversold regimes (RankIC 0.022) and 5-day liquidity spikes identify micro-reversals (RankIC 0.029), neither captures the full 'liquidity vacuum' effect where structural distress meets immediate execution friction.\n                Concise Justification: Combining macro-capitulation with micro-liquidity spikes ensures that mean-reversion signals are only generated when both the trend is exhausted and the market's ability to absorb further selling is depleted, minimizing 'falling knife' risks.\n                Concise Knowledge: If long-term price-volume decoupling (structural capitulation) coincides with short-term surges in illiquidity and negative returns skewness (tactical exhaustion), then the probability of a sharp price reversal increases due to the exhaustion of selling pressure in a thin order book.\n                concise Specification: The factor is defined as (Close/Close[60]-1) * Correlation(Close, Volume, 60) * (Abs(Return)/Volume_Mean5) * Skew(Return, 3). It expects a positive relationship with future returns when the combined metric reaches extreme negative values (indicating synchronized exhaustion).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:40:38.859346"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2519851770587492,
        "ICIR": 0.0146578009969735,
        "1day.excess_return_without_cost.std": 0.0049223544410473,
        "1day.excess_return_with_cost.annualized_return": -0.0207331404120095,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001121223981439,
        "1day.excess_return_without_cost.annualized_return": 0.0266851307582553,
        "1day.excess_return_with_cost.std": 0.0049234541779028,
        "Rank IC": 0.0182401281383075,
        "IC": 0.0023483241518226,
        "1day.excess_return_without_cost.max_drawdown": -0.1747620535791422,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3514050304207115,
        "1day.pa": 0.0,
        "l2.valid": 0.9968710826959228,
        "Rank ICIR": 0.1173352629461957,
        "l2.train": 0.994833649183081,
        "1day.excess_return_with_cost.information_ratio": -0.2729648399351794,
        "1day.excess_return_with_cost.mean": -8.71140353445781e-05
      },
      "feedback": {
        "observations": "The experiment focused on testing the 'Structural Capitulation Index', a component of the 'Dual-Horizon Liquidity Vacuum' hypothesis. The implemented factor utilized a 60-day price percentage change and a 60-day price-volume correlation, both cross-sectionally ranked. The results show that while the factor is positive, it significantly underperforms the current SOTA across all metrics, including IC (0.0023 vs 0.0058) and Information Ratio (0.351 vs 0.973). The high Max Drawdown (-0.174) suggests that the structural component alone lacks sufficient timing precision or risk control.",
        "hypothesis_evaluation": "The current results partially support the 'structural' part of the hypothesis (positive IC and returns), but the significant gap between this simplified version and the SOTA suggests that the 'structural capitulation' signal requires the 'tactical exhaustion' overlay to be effective. The interaction between long-term distress and short-term liquidity gaps is likely necessary to filter out 'falling knives' that continue to trend downward without immediate reversal potential.",
        "decision": false,
        "reason": "The 'Structural_Capitulation_Index' failed to reach SOTA likely because cross-sectional RANK does not capture the intensity of the capitulation for an individual asset relative to its own history. By using TS_ZSCORE on the product of ROC and Correlation, we identify extreme local deviations. Adding a volatility-adjusted volume component (Amihud-like) will help distinguish between a slow drift and a true liquidity vacuum event, which is the core of the target hypothesis."
      }
    },
    "7a7ccb4c7eef2df2": {
      "factor_id": "7a7ccb4c7eef2df2",
      "factor_name": "Amihud_Resonance_Divergence_5D",
      "factor_expression": "TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (TS_MEAN($high - $low, 5) / (TS_MEAN(ABS($open - DELAY($close, 1)), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (TS_MEAN($high - $low, 5) / (TS_MEAN(ABS($open - DELAY($close, 1)), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Resonance_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the divergence between price impact (Amihud Illiquidity) and overnight sentiment conviction. It identifies mean-reversion opportunities where high intraday volatility (high-low) is not supported by overnight price gaps, suggesting liquidity-driven exhaustion rather than fundamental trends.",
      "factor_formulation": "\\text{TS_MEAN}(\\frac{|\\text{return}|}{\\text{volume}}, 5) \\times \\frac{\\text{TS_MEAN}(\\text{high} - \\text{low}, 5)}{\\text{TS_MEAN}(|\\text{open} - \\text{DELAY}(\\text{close}, 1)|, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "4dce22ce14d7",
        "parent_trajectory_ids": [
          "85552c59600c",
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Gap Divergence' factor, defined as the product of the 5-day Amihud Illiquidity measure and the ratio of the 5-day Intraday Range to the absolute 5-day Overnight Gap, positively predicts mean-reversion returns by identifying price moves driven by liquidity exhaustion rather than fundamental conviction.\n                Concise Observation: Parent 1 identifies mean reversion via illiquidity spikes, while Parent 2 identifies conviction via range-to-gap ratios; combining them reveals that high-impact intraday moves lacking overnight validation are prone to immediate reversal.\n                Concise Justification: Institutional repositioning often creates temporary price distortions (Amihud spikes) that are not supported by the broader market's overnight consensus, leading to a decoupling that signals an overextended price state ready for correction.\n                Concise Knowledge: If a high intraday price range is accompanied by low overnight sentiment (small gaps) and high price impact (Amihud spike), then the price move is likely a liquidity-driven exhaustion event rather than a sustainable trend.\n                concise Specification: Calculate Amihud Illiquidity (mean of |return|/volume over 5 days) multiplied by the 'Resonance Ratio' (5-day average of (high-low) divided by the 5-day average of |close_t-1 - open_t| + epsilon) to capture the divergence between liquidity cost and sentiment conviction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:48:35.502076"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1894730008726187,
        "ICIR": 0.017305671889405,
        "1day.excess_return_without_cost.std": 0.0045241161223448,
        "1day.excess_return_with_cost.annualized_return": -0.0253295039907774,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.277718526407505e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0220809700928498,
        "1day.excess_return_with_cost.std": 0.004524775581032,
        "Rank IC": 0.0178614159744648,
        "IC": 0.002410938318167,
        "1day.excess_return_without_cost.max_drawdown": -0.1318519292003346,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3163704610307561,
        "1day.pa": 0.0,
        "l2.valid": 0.9966456875621796,
        "Rank ICIR": 0.1319782047800634,
        "l2.train": 0.9944103638841386,
        "1day.excess_return_with_cost.information_ratio": -0.3628617266981943,
        "1day.excess_return_with_cost.mean": -0.0001064264873562
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the 'Institutional Liquidity-Gap Divergence' hypothesis: a 5-day version (Amihud_Resonance_Divergence_5D) and a 20-day smoothed version (Smoothed_Amihud_Gap_Divergence_20D). The results show that while the factors possess positive IC (0.0024) and positive annualized returns (2.2%), they significantly underperform the current SOTA across all metrics. Specifically, the Information Ratio (0.316) is substantially lower than the SOTA (0.972), and the Max Drawdown (-0.131) is nearly double that of the SOTA (-0.072).",
        "hypothesis_evaluation": "The hypothesis that the product of Amihud illiquidity and the range-to-gap ratio predicts returns is supported in direction (positive IC and returns), but the current mathematical formulation lacks sufficient predictive power to surpass existing benchmarks. The 5-day window might be too noisy, and the inclusion of the absolute return in the numerator of the Amihud component alongside the intraday range in the second component may be creating redundant volatility signaling rather than isolating 'exhaustion'.",
        "decision": false,
        "reason": "The current results suggest that the raw product of these measures is too volatile. Moving to a relative framework (Z-scores) helps normalize the 'exhaustion' signal across different market regimes and instruments. Furthermore, the 10-day window provides a middle ground between the noisy 5-day and the potentially lagging 20-day EMA versions. Using Volume directly in the denominator of the range (Price Impact per unit of volume) instead of the standard Amihud formulation may more cleanly capture the liquidity-gap divergence."
      }
    },
    "9300bf51cc554e0d": {
      "factor_id": "9300bf51cc554e0d",
      "factor_name": "Zscore_Liquidity_Gap_Ratio_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8), 10) * RANK(ABS($return) / ($volume + 1e-8))",
      "factor_implementation_code": "",
      "factor_description": "A standardized version of the Institutional Liquidity-Gap Divergence, using a 10-day window and Z-score normalization. It highlights extreme cases where the ratio of intraday range to overnight gap significantly exceeds its recent history, indicating potential price exhaustion.",
      "factor_formulation": "\\text{TS_ZSCORE}(\\frac{\\text{high} - \\text{low}}{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) + 1e-8}, 10) \\times \\text{RANK}(\\frac{\\text{ABS}(\\text{return})}{\\text{volume} + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "4dce22ce14d7",
        "parent_trajectory_ids": [
          "85552c59600c",
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Gap Divergence' factor, defined as the product of the 5-day Amihud Illiquidity measure and the ratio of the 5-day Intraday Range to the absolute 5-day Overnight Gap, positively predicts mean-reversion returns by identifying price moves driven by liquidity exhaustion rather than fundamental conviction.\n                Concise Observation: Parent 1 identifies mean reversion via illiquidity spikes, while Parent 2 identifies conviction via range-to-gap ratios; combining them reveals that high-impact intraday moves lacking overnight validation are prone to immediate reversal.\n                Concise Justification: Institutional repositioning often creates temporary price distortions (Amihud spikes) that are not supported by the broader market's overnight consensus, leading to a decoupling that signals an overextended price state ready for correction.\n                Concise Knowledge: If a high intraday price range is accompanied by low overnight sentiment (small gaps) and high price impact (Amihud spike), then the price move is likely a liquidity-driven exhaustion event rather than a sustainable trend.\n                concise Specification: Calculate Amihud Illiquidity (mean of |return|/volume over 5 days) multiplied by the 'Resonance Ratio' (5-day average of (high-low) divided by the 5-day average of |close_t-1 - open_t| + epsilon) to capture the divergence between liquidity cost and sentiment conviction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:48:35.502076"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1894730008726187,
        "ICIR": 0.017305671889405,
        "1day.excess_return_without_cost.std": 0.0045241161223448,
        "1day.excess_return_with_cost.annualized_return": -0.0253295039907774,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.277718526407505e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0220809700928498,
        "1day.excess_return_with_cost.std": 0.004524775581032,
        "Rank IC": 0.0178614159744648,
        "IC": 0.002410938318167,
        "1day.excess_return_without_cost.max_drawdown": -0.1318519292003346,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3163704610307561,
        "1day.pa": 0.0,
        "l2.valid": 0.9966456875621796,
        "Rank ICIR": 0.1319782047800634,
        "l2.train": 0.9944103638841386,
        "1day.excess_return_with_cost.information_ratio": -0.3628617266981943,
        "1day.excess_return_with_cost.mean": -0.0001064264873562
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the 'Institutional Liquidity-Gap Divergence' hypothesis: a 5-day version (Amihud_Resonance_Divergence_5D) and a 20-day smoothed version (Smoothed_Amihud_Gap_Divergence_20D). The results show that while the factors possess positive IC (0.0024) and positive annualized returns (2.2%), they significantly underperform the current SOTA across all metrics. Specifically, the Information Ratio (0.316) is substantially lower than the SOTA (0.972), and the Max Drawdown (-0.131) is nearly double that of the SOTA (-0.072).",
        "hypothesis_evaluation": "The hypothesis that the product of Amihud illiquidity and the range-to-gap ratio predicts returns is supported in direction (positive IC and returns), but the current mathematical formulation lacks sufficient predictive power to surpass existing benchmarks. The 5-day window might be too noisy, and the inclusion of the absolute return in the numerator of the Amihud component alongside the intraday range in the second component may be creating redundant volatility signaling rather than isolating 'exhaustion'.",
        "decision": false,
        "reason": "The current results suggest that the raw product of these measures is too volatile. Moving to a relative framework (Z-scores) helps normalize the 'exhaustion' signal across different market regimes and instruments. Furthermore, the 10-day window provides a middle ground between the noisy 5-day and the potentially lagging 20-day EMA versions. Using Volume directly in the denominator of the range (Price Impact per unit of volume) instead of the standard Amihud formulation may more cleanly capture the liquidity-gap divergence."
      }
    },
    "adbb13da2f59cdec": {
      "factor_id": "adbb13da2f59cdec",
      "factor_name": "Smoothed_Amihud_Gap_Divergence_20D",
      "factor_expression": "EMA(ABS($return) / ($volume + 1e-8), 20) * EMA(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"EMA(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 20) * EMA(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Amihud_Gap_Divergence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor uses exponential moving averages to smooth the Amihud illiquidity and the range-to-gap ratio over a 20-day period. It seeks to identify persistent structural liquidity issues where intraday price action consistently decouples from overnight consensus.",
      "factor_formulation": "\\text{EMA}(\\frac{|\\text{return}|}{\\text{volume}}, 20) \\times \\text{EMA}(\\frac{\\text{high} - \\text{low}}{|\\text{open} - \\text{DELAY}(\\text{close}, 1)| + 1e-8}, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "4dce22ce14d7",
        "parent_trajectory_ids": [
          "85552c59600c",
          "ce9e8ca5b04c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Gap Divergence' factor, defined as the product of the 5-day Amihud Illiquidity measure and the ratio of the 5-day Intraday Range to the absolute 5-day Overnight Gap, positively predicts mean-reversion returns by identifying price moves driven by liquidity exhaustion rather than fundamental conviction.\n                Concise Observation: Parent 1 identifies mean reversion via illiquidity spikes, while Parent 2 identifies conviction via range-to-gap ratios; combining them reveals that high-impact intraday moves lacking overnight validation are prone to immediate reversal.\n                Concise Justification: Institutional repositioning often creates temporary price distortions (Amihud spikes) that are not supported by the broader market's overnight consensus, leading to a decoupling that signals an overextended price state ready for correction.\n                Concise Knowledge: If a high intraday price range is accompanied by low overnight sentiment (small gaps) and high price impact (Amihud spike), then the price move is likely a liquidity-driven exhaustion event rather than a sustainable trend.\n                concise Specification: Calculate Amihud Illiquidity (mean of |return|/volume over 5 days) multiplied by the 'Resonance Ratio' (5-day average of (high-low) divided by the 5-day average of |close_t-1 - open_t| + epsilon) to capture the divergence between liquidity cost and sentiment conviction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T03:48:35.502076"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1894730008726187,
        "ICIR": 0.017305671889405,
        "1day.excess_return_without_cost.std": 0.0045241161223448,
        "1day.excess_return_with_cost.annualized_return": -0.0253295039907774,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.277718526407505e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0220809700928498,
        "1day.excess_return_with_cost.std": 0.004524775581032,
        "Rank IC": 0.0178614159744648,
        "IC": 0.002410938318167,
        "1day.excess_return_without_cost.max_drawdown": -0.1318519292003346,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3163704610307561,
        "1day.pa": 0.0,
        "l2.valid": 0.9966456875621796,
        "Rank ICIR": 0.1319782047800634,
        "l2.train": 0.9944103638841386,
        "1day.excess_return_with_cost.information_ratio": -0.3628617266981943,
        "1day.excess_return_with_cost.mean": -0.0001064264873562
      },
      "feedback": {
        "observations": "The experiment tested two implementations of the 'Institutional Liquidity-Gap Divergence' hypothesis: a 5-day version (Amihud_Resonance_Divergence_5D) and a 20-day smoothed version (Smoothed_Amihud_Gap_Divergence_20D). The results show that while the factors possess positive IC (0.0024) and positive annualized returns (2.2%), they significantly underperform the current SOTA across all metrics. Specifically, the Information Ratio (0.316) is substantially lower than the SOTA (0.972), and the Max Drawdown (-0.131) is nearly double that of the SOTA (-0.072).",
        "hypothesis_evaluation": "The hypothesis that the product of Amihud illiquidity and the range-to-gap ratio predicts returns is supported in direction (positive IC and returns), but the current mathematical formulation lacks sufficient predictive power to surpass existing benchmarks. The 5-day window might be too noisy, and the inclusion of the absolute return in the numerator of the Amihud component alongside the intraday range in the second component may be creating redundant volatility signaling rather than isolating 'exhaustion'.",
        "decision": false,
        "reason": "The current results suggest that the raw product of these measures is too volatile. Moving to a relative framework (Z-scores) helps normalize the 'exhaustion' signal across different market regimes and instruments. Furthermore, the 10-day window provides a middle ground between the noisy 5-day and the potentially lagging 20-day EMA versions. Using Volume directly in the denominator of the range (Price Impact per unit of volume) instead of the standard Amihud formulation may more cleanly capture the liquidity-gap divergence."
      }
    },
    "0f6de17606ad3381": {
      "factor_id": "0f6de17606ad3381",
      "factor_name": "Structural_Exhaustion_Gap_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (1 - TS_CORR($close, $volume, 20))) * RANK((($open / (DELAY($close, 1) + 1e-8)) - 1) * ((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (1 - TS_CORR($close, $volume, 20))) * RANK((($open / (DELAY($close, 1) + 1e-8)) - 1) * ((MIN($open, $close) - $low) / (TS_STD($volume, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-probability reversals by combining a 10-day price-trend maturity measure (based on regression R-squared) with a 5-day volatility-adjusted gap-support ratio. It seeks to capture assets where a maturing trend meets institutional price-floor validation through lower shadows and overnight gaps.",
      "factor_formulation": "\\text{RANK}(\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) * (1 - \\text{TS_CORR}(\\text{close}, \\text{volume}, 20))) * \\text{RANK}((\\text{open} / \\text{DELAY}(\\text{close}, 1) - 1) * ((\\text{MIN}(\\text{open}, \\text{close}) - \\text{low}) / (\\text{TS_STD}(\\text{volume}, 5) + 1e-8)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "7737944c2bde",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion Gap Support' factor, defined as the product of a 10-day price-volume convexity measure and a 5-day volatility-adjusted gap-shadow ratio, identifies high-probability reversals or continuations by filtering intraday trend exhaustion through institutional price-floor validation.\n                Concise Observation: Parent 1 (RankIC 0.0267) identifies trend maturity via convexity, while Parent 2 (RankIC 0.0243) identifies institutional gaps; combining them addresses the weakness of gaps occurring in overextended trends without structural support.\n                Concise Justification: Fusing medium-term trend convexity with short-term gap integrity creates a multi-horizon signal that distinguishes between retail-driven noise and institutional positioning, ensuring that 'exhaustion' signals are only traded when 'support' is verified.\n                Concise Knowledge: If a stock displays high price-trend persistence (R-squared) alongside low price-volume correlation, it indicates trend exhaustion; when this coincides with an overnight gap supported by significant lower shadows relative to volume volatility, it confirms institutional support for a new price floor.\n                concise Specification: The factor is the product of (10-day price R-squared * (1 - 20-day price-volume correlation)) and (overnight gap ratio * (lower shadow / 5-day volume standard deviation)), targeting assets where structural trend maturity meets high-integrity price floors.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:03:55.795554"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current iteration attempted to implement the 'Structural Exhaustion Gap Support' hypothesis through three distinct factor formulations: a complex rank-product version, a simplified floor validation version, and a convexity-rank version. However, the 'Current Result' column shows 'NaN' across all key performance metrics (IC, Annualized Return, IR, and Max Drawdown). This indicates that while the factors were successfully implemented in Python, they failed to generate valid predictive signals or the model training phase encountered issues, possibly due to the mathematical complexity or data sparsity (e.g., division by zero in the volatility-adjusted components).",
        "hypothesis_evaluation": "The hypothesis remains unverified as the current implementations did not yield measurable performance metrics. The 'Structural_Exhaustion_Gap_Factor' is particularly complex (Symbol Length is likely high), combining trend maturity, price-volume decoupling, and gap-shadow ratios. The 'NaN' results suggest that the interaction between these components might be too restrictive or numerically unstable (e.g., the use of TS_STD(volume) in the denominator without robust scaling).",
        "decision": false,
        "reason": "The previous complex formulations likely suffered from 'over-engineering' and numerical instability. By focusing on a simpler 'Exhaustion + Support' logic—specifically looking for price-volume divergence (low correlation) combined with a strong lower shadow after a gap—we reduce the symbol length and the number of base features. Replacing complex RANK(POW(TS_CORR...)) with a more direct measure of price-volume decoupling and using a standard denominator (like $close instead of volume volatility) should improve signal robustness and eliminate the 'NaN' issues."
      }
    },
    "e36a7feea3538368": {
      "factor_id": "e36a7feea3538368",
      "factor_name": "Institutional_Floor_Validation_Factor",
      "factor_expression": "((1 - TS_CORR($close, $volume, 10)) / (TS_STD($return, 10) + 1e-8)) * (($close - $low) / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((1 - TS_CORR($close, $volume, 10)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)) * (($close - $low) / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Floor_Validation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the structural exhaustion hypothesis focusing on the interaction between price-volume decoupling (exhaustion) and the strength of the lower shadow relative to recent volume volatility (support).",
      "factor_formulation": "\\frac{1 - \\text{TS_CORR}(\\text{close}, \\text{volume}, 10)}{\\text{TS_STD}(\\text{return}, 10) + 1e-8} * \\frac{\\text{close} - \\text{low}}{\\text{TS_STD}(\\text{volume}, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "7737944c2bde",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion Gap Support' factor, defined as the product of a 10-day price-volume convexity measure and a 5-day volatility-adjusted gap-shadow ratio, identifies high-probability reversals or continuations by filtering intraday trend exhaustion through institutional price-floor validation.\n                Concise Observation: Parent 1 (RankIC 0.0267) identifies trend maturity via convexity, while Parent 2 (RankIC 0.0243) identifies institutional gaps; combining them addresses the weakness of gaps occurring in overextended trends without structural support.\n                Concise Justification: Fusing medium-term trend convexity with short-term gap integrity creates a multi-horizon signal that distinguishes between retail-driven noise and institutional positioning, ensuring that 'exhaustion' signals are only traded when 'support' is verified.\n                Concise Knowledge: If a stock displays high price-trend persistence (R-squared) alongside low price-volume correlation, it indicates trend exhaustion; when this coincides with an overnight gap supported by significant lower shadows relative to volume volatility, it confirms institutional support for a new price floor.\n                concise Specification: The factor is the product of (10-day price R-squared * (1 - 20-day price-volume correlation)) and (overnight gap ratio * (lower shadow / 5-day volume standard deviation)), targeting assets where structural trend maturity meets high-integrity price floors.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:03:55.795554"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current iteration attempted to implement the 'Structural Exhaustion Gap Support' hypothesis through three distinct factor formulations: a complex rank-product version, a simplified floor validation version, and a convexity-rank version. However, the 'Current Result' column shows 'NaN' across all key performance metrics (IC, Annualized Return, IR, and Max Drawdown). This indicates that while the factors were successfully implemented in Python, they failed to generate valid predictive signals or the model training phase encountered issues, possibly due to the mathematical complexity or data sparsity (e.g., division by zero in the volatility-adjusted components).",
        "hypothesis_evaluation": "The hypothesis remains unverified as the current implementations did not yield measurable performance metrics. The 'Structural_Exhaustion_Gap_Factor' is particularly complex (Symbol Length is likely high), combining trend maturity, price-volume decoupling, and gap-shadow ratios. The 'NaN' results suggest that the interaction between these components might be too restrictive or numerically unstable (e.g., the use of TS_STD(volume) in the denominator without robust scaling).",
        "decision": false,
        "reason": "The previous complex formulations likely suffered from 'over-engineering' and numerical instability. By focusing on a simpler 'Exhaustion + Support' logic—specifically looking for price-volume divergence (low correlation) combined with a strong lower shadow after a gap—we reduce the symbol length and the number of base features. Replacing complex RANK(POW(TS_CORR...)) with a more direct measure of price-volume decoupling and using a standard denominator (like $close instead of volume volatility) should improve signal robustness and eliminate the 'NaN' issues."
      }
    },
    "35fc93dac23d689d": {
      "factor_id": "35fc93dac23d689d",
      "factor_name": "Convexity_Gap_Support_Rank",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK((($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK((($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * ((MIN($open, $close) - $low) / ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Convexity_Gap_Support_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets assets where the trend shows high persistence (R-squared) but is met with an overnight gap and price-floor support. It uses the ratio of the lower shadow to the daily range to identify institutional buying pressure at the gap level.",
      "factor_formulation": "\\text{RANK}(\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)) * \\text{RANK}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{DELAY}(\\text{close}, 1) + 1e-8} * \\frac{\\text{MIN}(\\text{open}, \\text{close}) - \\text{low}}{\\text{high} - \\text{low} + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "7737944c2bde",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion Gap Support' factor, defined as the product of a 10-day price-volume convexity measure and a 5-day volatility-adjusted gap-shadow ratio, identifies high-probability reversals or continuations by filtering intraday trend exhaustion through institutional price-floor validation.\n                Concise Observation: Parent 1 (RankIC 0.0267) identifies trend maturity via convexity, while Parent 2 (RankIC 0.0243) identifies institutional gaps; combining them addresses the weakness of gaps occurring in overextended trends without structural support.\n                Concise Justification: Fusing medium-term trend convexity with short-term gap integrity creates a multi-horizon signal that distinguishes between retail-driven noise and institutional positioning, ensuring that 'exhaustion' signals are only traded when 'support' is verified.\n                Concise Knowledge: If a stock displays high price-trend persistence (R-squared) alongside low price-volume correlation, it indicates trend exhaustion; when this coincides with an overnight gap supported by significant lower shadows relative to volume volatility, it confirms institutional support for a new price floor.\n                concise Specification: The factor is the product of (10-day price R-squared * (1 - 20-day price-volume correlation)) and (overnight gap ratio * (lower shadow / 5-day volume standard deviation)), targeting assets where structural trend maturity meets high-integrity price floors.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:03:55.795554"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current iteration attempted to implement the 'Structural Exhaustion Gap Support' hypothesis through three distinct factor formulations: a complex rank-product version, a simplified floor validation version, and a convexity-rank version. However, the 'Current Result' column shows 'NaN' across all key performance metrics (IC, Annualized Return, IR, and Max Drawdown). This indicates that while the factors were successfully implemented in Python, they failed to generate valid predictive signals or the model training phase encountered issues, possibly due to the mathematical complexity or data sparsity (e.g., division by zero in the volatility-adjusted components).",
        "hypothesis_evaluation": "The hypothesis remains unverified as the current implementations did not yield measurable performance metrics. The 'Structural_Exhaustion_Gap_Factor' is particularly complex (Symbol Length is likely high), combining trend maturity, price-volume decoupling, and gap-shadow ratios. The 'NaN' results suggest that the interaction between these components might be too restrictive or numerically unstable (e.g., the use of TS_STD(volume) in the denominator without robust scaling).",
        "decision": false,
        "reason": "The previous complex formulations likely suffered from 'over-engineering' and numerical instability. By focusing on a simpler 'Exhaustion + Support' logic—specifically looking for price-volume divergence (low correlation) combined with a strong lower shadow after a gap—we reduce the symbol length and the number of base features. Replacing complex RANK(POW(TS_CORR...)) with a more direct measure of price-volume decoupling and using a standard denominator (like $close instead of volume volatility) should improve signal robustness and eliminate the 'NaN' issues."
      }
    },
    "9bcd52351ccee47e": {
      "factor_id": "9bcd52351ccee47e",
      "factor_name": "Liquidity_Validated_Gap_5D",
      "factor_expression": "ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE((MIN($open, $close) - $low) / (($high - $low) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE($open / DELAY($close, 1) - 1) * ZSCORE((MIN($open, $close) - $low) / (($high - $low) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Gap_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-quality overnight gaps by scaling the gap magnitude by the ratio of lower shadow support to intraday range-per-unit-volume. It prioritizes gaps where price discovery is supported by institutional absorption (lower shadow) rather than liquidity vacuums (high range-to-volume).",
      "factor_formulation": "LVG_{5D} = ZSCORE(\\frac{open}{DELAY(close, 1)} - 1) \\times ZSCORE(\\frac{MIN(open, close) - low}{(high - low) / (TS\\_MEAN(volume, 5) + 1e-8) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "08c954752077",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Gap' factor, defined as the product of the overnight gap and the ratio of the lower shadow length to the intraday range-to-volume ratio, positively predicts returns by identifying price jumps supported by institutional absorption rather than hollow liquidity vacuums.\n                Concise Observation: Parent 1 showed that high range-to-volume ratios (liquidity vacuums) lead to mean reversion (RankIC=0.0267), while Parent 2 showed that overnight gaps with shadow support predict continuation (RankIC=0.0243).\n                Concise Justification: By scaling the overnight gap by the ratio of the lower shadow (support) to the range-per-unit-volume (vacuum intensity), we filter out 'fake-out' gaps caused by thin order books and prioritize those where buyers actively defended price levels during high-volume interaction.\n                Concise Knowledge: If an overnight price gap is accompanied by a significant lower shadow relative to the intraday range-to-volume ratio, it indicates institutional support; conversely, gaps with high range-to-volume ratios without shadow support suggest fragile liquidity prone to mean reversion.\n                concise Specification: The factor is calculated as (Open/Close[t-1] - 1) * (Low_Shadow / ((High - Low) / MA(Volume, 5))), where Low_Shadow is (min(Open, Close) - Low). All components are cross-sectionally Z-scored before multiplication to ensure scale consistency.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:07:29.663532"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1625580102822972,
        "ICIR": 0.0194090746783034,
        "1day.excess_return_without_cost.std": 0.0043465612604111,
        "1day.excess_return_with_cost.annualized_return": -0.0163031686190775,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001291191370586,
        "1day.excess_return_without_cost.annualized_return": 0.0307303546199512,
        "1day.excess_return_with_cost.std": 0.0043481548099451,
        "Rank IC": 0.0193150273254514,
        "IC": 0.0026394155947826,
        "1day.excess_return_without_cost.max_drawdown": -0.1125879540968572,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4582825157017725,
        "1day.pa": 0.0,
        "l2.valid": 0.9967399126049452,
        "Rank ICIR": 0.1447416470014257,
        "l2.train": 0.9939605253638398,
        "1day.excess_return_with_cost.information_ratio": -0.2430404405200602,
        "1day.excess_return_with_cost.mean": -6.850070848351923e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity-Validated Structural Gap' framework show that while the theoretical concept of combining overnight gaps with intraday absorption (lower shadows) is sound, the current implementations (LVG_5D, SSR_10D, GAF_20D) underperform compared to the SOTA. The IC of 0.0026 and Information Ratio of 0.458 are significantly lower than the SOTA benchmarks. The primary issue appears to be the interaction logic between the gap and the absorption component; the current multiplicative forms might be creating extreme outliers or 'noisy' signals that dilute the predictive power of the structural gap.",
        "hypothesis_evaluation": "The results partially support the hypothesis that structural support (lower shadows) matters, but the 'Liquidity-Validated' component (range-to-volume ratio) as currently formulated may be adding too much noise. The GAF_20D and LVG_5D both use a product of two Z-scored or raw terms, which can be unstable. The hypothesis that institutional absorption validates a gap is likely correct, but the mathematical representation needs to move away from complex ratios and toward more robust 'filtering' or 'additive' logic.",
        "decision": false,
        "reason": "The current 'range-per-unit-volume' metric is highly sensitive to small volume spikes and can lead to overfitting (Complexity Control). By simplifying the 'absorption' measure to a ratio of the lower shadow to the total candle range, and using a simple 20-day ATR or Standard Deviation for normalization, we reduce the number of base features and free parameters. This addresses the 'Complexity Impact' mentioned in the instructions while focusing on the core 'structural support' signal."
      }
    },
    "7733623e496a590c": {
      "factor_id": "7733623e496a590c",
      "factor_name": "Structural_Support_Ratio_10D",
      "factor_expression": "RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(TS_MEAN($volume, 10) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(TS_MEAN($volume, 10) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Support_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the liquidity-validated gap hypothesis focusing on the ratio of the lower shadow to the average intraday volatility normalized by volume. It aims to identify days where price dips were aggressively bought back relative to the ease of price movement (range/volume).",
      "factor_formulation": "SSR_{10D} = RANK(\\frac{MIN(open, close) - low}{high - low + 1e-8}) \\times RANK(\\frac{TS\\_MEAN(volume, 10)}{high - low + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "08c954752077",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Gap' factor, defined as the product of the overnight gap and the ratio of the lower shadow length to the intraday range-to-volume ratio, positively predicts returns by identifying price jumps supported by institutional absorption rather than hollow liquidity vacuums.\n                Concise Observation: Parent 1 showed that high range-to-volume ratios (liquidity vacuums) lead to mean reversion (RankIC=0.0267), while Parent 2 showed that overnight gaps with shadow support predict continuation (RankIC=0.0243).\n                Concise Justification: By scaling the overnight gap by the ratio of the lower shadow (support) to the range-per-unit-volume (vacuum intensity), we filter out 'fake-out' gaps caused by thin order books and prioritize those where buyers actively defended price levels during high-volume interaction.\n                Concise Knowledge: If an overnight price gap is accompanied by a significant lower shadow relative to the intraday range-to-volume ratio, it indicates institutional support; conversely, gaps with high range-to-volume ratios without shadow support suggest fragile liquidity prone to mean reversion.\n                concise Specification: The factor is calculated as (Open/Close[t-1] - 1) * (Low_Shadow / ((High - Low) / MA(Volume, 5))), where Low_Shadow is (min(Open, Close) - Low). All components are cross-sectionally Z-scored before multiplication to ensure scale consistency.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:07:29.663532"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1625580102822972,
        "ICIR": 0.0194090746783034,
        "1day.excess_return_without_cost.std": 0.0043465612604111,
        "1day.excess_return_with_cost.annualized_return": -0.0163031686190775,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001291191370586,
        "1day.excess_return_without_cost.annualized_return": 0.0307303546199512,
        "1day.excess_return_with_cost.std": 0.0043481548099451,
        "Rank IC": 0.0193150273254514,
        "IC": 0.0026394155947826,
        "1day.excess_return_without_cost.max_drawdown": -0.1125879540968572,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4582825157017725,
        "1day.pa": 0.0,
        "l2.valid": 0.9967399126049452,
        "Rank ICIR": 0.1447416470014257,
        "l2.train": 0.9939605253638398,
        "1day.excess_return_with_cost.information_ratio": -0.2430404405200602,
        "1day.excess_return_with_cost.mean": -6.850070848351923e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity-Validated Structural Gap' framework show that while the theoretical concept of combining overnight gaps with intraday absorption (lower shadows) is sound, the current implementations (LVG_5D, SSR_10D, GAF_20D) underperform compared to the SOTA. The IC of 0.0026 and Information Ratio of 0.458 are significantly lower than the SOTA benchmarks. The primary issue appears to be the interaction logic between the gap and the absorption component; the current multiplicative forms might be creating extreme outliers or 'noisy' signals that dilute the predictive power of the structural gap.",
        "hypothesis_evaluation": "The results partially support the hypothesis that structural support (lower shadows) matters, but the 'Liquidity-Validated' component (range-to-volume ratio) as currently formulated may be adding too much noise. The GAF_20D and LVG_5D both use a product of two Z-scored or raw terms, which can be unstable. The hypothesis that institutional absorption validates a gap is likely correct, but the mathematical representation needs to move away from complex ratios and toward more robust 'filtering' or 'additive' logic.",
        "decision": false,
        "reason": "The current 'range-per-unit-volume' metric is highly sensitive to small volume spikes and can lead to overfitting (Complexity Control). By simplifying the 'absorption' measure to a ratio of the lower shadow to the total candle range, and using a simple 20-day ATR or Standard Deviation for normalization, we reduce the number of base features and free parameters. This addresses the 'Complexity Impact' mentioned in the instructions while focusing on the core 'structural support' signal."
      }
    },
    "cf4421222570d91f": {
      "factor_id": "cf4421222570d91f",
      "factor_name": "Gap_Absorption_Factor_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * ((MIN($open, $close) - $low) / (TS_STD($high - $low, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * ((MIN($open, $close) - $low) / (TS_STD($high - $low, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Gap_Absorption_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the interaction between overnight returns and the intraday 'absorption' capacity. It uses the ratio of the lower shadow to the 20-day average volume-adjusted range to filter for gaps that occur at structural support levels.",
      "factor_formulation": "GAF_{20D} = (\\frac{open - DELAY(close, 1)}{DELAY(close, 1)}) \\times (\\frac{MIN(open, close) - low}{TS\\_STD(high - low, 20) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "08c954752077",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "8ccdb416db3d"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Gap' factor, defined as the product of the overnight gap and the ratio of the lower shadow length to the intraday range-to-volume ratio, positively predicts returns by identifying price jumps supported by institutional absorption rather than hollow liquidity vacuums.\n                Concise Observation: Parent 1 showed that high range-to-volume ratios (liquidity vacuums) lead to mean reversion (RankIC=0.0267), while Parent 2 showed that overnight gaps with shadow support predict continuation (RankIC=0.0243).\n                Concise Justification: By scaling the overnight gap by the ratio of the lower shadow (support) to the range-per-unit-volume (vacuum intensity), we filter out 'fake-out' gaps caused by thin order books and prioritize those where buyers actively defended price levels during high-volume interaction.\n                Concise Knowledge: If an overnight price gap is accompanied by a significant lower shadow relative to the intraday range-to-volume ratio, it indicates institutional support; conversely, gaps with high range-to-volume ratios without shadow support suggest fragile liquidity prone to mean reversion.\n                concise Specification: The factor is calculated as (Open/Close[t-1] - 1) * (Low_Shadow / ((High - Low) / MA(Volume, 5))), where Low_Shadow is (min(Open, Close) - Low). All components are cross-sectionally Z-scored before multiplication to ensure scale consistency.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:07:29.663532"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1625580102822972,
        "ICIR": 0.0194090746783034,
        "1day.excess_return_without_cost.std": 0.0043465612604111,
        "1day.excess_return_with_cost.annualized_return": -0.0163031686190775,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001291191370586,
        "1day.excess_return_without_cost.annualized_return": 0.0307303546199512,
        "1day.excess_return_with_cost.std": 0.0043481548099451,
        "Rank IC": 0.0193150273254514,
        "IC": 0.0026394155947826,
        "1day.excess_return_without_cost.max_drawdown": -0.1125879540968572,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4582825157017725,
        "1day.pa": 0.0,
        "l2.valid": 0.9967399126049452,
        "Rank ICIR": 0.1447416470014257,
        "l2.train": 0.9939605253638398,
        "1day.excess_return_with_cost.information_ratio": -0.2430404405200602,
        "1day.excess_return_with_cost.mean": -6.850070848351923e-05
      },
      "feedback": {
        "observations": "The experimental results for the 'Liquidity-Validated Structural Gap' framework show that while the theoretical concept of combining overnight gaps with intraday absorption (lower shadows) is sound, the current implementations (LVG_5D, SSR_10D, GAF_20D) underperform compared to the SOTA. The IC of 0.0026 and Information Ratio of 0.458 are significantly lower than the SOTA benchmarks. The primary issue appears to be the interaction logic between the gap and the absorption component; the current multiplicative forms might be creating extreme outliers or 'noisy' signals that dilute the predictive power of the structural gap.",
        "hypothesis_evaluation": "The results partially support the hypothesis that structural support (lower shadows) matters, but the 'Liquidity-Validated' component (range-to-volume ratio) as currently formulated may be adding too much noise. The GAF_20D and LVG_5D both use a product of two Z-scored or raw terms, which can be unstable. The hypothesis that institutional absorption validates a gap is likely correct, but the mathematical representation needs to move away from complex ratios and toward more robust 'filtering' or 'additive' logic.",
        "decision": false,
        "reason": "The current 'range-per-unit-volume' metric is highly sensitive to small volume spikes and can lead to overfitting (Complexity Control). By simplifying the 'absorption' measure to a ratio of the lower shadow to the total candle range, and using a simple 20-day ATR or Standard Deviation for normalization, we reduce the number of base features and free parameters. This addresses the 'Complexity Impact' mentioned in the instructions while focusing on the core 'structural support' signal."
      }
    },
    "367865f34f88b9f9": {
      "factor_id": "367865f34f88b9f9",
      "factor_name": "Liquidity_Validated_Sentiment_Efficiency_5D",
      "factor_expression": "(($open / DELAY($close, 1) - 1) / (($high - $low) / $close + 1e-8)) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1) - 1) / (($high - $low) / $close + 0.000001)) / (TS_MEAN(ABS(($close / DELAY($close, 1) - 1)) / ($volume + 0.000001), 5) + 0.000001)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Sentiment_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the quality of overnight sentiment by normalizing the price gap by the intraday range and weighting it by the inverse of the Amihud illiquidity. A high value suggests that the price gap is supported by sufficient volume (liquidity), indicating institutional conviction and trend persistence, whereas a low value suggests a liquidity hole prone to reversal.",
      "factor_formulation": "LSE = \\frac{(Open_t / Close_{t-1} - 1) / ((High_t - Low_t) / Close_t + 1e-8)}{\\text{TS_MEAN}(|Return_t| / (Volume_t + 1e-8), 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "89d3f4d57158",
        "parent_trajectory_ids": [
          "85552c59600c",
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Sentiment Efficiency' factor, defined as the ratio of the overnight gap (normalized by intraday range) to the 5-day average Amihud illiquidity, predicts that sentiment-driven price gaps are persistent only when supported by high liquidity, while gaps occurring during liquidity exhaustion are prone to reversal.\n                Concise Observation: Parent 1 showed that illiquidity spikes signal exhaustion (RankIC 0.029), while Parent 2 showed that overnight gaps relative to intraday ranges capture sentiment (RankIC 0.021), suggesting their interaction can filter false momentum signals.\n                Concise Justification: Institutional investors require deep liquidity to execute large orders; therefore, a sentiment gap that doesn't trigger an illiquidity spike (Amihud) suggests the market can absorb the move, whereas high illiquidity during a gap suggests a lack of counterparty depth and imminent price collapse.\n                Concise Knowledge: If a price gap is accompanied by low illiquidity (high volume per price move), it indicates institutional conviction and trend persistence; when a gap occurs alongside high illiquidity spikes, it represents a 'liquidity hole' likely to result in mean-reversion.\n                concise Specification: The factor is calculated as [(Open / Prev_Close - 1) / ((High - Low) / Close)] divided by [Mean(Volume / |Return|, 5)]. A high value indicates high-quality sentiment efficiency, while a low or negative value indicates liquidity-starved exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:13:19.528767"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1107821768974279,
        "ICIR": 0.0462114225566524,
        "1day.excess_return_without_cost.std": 0.0042765972951899,
        "1day.excess_return_with_cost.annualized_return": 0.0226519339170441,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000293856028294,
        "1day.excess_return_without_cost.annualized_return": 0.0699377347339783,
        "1day.excess_return_with_cost.std": 0.0042764494116135,
        "Rank IC": 0.0237787656792307,
        "IC": 0.0061631532222273,
        "1day.excess_return_without_cost.max_drawdown": -0.1016062599440744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.060046035252296,
        "1day.pa": 0.0,
        "l2.valid": 0.9963392363304696,
        "Rank ICIR": 0.1815210472333898,
        "l2.train": 0.9936850430846222,
        "1day.excess_return_with_cost.information_ratio": 0.3433471671805804,
        "1day.excess_return_with_cost.mean": 9.517619292875698e-05
      },
      "feedback": {
        "observations": "The current iteration demonstrates a significant improvement in predictive power and risk-adjusted returns compared to the SOTA. The Information Ratio (IR) increased from 0.97 to 1.06, and the Annualized Return rose from 5.2% to 6.99%. The Information Coefficient (IC) also improved, suggesting that the interaction between overnight sentiment (the gap) and liquidity (Amihud/Volume) is a robust signal. However, the Max Drawdown deepened from -0.07 to -0.10, indicating that while the signal is stronger, it may introduce higher tail risk or sensitivity to market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that sentiment-driven price gaps are more persistent when validated by liquidity. The 'Cross_Sectional_Sentiment_Liquidity_Ratio' and 'Liquidity_Validated_Sentiment_Efficiency_5D' successfully capture the synergy between the magnitude of the gap and the ease of trading. The use of RANK in the cross-sectional version likely helped in neutralizing market-wide liquidity shocks, contributing to the improved IC and IR.",
        "decision": true,
        "reason": "While the current Amihud-based approach is effective, it uses full-day volume which includes the impact of the gap itself. By focusing on the 'Surprise' element (Gap / ATR) and weighting it by a Volume Shock (Current Volume / 20-day Mean Volume), we can better distinguish between institutional positioning and retail-driven noise. This should help address the increased drawdown by filtering out gaps that occur on standard or declining volume, which are more likely to be 'liquidity holes' rather than conviction-driven moves."
      }
    },
    "50ca9d20fa028e6f": {
      "factor_id": "50ca9d20fa028e6f",
      "factor_name": "Cross_Sectional_Sentiment_Liquidity_Ratio",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(TS_MEAN($volume / (ABS($return) + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) * RANK(INV(TS_MEAN(ABS(($close - DELAY($close, 1)) / DELAY($close, 1)) / ($volume + 0.000001), 10)))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Sentiment_Liquidity_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally normalized version of the sentiment efficiency hypothesis. It ranks the overnight gap relative to volatility and compares it against the ranked liquidity (inverse Amihud). This version uses a 10-day window for liquidity smoothing and applies RANK to ensure cross-sectional comparability, focusing on identifying stocks where sentiment and liquidity are most aligned.",
      "factor_formulation": "CSLR = \\text{RANK}(\\frac{Open_t - Close_{t-1}}{Close_{t-1}}) * \\text{RANK}(\\text{TS_MEAN}(\\frac{Volume_t}{|Return_t| + 1e-8}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "89d3f4d57158",
        "parent_trajectory_ids": [
          "85552c59600c",
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Sentiment Efficiency' factor, defined as the ratio of the overnight gap (normalized by intraday range) to the 5-day average Amihud illiquidity, predicts that sentiment-driven price gaps are persistent only when supported by high liquidity, while gaps occurring during liquidity exhaustion are prone to reversal.\n                Concise Observation: Parent 1 showed that illiquidity spikes signal exhaustion (RankIC 0.029), while Parent 2 showed that overnight gaps relative to intraday ranges capture sentiment (RankIC 0.021), suggesting their interaction can filter false momentum signals.\n                Concise Justification: Institutional investors require deep liquidity to execute large orders; therefore, a sentiment gap that doesn't trigger an illiquidity spike (Amihud) suggests the market can absorb the move, whereas high illiquidity during a gap suggests a lack of counterparty depth and imminent price collapse.\n                Concise Knowledge: If a price gap is accompanied by low illiquidity (high volume per price move), it indicates institutional conviction and trend persistence; when a gap occurs alongside high illiquidity spikes, it represents a 'liquidity hole' likely to result in mean-reversion.\n                concise Specification: The factor is calculated as [(Open / Prev_Close - 1) / ((High - Low) / Close)] divided by [Mean(Volume / |Return|, 5)]. A high value indicates high-quality sentiment efficiency, while a low or negative value indicates liquidity-starved exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:13:19.528767"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1107821768974279,
        "ICIR": 0.0462114225566524,
        "1day.excess_return_without_cost.std": 0.0042765972951899,
        "1day.excess_return_with_cost.annualized_return": 0.0226519339170441,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000293856028294,
        "1day.excess_return_without_cost.annualized_return": 0.0699377347339783,
        "1day.excess_return_with_cost.std": 0.0042764494116135,
        "Rank IC": 0.0237787656792307,
        "IC": 0.0061631532222273,
        "1day.excess_return_without_cost.max_drawdown": -0.1016062599440744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.060046035252296,
        "1day.pa": 0.0,
        "l2.valid": 0.9963392363304696,
        "Rank ICIR": 0.1815210472333898,
        "l2.train": 0.9936850430846222,
        "1day.excess_return_with_cost.information_ratio": 0.3433471671805804,
        "1day.excess_return_with_cost.mean": 9.517619292875698e-05
      },
      "feedback": {
        "observations": "The current iteration demonstrates a significant improvement in predictive power and risk-adjusted returns compared to the SOTA. The Information Ratio (IR) increased from 0.97 to 1.06, and the Annualized Return rose from 5.2% to 6.99%. The Information Coefficient (IC) also improved, suggesting that the interaction between overnight sentiment (the gap) and liquidity (Amihud/Volume) is a robust signal. However, the Max Drawdown deepened from -0.07 to -0.10, indicating that while the signal is stronger, it may introduce higher tail risk or sensitivity to market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that sentiment-driven price gaps are more persistent when validated by liquidity. The 'Cross_Sectional_Sentiment_Liquidity_Ratio' and 'Liquidity_Validated_Sentiment_Efficiency_5D' successfully capture the synergy between the magnitude of the gap and the ease of trading. The use of RANK in the cross-sectional version likely helped in neutralizing market-wide liquidity shocks, contributing to the improved IC and IR.",
        "decision": true,
        "reason": "While the current Amihud-based approach is effective, it uses full-day volume which includes the impact of the gap itself. By focusing on the 'Surprise' element (Gap / ATR) and weighting it by a Volume Shock (Current Volume / 20-day Mean Volume), we can better distinguish between institutional positioning and retail-driven noise. This should help address the increased drawdown by filtering out gaps that occur on standard or declining volume, which are more likely to be 'liquidity holes' rather than conviction-driven moves."
      }
    },
    "045aaadb78b8a050": {
      "factor_id": "045aaadb78b8a050",
      "factor_name": "Sentiment_Exhaustion_Index_20D",
      "factor_expression": "TS_ZSCORE(($open / DELAY($close, 1) - 1), 20) / (TS_ZSCORE(ABS($return) / ($volume + 1e-8), 20) + 2.0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($open / DELAY($close, 1) - 1), 20) / (TS_ZSCORE(ABS(($close / DELAY($close, 1) - 1)) / ($volume + 1e-8), 20) + 2)\" # Your output factor expression will be filled in here\n    name = \"Sentiment_Exhaustion_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by detecting 'liquidity-starved' gaps. It calculates the Z-score of the overnight gap and divides it by the Z-score of the Amihud illiquidity over a 20-day period. High values indicate sentiment efficiency, while extreme negative values or divergences suggest exhaustion in a liquidity vacuum.",
      "factor_formulation": "SEI = \\frac{\\text{TS_ZSCORE}(Open_t / Close_{t-1} - 1, 20)}{\\text{TS_ZSCORE}(|Return_t| / (Volume_t + 1e-8), 20) + 2}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "89d3f4d57158",
        "parent_trajectory_ids": [
          "85552c59600c",
          "3f240b40faa8"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Sentiment Efficiency' factor, defined as the ratio of the overnight gap (normalized by intraday range) to the 5-day average Amihud illiquidity, predicts that sentiment-driven price gaps are persistent only when supported by high liquidity, while gaps occurring during liquidity exhaustion are prone to reversal.\n                Concise Observation: Parent 1 showed that illiquidity spikes signal exhaustion (RankIC 0.029), while Parent 2 showed that overnight gaps relative to intraday ranges capture sentiment (RankIC 0.021), suggesting their interaction can filter false momentum signals.\n                Concise Justification: Institutional investors require deep liquidity to execute large orders; therefore, a sentiment gap that doesn't trigger an illiquidity spike (Amihud) suggests the market can absorb the move, whereas high illiquidity during a gap suggests a lack of counterparty depth and imminent price collapse.\n                Concise Knowledge: If a price gap is accompanied by low illiquidity (high volume per price move), it indicates institutional conviction and trend persistence; when a gap occurs alongside high illiquidity spikes, it represents a 'liquidity hole' likely to result in mean-reversion.\n                concise Specification: The factor is calculated as [(Open / Prev_Close - 1) / ((High - Low) / Close)] divided by [Mean(Volume / |Return|, 5)]. A high value indicates high-quality sentiment efficiency, while a low or negative value indicates liquidity-starved exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:13:19.528767"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1107821768974279,
        "ICIR": 0.0462114225566524,
        "1day.excess_return_without_cost.std": 0.0042765972951899,
        "1day.excess_return_with_cost.annualized_return": 0.0226519339170441,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000293856028294,
        "1day.excess_return_without_cost.annualized_return": 0.0699377347339783,
        "1day.excess_return_with_cost.std": 0.0042764494116135,
        "Rank IC": 0.0237787656792307,
        "IC": 0.0061631532222273,
        "1day.excess_return_without_cost.max_drawdown": -0.1016062599440744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.060046035252296,
        "1day.pa": 0.0,
        "l2.valid": 0.9963392363304696,
        "Rank ICIR": 0.1815210472333898,
        "l2.train": 0.9936850430846222,
        "1day.excess_return_with_cost.information_ratio": 0.3433471671805804,
        "1day.excess_return_with_cost.mean": 9.517619292875698e-05
      },
      "feedback": {
        "observations": "The current iteration demonstrates a significant improvement in predictive power and risk-adjusted returns compared to the SOTA. The Information Ratio (IR) increased from 0.97 to 1.06, and the Annualized Return rose from 5.2% to 6.99%. The Information Coefficient (IC) also improved, suggesting that the interaction between overnight sentiment (the gap) and liquidity (Amihud/Volume) is a robust signal. However, the Max Drawdown deepened from -0.07 to -0.10, indicating that while the signal is stronger, it may introduce higher tail risk or sensitivity to market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that sentiment-driven price gaps are more persistent when validated by liquidity. The 'Cross_Sectional_Sentiment_Liquidity_Ratio' and 'Liquidity_Validated_Sentiment_Efficiency_5D' successfully capture the synergy between the magnitude of the gap and the ease of trading. The use of RANK in the cross-sectional version likely helped in neutralizing market-wide liquidity shocks, contributing to the improved IC and IR.",
        "decision": true,
        "reason": "While the current Amihud-based approach is effective, it uses full-day volume which includes the impact of the gap itself. By focusing on the 'Surprise' element (Gap / ATR) and weighting it by a Volume Shock (Current Volume / 20-day Mean Volume), we can better distinguish between institutional positioning and retail-driven noise. This should help address the increased drawdown by filtering out gaps that occur on standard or declining volume, which are more likely to be 'liquidity holes' rather than conviction-driven moves."
      }
    },
    "295221a0e133815f": {
      "factor_id": "295221a0e133815f",
      "factor_name": "IMEI_Gap_Linearity_20D",
      "factor_expression": "ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN(($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2))\" # Your output factor expression will be filled in here\n    name = \"IMEI_Gap_Linearity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Institutional Momentum Exhaustion Index (IMEI) component focusing on the synergy between overnight gaps and price linearity. It measures the 5-day average of normalized overnight gaps scaled by the 10-day price trend linearity (R-squared proxy), identifying high-conviction institutional moves.",
      "factor_formulation": "\\text{ZSCORE}(\\text{TS_MEAN}(\\frac{open - prev\\_close}{high - low}, 5)) \\times \\text{ZSCORE}(\\text{TS_CORR}(close, \\text{SEQUENCE}(10), 10)^2)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "5c99d6654ee5",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Momentum Exhaustion Index' (IMEI) predicts asset returns by scaling the 5-day institutional gap-trend synergy (product of normalized overnight gaps and 10-day price linearity) by a 20-day volume-price convexity penalty, identifying high-conviction trends before they reach liquidity depletion.\n                Concise Observation: Parent 1 (RankIC 0.0267) shows that price-volume convexity captures trend fragility, while Parent 2 (RankIC 0.0237) demonstrates that overnight gaps combined with trend linearity effectively signal institutional conviction.\n                Concise Justification: Fusing these signals allows the model to distinguish between 'healthy' institutional accumulation (high gap synergy, low convexity) and 'exhausted' retail-driven climaxes (high convexity), improving the signal-to-noise ratio of momentum factors.\n                Concise Knowledge: If institutional overnight gaps align with linear price trends, momentum persists; however, when the correlation between price returns and volume growth turns negative or price-volume convexity peaks, the trend becomes brittle and prone to reversal.\n                concise Specification: Define IMEI as (5-day mean of (Open - Prev_Close) / (High - Low)) * (10-day price R-squared) * (1 - 20-day correlation between price returns and volume changes), where all components are z-scored cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:28:58.098143"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1450854929483079,
        "ICIR": 0.0378510838006322,
        "1day.excess_return_without_cost.std": 0.0042753851269329,
        "1day.excess_return_with_cost.annualized_return": -0.0138693005378254,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001405078496683,
        "1day.excess_return_without_cost.annualized_return": 0.0334408682210643,
        "1day.excess_return_with_cost.std": 0.0042760195952111,
        "Rank IC": 0.023007782032308,
        "IC": 0.0053104123883917,
        "1day.excess_return_without_cost.max_drawdown": -0.0930951903683457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5070068463109773,
        "1day.pa": 0.0,
        "l2.valid": 0.9967266058301948,
        "Rank ICIR": 0.167903601252565,
        "l2.train": 0.9940489479907376,
        "1day.excess_return_with_cost.information_ratio": -0.2102453473728435,
        "1day.excess_return_with_cost.mean": -5.827437200766979e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Institutional Momentum Exhaustion Index' (IMEI) by breaking it into components (Gap-Linearity and Convexity Penalty) and a full synergy factor. While the theoretical framework is sound, the 'IMEI_Full_Synergy_Factor' failed to surpass the current SOTA results. The Information Ratio (0.507 vs 0.973) and IC (0.0053 vs 0.0058) are significantly lower than the benchmark. The full synergy factor's complexity is high, involving multiple Z-scores and cross-product terms, which likely led to noise amplification rather than signal enhancement. The 'Convexity Penalty' component, while theoretically interesting, may be too restrictive when combined multiplicatively with the momentum signals.",
        "hypothesis_evaluation": "The hypothesis that scaling gap-trend synergy by a convexity penalty identifies 'high-conviction trends' is partially supported by the fact that the factor generates positive returns, but it is not yet optimized. The current implementation of the 'convexity penalty' (1 - ZSCORE of price-volume correlation) might be overly simplistic. The interaction between overnight gaps and intra-day linearity is a strong signal, but the triple-product structure (Gap * Linearity * Penalty) creates a highly non-linear distribution that may be unstable across different market regimes.",
        "decision": false,
        "reason": "The previous 'Linearity' component (R-squared) often selects for 'over-extended' trends that are nearing exhaustion. By switching focus to 'Gap-Persistence' (the ability of the price to stay above the open) and 'Volatility-Adjusted Volume', we can identify the early stages of institutional accumulation. Furthermore, reducing the complexity from a triple-product to a dual-component additive or simpler multiplicative model will improve robustness and reduce the risk of overfitting observed in the current iteration."
      }
    },
    "3d7da8b842ca153d": {
      "factor_id": "3d7da8b842ca153d",
      "factor_name": "IMEI_Convexity_Penalty_20D",
      "factor_expression": "1.0 - ZSCORE(TS_CORR($return, TS_PCTCHANGE($volume, 1), 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"INV(TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 20))\" # Your output factor expression will be filled in here\n    name = \"IMEI_Convexity_Penalty_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'exhaustion' part of the IMEI hypothesis by penalizing momentum when price-volume convexity becomes extreme. It uses the inverse of the correlation between price returns and volume changes over a 20-day window to identify brittle trends.",
      "factor_formulation": "1 - \\text{ZSCORE}(\\text{TS_CORR}(return, \\text{TS_PCTCHANGE}(volume, 1), 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "5c99d6654ee5",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Momentum Exhaustion Index' (IMEI) predicts asset returns by scaling the 5-day institutional gap-trend synergy (product of normalized overnight gaps and 10-day price linearity) by a 20-day volume-price convexity penalty, identifying high-conviction trends before they reach liquidity depletion.\n                Concise Observation: Parent 1 (RankIC 0.0267) shows that price-volume convexity captures trend fragility, while Parent 2 (RankIC 0.0237) demonstrates that overnight gaps combined with trend linearity effectively signal institutional conviction.\n                Concise Justification: Fusing these signals allows the model to distinguish between 'healthy' institutional accumulation (high gap synergy, low convexity) and 'exhausted' retail-driven climaxes (high convexity), improving the signal-to-noise ratio of momentum factors.\n                Concise Knowledge: If institutional overnight gaps align with linear price trends, momentum persists; however, when the correlation between price returns and volume growth turns negative or price-volume convexity peaks, the trend becomes brittle and prone to reversal.\n                concise Specification: Define IMEI as (5-day mean of (Open - Prev_Close) / (High - Low)) * (10-day price R-squared) * (1 - 20-day correlation between price returns and volume changes), where all components are z-scored cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:28:58.098143"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1450854929483079,
        "ICIR": 0.0378510838006322,
        "1day.excess_return_without_cost.std": 0.0042753851269329,
        "1day.excess_return_with_cost.annualized_return": -0.0138693005378254,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001405078496683,
        "1day.excess_return_without_cost.annualized_return": 0.0334408682210643,
        "1day.excess_return_with_cost.std": 0.0042760195952111,
        "Rank IC": 0.023007782032308,
        "IC": 0.0053104123883917,
        "1day.excess_return_without_cost.max_drawdown": -0.0930951903683457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5070068463109773,
        "1day.pa": 0.0,
        "l2.valid": 0.9967266058301948,
        "Rank ICIR": 0.167903601252565,
        "l2.train": 0.9940489479907376,
        "1day.excess_return_with_cost.information_ratio": -0.2102453473728435,
        "1day.excess_return_with_cost.mean": -5.827437200766979e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Institutional Momentum Exhaustion Index' (IMEI) by breaking it into components (Gap-Linearity and Convexity Penalty) and a full synergy factor. While the theoretical framework is sound, the 'IMEI_Full_Synergy_Factor' failed to surpass the current SOTA results. The Information Ratio (0.507 vs 0.973) and IC (0.0053 vs 0.0058) are significantly lower than the benchmark. The full synergy factor's complexity is high, involving multiple Z-scores and cross-product terms, which likely led to noise amplification rather than signal enhancement. The 'Convexity Penalty' component, while theoretically interesting, may be too restrictive when combined multiplicatively with the momentum signals.",
        "hypothesis_evaluation": "The hypothesis that scaling gap-trend synergy by a convexity penalty identifies 'high-conviction trends' is partially supported by the fact that the factor generates positive returns, but it is not yet optimized. The current implementation of the 'convexity penalty' (1 - ZSCORE of price-volume correlation) might be overly simplistic. The interaction between overnight gaps and intra-day linearity is a strong signal, but the triple-product structure (Gap * Linearity * Penalty) creates a highly non-linear distribution that may be unstable across different market regimes.",
        "decision": false,
        "reason": "The previous 'Linearity' component (R-squared) often selects for 'over-extended' trends that are nearing exhaustion. By switching focus to 'Gap-Persistence' (the ability of the price to stay above the open) and 'Volatility-Adjusted Volume', we can identify the early stages of institutional accumulation. Furthermore, reducing the complexity from a triple-product to a dual-component additive or simpler multiplicative model will improve robustness and reduce the risk of overfitting observed in the current iteration."
      }
    },
    "9a289aa77ac1fdc1": {
      "factor_id": "9a289aa77ac1fdc1",
      "factor_name": "IMEI_Full_Synergy_Factor",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * (1.0 - ZSCORE(TS_CORR($return, DELTA($volume, 1), 20)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * (1.0 - ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), DELTA($volume, 1), 20)))\" # Your output factor expression will be filled in here\n    name = \"IMEI_Full_Synergy_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The integrated IMEI factor combining institutional gap conviction, trend linearity, and the volume-price convexity penalty. It identifies assets where institutional gaps align with steady trends and volume support, while avoiding those showing signs of liquidity depletion.",
      "factor_formulation": "\\text{ZSCORE}(\\frac{open - DELAY(close, 1)}{high - low}) \\times \\text{ZSCORE}(\\text{POW}(\\text{TS_CORR}(close, \\text{SEQUENCE}(10), 10), 2)) \\times (1 - \\text{ZSCORE}(\\text{TS_CORR}(return, \\text{DELTA}(volume, 1), 20)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "5c99d6654ee5",
        "parent_trajectory_ids": [
          "6d4195d3d1f0",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Momentum Exhaustion Index' (IMEI) predicts asset returns by scaling the 5-day institutional gap-trend synergy (product of normalized overnight gaps and 10-day price linearity) by a 20-day volume-price convexity penalty, identifying high-conviction trends before they reach liquidity depletion.\n                Concise Observation: Parent 1 (RankIC 0.0267) shows that price-volume convexity captures trend fragility, while Parent 2 (RankIC 0.0237) demonstrates that overnight gaps combined with trend linearity effectively signal institutional conviction.\n                Concise Justification: Fusing these signals allows the model to distinguish between 'healthy' institutional accumulation (high gap synergy, low convexity) and 'exhausted' retail-driven climaxes (high convexity), improving the signal-to-noise ratio of momentum factors.\n                Concise Knowledge: If institutional overnight gaps align with linear price trends, momentum persists; however, when the correlation between price returns and volume growth turns negative or price-volume convexity peaks, the trend becomes brittle and prone to reversal.\n                concise Specification: Define IMEI as (5-day mean of (Open - Prev_Close) / (High - Low)) * (10-day price R-squared) * (1 - 20-day correlation between price returns and volume changes), where all components are z-scored cross-sectionally.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:28:58.098143"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1450854929483079,
        "ICIR": 0.0378510838006322,
        "1day.excess_return_without_cost.std": 0.0042753851269329,
        "1day.excess_return_with_cost.annualized_return": -0.0138693005378254,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001405078496683,
        "1day.excess_return_without_cost.annualized_return": 0.0334408682210643,
        "1day.excess_return_with_cost.std": 0.0042760195952111,
        "Rank IC": 0.023007782032308,
        "IC": 0.0053104123883917,
        "1day.excess_return_without_cost.max_drawdown": -0.0930951903683457,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5070068463109773,
        "1day.pa": 0.0,
        "l2.valid": 0.9967266058301948,
        "Rank ICIR": 0.167903601252565,
        "l2.train": 0.9940489479907376,
        "1day.excess_return_with_cost.information_ratio": -0.2102453473728435,
        "1day.excess_return_with_cost.mean": -5.827437200766979e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Institutional Momentum Exhaustion Index' (IMEI) by breaking it into components (Gap-Linearity and Convexity Penalty) and a full synergy factor. While the theoretical framework is sound, the 'IMEI_Full_Synergy_Factor' failed to surpass the current SOTA results. The Information Ratio (0.507 vs 0.973) and IC (0.0053 vs 0.0058) are significantly lower than the benchmark. The full synergy factor's complexity is high, involving multiple Z-scores and cross-product terms, which likely led to noise amplification rather than signal enhancement. The 'Convexity Penalty' component, while theoretically interesting, may be too restrictive when combined multiplicatively with the momentum signals.",
        "hypothesis_evaluation": "The hypothesis that scaling gap-trend synergy by a convexity penalty identifies 'high-conviction trends' is partially supported by the fact that the factor generates positive returns, but it is not yet optimized. The current implementation of the 'convexity penalty' (1 - ZSCORE of price-volume correlation) might be overly simplistic. The interaction between overnight gaps and intra-day linearity is a strong signal, but the triple-product structure (Gap * Linearity * Penalty) creates a highly non-linear distribution that may be unstable across different market regimes.",
        "decision": false,
        "reason": "The previous 'Linearity' component (R-squared) often selects for 'over-extended' trends that are nearing exhaustion. By switching focus to 'Gap-Persistence' (the ability of the price to stay above the open) and 'Volatility-Adjusted Volume', we can identify the early stages of institutional accumulation. Furthermore, reducing the complexity from a triple-product to a dual-component additive or simpler multiplicative model will improve robustness and reduce the risk of overfitting observed in the current iteration."
      }
    },
    "ba526a647cf5ee0e": {
      "factor_id": "ba526a647cf5ee0e",
      "factor_name": "Inst_Trend_Liquidity_Validated_5D",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)) / (TS_MEAN($high - $low, 5) / (WMA($volume, 5) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8), 5)) / (TS_MEAN($high - $low, 5) / (WMA($volume, 5) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Inst_Trend_Liquidity_Validated_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction institutional moves by combining price trend linearity (R-squared) with overnight gaps, normalized by a 'liquidity vacuum' metric. It rewards linear trends backed by gaps and penalizes moves occurring in low-volume, high-volatility environments to filter out fragile price spikes.",
      "factor_formulation": "ITLV = \\frac{\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{TS_MEAN}(\\frac{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1))}{\\text{high} - \\text{low} + 1e-8}, 5)}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 5) / (\\text{WMA}(\\text{volume}, 5) + 1e-8)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1b235054d33f",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Validated Trend' factor, calculated as the product of 10-day price trend linearity (R-squared) and the 5-day average overnight gap, divided by the 5-day liquidity vacuum (High-Low range over weighted volume), identifies high-conviction institutional moves while filtering out fragile, low-liquidity price spikes.\n                Concise Observation: Parent 1's liquidity vacuum effectively identifies mean-reverting 'hollow' moves (RankIC 0.0267), while Parent 2's gap-trend synergy captures institutional momentum (RankIC 0.0237); combining them addresses the weakness where trend signals fail during liquidity-depleted volatility spikes.\n                Concise Justification: By using the liquidity vacuum as a denominator (inverse weighting), we amplify trend signals that occur within high-volume environments and penalize those occurring in 'thin' markets, ensuring the factor captures high-quality, volume-backed price discovery.\n                Concise Knowledge: If a price trend exhibits high linearity and is initiated by overnight gaps, it indicates institutional conviction; however, this signal is only sustainable if the 'liquidity vacuum' is low, as high volatility relative to volume suggests a lack of depth prone to mean reversion.\n                concise Specification: The factor is defined as (10-day Close price R-squared * 5-day Mean(Overnight Gap / Daily Range)) / (5-day Mean(High-Low Range) / 5-day Weighted Volume Moving Average), where all components are calculated using daily adjusted price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:44:34.968896"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.082704194736218,
        "ICIR": 0.0413461075933884,
        "1day.excess_return_without_cost.std": 0.004044798614246,
        "1day.excess_return_with_cost.annualized_return": 0.0148373130190573,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002616095104362,
        "1day.excess_return_without_cost.annualized_return": 0.0622630634838351,
        "1day.excess_return_with_cost.std": 0.0040457049078413,
        "Rank IC": 0.0216708623224584,
        "IC": 0.0055443709098467,
        "1day.excess_return_without_cost.max_drawdown": -0.064274655491318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.997803684164623,
        "1day.pa": 0.0,
        "l2.valid": 0.99646685489234,
        "Rank ICIR": 0.1670212671017849,
        "l2.train": 0.9938931393352156,
        "1day.excess_return_with_cost.information_ratio": 0.2377237531047136,
        "1day.excess_return_with_cost.mean": 6.234165134057718e-05
      },
      "feedback": {
        "observations": "The experimental results demonstrate a successful iteration of the 'Institutional Liquidity-Validated Trend' framework. The current iteration achieved a higher Information Ratio (0.9978 vs 0.9725) and a significantly improved Annualized Return (0.0623 vs 0.0520) compared to the SOTA, while also reducing the Max Drawdown (-0.0643 vs -0.0726). Although the IC slightly decreased (0.0055 vs 0.0058), the risk-adjusted performance metrics suggest that the combination of price linearity and liquidity filtering is capturing higher-quality alpha. Among the tested factors, 'Institutional_Conviction_Index_10D' and 'Inst_Trend_Liquidity_Validated_5D' appear to be the primary drivers, effectively using volume to validate price trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional moves are best identified by combining price trend linearity (R-squared) with liquidity metrics. The 'liquidity vacuum' concept (High-Low range relative to volume) effectively filters out noise. However, the complexity of 'Inst_Trend_Liquidity_Validated_5D' (using 5 raw features: open, close, high, low, volume) is approaching the threshold of over-engineering. The simpler 'Institutional_Conviction_Index_10D' provides a more robust foundation by focusing on the core interaction between trend persistence and volume-backed stability.",
        "decision": true,
        "reason": "The current factors use mixed window sizes (10-day for trend, 5-day for liquidity), which may introduce phase-shift noise. By synchronizing the lookback period to 10 days and simplifying the 'liquidity vacuum' to a more standard Volume/ATR ratio, we can reduce the number of base features and free parameters. This follows the principle of complexity control while maintaining the core logic that institutional moves require both price directionality and deep liquidity to be sustainable."
      }
    },
    "cd80fb0b5339b0cd": {
      "factor_id": "cd80fb0b5339b0cd",
      "factor_name": "Liquidity_Vacuum_Adjusted_Gap_Trend",
      "factor_expression": "RANK(TS_MEAN(($open - DELAY($close, 1)) / $close, 5)) / (RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($open - DELAY($close, 1)) / $close, 5)) / (RANK(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Adjusted_Gap_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the institutional conviction hypothesis focusing on the ratio of overnight gap momentum to the liquidity vacuum. It uses the 5-day average of the gap relative to daily range, divided by the ratio of price volatility to volume, cross-sectionally ranked for stability.",
      "factor_formulation": "LVAGT = \\text{RANK}(\\text{TS_MEAN}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{close}}, 5)) / \\text{RANK}(\\frac{\\text{TS_MEAN}(\\text{high} - \\text{low}, 5)}{\\text{TS_MEAN}(\\text{volume}, 5) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1b235054d33f",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Validated Trend' factor, calculated as the product of 10-day price trend linearity (R-squared) and the 5-day average overnight gap, divided by the 5-day liquidity vacuum (High-Low range over weighted volume), identifies high-conviction institutional moves while filtering out fragile, low-liquidity price spikes.\n                Concise Observation: Parent 1's liquidity vacuum effectively identifies mean-reverting 'hollow' moves (RankIC 0.0267), while Parent 2's gap-trend synergy captures institutional momentum (RankIC 0.0237); combining them addresses the weakness where trend signals fail during liquidity-depleted volatility spikes.\n                Concise Justification: By using the liquidity vacuum as a denominator (inverse weighting), we amplify trend signals that occur within high-volume environments and penalize those occurring in 'thin' markets, ensuring the factor captures high-quality, volume-backed price discovery.\n                Concise Knowledge: If a price trend exhibits high linearity and is initiated by overnight gaps, it indicates institutional conviction; however, this signal is only sustainable if the 'liquidity vacuum' is low, as high volatility relative to volume suggests a lack of depth prone to mean reversion.\n                concise Specification: The factor is defined as (10-day Close price R-squared * 5-day Mean(Overnight Gap / Daily Range)) / (5-day Mean(High-Low Range) / 5-day Weighted Volume Moving Average), where all components are calculated using daily adjusted price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:44:34.968896"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.082704194736218,
        "ICIR": 0.0413461075933884,
        "1day.excess_return_without_cost.std": 0.004044798614246,
        "1day.excess_return_with_cost.annualized_return": 0.0148373130190573,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002616095104362,
        "1day.excess_return_without_cost.annualized_return": 0.0622630634838351,
        "1day.excess_return_with_cost.std": 0.0040457049078413,
        "Rank IC": 0.0216708623224584,
        "IC": 0.0055443709098467,
        "1day.excess_return_without_cost.max_drawdown": -0.064274655491318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.997803684164623,
        "1day.pa": 0.0,
        "l2.valid": 0.99646685489234,
        "Rank ICIR": 0.1670212671017849,
        "l2.train": 0.9938931393352156,
        "1day.excess_return_with_cost.information_ratio": 0.2377237531047136,
        "1day.excess_return_with_cost.mean": 6.234165134057718e-05
      },
      "feedback": {
        "observations": "The experimental results demonstrate a successful iteration of the 'Institutional Liquidity-Validated Trend' framework. The current iteration achieved a higher Information Ratio (0.9978 vs 0.9725) and a significantly improved Annualized Return (0.0623 vs 0.0520) compared to the SOTA, while also reducing the Max Drawdown (-0.0643 vs -0.0726). Although the IC slightly decreased (0.0055 vs 0.0058), the risk-adjusted performance metrics suggest that the combination of price linearity and liquidity filtering is capturing higher-quality alpha. Among the tested factors, 'Institutional_Conviction_Index_10D' and 'Inst_Trend_Liquidity_Validated_5D' appear to be the primary drivers, effectively using volume to validate price trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional moves are best identified by combining price trend linearity (R-squared) with liquidity metrics. The 'liquidity vacuum' concept (High-Low range relative to volume) effectively filters out noise. However, the complexity of 'Inst_Trend_Liquidity_Validated_5D' (using 5 raw features: open, close, high, low, volume) is approaching the threshold of over-engineering. The simpler 'Institutional_Conviction_Index_10D' provides a more robust foundation by focusing on the core interaction between trend persistence and volume-backed stability.",
        "decision": true,
        "reason": "The current factors use mixed window sizes (10-day for trend, 5-day for liquidity), which may introduce phase-shift noise. By synchronizing the lookback period to 10 days and simplifying the 'liquidity vacuum' to a more standard Volume/ATR ratio, we can reduce the number of base features and free parameters. This follows the principle of complexity control while maintaining the core logic that institutional moves require both price directionality and deep liquidity to be sustainable."
      }
    },
    "1d6baf776f496c35": {
      "factor_id": "1d6baf776f496c35",
      "factor_name": "Institutional_Conviction_Index_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (TS_MEAN($volume, 10) / (TS_MEAN($high - $low, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the synergy between price trend persistence and liquidity depth. It multiplies the 10-day price linearity by the inverse of the 'liquidity vacuum' (High-Low range / Volume), ensuring that only trends supported by significant volume and low intraday volatility are flagged as high conviction.",
      "factor_formulation": "ICI = \\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\frac{\\text{TS_MEAN}(\\text{volume}, 10)}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 10) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "1b235054d33f",
        "parent_trajectory_ids": [
          "407b02bacaff",
          "74ba6f865315"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Liquidity-Validated Trend' factor, calculated as the product of 10-day price trend linearity (R-squared) and the 5-day average overnight gap, divided by the 5-day liquidity vacuum (High-Low range over weighted volume), identifies high-conviction institutional moves while filtering out fragile, low-liquidity price spikes.\n                Concise Observation: Parent 1's liquidity vacuum effectively identifies mean-reverting 'hollow' moves (RankIC 0.0267), while Parent 2's gap-trend synergy captures institutional momentum (RankIC 0.0237); combining them addresses the weakness where trend signals fail during liquidity-depleted volatility spikes.\n                Concise Justification: By using the liquidity vacuum as a denominator (inverse weighting), we amplify trend signals that occur within high-volume environments and penalize those occurring in 'thin' markets, ensuring the factor captures high-quality, volume-backed price discovery.\n                Concise Knowledge: If a price trend exhibits high linearity and is initiated by overnight gaps, it indicates institutional conviction; however, this signal is only sustainable if the 'liquidity vacuum' is low, as high volatility relative to volume suggests a lack of depth prone to mean reversion.\n                concise Specification: The factor is defined as (10-day Close price R-squared * 5-day Mean(Overnight Gap / Daily Range)) / (5-day Mean(High-Low Range) / 5-day Weighted Volume Moving Average), where all components are calculated using daily adjusted price and volume data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:44:34.968896"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.082704194736218,
        "ICIR": 0.0413461075933884,
        "1day.excess_return_without_cost.std": 0.004044798614246,
        "1day.excess_return_with_cost.annualized_return": 0.0148373130190573,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002616095104362,
        "1day.excess_return_without_cost.annualized_return": 0.0622630634838351,
        "1day.excess_return_with_cost.std": 0.0040457049078413,
        "Rank IC": 0.0216708623224584,
        "IC": 0.0055443709098467,
        "1day.excess_return_without_cost.max_drawdown": -0.064274655491318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.997803684164623,
        "1day.pa": 0.0,
        "l2.valid": 0.99646685489234,
        "Rank ICIR": 0.1670212671017849,
        "l2.train": 0.9938931393352156,
        "1day.excess_return_with_cost.information_ratio": 0.2377237531047136,
        "1day.excess_return_with_cost.mean": 6.234165134057718e-05
      },
      "feedback": {
        "observations": "The experimental results demonstrate a successful iteration of the 'Institutional Liquidity-Validated Trend' framework. The current iteration achieved a higher Information Ratio (0.9978 vs 0.9725) and a significantly improved Annualized Return (0.0623 vs 0.0520) compared to the SOTA, while also reducing the Max Drawdown (-0.0643 vs -0.0726). Although the IC slightly decreased (0.0055 vs 0.0058), the risk-adjusted performance metrics suggest that the combination of price linearity and liquidity filtering is capturing higher-quality alpha. Among the tested factors, 'Institutional_Conviction_Index_10D' and 'Inst_Trend_Liquidity_Validated_5D' appear to be the primary drivers, effectively using volume to validate price trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional moves are best identified by combining price trend linearity (R-squared) with liquidity metrics. The 'liquidity vacuum' concept (High-Low range relative to volume) effectively filters out noise. However, the complexity of 'Inst_Trend_Liquidity_Validated_5D' (using 5 raw features: open, close, high, low, volume) is approaching the threshold of over-engineering. The simpler 'Institutional_Conviction_Index_10D' provides a more robust foundation by focusing on the core interaction between trend persistence and volume-backed stability.",
        "decision": true,
        "reason": "The current factors use mixed window sizes (10-day for trend, 5-day for liquidity), which may introduce phase-shift noise. By synchronizing the lookback period to 10 days and simplifying the 'liquidity vacuum' to a more standard Volume/ATR ratio, we can reduce the number of base features and free parameters. This follows the principle of complexity control while maintaining the core logic that institutional moves require both price directionality and deep liquidity to be sustainable."
      }
    },
    "5e477df39189f4f7": {
      "factor_id": "5e477df39189f4f7",
      "factor_name": "Liquidity_Buffered_Gap_Continuity_5D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * (1 - RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_MEAN(MAX($high - $low, MAX(ABS($high - DELAY($close, 1)), ABS($low - DELAY($close, 1)))), 5) + 1e-8)) * (1 - RANK(TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Buffered_Gap_Continuity_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies sustainable institutional signals by combining the overnight price gap with a liquidity filter. The gap is normalized by the average true range (ATR) to measure conviction. It is then adjusted by the inverse rank of the Amihud illiquidity ratio (absolute return over volume) over a 5-day window. Gaps occurring with low illiquidity (high liquidity) are prioritized, as they suggest sustainable institutional positioning rather than exhausted price spikes.",
      "factor_formulation": "\\text{Gap} = \\frac{\\text{open} - \\text{delay}(\\text{close}, 1)}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 5)}, \\text{Illiq} = \\frac{\\text{ABS}(\\text{return})}{\\text{volume}}, \\text{Factor} = \\text{Gap} \\times (1 - \\text{RANK}(\\text{TS_MEAN}(\\text{Illiq}, 5)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "8005870a87f9",
        "parent_trajectory_ids": [
          "85552c59600c",
          "849c0b2b23a0"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Buffered Gap Continuity' factor identifies high-conviction institutional signals by multiplying the overnight gap (normalized by ATR) with a volume-weighted momentum component, while applying a non-linear penalty for liquidity exhaustion via the Amihud illiquidity spike.\n                Concise Observation: Parent 1 (RankIC 0.029) captures mean-reversion from liquidity exhaustion, while Parent 2 (RankIC 0.021) captures momentum from overnight gaps; combining them addresses the failure of gaps to persist when liquidity is thin.\n                Concise Justification: Institutional flows create price gaps that require sufficient liquidity to sustain a trend; by filtering gaps through a 5-day liquidity exhaustion window, we distinguish between high-capacity informed trades and low-capacity price spikes.\n                Concise Knowledge: If an overnight price gap occurs without a corresponding spike in the Amihud illiquidity ratio, it is more likely to represent sustainable institutional positioning; conversely, gaps accompanied by liquidity exhaustion often signal mean-reverting blow-off tops.\n                concise Specification: Define Gap as (Open - PrevClose) / ATR(5); define Liquidity Exhaustion as the 5-day Amihud Illiquidity (abs(Return)/Volume) relative to its moving average; the factor is the Gap multiplied by (1 - Rank(Liquidity Exhaustion)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:48:52.566842"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0997286417633351,
        "ICIR": 0.0383901482681001,
        "1day.excess_return_without_cost.std": 0.0042050885487607,
        "1day.excess_return_with_cost.annualized_return": 0.0442622896678722,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003828496826256,
        "1day.excess_return_without_cost.annualized_return": 0.0911182244648932,
        "1day.excess_return_with_cost.std": 0.0042059549999511,
        "Rank IC": 0.0218397678289023,
        "IC": 0.0052286194384379,
        "1day.excess_return_without_cost.max_drawdown": -0.0924830475110537,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4045642962503515,
        "1day.pa": 0.0,
        "l2.valid": 0.996452257992103,
        "Rank ICIR": 0.1641165388268079,
        "l2.train": 0.9944704030580672,
        "1day.excess_return_with_cost.information_ratio": 0.6821514014294594,
        "1day.excess_return_with_cost.mean": 0.0001859760070078
      },
      "feedback": {
        "observations": "The current experiment focused on the 'Liquidity-Buffered Gap Continuity' hypothesis by testing two variations: a 5-day ATR-normalized gap with a liquidity rank filter, and a 10-day Z-score gap with an illiquidity penalty. The results show a significant improvement in the Information Ratio (1.40 vs 0.97) and Annualized Return (9.1% vs 5.2%) compared to the SOTA, although the Max Drawdown and IC slightly deteriorated. This suggests that the liquidity filter effectively isolates higher-quality momentum signals, leading to better risk-adjusted returns despite a slightly lower overall correlation (IC).",
        "hypothesis_evaluation": "The results strongly support the hypothesis that filtering overnight gaps with liquidity metrics (Amihud ratio) identifies more sustainable price movements. The 5-day and 10-day implementations demonstrate that 'liquidity-buffered' gaps provide a more robust signal than raw price gaps. However, the increase in Max Drawdown suggests that while the returns are higher, the factor may be susceptible to specific market regimes where liquidity-driven signals cluster and then revert.",
        "decision": true,
        "reason": "The current factors use static windows (5D/10D). In high-volatility regimes, liquidity dries up faster, making static windows lag. By using a 'Liquidity Surprise' (ratio of current illiquidity to its trend), we can better identify genuine institutional 'stealth' entries versus broad market exhaustion. Furthermore, simplifying the gap normalization to a simple percentage change relative to a 20-day volatility band may reduce complexity while maintaining the signal's core logic."
      }
    },
    "1c7c5aba6cd4860d": {
      "factor_id": "1c7c5aba6cd4860d",
      "factor_name": "Gap_Momentum_Liquidity_Resilience_10D",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * RANK(-TS_MEAN(ABS($return) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * RANK(-TS_MEAN(ABS(($close - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Gap_Momentum_Liquidity_Resilience_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the persistence of overnight gaps by filtering for liquidity exhaustion. It uses a 10-day window to calculate the average illiquidity (Amihud ratio) and penalizes gaps that coincide with spikes in illiquidity. By multiplying the normalized gap by the negative Z-score of recent illiquidity, the factor highlights price jumps supported by deep market interest, which are more likely to trend rather than mean-revert.",
      "factor_formulation": "\\text{Factor} = \\text{ZSCORE}(\\frac{\\text{open} - \\text{delay}(\\text{close}, 1)}{\\text{delay}(\\text{close}, 1)}) \\times \\text{RANK}(-\\text{TS_MEAN}(\\frac{\\text{ABS}(\\text{return})}{\\text{volume}}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 4,
        "evolution_phase": "crossover",
        "trajectory_id": "8005870a87f9",
        "parent_trajectory_ids": [
          "85552c59600c",
          "849c0b2b23a0"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Buffered Gap Continuity' factor identifies high-conviction institutional signals by multiplying the overnight gap (normalized by ATR) with a volume-weighted momentum component, while applying a non-linear penalty for liquidity exhaustion via the Amihud illiquidity spike.\n                Concise Observation: Parent 1 (RankIC 0.029) captures mean-reversion from liquidity exhaustion, while Parent 2 (RankIC 0.021) captures momentum from overnight gaps; combining them addresses the failure of gaps to persist when liquidity is thin.\n                Concise Justification: Institutional flows create price gaps that require sufficient liquidity to sustain a trend; by filtering gaps through a 5-day liquidity exhaustion window, we distinguish between high-capacity informed trades and low-capacity price spikes.\n                Concise Knowledge: If an overnight price gap occurs without a corresponding spike in the Amihud illiquidity ratio, it is more likely to represent sustainable institutional positioning; conversely, gaps accompanied by liquidity exhaustion often signal mean-reverting blow-off tops.\n                concise Specification: Define Gap as (Open - PrevClose) / ATR(5); define Liquidity Exhaustion as the 5-day Amihud Illiquidity (abs(Return)/Volume) relative to its moving average; the factor is the Gap multiplied by (1 - Rank(Liquidity Exhaustion)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T04:48:52.566842"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0997286417633351,
        "ICIR": 0.0383901482681001,
        "1day.excess_return_without_cost.std": 0.0042050885487607,
        "1day.excess_return_with_cost.annualized_return": 0.0442622896678722,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003828496826256,
        "1day.excess_return_without_cost.annualized_return": 0.0911182244648932,
        "1day.excess_return_with_cost.std": 0.0042059549999511,
        "Rank IC": 0.0218397678289023,
        "IC": 0.0052286194384379,
        "1day.excess_return_without_cost.max_drawdown": -0.0924830475110537,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.4045642962503515,
        "1day.pa": 0.0,
        "l2.valid": 0.996452257992103,
        "Rank ICIR": 0.1641165388268079,
        "l2.train": 0.9944704030580672,
        "1day.excess_return_with_cost.information_ratio": 0.6821514014294594,
        "1day.excess_return_with_cost.mean": 0.0001859760070078
      },
      "feedback": {
        "observations": "The current experiment focused on the 'Liquidity-Buffered Gap Continuity' hypothesis by testing two variations: a 5-day ATR-normalized gap with a liquidity rank filter, and a 10-day Z-score gap with an illiquidity penalty. The results show a significant improvement in the Information Ratio (1.40 vs 0.97) and Annualized Return (9.1% vs 5.2%) compared to the SOTA, although the Max Drawdown and IC slightly deteriorated. This suggests that the liquidity filter effectively isolates higher-quality momentum signals, leading to better risk-adjusted returns despite a slightly lower overall correlation (IC).",
        "hypothesis_evaluation": "The results strongly support the hypothesis that filtering overnight gaps with liquidity metrics (Amihud ratio) identifies more sustainable price movements. The 5-day and 10-day implementations demonstrate that 'liquidity-buffered' gaps provide a more robust signal than raw price gaps. However, the increase in Max Drawdown suggests that while the returns are higher, the factor may be susceptible to specific market regimes where liquidity-driven signals cluster and then revert.",
        "decision": true,
        "reason": "The current factors use static windows (5D/10D). In high-volatility regimes, liquidity dries up faster, making static windows lag. By using a 'Liquidity Surprise' (ratio of current illiquidity to its trend), we can better identify genuine institutional 'stealth' entries versus broad market exhaustion. Furthermore, simplifying the gap normalization to a simple percentage change relative to a 20-day volatility band may reduce complexity while maintaining the signal's core logic."
      }
    },
    "c3e95ca956f44c5f": {
      "factor_id": "c3e95ca956f44c5f",
      "factor_name": "Trend_Exhaustion_Index_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(REGRESI($close, SEQUENCE(10), 10), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(REGRESI($close, SEQUENCE(10), 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by multiplying the linearity of the price trend (R-squared) by the recent average deviation from that trend. A high R-squared combined with high positive residuals suggests a parabolic move that is likely to exhaust.",
      "factor_formulation": "\\text{TrendExhaustion} = \\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{TS\\_MEAN}(\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(10), 10), 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "04512a60411e",
        "parent_trajectory_ids": [
          "a18c15e6fbc9"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion' factor, calculated as the interaction between a 10-day price-time R-squared and the 5-day average of residuals from a linear trend, predicts a negative return reversal when both metrics are high, as it identifies overextended price moves that lack sustainable structural support.\n                Concise Observation: While the parent strategy focused on illiquid gaps and price floors, market data often shows that even liquid, high-momentum stocks reach 'exhaustion' points where the strength of the trend (R-squared) becomes a liability if the price accelerates too far above the regression line.\n                Concise Justification: High R-squared values indicate a consensus-driven trend; however, when residuals also spike, it suggests a 'blow-off top' or parabolic move where the rate of change is no longer consistent with the established trend, leading to a high-probability reversal.\n                Concise Knowledge: If a price trend exhibits extremely high linearity (high R-squared) alongside large positive deviations from that trend (high residuals), the probability of a mean-reversion event increases because the current price has decoupled from its recent growth trajectory.\n                concise Specification: The factor is defined as the product of the R-squared of $close over a 10-day window against a time index and the 5-day mean of the residuals from that same regression. High positive values are expected to correlate with negative future returns.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T05:08:19.773615"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.138769923707156,
        "ICIR": 0.0579389812500951,
        "1day.excess_return_without_cost.std": 0.0040989617588207,
        "1day.excess_return_with_cost.annualized_return": 0.0051778527602755,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002212018467671,
        "1day.excess_return_without_cost.annualized_return": 0.0526460395305887,
        "1day.excess_return_with_cost.std": 0.0041005433745646,
        "Rank IC": 0.0219338929702103,
        "IC": 0.007835455148842,
        "1day.excess_return_without_cost.max_drawdown": -0.0926508288638392,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8325366485931793,
        "1day.pa": 0.0,
        "l2.valid": 0.996543139529108,
        "Rank ICIR": 0.1626444140519063,
        "l2.train": 0.9938319614595916,
        "1day.excess_return_with_cost.information_ratio": 0.0818502118532473,
        "1day.excess_return_with_cost.mean": 2.1755683866704084e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. The current results show a significant improvement in Information Coefficient (IC) and a slight increase in Annualized Return compared to the previous SOTA, although the Information Ratio (IR) and Max Drawdown (MDD) have deteriorated. This suggests that while the predictive power (IC) of the trend exhaustion concept is strong, the current implementations—specifically combining R-squared with residuals—may introduce higher volatility or tail risk in the portfolio construction phase.",
        "hypothesis_evaluation": "The hypothesis that combining trend linearity (R-squared) with residuals identifies exhaustion is supported by the improved IC (0.0078 vs 0.0057). However, the 'Normalized_Linear_Deviation_Reversal' and 'Trend_Linearity_Volume_Exhaustion' implementations likely contributed to the higher IC. The interaction between price acceleration and volume (VolExhaust) appears to be a strong signal, but the increased drawdown suggests the 'exhaustion' signal might be premature or lead to high-turnover volatility.",
        "decision": true,
        "reason": "The current factors use the absolute level of residuals or their Z-score. However, a high residual can persist in a strong trend. By looking at the change in residuals (the second derivative of price relative to the linear trend), we can better capture the 'parabolic' acceleration phase. Furthermore, the current symbol lengths are approaching complexity limits; simplifying the interaction by using a 5-day ROC of the 10-day residual, multiplied by a binary volume trigger (volume > mean volume), may reduce noise and improve the Information Ratio."
      }
    },
    "6e0856d7f18174be": {
      "factor_id": "6e0856d7f18174be",
      "factor_name": "Normalized_Linear_Deviation_Reversal",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE(REGRESI($close, SEQUENCE(10), 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Linear_Deviation_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A refined version of the trend exhaustion hypothesis that uses Z-scored residuals to normalize the deviation across different price levels. It captures the interaction between trend strength (R-squared) and the magnitude of recent 'over-shooting' relative to the 10-day linear trend.",
      "factor_formulation": "\\text{NormDev} = \\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{TS\\_ZSCORE}(\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(10), 10), 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "04512a60411e",
        "parent_trajectory_ids": [
          "a18c15e6fbc9"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion' factor, calculated as the interaction between a 10-day price-time R-squared and the 5-day average of residuals from a linear trend, predicts a negative return reversal when both metrics are high, as it identifies overextended price moves that lack sustainable structural support.\n                Concise Observation: While the parent strategy focused on illiquid gaps and price floors, market data often shows that even liquid, high-momentum stocks reach 'exhaustion' points where the strength of the trend (R-squared) becomes a liability if the price accelerates too far above the regression line.\n                Concise Justification: High R-squared values indicate a consensus-driven trend; however, when residuals also spike, it suggests a 'blow-off top' or parabolic move where the rate of change is no longer consistent with the established trend, leading to a high-probability reversal.\n                Concise Knowledge: If a price trend exhibits extremely high linearity (high R-squared) alongside large positive deviations from that trend (high residuals), the probability of a mean-reversion event increases because the current price has decoupled from its recent growth trajectory.\n                concise Specification: The factor is defined as the product of the R-squared of $close over a 10-day window against a time index and the 5-day mean of the residuals from that same regression. High positive values are expected to correlate with negative future returns.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T05:08:19.773615"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.138769923707156,
        "ICIR": 0.0579389812500951,
        "1day.excess_return_without_cost.std": 0.0040989617588207,
        "1day.excess_return_with_cost.annualized_return": 0.0051778527602755,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002212018467671,
        "1day.excess_return_without_cost.annualized_return": 0.0526460395305887,
        "1day.excess_return_with_cost.std": 0.0041005433745646,
        "Rank IC": 0.0219338929702103,
        "IC": 0.007835455148842,
        "1day.excess_return_without_cost.max_drawdown": -0.0926508288638392,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8325366485931793,
        "1day.pa": 0.0,
        "l2.valid": 0.996543139529108,
        "Rank ICIR": 0.1626444140519063,
        "l2.train": 0.9938319614595916,
        "1day.excess_return_with_cost.information_ratio": 0.0818502118532473,
        "1day.excess_return_with_cost.mean": 2.1755683866704084e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. The current results show a significant improvement in Information Coefficient (IC) and a slight increase in Annualized Return compared to the previous SOTA, although the Information Ratio (IR) and Max Drawdown (MDD) have deteriorated. This suggests that while the predictive power (IC) of the trend exhaustion concept is strong, the current implementations—specifically combining R-squared with residuals—may introduce higher volatility or tail risk in the portfolio construction phase.",
        "hypothesis_evaluation": "The hypothesis that combining trend linearity (R-squared) with residuals identifies exhaustion is supported by the improved IC (0.0078 vs 0.0057). However, the 'Normalized_Linear_Deviation_Reversal' and 'Trend_Linearity_Volume_Exhaustion' implementations likely contributed to the higher IC. The interaction between price acceleration and volume (VolExhaust) appears to be a strong signal, but the increased drawdown suggests the 'exhaustion' signal might be premature or lead to high-turnover volatility.",
        "decision": true,
        "reason": "The current factors use the absolute level of residuals or their Z-score. However, a high residual can persist in a strong trend. By looking at the change in residuals (the second derivative of price relative to the linear trend), we can better capture the 'parabolic' acceleration phase. Furthermore, the current symbol lengths are approaching complexity limits; simplifying the interaction by using a 5-day ROC of the 10-day residual, multiplied by a binary volume trigger (volume > mean volume), may reduce noise and improve the Information Ratio."
      }
    },
    "a9ac3f9a546cccad": {
      "factor_id": "a9ac3f9a546cccad",
      "factor_name": "Trend_Linearity_Volume_Exhaustion",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * REGRESI($close, SEQUENCE(10), 10) * TS_RANK($volume, 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * REGRESI($close, SEQUENCE(10), 10) * TS_RANK($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Trend_Linearity_Volume_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor combines the trend exhaustion logic (R-squared and residuals) with volume confirmation. It assumes that exhaustion is more likely when the price acceleration (residuals) occurs on high relative volume, indicating a final 'blow-off' phase.",
      "factor_formulation": "\\text{VolExhaust} = \\text{POW}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(10), 10) \\times \\text{TS\\_RANK}(\\text{volume}, 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "04512a60411e",
        "parent_trajectory_ids": [
          "a18c15e6fbc9"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion' factor, calculated as the interaction between a 10-day price-time R-squared and the 5-day average of residuals from a linear trend, predicts a negative return reversal when both metrics are high, as it identifies overextended price moves that lack sustainable structural support.\n                Concise Observation: While the parent strategy focused on illiquid gaps and price floors, market data often shows that even liquid, high-momentum stocks reach 'exhaustion' points where the strength of the trend (R-squared) becomes a liability if the price accelerates too far above the regression line.\n                Concise Justification: High R-squared values indicate a consensus-driven trend; however, when residuals also spike, it suggests a 'blow-off top' or parabolic move where the rate of change is no longer consistent with the established trend, leading to a high-probability reversal.\n                Concise Knowledge: If a price trend exhibits extremely high linearity (high R-squared) alongside large positive deviations from that trend (high residuals), the probability of a mean-reversion event increases because the current price has decoupled from its recent growth trajectory.\n                concise Specification: The factor is defined as the product of the R-squared of $close over a 10-day window against a time index and the 5-day mean of the residuals from that same regression. High positive values are expected to correlate with negative future returns.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T05:08:19.773615"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.138769923707156,
        "ICIR": 0.0579389812500951,
        "1day.excess_return_without_cost.std": 0.0040989617588207,
        "1day.excess_return_with_cost.annualized_return": 0.0051778527602755,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002212018467671,
        "1day.excess_return_without_cost.annualized_return": 0.0526460395305887,
        "1day.excess_return_with_cost.std": 0.0041005433745646,
        "Rank IC": 0.0219338929702103,
        "IC": 0.007835455148842,
        "1day.excess_return_without_cost.max_drawdown": -0.0926508288638392,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8325366485931793,
        "1day.pa": 0.0,
        "l2.valid": 0.996543139529108,
        "Rank ICIR": 0.1626444140519063,
        "l2.train": 0.9938319614595916,
        "1day.excess_return_with_cost.information_ratio": 0.0818502118532473,
        "1day.excess_return_with_cost.mean": 2.1755683866704084e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Exhaustion' hypothesis. The current results show a significant improvement in Information Coefficient (IC) and a slight increase in Annualized Return compared to the previous SOTA, although the Information Ratio (IR) and Max Drawdown (MDD) have deteriorated. This suggests that while the predictive power (IC) of the trend exhaustion concept is strong, the current implementations—specifically combining R-squared with residuals—may introduce higher volatility or tail risk in the portfolio construction phase.",
        "hypothesis_evaluation": "The hypothesis that combining trend linearity (R-squared) with residuals identifies exhaustion is supported by the improved IC (0.0078 vs 0.0057). However, the 'Normalized_Linear_Deviation_Reversal' and 'Trend_Linearity_Volume_Exhaustion' implementations likely contributed to the higher IC. The interaction between price acceleration and volume (VolExhaust) appears to be a strong signal, but the increased drawdown suggests the 'exhaustion' signal might be premature or lead to high-turnover volatility.",
        "decision": true,
        "reason": "The current factors use the absolute level of residuals or their Z-score. However, a high residual can persist in a strong trend. By looking at the change in residuals (the second derivative of price relative to the linear trend), we can better capture the 'parabolic' acceleration phase. Furthermore, the current symbol lengths are approaching complexity limits; simplifying the interaction by using a 5-day ROC of the 10-day residual, multiplied by a binary volume trigger (volume > mean volume), may reduce noise and improve the Information Ratio."
      }
    },
    "e3b8a13f1577e2e4": {
      "factor_id": "e3b8a13f1577e2e4",
      "factor_name": "Intraday_Noise_Reversal_5D",
      "factor_expression": "TS_MEAN($high - $low, 5) / (TS_MEAN(ABS($close - DELAY($close, 1)), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($high - $low, 5) / (TS_MEAN(ABS($close - DELAY($close, 1)), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Noise_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies assets where intraday price volatility (High-Low) significantly exceeds the net daily price movement (Close-Prev_Close). High values suggest retail-driven noise and lack of institutional trend conviction, leading to expected mean-reversion.",
      "factor_formulation": "\\frac{\\text{TS_MEAN}(\\text{high} - \\text{low}, 5)}{\\text{TS_MEAN}(\\text{ABS}(\\text{close} - \\text{DELAY}(\\text{close}, 1)), 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "2e1b6ecbbe3f",
        "parent_trajectory_ids": [
          "1f6370143231"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Noise Reversal' factor, defined as the ratio of the daily price range to the absolute total daily return, predicts that assets with excessive intraday volatility relative to their net price movement are dominated by retail-driven noise and will likely mean-revert.\n                Concise Observation: Parent strategies focused on institutional trend conviction (R-squared) and liquidity exhaustion, yet assets often exhibit high 'churn' or 'noise' where wide price swings result in little net progress, suggesting a different regime of retail overreaction.\n                Concise Justification: By isolating the portion of volatility that does not contribute to the net trend (the 'noise' component), we can identify overextended retail sentiment that lacks institutional support, providing an orthogonal signal to trend-following models.\n                Concise Knowledge: If intraday price dispersion (High-Low) significantly exceeds the net directional move (Close-Open), the price action is likely driven by transitory liquidity imbalances rather than fundamental information; such noise-heavy assets tend to mean-revert as market makers stabilize the price.\n                concise Specification: The factor is calculated as the 5-day average of (High - Low) divided by the 5-day average of (Abs(Close - Prev_Close) + epsilon); high values indicate high noise and predict negative future returns (mean-reversion), while low values indicate efficient, directional movement.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T05:11:38.657794"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1334165522308853,
        "ICIR": 0.0331045856660251,
        "1day.excess_return_without_cost.std": 0.0042736711198766,
        "1day.excess_return_with_cost.annualized_return": -0.0066401507172893,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001696729086294,
        "1day.excess_return_without_cost.annualized_return": 0.0403821522538175,
        "1day.excess_return_with_cost.std": 0.0042754410271156,
        "Rank IC": 0.0182919130138323,
        "IC": 0.004221055951423,
        "1day.excess_return_without_cost.max_drawdown": -0.1046430639147896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.612491245155302,
        "1day.pa": 0.0,
        "l2.valid": 0.9966388129433296,
        "Rank ICIR": 0.1455556713988343,
        "l2.train": 0.9935560371589632,
        "1day.excess_return_with_cost.information_ratio": -0.1006719632570456,
        "1day.excess_return_with_cost.mean": -2.7899792929787255e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Intraday Noise Reversal' hypothesis using 5-day, 10-day, and 20-day windows with different normalization techniques (Z-score and Rank). While the core concept of comparing intraday range to net movement remains theoretically sound, the current implementations (Intraday_Noise_Reversal_5D, Zscored_Noise_Efficiency_Ratio_10D, and Relative_Intraday_Churn_Rank_20D) failed to outperform the existing SOTA. The Information Ratio (0.612 vs 0.972) and IC (0.0042 vs 0.0057) show significant deterioration, suggesting that the current mathematical formulations may be capturing too much noise or the windows are not optimized for the reversal decay profile.",
        "hypothesis_evaluation": "The results partially support the hypothesis that intraday 'churn' contains predictive information, as the IC remains positive. However, the performance drop compared to SOTA suggests that simple ratios of (High-Low) to (Close-PrevClose) might be too raw. The 'Relative_Intraday_Churn_Rank_20D' using (High-Low)/(Close-Open) is a better proxy for 'spinning wheels' but the 20-day window might be too long for a mean-reversion signal, which typically operates on shorter horizons. The 'noise' identified might be transitioning into a trend rather than reversing if the window is too wide.",
        "decision": false,
        "reason": "1. Window Size: Mean-reversion signals based on 'noise' typically decay quickly; 20 days is likely capturing structural volatility rather than transient noise. 2. Volume Confirmation: High intraday range without net progress ('churn') is more likely to reverse if it is accompanied by high volume, signaling a 'blow-off' top or bottom. 3. Complexity: The current factors are simple (low SL and ER), which is good, but they lack the conditional logic (like volume weighting) that distinguishes between healthy trend volatility and exhausted noise."
      }
    },
    "3c6ae7d093821046": {
      "factor_id": "3c6ae7d093821046",
      "factor_name": "Zscored_Noise_Efficiency_Ratio_10D",
      "factor_expression": "ZSCORE(TS_SUM($high - $low, 10) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM($high - $low, 10) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Zscored_Noise_Efficiency_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally standardized measure of the ratio between intraday range and absolute net movement over 10 days. It filters out market-wide volatility to isolate idiosyncratic noise that predicts short-term reversals.",
      "factor_formulation": "\\text{ZSCORE}\\left(\\frac{\\text{TS_SUM}(\\text{high} - \\text{low}, 10)}{\\text{TS_SUM}(\\text{ABS}(\\text{close} - \\text{DELAY}(\\text{close}, 1)), 10) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "2e1b6ecbbe3f",
        "parent_trajectory_ids": [
          "1f6370143231"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Noise Reversal' factor, defined as the ratio of the daily price range to the absolute total daily return, predicts that assets with excessive intraday volatility relative to their net price movement are dominated by retail-driven noise and will likely mean-revert.\n                Concise Observation: Parent strategies focused on institutional trend conviction (R-squared) and liquidity exhaustion, yet assets often exhibit high 'churn' or 'noise' where wide price swings result in little net progress, suggesting a different regime of retail overreaction.\n                Concise Justification: By isolating the portion of volatility that does not contribute to the net trend (the 'noise' component), we can identify overextended retail sentiment that lacks institutional support, providing an orthogonal signal to trend-following models.\n                Concise Knowledge: If intraday price dispersion (High-Low) significantly exceeds the net directional move (Close-Open), the price action is likely driven by transitory liquidity imbalances rather than fundamental information; such noise-heavy assets tend to mean-revert as market makers stabilize the price.\n                concise Specification: The factor is calculated as the 5-day average of (High - Low) divided by the 5-day average of (Abs(Close - Prev_Close) + epsilon); high values indicate high noise and predict negative future returns (mean-reversion), while low values indicate efficient, directional movement.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T05:11:38.657794"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1334165522308853,
        "ICIR": 0.0331045856660251,
        "1day.excess_return_without_cost.std": 0.0042736711198766,
        "1day.excess_return_with_cost.annualized_return": -0.0066401507172893,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001696729086294,
        "1day.excess_return_without_cost.annualized_return": 0.0403821522538175,
        "1day.excess_return_with_cost.std": 0.0042754410271156,
        "Rank IC": 0.0182919130138323,
        "IC": 0.004221055951423,
        "1day.excess_return_without_cost.max_drawdown": -0.1046430639147896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.612491245155302,
        "1day.pa": 0.0,
        "l2.valid": 0.9966388129433296,
        "Rank ICIR": 0.1455556713988343,
        "l2.train": 0.9935560371589632,
        "1day.excess_return_with_cost.information_ratio": -0.1006719632570456,
        "1day.excess_return_with_cost.mean": -2.7899792929787255e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Intraday Noise Reversal' hypothesis using 5-day, 10-day, and 20-day windows with different normalization techniques (Z-score and Rank). While the core concept of comparing intraday range to net movement remains theoretically sound, the current implementations (Intraday_Noise_Reversal_5D, Zscored_Noise_Efficiency_Ratio_10D, and Relative_Intraday_Churn_Rank_20D) failed to outperform the existing SOTA. The Information Ratio (0.612 vs 0.972) and IC (0.0042 vs 0.0057) show significant deterioration, suggesting that the current mathematical formulations may be capturing too much noise or the windows are not optimized for the reversal decay profile.",
        "hypothesis_evaluation": "The results partially support the hypothesis that intraday 'churn' contains predictive information, as the IC remains positive. However, the performance drop compared to SOTA suggests that simple ratios of (High-Low) to (Close-PrevClose) might be too raw. The 'Relative_Intraday_Churn_Rank_20D' using (High-Low)/(Close-Open) is a better proxy for 'spinning wheels' but the 20-day window might be too long for a mean-reversion signal, which typically operates on shorter horizons. The 'noise' identified might be transitioning into a trend rather than reversing if the window is too wide.",
        "decision": false,
        "reason": "1. Window Size: Mean-reversion signals based on 'noise' typically decay quickly; 20 days is likely capturing structural volatility rather than transient noise. 2. Volume Confirmation: High intraday range without net progress ('churn') is more likely to reverse if it is accompanied by high volume, signaling a 'blow-off' top or bottom. 3. Complexity: The current factors are simple (low SL and ER), which is good, but they lack the conditional logic (like volume weighting) that distinguishes between healthy trend volatility and exhausted noise."
      }
    },
    "b4a9bc198ba88b3f": {
      "factor_id": "b4a9bc198ba88b3f",
      "factor_name": "Relative_Intraday_Churn_Rank_20D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Relative_Intraday_Churn_Rank_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the relative rank of price 'churn' by comparing the daily high-low spread to the net price change magnitude. High ranks indicate price action that is 'spinning its wheels', often a precursor to a reversal in retail sentiment.",
      "factor_formulation": "\\text{RANK}(\\text{TS_MEAN}((\\text{high} - \\text{low}) / (\\text{ABS}(\\text{close} - \\text{open}) + 1e-8), 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "2e1b6ecbbe3f",
        "parent_trajectory_ids": [
          "1f6370143231"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Noise Reversal' factor, defined as the ratio of the daily price range to the absolute total daily return, predicts that assets with excessive intraday volatility relative to their net price movement are dominated by retail-driven noise and will likely mean-revert.\n                Concise Observation: Parent strategies focused on institutional trend conviction (R-squared) and liquidity exhaustion, yet assets often exhibit high 'churn' or 'noise' where wide price swings result in little net progress, suggesting a different regime of retail overreaction.\n                Concise Justification: By isolating the portion of volatility that does not contribute to the net trend (the 'noise' component), we can identify overextended retail sentiment that lacks institutional support, providing an orthogonal signal to trend-following models.\n                Concise Knowledge: If intraday price dispersion (High-Low) significantly exceeds the net directional move (Close-Open), the price action is likely driven by transitory liquidity imbalances rather than fundamental information; such noise-heavy assets tend to mean-revert as market makers stabilize the price.\n                concise Specification: The factor is calculated as the 5-day average of (High - Low) divided by the 5-day average of (Abs(Close - Prev_Close) + epsilon); high values indicate high noise and predict negative future returns (mean-reversion), while low values indicate efficient, directional movement.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T05:11:38.657794"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1334165522308853,
        "ICIR": 0.0331045856660251,
        "1day.excess_return_without_cost.std": 0.0042736711198766,
        "1day.excess_return_with_cost.annualized_return": -0.0066401507172893,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001696729086294,
        "1day.excess_return_without_cost.annualized_return": 0.0403821522538175,
        "1day.excess_return_with_cost.std": 0.0042754410271156,
        "Rank IC": 0.0182919130138323,
        "IC": 0.004221055951423,
        "1day.excess_return_without_cost.max_drawdown": -0.1046430639147896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.612491245155302,
        "1day.pa": 0.0,
        "l2.valid": 0.9966388129433296,
        "Rank ICIR": 0.1455556713988343,
        "l2.train": 0.9935560371589632,
        "1day.excess_return_with_cost.information_ratio": -0.1006719632570456,
        "1day.excess_return_with_cost.mean": -2.7899792929787255e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Intraday Noise Reversal' hypothesis using 5-day, 10-day, and 20-day windows with different normalization techniques (Z-score and Rank). While the core concept of comparing intraday range to net movement remains theoretically sound, the current implementations (Intraday_Noise_Reversal_5D, Zscored_Noise_Efficiency_Ratio_10D, and Relative_Intraday_Churn_Rank_20D) failed to outperform the existing SOTA. The Information Ratio (0.612 vs 0.972) and IC (0.0042 vs 0.0057) show significant deterioration, suggesting that the current mathematical formulations may be capturing too much noise or the windows are not optimized for the reversal decay profile.",
        "hypothesis_evaluation": "The results partially support the hypothesis that intraday 'churn' contains predictive information, as the IC remains positive. However, the performance drop compared to SOTA suggests that simple ratios of (High-Low) to (Close-PrevClose) might be too raw. The 'Relative_Intraday_Churn_Rank_20D' using (High-Low)/(Close-Open) is a better proxy for 'spinning wheels' but the 20-day window might be too long for a mean-reversion signal, which typically operates on shorter horizons. The 'noise' identified might be transitioning into a trend rather than reversing if the window is too wide.",
        "decision": false,
        "reason": "1. Window Size: Mean-reversion signals based on 'noise' typically decay quickly; 20 days is likely capturing structural volatility rather than transient noise. 2. Volume Confirmation: High intraday range without net progress ('churn') is more likely to reverse if it is accompanied by high volume, signaling a 'blow-off' top or bottom. 3. Complexity: The current factors are simple (low SL and ER), which is good, but they lack the conditional logic (like volume weighting) that distinguishes between healthy trend volatility and exhausted noise."
      }
    },
    "7a6fa6db948c5c0e": {
      "factor_id": "7a6fa6db948c5c0e",
      "factor_name": "Support_Integrity_V1_5D",
      "factor_expression": "TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-8)) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(((MIN($open, $close) - $low) / ($high - $low + 1e-8)) / (TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Support_Integrity_V1_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies robust price floors by calculating the interaction between lower shadow intensity and the inverse of volume volatility over a 5-day window. High values suggest price rejection (lower shadows) occurring under stable volume conditions, indicating institutional accumulation rather than speculative noise.",
      "factor_formulation": "\\text{TS\\_MEAN}\\left(\\frac{(\\min(\\text{open}, \\text{close}) - \\text{low}) / (\\text{high} - \\text{low} + 1e-8)}{\\text{TS\\_STD}(\\text{volume}, 5) / \\text{TS\\_MEAN}(\\text{volume}, 5) + 1e-8}, 5\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "1a54f34c260c",
        "parent_trajectory_ids": [
          "1c383f3ba18b"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the interaction between the 5-day lower shadow intensity (KLOW) and the inverse of 5-day volume volatility (VSTD5), identifies robust price floors where low-variance trading activity validates institutional accumulation.\n                Concise Observation: The parent strategy focused on macro capitulation and liquidity exhaustion (mean-reversion), but failed to distinguish between 'noisy' price spikes and 'stable' accumulation phases where volume remains steady despite downward price pressure.\n                Concise Justification: Stable volume during the formation of lower shadows suggests 'passive' absorption of selling pressure by informed buyers, creating a high-integrity support level that is less prone to the 'liquidity vacuum' reversals seen in high-volatility regimes.\n                Concise Knowledge: If a price rejection (lower shadow) occurs with low volume dispersion, it indicates a consensus on value rather than speculative noise; when volume volatility is low during price tests, the resulting support levels are more likely to persist.\n                concise Specification: The factor is calculated as the 5-day moving average of (Low Price Rejection / Volume Volatility), where Low Price Rejection is (min(Open, Close) - Low) / (High - Low) and Volume Volatility is the standard deviation of volume over 5 days.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T05:16:19.410575"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.099254510720057,
        "ICIR": 0.0370074529819554,
        "1day.excess_return_without_cost.std": 0.0042440557148108,
        "1day.excess_return_with_cost.annualized_return": 0.0202261783034501,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002838570960112,
        "1day.excess_return_without_cost.annualized_return": 0.0675579888506793,
        "1day.excess_return_with_cost.std": 0.0042449708039688,
        "Rank IC": 0.0215642640989362,
        "IC": 0.0050912916195498,
        "1day.excess_return_without_cost.max_drawdown": -0.0866152979226323,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0318276401481683,
        "1day.pa": 0.0,
        "l2.valid": 0.996497937678522,
        "Rank ICIR": 0.1612609848728832,
        "l2.train": 0.9938203988102152,
        "1day.excess_return_with_cost.information_ratio": 0.3088521616513451,
        "1day.excess_return_with_cost.mean": 8.498394245147122e-05
      },
      "feedback": {
        "observations": "The current iteration focused on testing three variations of the 'Support Integrity' hypothesis: a direct ratio (V1), a cross-sectional rank interaction (Ranked), and a Z-score differential (Accumulation Floor). The results show a significant improvement in risk-adjusted returns. Specifically, the Information Ratio increased from 0.97 to 1.03, and the Annualized Return rose from 5.2% to 6.76%. Although the IC and Max Drawdown slightly deteriorated compared to the SOTA, the overall efficiency of the signal in capturing excess returns has improved. The 'Ranked' and 'Z-score' approaches likely contributed to this by filtering out noise and focusing on relative price floor strength.",
        "hypothesis_evaluation": "The hypothesis that price rejection (lower shadows) coupled with low volume volatility identifies institutional accumulation is strongly supported. The improvement in Annualized Return and Information Ratio suggests that 'Support Integrity' is a valid alpha source. However, the slight drop in IC suggests that while the signal is more profitable on average, its linear correlation with daily returns is slightly noisier, possibly due to the interaction terms being non-linear in nature.",
        "decision": true,
        "reason": "Currently, the factor identifies lower shadows anywhere. By adding a condition or multiplier that reflects where the current price sits relative to its 10-day high/low range, we can distinguish between a 'dip-buying' opportunity in a consolidation phase and a potential reversal at a peak. This adds a 'Value' dimension to the existing 'Liquidity/Volatility' dimension, likely reducing the Max Drawdown and improving the IC by ensuring we only buy 'cheap' support."
      }
    },
    "e7966d4fc526a1b6": {
      "factor_id": "e7966d4fc526a1b6",
      "factor_name": "Ranked_Support_Stability_5D",
      "factor_expression": "RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Support_Stability_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the Support Integrity hypothesis. It measures the relative strength of price rejection normalized by volume dispersion. By ranking the lower shadow intensity and the inverse of volume volatility separately, it identifies stocks with the most 'stable' support levels relative to the market.",
      "factor_formulation": "\\text{RANK}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{high} - \\text{low} + 1e-8}\\right) * \\text{RANK}\\left(\\frac{1}{\\text{TS\\_STD}(\\text{volume}, 5) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "1a54f34c260c",
        "parent_trajectory_ids": [
          "1c383f3ba18b"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the interaction between the 5-day lower shadow intensity (KLOW) and the inverse of 5-day volume volatility (VSTD5), identifies robust price floors where low-variance trading activity validates institutional accumulation.\n                Concise Observation: The parent strategy focused on macro capitulation and liquidity exhaustion (mean-reversion), but failed to distinguish between 'noisy' price spikes and 'stable' accumulation phases where volume remains steady despite downward price pressure.\n                Concise Justification: Stable volume during the formation of lower shadows suggests 'passive' absorption of selling pressure by informed buyers, creating a high-integrity support level that is less prone to the 'liquidity vacuum' reversals seen in high-volatility regimes.\n                Concise Knowledge: If a price rejection (lower shadow) occurs with low volume dispersion, it indicates a consensus on value rather than speculative noise; when volume volatility is low during price tests, the resulting support levels are more likely to persist.\n                concise Specification: The factor is calculated as the 5-day moving average of (Low Price Rejection / Volume Volatility), where Low Price Rejection is (min(Open, Close) - Low) / (High - Low) and Volume Volatility is the standard deviation of volume over 5 days.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T05:16:19.410575"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.099254510720057,
        "ICIR": 0.0370074529819554,
        "1day.excess_return_without_cost.std": 0.0042440557148108,
        "1day.excess_return_with_cost.annualized_return": 0.0202261783034501,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002838570960112,
        "1day.excess_return_without_cost.annualized_return": 0.0675579888506793,
        "1day.excess_return_with_cost.std": 0.0042449708039688,
        "Rank IC": 0.0215642640989362,
        "IC": 0.0050912916195498,
        "1day.excess_return_without_cost.max_drawdown": -0.0866152979226323,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0318276401481683,
        "1day.pa": 0.0,
        "l2.valid": 0.996497937678522,
        "Rank ICIR": 0.1612609848728832,
        "l2.train": 0.9938203988102152,
        "1day.excess_return_with_cost.information_ratio": 0.3088521616513451,
        "1day.excess_return_with_cost.mean": 8.498394245147122e-05
      },
      "feedback": {
        "observations": "The current iteration focused on testing three variations of the 'Support Integrity' hypothesis: a direct ratio (V1), a cross-sectional rank interaction (Ranked), and a Z-score differential (Accumulation Floor). The results show a significant improvement in risk-adjusted returns. Specifically, the Information Ratio increased from 0.97 to 1.03, and the Annualized Return rose from 5.2% to 6.76%. Although the IC and Max Drawdown slightly deteriorated compared to the SOTA, the overall efficiency of the signal in capturing excess returns has improved. The 'Ranked' and 'Z-score' approaches likely contributed to this by filtering out noise and focusing on relative price floor strength.",
        "hypothesis_evaluation": "The hypothesis that price rejection (lower shadows) coupled with low volume volatility identifies institutional accumulation is strongly supported. The improvement in Annualized Return and Information Ratio suggests that 'Support Integrity' is a valid alpha source. However, the slight drop in IC suggests that while the signal is more profitable on average, its linear correlation with daily returns is slightly noisier, possibly due to the interaction terms being non-linear in nature.",
        "decision": true,
        "reason": "Currently, the factor identifies lower shadows anywhere. By adding a condition or multiplier that reflects where the current price sits relative to its 10-day high/low range, we can distinguish between a 'dip-buying' opportunity in a consolidation phase and a potential reversal at a peak. This adds a 'Value' dimension to the existing 'Liquidity/Volatility' dimension, likely reducing the Max Drawdown and improving the IC by ensuring we only buy 'cheap' support."
      }
    },
    "7cf1f3ed654504a9": {
      "factor_id": "7cf1f3ed654504a9",
      "factor_name": "Accumulation_Floor_ZScore_10D",
      "factor_expression": "TS_ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-8), 10) - TS_ZSCORE(TS_STD($volume, 5), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((MIN($open, $close) - $low) / ($high - $low + 1e-8), 10) - TS_ZSCORE(TS_STD($volume, 5), 10)\" # Your output factor expression will be filled in here\n    name = \"Accumulation_Floor_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor uses a Z-score approach to identify periods where the lower shadow is significantly larger than its recent history while volume volatility is lower than average. It targets the 'Support Integrity' hypothesis by looking for high-quality price rejections over a slightly longer 10-day smoothing period.",
      "factor_formulation": "\\text{TS\\_ZSCORE}\\left(\\frac{\\min(\\text{open}, \\text{close}) - \\text{low}}{\\text{high} - \\text{low} + 1e-8}, 10\\right) - \\text{TS\\_ZSCORE}(\\text{TS\\_STD}(\\text{volume}, 5), 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "1a54f34c260c",
        "parent_trajectory_ids": [
          "1c383f3ba18b"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor, defined as the interaction between the 5-day lower shadow intensity (KLOW) and the inverse of 5-day volume volatility (VSTD5), identifies robust price floors where low-variance trading activity validates institutional accumulation.\n                Concise Observation: The parent strategy focused on macro capitulation and liquidity exhaustion (mean-reversion), but failed to distinguish between 'noisy' price spikes and 'stable' accumulation phases where volume remains steady despite downward price pressure.\n                Concise Justification: Stable volume during the formation of lower shadows suggests 'passive' absorption of selling pressure by informed buyers, creating a high-integrity support level that is less prone to the 'liquidity vacuum' reversals seen in high-volatility regimes.\n                Concise Knowledge: If a price rejection (lower shadow) occurs with low volume dispersion, it indicates a consensus on value rather than speculative noise; when volume volatility is low during price tests, the resulting support levels are more likely to persist.\n                concise Specification: The factor is calculated as the 5-day moving average of (Low Price Rejection / Volume Volatility), where Low Price Rejection is (min(Open, Close) - Low) / (High - Low) and Volume Volatility is the standard deviation of volume over 5 days.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T05:16:19.410575"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.099254510720057,
        "ICIR": 0.0370074529819554,
        "1day.excess_return_without_cost.std": 0.0042440557148108,
        "1day.excess_return_with_cost.annualized_return": 0.0202261783034501,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002838570960112,
        "1day.excess_return_without_cost.annualized_return": 0.0675579888506793,
        "1day.excess_return_with_cost.std": 0.0042449708039688,
        "Rank IC": 0.0215642640989362,
        "IC": 0.0050912916195498,
        "1day.excess_return_without_cost.max_drawdown": -0.0866152979226323,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0318276401481683,
        "1day.pa": 0.0,
        "l2.valid": 0.996497937678522,
        "Rank ICIR": 0.1612609848728832,
        "l2.train": 0.9938203988102152,
        "1day.excess_return_with_cost.information_ratio": 0.3088521616513451,
        "1day.excess_return_with_cost.mean": 8.498394245147122e-05
      },
      "feedback": {
        "observations": "The current iteration focused on testing three variations of the 'Support Integrity' hypothesis: a direct ratio (V1), a cross-sectional rank interaction (Ranked), and a Z-score differential (Accumulation Floor). The results show a significant improvement in risk-adjusted returns. Specifically, the Information Ratio increased from 0.97 to 1.03, and the Annualized Return rose from 5.2% to 6.76%. Although the IC and Max Drawdown slightly deteriorated compared to the SOTA, the overall efficiency of the signal in capturing excess returns has improved. The 'Ranked' and 'Z-score' approaches likely contributed to this by filtering out noise and focusing on relative price floor strength.",
        "hypothesis_evaluation": "The hypothesis that price rejection (lower shadows) coupled with low volume volatility identifies institutional accumulation is strongly supported. The improvement in Annualized Return and Information Ratio suggests that 'Support Integrity' is a valid alpha source. However, the slight drop in IC suggests that while the signal is more profitable on average, its linear correlation with daily returns is slightly noisier, possibly due to the interaction terms being non-linear in nature.",
        "decision": true,
        "reason": "Currently, the factor identifies lower shadows anywhere. By adding a condition or multiplier that reflects where the current price sits relative to its 10-day high/low range, we can distinguish between a 'dip-buying' opportunity in a consolidation phase and a potential reversal at a peak. This adds a 'Value' dimension to the existing 'Liquidity/Volatility' dimension, likely reducing the Max Drawdown and improving the IC by ensuring we only buy 'cheap' support."
      }
    },
    "90e80ee811c1e3ea": {
      "factor_id": "90e80ee811c1e3ea",
      "factor_name": "Info_Diffusion_Velocity_20D",
      "factor_expression": "TS_SUM($return, 20) * (-1 * ZSCORE(REGBETA($volume, SEQUENCE(10), 10)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM(TS_PCTCHANGE($close, 1), 20) * (-1 * ZSCORE(REGBETA($volume, SEQUENCE(10), 10)))\" # Your output factor expression will be filled in here\n    name = \"Info_Diffusion_Velocity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies sustainable momentum by combining the 20-day cumulative return with the negative slope of volume. It targets 'quiet' institutional accumulation where price rises while volume decays, suggesting incomplete information diffusion and trend persistence.",
      "factor_formulation": "IDV_{20D} = \\text{TS_SUM}(\\text{return}, 20) \\times (-1 \\times \\text{ZSCORE}(\\text{REGBETA}(\\text{volume}, \\text{SEQUENCE}(10), 10)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "825a7962879d",
        "parent_trajectory_ids": [
          "80d8b859336c"
        ],
        "hypothesis": "Hypothesis: The 'Information Diffusion Velocity' factor, calculated as the 20-day cumulative abnormal return multiplied by the negative z-score of the 10-day volume decay slope, identifies sustainable momentum trends driven by quiet institutional accumulation following significant price shocks.\n                Concise Observation: The parent strategy focused on mean reversion during high-impact liquidity exhaustion (high Amihud); however, market leaders often exhibit a 'quiet' phase where volume dries up but price does not mean-revert, suggesting a transition from liquidity-driven noise to information-driven momentum.\n                Concise Justification: Low volume following a major price move (gap) suggests a lack of counter-party conviction to reverse the trend, while 'tight' price action indicates that informed participants are not aggressively bidding up the price, allowing for a longer-term drift as the broader market gradually recognizes the new valuation.\n                Concise Knowledge: If a significant price gap is followed by decreasing volume and low price volatility, it indicates institutional absorption of information; when volume decays while price remains stable or drifts, the initial trend is likely to persist due to incomplete information diffusion.\n                concise Specification: The factor targets the momentum dimension by combining the 20-day price change (ROC20) with the 10-day linear regression slope of volume; it expects a positive relationship between return and the rate of volume contraction (negative slope) during the post-shock consolidation period.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T05:25:06.521097"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1054775814188652,
        "ICIR": 0.0290493898082324,
        "1day.excess_return_without_cost.std": 0.0047770326610012,
        "1day.excess_return_with_cost.annualized_return": 0.0049665811580612,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002198146614213,
        "1day.excess_return_without_cost.annualized_return": 0.0523158894182696,
        "1day.excess_return_with_cost.std": 0.0047776028248885,
        "Rank IC": 0.0207639315900022,
        "IC": 0.0040874613483027,
        "1day.excess_return_without_cost.max_drawdown": -0.0865488341161516,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7098832419278053,
        "1day.pa": 0.0,
        "l2.valid": 0.9968153943523989,
        "Rank ICIR": 0.1524454528680154,
        "l2.train": 0.9942179639476182,
        "1day.excess_return_with_cost.information_ratio": 0.0673843456222096,
        "1day.excess_return_with_cost.mean": 2.0867988059080905e-05
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Information Diffusion Velocity' framework. The results show that while the current iteration achieved a slightly higher annualized return (0.0523 vs 0.0520) compared to the SOTA, it suffered from a significant decline in Information Ratio (0.709 vs 0.972) and IC (0.0040 vs 0.0057), alongside a deeper maximum drawdown. This suggests that while the 'quiet accumulation' signal captures some alpha, the current mathematical implementations (specifically using raw volume regression slopes and simple division by volume volatility) introduce significant noise or instability into the signal.",
        "hypothesis_evaluation": "The hypothesis that 'Information Diffusion Velocity' identifies sustainable trends is partially supported by the positive annualized return, but the low IC and IR suggest the 'velocity' component (volume decay) is not yet optimally captured. The 'Quiet_Accumulation_Momentum_15D' and 'Info_Diffusion_Velocity_20D' both rely on linear regression of volume (REGBETA), which might be too sensitive to outliers or specific volume spikes. The 'Absorption_Efficiency_Factor' uses volume CV (Coefficient of Variation), which appears to be a more stable representation of 'quietness' but may need better integration with price action.",
        "decision": false,
        "reason": "The current use of REGBETA(volume, 10) is highly sensitive to the starting and ending points of the 10-day window. A more robust measure of 'quiet accumulation' is the ratio of price trend strength to volume volatility. By using the ratio of the 20-day price rank to the 10-day volume standard deviation rank (normalized), we can identify stocks that are moving significantly on low relative effort (volume), which is a classic sign of institutional absorption. This reduces the complexity of regression while maintaining the core theoretical framework."
      }
    },
    "bc9092d159ea6f21": {
      "factor_id": "bc9092d159ea6f21",
      "factor_name": "Quiet_Accumulation_Momentum_15D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 20)) * (1 - RANK(REGBETA($volume, SEQUENCE(10), 10)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 20)) * (1 - RANK(REGBETA($volume, SEQUENCE(10), 10)))\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Momentum_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the transition from high-impact shocks to quiet momentum. It measures the 20-day price change normalized by the negative rank of the 10-day volume trend, identifying stocks where selling pressure has exhausted while the price trend remains intact.",
      "factor_formulation": "QAM_{15D} = \\text{RANK}(\\text{TS_PCTCHANGE}(\\text{close}, 20)) \\times (1 - \\text{RANK}(\\text{REGBETA}(\\text{volume}, \\text{SEQUENCE}(10), 10)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "825a7962879d",
        "parent_trajectory_ids": [
          "80d8b859336c"
        ],
        "hypothesis": "Hypothesis: The 'Information Diffusion Velocity' factor, calculated as the 20-day cumulative abnormal return multiplied by the negative z-score of the 10-day volume decay slope, identifies sustainable momentum trends driven by quiet institutional accumulation following significant price shocks.\n                Concise Observation: The parent strategy focused on mean reversion during high-impact liquidity exhaustion (high Amihud); however, market leaders often exhibit a 'quiet' phase where volume dries up but price does not mean-revert, suggesting a transition from liquidity-driven noise to information-driven momentum.\n                Concise Justification: Low volume following a major price move (gap) suggests a lack of counter-party conviction to reverse the trend, while 'tight' price action indicates that informed participants are not aggressively bidding up the price, allowing for a longer-term drift as the broader market gradually recognizes the new valuation.\n                Concise Knowledge: If a significant price gap is followed by decreasing volume and low price volatility, it indicates institutional absorption of information; when volume decays while price remains stable or drifts, the initial trend is likely to persist due to incomplete information diffusion.\n                concise Specification: The factor targets the momentum dimension by combining the 20-day price change (ROC20) with the 10-day linear regression slope of volume; it expects a positive relationship between return and the rate of volume contraction (negative slope) during the post-shock consolidation period.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T05:25:06.521097"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1054775814188652,
        "ICIR": 0.0290493898082324,
        "1day.excess_return_without_cost.std": 0.0047770326610012,
        "1day.excess_return_with_cost.annualized_return": 0.0049665811580612,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002198146614213,
        "1day.excess_return_without_cost.annualized_return": 0.0523158894182696,
        "1day.excess_return_with_cost.std": 0.0047776028248885,
        "Rank IC": 0.0207639315900022,
        "IC": 0.0040874613483027,
        "1day.excess_return_without_cost.max_drawdown": -0.0865488341161516,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7098832419278053,
        "1day.pa": 0.0,
        "l2.valid": 0.9968153943523989,
        "Rank ICIR": 0.1524454528680154,
        "l2.train": 0.9942179639476182,
        "1day.excess_return_with_cost.information_ratio": 0.0673843456222096,
        "1day.excess_return_with_cost.mean": 2.0867988059080905e-05
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Information Diffusion Velocity' framework. The results show that while the current iteration achieved a slightly higher annualized return (0.0523 vs 0.0520) compared to the SOTA, it suffered from a significant decline in Information Ratio (0.709 vs 0.972) and IC (0.0040 vs 0.0057), alongside a deeper maximum drawdown. This suggests that while the 'quiet accumulation' signal captures some alpha, the current mathematical implementations (specifically using raw volume regression slopes and simple division by volume volatility) introduce significant noise or instability into the signal.",
        "hypothesis_evaluation": "The hypothesis that 'Information Diffusion Velocity' identifies sustainable trends is partially supported by the positive annualized return, but the low IC and IR suggest the 'velocity' component (volume decay) is not yet optimally captured. The 'Quiet_Accumulation_Momentum_15D' and 'Info_Diffusion_Velocity_20D' both rely on linear regression of volume (REGBETA), which might be too sensitive to outliers or specific volume spikes. The 'Absorption_Efficiency_Factor' uses volume CV (Coefficient of Variation), which appears to be a more stable representation of 'quietness' but may need better integration with price action.",
        "decision": false,
        "reason": "The current use of REGBETA(volume, 10) is highly sensitive to the starting and ending points of the 10-day window. A more robust measure of 'quiet accumulation' is the ratio of price trend strength to volume volatility. By using the ratio of the 20-day price rank to the 10-day volume standard deviation rank (normalized), we can identify stocks that are moving significantly on low relative effort (volume), which is a classic sign of institutional absorption. This reduces the complexity of regression while maintaining the core theoretical framework."
      }
    },
    "e37760bc39900c86": {
      "factor_id": "e37760bc39900c86",
      "factor_name": "Absorption_Efficiency_Factor",
      "factor_expression": "RANK(TS_MEAN($return, 20)) / (TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(TS_PCTCHANGE($close, 1), 20)) / (TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 0.00000001) + 0.00000001)\" # Your output factor expression will be filled in here\n    name = \"Absorption_Efficiency_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the efficiency of information absorption by looking for positive returns during periods of declining volume volatility. It uses the inverse of volume standard deviation to weight the recent return, emphasizing 'tight' price action during consolidation.",
      "factor_formulation": "AEF = \\text{RANK}(\\text{TS_MEAN}(\\text{return}, 20)) / (\\text{TS_STD}(\\text{volume}, 10) / \\text{TS_MEAN}(\\text{volume}, 10) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "825a7962879d",
        "parent_trajectory_ids": [
          "80d8b859336c"
        ],
        "hypothesis": "Hypothesis: The 'Information Diffusion Velocity' factor, calculated as the 20-day cumulative abnormal return multiplied by the negative z-score of the 10-day volume decay slope, identifies sustainable momentum trends driven by quiet institutional accumulation following significant price shocks.\n                Concise Observation: The parent strategy focused on mean reversion during high-impact liquidity exhaustion (high Amihud); however, market leaders often exhibit a 'quiet' phase where volume dries up but price does not mean-revert, suggesting a transition from liquidity-driven noise to information-driven momentum.\n                Concise Justification: Low volume following a major price move (gap) suggests a lack of counter-party conviction to reverse the trend, while 'tight' price action indicates that informed participants are not aggressively bidding up the price, allowing for a longer-term drift as the broader market gradually recognizes the new valuation.\n                Concise Knowledge: If a significant price gap is followed by decreasing volume and low price volatility, it indicates institutional absorption of information; when volume decays while price remains stable or drifts, the initial trend is likely to persist due to incomplete information diffusion.\n                concise Specification: The factor targets the momentum dimension by combining the 20-day price change (ROC20) with the 10-day linear regression slope of volume; it expects a positive relationship between return and the rate of volume contraction (negative slope) during the post-shock consolidation period.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T05:25:06.521097"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1054775814188652,
        "ICIR": 0.0290493898082324,
        "1day.excess_return_without_cost.std": 0.0047770326610012,
        "1day.excess_return_with_cost.annualized_return": 0.0049665811580612,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002198146614213,
        "1day.excess_return_without_cost.annualized_return": 0.0523158894182696,
        "1day.excess_return_with_cost.std": 0.0047776028248885,
        "Rank IC": 0.0207639315900022,
        "IC": 0.0040874613483027,
        "1day.excess_return_without_cost.max_drawdown": -0.0865488341161516,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7098832419278053,
        "1day.pa": 0.0,
        "l2.valid": 0.9968153943523989,
        "Rank ICIR": 0.1524454528680154,
        "l2.train": 0.9942179639476182,
        "1day.excess_return_with_cost.information_ratio": 0.0673843456222096,
        "1day.excess_return_with_cost.mean": 2.0867988059080905e-05
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Information Diffusion Velocity' framework. The results show that while the current iteration achieved a slightly higher annualized return (0.0523 vs 0.0520) compared to the SOTA, it suffered from a significant decline in Information Ratio (0.709 vs 0.972) and IC (0.0040 vs 0.0057), alongside a deeper maximum drawdown. This suggests that while the 'quiet accumulation' signal captures some alpha, the current mathematical implementations (specifically using raw volume regression slopes and simple division by volume volatility) introduce significant noise or instability into the signal.",
        "hypothesis_evaluation": "The hypothesis that 'Information Diffusion Velocity' identifies sustainable trends is partially supported by the positive annualized return, but the low IC and IR suggest the 'velocity' component (volume decay) is not yet optimally captured. The 'Quiet_Accumulation_Momentum_15D' and 'Info_Diffusion_Velocity_20D' both rely on linear regression of volume (REGBETA), which might be too sensitive to outliers or specific volume spikes. The 'Absorption_Efficiency_Factor' uses volume CV (Coefficient of Variation), which appears to be a more stable representation of 'quietness' but may need better integration with price action.",
        "decision": false,
        "reason": "The current use of REGBETA(volume, 10) is highly sensitive to the starting and ending points of the 10-day window. A more robust measure of 'quiet accumulation' is the ratio of price trend strength to volume volatility. By using the ratio of the 20-day price rank to the 10-day volume standard deviation rank (normalized), we can identify stocks that are moving significantly on low relative effort (volume), which is a classic sign of institutional absorption. This reduces the complexity of regression while maintaining the core theoretical framework."
      }
    },
    "b6664f3b34123332": {
      "factor_id": "b6664f3b34123332",
      "factor_name": "Trend_Fragility_Index_10D",
      "factor_expression": "TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by calculating the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity. Linearity is represented by the R-squared of the close price against a time sequence over 10 days. A high ratio signifies that volatility is overwhelming the structural trend, indicating fragility.",
      "factor_formulation": "TFI_{10D} = \\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "530df3fa45ca",
        "parent_trajectory_ids": [
          "387e9b891c3f"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared), where a high ratio signifies that volatility is overwhelming the structural trend.\n                Concise Observation: The parent strategy focused on price-volume convexity and institutional gaps, but it ignored the 'noise-to-signal' ratio of the trend itself; market regimes often shift when the 'energy' of price swings exceeds the 'order' of the directional path.\n                Concise Justification: A high standard deviation relative to a low R-squared indicates that price action is becoming erratic and 'fragile,' suggesting that the consensus driving the trend is dissolving, whereas a high R-squared with low volatility suggests a stable, institutional-led move.\n                Concise Knowledge: If price volatility increases while the linear strength of a trend (R-squared) diminishes, the current price movement is likely unsustainable and prone to a structural break; When volatility is low relative to trend stability, the trend is robust.\n                concise Specification: The factor is defined as TS_STD($close, 5) divided by the R-squared of $close against a time sequence over 10 days; high values predict trend exhaustion/reversal, while low values predict trend persistence.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T05:43:14.589399"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1849158787669921,
        "ICIR": 0.0163564914895835,
        "1day.excess_return_without_cost.std": 0.004067533810132,
        "1day.excess_return_with_cost.annualized_return": -0.0170189648831944,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001264287937155,
        "1day.excess_return_without_cost.annualized_return": 0.030090052904289,
        "1day.excess_return_with_cost.std": 0.0040690885949618,
        "Rank IC": 0.0136614121145102,
        "IC": 0.0021005862278118,
        "1day.excess_return_without_cost.max_drawdown": -0.1295122408916024,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4795162190381012,
        "1day.pa": 0.0,
        "l2.valid": 0.9968226712624446,
        "Rank ICIR": 0.1056611680815067,
        "l2.train": 0.9942063888525235,
        "1day.excess_return_with_cost.information_ratio": -0.271111236603433,
        "1day.excess_return_with_cost.mean": -7.150825581174153e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the ratio of volatility/dispersion to trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_10D, Robust_Trend_Signal_20D, and Cross_Sectional_Trend_Fragility) failed to outperform the SOTA result across all key metrics. The Information Ratio (0.479 vs 0.972) and IC (0.0021 vs 0.0057) suggest that the current signal-to-noise ratio of these factors is relatively weak. The Cross_Sectional_Trend_Fragility factor introduced more raw features ($high, $low) but did not yield the expected performance boost, suggesting that the core 'fragility' calculation might be too sensitive to outliers or requires a different normalization approach.",
        "hypothesis_evaluation": "The hypothesis that a high ratio of dispersion to linearity identifies reversals is partially supported by the fact that the factors generate positive excess returns, but the low IC indicates the relationship is not as robust as initially theorized. The 10-day R-squared denominator might be too unstable; when the correlation is near zero, the factor value explodes, creating extreme outliers that degrade model performance. The 'Robust' version using MAD and a 20-day window showed that extending the lookback period and using robust statistics is a valid direction, but it still lacks the predictive power of the SOTA.",
        "decision": false,
        "reason": "1. Stability: Using a bounded denominator (e.g., Trend Strength = ABS(CORR)) prevents extreme values that occur when R-squared is near zero. 2. Change Detection: Reversals are often preceded by a *sudden increase* in fragility rather than a sustained high level; therefore, a Z-score or a percentage change of the TFI over a 5-day window may capture the 'exhaustion' point more accurately. 3. Complexity Control: By keeping the feature count low and focusing on the mathematical transformation of the core ratio, we maintain a low Symbol Length and avoid over-engineering."
      }
    },
    "a3d767c309827a63": {
      "factor_id": "a3d767c309827a63",
      "factor_name": "Robust_Trend_Signal_20D",
      "factor_expression": "TS_MAD($close, 10) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MAD($close, 10) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Robust_Trend_Signal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the trend fragility concept that uses the Median Absolute Deviation (MAD) for robust volatility and a longer 20-day window for trend linearity. It measures the 'noise-to-signal' ratio; lower values indicate a stable, institutional-led move, while higher values suggest the trend is becoming erratic.",
      "factor_formulation": "RTS_{20D} = \\frac{TS\\_MAD(close, 10)}{ABS(TS\\_CORR(close, SEQUENCE(20), 20)) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "530df3fa45ca",
        "parent_trajectory_ids": [
          "387e9b891c3f"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared), where a high ratio signifies that volatility is overwhelming the structural trend.\n                Concise Observation: The parent strategy focused on price-volume convexity and institutional gaps, but it ignored the 'noise-to-signal' ratio of the trend itself; market regimes often shift when the 'energy' of price swings exceeds the 'order' of the directional path.\n                Concise Justification: A high standard deviation relative to a low R-squared indicates that price action is becoming erratic and 'fragile,' suggesting that the consensus driving the trend is dissolving, whereas a high R-squared with low volatility suggests a stable, institutional-led move.\n                Concise Knowledge: If price volatility increases while the linear strength of a trend (R-squared) diminishes, the current price movement is likely unsustainable and prone to a structural break; When volatility is low relative to trend stability, the trend is robust.\n                concise Specification: The factor is defined as TS_STD($close, 5) divided by the R-squared of $close against a time sequence over 10 days; high values predict trend exhaustion/reversal, while low values predict trend persistence.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T05:43:14.589399"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1849158787669921,
        "ICIR": 0.0163564914895835,
        "1day.excess_return_without_cost.std": 0.004067533810132,
        "1day.excess_return_with_cost.annualized_return": -0.0170189648831944,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001264287937155,
        "1day.excess_return_without_cost.annualized_return": 0.030090052904289,
        "1day.excess_return_with_cost.std": 0.0040690885949618,
        "Rank IC": 0.0136614121145102,
        "IC": 0.0021005862278118,
        "1day.excess_return_without_cost.max_drawdown": -0.1295122408916024,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4795162190381012,
        "1day.pa": 0.0,
        "l2.valid": 0.9968226712624446,
        "Rank ICIR": 0.1056611680815067,
        "l2.train": 0.9942063888525235,
        "1day.excess_return_with_cost.information_ratio": -0.271111236603433,
        "1day.excess_return_with_cost.mean": -7.150825581174153e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the ratio of volatility/dispersion to trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_10D, Robust_Trend_Signal_20D, and Cross_Sectional_Trend_Fragility) failed to outperform the SOTA result across all key metrics. The Information Ratio (0.479 vs 0.972) and IC (0.0021 vs 0.0057) suggest that the current signal-to-noise ratio of these factors is relatively weak. The Cross_Sectional_Trend_Fragility factor introduced more raw features ($high, $low) but did not yield the expected performance boost, suggesting that the core 'fragility' calculation might be too sensitive to outliers or requires a different normalization approach.",
        "hypothesis_evaluation": "The hypothesis that a high ratio of dispersion to linearity identifies reversals is partially supported by the fact that the factors generate positive excess returns, but the low IC indicates the relationship is not as robust as initially theorized. The 10-day R-squared denominator might be too unstable; when the correlation is near zero, the factor value explodes, creating extreme outliers that degrade model performance. The 'Robust' version using MAD and a 20-day window showed that extending the lookback period and using robust statistics is a valid direction, but it still lacks the predictive power of the SOTA.",
        "decision": false,
        "reason": "1. Stability: Using a bounded denominator (e.g., Trend Strength = ABS(CORR)) prevents extreme values that occur when R-squared is near zero. 2. Change Detection: Reversals are often preceded by a *sudden increase* in fragility rather than a sustained high level; therefore, a Z-score or a percentage change of the TFI over a 5-day window may capture the 'exhaustion' point more accurately. 3. Complexity Control: By keeping the feature count low and focusing on the mathematical transformation of the core ratio, we maintain a low Symbol Length and avoid over-engineering."
      }
    },
    "0d4f9726c1d380f6": {
      "factor_id": "0d4f9726c1d380f6",
      "factor_name": "Cross_Sectional_Trend_Fragility",
      "factor_expression": "RANK(TS_MEAN($high - $low, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($high - $low, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Trend_Fragility\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor normalizes the Trend Fragility Index cross-sectionally to identify stocks that are most 'fragile' relative to the market. It uses the 5-day price range normalized by the 10-day trend strength (R-squared), then applies a RANK to ensure comparability across different instruments.",
      "factor_formulation": "CSTF = RANK(\\frac{TS\\_MEAN(high - low, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "530df3fa45ca",
        "parent_trajectory_ids": [
          "387e9b891c3f"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' identifies potential price reversals by calculating the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared), where a high ratio signifies that volatility is overwhelming the structural trend.\n                Concise Observation: The parent strategy focused on price-volume convexity and institutional gaps, but it ignored the 'noise-to-signal' ratio of the trend itself; market regimes often shift when the 'energy' of price swings exceeds the 'order' of the directional path.\n                Concise Justification: A high standard deviation relative to a low R-squared indicates that price action is becoming erratic and 'fragile,' suggesting that the consensus driving the trend is dissolving, whereas a high R-squared with low volatility suggests a stable, institutional-led move.\n                Concise Knowledge: If price volatility increases while the linear strength of a trend (R-squared) diminishes, the current price movement is likely unsustainable and prone to a structural break; When volatility is low relative to trend stability, the trend is robust.\n                concise Specification: The factor is defined as TS_STD($close, 5) divided by the R-squared of $close against a time sequence over 10 days; high values predict trend exhaustion/reversal, while low values predict trend persistence.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T05:43:14.589399"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1849158787669921,
        "ICIR": 0.0163564914895835,
        "1day.excess_return_without_cost.std": 0.004067533810132,
        "1day.excess_return_with_cost.annualized_return": -0.0170189648831944,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001264287937155,
        "1day.excess_return_without_cost.annualized_return": 0.030090052904289,
        "1day.excess_return_with_cost.std": 0.0040690885949618,
        "Rank IC": 0.0136614121145102,
        "IC": 0.0021005862278118,
        "1day.excess_return_without_cost.max_drawdown": -0.1295122408916024,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4795162190381012,
        "1day.pa": 0.0,
        "l2.valid": 0.9968226712624446,
        "Rank ICIR": 0.1056611680815067,
        "l2.train": 0.9942063888525235,
        "1day.excess_return_with_cost.information_ratio": -0.271111236603433,
        "1day.excess_return_with_cost.mean": -7.150825581174153e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the ratio of volatility/dispersion to trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_10D, Robust_Trend_Signal_20D, and Cross_Sectional_Trend_Fragility) failed to outperform the SOTA result across all key metrics. The Information Ratio (0.479 vs 0.972) and IC (0.0021 vs 0.0057) suggest that the current signal-to-noise ratio of these factors is relatively weak. The Cross_Sectional_Trend_Fragility factor introduced more raw features ($high, $low) but did not yield the expected performance boost, suggesting that the core 'fragility' calculation might be too sensitive to outliers or requires a different normalization approach.",
        "hypothesis_evaluation": "The hypothesis that a high ratio of dispersion to linearity identifies reversals is partially supported by the fact that the factors generate positive excess returns, but the low IC indicates the relationship is not as robust as initially theorized. The 10-day R-squared denominator might be too unstable; when the correlation is near zero, the factor value explodes, creating extreme outliers that degrade model performance. The 'Robust' version using MAD and a 20-day window showed that extending the lookback period and using robust statistics is a valid direction, but it still lacks the predictive power of the SOTA.",
        "decision": false,
        "reason": "1. Stability: Using a bounded denominator (e.g., Trend Strength = ABS(CORR)) prevents extreme values that occur when R-squared is near zero. 2. Change Detection: Reversals are often preceded by a *sudden increase* in fragility rather than a sustained high level; therefore, a Z-score or a percentage change of the TFI over a 5-day window may capture the 'exhaustion' point more accurately. 3. Complexity Control: By keeping the feature count low and focusing on the mathematical transformation of the core ratio, we maintain a low Symbol Length and avoid over-engineering."
      }
    },
    "be813732c0247940": {
      "factor_id": "be813732c0247940",
      "factor_name": "Liquidity_Adjusted_Rebound_5D",
      "factor_expression": "REGRESI($close, $volume, 5) * (1.0 - RANK(TS_STD($volume, 5)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, $volume, 5) * (1.0 - RANK(TS_STD($volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Rebound_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies mean-reversion opportunities by calculating the residual of a 5-day regression of close price on volume, then weighting it by the inverse rank of volume volatility. A high negative residual combined with low volume volatility indicates an orderly price exhaustion likely to rebound.",
      "factor_formulation": "\\text{REGRESI}(\\text{close}, \\text{volume}, 5) * (1 - \\text{RANK}(\\text{TS\\_STD}(\\text{volume}, 5)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "69842786b42d",
        "parent_trajectory_ids": [
          "834df2df49dc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Rebound' factor, defined as the negative residual of a 5-day price-volume regression filtered by low volume volatility, identifies high-probability mean-reversion opportunities where price exhaustion occurs without chaotic liquidity withdrawal.\n                Concise Observation: While the parent strategy focused on intraday shadows and gaps, market reversals often depend on the stability of the volume profile during the preceding trend; high volume variance (VSTD) often signals 'noise' or 'panic' that invalidates simple price-action signals.\n                Concise Justification: RESI5 captures the deviation of price from its recent volume-weighted trend, while VSTD5 acts as a regime filter to ensure the signal is generated during 'quiet' liquidity conditions, increasing the signal-to-noise ratio for mean reversion.\n                Concise Knowledge: If a price decline is accompanied by stable volume (low VSTD), it suggests an orderly transfer of ownership rather than panic; when this occurs alongside deep negative price residuals, the probability of a technical rebound increases.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close on $volume, then multiplying it by the inverse rank of the 5-day standard deviation of volume (VSTD5) to penalize high-volatility environments.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T05:55:32.988351"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1720953765920612,
        "ICIR": 0.0312013337046408,
        "1day.excess_return_without_cost.std": 0.0048648320586839,
        "1day.excess_return_with_cost.annualized_return": -0.0146314166528842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001411815377149,
        "1day.excess_return_without_cost.annualized_return": 0.0336012059761615,
        "1day.excess_return_with_cost.std": 0.0048656509679572,
        "Rank IC": 0.0207749950678175,
        "IC": 0.0044690879940256,
        "1day.excess_return_without_cost.max_drawdown": -0.1223438988265343,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4477117928606026,
        "1day.pa": 0.0,
        "l2.valid": 0.9967486971684446,
        "Rank ICIR": 0.1473913248062582,
        "l2.train": 0.99297631065308,
        "1day.excess_return_with_cost.information_ratio": -0.1949202443352499,
        "1day.excess_return_with_cost.mean": -6.147654055833726e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity-Adjusted Rebound' hypothesis using different windows (5D, 10D) and mathematical structures (Regression residuals vs. Z-scores). While the factors were successfully implemented, the collective performance (IC: 0.004469, IR: 0.4477) significantly underperforms the SOTA (IC: 0.005798, IR: 0.9725). The high Max Drawdown (-0.122) compared to SOTA (-0.072) suggests that the current 'orderly exhaustion' filters are not sufficiently distinguishing between healthy mean-reversion and 'falling knives' or persistent low-volatility downtrends.",
        "hypothesis_evaluation": "The hypothesis that low volume volatility acts as a reliable filter for price exhaustion is partially supported but lacks precision. The 'Orderly_Decline_Reversion_Factor' using a binary threshold (0.33) might be too blunt, and the linear regression of price on volume in 'Liquidity_Adjusted_Rebound_5D' may be capturing simple trend strength rather than the 'exhaustion' intended. The deterioration in IR suggests the signal-to-noise ratio is currently too low.",
        "decision": false,
        "reason": "The current factors use raw volume volatility, which can occur in stagnant markets. By shifting to the deviation from Volume Weighted Average Price (VWAP) and scaling by the 'Relative Volume' (current volume vs. 20-day average), we can better isolate instances where price has moved too far on insufficient support. This maintains the 'Liquidity-Adjusted' core but uses more robust benchmarks for both price (VWAP) and liquidity (Relative Volume)."
      }
    },
    "6e8b7c2e92851a7d": {
      "factor_id": "6e8b7c2e92851a7d",
      "factor_name": "Stable_Volume_Price_Exhaustion_10D",
      "factor_expression": "RANK(REGRESI($return, $volume, 10)) / (RANK(TS_STD($volume, 10)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI(TS_PCTCHANGE($close, 1), $volume, 10)) / (1e-8 + RANK(TS_STD($volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Stable_Volume_Price_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the liquidity-adjusted rebound hypothesis focusing on a 10-day window. It measures the deviation of returns from their volume-weighted trend, scaled by the inverse of volume instability to filter out noise and panic selling.",
      "factor_formulation": "\\text{RANK}(\\text{REGRESI}(\\text{return}, \\text{volume}, 10)) / (\\text{RANK}(\\text{TS\\_STD}(\\text{volume}, 10)) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "69842786b42d",
        "parent_trajectory_ids": [
          "834df2df49dc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Rebound' factor, defined as the negative residual of a 5-day price-volume regression filtered by low volume volatility, identifies high-probability mean-reversion opportunities where price exhaustion occurs without chaotic liquidity withdrawal.\n                Concise Observation: While the parent strategy focused on intraday shadows and gaps, market reversals often depend on the stability of the volume profile during the preceding trend; high volume variance (VSTD) often signals 'noise' or 'panic' that invalidates simple price-action signals.\n                Concise Justification: RESI5 captures the deviation of price from its recent volume-weighted trend, while VSTD5 acts as a regime filter to ensure the signal is generated during 'quiet' liquidity conditions, increasing the signal-to-noise ratio for mean reversion.\n                Concise Knowledge: If a price decline is accompanied by stable volume (low VSTD), it suggests an orderly transfer of ownership rather than panic; when this occurs alongside deep negative price residuals, the probability of a technical rebound increases.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close on $volume, then multiplying it by the inverse rank of the 5-day standard deviation of volume (VSTD5) to penalize high-volatility environments.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T05:55:32.988351"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1720953765920612,
        "ICIR": 0.0312013337046408,
        "1day.excess_return_without_cost.std": 0.0048648320586839,
        "1day.excess_return_with_cost.annualized_return": -0.0146314166528842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001411815377149,
        "1day.excess_return_without_cost.annualized_return": 0.0336012059761615,
        "1day.excess_return_with_cost.std": 0.0048656509679572,
        "Rank IC": 0.0207749950678175,
        "IC": 0.0044690879940256,
        "1day.excess_return_without_cost.max_drawdown": -0.1223438988265343,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4477117928606026,
        "1day.pa": 0.0,
        "l2.valid": 0.9967486971684446,
        "Rank ICIR": 0.1473913248062582,
        "l2.train": 0.99297631065308,
        "1day.excess_return_with_cost.information_ratio": -0.1949202443352499,
        "1day.excess_return_with_cost.mean": -6.147654055833726e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity-Adjusted Rebound' hypothesis using different windows (5D, 10D) and mathematical structures (Regression residuals vs. Z-scores). While the factors were successfully implemented, the collective performance (IC: 0.004469, IR: 0.4477) significantly underperforms the SOTA (IC: 0.005798, IR: 0.9725). The high Max Drawdown (-0.122) compared to SOTA (-0.072) suggests that the current 'orderly exhaustion' filters are not sufficiently distinguishing between healthy mean-reversion and 'falling knives' or persistent low-volatility downtrends.",
        "hypothesis_evaluation": "The hypothesis that low volume volatility acts as a reliable filter for price exhaustion is partially supported but lacks precision. The 'Orderly_Decline_Reversion_Factor' using a binary threshold (0.33) might be too blunt, and the linear regression of price on volume in 'Liquidity_Adjusted_Rebound_5D' may be capturing simple trend strength rather than the 'exhaustion' intended. The deterioration in IR suggests the signal-to-noise ratio is currently too low.",
        "decision": false,
        "reason": "The current factors use raw volume volatility, which can occur in stagnant markets. By shifting to the deviation from Volume Weighted Average Price (VWAP) and scaling by the 'Relative Volume' (current volume vs. 20-day average), we can better isolate instances where price has moved too far on insufficient support. This maintains the 'Liquidity-Adjusted' core but uses more robust benchmarks for both price (VWAP) and liquidity (Relative Volume)."
      }
    },
    "50907e5aa74d9f13": {
      "factor_id": "50907e5aa74d9f13",
      "factor_name": "Orderly_Decline_Reversion_Factor",
      "factor_expression": "-(TS_ZSCORE($close, 5)) * (RANK(TS_STD($volume, 5)) < 0.33 ? 1.0 : 0.0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-(TS_ZSCORE($close, 5)) * (RANK(TS_STD($volume, 5)) < 0.33 ? 1.0 : 0.0)\" # Your output factor expression will be filled in here\n    name = \"Orderly_Decline_Reversion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'Orderly Transfer' concept by looking for cases where the price is significantly below its 5-day average (negative Z-score) while volume volatility is in the lowest tercile, suggesting non-chaotic price exhaustion.",
      "factor_formulation": "-\\text{TS\\_ZSCORE}(\\text{close}, 5) * (\\text{RANK}(\\text{TS\\_STD}(\\text{volume}, 5)) < 0.33 ? 1 : 0)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "69842786b42d",
        "parent_trajectory_ids": [
          "834df2df49dc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Adjusted Rebound' factor, defined as the negative residual of a 5-day price-volume regression filtered by low volume volatility, identifies high-probability mean-reversion opportunities where price exhaustion occurs without chaotic liquidity withdrawal.\n                Concise Observation: While the parent strategy focused on intraday shadows and gaps, market reversals often depend on the stability of the volume profile during the preceding trend; high volume variance (VSTD) often signals 'noise' or 'panic' that invalidates simple price-action signals.\n                Concise Justification: RESI5 captures the deviation of price from its recent volume-weighted trend, while VSTD5 acts as a regime filter to ensure the signal is generated during 'quiet' liquidity conditions, increasing the signal-to-noise ratio for mean reversion.\n                Concise Knowledge: If a price decline is accompanied by stable volume (low VSTD), it suggests an orderly transfer of ownership rather than panic; when this occurs alongside deep negative price residuals, the probability of a technical rebound increases.\n                concise Specification: The factor is calculated by taking the residual of a 5-day linear regression of $close on $volume, then multiplying it by the inverse rank of the 5-day standard deviation of volume (VSTD5) to penalize high-volatility environments.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T05:55:32.988351"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1720953765920612,
        "ICIR": 0.0312013337046408,
        "1day.excess_return_without_cost.std": 0.0048648320586839,
        "1day.excess_return_with_cost.annualized_return": -0.0146314166528842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001411815377149,
        "1day.excess_return_without_cost.annualized_return": 0.0336012059761615,
        "1day.excess_return_with_cost.std": 0.0048656509679572,
        "Rank IC": 0.0207749950678175,
        "IC": 0.0044690879940256,
        "1day.excess_return_without_cost.max_drawdown": -0.1223438988265343,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4477117928606026,
        "1day.pa": 0.0,
        "l2.valid": 0.9967486971684446,
        "Rank ICIR": 0.1473913248062582,
        "l2.train": 0.99297631065308,
        "1day.excess_return_with_cost.information_ratio": -0.1949202443352499,
        "1day.excess_return_with_cost.mean": -6.147654055833726e-05
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Liquidity-Adjusted Rebound' hypothesis using different windows (5D, 10D) and mathematical structures (Regression residuals vs. Z-scores). While the factors were successfully implemented, the collective performance (IC: 0.004469, IR: 0.4477) significantly underperforms the SOTA (IC: 0.005798, IR: 0.9725). The high Max Drawdown (-0.122) compared to SOTA (-0.072) suggests that the current 'orderly exhaustion' filters are not sufficiently distinguishing between healthy mean-reversion and 'falling knives' or persistent low-volatility downtrends.",
        "hypothesis_evaluation": "The hypothesis that low volume volatility acts as a reliable filter for price exhaustion is partially supported but lacks precision. The 'Orderly_Decline_Reversion_Factor' using a binary threshold (0.33) might be too blunt, and the linear regression of price on volume in 'Liquidity_Adjusted_Rebound_5D' may be capturing simple trend strength rather than the 'exhaustion' intended. The deterioration in IR suggests the signal-to-noise ratio is currently too low.",
        "decision": false,
        "reason": "The current factors use raw volume volatility, which can occur in stagnant markets. By shifting to the deviation from Volume Weighted Average Price (VWAP) and scaling by the 'Relative Volume' (current volume vs. 20-day average), we can better isolate instances where price has moved too far on insufficient support. This maintains the 'Liquidity-Adjusted' core but uses more robust benchmarks for both price (VWAP) and liquidity (Relative Volume)."
      }
    },
    "2c3bc84638006fee": {
      "factor_id": "2c3bc84638006fee",
      "factor_name": "Intraday_Compression_Breakout_20D",
      "factor_expression": "$return / ((($high - $low) / ($close + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 1) / ((($high - $low) / ($close + 1e-8) + 1e-8) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Compression_Breakout_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the ratio of price movement intensity to intraday range compression. It uses the daily return as a proxy for breakout direction and magnitude, normalized by the intraday range relative to 20-day volatility. High values suggest a strong directional move relative to a tight price channel.",
      "factor_formulation": "\\text{ICB}_{20D} = \\frac{\\text{return}}{\\frac{(\\text{high} - \\text{low}) / \\text{close}}{\\text{TS\\_STD}(\\text{return}, 20)}}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "6eec8f66c883",
        "parent_trajectory_ids": [
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Compression-Breakout' factor, defined as the ratio of late-session volume intensity to the day's price range normalized by 20-day volatility, predicts that price breakouts following periods of intraday compression are driven by institutional conviction and lead to multi-day trend persistence.\n                Concise Observation: While the parent strategy focused on overnight gap reversals and liquidity exhaustion, market data suggests that low intraday volatility (tight high-low range) often precedes explosive moves when accompanied by significant late-day volume participation.\n                Concise Justification: Intraday price compression represents a state of equilibrium or 'coiling'; a surge in volume during the final session indicates institutional repositioning that overcomes this equilibrium, signaling a high-conviction breakout that typically carries over into subsequent days.\n                Concise Knowledge: If a stock's intraday range is narrow relative to its historical volatility (compression) while volume concentrates in the final trading hour (late-session imbalance), then the resulting price direction is more likely to persist as a structural trend rather than a mean-reverting noise.\n                concise Specification: The factor is calculated as (Last Hour Volume / Total Daily Volume) divided by ((High - Low) / Close / ATR_20D). High values indicate high-conviction breakouts from tight ranges, while low values indicate aimless volatility or low-conviction trading.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T06:01:44.336577"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0969020149008347,
        "ICIR": 0.0511100672463702,
        "1day.excess_return_without_cost.std": 0.0043168528602969,
        "1day.excess_return_with_cost.annualized_return": 0.0103233561138843,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002405021454377,
        "1day.excess_return_without_cost.annualized_return": 0.0572395106141823,
        "1day.excess_return_with_cost.std": 0.0043175284180423,
        "Rank IC": 0.0229860436999911,
        "IC": 0.0069767094157484,
        "1day.excess_return_without_cost.max_drawdown": -0.0889608553406053,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.859488732072847,
        "1day.pa": 0.0,
        "l2.valid": 0.9963866572458152,
        "Rank ICIR": 0.169727915651973,
        "l2.train": 0.9933586199061692,
        "1day.excess_return_with_cost.information_ratio": 0.1549876972346362,
        "1day.excess_return_with_cost.mean": 4.337544585665691e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Compression-Breakout' hypothesis by testing three distinct implementations: a direct ratio of return to normalized range (ICB_20D), a volume-efficiency rank (VRE_10D), and a sign-based relative compression measure (RCS_15D). The combined result shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0070 and an increase in Annualized Return from 0.052 to 0.057. However, the Information Ratio (IR) decreased slightly, and the Max Drawdown worsened, suggesting that while the signal strength (IC) is higher, the volatility of the excess returns has also increased.",
        "hypothesis_evaluation": "The hypothesis that price breakouts following compression lead to trend persistence is supported by the improved IC and Annualized Return. Specifically, the 'RCS_15D' and 'ICB_20D' formulations likely contributed to capturing the directional conviction. The 'VRE_10D' factor's use of volume rank suggests that adding a liquidity/intensity dimension helps filter for institutional activity, though the increased drawdown indicates these breakouts might be subject to higher 'fake-out' risks or higher volatility.",
        "decision": true,
        "reason": "The current results show higher returns but also higher risk (drawdown). By refining the 'Volume' component to look for 'Volume Volatility Compression' (the 'quiet before the storm') and ensuring the breakout occurs on a significant volume spike relative to the compression period, we can likely filter out low-conviction noise and improve the Information Ratio and Max Drawdown."
      }
    },
    "8e8b8ce62850fa9c": {
      "factor_id": "8e8b8ce62850fa9c",
      "factor_name": "Volume_Range_Efficiency_Rank_10D",
      "factor_expression": "RANK($volume / (TS_MEAN($volume, 10) + 1e-8)) * RANK(TS_STD($return, 10) / (($high - $low) / ($close + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($volume / (TS_MEAN($volume, 10) + 1e-8)) * RANK(TS_STD(TS_PCTCHANGE($close, 1), 10) / (($high - $low) / ($close + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Range_Efficiency_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'coiling' effect by identifying days where volume is high but the price range is narrow relative to historical volatility. It ranks the efficiency of volume in moving the price range. A high rank indicates that the stock is experiencing high-volume consolidation, often a precursor to a trend breakout.",
      "factor_formulation": "\\text{VRE}_{10D} = \\text{RANK}\\left(\\frac{\\$volume}{\\text{TS\\_MEAN}(\\$volume, 10)}\\right) * \\text{RANK}\\left(\\frac{\\text{TS\\_STD}(\\$return, 10)}{(\\$high - \\$low)/\\$close}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "6eec8f66c883",
        "parent_trajectory_ids": [
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Compression-Breakout' factor, defined as the ratio of late-session volume intensity to the day's price range normalized by 20-day volatility, predicts that price breakouts following periods of intraday compression are driven by institutional conviction and lead to multi-day trend persistence.\n                Concise Observation: While the parent strategy focused on overnight gap reversals and liquidity exhaustion, market data suggests that low intraday volatility (tight high-low range) often precedes explosive moves when accompanied by significant late-day volume participation.\n                Concise Justification: Intraday price compression represents a state of equilibrium or 'coiling'; a surge in volume during the final session indicates institutional repositioning that overcomes this equilibrium, signaling a high-conviction breakout that typically carries over into subsequent days.\n                Concise Knowledge: If a stock's intraday range is narrow relative to its historical volatility (compression) while volume concentrates in the final trading hour (late-session imbalance), then the resulting price direction is more likely to persist as a structural trend rather than a mean-reverting noise.\n                concise Specification: The factor is calculated as (Last Hour Volume / Total Daily Volume) divided by ((High - Low) / Close / ATR_20D). High values indicate high-conviction breakouts from tight ranges, while low values indicate aimless volatility or low-conviction trading.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T06:01:44.336577"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0969020149008347,
        "ICIR": 0.0511100672463702,
        "1day.excess_return_without_cost.std": 0.0043168528602969,
        "1day.excess_return_with_cost.annualized_return": 0.0103233561138843,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002405021454377,
        "1day.excess_return_without_cost.annualized_return": 0.0572395106141823,
        "1day.excess_return_with_cost.std": 0.0043175284180423,
        "Rank IC": 0.0229860436999911,
        "IC": 0.0069767094157484,
        "1day.excess_return_without_cost.max_drawdown": -0.0889608553406053,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.859488732072847,
        "1day.pa": 0.0,
        "l2.valid": 0.9963866572458152,
        "Rank ICIR": 0.169727915651973,
        "l2.train": 0.9933586199061692,
        "1day.excess_return_with_cost.information_ratio": 0.1549876972346362,
        "1day.excess_return_with_cost.mean": 4.337544585665691e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Compression-Breakout' hypothesis by testing three distinct implementations: a direct ratio of return to normalized range (ICB_20D), a volume-efficiency rank (VRE_10D), and a sign-based relative compression measure (RCS_15D). The combined result shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0070 and an increase in Annualized Return from 0.052 to 0.057. However, the Information Ratio (IR) decreased slightly, and the Max Drawdown worsened, suggesting that while the signal strength (IC) is higher, the volatility of the excess returns has also increased.",
        "hypothesis_evaluation": "The hypothesis that price breakouts following compression lead to trend persistence is supported by the improved IC and Annualized Return. Specifically, the 'RCS_15D' and 'ICB_20D' formulations likely contributed to capturing the directional conviction. The 'VRE_10D' factor's use of volume rank suggests that adding a liquidity/intensity dimension helps filter for institutional activity, though the increased drawdown indicates these breakouts might be subject to higher 'fake-out' risks or higher volatility.",
        "decision": true,
        "reason": "The current results show higher returns but also higher risk (drawdown). By refining the 'Volume' component to look for 'Volume Volatility Compression' (the 'quiet before the storm') and ensuring the breakout occurs on a significant volume spike relative to the compression period, we can likely filter out low-conviction noise and improve the Information Ratio and Max Drawdown."
      }
    },
    "9b38466a17c63e06": {
      "factor_id": "9b38466a17c63e06",
      "factor_name": "Relative_Compression_Strength_15D",
      "factor_expression": "SIGN($return) * (1 - TS_RANK(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_PCTCHANGE($close, 1)) * (1 - TS_RANK(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Strength_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the current intraday range relative to its 15-day historical distribution. A low value indicates extreme price compression. When combined with a directional return, it signals the start of a trend from a state of equilibrium.",
      "factor_formulation": "\\text{RCS}_{15D} = \\text{SIGN}(\\$return) * (1 - \\text{TS\\_RANK}((\\text{high} - \\text{low})/\\text{close}, 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "6eec8f66c883",
        "parent_trajectory_ids": [
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Compression-Breakout' factor, defined as the ratio of late-session volume intensity to the day's price range normalized by 20-day volatility, predicts that price breakouts following periods of intraday compression are driven by institutional conviction and lead to multi-day trend persistence.\n                Concise Observation: While the parent strategy focused on overnight gap reversals and liquidity exhaustion, market data suggests that low intraday volatility (tight high-low range) often precedes explosive moves when accompanied by significant late-day volume participation.\n                Concise Justification: Intraday price compression represents a state of equilibrium or 'coiling'; a surge in volume during the final session indicates institutional repositioning that overcomes this equilibrium, signaling a high-conviction breakout that typically carries over into subsequent days.\n                Concise Knowledge: If a stock's intraday range is narrow relative to its historical volatility (compression) while volume concentrates in the final trading hour (late-session imbalance), then the resulting price direction is more likely to persist as a structural trend rather than a mean-reverting noise.\n                concise Specification: The factor is calculated as (Last Hour Volume / Total Daily Volume) divided by ((High - Low) / Close / ATR_20D). High values indicate high-conviction breakouts from tight ranges, while low values indicate aimless volatility or low-conviction trading.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T06:01:44.336577"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0969020149008347,
        "ICIR": 0.0511100672463702,
        "1day.excess_return_without_cost.std": 0.0043168528602969,
        "1day.excess_return_with_cost.annualized_return": 0.0103233561138843,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002405021454377,
        "1day.excess_return_without_cost.annualized_return": 0.0572395106141823,
        "1day.excess_return_with_cost.std": 0.0043175284180423,
        "Rank IC": 0.0229860436999911,
        "IC": 0.0069767094157484,
        "1day.excess_return_without_cost.max_drawdown": -0.0889608553406053,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.859488732072847,
        "1day.pa": 0.0,
        "l2.valid": 0.9963866572458152,
        "Rank ICIR": 0.169727915651973,
        "l2.train": 0.9933586199061692,
        "1day.excess_return_with_cost.information_ratio": 0.1549876972346362,
        "1day.excess_return_with_cost.mean": 4.337544585665691e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Compression-Breakout' hypothesis by testing three distinct implementations: a direct ratio of return to normalized range (ICB_20D), a volume-efficiency rank (VRE_10D), and a sign-based relative compression measure (RCS_15D). The combined result shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0070 and an increase in Annualized Return from 0.052 to 0.057. However, the Information Ratio (IR) decreased slightly, and the Max Drawdown worsened, suggesting that while the signal strength (IC) is higher, the volatility of the excess returns has also increased.",
        "hypothesis_evaluation": "The hypothesis that price breakouts following compression lead to trend persistence is supported by the improved IC and Annualized Return. Specifically, the 'RCS_15D' and 'ICB_20D' formulations likely contributed to capturing the directional conviction. The 'VRE_10D' factor's use of volume rank suggests that adding a liquidity/intensity dimension helps filter for institutional activity, though the increased drawdown indicates these breakouts might be subject to higher 'fake-out' risks or higher volatility.",
        "decision": true,
        "reason": "The current results show higher returns but also higher risk (drawdown). By refining the 'Volume' component to look for 'Volume Volatility Compression' (the 'quiet before the storm') and ensuring the breakout occurs on a significant volume spike relative to the compression period, we can likely filter out low-conviction noise and improve the Information Ratio and Max Drawdown."
      }
    },
    "70992e224849158f": {
      "factor_id": "70992e224849158f",
      "factor_name": "IMRF_Fragility_Ratio_5D",
      "factor_expression": "ZSCORE(TS_MEAN($high - $low, 5) / (ABS($open - DELAY($close, 1)) + 1e-8)) * TS_STD($volume, 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($high - $low, 5) / (ABS($open - DELAY($close, 1)) + 1e-8)) * TS_STD($volume, 20)\" # Your output factor expression will be filled in here\n    name = \"IMRF_Fragility_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'Intraday Mean-Reversion Fragility' by calculating the ratio of the 5-day average intraday range to the absolute overnight gap. A high ratio suggests that price action is dominated by intraday noise rather than the conviction shown in the overnight gap, leading to potential reversals. It is penalized by the 20-day volatility of volume to filter for liquidity exhaustion.",
      "factor_formulation": "IMRF = ZSCORE(\\frac{TS\\_MEAN(high - low, 5)}{ABS(open - DELAY(close, 1)) + 1e-8}) * TS\\_STD(volume, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "410d3eb0aaf5",
        "parent_trajectory_ids": [
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Mean-Reversion Fragility' (IMRF) factor predicts negative future returns by identifying stocks where the intraday price range significantly decouples from the overnight gap, indicating retail-driven noise and liquidity exhaustion rather than institutional conviction.\n                Concise Observation: The parent strategy (IMEI) successfully used overnight gaps as conviction signals, but failed to account for cases where excessive intraday volatility (High-Low range) washes out the signal, suggesting a regime shift from trend-following to mean-reversion.\n                Concise Justification: Institutional investors typically minimize market impact, leading to tighter intraday ranges relative to the trend; conversely, retail-dominated 'noise' creates wide price swings that lack the capital depth to sustain the direction, leading to a reversal.\n                Concise Knowledge: If the intraday range-to-gap ratio is high and coupled with extreme price dispersion, the move is likely noise-driven; when liquidity is provided by noise traders rather than institutional flow, price tends to mean-revert.\n                concise Specification: The factor is defined as the Z-scored ratio of the 5-day average Intraday Range ($high - $low) to the absolute Overnight Gap (abs($open - delay($close, 1))), penalized by the 20-day volatility of volume.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T06:07:02.988031"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1480298373015452,
        "ICIR": 0.0383631223901779,
        "1day.excess_return_without_cost.std": 0.0042481310476016,
        "1day.excess_return_with_cost.annualized_return": -0.0096612847825443,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001586457298363,
        "1day.excess_return_without_cost.annualized_return": 0.0377576837010516,
        "1day.excess_return_with_cost.std": 0.0042493151955549,
        "Rank IC": 0.0215396706457665,
        "IC": 0.0053389648054194,
        "1day.excess_return_without_cost.max_drawdown": -0.1055294797194848,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.576127970005634,
        "1day.pa": 0.0,
        "l2.valid": 0.9966818727365728,
        "Rank ICIR": 0.1589922220875123,
        "l2.train": 0.993560364859464,
        "1day.excess_return_with_cost.information_ratio": -0.1473762355142323,
        "1day.excess_return_with_cost.mean": -4.059363354010224e-05
      },
      "feedback": {
        "observations": "The current iteration exploring 'Intraday Mean-Reversion Fragility' (IMRF) shows that while the core concept of decoupling intraday range from overnight gaps has predictive power (IC 0.0053), it currently underperforms the SOTA across all key metrics. Specifically, the Information Ratio (0.576 vs 0.972) and Max Drawdown (-0.105 vs -0.072) indicate that the current implementations are significantly more volatile and less risk-adjusted than the existing benchmark. The use of volume volatility as a penalty term appears to add noise or over-complicate the signal rather than effectively filtering for liquidity exhaustion.",
        "hypothesis_evaluation": "The hypothesis that decoupling intraday range from overnight gaps predicts reversals is partially supported by the positive IC, but the 'fragility' aspect via volume-based penalization seems suboptimal. The current factors (IMRF_Fragility_Ratio_5D and IMRF_Dispersion_Penalized_20D) use a product of two distinct concepts (range ratio and volume std), which might be creating an unstable interaction. The 10-day TS_ZSCORE approach also failed to capture the regime shift more effectively than the SOTA.",
        "decision": false,
        "reason": "The previous results suggest that multiplying the range ratio by volume volatility (TS_STD) increases the factor's variance and drawdown. By shifting to a 'Range Exhaustion' framework, we focus on the pure price action anomaly. Using a RANK-based normalization of the ratio (High-Low)/(Abs(Gap)) and then applying a simple 5-day or 10-day mean will likely produce a more stable signal. This addresses the complexity issue by reducing the number of base features and focusing on the most robust part of the original hypothesis."
      }
    },
    "ed70d97fb83c2915": {
      "factor_id": "ed70d97fb83c2915",
      "factor_name": "IMRF_Dispersion_Penalized_20D",
      "factor_expression": "RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD($volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8)) * RANK(TS_STD($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"IMRF_Dispersion_Penalized_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the Fragility factor that focuses on the decoupling of intraday volatility from gap conviction. It uses the 20-day volume volatility as a proxy for noise-driven exhaustion. When intraday swings are large relative to the structural gap and volume is highly unstable, the stock is likely experiencing retail-driven noise prone to mean-reversion.",
      "factor_formulation": "IMRF\\_Disp = RANK(\\frac{high - low}{ABS(open - DELAY(close, 1)) + 1e-8}) * RANK(TS\\_STD(volume, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "410d3eb0aaf5",
        "parent_trajectory_ids": [
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Mean-Reversion Fragility' (IMRF) factor predicts negative future returns by identifying stocks where the intraday price range significantly decouples from the overnight gap, indicating retail-driven noise and liquidity exhaustion rather than institutional conviction.\n                Concise Observation: The parent strategy (IMEI) successfully used overnight gaps as conviction signals, but failed to account for cases where excessive intraday volatility (High-Low range) washes out the signal, suggesting a regime shift from trend-following to mean-reversion.\n                Concise Justification: Institutional investors typically minimize market impact, leading to tighter intraday ranges relative to the trend; conversely, retail-dominated 'noise' creates wide price swings that lack the capital depth to sustain the direction, leading to a reversal.\n                Concise Knowledge: If the intraday range-to-gap ratio is high and coupled with extreme price dispersion, the move is likely noise-driven; when liquidity is provided by noise traders rather than institutional flow, price tends to mean-revert.\n                concise Specification: The factor is defined as the Z-scored ratio of the 5-day average Intraday Range ($high - $low) to the absolute Overnight Gap (abs($open - delay($close, 1))), penalized by the 20-day volatility of volume.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T06:07:02.988031"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1480298373015452,
        "ICIR": 0.0383631223901779,
        "1day.excess_return_without_cost.std": 0.0042481310476016,
        "1day.excess_return_with_cost.annualized_return": -0.0096612847825443,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001586457298363,
        "1day.excess_return_without_cost.annualized_return": 0.0377576837010516,
        "1day.excess_return_with_cost.std": 0.0042493151955549,
        "Rank IC": 0.0215396706457665,
        "IC": 0.0053389648054194,
        "1day.excess_return_without_cost.max_drawdown": -0.1055294797194848,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.576127970005634,
        "1day.pa": 0.0,
        "l2.valid": 0.9966818727365728,
        "Rank ICIR": 0.1589922220875123,
        "l2.train": 0.993560364859464,
        "1day.excess_return_with_cost.information_ratio": -0.1473762355142323,
        "1day.excess_return_with_cost.mean": -4.059363354010224e-05
      },
      "feedback": {
        "observations": "The current iteration exploring 'Intraday Mean-Reversion Fragility' (IMRF) shows that while the core concept of decoupling intraday range from overnight gaps has predictive power (IC 0.0053), it currently underperforms the SOTA across all key metrics. Specifically, the Information Ratio (0.576 vs 0.972) and Max Drawdown (-0.105 vs -0.072) indicate that the current implementations are significantly more volatile and less risk-adjusted than the existing benchmark. The use of volume volatility as a penalty term appears to add noise or over-complicate the signal rather than effectively filtering for liquidity exhaustion.",
        "hypothesis_evaluation": "The hypothesis that decoupling intraday range from overnight gaps predicts reversals is partially supported by the positive IC, but the 'fragility' aspect via volume-based penalization seems suboptimal. The current factors (IMRF_Fragility_Ratio_5D and IMRF_Dispersion_Penalized_20D) use a product of two distinct concepts (range ratio and volume std), which might be creating an unstable interaction. The 10-day TS_ZSCORE approach also failed to capture the regime shift more effectively than the SOTA.",
        "decision": false,
        "reason": "The previous results suggest that multiplying the range ratio by volume volatility (TS_STD) increases the factor's variance and drawdown. By shifting to a 'Range Exhaustion' framework, we focus on the pure price action anomaly. Using a RANK-based normalization of the ratio (High-Low)/(Abs(Gap)) and then applying a simple 5-day or 10-day mean will likely produce a more stable signal. This addresses the complexity issue by reducing the number of base features and focusing on the most robust part of the original hypothesis."
      }
    },
    "4c82ae429632f113": {
      "factor_id": "4c82ae429632f113",
      "factor_name": "Intraday_Noise_Reversal_10D",
      "factor_expression": "TS_ZSCORE(($high - $low) / (ABS($open - DELAY($close, 1)) + 1e-8), 10) * TS_STD($volume, 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / MAX(ABS($open - DELAY($close, 1)), 0.001), 10) * TS_STD($volume, 10)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Noise_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the regime shift from trend-following to mean-reversion by identifying stocks where the intraday range significantly exceeds the typical gap size over a 10-day window, standardized by volume instability. High values indicate liquidity exhaustion by noise traders.",
      "factor_formulation": "INR = TS\\_ZSCORE(\\frac{high - low}{ABS(open - DELAY(close, 1)) + 1e-8}, 10) * TS\\_STD(volume, 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "410d3eb0aaf5",
        "parent_trajectory_ids": [
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Mean-Reversion Fragility' (IMRF) factor predicts negative future returns by identifying stocks where the intraday price range significantly decouples from the overnight gap, indicating retail-driven noise and liquidity exhaustion rather than institutional conviction.\n                Concise Observation: The parent strategy (IMEI) successfully used overnight gaps as conviction signals, but failed to account for cases where excessive intraday volatility (High-Low range) washes out the signal, suggesting a regime shift from trend-following to mean-reversion.\n                Concise Justification: Institutional investors typically minimize market impact, leading to tighter intraday ranges relative to the trend; conversely, retail-dominated 'noise' creates wide price swings that lack the capital depth to sustain the direction, leading to a reversal.\n                Concise Knowledge: If the intraday range-to-gap ratio is high and coupled with extreme price dispersion, the move is likely noise-driven; when liquidity is provided by noise traders rather than institutional flow, price tends to mean-revert.\n                concise Specification: The factor is defined as the Z-scored ratio of the 5-day average Intraday Range ($high - $low) to the absolute Overnight Gap (abs($open - delay($close, 1))), penalized by the 20-day volatility of volume.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T06:07:02.988031"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1480298373015452,
        "ICIR": 0.0383631223901779,
        "1day.excess_return_without_cost.std": 0.0042481310476016,
        "1day.excess_return_with_cost.annualized_return": -0.0096612847825443,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001586457298363,
        "1day.excess_return_without_cost.annualized_return": 0.0377576837010516,
        "1day.excess_return_with_cost.std": 0.0042493151955549,
        "Rank IC": 0.0215396706457665,
        "IC": 0.0053389648054194,
        "1day.excess_return_without_cost.max_drawdown": -0.1055294797194848,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.576127970005634,
        "1day.pa": 0.0,
        "l2.valid": 0.9966818727365728,
        "Rank ICIR": 0.1589922220875123,
        "l2.train": 0.993560364859464,
        "1day.excess_return_with_cost.information_ratio": -0.1473762355142323,
        "1day.excess_return_with_cost.mean": -4.059363354010224e-05
      },
      "feedback": {
        "observations": "The current iteration exploring 'Intraday Mean-Reversion Fragility' (IMRF) shows that while the core concept of decoupling intraday range from overnight gaps has predictive power (IC 0.0053), it currently underperforms the SOTA across all key metrics. Specifically, the Information Ratio (0.576 vs 0.972) and Max Drawdown (-0.105 vs -0.072) indicate that the current implementations are significantly more volatile and less risk-adjusted than the existing benchmark. The use of volume volatility as a penalty term appears to add noise or over-complicate the signal rather than effectively filtering for liquidity exhaustion.",
        "hypothesis_evaluation": "The hypothesis that decoupling intraday range from overnight gaps predicts reversals is partially supported by the positive IC, but the 'fragility' aspect via volume-based penalization seems suboptimal. The current factors (IMRF_Fragility_Ratio_5D and IMRF_Dispersion_Penalized_20D) use a product of two distinct concepts (range ratio and volume std), which might be creating an unstable interaction. The 10-day TS_ZSCORE approach also failed to capture the regime shift more effectively than the SOTA.",
        "decision": false,
        "reason": "The previous results suggest that multiplying the range ratio by volume volatility (TS_STD) increases the factor's variance and drawdown. By shifting to a 'Range Exhaustion' framework, we focus on the pure price action anomaly. Using a RANK-based normalization of the ratio (High-Low)/(Abs(Gap)) and then applying a simple 5-day or 10-day mean will likely produce a more stable signal. This addresses the complexity issue by reducing the number of base features and focusing on the most robust part of the original hypothesis."
      }
    },
    "5805b8704fe7de25": {
      "factor_id": "5805b8704fe7de25",
      "factor_name": "Intraday_Exhaustion_Skew_5D",
      "factor_expression": "RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8) * TS_MEAN($volume / (TS_STD($close, 5) + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8) * TS_MEAN($volume / (TS_STD($close, 5) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_Skew_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies price exhaustion by measuring the distance between the close and the daily price midpoint, normalized by the daily range and scaled by the 5-day moving average of volume-weighted volatility. It targets mean-reversion where price extremes lack volume support.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}\\left( \\frac{$close - ($high + $low) / 2}{$high - $low + 1e-8} \\times \\text{TS_MEAN}\\left(\\frac{$volume}{\\text{TS_STD}($close, 5) + 1e-8}, 5\\right) \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f202527d2da5",
        "parent_trajectory_ids": [
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Exhaustion' factor, defined by the divergence between the close price and the daily price center weighted by volume skewness, identifies mean-reversion opportunities where price extremes lack structural volume support.\n                Concise Observation: Parent strategies focused on multi-day trend linearity (R-squared) often fail during intraday blow-off tops or capitulation bottoms where price moves independently of volume density.\n                Concise Justification: Market efficiency suggests that prices should gravitate towards levels with the highest liquidity (volume density); significant deviations from this 'fair value' on thin volume indicate exhaustion of the current move and a high probability of mean reversion.\n                Concise Knowledge: If a price extreme is achieved with low volume concentration (high volume skewness), the move is likely a 'hollow' liquidity gap; when the distance between the close and the daily mean price is maximized under low-volume tail conditions, a reversal is imminent.\n                concise Specification: The factor calculates the ratio of the distance between ($close - ($high+$low)/2) to the daily range ($high-$low), scaled by a 5-day moving average of volume-weighted volatility, specifically targeting stocks where the close is at an extreme but volume is concentrated at the opposite end of the daily range.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T06:09:54.661347"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1148679011060151,
        "ICIR": 0.0191821678571851,
        "1day.excess_return_without_cost.std": 0.00481309753073,
        "1day.excess_return_with_cost.annualized_return": 0.0082872907863059,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002352362680794,
        "1day.excess_return_without_cost.annualized_return": 0.0559862318029002,
        "1day.excess_return_with_cost.std": 0.0048143351423451,
        "Rank IC": 0.0169518231950435,
        "IC": 0.00282514780245,
        "1day.excess_return_without_cost.max_drawdown": -0.0940445514266728,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7539943599852704,
        "1day.pa": 0.0,
        "l2.valid": 0.996514616957805,
        "Rank ICIR": 0.1178578377102711,
        "l2.train": 0.9937304283268564,
        "1day.excess_return_with_cost.information_ratio": 0.1115803654505524,
        "1day.excess_return_with_cost.mean": 3.482054952229388e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Volume-Price Exhaustion' through three distinct implementations: a 5-day skew-based approach, a 10-day hollow-price reversal, and a 20-day volume density deviation. The results show a slight improvement in annualized return (0.0560 vs 0.0520) but a significant deterioration in risk-adjusted metrics, specifically the Information Ratio (0.754 vs 0.973) and IC (0.0028 vs 0.0058). The Max Drawdown also worsened, suggesting that while the exhaustion signals capture some alpha, they introduce higher volatility and less consistent predictive power compared to the SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes lacking volume support identify mean-reversion opportunities is partially supported by the positive annualized return. However, the low IC and IR suggest that the current mathematical formulations—particularly the 'Intraday_Exhaustion_Skew_5D' and 'Volume_Density_Deviation_20D'—might be too noisy. The use of raw volume in the numerator or denominator without proper normalization against long-term averages likely causes the factor to be dominated by high-volume outliers rather than 'hollow' price moves.",
        "decision": true,
        "reason": "To improve the signal-to-noise ratio, we should move away from absolute volume/price ratios and toward relative measures. By comparing the current day's 'Price Range per Unit of Volume' to its 20-day historical distribution, we can more accurately identify 'exhaustion' events. The previous factors used 5-day and 10-day windows which might be too short to establish a stable 'normal' volume baseline. Extending the lookback and using a rank-based comparison of price-volume efficiency should yield more robust results."
      }
    },
    "fbc57cfae1f7294a": {
      "factor_id": "fbc57cfae1f7294a",
      "factor_name": "Hollow_Price_Reversal_10D",
      "factor_expression": "RANK(TS_ZSCORE(($close - $low) / ($high - $low + 1e-8), 10)) * RANK(INV($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(($close - $low) / ($high - $low + 1e-8), 10)) * RANK(INV($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Price_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures 'hollow' price moves by comparing the current day's price position within its range against the historical volume-price efficiency. A high value suggests the close is at an extreme relative to the volume density, signaling a potential reversal.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}(\\text{TS_ZSCORE}(($close - $low) / ($high - $low + 1e-8), 10)) * \\text{RANK}(\\text{INV}($volume))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f202527d2da5",
        "parent_trajectory_ids": [
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Exhaustion' factor, defined by the divergence between the close price and the daily price center weighted by volume skewness, identifies mean-reversion opportunities where price extremes lack structural volume support.\n                Concise Observation: Parent strategies focused on multi-day trend linearity (R-squared) often fail during intraday blow-off tops or capitulation bottoms where price moves independently of volume density.\n                Concise Justification: Market efficiency suggests that prices should gravitate towards levels with the highest liquidity (volume density); significant deviations from this 'fair value' on thin volume indicate exhaustion of the current move and a high probability of mean reversion.\n                Concise Knowledge: If a price extreme is achieved with low volume concentration (high volume skewness), the move is likely a 'hollow' liquidity gap; when the distance between the close and the daily mean price is maximized under low-volume tail conditions, a reversal is imminent.\n                concise Specification: The factor calculates the ratio of the distance between ($close - ($high+$low)/2) to the daily range ($high-$low), scaled by a 5-day moving average of volume-weighted volatility, specifically targeting stocks where the close is at an extreme but volume is concentrated at the opposite end of the daily range.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T06:09:54.661347"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1148679011060151,
        "ICIR": 0.0191821678571851,
        "1day.excess_return_without_cost.std": 0.00481309753073,
        "1day.excess_return_with_cost.annualized_return": 0.0082872907863059,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002352362680794,
        "1day.excess_return_without_cost.annualized_return": 0.0559862318029002,
        "1day.excess_return_with_cost.std": 0.0048143351423451,
        "Rank IC": 0.0169518231950435,
        "IC": 0.00282514780245,
        "1day.excess_return_without_cost.max_drawdown": -0.0940445514266728,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7539943599852704,
        "1day.pa": 0.0,
        "l2.valid": 0.996514616957805,
        "Rank ICIR": 0.1178578377102711,
        "l2.train": 0.9937304283268564,
        "1day.excess_return_with_cost.information_ratio": 0.1115803654505524,
        "1day.excess_return_with_cost.mean": 3.482054952229388e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Volume-Price Exhaustion' through three distinct implementations: a 5-day skew-based approach, a 10-day hollow-price reversal, and a 20-day volume density deviation. The results show a slight improvement in annualized return (0.0560 vs 0.0520) but a significant deterioration in risk-adjusted metrics, specifically the Information Ratio (0.754 vs 0.973) and IC (0.0028 vs 0.0058). The Max Drawdown also worsened, suggesting that while the exhaustion signals capture some alpha, they introduce higher volatility and less consistent predictive power compared to the SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes lacking volume support identify mean-reversion opportunities is partially supported by the positive annualized return. However, the low IC and IR suggest that the current mathematical formulations—particularly the 'Intraday_Exhaustion_Skew_5D' and 'Volume_Density_Deviation_20D'—might be too noisy. The use of raw volume in the numerator or denominator without proper normalization against long-term averages likely causes the factor to be dominated by high-volume outliers rather than 'hollow' price moves.",
        "decision": true,
        "reason": "To improve the signal-to-noise ratio, we should move away from absolute volume/price ratios and toward relative measures. By comparing the current day's 'Price Range per Unit of Volume' to its 20-day historical distribution, we can more accurately identify 'exhaustion' events. The previous factors used 5-day and 10-day windows which might be too short to establish a stable 'normal' volume baseline. Extending the lookback and using a rank-based comparison of price-volume efficiency should yield more robust results."
      }
    },
    "472bd752da392eeb": {
      "factor_id": "472bd752da392eeb",
      "factor_name": "Volume_Density_Deviation_20D",
      "factor_expression": "ZSCORE(($close - TS_MEDIAN($close, 20)) / (TS_MEAN($volume / ($high - $low + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - TS_MEDIAN($close, 20)) / (TS_MEAN($volume / ($high - $low + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Density_Deviation_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the deviation of the closing price from the 20-day median price, weighted by the inverse of the volume-to-range ratio. High values indicate price has drifted far from 'fair value' on low volume density, suggesting exhaustion.",
      "factor_formulation": "\\text{Factor} = \\text{ZSCORE}\\left( \\frac{$close - \\text{TS_MEDIAN}($close, 20)}{\\text{TS_MEAN}($volume / ($high - $low + 1e-8), 5) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "f202527d2da5",
        "parent_trajectory_ids": [
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Volume-Price Exhaustion' factor, defined by the divergence between the close price and the daily price center weighted by volume skewness, identifies mean-reversion opportunities where price extremes lack structural volume support.\n                Concise Observation: Parent strategies focused on multi-day trend linearity (R-squared) often fail during intraday blow-off tops or capitulation bottoms where price moves independently of volume density.\n                Concise Justification: Market efficiency suggests that prices should gravitate towards levels with the highest liquidity (volume density); significant deviations from this 'fair value' on thin volume indicate exhaustion of the current move and a high probability of mean reversion.\n                Concise Knowledge: If a price extreme is achieved with low volume concentration (high volume skewness), the move is likely a 'hollow' liquidity gap; when the distance between the close and the daily mean price is maximized under low-volume tail conditions, a reversal is imminent.\n                concise Specification: The factor calculates the ratio of the distance between ($close - ($high+$low)/2) to the daily range ($high-$low), scaled by a 5-day moving average of volume-weighted volatility, specifically targeting stocks where the close is at an extreme but volume is concentrated at the opposite end of the daily range.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T06:09:54.661347"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1148679011060151,
        "ICIR": 0.0191821678571851,
        "1day.excess_return_without_cost.std": 0.00481309753073,
        "1day.excess_return_with_cost.annualized_return": 0.0082872907863059,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002352362680794,
        "1day.excess_return_without_cost.annualized_return": 0.0559862318029002,
        "1day.excess_return_with_cost.std": 0.0048143351423451,
        "Rank IC": 0.0169518231950435,
        "IC": 0.00282514780245,
        "1day.excess_return_without_cost.max_drawdown": -0.0940445514266728,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7539943599852704,
        "1day.pa": 0.0,
        "l2.valid": 0.996514616957805,
        "Rank ICIR": 0.1178578377102711,
        "l2.train": 0.9937304283268564,
        "1day.excess_return_with_cost.information_ratio": 0.1115803654505524,
        "1day.excess_return_with_cost.mean": 3.482054952229388e-05
      },
      "feedback": {
        "observations": "The current iteration focused on 'Intraday Volume-Price Exhaustion' through three distinct implementations: a 5-day skew-based approach, a 10-day hollow-price reversal, and a 20-day volume density deviation. The results show a slight improvement in annualized return (0.0560 vs 0.0520) but a significant deterioration in risk-adjusted metrics, specifically the Information Ratio (0.754 vs 0.973) and IC (0.0028 vs 0.0058). The Max Drawdown also worsened, suggesting that while the exhaustion signals capture some alpha, they introduce higher volatility and less consistent predictive power compared to the SOTA.",
        "hypothesis_evaluation": "The hypothesis that price extremes lacking volume support identify mean-reversion opportunities is partially supported by the positive annualized return. However, the low IC and IR suggest that the current mathematical formulations—particularly the 'Intraday_Exhaustion_Skew_5D' and 'Volume_Density_Deviation_20D'—might be too noisy. The use of raw volume in the numerator or denominator without proper normalization against long-term averages likely causes the factor to be dominated by high-volume outliers rather than 'hollow' price moves.",
        "decision": true,
        "reason": "To improve the signal-to-noise ratio, we should move away from absolute volume/price ratios and toward relative measures. By comparing the current day's 'Price Range per Unit of Volume' to its 20-day historical distribution, we can more accurately identify 'exhaustion' events. The previous factors used 5-day and 10-day windows which might be too short to establish a stable 'normal' volume baseline. Extending the lookback and using a rank-based comparison of price-volume efficiency should yield more robust results."
      }
    },
    "00a3be13d327fa71": {
      "factor_id": "00a3be13d327fa71",
      "factor_name": "VWAP_Exhaustion_Reversal_20D",
      "factor_expression": "ZSCORE(($close - ($high + $low + $close) / 3) / (($high + $low + $close) / 3 + 1e-8) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - ($high + $low + $close) / 3) / (($high + $low + $close) / 3 + 1e-8) * ($volume / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VWAP_Exhaustion_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies price exhaustion by measuring the deviation of the closing price from a proxy of the daily VWAP (approximated by the average of high, low, and close), scaled by the relative volume surge. High positive values indicate overbought conditions likely to mean-revert.",
      "factor_formulation": "\\text{ZSCORE}\\left( \\frac{\\text{close} - (\\text{high} + \\text{low} + \\text{close})/3}{(\\text{high} + \\text{low} + \\text{close})/3} \\times \\frac{\\text{volume}}{\\text{TS_MEAN}(\\text{volume}, 20)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "bd184224558c",
        "parent_trajectory_ids": [
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Price-VWAP Exhaustion' factor predicts mean-reversion by identifying stocks where the closing price significantly deviates from the daily Volume-Weighted Average Price (VWAP) while accompanied by an abnormal surge in late-session volume, signaling liquidity-driven price over-extension.\n                Concise Observation: The parent strategy's 5-10 day gap-continuity logic (RankIC 0.0218) captures multi-day momentum, but fails to account for intraday price distortions where high-volume 'climax' buying or selling at the close often leads to immediate price reversals.\n                Concise Justification: VWAP represents the fair value of a session's liquidity distribution; a large 'Close-to-VWAP' distance suggests that the price has moved faster than the volume-weighted consensus, creating a 'rubber-band' effect likely to snap back when the aggressive pressure subsides.\n                Concise Knowledge: If a stock's closing price deviates sharply from its daily VWAP during high-volume periods, it indicates aggressive order flow that temporarily exhausts liquidity; such imbalances typically mean-revert as market makers restore equilibrium in the subsequent session.\n                concise Specification: The factor is defined as the Z-score of the distance between $close and an estimated daily VWAP, multiplied by the ratio of current volume to its 20-day average. A high positive value (price far above VWAP on high volume) suggests a short signal, while a high negative value suggests a long signal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T06:13:19.012687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739818979719101,
        "ICIR": 0.0272984471960774,
        "1day.excess_return_without_cost.std": 0.0042196390708091,
        "1day.excess_return_with_cost.annualized_return": 0.0300942102163383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003235518141379,
        "1day.excess_return_without_cost.annualized_return": 0.077005331764838,
        "1day.excess_return_with_cost.std": 0.0042209546428914,
        "Rank IC": 0.020390477415826,
        "IC": 0.0037194662095988,
        "1day.excess_return_without_cost.max_drawdown": -0.0590589157243763,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1829244621570465,
        "1day.pa": 0.0,
        "l2.valid": 0.9962159569219158,
        "Rank ICIR": 0.1500454230325241,
        "l2.train": 0.994009682809852,
        "1day.excess_return_with_cost.information_ratio": 0.462150882204908,
        "1day.excess_return_with_cost.mean": 0.0001264462614131
      },
      "feedback": {
        "observations": "The current iteration focused on measuring price exhaustion through deviations from intraday typical price proxies (VWAP approximations) combined with volume surges. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and Annualized Return (increased from 5.2% to 7.7%), while also reducing the Max Drawdown from -0.072 to -0.059. Although the IC is slightly lower than the SOTA (0.0037 vs 0.0057), the strategy's ability to capture high-conviction reversal points has clearly improved, leading to better portfolio-level performance.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that 'Intraday Price-VWAP Exhaustion' can predict mean-reversion. Specifically, the 'Volume_Weighted_Price_Stretch_15D' and 'VWAP_Exhaustion_Reversal_20D' implementations suggest that scaling price deviation by volume intensity effectively filters for 'exhaustion' rather than 'trend strength'. The use of typical price (HLC/3) as a VWAP proxy appears to be a robust anchor for identifying over-extension.",
        "decision": true,
        "reason": "While current factors use raw price deviation or Z-scores, they don't account for the 'normal' volatility of the spread between price and VWAP. By normalizing the deviation using the standard deviation of (Close - VWAP) over a lookback period, we can better identify truly 'abnormal' stretching. Additionally, incorporating ATR ensures that the exhaustion signal is relative to the stock's specific volatility regime, potentially improving the IC which lagged in this iteration."
      }
    },
    "5c5260aed2542a2d": {
      "factor_id": "5c5260aed2542a2d",
      "factor_name": "Intraday_Climax_Deviation_10D",
      "factor_expression": "RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)) * RANK($volume / (TS_MAX($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)) * RANK($volume / (TS_MAX($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Intraday_Climax_Deviation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures liquidity-driven price over-extension by calculating the cross-sectional rank of the price deviation from the session median (High-Low-Close average), weighted by the volume intensity relative to its 10-day history.",
      "factor_formulation": "\\text{RANK}\\left( \\frac{\\text{close} - (\\text{high} + \\text{low})/2}{\\text{high} - \\text{low} + 1e-8} \\right) \\times \\text{RANK}\\left( \\frac{\\text{volume}}{\\text{TS_MAX}(\\text{volume}, 10)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "bd184224558c",
        "parent_trajectory_ids": [
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Price-VWAP Exhaustion' factor predicts mean-reversion by identifying stocks where the closing price significantly deviates from the daily Volume-Weighted Average Price (VWAP) while accompanied by an abnormal surge in late-session volume, signaling liquidity-driven price over-extension.\n                Concise Observation: The parent strategy's 5-10 day gap-continuity logic (RankIC 0.0218) captures multi-day momentum, but fails to account for intraday price distortions where high-volume 'climax' buying or selling at the close often leads to immediate price reversals.\n                Concise Justification: VWAP represents the fair value of a session's liquidity distribution; a large 'Close-to-VWAP' distance suggests that the price has moved faster than the volume-weighted consensus, creating a 'rubber-band' effect likely to snap back when the aggressive pressure subsides.\n                Concise Knowledge: If a stock's closing price deviates sharply from its daily VWAP during high-volume periods, it indicates aggressive order flow that temporarily exhausts liquidity; such imbalances typically mean-revert as market makers restore equilibrium in the subsequent session.\n                concise Specification: The factor is defined as the Z-score of the distance between $close and an estimated daily VWAP, multiplied by the ratio of current volume to its 20-day average. A high positive value (price far above VWAP on high volume) suggests a short signal, while a high negative value suggests a long signal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T06:13:19.012687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739818979719101,
        "ICIR": 0.0272984471960774,
        "1day.excess_return_without_cost.std": 0.0042196390708091,
        "1day.excess_return_with_cost.annualized_return": 0.0300942102163383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003235518141379,
        "1day.excess_return_without_cost.annualized_return": 0.077005331764838,
        "1day.excess_return_with_cost.std": 0.0042209546428914,
        "Rank IC": 0.020390477415826,
        "IC": 0.0037194662095988,
        "1day.excess_return_without_cost.max_drawdown": -0.0590589157243763,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1829244621570465,
        "1day.pa": 0.0,
        "l2.valid": 0.9962159569219158,
        "Rank ICIR": 0.1500454230325241,
        "l2.train": 0.994009682809852,
        "1day.excess_return_with_cost.information_ratio": 0.462150882204908,
        "1day.excess_return_with_cost.mean": 0.0001264462614131
      },
      "feedback": {
        "observations": "The current iteration focused on measuring price exhaustion through deviations from intraday typical price proxies (VWAP approximations) combined with volume surges. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and Annualized Return (increased from 5.2% to 7.7%), while also reducing the Max Drawdown from -0.072 to -0.059. Although the IC is slightly lower than the SOTA (0.0037 vs 0.0057), the strategy's ability to capture high-conviction reversal points has clearly improved, leading to better portfolio-level performance.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that 'Intraday Price-VWAP Exhaustion' can predict mean-reversion. Specifically, the 'Volume_Weighted_Price_Stretch_15D' and 'VWAP_Exhaustion_Reversal_20D' implementations suggest that scaling price deviation by volume intensity effectively filters for 'exhaustion' rather than 'trend strength'. The use of typical price (HLC/3) as a VWAP proxy appears to be a robust anchor for identifying over-extension.",
        "decision": true,
        "reason": "While current factors use raw price deviation or Z-scores, they don't account for the 'normal' volatility of the spread between price and VWAP. By normalizing the deviation using the standard deviation of (Close - VWAP) over a lookback period, we can better identify truly 'abnormal' stretching. Additionally, incorporating ATR ensures that the exhaustion signal is relative to the stock's specific volatility regime, potentially improving the IC which lagged in this iteration."
      }
    },
    "2f98e637c9557dff": {
      "factor_id": "2f98e637c9557dff",
      "factor_name": "Volume_Weighted_Price_Stretch_15D",
      "factor_expression": "ZSCORE(($close - ($high + $low + $close) / 3) / (TS_STD($close, 15) + 1e-8)) * TS_ZSCORE($volume, 15)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - ($high + $low + $close) / 3) / (TS_STD($close, 15) + 1e-8)) * TS_ZSCORE($volume, 15)\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Price_Stretch_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the 'rubber-band' effect by calculating the Z-score of the close-to-VWAP distance, where VWAP is estimated as the typical price, amplified by the volume's time-series Z-score to highlight exhaustion points.",
      "factor_formulation": "\\text{ZSCORE}\\left( \\frac{\\text{close} - (\\text{high} + \\text{low} + \\text{close})/3}{\\text{TS_STD}(\\text{close}, 15)} \\right) \\times \\text{TS_ZSCORE}(\\text{volume}, 15)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 5,
        "evolution_phase": "mutation",
        "trajectory_id": "bd184224558c",
        "parent_trajectory_ids": [
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Price-VWAP Exhaustion' factor predicts mean-reversion by identifying stocks where the closing price significantly deviates from the daily Volume-Weighted Average Price (VWAP) while accompanied by an abnormal surge in late-session volume, signaling liquidity-driven price over-extension.\n                Concise Observation: The parent strategy's 5-10 day gap-continuity logic (RankIC 0.0218) captures multi-day momentum, but fails to account for intraday price distortions where high-volume 'climax' buying or selling at the close often leads to immediate price reversals.\n                Concise Justification: VWAP represents the fair value of a session's liquidity distribution; a large 'Close-to-VWAP' distance suggests that the price has moved faster than the volume-weighted consensus, creating a 'rubber-band' effect likely to snap back when the aggressive pressure subsides.\n                Concise Knowledge: If a stock's closing price deviates sharply from its daily VWAP during high-volume periods, it indicates aggressive order flow that temporarily exhausts liquidity; such imbalances typically mean-revert as market makers restore equilibrium in the subsequent session.\n                concise Specification: The factor is defined as the Z-score of the distance between $close and an estimated daily VWAP, multiplied by the ratio of current volume to its 20-day average. A high positive value (price far above VWAP on high volume) suggests a short signal, while a high negative value suggests a long signal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T06:13:19.012687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0739818979719101,
        "ICIR": 0.0272984471960774,
        "1day.excess_return_without_cost.std": 0.0042196390708091,
        "1day.excess_return_with_cost.annualized_return": 0.0300942102163383,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003235518141379,
        "1day.excess_return_without_cost.annualized_return": 0.077005331764838,
        "1day.excess_return_with_cost.std": 0.0042209546428914,
        "Rank IC": 0.020390477415826,
        "IC": 0.0037194662095988,
        "1day.excess_return_without_cost.max_drawdown": -0.0590589157243763,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1829244621570465,
        "1day.pa": 0.0,
        "l2.valid": 0.9962159569219158,
        "Rank ICIR": 0.1500454230325241,
        "l2.train": 0.994009682809852,
        "1day.excess_return_with_cost.information_ratio": 0.462150882204908,
        "1day.excess_return_with_cost.mean": 0.0001264462614131
      },
      "feedback": {
        "observations": "The current iteration focused on measuring price exhaustion through deviations from intraday typical price proxies (VWAP approximations) combined with volume surges. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and Annualized Return (increased from 5.2% to 7.7%), while also reducing the Max Drawdown from -0.072 to -0.059. Although the IC is slightly lower than the SOTA (0.0037 vs 0.0057), the strategy's ability to capture high-conviction reversal points has clearly improved, leading to better portfolio-level performance.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that 'Intraday Price-VWAP Exhaustion' can predict mean-reversion. Specifically, the 'Volume_Weighted_Price_Stretch_15D' and 'VWAP_Exhaustion_Reversal_20D' implementations suggest that scaling price deviation by volume intensity effectively filters for 'exhaustion' rather than 'trend strength'. The use of typical price (HLC/3) as a VWAP proxy appears to be a robust anchor for identifying over-extension.",
        "decision": true,
        "reason": "While current factors use raw price deviation or Z-scores, they don't account for the 'normal' volatility of the spread between price and VWAP. By normalizing the deviation using the standard deviation of (Close - VWAP) over a lookback period, we can better identify truly 'abnormal' stretching. Additionally, incorporating ATR ensures that the exhaustion signal is relative to the stock's specific volatility regime, potentially improving the IC which lagged in this iteration."
      }
    },
    "70e8a4524ea98152": {
      "factor_id": "70e8a4524ea98152",
      "factor_name": "ICCG_Compression_Gap_Synergy",
      "factor_expression": "TS_MEAN((($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8)) * TS_CORR($close, SEQUENCE(10), 10), 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((($open / DELAY($close, 1) - 1) * TS_CORR($close, SEQUENCE(10), 10)), 5) * (TS_STD(TS_PCTCHANGE($close, 1), 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ICCG_Compression_Gap_Synergy\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional conviction by detecting overnight gaps that occur after a period of low-volatility compression. It combines the gap magnitude, the price linearity (measured by correlation with time), and a compression ratio (volatility vs. range) to highlight high-quality trend initiations.",
      "factor_formulation": "ICCG = \\text{TS_MEAN}\\left(\\frac{open - \\text{DELAY}(close, 1)}{\\text{DELAY}(close, 1)} \\times \\text{TS_CORR}(close, \\text{SEQUENCE}(10), 10), 5\\right) \\times \\frac{\\text{TS_STD}(return, 20) + 1e-8}{\\text{TS_MAX}(high, 5) - \\text{TS_MIN}(low, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "656b66d5e22e",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Conviction Compression-Gap' (ICCG) factor predicts that the highest quality returns follow overnight gaps that emerge from a 15-day low-volatility compression state, where the gap's institutional conviction is validated by a high synergy between the overnight jump and the 10-day price linearity.\n                Concise Observation: Parent 1 (RankIC=0.0230) showed that intraday compression precedes significant breakouts, while Parent 2 (RankIC=0.0230) demonstrated that overnight gaps coupled with trend linearity (synergy) are strong predictors of institutional flow.\n                Concise Justification: Combining compression with gap-trend synergy filters out 'exhaustion gaps' (which occur at high volatility) and 'speculative noise' (which lacks trend linearity), focusing instead on 'coiled' assets where institutional conviction triggers a low-resistance trend initiation.\n                Concise Knowledge: If a price breakout via an overnight gap occurs after a period of range compression (low volatility), it is more likely to represent a structural shift in institutional positioning rather than noise; when this gap is aligned with a linear price trend, the momentum is more sustainable.\n                concise Specification: Define ICCG as the product of (1) the 5-day average of (Overnight Gap * 10-day Price Linearity) and (2) a Compression Factor (20-day Volatility / 5-day Range), penalized by a 10-day volume-price convexity measure to avoid late-stage exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:31:15.041808"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0885796932006375,
        "ICIR": 0.0443091035388941,
        "1day.excess_return_without_cost.std": 0.0039561987896372,
        "1day.excess_return_with_cost.annualized_return": 0.0277769125145813,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000314912519629,
        "1day.excess_return_without_cost.annualized_return": 0.0749491796717027,
        "1day.excess_return_with_cost.std": 0.0039569221555321,
        "Rank IC": 0.0229274407857934,
        "IC": 0.0058246351507859,
        "1day.excess_return_without_cost.max_drawdown": -0.0786960514076617,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.228005464933501,
        "1day.pa": 0.0,
        "l2.valid": 0.9964054979421716,
        "Rank ICIR": 0.1799234462340459,
        "l2.train": 0.9933104059120548,
        "1day.excess_return_with_cost.information_ratio": 0.4550278578405051,
        "1day.excess_return_with_cost.mean": 0.0001167097164478
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Institutional Conviction Compression-Gap' (ICCG) framework. The current iteration significantly outperformed the previous SOTA in three out of four key metrics: Information Ratio (1.228 vs 0.972), Annualized Return (0.0749 vs 0.0520), and IC (0.005825 vs 0.005798). While the Max Drawdown slightly increased (-0.078 vs -0.072), the substantial gain in risk-adjusted return (IR) suggests a much stronger predictive signal. The 'Institutional_Coil_Breakout_Factor' and 'Gap_Linearity_Convexity_Filter' appear to have effectively isolated the structural shifts hypothesized, though the complexity of the ICCG_Compression_Gap_Synergy factor (using 5 base features and multiple nested TS functions) warrants monitoring.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that overnight gaps emerging from compression states, when validated by price linearity, predict high-quality returns. Specifically, the synergy between the gap magnitude and the 10-day price linearity (TS_CORR) proves to be a robust filter for institutional conviction. The inclusion of volume-price convexity (GLCF) also suggests that penalizing 'heavy' volume moves helps in avoiding late-stage trend exhaustion.",
        "decision": true,
        "reason": "While the current results are strong, the ICCG_Compression_Gap_Synergy factor is becoming complex. By focusing on 'Relative Volatility Tightness' (e.g., ATR(5)/ATR(20)), we can capture the 'coil' effect more cleanly with fewer parameters. Additionally, institutional conviction is often most visible in the volume transacted at the open; therefore, scaling the gap by the opening volume rank should filter out low-liquidity noise gaps that currently might be diluting the signal."
      }
    },
    "b363196b7e9d51e3": {
      "factor_id": "b363196b7e9d51e3",
      "factor_name": "Institutional_Coil_Breakout_Factor",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_STD($return, 15) + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_STD($close / DELAY($close, 1) - 1, 15) + 1e-8)) * RANK(TS_CORR($close, SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Coil_Breakout_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the ICCG hypothesis focusing on the 'coiled' state. It measures the ratio of the overnight gap to the recent 15-day volatility, scaled by the 10-day price trend linearity to filter for structural shifts rather than noise.",
      "factor_formulation": "ICBF = \\text{RANK}\\left(\\frac{open - \\text{DELAY}(close, 1)}{\\text{TS_STD}(return, 15) + 1e-8}\\right) \\times \\text{RANK}(\\text{TS_CORR}(close, \\text{SEQUENCE}(10), 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "656b66d5e22e",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Conviction Compression-Gap' (ICCG) factor predicts that the highest quality returns follow overnight gaps that emerge from a 15-day low-volatility compression state, where the gap's institutional conviction is validated by a high synergy between the overnight jump and the 10-day price linearity.\n                Concise Observation: Parent 1 (RankIC=0.0230) showed that intraday compression precedes significant breakouts, while Parent 2 (RankIC=0.0230) demonstrated that overnight gaps coupled with trend linearity (synergy) are strong predictors of institutional flow.\n                Concise Justification: Combining compression with gap-trend synergy filters out 'exhaustion gaps' (which occur at high volatility) and 'speculative noise' (which lacks trend linearity), focusing instead on 'coiled' assets where institutional conviction triggers a low-resistance trend initiation.\n                Concise Knowledge: If a price breakout via an overnight gap occurs after a period of range compression (low volatility), it is more likely to represent a structural shift in institutional positioning rather than noise; when this gap is aligned with a linear price trend, the momentum is more sustainable.\n                concise Specification: Define ICCG as the product of (1) the 5-day average of (Overnight Gap * 10-day Price Linearity) and (2) a Compression Factor (20-day Volatility / 5-day Range), penalized by a 10-day volume-price convexity measure to avoid late-stage exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:31:15.041808"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0885796932006375,
        "ICIR": 0.0443091035388941,
        "1day.excess_return_without_cost.std": 0.0039561987896372,
        "1day.excess_return_with_cost.annualized_return": 0.0277769125145813,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000314912519629,
        "1day.excess_return_without_cost.annualized_return": 0.0749491796717027,
        "1day.excess_return_with_cost.std": 0.0039569221555321,
        "Rank IC": 0.0229274407857934,
        "IC": 0.0058246351507859,
        "1day.excess_return_without_cost.max_drawdown": -0.0786960514076617,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.228005464933501,
        "1day.pa": 0.0,
        "l2.valid": 0.9964054979421716,
        "Rank ICIR": 0.1799234462340459,
        "l2.train": 0.9933104059120548,
        "1day.excess_return_with_cost.information_ratio": 0.4550278578405051,
        "1day.excess_return_with_cost.mean": 0.0001167097164478
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Institutional Conviction Compression-Gap' (ICCG) framework. The current iteration significantly outperformed the previous SOTA in three out of four key metrics: Information Ratio (1.228 vs 0.972), Annualized Return (0.0749 vs 0.0520), and IC (0.005825 vs 0.005798). While the Max Drawdown slightly increased (-0.078 vs -0.072), the substantial gain in risk-adjusted return (IR) suggests a much stronger predictive signal. The 'Institutional_Coil_Breakout_Factor' and 'Gap_Linearity_Convexity_Filter' appear to have effectively isolated the structural shifts hypothesized, though the complexity of the ICCG_Compression_Gap_Synergy factor (using 5 base features and multiple nested TS functions) warrants monitoring.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that overnight gaps emerging from compression states, when validated by price linearity, predict high-quality returns. Specifically, the synergy between the gap magnitude and the 10-day price linearity (TS_CORR) proves to be a robust filter for institutional conviction. The inclusion of volume-price convexity (GLCF) also suggests that penalizing 'heavy' volume moves helps in avoiding late-stage trend exhaustion.",
        "decision": true,
        "reason": "While the current results are strong, the ICCG_Compression_Gap_Synergy factor is becoming complex. By focusing on 'Relative Volatility Tightness' (e.g., ATR(5)/ATR(20)), we can capture the 'coil' effect more cleanly with fewer parameters. Additionally, institutional conviction is often most visible in the volume transacted at the open; therefore, scaling the gap by the opening volume rank should filter out low-liquidity noise gaps that currently might be diluting the signal."
      }
    },
    "3548a08d29141808": {
      "factor_id": "3548a08d29141808",
      "factor_name": "Gap_Linearity_Convexity_Filter",
      "factor_expression": "(($open / DELAY($close, 1) - 1) * TS_CORR($close, SEQUENCE(10), 10)) / (ABS(REGBETA($volume, $close, 10)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1) - 1) * TS_CORR($close, SEQUENCE(10), 10)) / (ABS(REGBETA($volume, $close, 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Gap_Linearity_Convexity_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets the synergy between overnight gaps and price linearity while penalizing volume-price convexity to avoid late-stage exhaustion. It uses the regression of volume on price to identify if the current move is becoming 'heavy' (high volume without price progress).",
      "factor_formulation": "GLCF = \\frac{(open / \\text{DELAY}(close, 1) - 1) \\times \\text{TS_CORR}(close, \\text{SEQUENCE}(10), 10)}{\\text{ABS}(\\text{REGBETA}(volume, close, 10)) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "656b66d5e22e",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Conviction Compression-Gap' (ICCG) factor predicts that the highest quality returns follow overnight gaps that emerge from a 15-day low-volatility compression state, where the gap's institutional conviction is validated by a high synergy between the overnight jump and the 10-day price linearity.\n                Concise Observation: Parent 1 (RankIC=0.0230) showed that intraday compression precedes significant breakouts, while Parent 2 (RankIC=0.0230) demonstrated that overnight gaps coupled with trend linearity (synergy) are strong predictors of institutional flow.\n                Concise Justification: Combining compression with gap-trend synergy filters out 'exhaustion gaps' (which occur at high volatility) and 'speculative noise' (which lacks trend linearity), focusing instead on 'coiled' assets where institutional conviction triggers a low-resistance trend initiation.\n                Concise Knowledge: If a price breakout via an overnight gap occurs after a period of range compression (low volatility), it is more likely to represent a structural shift in institutional positioning rather than noise; when this gap is aligned with a linear price trend, the momentum is more sustainable.\n                concise Specification: Define ICCG as the product of (1) the 5-day average of (Overnight Gap * 10-day Price Linearity) and (2) a Compression Factor (20-day Volatility / 5-day Range), penalized by a 10-day volume-price convexity measure to avoid late-stage exhaustion.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:31:15.041808"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0885796932006375,
        "ICIR": 0.0443091035388941,
        "1day.excess_return_without_cost.std": 0.0039561987896372,
        "1day.excess_return_with_cost.annualized_return": 0.0277769125145813,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000314912519629,
        "1day.excess_return_without_cost.annualized_return": 0.0749491796717027,
        "1day.excess_return_with_cost.std": 0.0039569221555321,
        "Rank IC": 0.0229274407857934,
        "IC": 0.0058246351507859,
        "1day.excess_return_without_cost.max_drawdown": -0.0786960514076617,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.228005464933501,
        "1day.pa": 0.0,
        "l2.valid": 0.9964054979421716,
        "Rank ICIR": 0.1799234462340459,
        "l2.train": 0.9933104059120548,
        "1day.excess_return_with_cost.information_ratio": 0.4550278578405051,
        "1day.excess_return_with_cost.mean": 0.0001167097164478
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Institutional Conviction Compression-Gap' (ICCG) framework. The current iteration significantly outperformed the previous SOTA in three out of four key metrics: Information Ratio (1.228 vs 0.972), Annualized Return (0.0749 vs 0.0520), and IC (0.005825 vs 0.005798). While the Max Drawdown slightly increased (-0.078 vs -0.072), the substantial gain in risk-adjusted return (IR) suggests a much stronger predictive signal. The 'Institutional_Coil_Breakout_Factor' and 'Gap_Linearity_Convexity_Filter' appear to have effectively isolated the structural shifts hypothesized, though the complexity of the ICCG_Compression_Gap_Synergy factor (using 5 base features and multiple nested TS functions) warrants monitoring.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that overnight gaps emerging from compression states, when validated by price linearity, predict high-quality returns. Specifically, the synergy between the gap magnitude and the 10-day price linearity (TS_CORR) proves to be a robust filter for institutional conviction. The inclusion of volume-price convexity (GLCF) also suggests that penalizing 'heavy' volume moves helps in avoiding late-stage trend exhaustion.",
        "decision": true,
        "reason": "While the current results are strong, the ICCG_Compression_Gap_Synergy factor is becoming complex. By focusing on 'Relative Volatility Tightness' (e.g., ATR(5)/ATR(20)), we can capture the 'coil' effect more cleanly with fewer parameters. Additionally, institutional conviction is often most visible in the volume transacted at the open; therefore, scaling the gap by the opening volume rank should filter out low-liquidity noise gaps that currently might be diluting the signal."
      }
    },
    "5065abb9d6409f34": {
      "factor_id": "5065abb9d6409f34",
      "factor_name": "SELV_Structural_Exhaustion_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN((ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (ABS($return) / ($volume + 1e-6) + 1e-8), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN((ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)) / (ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-6)), 5)\" # Your output factor expression will be filled in here\n    name = \"SELV_Structural_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies overextended price trends prone to reversal by combining price linearity (R-squared) with a liquidity-adjusted overnight gap. High linearity coupled with high illiquidity in overnight moves suggests a 'blow-off' exhaustion where the trend lacks sustainable volume support.",
      "factor_formulation": "SELV = \\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{TS_MEAN}\\left(\\frac{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / (\\text{high} - \\text{low} + 1e-6)}{\\text{ABS}(\\text{return}) / (\\text{volume} + 1e-6)}, 5\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "a6f74b3e3f71",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion and Liquidity Validation' (SELV) factor, calculated as the product of the 10-day price-time R-squared and the 5-day average ratio of the overnight gap to Amihud illiquidity, identifies overextended price trends that lack liquidity support and are prone to reversal.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies rigid price structures through R-squared but lacks volume context, while Parent 2 (RankIC 0.0238) captures sentiment via overnight gaps but lacks a structural trend filter.\n                Concise Justification: Linear trends represent a state of market consensus that becomes fragile when the 'marginal' price setter (overnight gap) requires increasingly less volume to move the price, signaling a 'blow-off' top or bottom rather than a sustainable shift.\n                Concise Knowledge: If a price trend exhibits high mathematical linearity (R-squared) while its recent price gaps occur under low liquidity conditions (high Amihud illiquidity), then the trend is likely exhausted; conversely, high-linearity moves supported by high liquidity suggest structural continuation.\n                concise Specification: The factor is defined as (10-day R-squared of $close vs. time) * (5-day mean of [abs($open - $close.shift(1)) / ($high - $low + 1e-6)] / [abs($close / $close.shift(1) - 1) / ($volume + 1e-6)]). High values indicate high-conviction exhaustion signals.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:54:25.484791"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1414150630035798,
        "ICIR": 0.0237097520313309,
        "1day.excess_return_without_cost.std": 0.0044968406673809,
        "1day.excess_return_with_cost.annualized_return": -0.015993970824379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001320682636608,
        "1day.excess_return_without_cost.annualized_return": 0.0314322467512754,
        "1day.excess_return_with_cost.std": 0.0044981714776555,
        "Rank IC": 0.0203380218308409,
        "IC": 0.0033567527697395,
        "1day.excess_return_without_cost.max_drawdown": -0.0950319381426461,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4530847519588359,
        "1day.pa": 0.0,
        "l2.valid": 0.9966661189272517,
        "Rank ICIR": 0.1497543430691238,
        "l2.train": 0.9938640048661884,
        "1day.excess_return_with_cost.information_ratio": -0.2304792401589487,
        "1day.excess_return_with_cost.mean": -6.720155808562625e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Structural Exhaustion and Liquidity Validation' (SELV) hypothesis. While the theoretical framework of combining price linearity (R-squared) with liquidity-based exhaustion (Amihud-like ratios) is sound, the current implementations failed to surpass the SOTA result. The primary factor, SELV_Structural_Exhaustion_10D, achieved an Information Ratio of 0.453 and an IC of 0.0033, which are significantly lower than the SOTA values (IR: 0.972, IC: 0.0058). The complexity of the formulation in the first factor (SELV) is high, involving multiple nested functions and divisions, which may have led to noise sensitivity rather than capturing a robust signal.",
        "hypothesis_evaluation": "The hypothesis that overextended trends lack liquidity support is partially supported by the positive IC, but the specific mathematical formulation is likely too noisy. The 'Overnight Gap / Amihud' ratio in the denominator of the first factor creates extreme values that might destabilize the signal. The simplified version (LVTL) using cross-sectional ranks showed that the interaction between linearity and liquidity is directional, but the current weighting scheme is suboptimal. The results suggest that 'structural exhaustion' is better captured by looking at the divergence between volume and price persistence rather than a direct product of complex ratios.",
        "decision": false,
        "reason": "The previous iteration's failure suggests that the direct ratio of gap-to-illiquidity is too volatile. By shifting to a correlation-based measure (TS_CORR of price change and volume), we can more stably capture whether a trend is being 'fueled' by liquidity or is merely drifting on low volume. Using RANK to normalize these components before multiplication will reduce the impact of outliers and address the complexity issues seen in the SELV formulation. We will also reduce the number of base features to improve generalization."
      }
    },
    "a0d458b98f1e0870": {
      "factor_id": "a0d458b98f1e0870",
      "factor_name": "Liquidity_Validated_Trend_Linearity",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(ABS($return) / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Trend_Linearity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the SELV hypothesis focusing on the cross-sectional rank of trend linearity weighted by the inverse of volume-adjusted volatility. It targets stocks where the price path is highly deterministic but the liquidity (volume relative to price movement) is thinning, signaling potential structural fragility.",
      "factor_formulation": "LVTL = \\text{RANK}(\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)) \\times \\text{RANK}(\\text{ABS}(\\text{return}) / (\\text{volume} + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "a6f74b3e3f71",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion and Liquidity Validation' (SELV) factor, calculated as the product of the 10-day price-time R-squared and the 5-day average ratio of the overnight gap to Amihud illiquidity, identifies overextended price trends that lack liquidity support and are prone to reversal.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies rigid price structures through R-squared but lacks volume context, while Parent 2 (RankIC 0.0238) captures sentiment via overnight gaps but lacks a structural trend filter.\n                Concise Justification: Linear trends represent a state of market consensus that becomes fragile when the 'marginal' price setter (overnight gap) requires increasingly less volume to move the price, signaling a 'blow-off' top or bottom rather than a sustainable shift.\n                Concise Knowledge: If a price trend exhibits high mathematical linearity (R-squared) while its recent price gaps occur under low liquidity conditions (high Amihud illiquidity), then the trend is likely exhausted; conversely, high-linearity moves supported by high liquidity suggest structural continuation.\n                concise Specification: The factor is defined as (10-day R-squared of $close vs. time) * (5-day mean of [abs($open - $close.shift(1)) / ($high - $low + 1e-6)] / [abs($close / $close.shift(1) - 1) / ($volume + 1e-6)]). High values indicate high-conviction exhaustion signals.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:54:25.484791"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1414150630035798,
        "ICIR": 0.0237097520313309,
        "1day.excess_return_without_cost.std": 0.0044968406673809,
        "1day.excess_return_with_cost.annualized_return": -0.015993970824379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001320682636608,
        "1day.excess_return_without_cost.annualized_return": 0.0314322467512754,
        "1day.excess_return_with_cost.std": 0.0044981714776555,
        "Rank IC": 0.0203380218308409,
        "IC": 0.0033567527697395,
        "1day.excess_return_without_cost.max_drawdown": -0.0950319381426461,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4530847519588359,
        "1day.pa": 0.0,
        "l2.valid": 0.9966661189272517,
        "Rank ICIR": 0.1497543430691238,
        "l2.train": 0.9938640048661884,
        "1day.excess_return_with_cost.information_ratio": -0.2304792401589487,
        "1day.excess_return_with_cost.mean": -6.720155808562625e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Structural Exhaustion and Liquidity Validation' (SELV) hypothesis. While the theoretical framework of combining price linearity (R-squared) with liquidity-based exhaustion (Amihud-like ratios) is sound, the current implementations failed to surpass the SOTA result. The primary factor, SELV_Structural_Exhaustion_10D, achieved an Information Ratio of 0.453 and an IC of 0.0033, which are significantly lower than the SOTA values (IR: 0.972, IC: 0.0058). The complexity of the formulation in the first factor (SELV) is high, involving multiple nested functions and divisions, which may have led to noise sensitivity rather than capturing a robust signal.",
        "hypothesis_evaluation": "The hypothesis that overextended trends lack liquidity support is partially supported by the positive IC, but the specific mathematical formulation is likely too noisy. The 'Overnight Gap / Amihud' ratio in the denominator of the first factor creates extreme values that might destabilize the signal. The simplified version (LVTL) using cross-sectional ranks showed that the interaction between linearity and liquidity is directional, but the current weighting scheme is suboptimal. The results suggest that 'structural exhaustion' is better captured by looking at the divergence between volume and price persistence rather than a direct product of complex ratios.",
        "decision": false,
        "reason": "The previous iteration's failure suggests that the direct ratio of gap-to-illiquidity is too volatile. By shifting to a correlation-based measure (TS_CORR of price change and volume), we can more stably capture whether a trend is being 'fueled' by liquidity or is merely drifting on low volume. Using RANK to normalize these components before multiplication will reduce the impact of outliers and address the complexity issues seen in the SELV formulation. We will also reduce the number of base features to improve generalization."
      }
    },
    "fa3da035092f3230": {
      "factor_id": "fa3da035092f3230",
      "factor_name": "Overnight_Gap_Illiquidity_Exhaustion",
      "factor_expression": "TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6), 5) / (TS_MEAN(ABS($return) / ($volume + 1e-6), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6), 5) / (TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) + 1e-8)) * TS_CORR($close, SEQUENCE(10), 10)\" # Your output factor expression will be filled in here\n    name = \"Overnight_Gap_Illiquidity_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the intensity of overnight price gaps relative to the intraday range, normalized by the Amihud illiquidity measure. It identifies periods where price gaps are large but liquidity is low, which, when combined with a consistent 10-day trend, indicates exhaustion.",
      "factor_formulation": "OGIE = \\text{TS_MEAN}(\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / (\\text{high} - \\text{low} + 1e-6), 5) / (\\text{TS_MEAN}(\\text{ABS}(\\text{return}) / (\\text{volume} + 1e-6), 5) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "a6f74b3e3f71",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion and Liquidity Validation' (SELV) factor, calculated as the product of the 10-day price-time R-squared and the 5-day average ratio of the overnight gap to Amihud illiquidity, identifies overextended price trends that lack liquidity support and are prone to reversal.\n                Concise Observation: Parent 1 (RankIC 0.0219) identifies rigid price structures through R-squared but lacks volume context, while Parent 2 (RankIC 0.0238) captures sentiment via overnight gaps but lacks a structural trend filter.\n                Concise Justification: Linear trends represent a state of market consensus that becomes fragile when the 'marginal' price setter (overnight gap) requires increasingly less volume to move the price, signaling a 'blow-off' top or bottom rather than a sustainable shift.\n                Concise Knowledge: If a price trend exhibits high mathematical linearity (R-squared) while its recent price gaps occur under low liquidity conditions (high Amihud illiquidity), then the trend is likely exhausted; conversely, high-linearity moves supported by high liquidity suggest structural continuation.\n                concise Specification: The factor is defined as (10-day R-squared of $close vs. time) * (5-day mean of [abs($open - $close.shift(1)) / ($high - $low + 1e-6)] / [abs($close / $close.shift(1) - 1) / ($volume + 1e-6)]). High values indicate high-conviction exhaustion signals.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:54:25.484791"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1414150630035798,
        "ICIR": 0.0237097520313309,
        "1day.excess_return_without_cost.std": 0.0044968406673809,
        "1day.excess_return_with_cost.annualized_return": -0.015993970824379,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001320682636608,
        "1day.excess_return_without_cost.annualized_return": 0.0314322467512754,
        "1day.excess_return_with_cost.std": 0.0044981714776555,
        "Rank IC": 0.0203380218308409,
        "IC": 0.0033567527697395,
        "1day.excess_return_without_cost.max_drawdown": -0.0950319381426461,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4530847519588359,
        "1day.pa": 0.0,
        "l2.valid": 0.9966661189272517,
        "Rank ICIR": 0.1497543430691238,
        "l2.train": 0.9938640048661884,
        "1day.excess_return_with_cost.information_ratio": -0.2304792401589487,
        "1day.excess_return_with_cost.mean": -6.720155808562625e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Structural Exhaustion and Liquidity Validation' (SELV) hypothesis. While the theoretical framework of combining price linearity (R-squared) with liquidity-based exhaustion (Amihud-like ratios) is sound, the current implementations failed to surpass the SOTA result. The primary factor, SELV_Structural_Exhaustion_10D, achieved an Information Ratio of 0.453 and an IC of 0.0033, which are significantly lower than the SOTA values (IR: 0.972, IC: 0.0058). The complexity of the formulation in the first factor (SELV) is high, involving multiple nested functions and divisions, which may have led to noise sensitivity rather than capturing a robust signal.",
        "hypothesis_evaluation": "The hypothesis that overextended trends lack liquidity support is partially supported by the positive IC, but the specific mathematical formulation is likely too noisy. The 'Overnight Gap / Amihud' ratio in the denominator of the first factor creates extreme values that might destabilize the signal. The simplified version (LVTL) using cross-sectional ranks showed that the interaction between linearity and liquidity is directional, but the current weighting scheme is suboptimal. The results suggest that 'structural exhaustion' is better captured by looking at the divergence between volume and price persistence rather than a direct product of complex ratios.",
        "decision": false,
        "reason": "The previous iteration's failure suggests that the direct ratio of gap-to-illiquidity is too volatile. By shifting to a correlation-based measure (TS_CORR of price change and volume), we can more stably capture whether a trend is being 'fueled' by liquidity or is merely drifting on low volume. Using RANK to normalize these components before multiplication will reduce the impact of outliers and address the complexity issues seen in the SELV formulation. We will also reduce the number of base features to improve generalization."
      }
    },
    "8d544709b04e858f": {
      "factor_id": "8d544709b04e858f",
      "factor_name": "Institutional_Absorption_Efficiency_5D",
      "factor_expression": "(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) / (TS_STD($volume, 5) + 1e-8)) * (($open - DELAY($close, 1)) / (DELAY($high, 1) - DELAY($low, 1) + 1e-8) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) / (TS_STD($volume, 5) + 1e-8)) * (($open - DELAY($close, 1)) / (DELAY($high, 1) - DELAY($low, 1) + 1e-8) / (TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction price reversals by combining institutional absorption (lower shadows in low-volatility environments) with sentiment efficiency (overnight gaps relative to Amihud illiquidity). It targets stocks where structural support meets efficient momentum.",
      "factor_formulation": "\\text{Factor} = \\frac{\\text{TS\\_MEAN}(\\frac{\\min(\\text{open, close}) - \\text{low}}{\\text{high} - \\text{low} + 1e-8}, 5)}{\\text{TS\\_STD}(\\text{volume}, 5) + 1e-8} \\times \\frac{(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / (\\text{DELAY}(\\text{high}, 1) - \\text{DELAY}(\\text{low}, 1) + 1e-8)}{\\text{TS\\_MEAN}(\\text{ABS}(\\text{return}) / (\\text{volume} + 1e-8), 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "daaf01ba2f43",
        "parent_trajectory_ids": [
          "810ec4913f1e",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption Efficiency' factor, calculated as the product of the 5-day average lower-shadow-to-range ratio (normalized by the inverse of 5-day volume volatility) and the ratio of the overnight gap to the 5-day average Amihud illiquidity, identifies high-conviction price reversals.\n                Concise Observation: Parent 1 (RankIC 0.0216) highlights structural price floors through low-volatility support, while Parent 2 (RankIC 0.0238) captures sentiment efficiency via liquidity-adjusted gaps; combining them targets stocks where structural support meets efficient momentum.\n                Concise Justification: Multiplying these metrics creates a synergistic signal where the 'Structural Filter' of support integrity ensures the asset is not in freefall, and the 'Momentum Catalyst' of sentiment efficiency ensures the market is reacting positively to that support with minimal friction.\n                Concise Knowledge: If price support (lower shadows) is accompanied by low volume dispersion, it indicates institutional absorption; when such support is followed by liquidity-efficient overnight gaps, the probability of a sustained trend reversal increases.\n                concise Specification: Define KLOW as (min(open, close) - low) / (high - low); VSTD5 as the 5-day rolling standard deviation of volume; Gap as (open - prev_close) / (prev_high - prev_low); Amihud as abs(return) / volume; the final factor is Mean(KLOW, 5) / VSTD5 * (Gap / Mean(Amihud, 5)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:58:02.530991"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1647226257746238,
        "ICIR": 0.0323271412482753,
        "1day.excess_return_without_cost.std": 0.0043652217525175,
        "1day.excess_return_with_cost.annualized_return": -0.0279200159058113,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 8.021791461917035e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0190918636793625,
        "1day.excess_return_with_cost.std": 0.0043653049856786,
        "Rank IC": 0.0212481910059462,
        "IC": 0.0044068469994508,
        "1day.excess_return_without_cost.max_drawdown": -0.0968520983176534,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.2835003083033711,
        "1day.pa": 0.0,
        "l2.valid": 0.9964851123242456,
        "Rank ICIR": 0.1622896067831404,
        "l2.train": 0.9939805525931916,
        "1day.excess_return_with_cost.information_ratio": -0.4145840515417952,
        "1day.excess_return_with_cost.mean": -0.0001173109912008
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Institutional Absorption Efficiency' hypothesis. The first implementation (Institutional_Absorption_Efficiency_5D) used a direct multiplicative approach with raw values, while the second (Structural_Support_Momentum_Rank) attempted to improve robustness through cross-sectional ranking. The results show that the current iteration significantly underperforms compared to the SOTA result across all key metrics: the Information Ratio dropped from 0.97 to 0.28, and the Annualized Return decreased from 5.2% to 1.9%. The IC also declined from 0.0058 to 0.0044.",
        "hypothesis_evaluation": "The results currently refute the hypothesis in its current mathematical form. While the theoretical concept of combining lower shadow support with overnight gap efficiency is sound, the direct multiplication of these components (especially with raw volume volatility in the denominator) appears to create an unstable signal. The low Information Ratio suggests that the 'absorption' and 'efficiency' components may be canceling each other out or creating extreme outliers that degrade the model's predictive power.",
        "decision": false,
        "reason": "The current failure likely stems from two issues: 1) Volume volatility is highly non-stationary and can distort the absorption ratio. Using ATR provides a price-based normalization that better reflects 'structural support' relative to recent price swings. 2) The 5-day window for Amihud illiquidity might be too short, capturing noise rather than structural liquidity constraints. Extending this to 10 days and separating the components into a multi-feature input (or a simpler additive combination) will reduce the sensitivity to outliers caused by the current multiplicative structure."
      }
    },
    "0cb669f564195a26": {
      "factor_id": "0cb669f564195a26",
      "factor_name": "Structural_Support_Momentum_Rank",
      "factor_expression": "RANK(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) / (TS_STD($volume, 5) + 1e-8)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) / (TS_STD($volume, 5) + 1e-8)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Support_Momentum_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the absorption efficiency hypothesis. It measures the strength of the lower shadow relative to volume volatility, multiplied by the efficiency of the overnight price gap relative to historical illiquidity, ensuring comparability across the universe.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}(\\frac{\\text{TS\\_MEAN}(\\text{KLOW}, 5)}{\\text{TS\\_STD}(\\text{volume}, 5)}) \\times \\text{RANK}(\\frac{\\text{Gap}}{\\text{TS\\_MEAN}(\\text{Amihud}, 5)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "daaf01ba2f43",
        "parent_trajectory_ids": [
          "810ec4913f1e",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption Efficiency' factor, calculated as the product of the 5-day average lower-shadow-to-range ratio (normalized by the inverse of 5-day volume volatility) and the ratio of the overnight gap to the 5-day average Amihud illiquidity, identifies high-conviction price reversals.\n                Concise Observation: Parent 1 (RankIC 0.0216) highlights structural price floors through low-volatility support, while Parent 2 (RankIC 0.0238) captures sentiment efficiency via liquidity-adjusted gaps; combining them targets stocks where structural support meets efficient momentum.\n                Concise Justification: Multiplying these metrics creates a synergistic signal where the 'Structural Filter' of support integrity ensures the asset is not in freefall, and the 'Momentum Catalyst' of sentiment efficiency ensures the market is reacting positively to that support with minimal friction.\n                Concise Knowledge: If price support (lower shadows) is accompanied by low volume dispersion, it indicates institutional absorption; when such support is followed by liquidity-efficient overnight gaps, the probability of a sustained trend reversal increases.\n                concise Specification: Define KLOW as (min(open, close) - low) / (high - low); VSTD5 as the 5-day rolling standard deviation of volume; Gap as (open - prev_close) / (prev_high - prev_low); Amihud as abs(return) / volume; the final factor is Mean(KLOW, 5) / VSTD5 * (Gap / Mean(Amihud, 5)).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T06:58:02.530991"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1647226257746238,
        "ICIR": 0.0323271412482753,
        "1day.excess_return_without_cost.std": 0.0043652217525175,
        "1day.excess_return_with_cost.annualized_return": -0.0279200159058113,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 8.021791461917035e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0190918636793625,
        "1day.excess_return_with_cost.std": 0.0043653049856786,
        "Rank IC": 0.0212481910059462,
        "IC": 0.0044068469994508,
        "1day.excess_return_without_cost.max_drawdown": -0.0968520983176534,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.2835003083033711,
        "1day.pa": 0.0,
        "l2.valid": 0.9964851123242456,
        "Rank ICIR": 0.1622896067831404,
        "l2.train": 0.9939805525931916,
        "1day.excess_return_with_cost.information_ratio": -0.4145840515417952,
        "1day.excess_return_with_cost.mean": -0.0001173109912008
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Institutional Absorption Efficiency' hypothesis. The first implementation (Institutional_Absorption_Efficiency_5D) used a direct multiplicative approach with raw values, while the second (Structural_Support_Momentum_Rank) attempted to improve robustness through cross-sectional ranking. The results show that the current iteration significantly underperforms compared to the SOTA result across all key metrics: the Information Ratio dropped from 0.97 to 0.28, and the Annualized Return decreased from 5.2% to 1.9%. The IC also declined from 0.0058 to 0.0044.",
        "hypothesis_evaluation": "The results currently refute the hypothesis in its current mathematical form. While the theoretical concept of combining lower shadow support with overnight gap efficiency is sound, the direct multiplication of these components (especially with raw volume volatility in the denominator) appears to create an unstable signal. The low Information Ratio suggests that the 'absorption' and 'efficiency' components may be canceling each other out or creating extreme outliers that degrade the model's predictive power.",
        "decision": false,
        "reason": "The current failure likely stems from two issues: 1) Volume volatility is highly non-stationary and can distort the absorption ratio. Using ATR provides a price-based normalization that better reflects 'structural support' relative to recent price swings. 2) The 5-day window for Amihud illiquidity might be too short, capturing noise rather than structural liquidity constraints. Extending this to 10 days and separating the components into a multi-feature input (or a simpler additive combination) will reduce the sensitivity to outliers caused by the current multiplicative structure."
      }
    },
    "817a0aaa51a83568": {
      "factor_id": "817a0aaa51a83568",
      "factor_name": "LGSF_Fragility_5D",
      "factor_expression": "TS_MEAN((ABS($return) / ($volume + 1e-8)) / (ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN((ABS(($close / DELAY($close, 1)) - 1) / ($volume + 1e-8)) / (ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)), 5)\" # Your output factor expression will be filled in here\n    name = \"LGSF_Fragility_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity-Gated Structural Fragility (LGSF) factor. It calculates the ratio of Amihud illiquidity to the Gap-to-Range ratio over a 5-day window. High values indicate that price gaps are occurring in illiquid environments with high intraday noise (low quality gaps), which typically precedes mean-reversion or downward pressure.",
      "factor_formulation": "LGSF = \\text{TS_MEAN}\\left(\\frac{\\text{ABS}(\\text{return}) / (\\text{volume} + 1e-8)}{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) / (\\text{high} - \\text{low} + 1e-6)}, 5\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "0f877d52f182",
        "parent_trajectory_ids": [
          "f556ae3ea79a",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Gated Structural Fragility' (LGSF) factor, calculated as the ratio of the 5-day average Amihud illiquidity to the 5-day average 'Gap-to-Range' ratio, predicts that overnight gaps supported by high liquidity and low intraday volatility signal high-conviction trends, while gaps in illiquid, high-noise environments indicate mean-reversion.\n                Concise Observation: Parent strategies show that both intraday range-to-gap ratios and liquidity-weighted sentiment have positive RankIC (0.0215 and 0.0238), suggesting that price structural quality and execution costs are synergistic predictors of return persistence.\n                Concise Justification: Combining the Intraday Mean-Reversion Fragility with Amihud illiquidity creates a 'conviction filter' that distinguishes between high-quality price discovery and low-quality volatility, penalizing signals where high transaction costs and high noise suggest retail exhaustion.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday price dispersion relative to the gap size and low liquidity (high Amihud), the price movement is likely a noise-driven liquidity trap; conversely, low intraday fragility in liquid environments confirms institutional conviction.\n                concise Specification: Define Gap as abs(open - prev_close), Range as (high - low), and Amihud as abs(return)/volume; the LGSF factor is the 5-day rolling mean of (Amihud / (Gap / (Range + 1e-6))), where a higher value indicates higher fragility and lower liquidity validation, expecting a negative correlation with future returns.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:05:27.204687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1587184482520541,
        "ICIR": 0.0264572099644405,
        "1day.excess_return_without_cost.std": 0.0043377946212455,
        "1day.excess_return_with_cost.annualized_return": -0.0110550713607779,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001532067413258,
        "1day.excess_return_without_cost.annualized_return": 0.0364632044355563,
        "1day.excess_return_with_cost.std": 0.0043382657857727,
        "Rank IC": 0.0190659058659936,
        "IC": 0.0036813709029438,
        "1day.excess_return_without_cost.max_drawdown": -0.1283470913056602,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5448756096475801,
        "1day.pa": 0.0,
        "l2.valid": 0.996730300262881,
        "Rank ICIR": 0.1409731696554867,
        "l2.train": 0.9941910180001404,
        "1day.excess_return_with_cost.information_ratio": -0.1651797924343784,
        "1day.excess_return_with_cost.mean": -4.644987966713415e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Gated Structural Fragility' (LGSF) framework. The core idea was to identify 'low quality' price gaps occurring in illiquid, high-noise environments. While the theoretical framework is sound, the current implementations (LGSF_Fragility_5D, LVGQ_10D, and FZT_20D) failed to surpass the existing SOTA result. Specifically, the Information Ratio (0.54 vs 0.97) and IC (0.0037 vs 0.0058) showed significant deterioration, suggesting that the current mathematical formulations may be capturing more noise than signal, or the window sizes are not optimized for the decay of these structural signals.",
        "hypothesis_evaluation": "The hypothesis that high illiquidity relative to gap quality signals mean-reversion is partially supported by the positive IC, but the weak performance compared to SOTA suggests the 'Fragility' ratio is currently too volatile. The LGSF_Fragility_5D factor uses a raw ratio of averages, which might be prone to outliers in the volume or intraday range denominators. The Fragility_ZScore_Trend_20D attempted to normalize this but likely suffered from a look-back period that is too long for high-frequency liquidity shocks.",
        "decision": false,
        "reason": "The previous Amihud-based approach (Price Change / Volume) might be redundant because price change is already represented in the 'Gap' and 'Return' components. By switching to a 'Relative Volume' (V / Mean(V, 20)) and 'Gap Efficiency' (Gap / Range) approach, we isolate the conviction of the move. Furthermore, using a 3-day window for the core signal and a 20-day window for the volume baseline reduces noise and addresses the complexity/overfitting concerns by using clearer, more distinct features."
      }
    },
    "1ea2cf1841ef2212": {
      "factor_id": "1ea2cf1841ef2212",
      "factor_name": "Liquidity_Validated_Gap_Quality_10D",
      "factor_expression": "RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)) * RANK($volume / (ABS($return) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-6)) * RANK(INV(TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 10)))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Gap_Quality_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the quality of overnight gaps by comparing the gap size to the intraday range, weighted by the inverse of Amihud illiquidity. It identifies high-conviction trends where gaps are large relative to intraday noise and supported by high liquidity (low Amihud).",
      "factor_formulation": "LVGQ = \\text{RANK}\\left(\\frac{\\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1))}{\\text{high} - \\text{low} + 1e-6}\\right) * \\text{RANK}\\left(\\frac{\\text{volume}}{\\text{ABS}(\\text{return}) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "0f877d52f182",
        "parent_trajectory_ids": [
          "f556ae3ea79a",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Gated Structural Fragility' (LGSF) factor, calculated as the ratio of the 5-day average Amihud illiquidity to the 5-day average 'Gap-to-Range' ratio, predicts that overnight gaps supported by high liquidity and low intraday volatility signal high-conviction trends, while gaps in illiquid, high-noise environments indicate mean-reversion.\n                Concise Observation: Parent strategies show that both intraday range-to-gap ratios and liquidity-weighted sentiment have positive RankIC (0.0215 and 0.0238), suggesting that price structural quality and execution costs are synergistic predictors of return persistence.\n                Concise Justification: Combining the Intraday Mean-Reversion Fragility with Amihud illiquidity creates a 'conviction filter' that distinguishes between high-quality price discovery and low-quality volatility, penalizing signals where high transaction costs and high noise suggest retail exhaustion.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday price dispersion relative to the gap size and low liquidity (high Amihud), the price movement is likely a noise-driven liquidity trap; conversely, low intraday fragility in liquid environments confirms institutional conviction.\n                concise Specification: Define Gap as abs(open - prev_close), Range as (high - low), and Amihud as abs(return)/volume; the LGSF factor is the 5-day rolling mean of (Amihud / (Gap / (Range + 1e-6))), where a higher value indicates higher fragility and lower liquidity validation, expecting a negative correlation with future returns.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:05:27.204687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1587184482520541,
        "ICIR": 0.0264572099644405,
        "1day.excess_return_without_cost.std": 0.0043377946212455,
        "1day.excess_return_with_cost.annualized_return": -0.0110550713607779,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001532067413258,
        "1day.excess_return_without_cost.annualized_return": 0.0364632044355563,
        "1day.excess_return_with_cost.std": 0.0043382657857727,
        "Rank IC": 0.0190659058659936,
        "IC": 0.0036813709029438,
        "1day.excess_return_without_cost.max_drawdown": -0.1283470913056602,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5448756096475801,
        "1day.pa": 0.0,
        "l2.valid": 0.996730300262881,
        "Rank ICIR": 0.1409731696554867,
        "l2.train": 0.9941910180001404,
        "1day.excess_return_with_cost.information_ratio": -0.1651797924343784,
        "1day.excess_return_with_cost.mean": -4.644987966713415e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Gated Structural Fragility' (LGSF) framework. The core idea was to identify 'low quality' price gaps occurring in illiquid, high-noise environments. While the theoretical framework is sound, the current implementations (LGSF_Fragility_5D, LVGQ_10D, and FZT_20D) failed to surpass the existing SOTA result. Specifically, the Information Ratio (0.54 vs 0.97) and IC (0.0037 vs 0.0058) showed significant deterioration, suggesting that the current mathematical formulations may be capturing more noise than signal, or the window sizes are not optimized for the decay of these structural signals.",
        "hypothesis_evaluation": "The hypothesis that high illiquidity relative to gap quality signals mean-reversion is partially supported by the positive IC, but the weak performance compared to SOTA suggests the 'Fragility' ratio is currently too volatile. The LGSF_Fragility_5D factor uses a raw ratio of averages, which might be prone to outliers in the volume or intraday range denominators. The Fragility_ZScore_Trend_20D attempted to normalize this but likely suffered from a look-back period that is too long for high-frequency liquidity shocks.",
        "decision": false,
        "reason": "The previous Amihud-based approach (Price Change / Volume) might be redundant because price change is already represented in the 'Gap' and 'Return' components. By switching to a 'Relative Volume' (V / Mean(V, 20)) and 'Gap Efficiency' (Gap / Range) approach, we isolate the conviction of the move. Furthermore, using a 3-day window for the core signal and a 20-day window for the volume baseline reduces noise and addresses the complexity/overfitting concerns by using clearer, more distinct features."
      }
    },
    "1af553913f15671f": {
      "factor_id": "1af553913f15671f",
      "factor_name": "Fragility_ZScore_Trend_20D",
      "factor_expression": "TS_ZSCORE((ABS($return) * ($high - $low)) / ($volume * ABS($open - DELAY($close, 1)) + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((ABS($close / DELAY($close, 1) - 1) / ($volume * $close + 1e-8)) / (ABS($open / DELAY($close, 1) - 1) + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Fragility_ZScore_Trend_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A standardized measure of structural fragility that compares the current Amihud-to-Gap ratio against its 20-day historical distribution. It identifies extreme structural decoupling between price discovery (gaps) and liquidity.",
      "factor_formulation": "FZT = \\text{TS_ZSCORE}\\left(\\frac{\\text{ABS}(\\text{return}) * (\\text{high} - \\text{low})}{\\text{volume} * \\text{ABS}(\\text{open} - \\text{DELAY}(\\text{close}, 1)) + 1e-8}, 20\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "0f877d52f182",
        "parent_trajectory_ids": [
          "f556ae3ea79a",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Gated Structural Fragility' (LGSF) factor, calculated as the ratio of the 5-day average Amihud illiquidity to the 5-day average 'Gap-to-Range' ratio, predicts that overnight gaps supported by high liquidity and low intraday volatility signal high-conviction trends, while gaps in illiquid, high-noise environments indicate mean-reversion.\n                Concise Observation: Parent strategies show that both intraday range-to-gap ratios and liquidity-weighted sentiment have positive RankIC (0.0215 and 0.0238), suggesting that price structural quality and execution costs are synergistic predictors of return persistence.\n                Concise Justification: Combining the Intraday Mean-Reversion Fragility with Amihud illiquidity creates a 'conviction filter' that distinguishes between high-quality price discovery and low-quality volatility, penalizing signals where high transaction costs and high noise suggest retail exhaustion.\n                Concise Knowledge: If an overnight price gap is accompanied by high intraday price dispersion relative to the gap size and low liquidity (high Amihud), the price movement is likely a noise-driven liquidity trap; conversely, low intraday fragility in liquid environments confirms institutional conviction.\n                concise Specification: Define Gap as abs(open - prev_close), Range as (high - low), and Amihud as abs(return)/volume; the LGSF factor is the 5-day rolling mean of (Amihud / (Gap / (Range + 1e-6))), where a higher value indicates higher fragility and lower liquidity validation, expecting a negative correlation with future returns.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:05:27.204687"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1587184482520541,
        "ICIR": 0.0264572099644405,
        "1day.excess_return_without_cost.std": 0.0043377946212455,
        "1day.excess_return_with_cost.annualized_return": -0.0110550713607779,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001532067413258,
        "1day.excess_return_without_cost.annualized_return": 0.0364632044355563,
        "1day.excess_return_with_cost.std": 0.0043382657857727,
        "Rank IC": 0.0190659058659936,
        "IC": 0.0036813709029438,
        "1day.excess_return_without_cost.max_drawdown": -0.1283470913056602,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5448756096475801,
        "1day.pa": 0.0,
        "l2.valid": 0.996730300262881,
        "Rank ICIR": 0.1409731696554867,
        "l2.train": 0.9941910180001404,
        "1day.excess_return_with_cost.information_ratio": -0.1651797924343784,
        "1day.excess_return_with_cost.mean": -4.644987966713415e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Gated Structural Fragility' (LGSF) framework. The core idea was to identify 'low quality' price gaps occurring in illiquid, high-noise environments. While the theoretical framework is sound, the current implementations (LGSF_Fragility_5D, LVGQ_10D, and FZT_20D) failed to surpass the existing SOTA result. Specifically, the Information Ratio (0.54 vs 0.97) and IC (0.0037 vs 0.0058) showed significant deterioration, suggesting that the current mathematical formulations may be capturing more noise than signal, or the window sizes are not optimized for the decay of these structural signals.",
        "hypothesis_evaluation": "The hypothesis that high illiquidity relative to gap quality signals mean-reversion is partially supported by the positive IC, but the weak performance compared to SOTA suggests the 'Fragility' ratio is currently too volatile. The LGSF_Fragility_5D factor uses a raw ratio of averages, which might be prone to outliers in the volume or intraday range denominators. The Fragility_ZScore_Trend_20D attempted to normalize this but likely suffered from a look-back period that is too long for high-frequency liquidity shocks.",
        "decision": false,
        "reason": "The previous Amihud-based approach (Price Change / Volume) might be redundant because price change is already represented in the 'Gap' and 'Return' components. By switching to a 'Relative Volume' (V / Mean(V, 20)) and 'Gap Efficiency' (Gap / Range) approach, we isolate the conviction of the move. Furthermore, using a 3-day window for the core signal and a 20-day window for the volume baseline reduces noise and addresses the complexity/overfitting concerns by using clearer, more distinct features."
      }
    },
    "885705120222fbc8": {
      "factor_id": "885705120222fbc8",
      "factor_name": "SEID_Institutional_Divergence_10D",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5)) / (TS_CORR($return, $volume, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_MEAN(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5)) / (TS_CORR(TS_PCTCHANGE($close, 1), $volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"SEID_Institutional_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor implements the Structural Exhaustion & Institutional Divergence (SEID) hypothesis. It measures the divergence between price trend linearity (R-squared) and institutional conviction (overnight gaps), normalized by volume-price correlation. High values indicate speculative exhaustion where a linear price path lacks institutional gap support and is driven by high-convexity retail volume.",
      "factor_formulation": "SEID = \\frac{\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2 \\times \\text{TS\\_MEAN}((\\text{open} - \\text{prev\\_close})/\\text{prev\\_close}, 5)}{\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "fb317a249559",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion & Institutional Divergence' (SEID) factor, defined as the product of a 10-day price-time R-squared and the 5-day average of overnight gaps, inversely weighted by the 5-day volume-price correlation, predicts a significant price reversal when geometric trend perfection diverges from institutional conviction.\n                Concise Observation: Parent 1 successfully used price-time linearity to find trend exhaustion (RankIC 0.0219), while Parent 2 identified that institutional gaps provide a quality filter for momentum (RankIC 0.0230); combining these reveals that price moves with high R-squared but low institutional 'gap' support are the most prone to failure.\n                Concise Justification: Linear price trends are unsustainable without continuous institutional liquidity provision; by measuring the divergence between the 'perfection' of the price path (R-squared) and the 'strength' of institutional entry (overnight gaps), we can isolate speculative bubbles from robust trends.\n                Concise Knowledge: If a price trend exhibits high geometric linearity (R-squared) while institutional support (overnight gaps) diminishes and volume-price alignment (convexity) peaks, the asset is likely entering a structural climax phase; When these conditions align, the probability of a mean-reversion event increases as speculative retail momentum replaces institutional accumulation.\n                concise Specification: The factor is calculated by multiplying the 10-day price-time R-squared by the 5-day mean of (Open - Prev_Close) / Prev_Close, then dividing by the 5-day rolling correlation between daily returns and volume to penalize high-convexity speculative moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:24:39.560807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1090159768569968,
        "ICIR": 0.0452362084803116,
        "1day.excess_return_without_cost.std": 0.004224799409635,
        "1day.excess_return_with_cost.annualized_return": 0.0196100505220739,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002811447780228,
        "1day.excess_return_without_cost.annualized_return": 0.0669124571694445,
        "1day.excess_return_with_cost.std": 0.0042261306915758,
        "Rank IC": 0.0222027890219965,
        "IC": 0.0060714284732353,
        "1day.excess_return_without_cost.max_drawdown": -0.1017431519051186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.026626347995202,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339753866596,
        "Rank ICIR": 0.1702555899170283,
        "l2.train": 0.9938257445745428,
        "1day.excess_return_with_cost.information_ratio": 0.3007788612120447,
        "1day.excess_return_with_cost.mean": 8.239517026081495e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Structural Exhaustion & Institutional Divergence' (SEID) framework has successfully yielded a new State-of-the-Art (SOTA) result. The 'SEID_Institutional_Divergence_10D' and its variants demonstrate strong predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the Annualized Return rising from 5.2% to 6.69%. The Information Coefficient (IC) also showed a marginal improvement. However, the Max Drawdown (MDD) worsened from -0.072 to -0.101, suggesting that while the signal is more aggressive in capturing returns, it introduces higher tail risk or volatility during market regime shifts.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the divergence between price linearity (R-squared) and institutional conviction (overnight gaps) serves as a potent reversal or exhaustion signal. The inclusion of the volume-price correlation as a denominator (inversely weighting) appears to be the primary driver of the performance boost, as it effectively filters out trends driven by retail-heavy speculative volume.",
        "decision": true,
        "reason": "The current MDD is high, likely because raw price gaps and R-squared values are sensitive to absolute volatility levels. By normalizing the overnight gap by a short-term ATR (Average True Range) and using an Efficiency Ratio (Net Change / Sum of Absolute Changes), we can create a more robust measure of 'structural perfection' that is comparable across different market environments, potentially smoothing the drawdown while maintaining the high IR."
      }
    },
    "757293c4f1d9e794": {
      "factor_id": "757293c4f1d9e794",
      "factor_name": "Structural_Exhaustion_Rank_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(TS_MEAN(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(TS_MEAN(($open - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the SEID hypothesis focusing on the cross-sectional rank of price linearity versus the rank of institutional gap strength. It identifies stocks where the 'perfection' of the trend (R-squared) is high but the institutional support (overnight gaps) is relatively low compared to the market, signaling potential mean reversion.",
      "factor_formulation": "\\text{Exhaustion} = \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2) - \\text{RANK}(\\text{TS\\_MEAN}((\\text{open} - \\text{prev\\_close})/\\text{prev\\_close}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "fb317a249559",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion & Institutional Divergence' (SEID) factor, defined as the product of a 10-day price-time R-squared and the 5-day average of overnight gaps, inversely weighted by the 5-day volume-price correlation, predicts a significant price reversal when geometric trend perfection diverges from institutional conviction.\n                Concise Observation: Parent 1 successfully used price-time linearity to find trend exhaustion (RankIC 0.0219), while Parent 2 identified that institutional gaps provide a quality filter for momentum (RankIC 0.0230); combining these reveals that price moves with high R-squared but low institutional 'gap' support are the most prone to failure.\n                Concise Justification: Linear price trends are unsustainable without continuous institutional liquidity provision; by measuring the divergence between the 'perfection' of the price path (R-squared) and the 'strength' of institutional entry (overnight gaps), we can isolate speculative bubbles from robust trends.\n                Concise Knowledge: If a price trend exhibits high geometric linearity (R-squared) while institutional support (overnight gaps) diminishes and volume-price alignment (convexity) peaks, the asset is likely entering a structural climax phase; When these conditions align, the probability of a mean-reversion event increases as speculative retail momentum replaces institutional accumulation.\n                concise Specification: The factor is calculated by multiplying the 10-day price-time R-squared by the 5-day mean of (Open - Prev_Close) / Prev_Close, then dividing by the 5-day rolling correlation between daily returns and volume to penalize high-convexity speculative moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:24:39.560807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1090159768569968,
        "ICIR": 0.0452362084803116,
        "1day.excess_return_without_cost.std": 0.004224799409635,
        "1day.excess_return_with_cost.annualized_return": 0.0196100505220739,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002811447780228,
        "1day.excess_return_without_cost.annualized_return": 0.0669124571694445,
        "1day.excess_return_with_cost.std": 0.0042261306915758,
        "Rank IC": 0.0222027890219965,
        "IC": 0.0060714284732353,
        "1day.excess_return_without_cost.max_drawdown": -0.1017431519051186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.026626347995202,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339753866596,
        "Rank ICIR": 0.1702555899170283,
        "l2.train": 0.9938257445745428,
        "1day.excess_return_with_cost.information_ratio": 0.3007788612120447,
        "1day.excess_return_with_cost.mean": 8.239517026081495e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Structural Exhaustion & Institutional Divergence' (SEID) framework has successfully yielded a new State-of-the-Art (SOTA) result. The 'SEID_Institutional_Divergence_10D' and its variants demonstrate strong predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the Annualized Return rising from 5.2% to 6.69%. The Information Coefficient (IC) also showed a marginal improvement. However, the Max Drawdown (MDD) worsened from -0.072 to -0.101, suggesting that while the signal is more aggressive in capturing returns, it introduces higher tail risk or volatility during market regime shifts.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the divergence between price linearity (R-squared) and institutional conviction (overnight gaps) serves as a potent reversal or exhaustion signal. The inclusion of the volume-price correlation as a denominator (inversely weighting) appears to be the primary driver of the performance boost, as it effectively filters out trends driven by retail-heavy speculative volume.",
        "decision": true,
        "reason": "The current MDD is high, likely because raw price gaps and R-squared values are sensitive to absolute volatility levels. By normalizing the overnight gap by a short-term ATR (Average True Range) and using an Efficiency Ratio (Net Change / Sum of Absolute Changes), we can create a more robust measure of 'structural perfection' that is comparable across different market environments, potentially smoothing the drawdown while maintaining the high IR."
      }
    },
    "47da4059d811475c": {
      "factor_id": "47da4059d811475c",
      "factor_name": "Speculative_Convexity_Divergence",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (ABS(TS_CORR($return, $volume, 5)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (ABS(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Speculative_Convexity_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the divergence between price linearity and volume-price alignment. It targets the 'Structural Climax' phase where price follows a strict linear path (high R-squared) but is increasingly penalized by high volume-return correlation, which suggests speculative retail participation rather than institutional accumulation.",
      "factor_formulation": "\\text{SCD} = \\frac{\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2}{\\text{ABS}(\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 5)) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "fb317a249559",
        "parent_trajectory_ids": [
          "668f01f1201b",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Structural Exhaustion & Institutional Divergence' (SEID) factor, defined as the product of a 10-day price-time R-squared and the 5-day average of overnight gaps, inversely weighted by the 5-day volume-price correlation, predicts a significant price reversal when geometric trend perfection diverges from institutional conviction.\n                Concise Observation: Parent 1 successfully used price-time linearity to find trend exhaustion (RankIC 0.0219), while Parent 2 identified that institutional gaps provide a quality filter for momentum (RankIC 0.0230); combining these reveals that price moves with high R-squared but low institutional 'gap' support are the most prone to failure.\n                Concise Justification: Linear price trends are unsustainable without continuous institutional liquidity provision; by measuring the divergence between the 'perfection' of the price path (R-squared) and the 'strength' of institutional entry (overnight gaps), we can isolate speculative bubbles from robust trends.\n                Concise Knowledge: If a price trend exhibits high geometric linearity (R-squared) while institutional support (overnight gaps) diminishes and volume-price alignment (convexity) peaks, the asset is likely entering a structural climax phase; When these conditions align, the probability of a mean-reversion event increases as speculative retail momentum replaces institutional accumulation.\n                concise Specification: The factor is calculated by multiplying the 10-day price-time R-squared by the 5-day mean of (Open - Prev_Close) / Prev_Close, then dividing by the 5-day rolling correlation between daily returns and volume to penalize high-convexity speculative moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:24:39.560807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1090159768569968,
        "ICIR": 0.0452362084803116,
        "1day.excess_return_without_cost.std": 0.004224799409635,
        "1day.excess_return_with_cost.annualized_return": 0.0196100505220739,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002811447780228,
        "1day.excess_return_without_cost.annualized_return": 0.0669124571694445,
        "1day.excess_return_with_cost.std": 0.0042261306915758,
        "Rank IC": 0.0222027890219965,
        "IC": 0.0060714284732353,
        "1day.excess_return_without_cost.max_drawdown": -0.1017431519051186,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.026626347995202,
        "1day.pa": 0.0,
        "l2.valid": 0.9964339753866596,
        "Rank ICIR": 0.1702555899170283,
        "l2.train": 0.9938257445745428,
        "1day.excess_return_with_cost.information_ratio": 0.3007788612120447,
        "1day.excess_return_with_cost.mean": 8.239517026081495e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Structural Exhaustion & Institutional Divergence' (SEID) framework has successfully yielded a new State-of-the-Art (SOTA) result. The 'SEID_Institutional_Divergence_10D' and its variants demonstrate strong predictive power, with the Information Ratio (IR) increasing from 0.97 to 1.02 and the Annualized Return rising from 5.2% to 6.69%. The Information Coefficient (IC) also showed a marginal improvement. However, the Max Drawdown (MDD) worsened from -0.072 to -0.101, suggesting that while the signal is more aggressive in capturing returns, it introduces higher tail risk or volatility during market regime shifts.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that the divergence between price linearity (R-squared) and institutional conviction (overnight gaps) serves as a potent reversal or exhaustion signal. The inclusion of the volume-price correlation as a denominator (inversely weighting) appears to be the primary driver of the performance boost, as it effectively filters out trends driven by retail-heavy speculative volume.",
        "decision": true,
        "reason": "The current MDD is high, likely because raw price gaps and R-squared values are sensitive to absolute volatility levels. By normalizing the overnight gap by a short-term ATR (Average True Range) and using an Efficiency Ratio (Net Change / Sum of Absolute Changes), we can create a more robust measure of 'structural perfection' that is comparable across different market environments, potentially smoothing the drawdown while maintaining the high IR."
      }
    },
    "adac85a6322affa4": {
      "factor_id": "adac85a6322affa4",
      "factor_name": "IAB_Absorption_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($volume / (TS_MEAN($volume, 20) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8)) * (($volume / (TS_MEAN($volume, 20) + 1e-8)) / (($high - $low) / ($close + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IAB_Absorption_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures institutional absorption by identifying overnight gaps that are sustained by high-volume intraday price consolidation. It normalizes the overnight gap by the 20-day ATR and multiplies it by the ratio of relative volume to intraday range, highlighting high-conviction moves with low volatility.",
      "factor_formulation": "IAB = \\frac{open - prev\\_close}{TS\\_STD(close, 20)} \\times \\frac{volume / TS\\_MEAN(volume, 20)}{(high - low) / close + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "f1f8d08ebe6a",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption-Breakout' factor (IAB) predicts positive returns by multiplying the ATR-normalized overnight gap with an intraday compression-to-volume ratio, identifying sessions where gaps are sustained by high-volume price consolidation.\n                Concise Observation: Parent strategies show that overnight gaps (RankIC=0.0218) and intraday volume-to-range compression (RankIC=0.0230) are both predictive, but individually prone to noise from liquidity traps or mean-reverting volatility.\n                Concise Justification: Combining gap magnitude with intraday 'tightness' ensures that the signal captures high-conviction institutional positioning where the price is supported by volume without excessive volatility, reducing the risk of entering low-liquidity spikes.\n                Concise Knowledge: If an overnight price gap is followed by high volume within a narrow intraday range, it indicates institutional absorption of liquidity; when this move is normalized by historical volatility (ATR), it distinguishes sustainable trend initiation from retail-driven exhaustion.\n                concise Specification: The factor is defined as (Gap / ATR_20) * (Volume / (High - Low + epsilon)) / StdDev_Close_20, where Gap is (Open - Prev_Close), ensuring all components are normalized by 20-day rolling volatility and volume metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:28:22.430213"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.122576746534548,
        "ICIR": 0.0463323552942473,
        "1day.excess_return_without_cost.std": 0.0040372089839621,
        "1day.excess_return_with_cost.annualized_return": 0.0159743529200005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002659664624397,
        "1day.excess_return_without_cost.annualized_return": 0.063300018060672,
        "1day.excess_return_with_cost.std": 0.0040370987752859,
        "Rank IC": 0.0214055937073698,
        "IC": 0.0059089617969652,
        "1day.excess_return_without_cost.max_drawdown": -0.0871778296375114,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0163285470443555,
        "1day.pa": 0.0,
        "l2.valid": 0.9965100224309764,
        "Rank ICIR": 0.1719915032363574,
        "l2.train": 0.993825648490252,
        "1day.excess_return_with_cost.information_ratio": 0.256487037361314,
        "1day.excess_return_with_cost.mean": 6.71191299159685e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a successful iteration of the 'Institutional Absorption-Breakout' (IAB) hypothesis. The current results, primarily driven by the 'Institutional_Tightness_Index_20D' and 'IAB_Absorption_20D' implementations, show a clear improvement in predictive power. The Information Ratio (IR) increased from 0.97 to 1.01, and the Annualized Return rose from 5.2% to 6.3%. While the Max Drawdown slightly worsened (-0.087 vs -0.072), the significant gains in IC and IR suggest a more robust signal-to-noise ratio in the current batch. The factors successfully utilize the interaction between overnight gaps and intraday volume-price compression, confirming that 'tight' price action on high volume following a gap is a strong bullish indicator.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The core idea—that institutional absorption is characterized by high volume relative to price range (compression) following a gap—is validated. Specifically, the 'Institutional_Tightness_Index_20D' which uses a 5-day smoothing of the volume/range ratio, suggests that the persistence of this absorption (smoothing) provides a cleaner signal than a single-day snapshot. The ATR-normalization of the gap also proves effective in scaling the signal across different volatility regimes.",
        "decision": true,
        "reason": "While the current factors capture the state of absorption, they don't capture the 'trend' of absorption. By measuring the change in the Volume/Range ratio (e.g., current ratio vs. 5-day average), we can identify accelerating institutional interest. Furthermore, adding a condition that the gap occurs after a period of low volatility (using a ratio of short-term to long-term ATR) could filter out 'exhaustion gaps' and focus on true 'breakout gaps' from consolidation zones. This addresses the slight increase in Max Drawdown by adding a volatility-regime filter."
      }
    },
    "a343e45f00f3c998": {
      "factor_id": "a343e45f00f3c998",
      "factor_name": "Z_Gap_Compression_10D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) + RANK($volume / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)) + RANK($volume / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Z_Gap_Compression_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Institutional Absorption hypothesis focusing on cross-sectional ranking. It identifies stocks where the overnight gap is significant relative to volatility and is accompanied by a high volume-to-range ratio, indicating tight price action under heavy trading.",
      "factor_formulation": "ZGC = RANK(\\frac{open - prev\\_close}{TS\\_STD(close, 10)}) + RANK(\\frac{volume}{high - low + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "f1f8d08ebe6a",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption-Breakout' factor (IAB) predicts positive returns by multiplying the ATR-normalized overnight gap with an intraday compression-to-volume ratio, identifying sessions where gaps are sustained by high-volume price consolidation.\n                Concise Observation: Parent strategies show that overnight gaps (RankIC=0.0218) and intraday volume-to-range compression (RankIC=0.0230) are both predictive, but individually prone to noise from liquidity traps or mean-reverting volatility.\n                Concise Justification: Combining gap magnitude with intraday 'tightness' ensures that the signal captures high-conviction institutional positioning where the price is supported by volume without excessive volatility, reducing the risk of entering low-liquidity spikes.\n                Concise Knowledge: If an overnight price gap is followed by high volume within a narrow intraday range, it indicates institutional absorption of liquidity; when this move is normalized by historical volatility (ATR), it distinguishes sustainable trend initiation from retail-driven exhaustion.\n                concise Specification: The factor is defined as (Gap / ATR_20) * (Volume / (High - Low + epsilon)) / StdDev_Close_20, where Gap is (Open - Prev_Close), ensuring all components are normalized by 20-day rolling volatility and volume metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:28:22.430213"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.122576746534548,
        "ICIR": 0.0463323552942473,
        "1day.excess_return_without_cost.std": 0.0040372089839621,
        "1day.excess_return_with_cost.annualized_return": 0.0159743529200005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002659664624397,
        "1day.excess_return_without_cost.annualized_return": 0.063300018060672,
        "1day.excess_return_with_cost.std": 0.0040370987752859,
        "Rank IC": 0.0214055937073698,
        "IC": 0.0059089617969652,
        "1day.excess_return_without_cost.max_drawdown": -0.0871778296375114,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0163285470443555,
        "1day.pa": 0.0,
        "l2.valid": 0.9965100224309764,
        "Rank ICIR": 0.1719915032363574,
        "l2.train": 0.993825648490252,
        "1day.excess_return_with_cost.information_ratio": 0.256487037361314,
        "1day.excess_return_with_cost.mean": 6.71191299159685e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a successful iteration of the 'Institutional Absorption-Breakout' (IAB) hypothesis. The current results, primarily driven by the 'Institutional_Tightness_Index_20D' and 'IAB_Absorption_20D' implementations, show a clear improvement in predictive power. The Information Ratio (IR) increased from 0.97 to 1.01, and the Annualized Return rose from 5.2% to 6.3%. While the Max Drawdown slightly worsened (-0.087 vs -0.072), the significant gains in IC and IR suggest a more robust signal-to-noise ratio in the current batch. The factors successfully utilize the interaction between overnight gaps and intraday volume-price compression, confirming that 'tight' price action on high volume following a gap is a strong bullish indicator.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The core idea—that institutional absorption is characterized by high volume relative to price range (compression) following a gap—is validated. Specifically, the 'Institutional_Tightness_Index_20D' which uses a 5-day smoothing of the volume/range ratio, suggests that the persistence of this absorption (smoothing) provides a cleaner signal than a single-day snapshot. The ATR-normalization of the gap also proves effective in scaling the signal across different volatility regimes.",
        "decision": true,
        "reason": "While the current factors capture the state of absorption, they don't capture the 'trend' of absorption. By measuring the change in the Volume/Range ratio (e.g., current ratio vs. 5-day average), we can identify accelerating institutional interest. Furthermore, adding a condition that the gap occurs after a period of low volatility (using a ratio of short-term to long-term ATR) could filter out 'exhaustion gaps' and focus on true 'breakout gaps' from consolidation zones. This addresses the slight increase in Max Drawdown by adding a volatility-regime filter."
      }
    },
    "444be5cefc3b92ab": {
      "factor_id": "444be5cefc3b92ab",
      "factor_name": "Institutional_Tightness_Index_20D",
      "factor_expression": "TS_MEAN($volume / ($high - $low + 1e-8), 5) * (($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($volume / ($high - $low + 1e-8), 5) * (($open - DELAY($close, 1)) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Tightness_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures price support following a gap. It uses the ratio of volume to the intraday range, smoothed over 5 days, and scales it by the 20-day volatility-normalized gap. Higher values suggest that the price is being 'held' by institutional volume within a narrow range.",
      "factor_formulation": "ITI = TS\\_MEAN(\\frac{volume}{high - low + 1e-8}, 5) \\times \\frac{open - prev\\_close}{TS\\_STD(close, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "f1f8d08ebe6a",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "fd9ea6a1608b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption-Breakout' factor (IAB) predicts positive returns by multiplying the ATR-normalized overnight gap with an intraday compression-to-volume ratio, identifying sessions where gaps are sustained by high-volume price consolidation.\n                Concise Observation: Parent strategies show that overnight gaps (RankIC=0.0218) and intraday volume-to-range compression (RankIC=0.0230) are both predictive, but individually prone to noise from liquidity traps or mean-reverting volatility.\n                Concise Justification: Combining gap magnitude with intraday 'tightness' ensures that the signal captures high-conviction institutional positioning where the price is supported by volume without excessive volatility, reducing the risk of entering low-liquidity spikes.\n                Concise Knowledge: If an overnight price gap is followed by high volume within a narrow intraday range, it indicates institutional absorption of liquidity; when this move is normalized by historical volatility (ATR), it distinguishes sustainable trend initiation from retail-driven exhaustion.\n                concise Specification: The factor is defined as (Gap / ATR_20) * (Volume / (High - Low + epsilon)) / StdDev_Close_20, where Gap is (Open - Prev_Close), ensuring all components are normalized by 20-day rolling volatility and volume metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:28:22.430213"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.122576746534548,
        "ICIR": 0.0463323552942473,
        "1day.excess_return_without_cost.std": 0.0040372089839621,
        "1day.excess_return_with_cost.annualized_return": 0.0159743529200005,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002659664624397,
        "1day.excess_return_without_cost.annualized_return": 0.063300018060672,
        "1day.excess_return_with_cost.std": 0.0040370987752859,
        "Rank IC": 0.0214055937073698,
        "IC": 0.0059089617969652,
        "1day.excess_return_without_cost.max_drawdown": -0.0871778296375114,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.0163285470443555,
        "1day.pa": 0.0,
        "l2.valid": 0.9965100224309764,
        "Rank ICIR": 0.1719915032363574,
        "l2.train": 0.993825648490252,
        "1day.excess_return_with_cost.information_ratio": 0.256487037361314,
        "1day.excess_return_with_cost.mean": 6.71191299159685e-05
      },
      "feedback": {
        "observations": "The experiment results demonstrate a successful iteration of the 'Institutional Absorption-Breakout' (IAB) hypothesis. The current results, primarily driven by the 'Institutional_Tightness_Index_20D' and 'IAB_Absorption_20D' implementations, show a clear improvement in predictive power. The Information Ratio (IR) increased from 0.97 to 1.01, and the Annualized Return rose from 5.2% to 6.3%. While the Max Drawdown slightly worsened (-0.087 vs -0.072), the significant gains in IC and IR suggest a more robust signal-to-noise ratio in the current batch. The factors successfully utilize the interaction between overnight gaps and intraday volume-price compression, confirming that 'tight' price action on high volume following a gap is a strong bullish indicator.",
        "hypothesis_evaluation": "The results strongly support the hypothesis. The core idea—that institutional absorption is characterized by high volume relative to price range (compression) following a gap—is validated. Specifically, the 'Institutional_Tightness_Index_20D' which uses a 5-day smoothing of the volume/range ratio, suggests that the persistence of this absorption (smoothing) provides a cleaner signal than a single-day snapshot. The ATR-normalization of the gap also proves effective in scaling the signal across different volatility regimes.",
        "decision": true,
        "reason": "While the current factors capture the state of absorption, they don't capture the 'trend' of absorption. By measuring the change in the Volume/Range ratio (e.g., current ratio vs. 5-day average), we can identify accelerating institutional interest. Furthermore, adding a condition that the gap occurs after a period of low volatility (using a ratio of short-term to long-term ATR) could filter out 'exhaustion gaps' and focus on true 'breakout gaps' from consolidation zones. This addresses the slight increase in Max Drawdown by adding a volatility-regime filter."
      }
    },
    "8c3fe85ed595682a": {
      "factor_id": "8c3fe85ed595682a",
      "factor_name": "Compression_Linearity_Gap_Factor",
      "factor_expression": "ZSCORE(INV(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS($open - DELAY($close, 1)), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(INV(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))) * ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS($open - DELAY($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"Compression_Linearity_Gap_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional conviction by combining intraday price compression, multi-day trend linearity, and overnight price gaps. Compression (low range relative to volume) indicates potential energy, linearity (R-squared of close prices) measures trend quality, and gaps validate institutional momentum.",
      "factor_formulation": "Factor = ZSCORE(INV(TS\\_MEAN(\\frac{high-low}{volume}, 5))) \\times ZSCORE(POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)) \\times ZSCORE(TS\\_MEAN(ABS(open - DELAY(close, 1)), 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "234cd24aa5f7",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Compression-Linearity Convergence' factor, defined as the product of the 5-day average intraday price range (normalized by volume) and the 10-day price trend linearity (R-squared), further scaled by the 5-day average overnight gap, identifies high-conviction institutional moves by filtering volatility-compressed breakouts with structural trend persistence.\n                Concise Observation: Parent 1 showed that intraday compression precedes breakouts (RankIC 0.023), while Parent 2 demonstrated that trend linearity and overnight gaps validate institutional conviction (RankIC 0.022); however, both suffer from false signals during high-volatility regime shifts.\n                Concise Justification: Combining compression (a lead indicator of potential energy) with linearity (a lag indicator of trend quality) creates a robust signal that requires both the 'spring-loading' effect of tight price action and the 'confirmation' of smooth, gap-supported price appreciation.\n                Concise Knowledge: If intraday price compression (low range relative to volume) coincides with high multi-day trend linearity and positive overnight gaps, then the resulting price move is more likely to be a sustainable institutional trend rather than retail-driven noise.\n                concise Specification: The factor is calculated as (1 / (5-day mean of ($high-$low)/$volume)) * (10-day R-squared of $close) * (5-day mean of abs($open - prev($close))), where all components are z-scored cross-sectionally to ensure comparability before multiplication.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:45:11.105077"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2427164450182771,
        "ICIR": 0.0118610679434706,
        "1day.excess_return_without_cost.std": 0.0049329925577491,
        "1day.excess_return_with_cost.annualized_return": -0.0373709219758495,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 4.1685731250235045e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0099212040375559,
        "1day.excess_return_with_cost.std": 0.0049343202415021,
        "Rank IC": 0.014115807765147,
        "IC": 0.0016385478602289,
        "1day.excess_return_without_cost.max_drawdown": -0.1780119199572636,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.1303663308626373,
        "1day.pa": 0.0,
        "l2.valid": 0.9967388799168068,
        "Rank ICIR": 0.1038116395712271,
        "l2.train": 0.99341317274491,
        "1day.excess_return_with_cost.information_ratio": -0.4909282249979919,
        "1day.excess_return_with_cost.mean": -0.0001570206805707
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Institutional Compression-Linearity Convergence' hypothesis. The results show a significant performance gap compared to the SOTA result. The 'Compression_Linearity_Gap_Factor' (the most complex implementation) achieved an IC of 0.0016 and an Information Ratio of 0.13, which are substantially lower than the SOTA's IR of 0.97. The use of multiplicative Z-scores in the first and third factors likely created extreme outliers or neutralized the signals, as Z-scores centered around zero can lead to sign-flipping issues when multiplied. Furthermore, the 'Institutional_Spring_Load_Factor' attempted a simpler additive approach with RANK, but the overall framework still lacks the predictive power captured by the current SOTA.",
        "hypothesis_evaluation": "The hypothesis that multiplying intraday compression, linearity, and overnight gaps identifies institutional conviction is not strongly supported by the current results. The multiplicative interaction of three distinct statistical properties (volatility, correlation, and gap) appears too restrictive or noisy. Specifically, the 'Compression' component (high-low/volume) might be better represented as a regime filter rather than a linear multiplier. The 'Linearity' (R-squared) component, while theoretically sound, may be redundant if the price trend itself is not strong enough.",
        "decision": false,
        "reason": "1. Multiplicative Z-scores are unstable because values near zero or negative values (if not handled) distort the combined signal. 2. The previous 'Compression' variable (high-low/volume) might be too noisy; replacing it with a simpler 'Trend Consistency' measure (Price/Moving Average) or focusing on the Gap's relationship with Trend Linearity should be more effective. 3. Using RANK instead of Z-SCORE for the components before adding them (rather than multiplying) will provide a more uniform distribution and reduce the impact of extreme price movements, which is critical for the stability of the Information Ratio."
      }
    },
    "d7428391239d524c": {
      "factor_id": "d7428391239d524c",
      "factor_name": "Institutional_Spring_Load_Factor",
      "factor_expression": "RANK(INV(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8))) + RANK(TS_CORR($close, SEQUENCE(10), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(INV(TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8))) + RANK(TS_CORR($close, SEQUENCE(10), 10))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Spring_Load_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the institutional conviction hypothesis focusing on the interaction between price range tightness (relative to volume) and the consistency of the current trend. It uses the inverse of the range-to-volume ratio to capture 'spring-loading' and the correlation of price with time to capture linearity.",
      "factor_formulation": "Factor = RANK(INV(TS\\_MEAN(high - low, 5) / (TS\\_MEAN(volume, 5) + 1e-8))) + RANK(TS\\_CORR(close, SEQUENCE(10), 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "234cd24aa5f7",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Compression-Linearity Convergence' factor, defined as the product of the 5-day average intraday price range (normalized by volume) and the 10-day price trend linearity (R-squared), further scaled by the 5-day average overnight gap, identifies high-conviction institutional moves by filtering volatility-compressed breakouts with structural trend persistence.\n                Concise Observation: Parent 1 showed that intraday compression precedes breakouts (RankIC 0.023), while Parent 2 demonstrated that trend linearity and overnight gaps validate institutional conviction (RankIC 0.022); however, both suffer from false signals during high-volatility regime shifts.\n                Concise Justification: Combining compression (a lead indicator of potential energy) with linearity (a lag indicator of trend quality) creates a robust signal that requires both the 'spring-loading' effect of tight price action and the 'confirmation' of smooth, gap-supported price appreciation.\n                Concise Knowledge: If intraday price compression (low range relative to volume) coincides with high multi-day trend linearity and positive overnight gaps, then the resulting price move is more likely to be a sustainable institutional trend rather than retail-driven noise.\n                concise Specification: The factor is calculated as (1 / (5-day mean of ($high-$low)/$volume)) * (10-day R-squared of $close) * (5-day mean of abs($open - prev($close))), where all components are z-scored cross-sectionally to ensure comparability before multiplication.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:45:11.105077"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2427164450182771,
        "ICIR": 0.0118610679434706,
        "1day.excess_return_without_cost.std": 0.0049329925577491,
        "1day.excess_return_with_cost.annualized_return": -0.0373709219758495,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 4.1685731250235045e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0099212040375559,
        "1day.excess_return_with_cost.std": 0.0049343202415021,
        "Rank IC": 0.014115807765147,
        "IC": 0.0016385478602289,
        "1day.excess_return_without_cost.max_drawdown": -0.1780119199572636,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.1303663308626373,
        "1day.pa": 0.0,
        "l2.valid": 0.9967388799168068,
        "Rank ICIR": 0.1038116395712271,
        "l2.train": 0.99341317274491,
        "1day.excess_return_with_cost.information_ratio": -0.4909282249979919,
        "1day.excess_return_with_cost.mean": -0.0001570206805707
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Institutional Compression-Linearity Convergence' hypothesis. The results show a significant performance gap compared to the SOTA result. The 'Compression_Linearity_Gap_Factor' (the most complex implementation) achieved an IC of 0.0016 and an Information Ratio of 0.13, which are substantially lower than the SOTA's IR of 0.97. The use of multiplicative Z-scores in the first and third factors likely created extreme outliers or neutralized the signals, as Z-scores centered around zero can lead to sign-flipping issues when multiplied. Furthermore, the 'Institutional_Spring_Load_Factor' attempted a simpler additive approach with RANK, but the overall framework still lacks the predictive power captured by the current SOTA.",
        "hypothesis_evaluation": "The hypothesis that multiplying intraday compression, linearity, and overnight gaps identifies institutional conviction is not strongly supported by the current results. The multiplicative interaction of three distinct statistical properties (volatility, correlation, and gap) appears too restrictive or noisy. Specifically, the 'Compression' component (high-low/volume) might be better represented as a regime filter rather than a linear multiplier. The 'Linearity' (R-squared) component, while theoretically sound, may be redundant if the price trend itself is not strong enough.",
        "decision": false,
        "reason": "1. Multiplicative Z-scores are unstable because values near zero or negative values (if not handled) distort the combined signal. 2. The previous 'Compression' variable (high-low/volume) might be too noisy; replacing it with a simpler 'Trend Consistency' measure (Price/Moving Average) or focusing on the Gap's relationship with Trend Linearity should be more effective. 3. Using RANK instead of Z-SCORE for the components before adding them (rather than multiplying) will provide a more uniform distribution and reduce the impact of extreme price movements, which is critical for the stability of the Information Ratio."
      }
    },
    "688338cdf1d5178b": {
      "factor_id": "688338cdf1d5178b",
      "factor_name": "Linear_Gap_Momentum_Factor",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS($open - DELAY($close, 1)), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * ZSCORE(TS_MEAN(ABS($open - DELAY($close, 1)), 5))\" # Your output factor expression will be filled in here\n    name = \"Linear_Gap_Momentum_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures institutional 'conviction' by multiplying the 10-day price linearity (R-squared) with the 5-day average magnitude of overnight gaps, normalized cross-sectionally to identify stocks with the most structural and gap-supported trends.",
      "factor_formulation": "Factor = ZSCORE(POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)) * ZSCORE(TS\\_MEAN(ABS(open - DELAY(close, 1)), 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "234cd24aa5f7",
        "parent_trajectory_ids": [
          "96deba3b9e1b",
          "6c51fa834c71"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Compression-Linearity Convergence' factor, defined as the product of the 5-day average intraday price range (normalized by volume) and the 10-day price trend linearity (R-squared), further scaled by the 5-day average overnight gap, identifies high-conviction institutional moves by filtering volatility-compressed breakouts with structural trend persistence.\n                Concise Observation: Parent 1 showed that intraday compression precedes breakouts (RankIC 0.023), while Parent 2 demonstrated that trend linearity and overnight gaps validate institutional conviction (RankIC 0.022); however, both suffer from false signals during high-volatility regime shifts.\n                Concise Justification: Combining compression (a lead indicator of potential energy) with linearity (a lag indicator of trend quality) creates a robust signal that requires both the 'spring-loading' effect of tight price action and the 'confirmation' of smooth, gap-supported price appreciation.\n                Concise Knowledge: If intraday price compression (low range relative to volume) coincides with high multi-day trend linearity and positive overnight gaps, then the resulting price move is more likely to be a sustainable institutional trend rather than retail-driven noise.\n                concise Specification: The factor is calculated as (1 / (5-day mean of ($high-$low)/$volume)) * (10-day R-squared of $close) * (5-day mean of abs($open - prev($close))), where all components are z-scored cross-sectionally to ensure comparability before multiplication.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:45:11.105077"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2427164450182771,
        "ICIR": 0.0118610679434706,
        "1day.excess_return_without_cost.std": 0.0049329925577491,
        "1day.excess_return_with_cost.annualized_return": -0.0373709219758495,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 4.1685731250235045e-05,
        "1day.excess_return_without_cost.annualized_return": 0.0099212040375559,
        "1day.excess_return_with_cost.std": 0.0049343202415021,
        "Rank IC": 0.014115807765147,
        "IC": 0.0016385478602289,
        "1day.excess_return_without_cost.max_drawdown": -0.1780119199572636,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.1303663308626373,
        "1day.pa": 0.0,
        "l2.valid": 0.9967388799168068,
        "Rank ICIR": 0.1038116395712271,
        "l2.train": 0.99341317274491,
        "1day.excess_return_with_cost.information_ratio": -0.4909282249979919,
        "1day.excess_return_with_cost.mean": -0.0001570206805707
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the 'Institutional Compression-Linearity Convergence' hypothesis. The results show a significant performance gap compared to the SOTA result. The 'Compression_Linearity_Gap_Factor' (the most complex implementation) achieved an IC of 0.0016 and an Information Ratio of 0.13, which are substantially lower than the SOTA's IR of 0.97. The use of multiplicative Z-scores in the first and third factors likely created extreme outliers or neutralized the signals, as Z-scores centered around zero can lead to sign-flipping issues when multiplied. Furthermore, the 'Institutional_Spring_Load_Factor' attempted a simpler additive approach with RANK, but the overall framework still lacks the predictive power captured by the current SOTA.",
        "hypothesis_evaluation": "The hypothesis that multiplying intraday compression, linearity, and overnight gaps identifies institutional conviction is not strongly supported by the current results. The multiplicative interaction of three distinct statistical properties (volatility, correlation, and gap) appears too restrictive or noisy. Specifically, the 'Compression' component (high-low/volume) might be better represented as a regime filter rather than a linear multiplier. The 'Linearity' (R-squared) component, while theoretically sound, may be redundant if the price trend itself is not strong enough.",
        "decision": false,
        "reason": "1. Multiplicative Z-scores are unstable because values near zero or negative values (if not handled) distort the combined signal. 2. The previous 'Compression' variable (high-low/volume) might be too noisy; replacing it with a simpler 'Trend Consistency' measure (Price/Moving Average) or focusing on the Gap's relationship with Trend Linearity should be more effective. 3. Using RANK instead of Z-SCORE for the components before adding them (rather than multiplying) will provide a more uniform distribution and reduce the impact of extreme price movements, which is critical for the stability of the Information Ratio."
      }
    },
    "e65d5b00dd96d2c5": {
      "factor_id": "e65d5b00dd96d2c5",
      "factor_name": "IFM_Floor_Momentum_5D",
      "factor_expression": "(TS_MEAN($low - MIN($open, $close), 5) / (TS_STD($volume, 5) + 1e-8)) * (LOG($open / (DELAY($close, 1) + 1e-8)) * TS_CORR(SEQUENCE(10), $close, 10)) / (1 + ABS(TS_CORR($close, $volume, 5)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(($low - ($open < $close ? $open : $close)), 5) / (TS_STD($volume, 5) + 1e-8)) * (LOG($open / DELAY($close, 1)) * TS_CORR($close, SEQUENCE(10), 10)) / (1 + ABS(TS_CORR($close, $volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"IFM_Floor_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor implements the Institutional Floor-to-Momentum (IFM) logic. It identifies price floors using volume-stabilized lower shadows (Support Integrity) and combines it with institutional entry signals (Overnight Gap and Price Linearity). It includes a penalty for price-volume convexity to avoid late-stage trend exhaustion.",
      "factor_formulation": "IFM = \\frac{TS\\_MEAN(low - MIN(open, close), 5)}{TS\\_STD(volume, 5) + 1e-8} \\times \\frac{LOG(open / DELAY(close, 1)) \\times TS\\_CORR(SEQUENCE(10), close, 10)}{1 + ABS(TS\\_CORR(close, volume, 5))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ebb03560fc20",
        "parent_trajectory_ids": [
          "810ec4913f1e",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Floor-to-Momentum' (IFM) factor identifies superior returns by multiplying the 5-day Support Integrity (average lower shadow length divided by volume standard deviation) with the 5-day Institutional Momentum (overnight gap multiplied by price linearity), penalizing late-stage exhaustion via price-volume convexity.\n                Concise Observation: Parent 1 (RankIC 0.0216) successfully identifies price floors through volume-stabilized shadows, while Parent 2 (RankIC 0.0230) captures institutional entry via gaps, but both individually lack a mechanism to distinguish between the start of a trend and its exhaustion phase.\n                Concise Justification: Combining these signals creates a conditional entry logic where momentum is only validated if a 'support floor' exists, while the volume-price convexity penalty prevents buying into overextended trends where liquidity is drying up.\n                Concise Knowledge: If a stock exhibits high price-floor integrity through consistent lower shadows and low volume volatility, it serves as a stable base; when this base is coupled with institutional gap-driven momentum and low price-volume convexity, the probability of a sustainable trend initiation increases.\n                concise Specification: The factor is defined as (Mean(($low - Min($open, $close)), 5) / Std($volume, 5)) * (Log($open / Delay($close, 1)) * Correlation(Sequence(10), $close, 10)) / (1 + Abs(Correlation($close, $volume, 5))), using 5-day and 10-day lookback windows.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:57:22.722909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2937071183417236,
        "ICIR": 0.0255317309470804,
        "1day.excess_return_without_cost.std": 0.0055112905593325,
        "1day.excess_return_with_cost.annualized_return": -0.019874405038312,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001195351766009,
        "1day.excess_return_without_cost.annualized_return": 0.0284493720310234,
        "1day.excess_return_with_cost.std": 0.0055129131799702,
        "Rank IC": 0.0174765846482413,
        "IC": 0.0040485815666102,
        "1day.excess_return_without_cost.max_drawdown": -0.2398133124607414,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3346038225475707,
        "1day.pa": 0.0,
        "l2.valid": 0.9965235861241476,
        "Rank ICIR": 0.1079046384802812,
        "l2.train": 0.9936130302867046,
        "1day.excess_return_with_cost.information_ratio": -0.233681593173345,
        "1day.excess_return_with_cost.mean": -8.350590352231955e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Floor-to-Momentum' (IFM) hypothesis. While the factors were successfully implemented, the combined performance metrics (Annualized Return: 0.028, IR: 0.33, IC: 0.004) significantly underperform compared to the current SOTA (Annualized Return: 0.052, IR: 0.97, IC: 0.005). The Max Drawdown is also notably higher (-0.239 vs -0.072), suggesting that the current formulation of 'Support Integrity' and 'Institutional Momentum' is capturing significant noise or is poorly timed.",
        "hypothesis_evaluation": "The hypothesis that multiplying Support Integrity by Institutional Momentum creates a superior signal is not supported by the current results. The 'Support Integrity' component (lower shadow / volume volatility) might be too sensitive to idiosyncratic noise, and the 'Price-Volume Convexity' penalty (1 + ABS(CORR)) may be dampening valid momentum signals too aggressively. The complexity of the IFM_Floor_Momentum_5D factor (using 4 raw features and multiple rolling windows) might be leading to poor generalization.",
        "decision": false,
        "reason": "The current multiplicative interaction between the floor and momentum components likely compounds the estimation errors of both. By using a 'Support Stability' measure (standard deviation of the low-to-close distance) and conditioning it on volume surges, we can identify high-conviction institutional floors. Simplifying the momentum component to a 3-day window will also reduce the lag observed in the current 5-day and 10-day versions, potentially improving the Information Ratio and reducing Drawdown."
      }
    },
    "3dbeb6a0794828e7": {
      "factor_id": "3dbeb6a0794828e7",
      "factor_name": "Support_Integrity_ZScore_10D",
      "factor_expression": "ZSCORE(TS_MEAN($low - MIN($open, $close), 10) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($low - MIN($open, $close), 10) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Support_Integrity_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified component of the IFM hypothesis focusing on the 'Support Floor'. It measures the magnitude of lower shadows relative to volume volatility, cross-sectionally standardized to identify stocks with the most stable price floors.",
      "factor_formulation": "SI = ZSCORE(\\frac{TS\\_MEAN(low - MIN(open, close), 10)}{TS\\_STD(volume, 10) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ebb03560fc20",
        "parent_trajectory_ids": [
          "810ec4913f1e",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Floor-to-Momentum' (IFM) factor identifies superior returns by multiplying the 5-day Support Integrity (average lower shadow length divided by volume standard deviation) with the 5-day Institutional Momentum (overnight gap multiplied by price linearity), penalizing late-stage exhaustion via price-volume convexity.\n                Concise Observation: Parent 1 (RankIC 0.0216) successfully identifies price floors through volume-stabilized shadows, while Parent 2 (RankIC 0.0230) captures institutional entry via gaps, but both individually lack a mechanism to distinguish between the start of a trend and its exhaustion phase.\n                Concise Justification: Combining these signals creates a conditional entry logic where momentum is only validated if a 'support floor' exists, while the volume-price convexity penalty prevents buying into overextended trends where liquidity is drying up.\n                Concise Knowledge: If a stock exhibits high price-floor integrity through consistent lower shadows and low volume volatility, it serves as a stable base; when this base is coupled with institutional gap-driven momentum and low price-volume convexity, the probability of a sustainable trend initiation increases.\n                concise Specification: The factor is defined as (Mean(($low - Min($open, $close)), 5) / Std($volume, 5)) * (Log($open / Delay($close, 1)) * Correlation(Sequence(10), $close, 10)) / (1 + Abs(Correlation($close, $volume, 5))), using 5-day and 10-day lookback windows.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:57:22.722909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2937071183417236,
        "ICIR": 0.0255317309470804,
        "1day.excess_return_without_cost.std": 0.0055112905593325,
        "1day.excess_return_with_cost.annualized_return": -0.019874405038312,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001195351766009,
        "1day.excess_return_without_cost.annualized_return": 0.0284493720310234,
        "1day.excess_return_with_cost.std": 0.0055129131799702,
        "Rank IC": 0.0174765846482413,
        "IC": 0.0040485815666102,
        "1day.excess_return_without_cost.max_drawdown": -0.2398133124607414,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3346038225475707,
        "1day.pa": 0.0,
        "l2.valid": 0.9965235861241476,
        "Rank ICIR": 0.1079046384802812,
        "l2.train": 0.9936130302867046,
        "1day.excess_return_with_cost.information_ratio": -0.233681593173345,
        "1day.excess_return_with_cost.mean": -8.350590352231955e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Floor-to-Momentum' (IFM) hypothesis. While the factors were successfully implemented, the combined performance metrics (Annualized Return: 0.028, IR: 0.33, IC: 0.004) significantly underperform compared to the current SOTA (Annualized Return: 0.052, IR: 0.97, IC: 0.005). The Max Drawdown is also notably higher (-0.239 vs -0.072), suggesting that the current formulation of 'Support Integrity' and 'Institutional Momentum' is capturing significant noise or is poorly timed.",
        "hypothesis_evaluation": "The hypothesis that multiplying Support Integrity by Institutional Momentum creates a superior signal is not supported by the current results. The 'Support Integrity' component (lower shadow / volume volatility) might be too sensitive to idiosyncratic noise, and the 'Price-Volume Convexity' penalty (1 + ABS(CORR)) may be dampening valid momentum signals too aggressively. The complexity of the IFM_Floor_Momentum_5D factor (using 4 raw features and multiple rolling windows) might be leading to poor generalization.",
        "decision": false,
        "reason": "The current multiplicative interaction between the floor and momentum components likely compounds the estimation errors of both. By using a 'Support Stability' measure (standard deviation of the low-to-close distance) and conditioning it on volume surges, we can identify high-conviction institutional floors. Simplifying the momentum component to a 3-day window will also reduce the lag observed in the current 5-day and 10-day versions, potentially improving the Information Ratio and reducing Drawdown."
      }
    },
    "4ff47e2dedb1d659": {
      "factor_id": "4ff47e2dedb1d659",
      "factor_name": "Inst_Momentum_Convexity_Adj_5D",
      "factor_expression": "(LOG($open / (DELAY($close, 1) + 1e-8)) * TS_CORR(SEQUENCE(5), $close, 5)) / (1 + ABS(TS_CORR($close, $volume, 5)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(LOG($open / DELAY($close, 1)) * REGBETA($close, SEQUENCE(5), 5)) / (1 + ABS(TS_CORR($close, $volume, 5)))\" # Your output factor expression will be filled in here\n    name = \"Inst_Momentum_Convexity_Adj_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures institutional momentum via overnight gaps and price linearity, adjusted by the inverse of price-volume correlation to penalize high-volume blow-off tops (exhaustion).",
      "factor_formulation": "IMC = \\frac{LOG(open / DELAY(close, 1)) \\times TS\\_CORR(SEQUENCE(5), close, 5)}{1 + ABS(TS\\_CORR(close, volume, 5))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "ebb03560fc20",
        "parent_trajectory_ids": [
          "810ec4913f1e",
          "b0fce848934c"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Floor-to-Momentum' (IFM) factor identifies superior returns by multiplying the 5-day Support Integrity (average lower shadow length divided by volume standard deviation) with the 5-day Institutional Momentum (overnight gap multiplied by price linearity), penalizing late-stage exhaustion via price-volume convexity.\n                Concise Observation: Parent 1 (RankIC 0.0216) successfully identifies price floors through volume-stabilized shadows, while Parent 2 (RankIC 0.0230) captures institutional entry via gaps, but both individually lack a mechanism to distinguish between the start of a trend and its exhaustion phase.\n                Concise Justification: Combining these signals creates a conditional entry logic where momentum is only validated if a 'support floor' exists, while the volume-price convexity penalty prevents buying into overextended trends where liquidity is drying up.\n                Concise Knowledge: If a stock exhibits high price-floor integrity through consistent lower shadows and low volume volatility, it serves as a stable base; when this base is coupled with institutional gap-driven momentum and low price-volume convexity, the probability of a sustainable trend initiation increases.\n                concise Specification: The factor is defined as (Mean(($low - Min($open, $close)), 5) / Std($volume, 5)) * (Log($open / Delay($close, 1)) * Correlation(Sequence(10), $close, 10)) / (1 + Abs(Correlation($close, $volume, 5))), using 5-day and 10-day lookback windows.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T07:57:22.722909"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2937071183417236,
        "ICIR": 0.0255317309470804,
        "1day.excess_return_without_cost.std": 0.0055112905593325,
        "1day.excess_return_with_cost.annualized_return": -0.019874405038312,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001195351766009,
        "1day.excess_return_without_cost.annualized_return": 0.0284493720310234,
        "1day.excess_return_with_cost.std": 0.0055129131799702,
        "Rank IC": 0.0174765846482413,
        "IC": 0.0040485815666102,
        "1day.excess_return_without_cost.max_drawdown": -0.2398133124607414,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3346038225475707,
        "1day.pa": 0.0,
        "l2.valid": 0.9965235861241476,
        "Rank ICIR": 0.1079046384802812,
        "l2.train": 0.9936130302867046,
        "1day.excess_return_with_cost.information_ratio": -0.233681593173345,
        "1day.excess_return_with_cost.mean": -8.350590352231955e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Floor-to-Momentum' (IFM) hypothesis. While the factors were successfully implemented, the combined performance metrics (Annualized Return: 0.028, IR: 0.33, IC: 0.004) significantly underperform compared to the current SOTA (Annualized Return: 0.052, IR: 0.97, IC: 0.005). The Max Drawdown is also notably higher (-0.239 vs -0.072), suggesting that the current formulation of 'Support Integrity' and 'Institutional Momentum' is capturing significant noise or is poorly timed.",
        "hypothesis_evaluation": "The hypothesis that multiplying Support Integrity by Institutional Momentum creates a superior signal is not supported by the current results. The 'Support Integrity' component (lower shadow / volume volatility) might be too sensitive to idiosyncratic noise, and the 'Price-Volume Convexity' penalty (1 + ABS(CORR)) may be dampening valid momentum signals too aggressively. The complexity of the IFM_Floor_Momentum_5D factor (using 4 raw features and multiple rolling windows) might be leading to poor generalization.",
        "decision": false,
        "reason": "The current multiplicative interaction between the floor and momentum components likely compounds the estimation errors of both. By using a 'Support Stability' measure (standard deviation of the low-to-close distance) and conditioning it on volume surges, we can identify high-conviction institutional floors. Simplifying the momentum component to a 3-day window will also reduce the lag observed in the current 5-day and 10-day versions, potentially improving the Information Ratio and reducing Drawdown."
      }
    },
    "ec31e5d5cf4e0de2": {
      "factor_id": "ec31e5d5cf4e0de2",
      "factor_name": "LSSR_MeanReversion_5D",
      "factor_expression": "REGRESI($close, $volume, 5) * (($open / (DELAY($close, 1) + 1e-8)) - 1) / ((TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8) * (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGRESI($close, $volume, 5) * (($open / DELAY($close, 1)) - 1) / ((TS_MEAN(ABS(($close / DELAY($close, 1)) - 1) / ($volume + 1e-8), 5) + 1e-8) * (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LSSR_MeanReversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor implements the Liquidity-Synchronized Sentiment Reversion (LSSR) hypothesis. It identifies mean-reversion opportunities by combining price-volume regression residuals (exhaustion) with overnight gaps normalized by Amihud illiquidity. It uses a 5-day window for the residual and illiquidity, and scales the result by the inverse of volume volatility to filter out structural breakdowns.",
      "factor_formulation": "\\text{Residual} = \\text{REGRESI}(\\text{close}, \\text{volume}, 5), \\quad \\text{Illiq} = \\text{TS_MEAN}(\\frac{|\\text{return}|}{\\text{volume}}, 5), \\quad \\text{Gap} = \\frac{\\text{open}}{\\text{delay(close, 1)}} - 1, \\quad \\text{LSSR} = \\frac{\\text{Residual} \\times \\text{Gap}}{(\\text{Illiq} + 1e-8) \\times (\\text{TS_STD}(\\text{volume}, 5) + 1e-8)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "8b7d84d81054",
        "parent_trajectory_ids": [
          "6d5da9c21f8a",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Synchronized Sentiment Reversion' (LSSR) factor predicts that mean-reversion is strongest when a 5-day negative price-volume regression residual (Parent 1) coincides with a high overnight gap relative to 5-day Amihud illiquidity (Parent 2), particularly under conditions of low volume volatility.\n                Concise Observation: Parent 1 successfully used regression residuals to find rebounds but lacked sentiment context, while Parent 2 used overnight gaps and illiquidity to capture sentiment efficiency but ignored the price-volume trend exhaustion found in Parent 1.\n                Concise Justification: By combining the residual-based rebound signal with the illiquidity-normalized sentiment gap, the factor filters out structural breakdowns (high volume volatility) and focuses on temporary liquidity-driven mispricing where sentiment and volume trends have reached a divergence point.\n                Concise Knowledge: If price-volume exhaustion (negative residuals) occurs alongside sentiment-driven overnight gaps in a low-volatility liquidity environment, then the probability of a corrective mean-reversion increases; high Amihud illiquidity values should discount the reliability of sentiment gaps to avoid 'liquidity traps'.\n                concise Specification: The factor is calculated as the product of the negative 5-day Close-Volume regression residual and the ratio of the Overnight Gap (Open/PrevClose - 1) to the 5-day Average Amihud Illiquidity (abs(Return)/Volume), scaled by the inverse of 5-day volume volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T08:03:28.023646"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.136030100653358,
        "ICIR": 0.0320827470837739,
        "1day.excess_return_without_cost.std": 0.0044511747550375,
        "1day.excess_return_with_cost.annualized_return": 0.0061809088630717,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002234581994246,
        "1day.excess_return_without_cost.annualized_return": 0.053183051463073,
        "1day.excess_return_with_cost.std": 0.0044535424569688,
        "Rank IC": 0.0198524726828561,
        "IC": 0.0042300484883422,
        "1day.excess_return_without_cost.max_drawdown": -0.1195191064638961,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7744798594846346,
        "1day.pa": 0.0,
        "l2.valid": 0.996483087913785,
        "Rank ICIR": 0.1521945500178176,
        "l2.train": 0.9939617153458286,
        "1day.excess_return_with_cost.information_ratio": 0.0899618265390159,
        "1day.excess_return_with_cost.mean": 2.5970205307024315e-05
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Liquidity-Synchronized Sentiment Reversion' (LSSR) hypothesis. The 'LSSR_Ranked_Exhaustion_10D' variation (Current Result) achieved a higher annualized return (5.32% vs 5.20%) compared to the SOTA, although it suffered from a significant increase in Max Drawdown (-0.1195 vs -0.0726) and a lower Information Ratio (0.774 vs 0.973). The IC also dropped from 0.0058 to 0.0042. This suggests that while the ranked approach and longer lookback windows (10-day) captured higher absolute returns, they introduced substantial volatility and reduced the consistency of the signal.",
        "hypothesis_evaluation": "The hypothesis that mean-reversion is strongest when price-volume residuals coincide with liquidity-adjusted gaps is partially supported by the positive annualized return. However, the deterioration in IR and IC suggests that the current mathematical representation—specifically the interaction between the ranked residual and the Z-scored gap—might be too noisy. The 10-day window for volume volatility and illiquidity appears to provide a more stable denominator but at the cost of signal timeliness.",
        "decision": true,
        "reason": "The current results show that increasing the lookback window improved annualized returns but hurt risk-adjusted metrics. By switching from a continuous multiplier to a conditional gate (e.g., using a sign-based interaction or focusing only on low-volatility regimes), we can reduce the noise introduced by the TS_STD and TS_MEAN denominators. Furthermore, simplifying the factor by using a 5-day window for all components (maintaining consistency) and replacing the complex regression residual with a simpler 'Volume-Weighted Price Momentum' might reduce the risk of overfitting indicated by the lower IC."
      }
    },
    "14324abd8f40bcd8": {
      "factor_id": "14324abd8f40bcd8",
      "factor_name": "LSSR_Ranked_Exhaustion_10D",
      "factor_expression": "RANK(REGRESI($close, $volume, 5)) * ZSCORE(($open / (DELAY($close, 1) + 1e-8)) - 1) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 10) * TS_STD($volume, 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, $volume, 5)) * ZSCORE(($open / DELAY($close, 1)) - 1) / (TS_MEAN(ABS(($close / DELAY($close, 1)) - 1) / ($volume + 1e-8), 10) * TS_STD($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"LSSR_Ranked_Exhaustion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A robust variation of the LSSR hypothesis focusing on the cross-sectional rank of price-volume exhaustion and liquidity-adjusted sentiment. It uses a 10-day window for volume volatility and illiquidity to ensure signal stability, and applies Z-scoring to the overnight gap to capture extreme sentiment relative to the market.",
      "factor_formulation": "\\text{LSSR_Ranked} = \\text{RANK}(\\text{REGRESI}(\\text{close}, \\text{volume}, 5)) \\times \\frac{\\text{ZSCORE}(\\text{open}/\\text{delay(close, 1)} - 1)}{\\text{TS_MEAN}(\\text{Illiq}, 10) \\times \\text{TS_STD}(\\text{volume}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "8b7d84d81054",
        "parent_trajectory_ids": [
          "6d5da9c21f8a",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Synchronized Sentiment Reversion' (LSSR) factor predicts that mean-reversion is strongest when a 5-day negative price-volume regression residual (Parent 1) coincides with a high overnight gap relative to 5-day Amihud illiquidity (Parent 2), particularly under conditions of low volume volatility.\n                Concise Observation: Parent 1 successfully used regression residuals to find rebounds but lacked sentiment context, while Parent 2 used overnight gaps and illiquidity to capture sentiment efficiency but ignored the price-volume trend exhaustion found in Parent 1.\n                Concise Justification: By combining the residual-based rebound signal with the illiquidity-normalized sentiment gap, the factor filters out structural breakdowns (high volume volatility) and focuses on temporary liquidity-driven mispricing where sentiment and volume trends have reached a divergence point.\n                Concise Knowledge: If price-volume exhaustion (negative residuals) occurs alongside sentiment-driven overnight gaps in a low-volatility liquidity environment, then the probability of a corrective mean-reversion increases; high Amihud illiquidity values should discount the reliability of sentiment gaps to avoid 'liquidity traps'.\n                concise Specification: The factor is calculated as the product of the negative 5-day Close-Volume regression residual and the ratio of the Overnight Gap (Open/PrevClose - 1) to the 5-day Average Amihud Illiquidity (abs(Return)/Volume), scaled by the inverse of 5-day volume volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T08:03:28.023646"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.136030100653358,
        "ICIR": 0.0320827470837739,
        "1day.excess_return_without_cost.std": 0.0044511747550375,
        "1day.excess_return_with_cost.annualized_return": 0.0061809088630717,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002234581994246,
        "1day.excess_return_without_cost.annualized_return": 0.053183051463073,
        "1day.excess_return_with_cost.std": 0.0044535424569688,
        "Rank IC": 0.0198524726828561,
        "IC": 0.0042300484883422,
        "1day.excess_return_without_cost.max_drawdown": -0.1195191064638961,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7744798594846346,
        "1day.pa": 0.0,
        "l2.valid": 0.996483087913785,
        "Rank ICIR": 0.1521945500178176,
        "l2.train": 0.9939617153458286,
        "1day.excess_return_with_cost.information_ratio": 0.0899618265390159,
        "1day.excess_return_with_cost.mean": 2.5970205307024315e-05
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Liquidity-Synchronized Sentiment Reversion' (LSSR) hypothesis. The 'LSSR_Ranked_Exhaustion_10D' variation (Current Result) achieved a higher annualized return (5.32% vs 5.20%) compared to the SOTA, although it suffered from a significant increase in Max Drawdown (-0.1195 vs -0.0726) and a lower Information Ratio (0.774 vs 0.973). The IC also dropped from 0.0058 to 0.0042. This suggests that while the ranked approach and longer lookback windows (10-day) captured higher absolute returns, they introduced substantial volatility and reduced the consistency of the signal.",
        "hypothesis_evaluation": "The hypothesis that mean-reversion is strongest when price-volume residuals coincide with liquidity-adjusted gaps is partially supported by the positive annualized return. However, the deterioration in IR and IC suggests that the current mathematical representation—specifically the interaction between the ranked residual and the Z-scored gap—might be too noisy. The 10-day window for volume volatility and illiquidity appears to provide a more stable denominator but at the cost of signal timeliness.",
        "decision": true,
        "reason": "The current results show that increasing the lookback window improved annualized returns but hurt risk-adjusted metrics. By switching from a continuous multiplier to a conditional gate (e.g., using a sign-based interaction or focusing only on low-volatility regimes), we can reduce the noise introduced by the TS_STD and TS_MEAN denominators. Furthermore, simplifying the factor by using a 5-day window for all components (maintaining consistency) and replacing the complex regression residual with a simpler 'Volume-Weighted Price Momentum' might reduce the risk of overfitting indicated by the lower IC."
      }
    },
    "3976c81be049a612": {
      "factor_id": "3976c81be049a612",
      "factor_name": "Inst_Absorp_Eff_20D",
      "factor_expression": "(($close / DELAY($open, 1) - 1) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8)) * (($close / DELAY($close, 20) - 1) / (TS_STD($volume, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close / DELAY($open, 1) - 1) / (TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5) + 1e-8)) * (TS_PCTCHANGE($close, 20) / (TS_STD($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Inst_Absorp_Eff_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction institutional trends by combining a liquidity-adjusted overnight sentiment gap with a volume-stability momentum filter. It captures stocks where price gaps are validated by high liquidity and subsequent momentum occurs with low volume volatility, indicating steady accumulation.",
      "factor_formulation": "\\left( \\frac{\\text{close} / \\text{delay}(\\text{open}, 1) - 1}{\\text{TS_MEAN}(\\text{ABS}(\\text{return}) / \\text{volume}, 5)} \\right) \\times \\left( \\frac{\\text{close} / \\text{delay}(\\text{close}, 20) - 1}{\\text{TS_STD}(\\text{volume}, 10)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "530ed6f4b2d2",
        "parent_trajectory_ids": [
          "aa9b2953183f",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption Efficiency' factor, calculated as the product of the 5-day Liquidity-Adjusted Sentiment Gap (overnight return divided by the 5-day average Amihud illiquidity) and the 20-day Information Diffusion Velocity (20-day momentum divided by the 10-day volume volatility), identifies high-conviction price trends driven by institutional accumulation.\n                Concise Observation: Parent strategies show that overnight gaps are noisy without liquidity filters (Parent 2) and that long-term momentum requires a 'quiet' volume structure to avoid exhaustion (Parent 1).\n                Concise Justification: Combining liquidity-validated entry signals with volume-stability filters ensures that the factor captures the transition from initial sentiment shock to steady institutional accumulation, reducing exposure to mean-reverting speculative spikes.\n                Concise Knowledge: If an overnight sentiment shock occurs in a high-liquidity environment and is followed by price persistence with low volume volatility, then the price move is likely driven by institutional absorption rather than retail speculation; such trends are more sustainable than those accompanied by high volume churn.\n                concise Specification: The factor is defined as ( (Close/Open_prev - 1) / Mean(Abs(Return)/Volume, 5) ) * ( (Close/Close_20 - 1) / Std(Volume, 10) ). It targets stocks where price gaps are supported by liquidity and subsequent momentum is characterized by low volume variance over a 20-day horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T08:11:21.965713"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1927016863723594,
        "ICIR": 0.0344349606072184,
        "1day.excess_return_without_cost.std": 0.0059900139505468,
        "1day.excess_return_with_cost.annualized_return": 0.0100678354864385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002423777891882,
        "1day.excess_return_without_cost.annualized_return": 0.0576859138267945,
        "1day.excess_return_with_cost.std": 0.0059931338440877,
        "Rank IC": 0.0207161070156809,
        "IC": 0.0054590553878437,
        "1day.excess_return_without_cost.max_drawdown": -0.1585485911126347,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6242426887106604,
        "1day.pa": 0.0,
        "l2.valid": 0.9966175003528412,
        "Rank ICIR": 0.1315914393078261,
        "l2.train": 0.9936151080410176,
        "1day.excess_return_with_cost.information_ratio": 0.1088914184163937,
        "1day.excess_return_with_cost.mean": 4.230182977495171e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption Efficiency' framework. The primary factor 'Inst_Absorp_Eff_20D' and its components aimed to capture institutional accumulation through liquidity-adjusted sentiment and quiet momentum. The results show that while the Current Result achieved a higher Annualized Return (0.0577 vs 0.0520) compared to the SOTA, it suffered from significantly higher volatility and risk, as evidenced by the doubled Max Drawdown (-0.1585 vs -0.0726) and a lower Information Ratio (0.6242 vs 0.9726). The IC also slightly lagged behind the SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining overnight sentiment gaps (Amihud-adjusted) with 'quiet' momentum identifies high-conviction trends is partially supported by the improvement in raw annualized returns. However, the high drawdown suggests that the current formulation of 'Institutional Absorption' might be picking up high-beta or tail-risk events rather than steady institutional accumulation. The 'Information Diffusion Velocity' component (momentum divided by volume volatility) may be too sensitive to low-volume spikes, leading to instability.",
        "decision": true,
        "reason": "The current factor's high drawdown is likely due to the use of raw volume standard deviation in the denominator, which can create extreme values when volume is consistently low but slightly fluctuates. By using the Coefficient of Variation (TS_STD/TS_MEAN), we normalize the 'quietness' of the momentum. Furthermore, a 1-day overnight gap is highly susceptible to noise; averaging this gap over 3 days before dividing by the 5-day illiquidity should provide a more stable signal of institutional sentiment shift."
      }
    },
    "7352f8870f2f6d9c": {
      "factor_id": "7352f8870f2f6d9c",
      "factor_name": "Liquidity_Validated_Gap_Rank",
      "factor_expression": "RANK(($close / DELAY($open, 1) - 1) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($close / DELAY($open, 1)) - 1) / (TS_MEAN(ABS(($close / DELAY($close, 1)) - 1) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Validated_Gap_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Focuses on the first component of the hypothesis: the sentiment gap adjusted by liquidity. It ranks stocks based on the overnight return relative to the 5-day average Amihud illiquidity, identifying stocks where price shocks are easily absorbed by market liquidity.",
      "factor_formulation": "\\text{RANK}\\left( \\frac{\\text{close} / \\text{delay}(\\text{open}, 1) - 1}{\\text{TS_MEAN}(\\text{ABS}(\\text{return}) / \\text{volume}, 5)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "530ed6f4b2d2",
        "parent_trajectory_ids": [
          "aa9b2953183f",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption Efficiency' factor, calculated as the product of the 5-day Liquidity-Adjusted Sentiment Gap (overnight return divided by the 5-day average Amihud illiquidity) and the 20-day Information Diffusion Velocity (20-day momentum divided by the 10-day volume volatility), identifies high-conviction price trends driven by institutional accumulation.\n                Concise Observation: Parent strategies show that overnight gaps are noisy without liquidity filters (Parent 2) and that long-term momentum requires a 'quiet' volume structure to avoid exhaustion (Parent 1).\n                Concise Justification: Combining liquidity-validated entry signals with volume-stability filters ensures that the factor captures the transition from initial sentiment shock to steady institutional accumulation, reducing exposure to mean-reverting speculative spikes.\n                Concise Knowledge: If an overnight sentiment shock occurs in a high-liquidity environment and is followed by price persistence with low volume volatility, then the price move is likely driven by institutional absorption rather than retail speculation; such trends are more sustainable than those accompanied by high volume churn.\n                concise Specification: The factor is defined as ( (Close/Open_prev - 1) / Mean(Abs(Return)/Volume, 5) ) * ( (Close/Close_20 - 1) / Std(Volume, 10) ). It targets stocks where price gaps are supported by liquidity and subsequent momentum is characterized by low volume variance over a 20-day horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T08:11:21.965713"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1927016863723594,
        "ICIR": 0.0344349606072184,
        "1day.excess_return_without_cost.std": 0.0059900139505468,
        "1day.excess_return_with_cost.annualized_return": 0.0100678354864385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002423777891882,
        "1day.excess_return_without_cost.annualized_return": 0.0576859138267945,
        "1day.excess_return_with_cost.std": 0.0059931338440877,
        "Rank IC": 0.0207161070156809,
        "IC": 0.0054590553878437,
        "1day.excess_return_without_cost.max_drawdown": -0.1585485911126347,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6242426887106604,
        "1day.pa": 0.0,
        "l2.valid": 0.9966175003528412,
        "Rank ICIR": 0.1315914393078261,
        "l2.train": 0.9936151080410176,
        "1day.excess_return_with_cost.information_ratio": 0.1088914184163937,
        "1day.excess_return_with_cost.mean": 4.230182977495171e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption Efficiency' framework. The primary factor 'Inst_Absorp_Eff_20D' and its components aimed to capture institutional accumulation through liquidity-adjusted sentiment and quiet momentum. The results show that while the Current Result achieved a higher Annualized Return (0.0577 vs 0.0520) compared to the SOTA, it suffered from significantly higher volatility and risk, as evidenced by the doubled Max Drawdown (-0.1585 vs -0.0726) and a lower Information Ratio (0.6242 vs 0.9726). The IC also slightly lagged behind the SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining overnight sentiment gaps (Amihud-adjusted) with 'quiet' momentum identifies high-conviction trends is partially supported by the improvement in raw annualized returns. However, the high drawdown suggests that the current formulation of 'Institutional Absorption' might be picking up high-beta or tail-risk events rather than steady institutional accumulation. The 'Information Diffusion Velocity' component (momentum divided by volume volatility) may be too sensitive to low-volume spikes, leading to instability.",
        "decision": true,
        "reason": "The current factor's high drawdown is likely due to the use of raw volume standard deviation in the denominator, which can create extreme values when volume is consistently low but slightly fluctuates. By using the Coefficient of Variation (TS_STD/TS_MEAN), we normalize the 'quietness' of the momentum. Furthermore, a 1-day overnight gap is highly susceptible to noise; averaging this gap over 3 days before dividing by the 5-day illiquidity should provide a more stable signal of institutional sentiment shift."
      }
    },
    "536b346fcb659017": {
      "factor_id": "536b346fcb659017",
      "factor_name": "Quiet_Momentum_Efficiency",
      "factor_expression": "TS_PCTCHANGE($close, 20) / (TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) / (TS_STD($volume, 10) / (TS_MEAN($volume, 10) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Quiet_Momentum_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Focuses on the second component of the hypothesis: information diffusion velocity. It identifies stocks with strong 20-day price trends that exhibit low volume volatility, suggesting a 'quiet' institutional accumulation rather than speculative churn.",
      "factor_formulation": "\\frac{\\text{TS_PCTCHANGE}(\\text{close}, 20)}{\\text{TS_STD}(\\text{volume}, 10) / \\text{TS_MEAN}(\\text{volume}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 6,
        "evolution_phase": "crossover",
        "trajectory_id": "530ed6f4b2d2",
        "parent_trajectory_ids": [
          "aa9b2953183f",
          "dc35ed2e2f1b"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Absorption Efficiency' factor, calculated as the product of the 5-day Liquidity-Adjusted Sentiment Gap (overnight return divided by the 5-day average Amihud illiquidity) and the 20-day Information Diffusion Velocity (20-day momentum divided by the 10-day volume volatility), identifies high-conviction price trends driven by institutional accumulation.\n                Concise Observation: Parent strategies show that overnight gaps are noisy without liquidity filters (Parent 2) and that long-term momentum requires a 'quiet' volume structure to avoid exhaustion (Parent 1).\n                Concise Justification: Combining liquidity-validated entry signals with volume-stability filters ensures that the factor captures the transition from initial sentiment shock to steady institutional accumulation, reducing exposure to mean-reverting speculative spikes.\n                Concise Knowledge: If an overnight sentiment shock occurs in a high-liquidity environment and is followed by price persistence with low volume volatility, then the price move is likely driven by institutional absorption rather than retail speculation; such trends are more sustainable than those accompanied by high volume churn.\n                concise Specification: The factor is defined as ( (Close/Open_prev - 1) / Mean(Abs(Return)/Volume, 5) ) * ( (Close/Close_20 - 1) / Std(Volume, 10) ). It targets stocks where price gaps are supported by liquidity and subsequent momentum is characterized by low volume variance over a 20-day horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T08:11:21.965713"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1927016863723594,
        "ICIR": 0.0344349606072184,
        "1day.excess_return_without_cost.std": 0.0059900139505468,
        "1day.excess_return_with_cost.annualized_return": 0.0100678354864385,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002423777891882,
        "1day.excess_return_without_cost.annualized_return": 0.0576859138267945,
        "1day.excess_return_with_cost.std": 0.0059931338440877,
        "Rank IC": 0.0207161070156809,
        "IC": 0.0054590553878437,
        "1day.excess_return_without_cost.max_drawdown": -0.1585485911126347,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6242426887106604,
        "1day.pa": 0.0,
        "l2.valid": 0.9966175003528412,
        "Rank ICIR": 0.1315914393078261,
        "l2.train": 0.9936151080410176,
        "1day.excess_return_with_cost.information_ratio": 0.1088914184163937,
        "1day.excess_return_with_cost.mean": 4.230182977495171e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Institutional Absorption Efficiency' framework. The primary factor 'Inst_Absorp_Eff_20D' and its components aimed to capture institutional accumulation through liquidity-adjusted sentiment and quiet momentum. The results show that while the Current Result achieved a higher Annualized Return (0.0577 vs 0.0520) compared to the SOTA, it suffered from significantly higher volatility and risk, as evidenced by the doubled Max Drawdown (-0.1585 vs -0.0726) and a lower Information Ratio (0.6242 vs 0.9726). The IC also slightly lagged behind the SOTA.",
        "hypothesis_evaluation": "The hypothesis that combining overnight sentiment gaps (Amihud-adjusted) with 'quiet' momentum identifies high-conviction trends is partially supported by the improvement in raw annualized returns. However, the high drawdown suggests that the current formulation of 'Institutional Absorption' might be picking up high-beta or tail-risk events rather than steady institutional accumulation. The 'Information Diffusion Velocity' component (momentum divided by volume volatility) may be too sensitive to low-volume spikes, leading to instability.",
        "decision": true,
        "reason": "The current factor's high drawdown is likely due to the use of raw volume standard deviation in the denominator, which can create extreme values when volume is consistently low but slightly fluctuates. By using the Coefficient of Variation (TS_STD/TS_MEAN), we normalize the 'quietness' of the momentum. Furthermore, a 1-day overnight gap is highly susceptible to noise; averaging this gap over 3 days before dividing by the 5-day illiquidity should provide a more stable signal of institutional sentiment shift."
      }
    },
    "31fe6672cfece10a": {
      "factor_id": "31fe6672cfece10a",
      "factor_name": "MRLV_Elasticity_Reversal_5D",
      "factor_expression": "(($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8) * (($return == TS_MAX($return, 10)) && ($volume < TS_MEAN($volume, 10)) ? 1 : 0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((($high - $low) / ($volume + 1e-8)) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)) * ((TS_PCTCHANGE($close, 1) == TS_MAX(TS_PCTCHANGE($close, 1), 10)) && ($volume < TS_MEAN($volume, 10)) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"MRLV_Elasticity_Reversal_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential mean reversion by measuring liquidity elasticity, defined as the ratio of the price range to volume. High elasticity combined with price extremes (10-day high return) and low volume relative to its 10-day average suggests a liquidity vacuum where price moves lack depth.",
      "factor_formulation": "MRLV = \\frac{(high - low) / (volume + 1e-8)}{\\text{TS_MEAN}((high - low) / (volume + 1e-8), 5)} \\times (return == \\text{TS_MAX}(return, 10) \\&\\& volume < \\text{TS_MEAN}(volume, 10) ? 1 : 0)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "5a966a671863",
        "parent_trajectory_ids": [
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts that price extremes reached on low relative volume and high price-range-to-volume ratios (liquidity elasticity) indicate trend exhaustion rather than conviction, leading to short-term mean reversion.\n                Concise Observation: While the parent strategy (ICCG) successfully identified momentum from low-volatility compression, market data shows that high-volatility extensions often fail when the 'cost' of price movement (volume) decreases, suggesting a lack of depth in the order book.\n                Concise Justification: Price movements without corresponding volume support (low liquidity density) reflect a temporary imbalance where noise traders exhaust available liquidity, creating a price-value gap that is typically closed by arbitrageurs or institutional 'mean-reversion' flows.\n                Concise Knowledge: If a price breakout occurs with decreasing volume intensity and high price elasticity, it is likely driven by a liquidity vacuum rather than institutional flow; when such 'thin' moves reach statistical extremes, the probability of a corrective reversal within 1-3 days increases significantly.\n                concise Specification: The MRLV factor is defined by the interaction of the 5-day price range relative to volume (Elasticity) and the 3-day divergence between absolute price change and volume trend, specifically targeting instruments where the 1-day return is at a 10-day high but volume is below its 10-day average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T08:28:17.941971"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.14433577286911,
        "ICIR": 0.0292275076723329,
        "1day.excess_return_without_cost.std": 0.0043452669492371,
        "1day.excess_return_with_cost.annualized_return": -0.0130325202224397,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001437870655468,
        "1day.excess_return_without_cost.annualized_return": 0.0342213216001535,
        "1day.excess_return_with_cost.std": 0.0043460551268255,
        "Rank IC": 0.0210569174050935,
        "IC": 0.0040990770738591,
        "1day.excess_return_without_cost.max_drawdown": -0.0716784456952363,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5104954044305549,
        "1day.pa": 0.0,
        "l2.valid": 0.9963972137057456,
        "Rank ICIR": 0.144679555816564,
        "l2.train": 0.9929005687877054,
        "1day.excess_return_with_cost.information_ratio": -0.194376920884222,
        "1day.excess_return_with_cost.mean": -5.47584883295786e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.071678 vs -0.072585) compared to the SOTA, it significantly underperformed in terms of Information Ratio (0.510 vs 0.972), Annualized Return (0.034 vs 0.052), and IC (0.004 vs 0.005). The 'MRLV_Elasticity_Reversal_5D' factor utilized a boolean trigger which might be too sparse for a robust signal, while 'Elasticity_ZScore_Exhaustion' provides a more continuous measure but perhaps lacks the necessary price-direction context to distinguish between exhaustion and breakout.",
        "hypothesis_evaluation": "The hypothesis that liquidity vacuums (high price range on low volume) lead to mean reversion is partially supported by the improved Max Drawdown, suggesting some risk-reduction properties. However, the drop in IR and IC indicates that the current mathematical formulations are not capturing the timing or the magnitude of the reversal effectively. The 'liquidity elasticity' concept is valid, but its interaction with trend strength needs refinement.",
        "decision": false,
        "reason": "The current factors either use a binary trigger (too sparse) or a simple Z-score (lacks direction). By focusing on the 'acceleration' of elasticity (the second derivative of the range-to-volume ratio) coupled with a directional filter (e.g., comparing current close to a moving average), we can better identify the specific moment of 'blow-off' exhaustion. This reduces the complexity of boolean logic while providing a smoother, more predictive signal for the model."
      }
    },
    "ac296dd865736184": {
      "factor_id": "ac296dd865736184",
      "factor_name": "Liquidity_Vacuum_Divergence_3D",
      "factor_expression": "RANK(TS_MEAN(ABS(DELTA($close, 1)), 3) / (TS_MEAN($volume, 3) + 1e-8)) - RANK(TS_CORR(ABS(DELTA($close, 1)), $volume, 3))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - DELAY($close, 1)), 3) / (TS_MEAN($volume, 3) + 1e-8) / (TS_STD($close / DELAY($close, 1) - 1, 10) + 1e-8)) - RANK(TS_CORR(ABS($close - DELAY($close, 1)), $volume, 3))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Vacuum_Divergence_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures the divergence between price movement magnitude and volume trend over a 3-day window. It targets instruments where the absolute price change is increasing while volume is decreasing, normalized by the 10-day volatility to detect exhaustion at price extremes.",
      "factor_formulation": "LVD = \\text{RANK}(\\frac{\\text{TS_MEAN}(\\text{ABS}(\\text{DELTA}(close, 1)), 3)}{\\text{TS_MEAN}(volume, 3) + 1e-8} - \\text{RANK}(\\text{TS_CORR}(ABS(\\text{DELTA}(close, 1)), volume, 3)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "5a966a671863",
        "parent_trajectory_ids": [
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts that price extremes reached on low relative volume and high price-range-to-volume ratios (liquidity elasticity) indicate trend exhaustion rather than conviction, leading to short-term mean reversion.\n                Concise Observation: While the parent strategy (ICCG) successfully identified momentum from low-volatility compression, market data shows that high-volatility extensions often fail when the 'cost' of price movement (volume) decreases, suggesting a lack of depth in the order book.\n                Concise Justification: Price movements without corresponding volume support (low liquidity density) reflect a temporary imbalance where noise traders exhaust available liquidity, creating a price-value gap that is typically closed by arbitrageurs or institutional 'mean-reversion' flows.\n                Concise Knowledge: If a price breakout occurs with decreasing volume intensity and high price elasticity, it is likely driven by a liquidity vacuum rather than institutional flow; when such 'thin' moves reach statistical extremes, the probability of a corrective reversal within 1-3 days increases significantly.\n                concise Specification: The MRLV factor is defined by the interaction of the 5-day price range relative to volume (Elasticity) and the 3-day divergence between absolute price change and volume trend, specifically targeting instruments where the 1-day return is at a 10-day high but volume is below its 10-day average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T08:28:17.941971"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.14433577286911,
        "ICIR": 0.0292275076723329,
        "1day.excess_return_without_cost.std": 0.0043452669492371,
        "1day.excess_return_with_cost.annualized_return": -0.0130325202224397,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001437870655468,
        "1day.excess_return_without_cost.annualized_return": 0.0342213216001535,
        "1day.excess_return_with_cost.std": 0.0043460551268255,
        "Rank IC": 0.0210569174050935,
        "IC": 0.0040990770738591,
        "1day.excess_return_without_cost.max_drawdown": -0.0716784456952363,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5104954044305549,
        "1day.pa": 0.0,
        "l2.valid": 0.9963972137057456,
        "Rank ICIR": 0.144679555816564,
        "l2.train": 0.9929005687877054,
        "1day.excess_return_with_cost.information_ratio": -0.194376920884222,
        "1day.excess_return_with_cost.mean": -5.47584883295786e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.071678 vs -0.072585) compared to the SOTA, it significantly underperformed in terms of Information Ratio (0.510 vs 0.972), Annualized Return (0.034 vs 0.052), and IC (0.004 vs 0.005). The 'MRLV_Elasticity_Reversal_5D' factor utilized a boolean trigger which might be too sparse for a robust signal, while 'Elasticity_ZScore_Exhaustion' provides a more continuous measure but perhaps lacks the necessary price-direction context to distinguish between exhaustion and breakout.",
        "hypothesis_evaluation": "The hypothesis that liquidity vacuums (high price range on low volume) lead to mean reversion is partially supported by the improved Max Drawdown, suggesting some risk-reduction properties. However, the drop in IR and IC indicates that the current mathematical formulations are not capturing the timing or the magnitude of the reversal effectively. The 'liquidity elasticity' concept is valid, but its interaction with trend strength needs refinement.",
        "decision": false,
        "reason": "The current factors either use a binary trigger (too sparse) or a simple Z-score (lacks direction). By focusing on the 'acceleration' of elasticity (the second derivative of the range-to-volume ratio) coupled with a directional filter (e.g., comparing current close to a moving average), we can better identify the specific moment of 'blow-off' exhaustion. This reduces the complexity of boolean logic while providing a smoother, more predictive signal for the model."
      }
    },
    "424d7f4f0b70aecb": {
      "factor_id": "424d7f4f0b70aecb",
      "factor_name": "Elasticity_ZScore_Exhaustion",
      "factor_expression": "RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(($high - $low) / ($volume + 1e-8), 10))\" # Your output factor expression will be filled in here\n    name = \"Elasticity_ZScore_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the statistical extremity of price elasticity (range per unit volume). A high Z-score in elasticity, particularly when the price range is wide but volume is thin, indicates a 'Mean-Reverting Liquidity Vacuum' likely to reverse as liquidity returns.",
      "factor_formulation": "EZE = \\text{RANK}(\\text{TS_ZSCORE}(\\frac{high - low}{volume + 1e-8}, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "5a966a671863",
        "parent_trajectory_ids": [
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts that price extremes reached on low relative volume and high price-range-to-volume ratios (liquidity elasticity) indicate trend exhaustion rather than conviction, leading to short-term mean reversion.\n                Concise Observation: While the parent strategy (ICCG) successfully identified momentum from low-volatility compression, market data shows that high-volatility extensions often fail when the 'cost' of price movement (volume) decreases, suggesting a lack of depth in the order book.\n                Concise Justification: Price movements without corresponding volume support (low liquidity density) reflect a temporary imbalance where noise traders exhaust available liquidity, creating a price-value gap that is typically closed by arbitrageurs or institutional 'mean-reversion' flows.\n                Concise Knowledge: If a price breakout occurs with decreasing volume intensity and high price elasticity, it is likely driven by a liquidity vacuum rather than institutional flow; when such 'thin' moves reach statistical extremes, the probability of a corrective reversal within 1-3 days increases significantly.\n                concise Specification: The MRLV factor is defined by the interaction of the 5-day price range relative to volume (Elasticity) and the 3-day divergence between absolute price change and volume trend, specifically targeting instruments where the 1-day return is at a 10-day high but volume is below its 10-day average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T08:28:17.941971"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.14433577286911,
        "ICIR": 0.0292275076723329,
        "1day.excess_return_without_cost.std": 0.0043452669492371,
        "1day.excess_return_with_cost.annualized_return": -0.0130325202224397,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001437870655468,
        "1day.excess_return_without_cost.annualized_return": 0.0342213216001535,
        "1day.excess_return_with_cost.std": 0.0043460551268255,
        "Rank IC": 0.0210569174050935,
        "IC": 0.0040990770738591,
        "1day.excess_return_without_cost.max_drawdown": -0.0716784456952363,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5104954044305549,
        "1day.pa": 0.0,
        "l2.valid": 0.9963972137057456,
        "Rank ICIR": 0.144679555816564,
        "l2.train": 0.9929005687877054,
        "1day.excess_return_with_cost.information_ratio": -0.194376920884222,
        "1day.excess_return_with_cost.mean": -5.47584883295786e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.071678 vs -0.072585) compared to the SOTA, it significantly underperformed in terms of Information Ratio (0.510 vs 0.972), Annualized Return (0.034 vs 0.052), and IC (0.004 vs 0.005). The 'MRLV_Elasticity_Reversal_5D' factor utilized a boolean trigger which might be too sparse for a robust signal, while 'Elasticity_ZScore_Exhaustion' provides a more continuous measure but perhaps lacks the necessary price-direction context to distinguish between exhaustion and breakout.",
        "hypothesis_evaluation": "The hypothesis that liquidity vacuums (high price range on low volume) lead to mean reversion is partially supported by the improved Max Drawdown, suggesting some risk-reduction properties. However, the drop in IR and IC indicates that the current mathematical formulations are not capturing the timing or the magnitude of the reversal effectively. The 'liquidity elasticity' concept is valid, but its interaction with trend strength needs refinement.",
        "decision": false,
        "reason": "The current factors either use a binary trigger (too sparse) or a simple Z-score (lacks direction). By focusing on the 'acceleration' of elasticity (the second derivative of the range-to-volume ratio) coupled with a directional filter (e.g., comparing current close to a moving average), we can better identify the specific moment of 'blow-off' exhaustion. This reduces the complexity of boolean logic while providing a smoother, more predictive signal for the model."
      }
    },
    "37769d65fa1ef885": {
      "factor_id": "37769d65fa1ef885",
      "factor_name": "IAE_Volatility_Adjusted_1D",
      "factor_expression": "(ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8)) * TS_STD($return, 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8)) * TS_STD(TS_PCTCHANGE($close, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"IAE_Volatility_Adjusted_1D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Intraday Absorption Efficiency (IAE) measures the proximity of the close to the daily typical price (proxy for VWAP) relative to the high-low range. This version is conditioned on a 5-day volatility window to identify sessions where high-volatility price action was absorbed by liquidity providers.",
      "factor_formulation": "IAE = \\frac{ABS(close - (high + low + close) / 3)}{high - low + 1e-8} \\times TS\\_STD(return, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ca4714481cd7",
        "parent_trajectory_ids": [
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Absorption Efficiency' (IAE) factor, defined as the ratio of the distance between the close and the daily VWAP to the total intraday range, identifies whether high-volatility sessions represent genuine price discovery or noise-driven mean reversion.\n                Concise Observation: The parent strategy SELV focuses on multi-day linear exhaustion, whereas intraday data often shows 'bursts' where price deviates from value (VWAP) and either reverts or consolidates, suggesting a micro-structural dimension of price efficiency.\n                Concise Justification: The proximity of the closing price to the VWAP relative to the high-low range measures the 'net displacement' of a session; a low ratio during high volatility indicates a 'wash-out' where institutional absorption neutralized retail-driven noise.\n                Concise Knowledge: If a stock experiences high intraday volatility but closes near its Volume Weighted Average Price (VWAP), it suggests that liquidity providers have absorbed the directional flow; conversely, a close far from VWAP indicates successful price displacement.\n                concise Specification: The factor is calculated as ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-6) over a 1-day period, where ($high + $low + $close) / 3 serves as a daily VWAP proxy, conditioned on a 5-day volatility window.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T08:33:19.874763"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1675770247487079,
        "ICIR": 0.0322548481063513,
        "1day.excess_return_without_cost.std": 0.0038979335858248,
        "1day.excess_return_with_cost.annualized_return": -0.0244432822278237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.596220813466825e-05,
        "1day.excess_return_without_cost.annualized_return": 0.022839005536051,
        "1day.excess_return_with_cost.std": 0.003899335001961,
        "Rank IC": 0.0180117934537671,
        "IC": 0.0040298430053514,
        "1day.excess_return_without_cost.max_drawdown": -0.1214745337117133,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3797994015222267,
        "1day.pa": 0.0,
        "l2.valid": 0.996372935798062,
        "Rank ICIR": 0.1437530076407563,
        "l2.train": 0.9931619347122904,
        "1day.excess_return_with_cost.information_ratio": -0.4063315039088317,
        "1day.excess_return_with_cost.mean": -0.0001027028665034
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Intraday Absorption Efficiency' (IAE) framework: a volatility-adjusted version, a smoothed rank version, and a 'washout' signal. While the theoretical framework is sound, the empirical results across all metrics (IC: 0.0040, Annualized Return: 2.28%, IR: 0.38) significantly underperform the SOTA (IC: 0.0058, Annualized Return: 5.20%, IR: 0.97). The 'IAE_Washout_Signal' implementation, which uses an inverse ratio, may have introduced extreme outliers or instability, while the 'IAE_Rank_Efficiency_5D' might be too diluted by the double-averaging effect of TS_MEAN and RANK.",
        "hypothesis_evaluation": "The hypothesis that the proximity of the close to the VWAP relative to the range identifies price discovery is partially supported by the positive IC, but the current implementations are not capturing the signal as effectively as the SOTA. The 'IAE_Volatility_Adjusted_1D' correctly identifies that volatility is a necessary condition, but the linear multiplication of TS_STD might be scaling the factor inappropriately across different market regimes.",
        "decision": false,
        "reason": "The current IAE factors focus on price levels ($high, $low, $close) but ignore the $volume required to reach those levels. A low IAE (close near typical price) on high volume suggests heavy absorption by liquidity providers, which is a stronger mean-reversion signal than the same price action on low volume. By incorporating $volume, we can distinguish between 'quiet' mean reversion and 'forced' absorption."
      }
    },
    "dbd4c3354dd7ee89": {
      "factor_id": "dbd4c3354dd7ee89",
      "factor_name": "IAE_Rank_Efficiency_5D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"IAE_Rank_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A smoothed version of the Intraday Absorption Efficiency factor that uses a 5-day moving average of the absorption ratio. It identifies stocks where price discovery is consistently efficient or inefficient relative to the intraday range, cross-sectionally ranked for stability.",
      "factor_formulation": "IAE\\_Smooth = RANK(TS\\_MEAN(\\frac{ABS(close - (high + low + close) / 3)}{high - low + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ca4714481cd7",
        "parent_trajectory_ids": [
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Absorption Efficiency' (IAE) factor, defined as the ratio of the distance between the close and the daily VWAP to the total intraday range, identifies whether high-volatility sessions represent genuine price discovery or noise-driven mean reversion.\n                Concise Observation: The parent strategy SELV focuses on multi-day linear exhaustion, whereas intraday data often shows 'bursts' where price deviates from value (VWAP) and either reverts or consolidates, suggesting a micro-structural dimension of price efficiency.\n                Concise Justification: The proximity of the closing price to the VWAP relative to the high-low range measures the 'net displacement' of a session; a low ratio during high volatility indicates a 'wash-out' where institutional absorption neutralized retail-driven noise.\n                Concise Knowledge: If a stock experiences high intraday volatility but closes near its Volume Weighted Average Price (VWAP), it suggests that liquidity providers have absorbed the directional flow; conversely, a close far from VWAP indicates successful price displacement.\n                concise Specification: The factor is calculated as ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-6) over a 1-day period, where ($high + $low + $close) / 3 serves as a daily VWAP proxy, conditioned on a 5-day volatility window.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T08:33:19.874763"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1675770247487079,
        "ICIR": 0.0322548481063513,
        "1day.excess_return_without_cost.std": 0.0038979335858248,
        "1day.excess_return_with_cost.annualized_return": -0.0244432822278237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.596220813466825e-05,
        "1day.excess_return_without_cost.annualized_return": 0.022839005536051,
        "1day.excess_return_with_cost.std": 0.003899335001961,
        "Rank IC": 0.0180117934537671,
        "IC": 0.0040298430053514,
        "1day.excess_return_without_cost.max_drawdown": -0.1214745337117133,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3797994015222267,
        "1day.pa": 0.0,
        "l2.valid": 0.996372935798062,
        "Rank ICIR": 0.1437530076407563,
        "l2.train": 0.9931619347122904,
        "1day.excess_return_with_cost.information_ratio": -0.4063315039088317,
        "1day.excess_return_with_cost.mean": -0.0001027028665034
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Intraday Absorption Efficiency' (IAE) framework: a volatility-adjusted version, a smoothed rank version, and a 'washout' signal. While the theoretical framework is sound, the empirical results across all metrics (IC: 0.0040, Annualized Return: 2.28%, IR: 0.38) significantly underperform the SOTA (IC: 0.0058, Annualized Return: 5.20%, IR: 0.97). The 'IAE_Washout_Signal' implementation, which uses an inverse ratio, may have introduced extreme outliers or instability, while the 'IAE_Rank_Efficiency_5D' might be too diluted by the double-averaging effect of TS_MEAN and RANK.",
        "hypothesis_evaluation": "The hypothesis that the proximity of the close to the VWAP relative to the range identifies price discovery is partially supported by the positive IC, but the current implementations are not capturing the signal as effectively as the SOTA. The 'IAE_Volatility_Adjusted_1D' correctly identifies that volatility is a necessary condition, but the linear multiplication of TS_STD might be scaling the factor inappropriately across different market regimes.",
        "decision": false,
        "reason": "The current IAE factors focus on price levels ($high, $low, $close) but ignore the $volume required to reach those levels. A low IAE (close near typical price) on high volume suggests heavy absorption by liquidity providers, which is a stronger mean-reversion signal than the same price action on low volume. By incorporating $volume, we can distinguish between 'quiet' mean reversion and 'forced' absorption."
      }
    },
    "dbf296f65302d588": {
      "factor_id": "dbf296f65302d588",
      "factor_name": "IAE_Washout_Signal",
      "factor_expression": "(($high - $low) / (ABS($close - ($high + $low + $close) / 3) + 1e-8)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high - $low) / (ABS($close - ($high + $low + $close) / 3) + 1e-8)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"IAE_Washout_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'wash-out' sessions where high intraday range results in a close very near the typical price. It uses the inverse of the absorption ratio multiplied by the 5-day range to highlight sessions with high absorption potential.",
      "factor_formulation": "Washout = \\frac{high - low}{ABS(close - (high + low + close) / 3) + 1e-8} / (TS\\_MAX(high, 5) - TS\\_MIN(low, 5) + 1e-8)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ca4714481cd7",
        "parent_trajectory_ids": [
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Absorption Efficiency' (IAE) factor, defined as the ratio of the distance between the close and the daily VWAP to the total intraday range, identifies whether high-volatility sessions represent genuine price discovery or noise-driven mean reversion.\n                Concise Observation: The parent strategy SELV focuses on multi-day linear exhaustion, whereas intraday data often shows 'bursts' where price deviates from value (VWAP) and either reverts or consolidates, suggesting a micro-structural dimension of price efficiency.\n                Concise Justification: The proximity of the closing price to the VWAP relative to the high-low range measures the 'net displacement' of a session; a low ratio during high volatility indicates a 'wash-out' where institutional absorption neutralized retail-driven noise.\n                Concise Knowledge: If a stock experiences high intraday volatility but closes near its Volume Weighted Average Price (VWAP), it suggests that liquidity providers have absorbed the directional flow; conversely, a close far from VWAP indicates successful price displacement.\n                concise Specification: The factor is calculated as ABS($close - ($high + $low + $close) / 3) / ($high - $low + 1e-6) over a 1-day period, where ($high + $low + $close) / 3 serves as a daily VWAP proxy, conditioned on a 5-day volatility window.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T08:33:19.874763"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1675770247487079,
        "ICIR": 0.0322548481063513,
        "1day.excess_return_without_cost.std": 0.0038979335858248,
        "1day.excess_return_with_cost.annualized_return": -0.0244432822278237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 9.596220813466825e-05,
        "1day.excess_return_without_cost.annualized_return": 0.022839005536051,
        "1day.excess_return_with_cost.std": 0.003899335001961,
        "Rank IC": 0.0180117934537671,
        "IC": 0.0040298430053514,
        "1day.excess_return_without_cost.max_drawdown": -0.1214745337117133,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.3797994015222267,
        "1day.pa": 0.0,
        "l2.valid": 0.996372935798062,
        "Rank ICIR": 0.1437530076407563,
        "l2.train": 0.9931619347122904,
        "1day.excess_return_with_cost.information_ratio": -0.4063315039088317,
        "1day.excess_return_with_cost.mean": -0.0001027028665034
      },
      "feedback": {
        "observations": "The current iteration explored three variations of the 'Intraday Absorption Efficiency' (IAE) framework: a volatility-adjusted version, a smoothed rank version, and a 'washout' signal. While the theoretical framework is sound, the empirical results across all metrics (IC: 0.0040, Annualized Return: 2.28%, IR: 0.38) significantly underperform the SOTA (IC: 0.0058, Annualized Return: 5.20%, IR: 0.97). The 'IAE_Washout_Signal' implementation, which uses an inverse ratio, may have introduced extreme outliers or instability, while the 'IAE_Rank_Efficiency_5D' might be too diluted by the double-averaging effect of TS_MEAN and RANK.",
        "hypothesis_evaluation": "The hypothesis that the proximity of the close to the VWAP relative to the range identifies price discovery is partially supported by the positive IC, but the current implementations are not capturing the signal as effectively as the SOTA. The 'IAE_Volatility_Adjusted_1D' correctly identifies that volatility is a necessary condition, but the linear multiplication of TS_STD might be scaling the factor inappropriately across different market regimes.",
        "decision": false,
        "reason": "The current IAE factors focus on price levels ($high, $low, $close) but ignore the $volume required to reach those levels. A low IAE (close near typical price) on high volume suggests heavy absorption by liquidity providers, which is a stronger mean-reversion signal than the same price action on low volume. By incorporating $volume, we can distinguish between 'quiet' mean reversion and 'forced' absorption."
      }
    },
    "8b39ce1839ed04c0": {
      "factor_id": "8b39ce1839ed04c0",
      "factor_name": "Late_Day_Exhaustion_Intensity",
      "factor_expression": "(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - $low) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Late_Day_Exhaustion_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures price exhaustion by multiplying the closing range position (where the price closes relative to its daily high/low) by the volume intensity relative to its 5-day average. A high value suggests a strong, volume-supported close, while a divergence (high price position with low volume intensity) indicates a potential blow-off top or mean reversion signal.",
      "factor_formulation": "\\text{Exhaustion} = \\frac{$close - $low}{$high - $low + 1e-8} \\times \\frac{$volume}{\\text{TS_MEAN}($volume, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccff6ed7caa8",
        "parent_trajectory_ids": [
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Late-Day Trend Exhaustion' factor, defined as the ratio of the closing price relative to the daily range (Close-Low)/(High-Low) adjusted by the ratio of daily volume to its 5-day moving average, predicts next-day mean reversion when high price extremes occur on thinning relative volume.\n                Concise Observation: The parent strategy focused on institutional floors via lower shadows and volume stability, but failed to capture the 'blow-off' or 'exhaustion' phase where price continues to move while volume participation drops.\n                Concise Justification: Price discovery requires volume validation; a high 'Closing Range' score (price near high) coupled with low 'Volume Intensity' suggests liquidity exhaustion rather than a sustainable breakout, making the asset prone to a reversal.\n                Concise Knowledge: If a price reaches its daily extreme on declining relative volume, it indicates a lack of institutional follow-through; when retail-driven late-day momentum lacks volume support, market makers likely over-extend prices, leading to a mean-reverting snap-back.\n                concise Specification: Calculate the daily 'Closing Position' as ($close - $low) / ($high - $low + 1e-8) and multiply it by the 'Volume Surge' ($volume / TS_MEAN($volume, 5)); a high value indicates strong, volume-backed closes (momentum), while a low value with high price position indicates exhaustion (reversal).\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T08:44:46.702334"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0801096653999234,
        "ICIR": 0.0323137840858001,
        "1day.excess_return_without_cost.std": 0.0038933268536367,
        "1day.excess_return_with_cost.annualized_return": 0.0224067038418408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002916131544456,
        "1day.excess_return_without_cost.annualized_return": 0.0694039307580737,
        "1day.excess_return_with_cost.std": 0.0038951193400999,
        "Rank IC": 0.0223438865785895,
        "IC": 0.0046130019394651,
        "1day.excess_return_without_cost.max_drawdown": -0.0636899799289828,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1555127025750906,
        "1day.pa": 0.0,
        "l2.valid": 0.9963781161583856,
        "Rank ICIR": 0.1589113087694215,
        "l2.train": 0.9935972769811862,
        "1day.excess_return_with_cost.information_ratio": 0.3728796885191014,
        "1day.excess_return_with_cost.mean": 9.41458144615162e-05
      },
      "feedback": {
        "observations": "The current iteration tested three variations of the 'Late-Day Trend Exhaustion' hypothesis. The results show a significant improvement in risk-adjusted performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.15, and the Annualized Return rose from 5.2% to 6.9%. While the Information Coefficient (IC) saw a slight decrease (0.0058 to 0.0046), the reduction in Max Drawdown (-0.072 to -0.063) suggests that the current factor set captures higher-quality, lower-volatility signals. The 'Smoothed_Exhaustion_Index_10D' likely contributed to this stability by filtering out daily noise through the Z-score and 10-day window.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining price positioning (Close relative to High/Low) with volume intensity provides a predictive signal for mean reversion. The success of the 'Exhaustion_Reversal_Rank' and 'Smoothed_Exhaustion_Index_10D' suggests that the 'thinning volume' component is more effective when viewed as a divergence (rank difference) or a time-series anomaly (Z-score) rather than a simple product of price and volume.",
        "decision": true,
        "reason": "The current factors utilize a 5-day volume mean, but do not account for the magnitude of the price range relative to historical volatility (ATR). By incorporating a 'Volatility-Adjusted Range' and checking if the current volume is not just low, but declining over multiple days (negative volume slope), we can better isolate 'blow-off' exhaustion from simple low-liquidity consolidation. This addresses the 'thinning' aspect more dynamically."
      }
    },
    "81113f66dc600f67": {
      "factor_id": "81113f66dc600f67",
      "factor_name": "Exhaustion_Reversal_Rank",
      "factor_expression": "RANK(($close - $low) / ($high - $low + 1e-8)) - RANK($volume / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $low) / ($high - $low + 1e-8)) - RANK($volume / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential reversal points by looking for instances where the closing price is near the high of the day but volume is significantly lower than the recent average. It applies a cross-sectional rank to the exhaustion signal to identify the most overextended assets relative to the market.",
      "factor_formulation": "\\text{Exhaustion\\_Rank} = \\text{RANK}\\left(\\frac{$close - $low}{$high - $low + 1e-8}\\right) - \\text{RANK}\\left(\\frac{$volume}{\\text{TS_MEAN}($volume, 5)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccff6ed7caa8",
        "parent_trajectory_ids": [
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Late-Day Trend Exhaustion' factor, defined as the ratio of the closing price relative to the daily range (Close-Low)/(High-Low) adjusted by the ratio of daily volume to its 5-day moving average, predicts next-day mean reversion when high price extremes occur on thinning relative volume.\n                Concise Observation: The parent strategy focused on institutional floors via lower shadows and volume stability, but failed to capture the 'blow-off' or 'exhaustion' phase where price continues to move while volume participation drops.\n                Concise Justification: Price discovery requires volume validation; a high 'Closing Range' score (price near high) coupled with low 'Volume Intensity' suggests liquidity exhaustion rather than a sustainable breakout, making the asset prone to a reversal.\n                Concise Knowledge: If a price reaches its daily extreme on declining relative volume, it indicates a lack of institutional follow-through; when retail-driven late-day momentum lacks volume support, market makers likely over-extend prices, leading to a mean-reverting snap-back.\n                concise Specification: Calculate the daily 'Closing Position' as ($close - $low) / ($high - $low + 1e-8) and multiply it by the 'Volume Surge' ($volume / TS_MEAN($volume, 5)); a high value indicates strong, volume-backed closes (momentum), while a low value with high price position indicates exhaustion (reversal).\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T08:44:46.702334"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0801096653999234,
        "ICIR": 0.0323137840858001,
        "1day.excess_return_without_cost.std": 0.0038933268536367,
        "1day.excess_return_with_cost.annualized_return": 0.0224067038418408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002916131544456,
        "1day.excess_return_without_cost.annualized_return": 0.0694039307580737,
        "1day.excess_return_with_cost.std": 0.0038951193400999,
        "Rank IC": 0.0223438865785895,
        "IC": 0.0046130019394651,
        "1day.excess_return_without_cost.max_drawdown": -0.0636899799289828,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1555127025750906,
        "1day.pa": 0.0,
        "l2.valid": 0.9963781161583856,
        "Rank ICIR": 0.1589113087694215,
        "l2.train": 0.9935972769811862,
        "1day.excess_return_with_cost.information_ratio": 0.3728796885191014,
        "1day.excess_return_with_cost.mean": 9.41458144615162e-05
      },
      "feedback": {
        "observations": "The current iteration tested three variations of the 'Late-Day Trend Exhaustion' hypothesis. The results show a significant improvement in risk-adjusted performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.15, and the Annualized Return rose from 5.2% to 6.9%. While the Information Coefficient (IC) saw a slight decrease (0.0058 to 0.0046), the reduction in Max Drawdown (-0.072 to -0.063) suggests that the current factor set captures higher-quality, lower-volatility signals. The 'Smoothed_Exhaustion_Index_10D' likely contributed to this stability by filtering out daily noise through the Z-score and 10-day window.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining price positioning (Close relative to High/Low) with volume intensity provides a predictive signal for mean reversion. The success of the 'Exhaustion_Reversal_Rank' and 'Smoothed_Exhaustion_Index_10D' suggests that the 'thinning volume' component is more effective when viewed as a divergence (rank difference) or a time-series anomaly (Z-score) rather than a simple product of price and volume.",
        "decision": true,
        "reason": "The current factors utilize a 5-day volume mean, but do not account for the magnitude of the price range relative to historical volatility (ATR). By incorporating a 'Volatility-Adjusted Range' and checking if the current volume is not just low, but declining over multiple days (negative volume slope), we can better isolate 'blow-off' exhaustion from simple low-liquidity consolidation. This addresses the 'thinning' aspect more dynamically."
      }
    },
    "11042c7817360441": {
      "factor_id": "11042c7817360441",
      "factor_name": "Smoothed_Exhaustion_Index_10D",
      "factor_expression": "TS_ZSCORE((($close - $low) / ($high - $low + 1e-8)) / (($volume / (TS_MEAN($volume, 5) + 1e-8)) + 1e-8), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((($close - $low) / ($high - $low + 1e-8)) / (($volume / (TS_MEAN($volume, 5) + 1e-8)) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Exhaustion_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A smoothed version of the exhaustion index that uses a 10-day Z-score of the closing position relative to volume surges. This helps identify persistent patterns of thinning volume during price rallies, which is a stronger signal for institutional exhaustion than a single day's movement.",
      "factor_formulation": "\\text{SEI} = \\text{TS_ZSCORE}\\left(\\frac{$close - $low}{$high - $low + 1e-8} \\times \\text{INV}\\left(\\frac{$volume}{\\text{TS_MEAN}($volume, 5)}\\right), 10\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccff6ed7caa8",
        "parent_trajectory_ids": [
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Late-Day Trend Exhaustion' factor, defined as the ratio of the closing price relative to the daily range (Close-Low)/(High-Low) adjusted by the ratio of daily volume to its 5-day moving average, predicts next-day mean reversion when high price extremes occur on thinning relative volume.\n                Concise Observation: The parent strategy focused on institutional floors via lower shadows and volume stability, but failed to capture the 'blow-off' or 'exhaustion' phase where price continues to move while volume participation drops.\n                Concise Justification: Price discovery requires volume validation; a high 'Closing Range' score (price near high) coupled with low 'Volume Intensity' suggests liquidity exhaustion rather than a sustainable breakout, making the asset prone to a reversal.\n                Concise Knowledge: If a price reaches its daily extreme on declining relative volume, it indicates a lack of institutional follow-through; when retail-driven late-day momentum lacks volume support, market makers likely over-extend prices, leading to a mean-reverting snap-back.\n                concise Specification: Calculate the daily 'Closing Position' as ($close - $low) / ($high - $low + 1e-8) and multiply it by the 'Volume Surge' ($volume / TS_MEAN($volume, 5)); a high value indicates strong, volume-backed closes (momentum), while a low value with high price position indicates exhaustion (reversal).\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T08:44:46.702334"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0801096653999234,
        "ICIR": 0.0323137840858001,
        "1day.excess_return_without_cost.std": 0.0038933268536367,
        "1day.excess_return_with_cost.annualized_return": 0.0224067038418408,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002916131544456,
        "1day.excess_return_without_cost.annualized_return": 0.0694039307580737,
        "1day.excess_return_with_cost.std": 0.0038951193400999,
        "Rank IC": 0.0223438865785895,
        "IC": 0.0046130019394651,
        "1day.excess_return_without_cost.max_drawdown": -0.0636899799289828,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1555127025750906,
        "1day.pa": 0.0,
        "l2.valid": 0.9963781161583856,
        "Rank ICIR": 0.1589113087694215,
        "l2.train": 0.9935972769811862,
        "1day.excess_return_with_cost.information_ratio": 0.3728796885191014,
        "1day.excess_return_with_cost.mean": 9.41458144615162e-05
      },
      "feedback": {
        "observations": "The current iteration tested three variations of the 'Late-Day Trend Exhaustion' hypothesis. The results show a significant improvement in risk-adjusted performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.15, and the Annualized Return rose from 5.2% to 6.9%. While the Information Coefficient (IC) saw a slight decrease (0.0058 to 0.0046), the reduction in Max Drawdown (-0.072 to -0.063) suggests that the current factor set captures higher-quality, lower-volatility signals. The 'Smoothed_Exhaustion_Index_10D' likely contributed to this stability by filtering out daily noise through the Z-score and 10-day window.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining price positioning (Close relative to High/Low) with volume intensity provides a predictive signal for mean reversion. The success of the 'Exhaustion_Reversal_Rank' and 'Smoothed_Exhaustion_Index_10D' suggests that the 'thinning volume' component is more effective when viewed as a divergence (rank difference) or a time-series anomaly (Z-score) rather than a simple product of price and volume.",
        "decision": true,
        "reason": "The current factors utilize a 5-day volume mean, but do not account for the magnitude of the price range relative to historical volatility (ATR). By incorporating a 'Volatility-Adjusted Range' and checking if the current volume is not just low, but declining over multiple days (negative volume slope), we can better isolate 'blow-off' exhaustion from simple low-liquidity consolidation. This addresses the 'thinning' aspect more dynamically."
      }
    },
    "5ad33d7cac53239a": {
      "factor_id": "5ad33d7cac53239a",
      "factor_name": "VSLLI_Factor_20D",
      "factor_expression": "TS_CORR($return, DELAY(MEAN($return * $volume) / (MEAN($volume) + 1e-8), 1), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(MEAN(TS_PCTCHANGE($close, 1) * $volume) / MEAN($volume) + ($close * 0), 1), 20)\" # Your output factor expression will be filled in here\n    name = \"VSLLI_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'Volume-Synchronized Lead-Lag Inertia' by calculating the 20-day correlation between a stock's current returns and the 1-day lagged turnover-weighted market returns. It identifies laggard stocks that are catching up to market movements driven by institutional flows.",
      "factor_formulation": "\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{MEAN}(\\text{return} \\times \\text{volume}) / \\text{MEAN}(\\text{volume}), 1), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "89654af3e60a",
        "parent_trajectory_ids": [
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) factor, defined as the rolling 20-day correlation between a stock's current returns and its 1-day lagged turnover-weighted market returns, identifies stocks with delayed information processing that are likely to continue their catch-up trend.\n                Concise Observation: While microstructure factors like LGSF focus on individual asset fragility, market-wide capital flows often show a ripple effect where high-liquidity leaders move first and low-turnover laggards follow with a measurable temporal delay.\n                Concise Justification: Institutional rebalancing and sector-rotation strategies often execute in waves, causing information to reflect in 'secondary' stocks slower than in 'primary' market proxies, creating a predictable lead-lag relationship driven by turnover intensity.\n                Concise Knowledge: If a stock's price discovery lags behind broader market movements due to lower turnover velocity, it will exhibit a positive correlation with lagged market returns; when this correlation is high, the stock tends to maintain its current directional inertia as information continues to diffuse.\n                concise Specification: The factor measures the 20-day Pearson correlation between the individual stock's daily return and the previous day's market-wide average return (weighted by volume), specifically targeting the 1-day diffusion window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T08:55:48.625002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0901795340266726,
        "ICIR": 0.0435174213312811,
        "1day.excess_return_without_cost.std": 0.004391030506516,
        "1day.excess_return_with_cost.annualized_return": 0.0467478739753404,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003936653318094,
        "1day.excess_return_without_cost.annualized_return": 0.0936923489706588,
        "1day.excess_return_with_cost.std": 0.0043948988450943,
        "Rank IC": 0.0212936587260516,
        "IC": 0.0057787701447008,
        "1day.excess_return_without_cost.max_drawdown": -0.081716614888749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3830860291452696,
        "1day.pa": 0.0,
        "l2.valid": 0.9965779431652604,
        "Rank ICIR": 0.1644664595971306,
        "l2.train": 0.9939897299184864,
        "1day.excess_return_with_cost.information_ratio": 0.6894844920671283,
        "1day.excess_return_with_cost.mean": 0.0001964196385518
      },
      "feedback": {
        "observations": "The current iteration significantly improved the Information Ratio (from 0.97 to 1.38) and Annualized Return (from 5.2% to 9.37%) compared to the SOTA, although the IC remained nearly identical (0.0058 vs 0.0058) and Max Drawdown slightly increased. The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) framework proves effective, particularly when using turnover-weighted market proxies. The results suggest that while the signal's raw correlation with future returns (IC) is stable, the quality of the risk-adjusted returns (IR) has been substantially enhanced by the current factor formulations.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that lead-lag inertia relative to turnover-weighted market returns identifies profitable 'catch-up' trends. The VSLLI_Factor_20D and its variants successfully capture a diffusion of information. However, the slight increase in Max Drawdown suggests that while the 'catch-up' trend is real, it may be subject to higher volatility or sharper reversals during market regime shifts.",
        "decision": true,
        "reason": "The current factors use a symmetric Pearson correlation which treats positive and negative lead-lag relationships equally. In quantitative finance, momentum and inertia often exhibit asymmetry. By conditioning the lead-lag correlation on the direction of the market or by using a shorter, more reactive window (like 10 days) specifically during high-volume periods, we can potentially reduce the Max Drawdown observed in the current results while maintaining the high Information Ratio. Furthermore, simplifying the market proxy (as seen in the 10D variant) helps maintain a low Symbol Length and prevents overfitting."
      }
    },
    "4de3af3f2b854bf8": {
      "factor_id": "4de3af3f2b854bf8",
      "factor_name": "Laggard_Inertia_ZScore_20D",
      "factor_expression": "TS_CORR($return, DELAY(MEDIAN($return), 1), 20) / (TS_STD($return, 20) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(MEDIAN(TS_PCTCHANGE($close, 1)) + ($close * 0), 1), 20) / TS_STD(TS_PCTCHANGE($close, 1), 20)\" # Your output factor expression will be filled in here\n    name = \"Laggard_Inertia_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the lead-lag inertia hypothesis that focuses on the stock's sensitivity to the previous day's cross-sectional median return, normalized by the stock's own return volatility to ensure the signal captures consistent following behavior rather than noise.",
      "factor_formulation": "\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{MEDIAN}(\\text{return}), 1), 20) / \\text{TS\\_STD}(\\text{return}, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "89654af3e60a",
        "parent_trajectory_ids": [
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) factor, defined as the rolling 20-day correlation between a stock's current returns and its 1-day lagged turnover-weighted market returns, identifies stocks with delayed information processing that are likely to continue their catch-up trend.\n                Concise Observation: While microstructure factors like LGSF focus on individual asset fragility, market-wide capital flows often show a ripple effect where high-liquidity leaders move first and low-turnover laggards follow with a measurable temporal delay.\n                Concise Justification: Institutional rebalancing and sector-rotation strategies often execute in waves, causing information to reflect in 'secondary' stocks slower than in 'primary' market proxies, creating a predictable lead-lag relationship driven by turnover intensity.\n                Concise Knowledge: If a stock's price discovery lags behind broader market movements due to lower turnover velocity, it will exhibit a positive correlation with lagged market returns; when this correlation is high, the stock tends to maintain its current directional inertia as information continues to diffuse.\n                concise Specification: The factor measures the 20-day Pearson correlation between the individual stock's daily return and the previous day's market-wide average return (weighted by volume), specifically targeting the 1-day diffusion window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T08:55:48.625002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0901795340266726,
        "ICIR": 0.0435174213312811,
        "1day.excess_return_without_cost.std": 0.004391030506516,
        "1day.excess_return_with_cost.annualized_return": 0.0467478739753404,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003936653318094,
        "1day.excess_return_without_cost.annualized_return": 0.0936923489706588,
        "1day.excess_return_with_cost.std": 0.0043948988450943,
        "Rank IC": 0.0212936587260516,
        "IC": 0.0057787701447008,
        "1day.excess_return_without_cost.max_drawdown": -0.081716614888749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3830860291452696,
        "1day.pa": 0.0,
        "l2.valid": 0.9965779431652604,
        "Rank ICIR": 0.1644664595971306,
        "l2.train": 0.9939897299184864,
        "1day.excess_return_with_cost.information_ratio": 0.6894844920671283,
        "1day.excess_return_with_cost.mean": 0.0001964196385518
      },
      "feedback": {
        "observations": "The current iteration significantly improved the Information Ratio (from 0.97 to 1.38) and Annualized Return (from 5.2% to 9.37%) compared to the SOTA, although the IC remained nearly identical (0.0058 vs 0.0058) and Max Drawdown slightly increased. The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) framework proves effective, particularly when using turnover-weighted market proxies. The results suggest that while the signal's raw correlation with future returns (IC) is stable, the quality of the risk-adjusted returns (IR) has been substantially enhanced by the current factor formulations.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that lead-lag inertia relative to turnover-weighted market returns identifies profitable 'catch-up' trends. The VSLLI_Factor_20D and its variants successfully capture a diffusion of information. However, the slight increase in Max Drawdown suggests that while the 'catch-up' trend is real, it may be subject to higher volatility or sharper reversals during market regime shifts.",
        "decision": true,
        "reason": "The current factors use a symmetric Pearson correlation which treats positive and negative lead-lag relationships equally. In quantitative finance, momentum and inertia often exhibit asymmetry. By conditioning the lead-lag correlation on the direction of the market or by using a shorter, more reactive window (like 10 days) specifically during high-volume periods, we can potentially reduce the Max Drawdown observed in the current results while maintaining the high Information Ratio. Furthermore, simplifying the market proxy (as seen in the 10D variant) helps maintain a low Symbol Length and prevents overfitting."
      }
    },
    "116c5a4023c21799": {
      "factor_id": "116c5a4023c21799",
      "factor_name": "Turnover_Weighted_Market_Lag_10D",
      "factor_expression": "TS_CORR($return, DELAY(MEAN($return * ($volume / ($close + 1e-8))), 1), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(MEAN(TS_PCTCHANGE($close, 1) * ($volume / $close)) + ($close * 0), 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Turnover_Weighted_Market_Lag_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the short-term (10-day) lead-lag effect using a simplified turnover-weighted market proxy. It targets stocks that show high synchronization with the previous day's market-wide price action, suggesting a diffusion of information from high-volume leaders to the target asset.",
      "factor_formulation": "\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{MEAN}(\\text{return} \\times (\\text{volume} / \\text{close})), 1), 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "89654af3e60a",
        "parent_trajectory_ids": [
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) factor, defined as the rolling 20-day correlation between a stock's current returns and its 1-day lagged turnover-weighted market returns, identifies stocks with delayed information processing that are likely to continue their catch-up trend.\n                Concise Observation: While microstructure factors like LGSF focus on individual asset fragility, market-wide capital flows often show a ripple effect where high-liquidity leaders move first and low-turnover laggards follow with a measurable temporal delay.\n                Concise Justification: Institutional rebalancing and sector-rotation strategies often execute in waves, causing information to reflect in 'secondary' stocks slower than in 'primary' market proxies, creating a predictable lead-lag relationship driven by turnover intensity.\n                Concise Knowledge: If a stock's price discovery lags behind broader market movements due to lower turnover velocity, it will exhibit a positive correlation with lagged market returns; when this correlation is high, the stock tends to maintain its current directional inertia as information continues to diffuse.\n                concise Specification: The factor measures the 20-day Pearson correlation between the individual stock's daily return and the previous day's market-wide average return (weighted by volume), specifically targeting the 1-day diffusion window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T08:55:48.625002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0901795340266726,
        "ICIR": 0.0435174213312811,
        "1day.excess_return_without_cost.std": 0.004391030506516,
        "1day.excess_return_with_cost.annualized_return": 0.0467478739753404,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003936653318094,
        "1day.excess_return_without_cost.annualized_return": 0.0936923489706588,
        "1day.excess_return_with_cost.std": 0.0043948988450943,
        "Rank IC": 0.0212936587260516,
        "IC": 0.0057787701447008,
        "1day.excess_return_without_cost.max_drawdown": -0.081716614888749,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3830860291452696,
        "1day.pa": 0.0,
        "l2.valid": 0.9965779431652604,
        "Rank ICIR": 0.1644664595971306,
        "l2.train": 0.9939897299184864,
        "1day.excess_return_with_cost.information_ratio": 0.6894844920671283,
        "1day.excess_return_with_cost.mean": 0.0001964196385518
      },
      "feedback": {
        "observations": "The current iteration significantly improved the Information Ratio (from 0.97 to 1.38) and Annualized Return (from 5.2% to 9.37%) compared to the SOTA, although the IC remained nearly identical (0.0058 vs 0.0058) and Max Drawdown slightly increased. The 'Volume-Synchronized Lead-Lag Inertia' (VSLLI) framework proves effective, particularly when using turnover-weighted market proxies. The results suggest that while the signal's raw correlation with future returns (IC) is stable, the quality of the risk-adjusted returns (IR) has been substantially enhanced by the current factor formulations.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that lead-lag inertia relative to turnover-weighted market returns identifies profitable 'catch-up' trends. The VSLLI_Factor_20D and its variants successfully capture a diffusion of information. However, the slight increase in Max Drawdown suggests that while the 'catch-up' trend is real, it may be subject to higher volatility or sharper reversals during market regime shifts.",
        "decision": true,
        "reason": "The current factors use a symmetric Pearson correlation which treats positive and negative lead-lag relationships equally. In quantitative finance, momentum and inertia often exhibit asymmetry. By conditioning the lead-lag correlation on the direction of the market or by using a shorter, more reactive window (like 10 days) specifically during high-volume periods, we can potentially reduce the Max Drawdown observed in the current results while maintaining the high Information Ratio. Furthermore, simplifying the market proxy (as seen in the 10D variant) helps maintain a low Symbol Length and prevents overfitting."
      }
    },
    "08ce691d3c8e82a6": {
      "factor_id": "08ce691d3c8e82a6",
      "factor_name": "Trend_Fragility_Index_5_10",
      "factor_expression": "TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies trend exhaustion by calculating the ratio of short-term volatility (5-day standard deviation) to medium-term trend linearity (10-day R-squared). A high value indicates that price action is becoming erratic relative to its established linear trend, signaling a potential reversal.",
      "factor_formulation": "TFI = \\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "38fdb87aa6aa",
        "parent_trajectory_ids": [
          "3074579fb242"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI) predicts price reversals by identifying regimes where short-term price volatility (STD5) significantly decouples from medium-term trend linearity (RSQR10), signaling that the current price direction is no longer supported by stable structural growth.\n                Concise Observation: The parent strategy successfully captured trend exhaustion using 10-day price-time linearity, but it ignored the destabilizing effect of rising short-term volatility which often precedes a trend break.\n                Concise Justification: A high ratio of short-term standard deviation to medium-term R-squared suggests that price action is becoming erratic and 'noisy' relative to its established path, indicating that the trend is becoming fragile and prone to a structural break.\n                Concise Knowledge: If a price trend's linear persistence (RSQR) decreases while its noise or local variance (STD) increases, the trend is likely to collapse; high volatility within a weakening structural trend indicates a loss of consensus among market participants.\n                concise Specification: The factor is defined as the ratio of the 5-day standard deviation of close prices to the squared 10-day Pearson correlation between close prices and a time sequence; higher values should predict a negative shift in the subsequent 5-day return.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T09:08:07.704116"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1497271446283253,
        "ICIR": 0.0156242842069791,
        "1day.excess_return_without_cost.std": 0.0041427391715111,
        "1day.excess_return_with_cost.annualized_return": -0.0156093282905237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001331126623437,
        "1day.excess_return_without_cost.annualized_return": 0.0316808136378092,
        "1day.excess_return_with_cost.std": 0.0041432624803664,
        "Rank IC": 0.0119562947443178,
        "IC": 0.0020123187424154,
        "1day.excess_return_without_cost.max_drawdown": -0.1166276566275141,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4957015277816668,
        "1day.pa": 0.0,
        "l2.valid": 0.9969541057060816,
        "Rank ICIR": 0.0913234254257069,
        "l2.train": 0.9941200196468376,
        "1day.excess_return_with_cost.information_ratio": -0.2442042899288067,
        "1day.excess_return_with_cost.mean": -6.558541298539411e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the decoupling of volatility and trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_5_10, NVLD, and CSFR) underperformed compared to the SOTA result across all key metrics. The Information Ratio (0.496 vs 0.973) and IC (0.0020 vs 0.0058) show a significant gap in predictive power. The results suggest that while the ratio of volatility to linearity captures some signal, the current mathematical formulations might be too noisy or the look-back windows (5, 10, 20) are not yet optimized to capture the specific 'fragility' window effectively.",
        "hypothesis_evaluation": "The hypothesis that volatility-linearity decoupling predicts reversals is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'fragility' signal is currently being overwhelmed by noise. The use of $close in the R-squared calculation (linearity) might be redundant when combined with $close-based volatility. The Cross-Sectional Fragility Rank (CSFR) using (high-low) for volatility is a promising direction but needs better normalization.",
        "decision": false,
        "reason": "Linear correlation (RSQR) can be high even in volatile markets if the trend is steep, which may not truly represent 'stability'. The Efficiency Ratio (Kaufman's Efficiency Ratio) specifically measures how much price movement is 'wasted' on noise. By replacing RSQR with the Efficiency Ratio and using a normalized Intraday Range (High-Low)/Close, we can create a cleaner 'Noise-to-Trend' ratio that avoids the complexity of SEQUENCE functions and better identifies structural exhaustion."
      }
    },
    "902bec3389f6933a": {
      "factor_id": "902bec3389f6933a",
      "factor_name": "Normalized_Volatility_Linearity_Decoupling",
      "factor_expression": "TS_STD($return, 10) / (ABS(TS_CORR($close, SEQUENCE(10), 10)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_PCTCHANGE($close, 1), 10) / (ABS(TS_CORR($close, SEQUENCE(10), 10)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Normalized_Volatility_Linearity_Decoupling\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the Trend Fragility Index that uses the Z-score of returns for volatility and the absolute correlation for trend strength. It measures the divergence between the intensity of price fluctuations and the consistency of the directional move over a 10-day window.",
      "factor_formulation": "NVLD = \\frac{TS\\_STD(return, 10)}{ABS(TS\\_CORR(close, SEQUENCE(10), 10))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "38fdb87aa6aa",
        "parent_trajectory_ids": [
          "3074579fb242"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI) predicts price reversals by identifying regimes where short-term price volatility (STD5) significantly decouples from medium-term trend linearity (RSQR10), signaling that the current price direction is no longer supported by stable structural growth.\n                Concise Observation: The parent strategy successfully captured trend exhaustion using 10-day price-time linearity, but it ignored the destabilizing effect of rising short-term volatility which often precedes a trend break.\n                Concise Justification: A high ratio of short-term standard deviation to medium-term R-squared suggests that price action is becoming erratic and 'noisy' relative to its established path, indicating that the trend is becoming fragile and prone to a structural break.\n                Concise Knowledge: If a price trend's linear persistence (RSQR) decreases while its noise or local variance (STD) increases, the trend is likely to collapse; high volatility within a weakening structural trend indicates a loss of consensus among market participants.\n                concise Specification: The factor is defined as the ratio of the 5-day standard deviation of close prices to the squared 10-day Pearson correlation between close prices and a time sequence; higher values should predict a negative shift in the subsequent 5-day return.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T09:08:07.704116"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1497271446283253,
        "ICIR": 0.0156242842069791,
        "1day.excess_return_without_cost.std": 0.0041427391715111,
        "1day.excess_return_with_cost.annualized_return": -0.0156093282905237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001331126623437,
        "1day.excess_return_without_cost.annualized_return": 0.0316808136378092,
        "1day.excess_return_with_cost.std": 0.0041432624803664,
        "Rank IC": 0.0119562947443178,
        "IC": 0.0020123187424154,
        "1day.excess_return_without_cost.max_drawdown": -0.1166276566275141,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4957015277816668,
        "1day.pa": 0.0,
        "l2.valid": 0.9969541057060816,
        "Rank ICIR": 0.0913234254257069,
        "l2.train": 0.9941200196468376,
        "1day.excess_return_with_cost.information_ratio": -0.2442042899288067,
        "1day.excess_return_with_cost.mean": -6.558541298539411e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the decoupling of volatility and trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_5_10, NVLD, and CSFR) underperformed compared to the SOTA result across all key metrics. The Information Ratio (0.496 vs 0.973) and IC (0.0020 vs 0.0058) show a significant gap in predictive power. The results suggest that while the ratio of volatility to linearity captures some signal, the current mathematical formulations might be too noisy or the look-back windows (5, 10, 20) are not yet optimized to capture the specific 'fragility' window effectively.",
        "hypothesis_evaluation": "The hypothesis that volatility-linearity decoupling predicts reversals is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'fragility' signal is currently being overwhelmed by noise. The use of $close in the R-squared calculation (linearity) might be redundant when combined with $close-based volatility. The Cross-Sectional Fragility Rank (CSFR) using (high-low) for volatility is a promising direction but needs better normalization.",
        "decision": false,
        "reason": "Linear correlation (RSQR) can be high even in volatile markets if the trend is steep, which may not truly represent 'stability'. The Efficiency Ratio (Kaufman's Efficiency Ratio) specifically measures how much price movement is 'wasted' on noise. By replacing RSQR with the Efficiency Ratio and using a normalized Intraday Range (High-Low)/Close, we can create a cleaner 'Noise-to-Trend' ratio that avoids the complexity of SEQUENCE functions and better identifies structural exhaustion."
      }
    },
    "02ad70fe5e56a000": {
      "factor_id": "02ad70fe5e56a000",
      "factor_name": "Cross_Sectional_Fragility_Rank",
      "factor_expression": "RANK(TS_STD($high - $low, 5) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($high - $low, 5) / (ABS(TS_CORR($close, SEQUENCE(20), 20)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Fragility_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor ranks the fragility of trends across the market. It compares the 5-day price range volatility to the 20-day trend persistence, cross-sectionally ranking the result to identify stocks with the most 'fragile' price structures relative to their peers.",
      "factor_formulation": "CSFR = RANK(\\frac{TS\\_STD(high - low, 5)}{ABS(TS\\_CORR(close, SEQUENCE(20), 20))})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "38fdb87aa6aa",
        "parent_trajectory_ids": [
          "3074579fb242"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI) predicts price reversals by identifying regimes where short-term price volatility (STD5) significantly decouples from medium-term trend linearity (RSQR10), signaling that the current price direction is no longer supported by stable structural growth.\n                Concise Observation: The parent strategy successfully captured trend exhaustion using 10-day price-time linearity, but it ignored the destabilizing effect of rising short-term volatility which often precedes a trend break.\n                Concise Justification: A high ratio of short-term standard deviation to medium-term R-squared suggests that price action is becoming erratic and 'noisy' relative to its established path, indicating that the trend is becoming fragile and prone to a structural break.\n                Concise Knowledge: If a price trend's linear persistence (RSQR) decreases while its noise or local variance (STD) increases, the trend is likely to collapse; high volatility within a weakening structural trend indicates a loss of consensus among market participants.\n                concise Specification: The factor is defined as the ratio of the 5-day standard deviation of close prices to the squared 10-day Pearson correlation between close prices and a time sequence; higher values should predict a negative shift in the subsequent 5-day return.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T09:08:07.704116"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1497271446283253,
        "ICIR": 0.0156242842069791,
        "1day.excess_return_without_cost.std": 0.0041427391715111,
        "1day.excess_return_with_cost.annualized_return": -0.0156093282905237,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001331126623437,
        "1day.excess_return_without_cost.annualized_return": 0.0316808136378092,
        "1day.excess_return_with_cost.std": 0.0041432624803664,
        "Rank IC": 0.0119562947443178,
        "IC": 0.0020123187424154,
        "1day.excess_return_without_cost.max_drawdown": -0.1166276566275141,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4957015277816668,
        "1day.pa": 0.0,
        "l2.valid": 0.9969541057060816,
        "Rank ICIR": 0.0913234254257069,
        "l2.train": 0.9941200196468376,
        "1day.excess_return_with_cost.information_ratio": -0.2442042899288067,
        "1day.excess_return_with_cost.mean": -6.558541298539411e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Trend Fragility Index' (TFI) concept, focusing on the decoupling of volatility and trend linearity. While the theoretical framework is sound, the current implementations (Trend_Fragility_Index_5_10, NVLD, and CSFR) underperformed compared to the SOTA result across all key metrics. The Information Ratio (0.496 vs 0.973) and IC (0.0020 vs 0.0058) show a significant gap in predictive power. The results suggest that while the ratio of volatility to linearity captures some signal, the current mathematical formulations might be too noisy or the look-back windows (5, 10, 20) are not yet optimized to capture the specific 'fragility' window effectively.",
        "hypothesis_evaluation": "The hypothesis that volatility-linearity decoupling predicts reversals is partially supported by the positive IC, but the weak performance relative to SOTA suggests the 'fragility' signal is currently being overwhelmed by noise. The use of $close in the R-squared calculation (linearity) might be redundant when combined with $close-based volatility. The Cross-Sectional Fragility Rank (CSFR) using (high-low) for volatility is a promising direction but needs better normalization.",
        "decision": false,
        "reason": "Linear correlation (RSQR) can be high even in volatile markets if the trend is steep, which may not truly represent 'stability'. The Efficiency Ratio (Kaufman's Efficiency Ratio) specifically measures how much price movement is 'wasted' on noise. By replacing RSQR with the Efficiency Ratio and using a normalized Intraday Range (High-Low)/Close, we can create a cleaner 'Noise-to-Trend' ratio that avoids the complexity of SEQUENCE functions and better identifies structural exhaustion."
      }
    },
    "8c503de13e77a254": {
      "factor_id": "8c503de13e77a254",
      "factor_name": "MRLV_Exhaustion_Ratio_10D",
      "factor_expression": "($high - $low) / (TS_MEAN($volume, 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($high - $low) / (TS_MEAN($volume, 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"MRLV_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price exhaustion by calculating the ratio of the current intraday range to the average volume over the last 10 days. A high ratio suggests a 'liquidity vacuum' where price moves are extended on relatively low volume, signaling a likely mean reversion.",
      "factor_formulation": "\\frac{high - low}{TS\\_MEAN(volume, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8ae114e41fee",
        "parent_trajectory_ids": [
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts short-term price reversals by identifying extreme intraday price extensions (high-low range) that occur on abnormally low volume, signaling a lack of liquidity support for the move.\n                Concise Observation: While the parent strategy succeeded by identifying high-volume absorption, many failed breakouts or sharp intraday spikes occur on thin volume, leading to immediate mean reversion.\n                Concise Justification: Market moves require liquidity to be sustained; a large price range relative to low trading volume suggests that the price was pushed by a small number of orders into a vacuum, making the level unsustainable.\n                Concise Knowledge: If a price extension occurs with diminishing volume, it likely represents a 'liquidity hole' rather than true conviction; such moves are prone to mechanical reversals when liquidity returns.\n                concise Specification: The factor is defined as the ratio of the intraday range ($high - $low) to the 10-day moving average of volume, specifically targeting the highest decile of range-to-volume ratios to signal exhaustion.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T09:13:25.149880"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1353241383765642,
        "ICIR": 0.0394741876949481,
        "1day.excess_return_without_cost.std": 0.0038109641119365,
        "1day.excess_return_with_cost.annualized_return": 0.0066348160571117,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002270410165916,
        "1day.excess_return_without_cost.annualized_return": 0.0540357619488201,
        "1day.excess_return_with_cost.std": 0.0038129474086759,
        "Rank IC": 0.0211590901160197,
        "IC": 0.0050222177334219,
        "1day.excess_return_without_cost.max_drawdown": -0.0782353804776635,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9190897912288354,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211160162996,
        "Rank ICIR": 0.1691260620766468,
        "l2.train": 0.9935959666700008,
        "1day.excess_return_with_cost.information_ratio": 0.112792336540432,
        "1day.excess_return_with_cost.mean": 2.787737839122564e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. The current results show a slight improvement in annualized return (0.0540 vs 0.0520) compared to the SOTA, but a decline in Information Ratio (0.919 vs 0.972) and IC (0.0050 vs 0.0058), along with a deeper maximum drawdown. This suggests that while the current iteration captures higher absolute returns, the risk-adjusted performance and predictive consistency (IC) have weakened. The factors successfully utilized the relationship between price range and volume, but the 'Vacuum Intensity Rank' approach might be introducing noise by multiplying ranks, which often leads to non-linearities that are harder for simple models to generalize.",
        "hypothesis_evaluation": "The hypothesis that extreme price extensions on low volume signal mean reversion is partially supported by the positive annualized return. However, the drop in IC and IR suggests that the current implementation (specifically the ranking and Z-score methods) may be too sensitive to outliers or cross-sectional noise. The 'liquidity vacuum' concept is sound, but the interaction between the intraday range and volume needs a more robust normalization than simple division or ranking to capture the 'exhaustion' point accurately.",
        "decision": true,
        "reason": "The current factors use the raw 'high-low' range, which is not stationary and varies significantly across different stocks and time periods. By using a Volatility-Adjusted Range (Range/ATR), we isolate 'abnormal' price movement. Combining this with a volume decay signal (Current Volume / 20-day Mean Volume) will more precisely identify the exhaustion points where price has moved too far without sufficient commitment, reducing the noise observed in the current IC and IR metrics."
      }
    },
    "998aa107b459b403": {
      "factor_id": "998aa107b459b403",
      "factor_name": "MRLV_Relative_Range_Volume_ZScore",
      "factor_expression": "ZSCORE(($high - $low) / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($high - $low) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MRLV_Relative_Range_Volume_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the divergence between price volatility and liquidity by taking the Z-score of the ratio between the intraday range and the current volume. It highlights extreme price extensions relative to immediate liquidity, normalized cross-sectionally to identify the most vulnerable stocks.",
      "factor_formulation": "ZSCORE(\\frac{high - low}{volume})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8ae114e41fee",
        "parent_trajectory_ids": [
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts short-term price reversals by identifying extreme intraday price extensions (high-low range) that occur on abnormally low volume, signaling a lack of liquidity support for the move.\n                Concise Observation: While the parent strategy succeeded by identifying high-volume absorption, many failed breakouts or sharp intraday spikes occur on thin volume, leading to immediate mean reversion.\n                Concise Justification: Market moves require liquidity to be sustained; a large price range relative to low trading volume suggests that the price was pushed by a small number of orders into a vacuum, making the level unsustainable.\n                Concise Knowledge: If a price extension occurs with diminishing volume, it likely represents a 'liquidity hole' rather than true conviction; such moves are prone to mechanical reversals when liquidity returns.\n                concise Specification: The factor is defined as the ratio of the intraday range ($high - $low) to the 10-day moving average of volume, specifically targeting the highest decile of range-to-volume ratios to signal exhaustion.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T09:13:25.149880"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1353241383765642,
        "ICIR": 0.0394741876949481,
        "1day.excess_return_without_cost.std": 0.0038109641119365,
        "1day.excess_return_with_cost.annualized_return": 0.0066348160571117,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002270410165916,
        "1day.excess_return_without_cost.annualized_return": 0.0540357619488201,
        "1day.excess_return_with_cost.std": 0.0038129474086759,
        "Rank IC": 0.0211590901160197,
        "IC": 0.0050222177334219,
        "1day.excess_return_without_cost.max_drawdown": -0.0782353804776635,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9190897912288354,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211160162996,
        "Rank ICIR": 0.1691260620766468,
        "l2.train": 0.9935959666700008,
        "1day.excess_return_with_cost.information_ratio": 0.112792336540432,
        "1day.excess_return_with_cost.mean": 2.787737839122564e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. The current results show a slight improvement in annualized return (0.0540 vs 0.0520) compared to the SOTA, but a decline in Information Ratio (0.919 vs 0.972) and IC (0.0050 vs 0.0058), along with a deeper maximum drawdown. This suggests that while the current iteration captures higher absolute returns, the risk-adjusted performance and predictive consistency (IC) have weakened. The factors successfully utilized the relationship between price range and volume, but the 'Vacuum Intensity Rank' approach might be introducing noise by multiplying ranks, which often leads to non-linearities that are harder for simple models to generalize.",
        "hypothesis_evaluation": "The hypothesis that extreme price extensions on low volume signal mean reversion is partially supported by the positive annualized return. However, the drop in IC and IR suggests that the current implementation (specifically the ranking and Z-score methods) may be too sensitive to outliers or cross-sectional noise. The 'liquidity vacuum' concept is sound, but the interaction between the intraday range and volume needs a more robust normalization than simple division or ranking to capture the 'exhaustion' point accurately.",
        "decision": true,
        "reason": "The current factors use the raw 'high-low' range, which is not stationary and varies significantly across different stocks and time periods. By using a Volatility-Adjusted Range (Range/ATR), we isolate 'abnormal' price movement. Combining this with a volume decay signal (Current Volume / 20-day Mean Volume) will more precisely identify the exhaustion points where price has moved too far without sufficient commitment, reducing the noise observed in the current IC and IR metrics."
      }
    },
    "db95221a35e8a3cc": {
      "factor_id": "db95221a35e8a3cc",
      "factor_name": "MRLV_Vacuum_Intensity_Rank",
      "factor_expression": "RANK($high - $low) * RANK(1.0 - TS_RANK($volume, 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($high - $low) * RANK(1.0 - TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"MRLV_Vacuum_Intensity_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor combines the intensity of the price range with a low-volume penalty. It ranks stocks based on the product of their intraday range and the inverse of their volume relative to its 20-day history, specifically looking for high-range moves that lack volume confirmation.",
      "factor_formulation": "RANK(high - low) * RANK(1 - TS\\_RANK(volume, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "8ae114e41fee",
        "parent_trajectory_ids": [
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Mean-Reverting Liquidity Vacuum' (MRLV) factor predicts short-term price reversals by identifying extreme intraday price extensions (high-low range) that occur on abnormally low volume, signaling a lack of liquidity support for the move.\n                Concise Observation: While the parent strategy succeeded by identifying high-volume absorption, many failed breakouts or sharp intraday spikes occur on thin volume, leading to immediate mean reversion.\n                Concise Justification: Market moves require liquidity to be sustained; a large price range relative to low trading volume suggests that the price was pushed by a small number of orders into a vacuum, making the level unsustainable.\n                Concise Knowledge: If a price extension occurs with diminishing volume, it likely represents a 'liquidity hole' rather than true conviction; such moves are prone to mechanical reversals when liquidity returns.\n                concise Specification: The factor is defined as the ratio of the intraday range ($high - $low) to the 10-day moving average of volume, specifically targeting the highest decile of range-to-volume ratios to signal exhaustion.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T09:13:25.149880"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1353241383765642,
        "ICIR": 0.0394741876949481,
        "1day.excess_return_without_cost.std": 0.0038109641119365,
        "1day.excess_return_with_cost.annualized_return": 0.0066348160571117,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002270410165916,
        "1day.excess_return_without_cost.annualized_return": 0.0540357619488201,
        "1day.excess_return_with_cost.std": 0.0038129474086759,
        "Rank IC": 0.0211590901160197,
        "IC": 0.0050222177334219,
        "1day.excess_return_without_cost.max_drawdown": -0.0782353804776635,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9190897912288354,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211160162996,
        "Rank ICIR": 0.1691260620766468,
        "l2.train": 0.9935959666700008,
        "1day.excess_return_with_cost.information_ratio": 0.112792336540432,
        "1day.excess_return_with_cost.mean": 2.787737839122564e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Mean-Reverting Liquidity Vacuum' (MRLV) hypothesis. The current results show a slight improvement in annualized return (0.0540 vs 0.0520) compared to the SOTA, but a decline in Information Ratio (0.919 vs 0.972) and IC (0.0050 vs 0.0058), along with a deeper maximum drawdown. This suggests that while the current iteration captures higher absolute returns, the risk-adjusted performance and predictive consistency (IC) have weakened. The factors successfully utilized the relationship between price range and volume, but the 'Vacuum Intensity Rank' approach might be introducing noise by multiplying ranks, which often leads to non-linearities that are harder for simple models to generalize.",
        "hypothesis_evaluation": "The hypothesis that extreme price extensions on low volume signal mean reversion is partially supported by the positive annualized return. However, the drop in IC and IR suggests that the current implementation (specifically the ranking and Z-score methods) may be too sensitive to outliers or cross-sectional noise. The 'liquidity vacuum' concept is sound, but the interaction between the intraday range and volume needs a more robust normalization than simple division or ranking to capture the 'exhaustion' point accurately.",
        "decision": true,
        "reason": "The current factors use the raw 'high-low' range, which is not stationary and varies significantly across different stocks and time periods. By using a Volatility-Adjusted Range (Range/ATR), we isolate 'abnormal' price movement. Combining this with a volume decay signal (Current Volume / 20-day Mean Volume) will more precisely identify the exhaustion points where price has moved too far without sufficient commitment, reducing the noise observed in the current IC and IR metrics."
      }
    },
    "089404eff5915be7": {
      "factor_id": "089404eff5915be7",
      "factor_name": "Liquidity_Exhaustion_Skew_Factor",
      "factor_expression": "RANK(TS_MEAN(POW($return, 3) * $volume, 5) / (TS_MEDIAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(POW(TS_PCTCHANGE($close, 1), 3) * $volume, 5) / (TS_MEDIAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Skew_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by combining volume-weighted price skewness with abnormal turnover. It captures 'blow-off' tops or 'panic' bottoms where extreme liquidity demand leads to price exhaustion. High values suggest a reversal is likely as the liquidity shock subsides.",
      "factor_formulation": "LE\\_Skew = \\text{RANK}\\left( \\frac{\\text{TS\\_MEAN}(\\text{return}^3 \\times \\text{volume}, 5)}{\\text{TS\\_MEDIAN}(\\text{volume}, 20) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6becae249925",
        "parent_trajectory_ids": [
          "ebb95d0d34c5"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Exhaustion Reversal' factor, calculated as the product of the 5-day volume-weighted price skewness and the ratio of current turnover to its 20-day median, identifies short-term price peaks or troughs driven by retail-induced liquidity shocks that are likely to mean-revert.\n                Concise Observation: The parent strategy focuses on smooth institutional trends, but market data shows that extreme volume spikes often accompany price 'blow-offs' where price linearity breaks down and volatility expands rapidly before a reversal.\n                Concise Justification: High turnover spikes combined with skewed price action represent 'panic' or 'FOMO' buying/selling; according to the theory of limits to arbitrage, these liquidity-driven price deviations are unsustainable and provide excess returns upon correction.\n                Concise Knowledge: If a stock exhibits high volume-weighted skewness alongside a significant spike in relative turnover, it indicates one-sided trade exhaustion; when such liquidity demand peaks, prices tend to reverse as market makers provide liquidity at a premium.\n                concise Specification: The factor uses a 5-day window for volume-weighted skewness to capture recent imbalance and a 20-day median turnover as a baseline to identify abnormal liquidity events, targeting mean-reversion over a 1-5 day horizon.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T09:35:47.006991"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1544946790876025,
        "ICIR": 0.0389000770099648,
        "1day.excess_return_without_cost.std": 0.0051997397791481,
        "1day.excess_return_with_cost.annualized_return": 0.00013792845762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002007259592352,
        "1day.excess_return_without_cost.annualized_return": 0.0477727782979781,
        "1day.excess_return_with_cost.std": 0.0052007682169644,
        "Rank IC": 0.0240130310402388,
        "IC": 0.0060782290173483,
        "1day.excess_return_without_cost.max_drawdown": -0.1138566444260834,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.595539278741646,
        "1day.pa": 0.0,
        "l2.valid": 0.996172786093824,
        "Rank ICIR": 0.1501068871148751,
        "l2.train": 0.9940168138187764,
        "1day.excess_return_with_cost.information_ratio": 0.0017190871825722,
        "1day.excess_return_with_cost.mean": 5.795313345380462e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Exhaustion Reversal' hypothesis. The 'Liquidity_Exhaustion_Skew_Factor' achieved a higher IC (0.006078) compared to the SOTA (0.005798), indicating a stronger point-in-time correlation with future returns. However, the portfolio-based metrics (Information Ratio and Annualized Return) underperformed the SOTA, and the Max Drawdown significantly worsened (-0.1138 vs -0.0725). This suggests that while the signal captures some predictive power, it introduces significant volatility or is concentrated in periods/stocks that are difficult to capture in a stable portfolio.",
        "hypothesis_evaluation": "The hypothesis that liquidity shocks driven by volume-weighted skewness lead to reversals is partially supported by the improved IC. However, the current implementation of 'Liquidity_Exhaustion_Skew_Factor' (using return^3 * volume) might be too noisy. The 'Turnover_Spike_Reversal_Factor' and 'Relative_Liquidity_Shock_Index' provide simpler alternatives, but the lack of improvement in annualized return suggests the interaction between skewness and abnormal turnover needs a more robust mathematical formulation to filter out noise.",
        "decision": false,
        "reason": "The previous factors used raw volume or simple medians, which do not account for the varying volatility of different instruments. By using a Z-score for turnover and normalizing the price signal by volatility (Sharpe-like ratio over 5 days), we can better identify 'exhaustion' points that are statistically significant relative to the stock's own history, rather than just cross-sectional extremes. This should improve the Information Ratio and reduce Drawdown by avoiding high-volatility traps."
      }
    },
    "a37e54740f503aac": {
      "factor_id": "a37e54740f503aac",
      "factor_name": "Turnover_Spike_Reversal_Factor",
      "factor_expression": "SIGN(TS_MEAN($return, 5)) * ($volume / (TS_MEDIAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(SIGN(TS_MEAN(TS_PCTCHANGE($close, 1), 5)) * ($volume / (TS_MEDIAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Turnover_Spike_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets mean-reversion by identifying stocks where current volume significantly deviates from its 20-day median, scaled by the direction of recent price volatility. It assumes that extreme turnover relative to the median indicates exhaustion of the current trend.",
      "factor_formulation": "TSR = \\text{SIGN}(\\text{TS\\_MEAN}(\\text{return}, 5)) \\times \\frac{\\text{volume}}{\\text{TS\\_MEDIAN}(\\text{volume}, 20) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6becae249925",
        "parent_trajectory_ids": [
          "ebb95d0d34c5"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Exhaustion Reversal' factor, calculated as the product of the 5-day volume-weighted price skewness and the ratio of current turnover to its 20-day median, identifies short-term price peaks or troughs driven by retail-induced liquidity shocks that are likely to mean-revert.\n                Concise Observation: The parent strategy focuses on smooth institutional trends, but market data shows that extreme volume spikes often accompany price 'blow-offs' where price linearity breaks down and volatility expands rapidly before a reversal.\n                Concise Justification: High turnover spikes combined with skewed price action represent 'panic' or 'FOMO' buying/selling; according to the theory of limits to arbitrage, these liquidity-driven price deviations are unsustainable and provide excess returns upon correction.\n                Concise Knowledge: If a stock exhibits high volume-weighted skewness alongside a significant spike in relative turnover, it indicates one-sided trade exhaustion; when such liquidity demand peaks, prices tend to reverse as market makers provide liquidity at a premium.\n                concise Specification: The factor uses a 5-day window for volume-weighted skewness to capture recent imbalance and a 20-day median turnover as a baseline to identify abnormal liquidity events, targeting mean-reversion over a 1-5 day horizon.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T09:35:47.006991"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1544946790876025,
        "ICIR": 0.0389000770099648,
        "1day.excess_return_without_cost.std": 0.0051997397791481,
        "1day.excess_return_with_cost.annualized_return": 0.00013792845762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002007259592352,
        "1day.excess_return_without_cost.annualized_return": 0.0477727782979781,
        "1day.excess_return_with_cost.std": 0.0052007682169644,
        "Rank IC": 0.0240130310402388,
        "IC": 0.0060782290173483,
        "1day.excess_return_without_cost.max_drawdown": -0.1138566444260834,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.595539278741646,
        "1day.pa": 0.0,
        "l2.valid": 0.996172786093824,
        "Rank ICIR": 0.1501068871148751,
        "l2.train": 0.9940168138187764,
        "1day.excess_return_with_cost.information_ratio": 0.0017190871825722,
        "1day.excess_return_with_cost.mean": 5.795313345380462e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Exhaustion Reversal' hypothesis. The 'Liquidity_Exhaustion_Skew_Factor' achieved a higher IC (0.006078) compared to the SOTA (0.005798), indicating a stronger point-in-time correlation with future returns. However, the portfolio-based metrics (Information Ratio and Annualized Return) underperformed the SOTA, and the Max Drawdown significantly worsened (-0.1138 vs -0.0725). This suggests that while the signal captures some predictive power, it introduces significant volatility or is concentrated in periods/stocks that are difficult to capture in a stable portfolio.",
        "hypothesis_evaluation": "The hypothesis that liquidity shocks driven by volume-weighted skewness lead to reversals is partially supported by the improved IC. However, the current implementation of 'Liquidity_Exhaustion_Skew_Factor' (using return^3 * volume) might be too noisy. The 'Turnover_Spike_Reversal_Factor' and 'Relative_Liquidity_Shock_Index' provide simpler alternatives, but the lack of improvement in annualized return suggests the interaction between skewness and abnormal turnover needs a more robust mathematical formulation to filter out noise.",
        "decision": false,
        "reason": "The previous factors used raw volume or simple medians, which do not account for the varying volatility of different instruments. By using a Z-score for turnover and normalizing the price signal by volatility (Sharpe-like ratio over 5 days), we can better identify 'exhaustion' points that are statistically significant relative to the stock's own history, rather than just cross-sectional extremes. This should improve the Information Ratio and reduce Drawdown by avoiding high-volatility traps."
      }
    },
    "1e0e100fb608c931": {
      "factor_id": "1e0e100fb608c931",
      "factor_name": "Relative_Liquidity_Shock_Index",
      "factor_expression": "RANK(SKEW($return)) * RANK($volume / (TS_MEDIAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($volume / TS_MEDIAN($volume, 20)) * RANK(SKEW(TS_PCTCHANGE($close, 1)))\" # Your output factor expression will be filled in here\n    name = \"Relative_Liquidity_Shock_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the liquidity exhaustion hypothesis that uses the ratio of current volume to historical median volume, interacted with the cross-sectional rank of price skewness to find outliers in liquidity demand.",
      "factor_formulation": "RLSI = \\text{RANK}(\\text{SKEW}(\\text{return})) \\times \\text{RANK}\\left(\\frac{\\text{volume}}{\\text{TS\\_MEDIAN}(\\text{volume}, 20) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6becae249925",
        "parent_trajectory_ids": [
          "ebb95d0d34c5"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity Exhaustion Reversal' factor, calculated as the product of the 5-day volume-weighted price skewness and the ratio of current turnover to its 20-day median, identifies short-term price peaks or troughs driven by retail-induced liquidity shocks that are likely to mean-revert.\n                Concise Observation: The parent strategy focuses on smooth institutional trends, but market data shows that extreme volume spikes often accompany price 'blow-offs' where price linearity breaks down and volatility expands rapidly before a reversal.\n                Concise Justification: High turnover spikes combined with skewed price action represent 'panic' or 'FOMO' buying/selling; according to the theory of limits to arbitrage, these liquidity-driven price deviations are unsustainable and provide excess returns upon correction.\n                Concise Knowledge: If a stock exhibits high volume-weighted skewness alongside a significant spike in relative turnover, it indicates one-sided trade exhaustion; when such liquidity demand peaks, prices tend to reverse as market makers provide liquidity at a premium.\n                concise Specification: The factor uses a 5-day window for volume-weighted skewness to capture recent imbalance and a 20-day median turnover as a baseline to identify abnormal liquidity events, targeting mean-reversion over a 1-5 day horizon.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T09:35:47.006991"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1544946790876025,
        "ICIR": 0.0389000770099648,
        "1day.excess_return_without_cost.std": 0.0051997397791481,
        "1day.excess_return_with_cost.annualized_return": 0.00013792845762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002007259592352,
        "1day.excess_return_without_cost.annualized_return": 0.0477727782979781,
        "1day.excess_return_with_cost.std": 0.0052007682169644,
        "Rank IC": 0.0240130310402388,
        "IC": 0.0060782290173483,
        "1day.excess_return_without_cost.max_drawdown": -0.1138566444260834,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.595539278741646,
        "1day.pa": 0.0,
        "l2.valid": 0.996172786093824,
        "Rank ICIR": 0.1501068871148751,
        "l2.train": 0.9940168138187764,
        "1day.excess_return_with_cost.information_ratio": 0.0017190871825722,
        "1day.excess_return_with_cost.mean": 5.795313345380462e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity Exhaustion Reversal' hypothesis. The 'Liquidity_Exhaustion_Skew_Factor' achieved a higher IC (0.006078) compared to the SOTA (0.005798), indicating a stronger point-in-time correlation with future returns. However, the portfolio-based metrics (Information Ratio and Annualized Return) underperformed the SOTA, and the Max Drawdown significantly worsened (-0.1138 vs -0.0725). This suggests that while the signal captures some predictive power, it introduces significant volatility or is concentrated in periods/stocks that are difficult to capture in a stable portfolio.",
        "hypothesis_evaluation": "The hypothesis that liquidity shocks driven by volume-weighted skewness lead to reversals is partially supported by the improved IC. However, the current implementation of 'Liquidity_Exhaustion_Skew_Factor' (using return^3 * volume) might be too noisy. The 'Turnover_Spike_Reversal_Factor' and 'Relative_Liquidity_Shock_Index' provide simpler alternatives, but the lack of improvement in annualized return suggests the interaction between skewness and abnormal turnover needs a more robust mathematical formulation to filter out noise.",
        "decision": false,
        "reason": "The previous factors used raw volume or simple medians, which do not account for the varying volatility of different instruments. By using a Z-score for turnover and normalizing the price signal by volatility (Sharpe-like ratio over 5 days), we can better identify 'exhaustion' points that are statistically significant relative to the stock's own history, rather than just cross-sectional extremes. This should improve the Information Ratio and reduce Drawdown by avoiding high-volatility traps."
      }
    },
    "d0a7d95b2a05c02f": {
      "factor_id": "d0a7d95b2a05c02f",
      "factor_name": "ILE_Liquidity_Exhaustion_20D",
      "factor_expression": "TS_ZSCORE(($high - $low) / $close, 20) * TS_MEAN(ABS($close / TS_MEAN($close, 20) - 1), 5) / (TS_STD($volume / TS_MEAN($volume, 20) - 1, 20) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 20) * TS_MEAN(ABS($close / TS_MEAN($close, 20) - 1), 5) / (TS_STD($volume / TS_MEAN($volume, 20) - 1, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ILE_Liquidity_Exhaustion_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'Intraday Liquidity Exhaustion' by combining the Z-score of the intraday price range with the deviation from the 20-day mean, normalized by volume volatility. High values suggest price overextension driven by noise rather than institutional conviction, signaling potential mean-reversion.",
      "factor_formulation": "ILE = \\text{TS_ZSCORE}(\\frac{high - low}{close}, 20) \\times \\frac{\\text{TS_MEAN}(\\text{ABS}(\\frac{close - \\text{TS_MEAN}(close, 20)}{\\text{TS_MEAN}(close, 20)}), 5)}{\\text{TS_STD}(\\frac{volume - \\text{TS_MEAN}(volume, 20)}{\\text{TS_MEAN}(volume, 20)}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccaea98db513",
        "parent_trajectory_ids": [
          "d7fcd1bf6e67"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' (ILE) factor predicts mean-reversion by identifying assets where price dispersion (High-Low range) significantly exceeds its 20-day average while volume-weighted price efficiency (VWAP-to-Close proximity) collapses, signaling noise-driven price extension.\n                Concise Observation: The parent strategy focuses on institutional 'entry' through gaps and floors, but fails to capture alpha from price overextensions where high volatility occurs on fragmented, non-institutional volume.\n                Concise Justification: Institutional conviction typically narrows the gap between VWAP and Close; a wide intraday range coupled with a large deviation from the 20-day mean price suggests an unsustainable liquidity shock rather than a fundamental trend shift.\n                Concise Knowledge: If intraday price range expands without a proportional increase in volume-weighted price stability, the movement is likely driven by liquidity vacuums; when noise-trader activity dominates, prices tend to mean-revert to their 20-day moving average.\n                concise Specification: The factor is defined as the product of the 20-day Z-score of the (High-Low)/Close ratio and the 5-day average of the absolute percentage difference between the Close and the 20-day Moving Average, normalized by volume volatility.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T09:39:14.602306"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1199255189300831,
        "ICIR": 0.0688690523525118,
        "1day.excess_return_without_cost.std": 0.0043374703473274,
        "1day.excess_return_with_cost.annualized_return": 0.0280418779763214,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003165802795771,
        "1day.excess_return_without_cost.annualized_return": 0.0753461065393688,
        "1day.excess_return_with_cost.std": 0.0043376160749288,
        "Rank IC": 0.0285430951709135,
        "IC": 0.0095150406915281,
        "1day.excess_return_without_cost.max_drawdown": -0.104283226245933,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.125993330284545,
        "1day.pa": 0.0,
        "l2.valid": 0.9963627958065904,
        "Rank ICIR": 0.2130055796981595,
        "l2.train": 0.992977300521778,
        "1day.excess_return_with_cost.information_ratio": 0.4190516035918447,
        "1day.excess_return_with_cost.mean": 0.0001178230167072
      },
      "feedback": {
        "observations": "The current iteration focused on three variations of the 'Intraday Liquidity Exhaustion' hypothesis: a complex volatility-normalized version (ILE), a rank-based efficiency collapse version (ECR), and a Z-score noise dispersion version (NDD). The results show a significant improvement in Information Ratio (1.126 vs 0.973), Annualized Return (7.53% vs 5.20%), and IC (0.0095 vs 0.0058) compared to the SOTA. However, the Max Drawdown has worsened (-0.104 vs -0.073), suggesting that while the predictive power (IC) and risk-adjusted returns (IR) have increased, the strategy may be exposed to higher tail risks or regime sensitivity.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that identifying price dispersion relative to historical norms (High-Low range) combined with price stretching (distance from mean) can predict mean-reversion. The 'Noise_Driven_Dispersion_Z' and 'ILE_Liquidity_Exhaustion_20D' implementations demonstrate that normalizing intraday range by volume or volume-volatility effectively isolates 'exhaustion' points. The increase in IC suggests the core logic of capturing noise-driven overextension is valid.",
        "decision": true,
        "reason": "The current ILE factor (SL > 300 potentially in formulation logic) is becoming complex. By using 'Relative Volume' as a denominator for the price range, we create a 'Price-Volume Efficiency' metric. If a large price range occurs on low relative volume, it is more likely to be noise-driven. Additionally, adding a 'Range Position' component (where the close sits relative to the high-low) helps distinguish between a strong trend close and a 'pin bar' reversal, which should improve the Max Drawdown by filtering out strong momentum days."
      }
    },
    "587097b4cb566b0a": {
      "factor_id": "587097b4cb566b0a",
      "factor_name": "Efficiency_Collapse_Reversion_15D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($high - $low, 15) + 1e-8)) * RANK(ABS($close / TS_MEAN($close, 15) - 1))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($high - $low, 15) + 1e-8)) * RANK(ABS($close / TS_MEAN($close, 15) - 1))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Collapse_Reversion_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified measure of liquidity-driven overextension. It captures the ratio of the intraday range to the historical average range, weighted by the distance from the long-term mean, specifically targeting periods where price dispersion is high relative to volume stability.",
      "factor_formulation": "ECR = \\text{RANK}(\\frac{high - low}{\\text{TS_MEAN}(high - low, 15)}) \\times \\text{RANK}(\\text{ABS}(\\frac{close}{\\text{TS_MEAN}(close, 15)} - 1))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccaea98db513",
        "parent_trajectory_ids": [
          "d7fcd1bf6e67"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' (ILE) factor predicts mean-reversion by identifying assets where price dispersion (High-Low range) significantly exceeds its 20-day average while volume-weighted price efficiency (VWAP-to-Close proximity) collapses, signaling noise-driven price extension.\n                Concise Observation: The parent strategy focuses on institutional 'entry' through gaps and floors, but fails to capture alpha from price overextensions where high volatility occurs on fragmented, non-institutional volume.\n                Concise Justification: Institutional conviction typically narrows the gap between VWAP and Close; a wide intraday range coupled with a large deviation from the 20-day mean price suggests an unsustainable liquidity shock rather than a fundamental trend shift.\n                Concise Knowledge: If intraday price range expands without a proportional increase in volume-weighted price stability, the movement is likely driven by liquidity vacuums; when noise-trader activity dominates, prices tend to mean-revert to their 20-day moving average.\n                concise Specification: The factor is defined as the product of the 20-day Z-score of the (High-Low)/Close ratio and the 5-day average of the absolute percentage difference between the Close and the 20-day Moving Average, normalized by volume volatility.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T09:39:14.602306"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1199255189300831,
        "ICIR": 0.0688690523525118,
        "1day.excess_return_without_cost.std": 0.0043374703473274,
        "1day.excess_return_with_cost.annualized_return": 0.0280418779763214,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003165802795771,
        "1day.excess_return_without_cost.annualized_return": 0.0753461065393688,
        "1day.excess_return_with_cost.std": 0.0043376160749288,
        "Rank IC": 0.0285430951709135,
        "IC": 0.0095150406915281,
        "1day.excess_return_without_cost.max_drawdown": -0.104283226245933,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.125993330284545,
        "1day.pa": 0.0,
        "l2.valid": 0.9963627958065904,
        "Rank ICIR": 0.2130055796981595,
        "l2.train": 0.992977300521778,
        "1day.excess_return_with_cost.information_ratio": 0.4190516035918447,
        "1day.excess_return_with_cost.mean": 0.0001178230167072
      },
      "feedback": {
        "observations": "The current iteration focused on three variations of the 'Intraday Liquidity Exhaustion' hypothesis: a complex volatility-normalized version (ILE), a rank-based efficiency collapse version (ECR), and a Z-score noise dispersion version (NDD). The results show a significant improvement in Information Ratio (1.126 vs 0.973), Annualized Return (7.53% vs 5.20%), and IC (0.0095 vs 0.0058) compared to the SOTA. However, the Max Drawdown has worsened (-0.104 vs -0.073), suggesting that while the predictive power (IC) and risk-adjusted returns (IR) have increased, the strategy may be exposed to higher tail risks or regime sensitivity.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that identifying price dispersion relative to historical norms (High-Low range) combined with price stretching (distance from mean) can predict mean-reversion. The 'Noise_Driven_Dispersion_Z' and 'ILE_Liquidity_Exhaustion_20D' implementations demonstrate that normalizing intraday range by volume or volume-volatility effectively isolates 'exhaustion' points. The increase in IC suggests the core logic of capturing noise-driven overextension is valid.",
        "decision": true,
        "reason": "The current ILE factor (SL > 300 potentially in formulation logic) is becoming complex. By using 'Relative Volume' as a denominator for the price range, we create a 'Price-Volume Efficiency' metric. If a large price range occurs on low relative volume, it is more likely to be noise-driven. Additionally, adding a 'Range Position' component (where the close sits relative to the high-low) helps distinguish between a strong trend close and a 'pin bar' reversal, which should improve the Max Drawdown by filtering out strong momentum days."
      }
    },
    "70182b5b650b1bab": {
      "factor_id": "70182b5b650b1bab",
      "factor_name": "Noise_Driven_Dispersion_Z",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) + TS_ZSCORE(ABS($close - TS_MEAN($close, 20)), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20) + TS_ZSCORE(ABS($close - TS_MEAN($close, 20)), 20)\" # Your output factor expression will be filled in here\n    name = \"Noise_Driven_Dispersion_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets noise-driven price extensions by identifying days where the intraday range (normalized by volume) deviates significantly from its 20-day norm, while the price is stretched away from its 20-day moving average.",
      "factor_formulation": "NDD = \\text{TS_ZSCORE}(\\frac{high - low}{volume + 1}, 20) + \\text{TS_ZSCORE}(ABS(close - \\text{TS_MEAN}(close, 20)), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "ccaea98db513",
        "parent_trajectory_ids": [
          "d7fcd1bf6e67"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion' (ILE) factor predicts mean-reversion by identifying assets where price dispersion (High-Low range) significantly exceeds its 20-day average while volume-weighted price efficiency (VWAP-to-Close proximity) collapses, signaling noise-driven price extension.\n                Concise Observation: The parent strategy focuses on institutional 'entry' through gaps and floors, but fails to capture alpha from price overextensions where high volatility occurs on fragmented, non-institutional volume.\n                Concise Justification: Institutional conviction typically narrows the gap between VWAP and Close; a wide intraday range coupled with a large deviation from the 20-day mean price suggests an unsustainable liquidity shock rather than a fundamental trend shift.\n                Concise Knowledge: If intraday price range expands without a proportional increase in volume-weighted price stability, the movement is likely driven by liquidity vacuums; when noise-trader activity dominates, prices tend to mean-revert to their 20-day moving average.\n                concise Specification: The factor is defined as the product of the 20-day Z-score of the (High-Low)/Close ratio and the 5-day average of the absolute percentage difference between the Close and the 20-day Moving Average, normalized by volume volatility.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T09:39:14.602306"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1199255189300831,
        "ICIR": 0.0688690523525118,
        "1day.excess_return_without_cost.std": 0.0043374703473274,
        "1day.excess_return_with_cost.annualized_return": 0.0280418779763214,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003165802795771,
        "1day.excess_return_without_cost.annualized_return": 0.0753461065393688,
        "1day.excess_return_with_cost.std": 0.0043376160749288,
        "Rank IC": 0.0285430951709135,
        "IC": 0.0095150406915281,
        "1day.excess_return_without_cost.max_drawdown": -0.104283226245933,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.125993330284545,
        "1day.pa": 0.0,
        "l2.valid": 0.9963627958065904,
        "Rank ICIR": 0.2130055796981595,
        "l2.train": 0.992977300521778,
        "1day.excess_return_with_cost.information_ratio": 0.4190516035918447,
        "1day.excess_return_with_cost.mean": 0.0001178230167072
      },
      "feedback": {
        "observations": "The current iteration focused on three variations of the 'Intraday Liquidity Exhaustion' hypothesis: a complex volatility-normalized version (ILE), a rank-based efficiency collapse version (ECR), and a Z-score noise dispersion version (NDD). The results show a significant improvement in Information Ratio (1.126 vs 0.973), Annualized Return (7.53% vs 5.20%), and IC (0.0095 vs 0.0058) compared to the SOTA. However, the Max Drawdown has worsened (-0.104 vs -0.073), suggesting that while the predictive power (IC) and risk-adjusted returns (IR) have increased, the strategy may be exposed to higher tail risks or regime sensitivity.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that identifying price dispersion relative to historical norms (High-Low range) combined with price stretching (distance from mean) can predict mean-reversion. The 'Noise_Driven_Dispersion_Z' and 'ILE_Liquidity_Exhaustion_20D' implementations demonstrate that normalizing intraday range by volume or volume-volatility effectively isolates 'exhaustion' points. The increase in IC suggests the core logic of capturing noise-driven overextension is valid.",
        "decision": true,
        "reason": "The current ILE factor (SL > 300 potentially in formulation logic) is becoming complex. By using 'Relative Volume' as a denominator for the price range, we create a 'Price-Volume Efficiency' metric. If a large price range occurs on low relative volume, it is more likely to be noise-driven. Additionally, adding a 'Range Position' component (where the close sits relative to the high-low) helps distinguish between a strong trend close and a 'pin bar' reversal, which should improve the Max Drawdown by filtering out strong momentum days."
      }
    },
    "93bace840fae541d": {
      "factor_id": "93bace840fae541d",
      "factor_name": "IOFP_Closing_Strength_Ratio",
      "factor_expression": "RANK(($close - $low) / ($high - $low + 1e-8)) * RANK($volume / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $low) / ($high - $low + 1e-8)) * RANK($volume / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IOFP_Closing_Strength_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures 'Intraday Order-Flow Persistence' by measuring the closing strength (position of close relative to daily range) scaled by the inverse of the relative range-to-volume ratio. High values indicate institutional accumulation where the price closes near the high despite high relative liquidity (volume), suggesting stealth buying.",
      "factor_formulation": "\\text{RANK}\\left( \\frac{\\text{close} - \\text{low}}{\\text{high} - \\text{low} + 1e-8} \\right) * \\text{RANK}\\left( \\frac{\\text{volume}}{\\text{high} - \\text{low} + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "24861539467d",
        "parent_trajectory_ids": [
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Order-Flow Persistence' (IOFP) factor predicts that positive price momentum in the final 60 minutes of trading, when scaled by the ratio of high-to-low price range relative to daily volume, identifies informed institutional accumulation that leads to next-day positive returns.\n                Concise Observation: The parent LSSR strategy focused on mean-reversion from overnight sentiment gaps and volume residuals, but it ignored the predictive power of the 'Power Hour' where institutional flow typically concentrates to minimize market impact.\n                Concise Justification: Institutional investors often use VWAP or TWAP algorithms that intensify towards the market close to meet benchmark targets; this 'informed' flow creates a persistent trend that is more fundamentally driven than the retail-heavy overnight gaps.\n                Concise Knowledge: If price trends in the final trading hour are accompanied by tight intraday ranges relative to volume, it indicates institutional 'stealth' accumulation; when this persistence occurs, the price is likely to continue its trend into the next session due to incomplete order execution.\n                concise Specification: The factor is defined as the product of the last hour's price change and the ratio of the daily (High - Low) to the daily Volume, specifically focusing on the persistence of the $close relative to the $low within a 1-day window to capture 'closing strength'.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T09:42:17.556324"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2184947737520144,
        "ICIR": 0.0115352070740947,
        "1day.excess_return_without_cost.std": 0.0046154245072503,
        "1day.excess_return_with_cost.annualized_return": -0.0269746558419943,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 8.735478362408833e-05,
        "1day.excess_return_without_cost.annualized_return": 0.020790438502533,
        "1day.excess_return_with_cost.std": 0.004616555058066,
        "Rank IC": 0.0171027304319254,
        "IC": 0.0017607329973587,
        "1day.excess_return_without_cost.max_drawdown": -0.1539372156267526,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.291987002072161,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211028948656,
        "Rank ICIR": 0.1148431586121024,
        "l2.train": 0.993719159930906,
        "1day.excess_return_with_cost.information_ratio": -0.3787471856913946,
        "1day.excess_return_with_cost.mean": -0.0001133388900924
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Intraday Order-Flow Persistence' (IOFP) framework: IOFP_Closing_Strength_Ratio, IOFP_Institutional_Persistence_5D, and IOFP_Stealth_Accumulation_ZScore. While these factors were successfully implemented, the collective performance (Annualized Return: 0.0208, IC: 0.00176, IR: 0.292) significantly underperforms the SOTA results (Annualized Return: 0.0520, IC: 0.0058, IR: 0.973). The Max Drawdown is also notably deeper (-0.154 vs -0.073). The current implementation captures some signal, but it is weak and lacks the robustness of the previous SOTA.",
        "hypothesis_evaluation": "The results provide weak support for the IOFP hypothesis. While the logic of combining closing strength with volume efficiency is theoretically sound, the current mathematical formulations (especially the 5-day persistence and Z-score variants) might be introducing too much noise or failing to isolate 'informed' flow from general volatility. The low IC suggests that the linear relationship between these specific 'Power Hour' proxies and next-day returns is not sufficiently captured by the current ranking and scaling methods.",
        "decision": false,
        "reason": "The current factors used raw volume or 20-day volume averages which can be noisy. By shifting focus to the 'consistency' of where a stock closes within its daily range (e.g., using a standard deviation of the (Close-Low)/(High-Low) ratio), we can better identify deliberate accumulation versus random late-day volatility. Reducing the look-back from 5 days to 3 days for persistence may also capture the shorter-term nature of institutional execution blocks more effectively, reducing signal decay."
      }
    },
    "a51253bbfec8a6e4": {
      "factor_id": "a51253bbfec8a6e4",
      "factor_name": "IOFP_Institutional_Persistence_5D",
      "factor_expression": "TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / (TS_MEAN($volume, 20) + 1e-8)), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close - $open) / ($high - $low + 1e-8) * ($volume / (TS_MEAN($volume, 20) + 1e-8)), 5)\" # Your output factor expression will be filled in here\n    name = \"IOFP_Institutional_Persistence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the persistence of institutional flow by calculating the 5-day average of the interaction between price trend (close vs open) and the efficiency of volume in moving the price within its range. It identifies stocks where the 'Power Hour' likely results in a strong close relative to the daily volatility.",
      "factor_formulation": "\\text{TS_MEAN}\\left( \\frac{\\text{close} - \\text{open}}{\\text{high} - \\text{low} + 1e-8} * \\frac{\\text{volume}}{\\text{TS_MEAN}(\\text{volume}, 20)}, 5 \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "24861539467d",
        "parent_trajectory_ids": [
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Order-Flow Persistence' (IOFP) factor predicts that positive price momentum in the final 60 minutes of trading, when scaled by the ratio of high-to-low price range relative to daily volume, identifies informed institutional accumulation that leads to next-day positive returns.\n                Concise Observation: The parent LSSR strategy focused on mean-reversion from overnight sentiment gaps and volume residuals, but it ignored the predictive power of the 'Power Hour' where institutional flow typically concentrates to minimize market impact.\n                Concise Justification: Institutional investors often use VWAP or TWAP algorithms that intensify towards the market close to meet benchmark targets; this 'informed' flow creates a persistent trend that is more fundamentally driven than the retail-heavy overnight gaps.\n                Concise Knowledge: If price trends in the final trading hour are accompanied by tight intraday ranges relative to volume, it indicates institutional 'stealth' accumulation; when this persistence occurs, the price is likely to continue its trend into the next session due to incomplete order execution.\n                concise Specification: The factor is defined as the product of the last hour's price change and the ratio of the daily (High - Low) to the daily Volume, specifically focusing on the persistence of the $close relative to the $low within a 1-day window to capture 'closing strength'.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T09:42:17.556324"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2184947737520144,
        "ICIR": 0.0115352070740947,
        "1day.excess_return_without_cost.std": 0.0046154245072503,
        "1day.excess_return_with_cost.annualized_return": -0.0269746558419943,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 8.735478362408833e-05,
        "1day.excess_return_without_cost.annualized_return": 0.020790438502533,
        "1day.excess_return_with_cost.std": 0.004616555058066,
        "Rank IC": 0.0171027304319254,
        "IC": 0.0017607329973587,
        "1day.excess_return_without_cost.max_drawdown": -0.1539372156267526,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.291987002072161,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211028948656,
        "Rank ICIR": 0.1148431586121024,
        "l2.train": 0.993719159930906,
        "1day.excess_return_with_cost.information_ratio": -0.3787471856913946,
        "1day.excess_return_with_cost.mean": -0.0001133388900924
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Intraday Order-Flow Persistence' (IOFP) framework: IOFP_Closing_Strength_Ratio, IOFP_Institutional_Persistence_5D, and IOFP_Stealth_Accumulation_ZScore. While these factors were successfully implemented, the collective performance (Annualized Return: 0.0208, IC: 0.00176, IR: 0.292) significantly underperforms the SOTA results (Annualized Return: 0.0520, IC: 0.0058, IR: 0.973). The Max Drawdown is also notably deeper (-0.154 vs -0.073). The current implementation captures some signal, but it is weak and lacks the robustness of the previous SOTA.",
        "hypothesis_evaluation": "The results provide weak support for the IOFP hypothesis. While the logic of combining closing strength with volume efficiency is theoretically sound, the current mathematical formulations (especially the 5-day persistence and Z-score variants) might be introducing too much noise or failing to isolate 'informed' flow from general volatility. The low IC suggests that the linear relationship between these specific 'Power Hour' proxies and next-day returns is not sufficiently captured by the current ranking and scaling methods.",
        "decision": false,
        "reason": "The current factors used raw volume or 20-day volume averages which can be noisy. By shifting focus to the 'consistency' of where a stock closes within its daily range (e.g., using a standard deviation of the (Close-Low)/(High-Low) ratio), we can better identify deliberate accumulation versus random late-day volatility. Reducing the look-back from 5 days to 3 days for persistence may also capture the shorter-term nature of institutional execution blocks more effectively, reducing signal decay."
      }
    },
    "97d32e40be712ca9": {
      "factor_id": "97d32e40be712ca9",
      "factor_name": "IOFP_Stealth_Accumulation_ZScore",
      "factor_expression": "ZSCORE(($close - ($high + $low) / 2) / ($high - $low + 1e-8) * LOG($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - ($high + $low) / 2) / ($high - $low + 1e-8) * LOG($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IOFP_Stealth_Accumulation_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'stealth' accumulation by looking for days where the closing price is significantly higher than the day's median price, normalized by the range-to-volume efficiency. It uses Z-score to find cross-sectional outliers in institutional buying pressure.",
      "factor_formulation": "\\text{ZSCORE}\\left( \\frac{\\text{close} - (\\text{high} + \\text{low})/2}{\\text{high} - \\text{low} + 1e-8} * \\text{LOG}(\\text{volume}) \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "24861539467d",
        "parent_trajectory_ids": [
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Order-Flow Persistence' (IOFP) factor predicts that positive price momentum in the final 60 minutes of trading, when scaled by the ratio of high-to-low price range relative to daily volume, identifies informed institutional accumulation that leads to next-day positive returns.\n                Concise Observation: The parent LSSR strategy focused on mean-reversion from overnight sentiment gaps and volume residuals, but it ignored the predictive power of the 'Power Hour' where institutional flow typically concentrates to minimize market impact.\n                Concise Justification: Institutional investors often use VWAP or TWAP algorithms that intensify towards the market close to meet benchmark targets; this 'informed' flow creates a persistent trend that is more fundamentally driven than the retail-heavy overnight gaps.\n                Concise Knowledge: If price trends in the final trading hour are accompanied by tight intraday ranges relative to volume, it indicates institutional 'stealth' accumulation; when this persistence occurs, the price is likely to continue its trend into the next session due to incomplete order execution.\n                concise Specification: The factor is defined as the product of the last hour's price change and the ratio of the daily (High - Low) to the daily Volume, specifically focusing on the persistence of the $close relative to the $low within a 1-day window to capture 'closing strength'.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T09:42:17.556324"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2184947737520144,
        "ICIR": 0.0115352070740947,
        "1day.excess_return_without_cost.std": 0.0046154245072503,
        "1day.excess_return_with_cost.annualized_return": -0.0269746558419943,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 8.735478362408833e-05,
        "1day.excess_return_without_cost.annualized_return": 0.020790438502533,
        "1day.excess_return_with_cost.std": 0.004616555058066,
        "Rank IC": 0.0171027304319254,
        "IC": 0.0017607329973587,
        "1day.excess_return_without_cost.max_drawdown": -0.1539372156267526,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.291987002072161,
        "1day.pa": 0.0,
        "l2.valid": 0.9965211028948656,
        "Rank ICIR": 0.1148431586121024,
        "l2.train": 0.993719159930906,
        "1day.excess_return_with_cost.information_ratio": -0.3787471856913946,
        "1day.excess_return_with_cost.mean": -0.0001133388900924
      },
      "feedback": {
        "observations": "The current experiment tested three factors under the 'Intraday Order-Flow Persistence' (IOFP) framework: IOFP_Closing_Strength_Ratio, IOFP_Institutional_Persistence_5D, and IOFP_Stealth_Accumulation_ZScore. While these factors were successfully implemented, the collective performance (Annualized Return: 0.0208, IC: 0.00176, IR: 0.292) significantly underperforms the SOTA results (Annualized Return: 0.0520, IC: 0.0058, IR: 0.973). The Max Drawdown is also notably deeper (-0.154 vs -0.073). The current implementation captures some signal, but it is weak and lacks the robustness of the previous SOTA.",
        "hypothesis_evaluation": "The results provide weak support for the IOFP hypothesis. While the logic of combining closing strength with volume efficiency is theoretically sound, the current mathematical formulations (especially the 5-day persistence and Z-score variants) might be introducing too much noise or failing to isolate 'informed' flow from general volatility. The low IC suggests that the linear relationship between these specific 'Power Hour' proxies and next-day returns is not sufficiently captured by the current ranking and scaling methods.",
        "decision": false,
        "reason": "The current factors used raw volume or 20-day volume averages which can be noisy. By shifting focus to the 'consistency' of where a stock closes within its daily range (e.g., using a standard deviation of the (Close-Low)/(High-Low) ratio), we can better identify deliberate accumulation versus random late-day volatility. Reducing the look-back from 5 days to 3 days for persistence may also capture the shorter-term nature of institutional execution blocks more effectively, reducing signal decay."
      }
    },
    "4d505c0c56459d17": {
      "factor_id": "4d505c0c56459d17",
      "factor_name": "Intraday_Exhaustion_Reversal_10D",
      "factor_expression": "TS_RANK(($high - $low) / $close, 10) * TS_MEAN(1 / (ABS($close - ($high + $low + $close) / 3) + 1e-8), 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / $close, 10) * TS_MEAN(1 / (ABS($close - ($high + $low + $close) / 3) + 1e-8), 5)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential trend reversals by interacting the 10-day time-series rank of the intraday range ratio with the inverse distance between the closing price and the daily average price (VWAP approximation). High values suggest high volatility without directional progress, signaling exhaustion.",
      "factor_formulation": "\\text{TS\\_RANK}(\\frac{high - low}{close}, 10) \\times \\text{TS\\_MEAN}(\\frac{1}{\\text{ABS}(close - \\frac{high+low+close}{3}) + 1e-8}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6a56d65b8b1a",
        "parent_trajectory_ids": [
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Exhaustion Reversal' factor, defined as the product of the 10-day rank of the High-Low range ratio and the inverse of the 5-day price-to-volume-weighted-average-price distance, identifies mean-reversion opportunities where high volatility without price displacement signals trend depletion.\n                Concise Observation: The parent strategy focused on inter-day gaps and low-volatility accumulation, whereas market data reveals that peaks in the High-Low range often coincide with a narrowing gap between the close and the volume-weighted average price, marking a shift from trend persistence to mean reversion.\n                Concise Justification: High intraday ranges indicate intense battle between buyers and sellers, but if the price closes near the VWAP, it suggests that neither side could sustain a breakout, leading to a 'volatility without progress' state that typically precedes a reversal.\n                Concise Knowledge: If intraday price dispersion reaches extreme levels while the closing price converges toward the daily average cost (VWAP), the prevailing trend is likely exhausted; when price volatility is high but net displacement is low, market participants are transitioning from directional aggression to passive liquidity provision.\n                concise Specification: The factor interacts the 10-day relative intraday range (High-Low / Close) with the 5-day proximity of the Close to the VWAP (approximated as (High+Low+Close)/3); high values indicate extreme range with tight VWAP convergence, signaling a high probability of a short-term trend reversal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T09:45:32.401384"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1112063441042629,
        "ICIR": 0.0403131468116047,
        "1day.excess_return_without_cost.std": 0.0039390795650048,
        "1day.excess_return_with_cost.annualized_return": -0.0054684005389127,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001761839813554,
        "1day.excess_return_without_cost.annualized_return": 0.0419317875625912,
        "1day.excess_return_with_cost.std": 0.0039388718397868,
        "Rank IC": 0.0238353203951861,
        "IC": 0.0052729275142378,
        "1day.excess_return_without_cost.max_drawdown": -0.1012113134845434,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900175633602922,
        "1day.pa": 0.0,
        "l2.valid": 0.9966187875448158,
        "Rank ICIR": 0.1814489347528798,
        "l2.train": 0.9932805025084444,
        "1day.excess_return_with_cost.information_ratio": -0.0899911887305707,
        "1day.excess_return_with_cost.mean": -2.297647285257453e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Intraday Exhaustion Reversal' hypothesis. The results indicate that while the core concept of using intraday range relative to price displacement has predictive power (positive IC and IR), the current implementations (Intraday_Exhaustion_Reversal_10D, Volatility_Convergence_Reversal_Factor, and Range_VWAP_Efficiency_Ratio) failed to outperform the existing SOTA. The SOTA remains superior across all key metrics, including IC (0.005798 vs 0.005273) and Information Ratio (0.972561 vs 0.690018). The 'Range_VWAP_Efficiency_Ratio' provided a simplified linear approach, but it appears that the interaction between raw volatility and price-to-VWAP distance requires a more robust normalization or a different look-back period to capture the 'exhaustion' signal effectively without being drowned out by absolute price levels.",
        "hypothesis_evaluation": "The hypothesis that high volatility without price displacement signals trend depletion is supported by the positive Information Ratio and IC, suggesting the signal is not noise. However, the current mathematical formulations are likely capturing too much 'level' information (e.g., high-low range in absolute terms) rather than 'relative' exhaustion. The 'Range_VWAP_Efficiency_Ratio' used raw price differences which might introduce scale bias. The use of TS_RANK in the first factor was a step in the right direction for normalization, but the 5-day window for the inverse distance might be too short, leading to high turnover and sensitivity to noise.",
        "decision": false,
        "reason": "Current factors either used raw values (Range_VWAP_Efficiency_Ratio) or mixed ranks with raw means. By using Z-scores for both the 'Volatility' component (High-Low) and the 'Displacement' component (Close-VWAP), we ensure both signals are on the same scale and represent 'abnormal' states. A high Z-score in range combined with a low or negative Z-score in displacement more accurately captures the 'churning' behavior indicative of exhaustion. Extending the displacement window to 10 days to match the range window will also provide a more stable baseline for comparison."
      }
    },
    "8ea5a5bb8514e525": {
      "factor_id": "8ea5a5bb8514e525",
      "factor_name": "Volatility_Convergence_Reversal_Factor",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / $close, 10)) * RANK(1 / (TS_MEAN(ABS($close - ($high + $low + $close) / 3), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / $close, 10)) * RANK(1 / (TS_MEAN(ABS($close - ($high + $low + $close) / 3), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Convergence_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures mean-reversion signals by measuring the cross-sectional rank of the 10-day average intraday range relative to the proximity of the price to its daily mean. It targets stocks where extreme intraday price dispersion is not resulting in net displacement from the daily average cost.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_MEAN}(\\frac{high - low}{close}, 10)) \\times \\text{RANK}(\\text{INV}(\\text{TS\\_MEAN}(\\text{ABS}(close - \\frac{high+low+close}{3}), 5) + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6a56d65b8b1a",
        "parent_trajectory_ids": [
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Exhaustion Reversal' factor, defined as the product of the 10-day rank of the High-Low range ratio and the inverse of the 5-day price-to-volume-weighted-average-price distance, identifies mean-reversion opportunities where high volatility without price displacement signals trend depletion.\n                Concise Observation: The parent strategy focused on inter-day gaps and low-volatility accumulation, whereas market data reveals that peaks in the High-Low range often coincide with a narrowing gap between the close and the volume-weighted average price, marking a shift from trend persistence to mean reversion.\n                Concise Justification: High intraday ranges indicate intense battle between buyers and sellers, but if the price closes near the VWAP, it suggests that neither side could sustain a breakout, leading to a 'volatility without progress' state that typically precedes a reversal.\n                Concise Knowledge: If intraday price dispersion reaches extreme levels while the closing price converges toward the daily average cost (VWAP), the prevailing trend is likely exhausted; when price volatility is high but net displacement is low, market participants are transitioning from directional aggression to passive liquidity provision.\n                concise Specification: The factor interacts the 10-day relative intraday range (High-Low / Close) with the 5-day proximity of the Close to the VWAP (approximated as (High+Low+Close)/3); high values indicate extreme range with tight VWAP convergence, signaling a high probability of a short-term trend reversal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T09:45:32.401384"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1112063441042629,
        "ICIR": 0.0403131468116047,
        "1day.excess_return_without_cost.std": 0.0039390795650048,
        "1day.excess_return_with_cost.annualized_return": -0.0054684005389127,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001761839813554,
        "1day.excess_return_without_cost.annualized_return": 0.0419317875625912,
        "1day.excess_return_with_cost.std": 0.0039388718397868,
        "Rank IC": 0.0238353203951861,
        "IC": 0.0052729275142378,
        "1day.excess_return_without_cost.max_drawdown": -0.1012113134845434,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900175633602922,
        "1day.pa": 0.0,
        "l2.valid": 0.9966187875448158,
        "Rank ICIR": 0.1814489347528798,
        "l2.train": 0.9932805025084444,
        "1day.excess_return_with_cost.information_ratio": -0.0899911887305707,
        "1day.excess_return_with_cost.mean": -2.297647285257453e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Intraday Exhaustion Reversal' hypothesis. The results indicate that while the core concept of using intraday range relative to price displacement has predictive power (positive IC and IR), the current implementations (Intraday_Exhaustion_Reversal_10D, Volatility_Convergence_Reversal_Factor, and Range_VWAP_Efficiency_Ratio) failed to outperform the existing SOTA. The SOTA remains superior across all key metrics, including IC (0.005798 vs 0.005273) and Information Ratio (0.972561 vs 0.690018). The 'Range_VWAP_Efficiency_Ratio' provided a simplified linear approach, but it appears that the interaction between raw volatility and price-to-VWAP distance requires a more robust normalization or a different look-back period to capture the 'exhaustion' signal effectively without being drowned out by absolute price levels.",
        "hypothesis_evaluation": "The hypothesis that high volatility without price displacement signals trend depletion is supported by the positive Information Ratio and IC, suggesting the signal is not noise. However, the current mathematical formulations are likely capturing too much 'level' information (e.g., high-low range in absolute terms) rather than 'relative' exhaustion. The 'Range_VWAP_Efficiency_Ratio' used raw price differences which might introduce scale bias. The use of TS_RANK in the first factor was a step in the right direction for normalization, but the 5-day window for the inverse distance might be too short, leading to high turnover and sensitivity to noise.",
        "decision": false,
        "reason": "Current factors either used raw values (Range_VWAP_Efficiency_Ratio) or mixed ranks with raw means. By using Z-scores for both the 'Volatility' component (High-Low) and the 'Displacement' component (Close-VWAP), we ensure both signals are on the same scale and represent 'abnormal' states. A high Z-score in range combined with a low or negative Z-score in displacement more accurately captures the 'churning' behavior indicative of exhaustion. Extending the displacement window to 10 days to match the range window will also provide a more stable baseline for comparison."
      }
    },
    "69942eab4c6c0627": {
      "factor_id": "69942eab4c6c0627",
      "factor_name": "Range_VWAP_Efficiency_Ratio",
      "factor_expression": "TS_MEAN($high - $low, 10) / (TS_MEAN(ABS($close - ($high + $low + $close) / 3), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($high - $low, 10) / (TS_MEAN(ABS($close - ($high + $low + $close) / 3), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Range_VWAP_Efficiency_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A refined exhaustion indicator that calculates the ratio of the 10-day average intraday range to the 5-day average deviation from the daily mean. A high ratio indicates that the stock is experiencing significant intraday volatility that is failing to pull the price away from its central daily value.",
      "factor_formulation": "\\frac{\\text{TS\\_MEAN}(high - low, 10)}{\\text{TS\\_MEAN}(\\text{ABS}(close - \\frac{high+low+close}{3}), 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 7,
        "evolution_phase": "mutation",
        "trajectory_id": "6a56d65b8b1a",
        "parent_trajectory_ids": [
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Exhaustion Reversal' factor, defined as the product of the 10-day rank of the High-Low range ratio and the inverse of the 5-day price-to-volume-weighted-average-price distance, identifies mean-reversion opportunities where high volatility without price displacement signals trend depletion.\n                Concise Observation: The parent strategy focused on inter-day gaps and low-volatility accumulation, whereas market data reveals that peaks in the High-Low range often coincide with a narrowing gap between the close and the volume-weighted average price, marking a shift from trend persistence to mean reversion.\n                Concise Justification: High intraday ranges indicate intense battle between buyers and sellers, but if the price closes near the VWAP, it suggests that neither side could sustain a breakout, leading to a 'volatility without progress' state that typically precedes a reversal.\n                Concise Knowledge: If intraday price dispersion reaches extreme levels while the closing price converges toward the daily average cost (VWAP), the prevailing trend is likely exhausted; when price volatility is high but net displacement is low, market participants are transitioning from directional aggression to passive liquidity provision.\n                concise Specification: The factor interacts the 10-day relative intraday range (High-Low / Close) with the 5-day proximity of the Close to the VWAP (approximated as (High+Low+Close)/3); high values indicate extreme range with tight VWAP convergence, signaling a high probability of a short-term trend reversal.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T09:45:32.401384"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1112063441042629,
        "ICIR": 0.0403131468116047,
        "1day.excess_return_without_cost.std": 0.0039390795650048,
        "1day.excess_return_with_cost.annualized_return": -0.0054684005389127,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001761839813554,
        "1day.excess_return_without_cost.annualized_return": 0.0419317875625912,
        "1day.excess_return_with_cost.std": 0.0039388718397868,
        "Rank IC": 0.0238353203951861,
        "IC": 0.0052729275142378,
        "1day.excess_return_without_cost.max_drawdown": -0.1012113134845434,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6900175633602922,
        "1day.pa": 0.0,
        "l2.valid": 0.9966187875448158,
        "Rank ICIR": 0.1814489347528798,
        "l2.train": 0.9932805025084444,
        "1day.excess_return_with_cost.information_ratio": -0.0899911887305707,
        "1day.excess_return_with_cost.mean": -2.297647285257453e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Intraday Exhaustion Reversal' hypothesis. The results indicate that while the core concept of using intraday range relative to price displacement has predictive power (positive IC and IR), the current implementations (Intraday_Exhaustion_Reversal_10D, Volatility_Convergence_Reversal_Factor, and Range_VWAP_Efficiency_Ratio) failed to outperform the existing SOTA. The SOTA remains superior across all key metrics, including IC (0.005798 vs 0.005273) and Information Ratio (0.972561 vs 0.690018). The 'Range_VWAP_Efficiency_Ratio' provided a simplified linear approach, but it appears that the interaction between raw volatility and price-to-VWAP distance requires a more robust normalization or a different look-back period to capture the 'exhaustion' signal effectively without being drowned out by absolute price levels.",
        "hypothesis_evaluation": "The hypothesis that high volatility without price displacement signals trend depletion is supported by the positive Information Ratio and IC, suggesting the signal is not noise. However, the current mathematical formulations are likely capturing too much 'level' information (e.g., high-low range in absolute terms) rather than 'relative' exhaustion. The 'Range_VWAP_Efficiency_Ratio' used raw price differences which might introduce scale bias. The use of TS_RANK in the first factor was a step in the right direction for normalization, but the 5-day window for the inverse distance might be too short, leading to high turnover and sensitivity to noise.",
        "decision": false,
        "reason": "Current factors either used raw values (Range_VWAP_Efficiency_Ratio) or mixed ranks with raw means. By using Z-scores for both the 'Volatility' component (High-Low) and the 'Displacement' component (Close-VWAP), we ensure both signals are on the same scale and represent 'abnormal' states. A high Z-score in range combined with a low or negative Z-score in displacement more accurately captures the 'churning' behavior indicative of exhaustion. Extending the displacement window to 10 days to match the range window will also provide a more stable baseline for comparison."
      }
    },
    "cf69c46a7831b882": {
      "factor_id": "cf69c46a7831b882",
      "factor_name": "EVB_Exhaustion_Score_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * (($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (TS_STD($close, 15) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * (($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) / (TS_STD($close, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"EVB_Exhaustion_Score_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies assets where a structural breakout (overnight gap) follows a period of low volatility, confirmed by high intraday price dispersion. It captures the 'Exhaustion-Validated Breakout' by multiplying the gap magnitude with the ratio of current intraday range to its 20-day average, inversely weighted by historical volatility.",
      "factor_formulation": "\\text{EVB} = \\frac{(\\text{open} - \\text{prev\\_close})}{\\text{prev\\_close}} \\times \\frac{(\\text{high} - \\text{low})}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 20)} \\times \\frac{1}{\\text{TS\\_STD}(\\text{close}, 15)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "06375b2caf72",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Breakout' (EVB) factor identifies superior entry points by detecting assets where an overnight price gap following a 15-day low-volatility period is subsequently 'stress-tested' by high intraday price dispersion (High-Low range) relative to its 20-day average, signaling that 'dumb money' volatility has been absorbed by institutional support.\n                Concise Observation: Parent 1 (ILE) captured mean-reversion via liquidity exhaustion (RankIC 0.0285), while Parent 2 (ICCG) captured institutional conviction via gaps (RankIC 0.0229); combining them addresses the false-breakout problem in trend-following and the timing problem in mean-reversion.\n                Concise Justification: High intraday price dispersion relative to historical norms, when occurring after a volatility-compressed gap, serves as a 'filter' that separates high-conviction institutional moves from speculative noise, as the exhaustion of intraday sellers at the gap level provides a high-probability support zone.\n                Concise Knowledge: If a structural breakout (overnight gap) occurs after a volatility compression, its sustainability is confirmed when high intraday noise (price dispersion) fails to reverse the trend, indicating liquidity exhaustion of counter-trend participants.\n                concise Specification: Define 'Compression' as 15-day std of close; 'Gap' as (Open - PrevClose) / PrevClose; 'Exhaustion' as (High - Low) / 20-day moving average of (High - Low). The factor combines these by selecting assets with low 15-day volatility, a positive overnight gap, and an intraday range significantly higher than its 20-day mean.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T09:48:37.145278"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0915459030702278,
        "ICIR": 0.0427183631987282,
        "1day.excess_return_without_cost.std": 0.0039868313033292,
        "1day.excess_return_with_cost.annualized_return": 3.153279764522561e-05,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001981999306096,
        "1day.excess_return_without_cost.annualized_return": 0.0471715834850993,
        "1day.excess_return_with_cost.std": 0.0039879486144452,
        "Rank IC": 0.0240013419644914,
        "IC": 0.0056665695019102,
        "1day.excess_return_without_cost.max_drawdown": -0.0713281509109673,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7669448174383438,
        "1day.pa": 0.0,
        "l2.valid": 0.9964473314653822,
        "Rank ICIR": 0.1842832950710088,
        "l2.train": 0.993766809216322,
        "1day.excess_return_with_cost.information_ratio": 0.0005125361137707,
        "1day.excess_return_with_cost.mean": 1.3249074640851096e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Breakout' (EVB) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.0713 vs -0.0725), it failed to surpass the SOTA in Information Ratio, Annualized Return, and IC. The EVB_Exhaustion_Score_20D factor effectively combines overnight gaps, intraday range expansion, and historical volatility, but the multiplicative structure might be creating extreme outliers that degrade the Information Ratio. The IC remains positive but slightly lower than the SOTA, suggesting that while the signal direction is correct, the magnitude or ranking of the signal needs refinement.",
        "hypothesis_evaluation": "The hypothesis that 'dumb money' volatility is absorbed by institutional support following a breakout is partially supported by the positive IC and improved Max Drawdown. However, the drop in Information Ratio (0.767 vs 0.973) suggests that the current mathematical representation (multiplicative interaction of three distinct signals) might be too noisy. The 'Exhaustion' component (intraday range) and the 'Compression' component (15-day volatility) are likely the primary drivers, but their interaction with the 'Gap' component needs better normalization.",
        "decision": false,
        "reason": "The current EVB_Exhaustion_Score_20D uses a raw ratio of (High-Low) to its mean, which can be highly unstable. By switching to a Z-Score for the range and incorporating volume (e.g., volume relative to a 20-day moving average), we can better distinguish between 'exhaustion' (high volume, high range) and simple 'noise'. Furthermore, reducing the complexity by using additive RANK-based combinations instead of raw multiplicative scores (as hinted by the EVB_Binary_Filter_Factor) may improve the Information Ratio by reducing the impact of outliers."
      }
    },
    "2ee20dab51b2c8e6": {
      "factor_id": "2ee20dab51b2c8e6",
      "factor_name": "EVB_Binary_Filter_Factor",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) + RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) - RANK(TS_STD($close, 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / DELAY($close, 1)) + RANK(($high - $low) / (TS_MEAN($high - $low, 20) + 1e-8)) - RANK(TS_STD($close, 15))\" # Your output factor expression will be filled in here\n    name = \"EVB_Binary_Filter_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A conditional factor that flags stocks meeting the Exhaustion-Validated Breakout criteria: 15-day volatility compression, a positive overnight gap, and intraday range expansion. It uses RANK to normalize the components cross-sectionally.",
      "factor_formulation": "\\text{EVB\\_Filter} = \\text{RANK}(\\text{Gap}) + \\text{RANK}(\\frac{\\text{Range}}{\\text{TS\\_MEAN}(\\text{Range}, 20)}) - \\text{RANK}(\\text{TS\\_STD}(\\text{close}, 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "06375b2caf72",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Breakout' (EVB) factor identifies superior entry points by detecting assets where an overnight price gap following a 15-day low-volatility period is subsequently 'stress-tested' by high intraday price dispersion (High-Low range) relative to its 20-day average, signaling that 'dumb money' volatility has been absorbed by institutional support.\n                Concise Observation: Parent 1 (ILE) captured mean-reversion via liquidity exhaustion (RankIC 0.0285), while Parent 2 (ICCG) captured institutional conviction via gaps (RankIC 0.0229); combining them addresses the false-breakout problem in trend-following and the timing problem in mean-reversion.\n                Concise Justification: High intraday price dispersion relative to historical norms, when occurring after a volatility-compressed gap, serves as a 'filter' that separates high-conviction institutional moves from speculative noise, as the exhaustion of intraday sellers at the gap level provides a high-probability support zone.\n                Concise Knowledge: If a structural breakout (overnight gap) occurs after a volatility compression, its sustainability is confirmed when high intraday noise (price dispersion) fails to reverse the trend, indicating liquidity exhaustion of counter-trend participants.\n                concise Specification: Define 'Compression' as 15-day std of close; 'Gap' as (Open - PrevClose) / PrevClose; 'Exhaustion' as (High - Low) / 20-day moving average of (High - Low). The factor combines these by selecting assets with low 15-day volatility, a positive overnight gap, and an intraday range significantly higher than its 20-day mean.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T09:48:37.145278"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0915459030702278,
        "ICIR": 0.0427183631987282,
        "1day.excess_return_without_cost.std": 0.0039868313033292,
        "1day.excess_return_with_cost.annualized_return": 3.153279764522561e-05,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001981999306096,
        "1day.excess_return_without_cost.annualized_return": 0.0471715834850993,
        "1day.excess_return_with_cost.std": 0.0039879486144452,
        "Rank IC": 0.0240013419644914,
        "IC": 0.0056665695019102,
        "1day.excess_return_without_cost.max_drawdown": -0.0713281509109673,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7669448174383438,
        "1day.pa": 0.0,
        "l2.valid": 0.9964473314653822,
        "Rank ICIR": 0.1842832950710088,
        "l2.train": 0.993766809216322,
        "1day.excess_return_with_cost.information_ratio": 0.0005125361137707,
        "1day.excess_return_with_cost.mean": 1.3249074640851096e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Breakout' (EVB) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.0713 vs -0.0725), it failed to surpass the SOTA in Information Ratio, Annualized Return, and IC. The EVB_Exhaustion_Score_20D factor effectively combines overnight gaps, intraday range expansion, and historical volatility, but the multiplicative structure might be creating extreme outliers that degrade the Information Ratio. The IC remains positive but slightly lower than the SOTA, suggesting that while the signal direction is correct, the magnitude or ranking of the signal needs refinement.",
        "hypothesis_evaluation": "The hypothesis that 'dumb money' volatility is absorbed by institutional support following a breakout is partially supported by the positive IC and improved Max Drawdown. However, the drop in Information Ratio (0.767 vs 0.973) suggests that the current mathematical representation (multiplicative interaction of three distinct signals) might be too noisy. The 'Exhaustion' component (intraday range) and the 'Compression' component (15-day volatility) are likely the primary drivers, but their interaction with the 'Gap' component needs better normalization.",
        "decision": false,
        "reason": "The current EVB_Exhaustion_Score_20D uses a raw ratio of (High-Low) to its mean, which can be highly unstable. By switching to a Z-Score for the range and incorporating volume (e.g., volume relative to a 20-day moving average), we can better distinguish between 'exhaustion' (high volume, high range) and simple 'noise'. Furthermore, reducing the complexity by using additive RANK-based combinations instead of raw multiplicative scores (as hinted by the EVB_Binary_Filter_Factor) may improve the Information Ratio by reducing the impact of outliers."
      }
    },
    "3d36617005cc5524": {
      "factor_id": "3d36617005cc5524",
      "factor_name": "Intraday_Absorption_Ratio",
      "factor_expression": "TS_ZSCORE($high - $low, 20) / (TS_STD($close, 15) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE($high - $low, 20) / (TS_STD($close, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Intraday_Absorption_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor focuses on the 'Exhaustion' component of the EVB hypothesis. It measures the current day's price dispersion relative to its recent history, specifically looking for high-dispersion days that occur after low-volatility regimes to identify institutional absorption.",
      "factor_formulation": "\\text{IAR} = \\frac{\\text{TS\\_ZSCORE}(\\text{high} - \\text{low}, 20)}{\\text{TS\\_STD}(\\text{close}, 15)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "06375b2caf72",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Breakout' (EVB) factor identifies superior entry points by detecting assets where an overnight price gap following a 15-day low-volatility period is subsequently 'stress-tested' by high intraday price dispersion (High-Low range) relative to its 20-day average, signaling that 'dumb money' volatility has been absorbed by institutional support.\n                Concise Observation: Parent 1 (ILE) captured mean-reversion via liquidity exhaustion (RankIC 0.0285), while Parent 2 (ICCG) captured institutional conviction via gaps (RankIC 0.0229); combining them addresses the false-breakout problem in trend-following and the timing problem in mean-reversion.\n                Concise Justification: High intraday price dispersion relative to historical norms, when occurring after a volatility-compressed gap, serves as a 'filter' that separates high-conviction institutional moves from speculative noise, as the exhaustion of intraday sellers at the gap level provides a high-probability support zone.\n                Concise Knowledge: If a structural breakout (overnight gap) occurs after a volatility compression, its sustainability is confirmed when high intraday noise (price dispersion) fails to reverse the trend, indicating liquidity exhaustion of counter-trend participants.\n                concise Specification: Define 'Compression' as 15-day std of close; 'Gap' as (Open - PrevClose) / PrevClose; 'Exhaustion' as (High - Low) / 20-day moving average of (High - Low). The factor combines these by selecting assets with low 15-day volatility, a positive overnight gap, and an intraday range significantly higher than its 20-day mean.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T09:48:37.145278"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0915459030702278,
        "ICIR": 0.0427183631987282,
        "1day.excess_return_without_cost.std": 0.0039868313033292,
        "1day.excess_return_with_cost.annualized_return": 3.153279764522561e-05,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001981999306096,
        "1day.excess_return_without_cost.annualized_return": 0.0471715834850993,
        "1day.excess_return_with_cost.std": 0.0039879486144452,
        "Rank IC": 0.0240013419644914,
        "IC": 0.0056665695019102,
        "1day.excess_return_without_cost.max_drawdown": -0.0713281509109673,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7669448174383438,
        "1day.pa": 0.0,
        "l2.valid": 0.9964473314653822,
        "Rank ICIR": 0.1842832950710088,
        "l2.train": 0.993766809216322,
        "1day.excess_return_with_cost.information_ratio": 0.0005125361137707,
        "1day.excess_return_with_cost.mean": 1.3249074640851096e-07
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Breakout' (EVB) hypothesis. While the current iteration achieved a slightly better Max Drawdown (-0.0713 vs -0.0725), it failed to surpass the SOTA in Information Ratio, Annualized Return, and IC. The EVB_Exhaustion_Score_20D factor effectively combines overnight gaps, intraday range expansion, and historical volatility, but the multiplicative structure might be creating extreme outliers that degrade the Information Ratio. The IC remains positive but slightly lower than the SOTA, suggesting that while the signal direction is correct, the magnitude or ranking of the signal needs refinement.",
        "hypothesis_evaluation": "The hypothesis that 'dumb money' volatility is absorbed by institutional support following a breakout is partially supported by the positive IC and improved Max Drawdown. However, the drop in Information Ratio (0.767 vs 0.973) suggests that the current mathematical representation (multiplicative interaction of three distinct signals) might be too noisy. The 'Exhaustion' component (intraday range) and the 'Compression' component (15-day volatility) are likely the primary drivers, but their interaction with the 'Gap' component needs better normalization.",
        "decision": false,
        "reason": "The current EVB_Exhaustion_Score_20D uses a raw ratio of (High-Low) to its mean, which can be highly unstable. By switching to a Z-Score for the range and incorporating volume (e.g., volume relative to a 20-day moving average), we can better distinguish between 'exhaustion' (high volume, high range) and simple 'noise'. Furthermore, reducing the complexity by using additive RANK-based combinations instead of raw multiplicative scores (as hinted by the EVB_Binary_Filter_Factor) may improve the Information Ratio by reducing the impact of outliers."
      }
    },
    "6390924c514e7e94": {
      "factor_id": "6390924c514e7e94",
      "factor_name": "Fractal_Exhaustion_Synergy_10D",
      "factor_expression": "(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * RANK(($high - $low) / ($close + 1e-8))) / (TS_CORR($return, $volume, 5) + 1.1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(10), 10), 2) * RANK(($high - $low) / ($close + 1e-8))) / (TS_CORR(TS_PCTCHANGE($close, 1), $volume, 5) + 1.1)\" # Your output factor expression will be filled in here\n    name = \"Fractal_Exhaustion_Synergy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by combining trend linearity (R-squared of price over time), intraday dispersion (High-Low range), and volume-price support breakdown. High linearity and dispersion coupled with low volume-return correlation indicate a terminal exhaustion phase.",
      "factor_formulation": "FES = \\frac{R^2(\\text{close}, 10) \\times \\text{RANK}(\\frac{\\text{high}-\\text{low}}{\\text{close}})}{\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 5) + 1.1}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "6c544e135be8",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "3074579fb242"
        ],
        "hypothesis": "Hypothesis: The 'Fractal Exhaustion Synergy' (FES) factor predicts price reversals by identifying assets where high multi-day trend linearity (R-squared) coincides with extreme intraday price dispersion (High-Low range) and a breakdown in volume-price support.\n                Concise Observation: Parent 1's intraday dispersion (RankIC 0.0285) captures tactical exhaustion, while Parent 2's structural R-squared (RankIC 0.0222) identifies trend maturity; combining them addresses the failure of dispersion signals in strong, volume-supported trends.\n                Concise Justification: The fusion logic assumes that the most reliable reversals occur when a 'blow-off' intraday move (Parent 1) happens at the end of a long-term linear trend (Parent 2) that no longer has the institutional volume backing to sustain its trajectory.\n                Concise Knowledge: If a price trend exhibits high geometric linearity but experiences a sudden spike in intraday volatility coupled with declining volume-price correlation, then the trend is likely entering a terminal exhaustion phase; When structural persistence meets liquidity voids, mean-reversion probability increases.\n                concise Specification: The factor is defined as the product of the 10-day price-time R-squared and the 20-day normalized High-Low range, divided by the 5-day rolling correlation between price returns and volume, focusing on the top decile of dispersion and linearity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:01:59.078591"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1001546538198187,
        "ICIR": 0.0410009823626141,
        "1day.excess_return_without_cost.std": 0.0043155308273293,
        "1day.excess_return_with_cost.annualized_return": 0.0410431365262001,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003721546358341,
        "1day.excess_return_without_cost.annualized_return": 0.0885728033285212,
        "1day.excess_return_with_cost.std": 0.0043174605851991,
        "Rank IC": 0.0259523213357421,
        "IC": 0.0056860530088302,
        "1day.excess_return_without_cost.max_drawdown": -0.0921949183384688,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3303860688334168,
        "1day.pa": 0.0,
        "l2.valid": 0.9965652592482478,
        "Rank ICIR": 0.1880754011340366,
        "l2.train": 0.9939190675352984,
        "1day.excess_return_with_cost.information_ratio": 0.6162028210227557,
        "1day.excess_return_with_cost.mean": 0.0001724501534714
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Fractal Exhaustion Synergy' (FES) hypothesis. The current results show a significant improvement in risk-adjusted performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.33, and the Annualized Return rose from 5.2% to 8.8%. Although the IC is slightly lower (0.0056 vs 0.0058) and the Max Drawdown increased, the substantial gain in excess return and IR suggests that the core logic of combining trend linearity with volume-price divergence is capturing high-conviction reversal signals effectively.",
        "hypothesis_evaluation": "The hypothesis that high trend linearity (R-squared) combined with intraday dispersion and volume-price breakdown predicts reversals is strongly supported. The 'Linear_Dispersion_Volume_Reversal' (LDVR) implementation, which uses a rank-based additive structure, appears more robust than the multiplicative FES_10D version. The additive structure likely prevents extreme values from a single component from skewing the factor, leading to better generalization and a much higher Information Ratio.",
        "decision": true,
        "reason": "While the current LDVR factor is successful, it relies on static window sizes (10D/20D). The next iteration should focus on 'acceleration' of exhaustion. By replacing the simple intraday range with a measure of range expansion relative to volume (Liquidity Gap), we can better identify 'blow-off tops' or 'panic bottoms'. Furthermore, the current factor uses 5 base features; maintaining this efficiency while refining the mathematical representation of 'exhaustion' (e.g., using a ratio of range to volume growth) should improve the IC without increasing complexity."
      }
    },
    "7ca06a3f2fd8a5d9": {
      "factor_id": "7ca06a3f2fd8a5d9",
      "factor_name": "Linear_Dispersion_Volume_Reversal",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)) - RANK(TS_CORR($return, $volume, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(TS_ZSCORE(($high - $low) / $close, 20)) - RANK(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Linear_Dispersion_Volume_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Fractal Exhaustion Synergy hypothesis. It targets assets where a long-term linear trend (10-day R-squared) meets high relative intraday volatility (20-day Z-score of range) while volume support (5-day return-volume correlation) is weakening.",
      "factor_formulation": "LDVR = \\text{RANK}(R^2(\\text{close}, 10)) + \\text{RANK}(\\text{TS\\_ZSCORE}(\\frac{\\text{high}-\\text{low}}{\\text{close}}, 20)) - \\text{RANK}(\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "6c544e135be8",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "3074579fb242"
        ],
        "hypothesis": "Hypothesis: The 'Fractal Exhaustion Synergy' (FES) factor predicts price reversals by identifying assets where high multi-day trend linearity (R-squared) coincides with extreme intraday price dispersion (High-Low range) and a breakdown in volume-price support.\n                Concise Observation: Parent 1's intraday dispersion (RankIC 0.0285) captures tactical exhaustion, while Parent 2's structural R-squared (RankIC 0.0222) identifies trend maturity; combining them addresses the failure of dispersion signals in strong, volume-supported trends.\n                Concise Justification: The fusion logic assumes that the most reliable reversals occur when a 'blow-off' intraday move (Parent 1) happens at the end of a long-term linear trend (Parent 2) that no longer has the institutional volume backing to sustain its trajectory.\n                Concise Knowledge: If a price trend exhibits high geometric linearity but experiences a sudden spike in intraday volatility coupled with declining volume-price correlation, then the trend is likely entering a terminal exhaustion phase; When structural persistence meets liquidity voids, mean-reversion probability increases.\n                concise Specification: The factor is defined as the product of the 10-day price-time R-squared and the 20-day normalized High-Low range, divided by the 5-day rolling correlation between price returns and volume, focusing on the top decile of dispersion and linearity.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:01:59.078591"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1001546538198187,
        "ICIR": 0.0410009823626141,
        "1day.excess_return_without_cost.std": 0.0043155308273293,
        "1day.excess_return_with_cost.annualized_return": 0.0410431365262001,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003721546358341,
        "1day.excess_return_without_cost.annualized_return": 0.0885728033285212,
        "1day.excess_return_with_cost.std": 0.0043174605851991,
        "Rank IC": 0.0259523213357421,
        "IC": 0.0056860530088302,
        "1day.excess_return_without_cost.max_drawdown": -0.0921949183384688,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3303860688334168,
        "1day.pa": 0.0,
        "l2.valid": 0.9965652592482478,
        "Rank ICIR": 0.1880754011340366,
        "l2.train": 0.9939190675352984,
        "1day.excess_return_with_cost.information_ratio": 0.6162028210227557,
        "1day.excess_return_with_cost.mean": 0.0001724501534714
      },
      "feedback": {
        "observations": "The experiment tested two variations of the 'Fractal Exhaustion Synergy' (FES) hypothesis. The current results show a significant improvement in risk-adjusted performance metrics compared to the previous SOTA. Specifically, the Information Ratio increased from 0.97 to 1.33, and the Annualized Return rose from 5.2% to 8.8%. Although the IC is slightly lower (0.0056 vs 0.0058) and the Max Drawdown increased, the substantial gain in excess return and IR suggests that the core logic of combining trend linearity with volume-price divergence is capturing high-conviction reversal signals effectively.",
        "hypothesis_evaluation": "The hypothesis that high trend linearity (R-squared) combined with intraday dispersion and volume-price breakdown predicts reversals is strongly supported. The 'Linear_Dispersion_Volume_Reversal' (LDVR) implementation, which uses a rank-based additive structure, appears more robust than the multiplicative FES_10D version. The additive structure likely prevents extreme values from a single component from skewing the factor, leading to better generalization and a much higher Information Ratio.",
        "decision": true,
        "reason": "While the current LDVR factor is successful, it relies on static window sizes (10D/20D). The next iteration should focus on 'acceleration' of exhaustion. By replacing the simple intraday range with a measure of range expansion relative to volume (Liquidity Gap), we can better identify 'blow-off tops' or 'panic bottoms'. Furthermore, the current factor uses 5 base features; maintaining this efficiency while refining the mathematical representation of 'exhaustion' (e.g., using a ratio of range to volume growth) should improve the IC without increasing complexity."
      }
    },
    "208aea9912ae16e6": {
      "factor_id": "208aea9912ae16e6",
      "factor_name": "LVSB_Efficiency_Factor_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) - TS_ZSCORE($high - $low, 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) - TS_ZSCORE($high - $low, 20)\" # Your output factor expression will be filled in here\n    name = \"LVSB_Efficiency_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction breakouts by calculating the ratio of the overnight gap to the intraday range, scaled by relative volume and penalized by recent volatility expansion. It rewards stocks where a gap is supported by high volume and tight intraday price action (low dispersion).",
      "factor_formulation": "LVSB = \\frac{$open - \\text{DELAY}($close, 1)}{($high - $low) + 1e-8} \\times \\frac{$volume}{\\text{TS_MEAN}($volume, 20)} - \\text{TS_ZSCORE}($high - $low, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "83429d02e7a4",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Breakout' (LVSB) factor identifies high-conviction institutional entries by selecting stocks with a significant overnight gap that is subsequently supported by high volume and low intraday price dispersion, while penalizing those with high-volatility exhaustion signatures.\n                Concise Observation: Parent 1 (ILE) successfully captures mean-reversion via high dispersion (RankIC=0.0285), while Parent 2 (IAB) captures momentum via overnight gaps (RankIC=0.0214); however, neither distinguishes between high-quality institutional breakouts and low-quality volatility spikes.\n                Concise Justification: By combining the overnight gap signal with a volume-weighted price efficiency metric, we can filter out 'noisy' volatility that leads to exhaustion, ensuring the factor only rewards breakouts where the intraday price action remains tight and liquid.\n                Concise Knowledge: If a positive overnight gap is followed by high volume and low price dispersion, it indicates institutional absorption and trend continuation; conversely, if a gap is accompanied by extreme price dispersion relative to volume, it signifies retail-driven exhaustion and likely mean-reversion.\n                concise Specification: The factor is calculated as the ratio of the Overnight Gap (Close[t-1] to Open[t]) to the Intraday Range (High-Low), multiplied by the ratio of Volume to its 20-day average, then penalized by the 20-day rolling Z-score of the High-Low range.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:05:11.867863"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1081249528506243,
        "ICIR": 0.0579463354585472,
        "1day.excess_return_without_cost.std": 0.0040139541076409,
        "1day.excess_return_with_cost.annualized_return": 0.0108404437147842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002437985558976,
        "1day.excess_return_without_cost.annualized_return": 0.0580240563036302,
        "1day.excess_return_with_cost.std": 0.0040145989171416,
        "Rank IC": 0.0274559579331133,
        "IC": 0.0079929222089182,
        "1day.excess_return_without_cost.max_drawdown": -0.0905515232058431,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9370164267702088,
        "1day.pa": 0.0,
        "l2.valid": 0.9965338220479508,
        "Rank ICIR": 0.2036564853945049,
        "l2.train": 0.9934091827710494,
        "1day.excess_return_with_cost.information_ratio": 0.1750315816326627,
        "1day.excess_return_with_cost.mean": 4.554808283522773e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Liquidity-Validated Structural Breakout' (LVSB) framework has successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0079, and the Annualized Return rose from 5.2% to 5.8%. However, this gain in return came at the cost of higher risk, as evidenced by a higher Max Drawdown (-0.090 vs -0.072) and a slightly lower Information Ratio (0.937 vs 0.972). The factors implemented—LVSB_Efficiency_Factor, Institutional_Absorption_Ratio, and Breakout_Quality_Score—effectively capture the interaction between overnight gaps and intraday liquidity, but the increased drawdown suggests the current formulations might be sensitive to market-wide volatility shocks.",
        "hypothesis_evaluation": "The results support the hypothesis that combining overnight gaps with intraday price dispersion and volume validation provides predictive power. The improvement in IC suggests that the 'cleanliness' of a breakout (gap / intraday range) is a valid signal for institutional entry. However, the 'volatility exhaustion' penalty (TS_ZSCORE of range) in the current factors might be too reactive or improperly scaled, leading to the observed increase in drawdown. The 'Institutional_Absorption_Ratio' using RANK appears robust, but the linear combination in other factors may be introducing noise.",
        "decision": true,
        "reason": "The current factors use relatively short windows (10-20 days) for volatility normalization, which likely caused the higher drawdown during regime shifts. By extending the volatility anchor to 60 days and refining the interaction between volume and range (Volume / (High-Low)), we can more precisely isolate 'absorption' (high volume, small price movement) versus 'exhaustion' (high volume, wide price movement). This should maintain the high IC while improving the Information Ratio and reducing Drawdown."
      }
    },
    "ce5d517e1781dd6e": {
      "factor_id": "ce5d517e1781dd6e",
      "factor_name": "Institutional_Absorption_Ratio_15D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * RANK($volume / (TS_STD($close, 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * RANK($volume / (TS_STD($close, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the LVSB hypothesis focusing on the 'Absorption' signature. It measures the overnight gap relative to the intraday range, multiplied by the volume-to-volatility ratio to identify liquid, low-dispersion breakouts.",
      "factor_formulation": "IAR = \\text{RANK}(\\frac{$open - \\text{DELAY}($close, 1)}{$high - $low + 1e-8}) \\times \\text{RANK}(\\frac{$volume}{\\text{TS_STD}($close, 15) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "83429d02e7a4",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Breakout' (LVSB) factor identifies high-conviction institutional entries by selecting stocks with a significant overnight gap that is subsequently supported by high volume and low intraday price dispersion, while penalizing those with high-volatility exhaustion signatures.\n                Concise Observation: Parent 1 (ILE) successfully captures mean-reversion via high dispersion (RankIC=0.0285), while Parent 2 (IAB) captures momentum via overnight gaps (RankIC=0.0214); however, neither distinguishes between high-quality institutional breakouts and low-quality volatility spikes.\n                Concise Justification: By combining the overnight gap signal with a volume-weighted price efficiency metric, we can filter out 'noisy' volatility that leads to exhaustion, ensuring the factor only rewards breakouts where the intraday price action remains tight and liquid.\n                Concise Knowledge: If a positive overnight gap is followed by high volume and low price dispersion, it indicates institutional absorption and trend continuation; conversely, if a gap is accompanied by extreme price dispersion relative to volume, it signifies retail-driven exhaustion and likely mean-reversion.\n                concise Specification: The factor is calculated as the ratio of the Overnight Gap (Close[t-1] to Open[t]) to the Intraday Range (High-Low), multiplied by the ratio of Volume to its 20-day average, then penalized by the 20-day rolling Z-score of the High-Low range.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:05:11.867863"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1081249528506243,
        "ICIR": 0.0579463354585472,
        "1day.excess_return_without_cost.std": 0.0040139541076409,
        "1day.excess_return_with_cost.annualized_return": 0.0108404437147842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002437985558976,
        "1day.excess_return_without_cost.annualized_return": 0.0580240563036302,
        "1day.excess_return_with_cost.std": 0.0040145989171416,
        "Rank IC": 0.0274559579331133,
        "IC": 0.0079929222089182,
        "1day.excess_return_without_cost.max_drawdown": -0.0905515232058431,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9370164267702088,
        "1day.pa": 0.0,
        "l2.valid": 0.9965338220479508,
        "Rank ICIR": 0.2036564853945049,
        "l2.train": 0.9934091827710494,
        "1day.excess_return_with_cost.information_ratio": 0.1750315816326627,
        "1day.excess_return_with_cost.mean": 4.554808283522773e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Liquidity-Validated Structural Breakout' (LVSB) framework has successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0079, and the Annualized Return rose from 5.2% to 5.8%. However, this gain in return came at the cost of higher risk, as evidenced by a higher Max Drawdown (-0.090 vs -0.072) and a slightly lower Information Ratio (0.937 vs 0.972). The factors implemented—LVSB_Efficiency_Factor, Institutional_Absorption_Ratio, and Breakout_Quality_Score—effectively capture the interaction between overnight gaps and intraday liquidity, but the increased drawdown suggests the current formulations might be sensitive to market-wide volatility shocks.",
        "hypothesis_evaluation": "The results support the hypothesis that combining overnight gaps with intraday price dispersion and volume validation provides predictive power. The improvement in IC suggests that the 'cleanliness' of a breakout (gap / intraday range) is a valid signal for institutional entry. However, the 'volatility exhaustion' penalty (TS_ZSCORE of range) in the current factors might be too reactive or improperly scaled, leading to the observed increase in drawdown. The 'Institutional_Absorption_Ratio' using RANK appears robust, but the linear combination in other factors may be introducing noise.",
        "decision": true,
        "reason": "The current factors use relatively short windows (10-20 days) for volatility normalization, which likely caused the higher drawdown during regime shifts. By extending the volatility anchor to 60 days and refining the interaction between volume and range (Volume / (High-Low)), we can more precisely isolate 'absorption' (high volume, small price movement) versus 'exhaustion' (high volume, wide price movement). This should maintain the high IC while improving the Information Ratio and reducing Drawdown."
      }
    },
    "0f9fa07bf2e5714b": {
      "factor_id": "0f9fa07bf2e5714b",
      "factor_name": "Breakout_Quality_Score_10D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / (1 + TS_ZSCORE($high - $low, 10) + 1e-8) * ($volume / TS_MEAN($volume, 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / (1 + TS_ZSCORE($high - $low, 10))\" # Your output factor expression will be filled in here\n    name = \"Breakout_Quality_Score_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor evaluates the quality of a breakout by comparing the overnight return to the intraday volatility (High-Low). It uses a 10-day window to penalize stocks with high historical price dispersion, favoring 'clean' structural breaks.",
      "factor_formulation": "BQS = \\frac{\\text{TS_PCTCHANGE}($close, 1) - \\text{TS_PCTCHANGE}($close, 1) \\text{ (intraday portion)}}{1 + \\text{TS_ZSCORE}(\\text{range}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "83429d02e7a4",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "0febcaea0735"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Breakout' (LVSB) factor identifies high-conviction institutional entries by selecting stocks with a significant overnight gap that is subsequently supported by high volume and low intraday price dispersion, while penalizing those with high-volatility exhaustion signatures.\n                Concise Observation: Parent 1 (ILE) successfully captures mean-reversion via high dispersion (RankIC=0.0285), while Parent 2 (IAB) captures momentum via overnight gaps (RankIC=0.0214); however, neither distinguishes between high-quality institutional breakouts and low-quality volatility spikes.\n                Concise Justification: By combining the overnight gap signal with a volume-weighted price efficiency metric, we can filter out 'noisy' volatility that leads to exhaustion, ensuring the factor only rewards breakouts where the intraday price action remains tight and liquid.\n                Concise Knowledge: If a positive overnight gap is followed by high volume and low price dispersion, it indicates institutional absorption and trend continuation; conversely, if a gap is accompanied by extreme price dispersion relative to volume, it signifies retail-driven exhaustion and likely mean-reversion.\n                concise Specification: The factor is calculated as the ratio of the Overnight Gap (Close[t-1] to Open[t]) to the Intraday Range (High-Low), multiplied by the ratio of Volume to its 20-day average, then penalized by the 20-day rolling Z-score of the High-Low range.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:05:11.867863"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1081249528506243,
        "ICIR": 0.0579463354585472,
        "1day.excess_return_without_cost.std": 0.0040139541076409,
        "1day.excess_return_with_cost.annualized_return": 0.0108404437147842,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002437985558976,
        "1day.excess_return_without_cost.annualized_return": 0.0580240563036302,
        "1day.excess_return_with_cost.std": 0.0040145989171416,
        "Rank IC": 0.0274559579331133,
        "IC": 0.0079929222089182,
        "1day.excess_return_without_cost.max_drawdown": -0.0905515232058431,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9370164267702088,
        "1day.pa": 0.0,
        "l2.valid": 0.9965338220479508,
        "Rank ICIR": 0.2036564853945049,
        "l2.train": 0.9934091827710494,
        "1day.excess_return_with_cost.information_ratio": 0.1750315816326627,
        "1day.excess_return_with_cost.mean": 4.554808283522773e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Liquidity-Validated Structural Breakout' (LVSB) framework has successfully improved the Information Coefficient (IC) and Annualized Return compared to the previous SOTA. Specifically, the IC increased from 0.0058 to 0.0079, and the Annualized Return rose from 5.2% to 5.8%. However, this gain in return came at the cost of higher risk, as evidenced by a higher Max Drawdown (-0.090 vs -0.072) and a slightly lower Information Ratio (0.937 vs 0.972). The factors implemented—LVSB_Efficiency_Factor, Institutional_Absorption_Ratio, and Breakout_Quality_Score—effectively capture the interaction between overnight gaps and intraday liquidity, but the increased drawdown suggests the current formulations might be sensitive to market-wide volatility shocks.",
        "hypothesis_evaluation": "The results support the hypothesis that combining overnight gaps with intraday price dispersion and volume validation provides predictive power. The improvement in IC suggests that the 'cleanliness' of a breakout (gap / intraday range) is a valid signal for institutional entry. However, the 'volatility exhaustion' penalty (TS_ZSCORE of range) in the current factors might be too reactive or improperly scaled, leading to the observed increase in drawdown. The 'Institutional_Absorption_Ratio' using RANK appears robust, but the linear combination in other factors may be introducing noise.",
        "decision": true,
        "reason": "The current factors use relatively short windows (10-20 days) for volatility normalization, which likely caused the higher drawdown during regime shifts. By extending the volatility anchor to 60 days and refining the interaction between volume and range (Volume / (High-Low)), we can more precisely isolate 'absorption' (high volume, small price movement) versus 'exhaustion' (high volume, wide price movement). This should maintain the high IC while improving the Information Ratio and reducing Drawdown."
      }
    },
    "d590f9fdac94714f": {
      "factor_id": "d590f9fdac94714f",
      "factor_name": "LVSR_Factor_Base",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($close + 1e-8), 20) * TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) * (1 / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / ($close + 1e-8), 20) * TS_MEAN((MIN($open, $close) - $low) / ($high - $low + 1e-8), 5) * (1 / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LVSR_Factor_Base\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Liquidity-Validated Structural Rebound factor: Combines intraday price dispersion (20-day Z-score of range), institutional absorption (5-day mean of lower shadow ratio), and inverse volume volatility. It identifies exhaustion points where high noise meets strong buying support.",
      "factor_formulation": "\\text{TS\\_ZSCORE}(\\frac{high-low}{close}, 20) \\times \\text{TS\\_MEAN}(\\frac{\\min(open, close)-low}{high-low}, 5) \\times \\frac{1}{\\text{TS\\_STD}(volume, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "b8009e9e70de",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Rebound' (LVSR) factor predicts short-term reversals by identifying assets where high intraday price dispersion (noise) is coupled with strong institutional absorption, defined as the product of the 20-day Z-score of the High-Low range and the 5-day average lower-shadow-to-total-range ratio, scaled by the inverse of volume volatility.\n                Concise Observation: Parent 1 captures high-alpha mean-reversion via price dispersion but suffers from 'falling knife' risks, while Parent 2 identifies structural support through shadow ratios but lacks a volatility-based trigger for timing.\n                Concise Justification: Fusing these identifies 'exhaustion' points where selling pressure is spent (high range/low volume conviction) and immediately met by buying support (lower shadows), creating a higher-probability reversal signal than either component alone.\n                Concise Knowledge: If high intraday volatility (dispersion) occurs without a corresponding surge in volume volatility, it indicates market noise; if this noise is accompanied by large lower shadows (absorption), a price reversal is more likely than a continuation.\n                concise Specification: The factor is the product of: (1) the 20-day Z-score of (High-Low)/Close, (2) the 5-day mean of (min(Open, Close)-Low)/(High-Low), and (3) the inverse of the 5-day standard deviation of Volume, all calculated using daily_pv.h5 data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:08:28.656044"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0895790740906607,
        "ICIR": 0.0472620471795279,
        "1day.excess_return_without_cost.std": 0.0038983818085295,
        "1day.excess_return_with_cost.annualized_return": 0.0360745920472733,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003503139706382,
        "1day.excess_return_without_cost.annualized_return": 0.0833747250119079,
        "1day.excess_return_with_cost.std": 0.0038996970574369,
        "Rank IC": 0.0233725195396657,
        "IC": 0.0062690397404904,
        "1day.excess_return_without_cost.max_drawdown": -0.0780516741682955,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3863138568061828,
        "1day.pa": 0.0,
        "l2.valid": 0.9962661055425046,
        "Rank ICIR": 0.1762123108905118,
        "l2.train": 0.9931667036808288,
        "1day.excess_return_with_cost.information_ratio": 0.5996282415341484,
        "1day.excess_return_with_cost.mean": 0.000151573916165
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Liquidity-Validated Structural Rebound' (LVSR) framework. The current iteration significantly outperformed the previous SOTA across almost all key performance indicators. Specifically, the Information Ratio (IR) improved from 0.97 to 1.38, and the Annualized Return increased from 5.2% to 8.3%. The IC also showed a healthy improvement to 0.0063. While the Max Drawdown slightly worsened (-0.078 vs -0.072), the substantial gains in risk-adjusted returns (IR) justify the current approach. The 'LVSR_Rank_Stabilized' and 'LVSR_Momentum_Filtered' variations suggest that cross-sectional ranking and simplifying the volume-volatility interaction are effective strategies for capturing the intended market inefficiency.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday price dispersion with institutional absorption (proxied by lower shadows) and volume stability predicts short-term reversals. The success of the 'LVSR_Rank_Stabilized' approach indicates that the relationship is more robust when viewed through a relative (cross-sectional) lens rather than absolute values. The 'LVSR_Momentum_Filtered' result suggests that the raw price range (high-low) might be a more direct proxy for dispersion than a complex Z-score when coupled with volume stability.",
        "decision": true,
        "reason": "Current results show that volume stability is a key filter, but absolute standard deviation can be sensitive to regime shifts. Using relative volume intensity (Volume/MA) focuses on liquidity surges accompanying the price tail. Furthermore, the 'lower shadow ratio' often contains noise in mid-range bars; by focusing on the top decile of shadow ratios (non-linear scaling), we can more accurately isolate the 'structural rebound' intended by the hypothesis while maintaining low symbol complexity and feature count."
      }
    },
    "ba727aca0bb9c171": {
      "factor_id": "ba727aca0bb9c171",
      "factor_name": "LVSR_Rank_Stabilized",
      "factor_expression": "RANK(TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)) * RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(1 / (TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)) * RANK((MIN($open, $close) - $low) / ($high - $low + 1e-8)) * RANK(1 / (TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LVSR_Rank_Stabilized\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally stabilized version of the LVSR factor. It uses RANK to normalize the components of price dispersion, shadow absorption, and volume stability before combining them to ensure robustness against outliers.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_ZSCORE}(\\frac{high-low}{close}, 20)) \\times \\text{RANK}(\\frac{\\min(open,close)-low}{high-low}) \\times \\text{RANK}(\\frac{1}{\\text{TS\\_STD}(volume, 5)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "b8009e9e70de",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Rebound' (LVSR) factor predicts short-term reversals by identifying assets where high intraday price dispersion (noise) is coupled with strong institutional absorption, defined as the product of the 20-day Z-score of the High-Low range and the 5-day average lower-shadow-to-total-range ratio, scaled by the inverse of volume volatility.\n                Concise Observation: Parent 1 captures high-alpha mean-reversion via price dispersion but suffers from 'falling knife' risks, while Parent 2 identifies structural support through shadow ratios but lacks a volatility-based trigger for timing.\n                Concise Justification: Fusing these identifies 'exhaustion' points where selling pressure is spent (high range/low volume conviction) and immediately met by buying support (lower shadows), creating a higher-probability reversal signal than either component alone.\n                Concise Knowledge: If high intraday volatility (dispersion) occurs without a corresponding surge in volume volatility, it indicates market noise; if this noise is accompanied by large lower shadows (absorption), a price reversal is more likely than a continuation.\n                concise Specification: The factor is the product of: (1) the 20-day Z-score of (High-Low)/Close, (2) the 5-day mean of (min(Open, Close)-Low)/(High-Low), and (3) the inverse of the 5-day standard deviation of Volume, all calculated using daily_pv.h5 data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:08:28.656044"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0895790740906607,
        "ICIR": 0.0472620471795279,
        "1day.excess_return_without_cost.std": 0.0038983818085295,
        "1day.excess_return_with_cost.annualized_return": 0.0360745920472733,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003503139706382,
        "1day.excess_return_without_cost.annualized_return": 0.0833747250119079,
        "1day.excess_return_with_cost.std": 0.0038996970574369,
        "Rank IC": 0.0233725195396657,
        "IC": 0.0062690397404904,
        "1day.excess_return_without_cost.max_drawdown": -0.0780516741682955,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3863138568061828,
        "1day.pa": 0.0,
        "l2.valid": 0.9962661055425046,
        "Rank ICIR": 0.1762123108905118,
        "l2.train": 0.9931667036808288,
        "1day.excess_return_with_cost.information_ratio": 0.5996282415341484,
        "1day.excess_return_with_cost.mean": 0.000151573916165
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Liquidity-Validated Structural Rebound' (LVSR) framework. The current iteration significantly outperformed the previous SOTA across almost all key performance indicators. Specifically, the Information Ratio (IR) improved from 0.97 to 1.38, and the Annualized Return increased from 5.2% to 8.3%. The IC also showed a healthy improvement to 0.0063. While the Max Drawdown slightly worsened (-0.078 vs -0.072), the substantial gains in risk-adjusted returns (IR) justify the current approach. The 'LVSR_Rank_Stabilized' and 'LVSR_Momentum_Filtered' variations suggest that cross-sectional ranking and simplifying the volume-volatility interaction are effective strategies for capturing the intended market inefficiency.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday price dispersion with institutional absorption (proxied by lower shadows) and volume stability predicts short-term reversals. The success of the 'LVSR_Rank_Stabilized' approach indicates that the relationship is more robust when viewed through a relative (cross-sectional) lens rather than absolute values. The 'LVSR_Momentum_Filtered' result suggests that the raw price range (high-low) might be a more direct proxy for dispersion than a complex Z-score when coupled with volume stability.",
        "decision": true,
        "reason": "Current results show that volume stability is a key filter, but absolute standard deviation can be sensitive to regime shifts. Using relative volume intensity (Volume/MA) focuses on liquidity surges accompanying the price tail. Furthermore, the 'lower shadow ratio' often contains noise in mid-range bars; by focusing on the top decile of shadow ratios (non-linear scaling), we can more accurately isolate the 'structural rebound' intended by the hypothesis while maintaining low symbol complexity and feature count."
      }
    },
    "2efcab566629671a": {
      "factor_id": "2efcab566629671a",
      "factor_name": "LVSR_Momentum_Filtered",
      "factor_expression": "(TS_MEAN($high - $low, 20) / (TS_STD($volume, 10) + 1e-8)) * (($close - $low) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($high - $low, 20) / (TS_STD($volume, 10) + 1e-8)) * (($close - $low) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"LVSR_Momentum_Filtered\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This variation of the LVSR factor focuses on the interaction between price range expansion and volume stability, specifically filtering for cases where the lower shadow is significant relative to the daily volatility.",
      "factor_formulation": "\\frac{\\text{TS\\_MEAN}(high-low, 20)}{\\text{TS\\_STD}(volume, 10)} \\times \\frac{close-low}{high-low}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "b8009e9e70de",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "043474954dbc"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Rebound' (LVSR) factor predicts short-term reversals by identifying assets where high intraday price dispersion (noise) is coupled with strong institutional absorption, defined as the product of the 20-day Z-score of the High-Low range and the 5-day average lower-shadow-to-total-range ratio, scaled by the inverse of volume volatility.\n                Concise Observation: Parent 1 captures high-alpha mean-reversion via price dispersion but suffers from 'falling knife' risks, while Parent 2 identifies structural support through shadow ratios but lacks a volatility-based trigger for timing.\n                Concise Justification: Fusing these identifies 'exhaustion' points where selling pressure is spent (high range/low volume conviction) and immediately met by buying support (lower shadows), creating a higher-probability reversal signal than either component alone.\n                Concise Knowledge: If high intraday volatility (dispersion) occurs without a corresponding surge in volume volatility, it indicates market noise; if this noise is accompanied by large lower shadows (absorption), a price reversal is more likely than a continuation.\n                concise Specification: The factor is the product of: (1) the 20-day Z-score of (High-Low)/Close, (2) the 5-day mean of (min(Open, Close)-Low)/(High-Low), and (3) the inverse of the 5-day standard deviation of Volume, all calculated using daily_pv.h5 data.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:08:28.656044"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0895790740906607,
        "ICIR": 0.0472620471795279,
        "1day.excess_return_without_cost.std": 0.0038983818085295,
        "1day.excess_return_with_cost.annualized_return": 0.0360745920472733,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003503139706382,
        "1day.excess_return_without_cost.annualized_return": 0.0833747250119079,
        "1day.excess_return_with_cost.std": 0.0038996970574369,
        "Rank IC": 0.0233725195396657,
        "IC": 0.0062690397404904,
        "1day.excess_return_without_cost.max_drawdown": -0.0780516741682955,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3863138568061828,
        "1day.pa": 0.0,
        "l2.valid": 0.9962661055425046,
        "Rank ICIR": 0.1762123108905118,
        "l2.train": 0.9931667036808288,
        "1day.excess_return_with_cost.information_ratio": 0.5996282415341484,
        "1day.excess_return_with_cost.mean": 0.000151573916165
      },
      "feedback": {
        "observations": "The experiment successfully validated the 'Liquidity-Validated Structural Rebound' (LVSR) framework. The current iteration significantly outperformed the previous SOTA across almost all key performance indicators. Specifically, the Information Ratio (IR) improved from 0.97 to 1.38, and the Annualized Return increased from 5.2% to 8.3%. The IC also showed a healthy improvement to 0.0063. While the Max Drawdown slightly worsened (-0.078 vs -0.072), the substantial gains in risk-adjusted returns (IR) justify the current approach. The 'LVSR_Rank_Stabilized' and 'LVSR_Momentum_Filtered' variations suggest that cross-sectional ranking and simplifying the volume-volatility interaction are effective strategies for capturing the intended market inefficiency.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday price dispersion with institutional absorption (proxied by lower shadows) and volume stability predicts short-term reversals. The success of the 'LVSR_Rank_Stabilized' approach indicates that the relationship is more robust when viewed through a relative (cross-sectional) lens rather than absolute values. The 'LVSR_Momentum_Filtered' result suggests that the raw price range (high-low) might be a more direct proxy for dispersion than a complex Z-score when coupled with volume stability.",
        "decision": true,
        "reason": "Current results show that volume stability is a key filter, but absolute standard deviation can be sensitive to regime shifts. Using relative volume intensity (Volume/MA) focuses on liquidity surges accompanying the price tail. Furthermore, the 'lower shadow ratio' often contains noise in mid-range bars; by focusing on the top decile of shadow ratios (non-linear scaling), we can more accurately isolate the 'structural rebound' intended by the hypothesis while maintaining low symbol complexity and feature count."
      }
    },
    "c1b05a7586bb7b8e": {
      "factor_id": "c1b05a7586bb7b8e",
      "factor_name": "LVSR_Factor_Reversion",
      "factor_expression": "TS_ZSCORE(($high - $low) / $close, 20) * (1 / (TS_MEAN(ABS($return) / ($volume * $close + 1e-8), 5) * ABS($open / (DELAY($close, 1) + 1e-8) - 1) + 1e-6))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 20) * INV(TS_MEAN(ABS(($close - DELAY($close, 1)) / DELAY($close, 1)) / ($volume * $close + 1e-8), 5) * ABS(($open - DELAY($close, 1)) / DELAY($close, 1)) + 1e-6)\" # Your output factor expression will be filled in here\n    name = \"LVSR_Factor_Reversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Liquidity-Validated Structural Reversion (LVSR) factor identifies 'hollow' price moves by scaling the 20-day Z-scored intraday range by the inverse of the 5-day Amihud illiquidity and overnight return magnitude. High values indicate high volatility on low liquidity, suggesting a high probability of mean-reversion.",
      "factor_formulation": "LVSR = \\text{TS_ZSCORE}(\\frac{high - low}{close}, 20) \\times \\frac{1}{\\text{TS_MEAN}(\\frac{|return|}{volume \\times close}, 5) \\times |\\frac{open}{\\text{DELAY}(close, 1)} - 1| + 1e-6}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "c4dc78139b53",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Reversion' (LVSR) factor, defined as the product of the 20-day Z-scored intraday price range and the inverse of the 5-day average Amihud illiquidity scaled by the absolute overnight return, predicts short-term mean-reversion by identifying 'hollow' price extensions lacking institutional support.\n                Concise Observation: Parent 1 (ILE) captures exhaustion through price range but fails during strong trends; Parent 2 (Institutional Absorption) identifies quality of price moves but lacks a volatility trigger; combining them filters out high-conviction institutional breakouts.\n                Concise Justification: By scaling intraday volatility by the inverse of illiquidity, we isolate 'cheap' volatility—moves that occur on low relative impact—which are theoretically more prone to mean-reversion than 'expensive' moves backed by institutional liquidity.\n                Concise Knowledge: If extreme intraday price dispersion occurs alongside low institutional absorption (low volume-to-price-impact ratio and minimal overnight sentiment), the price move is likely a liquidity-driven vacuum rather than information-driven, leading to a higher probability of reversion.\n                concise Specification: The factor is calculated as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) multiplied by [1 / (MA(Abs(Return) / (Volume * Close), 5) * Abs(Open / Delay(Close, 1) - 1) + 1e-6)], targeting a 5-day reversion horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:13:06.736021"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1258935792347857,
        "ICIR": 0.0390560526366975,
        "1day.excess_return_without_cost.std": 0.0040971998383566,
        "1day.excess_return_with_cost.annualized_return": -0.0010019363489492,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001957757669479,
        "1day.excess_return_without_cost.annualized_return": 0.0465946325336084,
        "1day.excess_return_with_cost.std": 0.0040981858728818,
        "Rank IC": 0.0252550352437647,
        "IC": 0.0055592755095405,
        "1day.excess_return_without_cost.max_drawdown": -0.0904368977392056,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7371574611294541,
        "1day.pa": 0.0,
        "l2.valid": 0.9964368775156224,
        "Rank ICIR": 0.1811824002641607,
        "l2.train": 0.9938609610323432,
        "1day.excess_return_with_cost.information_ratio": -0.0158474723279076,
        "1day.excess_return_with_cost.mean": -4.209816592223806e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Reversion' (LVSR) hypothesis. While the core concept of identifying 'hollow' price moves through the interaction of volatility and liquidity is theoretically sound, the current implementations failed to surpass the SOTA result. The LVSR_Factor_Reversion (the most complex formulation) and its derivatives (IAR, HVR) showed positive IC (0.005559) and IR (0.737157), but were unable to match the SOTA's risk-adjusted performance (IR 0.9725) and drawdown control. The results suggest that while the signal contains predictive power, the current mathematical formulations—particularly the denominator in the LVSR_Factor_Reversion—might be overly sensitive or noisy.",
        "hypothesis_evaluation": "The hypothesis that 'hollow' price extensions (high range, low liquidity) lead to reversion is partially supported by the positive Information Ratio and IC. However, the complexity of the LVSR_Factor_Reversion (using 5 base features and a multi-component denominator) may be introducing noise. The Institutional_Absorption_Ratio (IAR) attempted to simplify this using RANK, which is a good direction for robustness, but likely lost the specific 'structural' nuance of overnight gaps vs. intraday range. The deterioration in Max Drawdown compared to SOTA suggests the 'reversion' signal might be catching falling knives during high-regime volatility periods.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address two issues: complexity and signal-to-noise. The new hypothesis simplifies the 'Amihud' concept into a 'Range-to-Turnover' ratio, which is more stable. By using a 5-day smoothing for both the numerator (range) and denominator (volume/liquidity) before calculating the Z-score or ratio, we reduce the impact of single-day outliers. Furthermore, focusing on 'Turnover' (Volume/Shares Outstanding, or volume as a proxy) avoids the scale issues of the absolute price in the denominator of the original LVSR formulation. This iteration moves away from the complex overnight-return scaling which likely contributed to the higher drawdown."
      }
    },
    "62fbe950bb141008": {
      "factor_id": "62fbe950bb141008",
      "factor_name": "Institutional_Absorption_Ratio",
      "factor_expression": "RANK(($high - $low) / $close) / (RANK(TS_MEAN($volume, 5) / (TS_STD($close, 5) + 1e-8)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / $close) / (RANK(TS_MEAN($volume, 5) / (TS_STD($close, 5) + 1e-8)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the LVSR logic focusing on the ratio of price dispersion to institutional absorption. It measures the efficiency of price movement relative to volume and overnight sentiment. High values suggest price moves are unsupported by volume, leading to reversion.",
      "factor_formulation": "IAR = \\frac{\\text{RANK}((high - low) / close)}{\\text{RANK}(\\text{TS_MEAN}(volume, 5) / \\text{TS_STD}(close, 5))}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "c4dc78139b53",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Reversion' (LVSR) factor, defined as the product of the 20-day Z-scored intraday price range and the inverse of the 5-day average Amihud illiquidity scaled by the absolute overnight return, predicts short-term mean-reversion by identifying 'hollow' price extensions lacking institutional support.\n                Concise Observation: Parent 1 (ILE) captures exhaustion through price range but fails during strong trends; Parent 2 (Institutional Absorption) identifies quality of price moves but lacks a volatility trigger; combining them filters out high-conviction institutional breakouts.\n                Concise Justification: By scaling intraday volatility by the inverse of illiquidity, we isolate 'cheap' volatility—moves that occur on low relative impact—which are theoretically more prone to mean-reversion than 'expensive' moves backed by institutional liquidity.\n                Concise Knowledge: If extreme intraday price dispersion occurs alongside low institutional absorption (low volume-to-price-impact ratio and minimal overnight sentiment), the price move is likely a liquidity-driven vacuum rather than information-driven, leading to a higher probability of reversion.\n                concise Specification: The factor is calculated as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) multiplied by [1 / (MA(Abs(Return) / (Volume * Close), 5) * Abs(Open / Delay(Close, 1) - 1) + 1e-6)], targeting a 5-day reversion horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:13:06.736021"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1258935792347857,
        "ICIR": 0.0390560526366975,
        "1day.excess_return_without_cost.std": 0.0040971998383566,
        "1day.excess_return_with_cost.annualized_return": -0.0010019363489492,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001957757669479,
        "1day.excess_return_without_cost.annualized_return": 0.0465946325336084,
        "1day.excess_return_with_cost.std": 0.0040981858728818,
        "Rank IC": 0.0252550352437647,
        "IC": 0.0055592755095405,
        "1day.excess_return_without_cost.max_drawdown": -0.0904368977392056,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7371574611294541,
        "1day.pa": 0.0,
        "l2.valid": 0.9964368775156224,
        "Rank ICIR": 0.1811824002641607,
        "l2.train": 0.9938609610323432,
        "1day.excess_return_with_cost.information_ratio": -0.0158474723279076,
        "1day.excess_return_with_cost.mean": -4.209816592223806e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Reversion' (LVSR) hypothesis. While the core concept of identifying 'hollow' price moves through the interaction of volatility and liquidity is theoretically sound, the current implementations failed to surpass the SOTA result. The LVSR_Factor_Reversion (the most complex formulation) and its derivatives (IAR, HVR) showed positive IC (0.005559) and IR (0.737157), but were unable to match the SOTA's risk-adjusted performance (IR 0.9725) and drawdown control. The results suggest that while the signal contains predictive power, the current mathematical formulations—particularly the denominator in the LVSR_Factor_Reversion—might be overly sensitive or noisy.",
        "hypothesis_evaluation": "The hypothesis that 'hollow' price extensions (high range, low liquidity) lead to reversion is partially supported by the positive Information Ratio and IC. However, the complexity of the LVSR_Factor_Reversion (using 5 base features and a multi-component denominator) may be introducing noise. The Institutional_Absorption_Ratio (IAR) attempted to simplify this using RANK, which is a good direction for robustness, but likely lost the specific 'structural' nuance of overnight gaps vs. intraday range. The deterioration in Max Drawdown compared to SOTA suggests the 'reversion' signal might be catching falling knives during high-regime volatility periods.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address two issues: complexity and signal-to-noise. The new hypothesis simplifies the 'Amihud' concept into a 'Range-to-Turnover' ratio, which is more stable. By using a 5-day smoothing for both the numerator (range) and denominator (volume/liquidity) before calculating the Z-score or ratio, we reduce the impact of single-day outliers. Furthermore, focusing on 'Turnover' (Volume/Shares Outstanding, or volume as a proxy) avoids the scale issues of the absolute price in the denominator of the original LVSR formulation. This iteration moves away from the complex overnight-return scaling which likely contributed to the higher drawdown."
      }
    },
    "8e24b780310c5566": {
      "factor_id": "8e24b780310c5566",
      "factor_name": "Hollow_Vol_Reversion_5D",
      "factor_expression": "TS_ZSCORE(($high - $low) / ($close + 1e-8), 20) / (EMA(ABS($return) / ($volume + 1e-8), 5) + 1e-6)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 20) / (EMA(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Vol_Reversion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor isolates 'cheap' volatility by comparing the current intraday range to its 20-day history, normalized by the 5-day average volume-price impact. It targets short-term reversion when price range expands without a proportional increase in liquidity absorption.",
      "factor_formulation": "HVR = \\text{TS_ZSCORE}(\\frac{high - low}{close}, 20) / \\text{EMA}(\\frac{|return|}{volume + 1}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "c4dc78139b53",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "fb494dc84807"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Reversion' (LVSR) factor, defined as the product of the 20-day Z-scored intraday price range and the inverse of the 5-day average Amihud illiquidity scaled by the absolute overnight return, predicts short-term mean-reversion by identifying 'hollow' price extensions lacking institutional support.\n                Concise Observation: Parent 1 (ILE) captures exhaustion through price range but fails during strong trends; Parent 2 (Institutional Absorption) identifies quality of price moves but lacks a volatility trigger; combining them filters out high-conviction institutional breakouts.\n                Concise Justification: By scaling intraday volatility by the inverse of illiquidity, we isolate 'cheap' volatility—moves that occur on low relative impact—which are theoretically more prone to mean-reversion than 'expensive' moves backed by institutional liquidity.\n                Concise Knowledge: If extreme intraday price dispersion occurs alongside low institutional absorption (low volume-to-price-impact ratio and minimal overnight sentiment), the price move is likely a liquidity-driven vacuum rather than information-driven, leading to a higher probability of reversion.\n                concise Specification: The factor is calculated as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) multiplied by [1 / (MA(Abs(Return) / (Volume * Close), 5) * Abs(Open / Delay(Close, 1) - 1) + 1e-6)], targeting a 5-day reversion horizon.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:13:06.736021"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1258935792347857,
        "ICIR": 0.0390560526366975,
        "1day.excess_return_without_cost.std": 0.0040971998383566,
        "1day.excess_return_with_cost.annualized_return": -0.0010019363489492,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001957757669479,
        "1day.excess_return_without_cost.annualized_return": 0.0465946325336084,
        "1day.excess_return_with_cost.std": 0.0040981858728818,
        "Rank IC": 0.0252550352437647,
        "IC": 0.0055592755095405,
        "1day.excess_return_without_cost.max_drawdown": -0.0904368977392056,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7371574611294541,
        "1day.pa": 0.0,
        "l2.valid": 0.9964368775156224,
        "Rank ICIR": 0.1811824002641607,
        "l2.train": 0.9938609610323432,
        "1day.excess_return_with_cost.information_ratio": -0.0158474723279076,
        "1day.excess_return_with_cost.mean": -4.209816592223806e-06
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Reversion' (LVSR) hypothesis. While the core concept of identifying 'hollow' price moves through the interaction of volatility and liquidity is theoretically sound, the current implementations failed to surpass the SOTA result. The LVSR_Factor_Reversion (the most complex formulation) and its derivatives (IAR, HVR) showed positive IC (0.005559) and IR (0.737157), but were unable to match the SOTA's risk-adjusted performance (IR 0.9725) and drawdown control. The results suggest that while the signal contains predictive power, the current mathematical formulations—particularly the denominator in the LVSR_Factor_Reversion—might be overly sensitive or noisy.",
        "hypothesis_evaluation": "The hypothesis that 'hollow' price extensions (high range, low liquidity) lead to reversion is partially supported by the positive Information Ratio and IC. However, the complexity of the LVSR_Factor_Reversion (using 5 base features and a multi-component denominator) may be introducing noise. The Institutional_Absorption_Ratio (IAR) attempted to simplify this using RANK, which is a good direction for robustness, but likely lost the specific 'structural' nuance of overnight gaps vs. intraday range. The deterioration in Max Drawdown compared to SOTA suggests the 'reversion' signal might be catching falling knives during high-regime volatility periods.",
        "decision": false,
        "reason": "To improve upon the current results, we need to address two issues: complexity and signal-to-noise. The new hypothesis simplifies the 'Amihud' concept into a 'Range-to-Turnover' ratio, which is more stable. By using a 5-day smoothing for both the numerator (range) and denominator (volume/liquidity) before calculating the Z-score or ratio, we reduce the impact of single-day outliers. Furthermore, focusing on 'Turnover' (Volume/Shares Outstanding, or volume as a proxy) avoids the scale issues of the absolute price in the denominator of the original LVSR formulation. This iteration moves away from the complex overnight-return scaling which likely contributed to the higher drawdown."
      }
    },
    "9156b79da11cb040": {
      "factor_id": "9156b79da11cb040",
      "factor_name": "LVSF_Fragility_Index_10D_20D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"LVSF_Fragility_Index_10D_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Liquidity-Validated Structural Fragility (LVSF) factor identifies mean-reversion opportunities by detecting high-linearity trends that lack robust liquidity support. It multiplies the 10-day price-time R-squared (linearity) by the 20-day Z-score of the price-range-to-volume ratio (liquidity efficiency). High values indicate 'hollow' trends prone to reversal.",
      "factor_formulation": "LVSF = (TS\\_CORR(close, SEQUENCE(10), 10))^2 \\times TS\\_ZSCORE(\\frac{high - low}{volume + 1e-8}, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "0952efee0364",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Fragility' (LVSF) factor, defined as the product of a 10-day price-time R-squared and a 20-day Z-score of the (High-Low)/Volume ratio, identifies mean-reversion opportunities by detecting high-linearity trends that lack robust liquidity support.\n                Concise Observation: Parent 1 (ILE) captured short-term exhaustion via range/volume (RankIC 0.0285), while Parent 2 (SELV) captured structural persistence via R-squared (RankIC 0.0203); combining them addresses the weakness of betting against high-liquidity, healthy trends.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if this trend is accompanied by rising intraday volatility (High-Low range) without proportional volume growth, it suggests that the price movement is driven by liquidity gaps rather than fundamental accumulation, leading to a 'blow-off' peak.\n                Concise Knowledge: If a medium-term price trend exhibits high linearity (R-squared) while simultaneously showing an increase in intraday price dispersion relative to volume (low liquidity efficiency), the trend is likely fragile and prone to reversal; When price-time persistence is decoupled from volume-weighted stability, the 'hollow' structure indicates exhaustion.\n                concise Specification: Calculate the 10-day R-squared of daily close prices against a time index; calculate the 20-day Z-score of the ratio (High - Low) / Volume; the final LVSF factor is the product of these two components, targeting assets where both structural overextension and liquidity exhaustion are at local extremes.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:24:58.763798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1262829311016289,
        "ICIR": 0.0214204101678223,
        "1day.excess_return_without_cost.std": 0.0044488694946108,
        "1day.excess_return_with_cost.annualized_return": -0.0140947247653691,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000140852363116,
        "1day.excess_return_without_cost.annualized_return": 0.0335228624216313,
        "1day.excess_return_with_cost.std": 0.0044504771575725,
        "Rank IC": 0.0208517220959135,
        "IC": 0.0029561887460994,
        "1day.excess_return_without_cost.max_drawdown": -0.0855281777242486,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4884306962060896,
        "1day.pa": 0.0,
        "l2.valid": 0.9967925557348868,
        "Rank ICIR": 0.1572338270369559,
        "l2.train": 0.9935689265100556,
        "1day.excess_return_with_cost.information_ratio": -0.2052870456780081,
        "1day.excess_return_with_cost.mean": -5.922153262760143e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Fragility' (LVSF) hypothesis. While the theoretical framework of combining price linearity (R-squared/Slope) with liquidity efficiency (Range/Volume) is sound, the current implementations significantly underperformed compared to the SOTA result. The Information Ratio (0.488 vs 0.972) and IC (0.0029 vs 0.0057) are approximately 50% lower than the benchmark, suggesting that the current mathematical formulations are not capturing the alpha signal effectively or are suffering from noise in the liquidity component.",
        "hypothesis_evaluation": "The results partially refute the current specific implementations of the LVSF hypothesis. While the concept of 'hollow trends' is intuitive, the interaction between the 10-day linearity and the 20-day liquidity Z-score/Rank might be too restrictive or poorly timed. Specifically, using a Z-score of (High-Low)/Volume can be highly volatile; a single day of low volume can spike the ratio, leading to false signals. The decoupling of trend and liquidity is likely a more subtle regime-based signal rather than a simple multiplicative relationship.",
        "decision": false,
        "reason": "1. Stability: The current use of (High-Low)/Volume is prone to outliers. Using a ratio of Average True Range (ATR) to Median Volume over a 20-day period provides a more robust 'liquidity cost' baseline. 2. Divergence: A 'fragile' trend is best identified when the price is accelerating (increasing slope) while the liquidity required to sustain that move is thinning. 3. Complexity: The current factors use 4-5 base features; by simplifying the liquidity component to a ratio of ATR and Volume, we maintain a low ER (Base Feature Count) while improving signal-to-noise. 4. Normalization: Cross-sectional ranking of the components before combination (as seen in TLDF) showed potential but needs a more precise interaction term than simple addition."
      }
    },
    "ee456dc0ee93cc45": {
      "factor_id": "ee456dc0ee93cc45",
      "factor_name": "Structural_Exhaustion_V2",
      "factor_expression": "(REGBETA($close, SEQUENCE(10), 10) / (TS_STD($close, 10) + 1e-8)) * TS_RANK(($high - $low) / ($volume + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(REGBETA($close, SEQUENCE(10), 10) / (TS_STD($close, 10) + 1e-8)) * TS_RANK(($high - $low) / ($volume + 1e-8), 20)\" # Your output factor expression will be filled in here\n    name = \"Structural_Exhaustion_V2\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the LVSF hypothesis focusing on the decoupling of trend persistence and volume-weighted stability. It uses the 10-day price-time regression coefficient (slope) normalized by volatility, multiplied by the 20-day rank of the range-to-volume ratio to identify overextended, low-liquidity peaks.",
      "factor_formulation": "SEV2 = \\frac{REGBETA(close, SEQUENCE(10), 10)}{TS\\_STD(close, 10) + 1e-8} \\times TS\\_RANK(\\frac{high - low}{volume + 1e-8}, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "0952efee0364",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Fragility' (LVSF) factor, defined as the product of a 10-day price-time R-squared and a 20-day Z-score of the (High-Low)/Volume ratio, identifies mean-reversion opportunities by detecting high-linearity trends that lack robust liquidity support.\n                Concise Observation: Parent 1 (ILE) captured short-term exhaustion via range/volume (RankIC 0.0285), while Parent 2 (SELV) captured structural persistence via R-squared (RankIC 0.0203); combining them addresses the weakness of betting against high-liquidity, healthy trends.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if this trend is accompanied by rising intraday volatility (High-Low range) without proportional volume growth, it suggests that the price movement is driven by liquidity gaps rather than fundamental accumulation, leading to a 'blow-off' peak.\n                Concise Knowledge: If a medium-term price trend exhibits high linearity (R-squared) while simultaneously showing an increase in intraday price dispersion relative to volume (low liquidity efficiency), the trend is likely fragile and prone to reversal; When price-time persistence is decoupled from volume-weighted stability, the 'hollow' structure indicates exhaustion.\n                concise Specification: Calculate the 10-day R-squared of daily close prices against a time index; calculate the 20-day Z-score of the ratio (High - Low) / Volume; the final LVSF factor is the product of these two components, targeting assets where both structural overextension and liquidity exhaustion are at local extremes.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:24:58.763798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1262829311016289,
        "ICIR": 0.0214204101678223,
        "1day.excess_return_without_cost.std": 0.0044488694946108,
        "1day.excess_return_with_cost.annualized_return": -0.0140947247653691,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000140852363116,
        "1day.excess_return_without_cost.annualized_return": 0.0335228624216313,
        "1day.excess_return_with_cost.std": 0.0044504771575725,
        "Rank IC": 0.0208517220959135,
        "IC": 0.0029561887460994,
        "1day.excess_return_without_cost.max_drawdown": -0.0855281777242486,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4884306962060896,
        "1day.pa": 0.0,
        "l2.valid": 0.9967925557348868,
        "Rank ICIR": 0.1572338270369559,
        "l2.train": 0.9935689265100556,
        "1day.excess_return_with_cost.information_ratio": -0.2052870456780081,
        "1day.excess_return_with_cost.mean": -5.922153262760143e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Fragility' (LVSF) hypothesis. While the theoretical framework of combining price linearity (R-squared/Slope) with liquidity efficiency (Range/Volume) is sound, the current implementations significantly underperformed compared to the SOTA result. The Information Ratio (0.488 vs 0.972) and IC (0.0029 vs 0.0057) are approximately 50% lower than the benchmark, suggesting that the current mathematical formulations are not capturing the alpha signal effectively or are suffering from noise in the liquidity component.",
        "hypothesis_evaluation": "The results partially refute the current specific implementations of the LVSF hypothesis. While the concept of 'hollow trends' is intuitive, the interaction between the 10-day linearity and the 20-day liquidity Z-score/Rank might be too restrictive or poorly timed. Specifically, using a Z-score of (High-Low)/Volume can be highly volatile; a single day of low volume can spike the ratio, leading to false signals. The decoupling of trend and liquidity is likely a more subtle regime-based signal rather than a simple multiplicative relationship.",
        "decision": false,
        "reason": "1. Stability: The current use of (High-Low)/Volume is prone to outliers. Using a ratio of Average True Range (ATR) to Median Volume over a 20-day period provides a more robust 'liquidity cost' baseline. 2. Divergence: A 'fragile' trend is best identified when the price is accelerating (increasing slope) while the liquidity required to sustain that move is thinning. 3. Complexity: The current factors use 4-5 base features; by simplifying the liquidity component to a ratio of ATR and Volume, we maintain a low ER (Base Feature Count) while improving signal-to-noise. 4. Normalization: Cross-sectional ranking of the components before combination (as seen in TLDF) showed potential but needs a more precise interaction term than simple addition."
      }
    },
    "fc7c0070e2cf1381": {
      "factor_id": "fc7c0070e2cf1381",
      "factor_name": "Trend_Liquidity_Decoupling_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 20))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) + RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 20))\" # Your output factor expression will be filled in here\n    name = \"Trend_Liquidity_Decoupling_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the divergence between price trend linearity and liquidity efficiency. It identifies assets where the trend is becoming more 'perfect' (high R-squared) while the liquidity required to move the price is decreasing (high range per unit volume), signaling a fragile blow-off phase.",
      "factor_formulation": "TLDF = RANK(TS\\_CORR(close, SEQUENCE(10), 10)) + RANK(TS\\_MEAN(\\frac{high - low}{volume + 1e-8}, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "0952efee0364",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "18526bc7960c"
        ],
        "hypothesis": "Hypothesis: The 'Liquidity-Validated Structural Fragility' (LVSF) factor, defined as the product of a 10-day price-time R-squared and a 20-day Z-score of the (High-Low)/Volume ratio, identifies mean-reversion opportunities by detecting high-linearity trends that lack robust liquidity support.\n                Concise Observation: Parent 1 (ILE) captured short-term exhaustion via range/volume (RankIC 0.0285), while Parent 2 (SELV) captured structural persistence via R-squared (RankIC 0.0203); combining them addresses the weakness of betting against high-liquidity, healthy trends.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if this trend is accompanied by rising intraday volatility (High-Low range) without proportional volume growth, it suggests that the price movement is driven by liquidity gaps rather than fundamental accumulation, leading to a 'blow-off' peak.\n                Concise Knowledge: If a medium-term price trend exhibits high linearity (R-squared) while simultaneously showing an increase in intraday price dispersion relative to volume (low liquidity efficiency), the trend is likely fragile and prone to reversal; When price-time persistence is decoupled from volume-weighted stability, the 'hollow' structure indicates exhaustion.\n                concise Specification: Calculate the 10-day R-squared of daily close prices against a time index; calculate the 20-day Z-score of the ratio (High - Low) / Volume; the final LVSF factor is the product of these two components, targeting assets where both structural overextension and liquidity exhaustion are at local extremes.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:24:58.763798"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1262829311016289,
        "ICIR": 0.0214204101678223,
        "1day.excess_return_without_cost.std": 0.0044488694946108,
        "1day.excess_return_with_cost.annualized_return": -0.0140947247653691,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000140852363116,
        "1day.excess_return_without_cost.annualized_return": 0.0335228624216313,
        "1day.excess_return_with_cost.std": 0.0044504771575725,
        "Rank IC": 0.0208517220959135,
        "IC": 0.0029561887460994,
        "1day.excess_return_without_cost.max_drawdown": -0.0855281777242486,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4884306962060896,
        "1day.pa": 0.0,
        "l2.valid": 0.9967925557348868,
        "Rank ICIR": 0.1572338270369559,
        "l2.train": 0.9935689265100556,
        "1day.excess_return_with_cost.information_ratio": -0.2052870456780081,
        "1day.excess_return_with_cost.mean": -5.922153262760143e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Liquidity-Validated Structural Fragility' (LVSF) hypothesis. While the theoretical framework of combining price linearity (R-squared/Slope) with liquidity efficiency (Range/Volume) is sound, the current implementations significantly underperformed compared to the SOTA result. The Information Ratio (0.488 vs 0.972) and IC (0.0029 vs 0.0057) are approximately 50% lower than the benchmark, suggesting that the current mathematical formulations are not capturing the alpha signal effectively or are suffering from noise in the liquidity component.",
        "hypothesis_evaluation": "The results partially refute the current specific implementations of the LVSF hypothesis. While the concept of 'hollow trends' is intuitive, the interaction between the 10-day linearity and the 20-day liquidity Z-score/Rank might be too restrictive or poorly timed. Specifically, using a Z-score of (High-Low)/Volume can be highly volatile; a single day of low volume can spike the ratio, leading to false signals. The decoupling of trend and liquidity is likely a more subtle regime-based signal rather than a simple multiplicative relationship.",
        "decision": false,
        "reason": "1. Stability: The current use of (High-Low)/Volume is prone to outliers. Using a ratio of Average True Range (ATR) to Median Volume over a 20-day period provides a more robust 'liquidity cost' baseline. 2. Divergence: A 'fragile' trend is best identified when the price is accelerating (increasing slope) while the liquidity required to sustain that move is thinning. 3. Complexity: The current factors use 4-5 base features; by simplifying the liquidity component to a ratio of ATR and Volume, we maintain a low ER (Base Feature Count) while improving signal-to-noise. 4. Normalization: Cross-sectional ranking of the components before combination (as seen in TLDF) showed potential but needs a more precise interaction term than simple addition."
      }
    },
    "79b83c44455b6cbf": {
      "factor_id": "79b83c44455b6cbf",
      "factor_name": "SLVR_Mean_Reversion_Factor",
      "factor_expression": "TS_ZSCORE(($high - $low) / $close, 20) * REGRESI($close, $volume, 5) * (($open / DELAY($close, 1) - 1) / (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 20) * REGRESI($close, $volume, 5) * (($open / DELAY($close, 1) - 1) / (TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"SLVR_Mean_Reversion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Structural Liquidity Vacuum Reversion (SLVR) factor identifies mean-reversion opportunities by combining a 20-day Z-score of price dispersion with the residual of a 5-day price-volume regression, weighted by the ratio of the overnight gap to the Amihud illiquidity measure. This captures price exhaustion unsupported by volume and liquidity.",
      "factor_formulation": "\\text{TS\\_ZSCORE}(\\frac{\\text{high}-\\text{low}}{\\text{close}}, 20) \\times \\text{REGRESI}(\\text{close}, \\text{volume}, 5) \\times \\frac{(\\text{open}/\\text{DELAY}(\\text{close}, 1) - 1)}{\\text{TS\\_MEAN}(\\text{ABS}(\\text{return})/\\text{volume}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "59e57460e166",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversion (SLVR) factor identifies mean-reversion opportunities by combining a 20-day Z-score of price dispersion with the residual of a 5-day price-volume regression, further weighted by the ratio of overnight gap to the Amihud illiquidity measure.\n                Concise Observation: Parent strategies show that intraday volatility (ILE) and price-volume decoupling (LSSR) both capture exhaustion, but individual signals often suffer from false positives during high-conviction trends where volume actually supports the move.\n                Concise Justification: By multiplying the volatility exhaustion signal (Z-score of range) with a volume-based 'lack of support' residual, we filter out high-conviction trends; adding the overnight gap normalized by illiquidity captures the sentiment-liquidity mismatch necessary for a snap-back.\n                Concise Knowledge: If price dispersion significantly exceeds its historical norm while volume support (regression residual) is lacking, then the price movement is likely noise-driven; when this coincides with an overnight sentiment gap that is disproportionate to the asset's liquidity, a sharp mean-reversion is expected.\n                concise Specification: Calculate the 20-day TS_ZSCORE of (High-Low)/Close; multiply by the residual of a 5-day linear regression of Close on Volume; then multiply by the 1-day overnight gap (Open/PrevClose - 1) divided by the 5-day average Amihud ratio (AbsReturn/Volume).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:31:35.343949"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1265687423718712,
        "ICIR": 0.0482339304091834,
        "1day.excess_return_without_cost.std": 0.0040529819320795,
        "1day.excess_return_with_cost.annualized_return": -0.0028430330893478,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001876002354567,
        "1day.excess_return_without_cost.annualized_return": 0.0446488560387137,
        "1day.excess_return_with_cost.std": 0.0040539879000024,
        "Rank IC": 0.0242647988977528,
        "IC": 0.0064672342129703,
        "1day.excess_return_without_cost.max_drawdown": -0.0884544431698634,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7140805269217989,
        "1day.pa": 0.0,
        "l2.valid": 0.996175390565952,
        "Rank ICIR": 0.1846047904711788,
        "l2.train": 0.9928822625621102,
        "1day.excess_return_with_cost.information_ratio": -0.0454580694406163,
        "1day.excess_return_with_cost.mean": -1.1945517182133794e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the Structural Liquidity Vacuum Reversion (SLVR) framework. The 'SLVR_Mean_Reversion_Factor' provides the most comprehensive implementation of the hypothesis, while the others explore simplified components. The results show a significant improvement in the Information Coefficient (IC) compared to the SOTA (0.006467 vs 0.005798), indicating a stronger linear relationship between the factor and future returns. However, the annualized return and Information Ratio (IR) have deteriorated, and the drawdown has increased. This suggests that while the core signal (IC) is stronger, the current construction might be introducing noise or volatility that degrades risk-adjusted performance.",
        "hypothesis_evaluation": "The hypothesis that a 'Liquidity Vacuum' (price moves unsupported by volume) leads to mean reversion is supported by the improved IC. However, the full SLVR formulation appears overly complex, potentially leading to the observed decay in IR and drawdown. The interaction between the Amihud illiquidity measure and the overnight gap in the denominator of the SLVR factor might be creating extreme values (outliers) that destabilize the portfolio construction.",
        "decision": false,
        "reason": "The current SLVR factor uses a raw ratio of (Gap / Amihud Illiquidity), which can be extremely volatile when volume is very low (the 'vacuum' effect). By applying a cross-sectional RANK to the residual and the gap components separately before multiplication, we can capture the same theoretical 'mismatch' without the instability of raw ratios. Furthermore, reducing the look-back window for price dispersion to 10 days (as seen in the Volume_Decoupled_Dispersion variant) may capture faster mean-reversion cycles more effectively than the 20-day window."
      }
    },
    "f2dad72c3710ec2c": {
      "factor_id": "f2dad72c3710ec2c",
      "factor_name": "Liquidity_Mismatch_Exhaustion_Rank",
      "factor_expression": "RANK(REGRESI($close, $volume, 5)) * RANK(($open - DELAY($close, 1)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGRESI($close, $volume, 5)) * RANK(($open - DELAY($close, 1)) / (TS_STD(TS_PCTCHANGE($close, 1), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Mismatch_Exhaustion_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the SLVR hypothesis focusing on the cross-sectional rank of price-volume decoupling and liquidity-normalized gaps. It identifies assets where price moves are extreme relative to their volume support and liquidity profile.",
      "factor_formulation": "\\text{RANK}(\\text{REGRESI}(\\text{close}, \\text{volume}, 5)) \\times \\text{RANK}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS\\_STD}(\\text{return}, 20)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "59e57460e166",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversion (SLVR) factor identifies mean-reversion opportunities by combining a 20-day Z-score of price dispersion with the residual of a 5-day price-volume regression, further weighted by the ratio of overnight gap to the Amihud illiquidity measure.\n                Concise Observation: Parent strategies show that intraday volatility (ILE) and price-volume decoupling (LSSR) both capture exhaustion, but individual signals often suffer from false positives during high-conviction trends where volume actually supports the move.\n                Concise Justification: By multiplying the volatility exhaustion signal (Z-score of range) with a volume-based 'lack of support' residual, we filter out high-conviction trends; adding the overnight gap normalized by illiquidity captures the sentiment-liquidity mismatch necessary for a snap-back.\n                Concise Knowledge: If price dispersion significantly exceeds its historical norm while volume support (regression residual) is lacking, then the price movement is likely noise-driven; when this coincides with an overnight sentiment gap that is disproportionate to the asset's liquidity, a sharp mean-reversion is expected.\n                concise Specification: Calculate the 20-day TS_ZSCORE of (High-Low)/Close; multiply by the residual of a 5-day linear regression of Close on Volume; then multiply by the 1-day overnight gap (Open/PrevClose - 1) divided by the 5-day average Amihud ratio (AbsReturn/Volume).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:31:35.343949"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1265687423718712,
        "ICIR": 0.0482339304091834,
        "1day.excess_return_without_cost.std": 0.0040529819320795,
        "1day.excess_return_with_cost.annualized_return": -0.0028430330893478,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001876002354567,
        "1day.excess_return_without_cost.annualized_return": 0.0446488560387137,
        "1day.excess_return_with_cost.std": 0.0040539879000024,
        "Rank IC": 0.0242647988977528,
        "IC": 0.0064672342129703,
        "1day.excess_return_without_cost.max_drawdown": -0.0884544431698634,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7140805269217989,
        "1day.pa": 0.0,
        "l2.valid": 0.996175390565952,
        "Rank ICIR": 0.1846047904711788,
        "l2.train": 0.9928822625621102,
        "1day.excess_return_with_cost.information_ratio": -0.0454580694406163,
        "1day.excess_return_with_cost.mean": -1.1945517182133794e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the Structural Liquidity Vacuum Reversion (SLVR) framework. The 'SLVR_Mean_Reversion_Factor' provides the most comprehensive implementation of the hypothesis, while the others explore simplified components. The results show a significant improvement in the Information Coefficient (IC) compared to the SOTA (0.006467 vs 0.005798), indicating a stronger linear relationship between the factor and future returns. However, the annualized return and Information Ratio (IR) have deteriorated, and the drawdown has increased. This suggests that while the core signal (IC) is stronger, the current construction might be introducing noise or volatility that degrades risk-adjusted performance.",
        "hypothesis_evaluation": "The hypothesis that a 'Liquidity Vacuum' (price moves unsupported by volume) leads to mean reversion is supported by the improved IC. However, the full SLVR formulation appears overly complex, potentially leading to the observed decay in IR and drawdown. The interaction between the Amihud illiquidity measure and the overnight gap in the denominator of the SLVR factor might be creating extreme values (outliers) that destabilize the portfolio construction.",
        "decision": false,
        "reason": "The current SLVR factor uses a raw ratio of (Gap / Amihud Illiquidity), which can be extremely volatile when volume is very low (the 'vacuum' effect). By applying a cross-sectional RANK to the residual and the gap components separately before multiplication, we can capture the same theoretical 'mismatch' without the instability of raw ratios. Furthermore, reducing the look-back window for price dispersion to 10 days (as seen in the Volume_Decoupled_Dispersion variant) may capture faster mean-reversion cycles more effectively than the 20-day window."
      }
    },
    "80c1ef6d4bbd149a": {
      "factor_id": "80c1ef6d4bbd149a",
      "factor_name": "Volume_Decoupled_Dispersion",
      "factor_expression": "TS_ZSCORE(($high - $low) / $close, 10) * SIGN(REGRESI($close, $volume, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 10) * SIGN(REGRESI($close, $volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Volume_Decoupled_Dispersion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the interaction between price dispersion (High-Low range) and the lack of volume support. It uses the residual of price-volume regression to weight the current volatility state, highlighting noise-driven price spikes.",
      "factor_formulation": "\\text{TS\\_ZSCORE}((\\text{high}-\\text{low})/\\text{close}, 10) \\times \\text{SIGN}(\\text{REGRESI}(\\text{close}, \\text{volume}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "59e57460e166",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "9f76eaf1aee4"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity Vacuum Reversion (SLVR) factor identifies mean-reversion opportunities by combining a 20-day Z-score of price dispersion with the residual of a 5-day price-volume regression, further weighted by the ratio of overnight gap to the Amihud illiquidity measure.\n                Concise Observation: Parent strategies show that intraday volatility (ILE) and price-volume decoupling (LSSR) both capture exhaustion, but individual signals often suffer from false positives during high-conviction trends where volume actually supports the move.\n                Concise Justification: By multiplying the volatility exhaustion signal (Z-score of range) with a volume-based 'lack of support' residual, we filter out high-conviction trends; adding the overnight gap normalized by illiquidity captures the sentiment-liquidity mismatch necessary for a snap-back.\n                Concise Knowledge: If price dispersion significantly exceeds its historical norm while volume support (regression residual) is lacking, then the price movement is likely noise-driven; when this coincides with an overnight sentiment gap that is disproportionate to the asset's liquidity, a sharp mean-reversion is expected.\n                concise Specification: Calculate the 20-day TS_ZSCORE of (High-Low)/Close; multiply by the residual of a 5-day linear regression of Close on Volume; then multiply by the 1-day overnight gap (Open/PrevClose - 1) divided by the 5-day average Amihud ratio (AbsReturn/Volume).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:31:35.343949"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1265687423718712,
        "ICIR": 0.0482339304091834,
        "1day.excess_return_without_cost.std": 0.0040529819320795,
        "1day.excess_return_with_cost.annualized_return": -0.0028430330893478,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001876002354567,
        "1day.excess_return_without_cost.annualized_return": 0.0446488560387137,
        "1day.excess_return_with_cost.std": 0.0040539879000024,
        "Rank IC": 0.0242647988977528,
        "IC": 0.0064672342129703,
        "1day.excess_return_without_cost.max_drawdown": -0.0884544431698634,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7140805269217989,
        "1day.pa": 0.0,
        "l2.valid": 0.996175390565952,
        "Rank ICIR": 0.1846047904711788,
        "l2.train": 0.9928822625621102,
        "1day.excess_return_with_cost.information_ratio": -0.0454580694406163,
        "1day.excess_return_with_cost.mean": -1.1945517182133794e-05
      },
      "feedback": {
        "observations": "The current experiment tested three variations of the Structural Liquidity Vacuum Reversion (SLVR) framework. The 'SLVR_Mean_Reversion_Factor' provides the most comprehensive implementation of the hypothesis, while the others explore simplified components. The results show a significant improvement in the Information Coefficient (IC) compared to the SOTA (0.006467 vs 0.005798), indicating a stronger linear relationship between the factor and future returns. However, the annualized return and Information Ratio (IR) have deteriorated, and the drawdown has increased. This suggests that while the core signal (IC) is stronger, the current construction might be introducing noise or volatility that degrades risk-adjusted performance.",
        "hypothesis_evaluation": "The hypothesis that a 'Liquidity Vacuum' (price moves unsupported by volume) leads to mean reversion is supported by the improved IC. However, the full SLVR formulation appears overly complex, potentially leading to the observed decay in IR and drawdown. The interaction between the Amihud illiquidity measure and the overnight gap in the denominator of the SLVR factor might be creating extreme values (outliers) that destabilize the portfolio construction.",
        "decision": false,
        "reason": "The current SLVR factor uses a raw ratio of (Gap / Amihud Illiquidity), which can be extremely volatile when volume is very low (the 'vacuum' effect). By applying a cross-sectional RANK to the residual and the gap components separately before multiplication, we can capture the same theoretical 'mismatch' without the instability of raw ratios. Furthermore, reducing the look-back window for price dispersion to 10 days (as seen in the Volume_Decoupled_Dispersion variant) may capture faster mean-reversion cycles more effectively than the 20-day window."
      }
    },
    "d99cd6ff03752ce7": {
      "factor_id": "d99cd6ff03752ce7",
      "factor_name": "LSEF_Fragility_Reversal_20D",
      "factor_expression": "TS_ZSCORE(($high - $low) / $close, 20) * (TS_MEAN(ABS($return) / ($volume * $close + 1e-8), 5) / (ABS($open / (DELAY($close, 1) + 1e-8) - 1) + 1e-6))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($high - $low) / $close, 20) * (TS_MEAN(ABS($close / DELAY($close, 1) - 1) / ($volume * $close + 1e-8), 5) / (ABS($open / (DELAY($close, 1) + 1e-8) - 1) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"LSEF_Fragility_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies 'hollow' price extensions by combining a Z-scored intraday range (exhaustion) with an illiquidity-to-gap ratio (fragility). It targets stocks where large intraday moves occur without institutional volume support and lack overnight gap conviction, signaling a high probability of mean reversion.",
      "factor_formulation": "LSEF = \\text{TS_ZSCORE}(\\frac{high - low}{close}, 20) \\times \\frac{\\text{TS_MEAN}(\\frac{|return|}{volume \\times close}, 5)}{|\\frac{open}{delay(close, 1)} - 1| + 1e-6}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "8c49999739ed",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The Liquidity-Synchronized Exhaustion & Fragility (LSEF) factor, formulated as the product of the 20-day Z-scored intraday range and the 5-day average Amihud illiquidity divided by the absolute overnight gap, identifies high-probability mean-reversion candidates by isolating 'hollow' price extensions that lack institutional liquidity support.\n                Concise Observation: Parent 1 (ILE) captures price exhaustion but suffers from noise in high-liquidity breakouts, while Parent 2 (LGSF) identifies structural fragility but lacks a trigger; combining them targets the intersection of price stretch and liquidity vacuum.\n                Concise Justification: By multiplying price dispersion (exhaustion) with an illiquidity-to-gap ratio (fragility), the factor amplifies signals where price moves are most disconnected from fundamental volume and sentiment, maximizing the probability of a corrective reversal.\n                Concise Knowledge: If a significant intraday price extension occurs with high Amihud illiquidity and a narrow overnight gap, it indicates a lack of structural conviction; such 'hollow' moves are more likely to mean-revert than high-volume, gap-supported breakouts.\n                concise Specification: The factor is defined as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) * (MA(Abs(Return) / (Volume * Close), 5) / (Abs(Open / Close_prev - 1) + 1e-6)), focusing on the top decile of the composite score for short-term reversal prediction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:35:04.829976"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072142662673837,
        "ICIR": 0.0422716403544326,
        "1day.excess_return_without_cost.std": 0.0045254165564265,
        "1day.excess_return_with_cost.annualized_return": 0.0458483829092523,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003919966020444,
        "1day.excess_return_without_cost.annualized_return": 0.0932951912865809,
        "1day.excess_return_with_cost.std": 0.0045266338671047,
        "Rank IC": 0.0259373863042807,
        "IC": 0.0060125371661244,
        "1day.excess_return_without_cost.max_drawdown": -0.0958714273116896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3363253885566175,
        "1day.pa": 0.0,
        "l2.valid": 0.9964040722033288,
        "Rank ICIR": 0.1840490634323747,
        "l2.train": 0.9933380235065068,
        "1day.excess_return_with_cost.information_ratio": 0.6565384652952106,
        "1day.excess_return_with_cost.mean": 0.0001926402643245
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Liquidity-Synchronized Exhaustion & Fragility (LSEF) framework. The primary factor, 'LSEF_Fragility_Reversal_20D', demonstrated superior performance compared to the previous SOTA, particularly in Information Ratio (1.336 vs 0.972) and Annualized Return (0.093 vs 0.052). The IC also showed a marginal improvement. However, the Max Drawdown increased slightly (-0.095 vs -0.072), suggesting that while the 'hollow' price extension signal is more predictive, it may introduce higher tail risk or volatility in specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday exhaustion (Z-scored range) with liquidity fragility (Amihud illiquidity/gap ratio) identifies mean-reversion opportunities. The 'LSEF_Fragility_Reversal_20D' factor, which uses the most comprehensive implementation of the theory, outperformed the simplified 'Hollow_Extension_Index_15D' and the cross-sectional 'CSLE'. This suggests that the interaction between time-series exhaustion and liquidity constraints is a more robust signal than simple ranking or raw illiquidity.",
        "decision": true,
        "reason": "While the current LSEF factor is effective, the increase in Max Drawdown suggests it might misidentify high-volume institutional breakouts as 'hollow' extensions. By adjusting the illiquidity measure by recent volatility (e.g., Amihud / TS_STD) and ensuring the volume isn't part of a sustained trend (volume decay), we can better isolate true exhaustion. Additionally, the current formula uses 5 base features ($high, $low, $close, $open, $volume), which is close to the complexity limit; further refinement should focus on mathematical elegance rather than adding more raw data inputs."
      }
    },
    "3c749a4c8d25398c": {
      "factor_id": "3c749a4c8d25398c",
      "factor_name": "Hollow_Extension_Index_15D",
      "factor_expression": "TS_RANK(($high - $low) / $close, 15) * (ABS($return) / ($volume * $close + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(($high - $low) / $close, 15) * (ABS(TS_PCTCHANGE($close, 1)) / ($volume * $close + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Hollow_Extension_Index_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the Liquidity-Synchronized Exhaustion factor. it measures the ratio of the current intraday range relative to its 15-day history, scaled by the Amihud illiquidity measure. High values indicate price stretches on low liquidity, suggesting fragility.",
      "factor_formulation": "HEI = \\text{TS_RANK}(\\frac{high - low}{close}, 15) \\times \\frac{ABS(return)}{volume \\times close + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "8c49999739ed",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The Liquidity-Synchronized Exhaustion & Fragility (LSEF) factor, formulated as the product of the 20-day Z-scored intraday range and the 5-day average Amihud illiquidity divided by the absolute overnight gap, identifies high-probability mean-reversion candidates by isolating 'hollow' price extensions that lack institutional liquidity support.\n                Concise Observation: Parent 1 (ILE) captures price exhaustion but suffers from noise in high-liquidity breakouts, while Parent 2 (LGSF) identifies structural fragility but lacks a trigger; combining them targets the intersection of price stretch and liquidity vacuum.\n                Concise Justification: By multiplying price dispersion (exhaustion) with an illiquidity-to-gap ratio (fragility), the factor amplifies signals where price moves are most disconnected from fundamental volume and sentiment, maximizing the probability of a corrective reversal.\n                Concise Knowledge: If a significant intraday price extension occurs with high Amihud illiquidity and a narrow overnight gap, it indicates a lack of structural conviction; such 'hollow' moves are more likely to mean-revert than high-volume, gap-supported breakouts.\n                concise Specification: The factor is defined as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) * (MA(Abs(Return) / (Volume * Close), 5) / (Abs(Open / Close_prev - 1) + 1e-6)), focusing on the top decile of the composite score for short-term reversal prediction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:35:04.829976"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072142662673837,
        "ICIR": 0.0422716403544326,
        "1day.excess_return_without_cost.std": 0.0045254165564265,
        "1day.excess_return_with_cost.annualized_return": 0.0458483829092523,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003919966020444,
        "1day.excess_return_without_cost.annualized_return": 0.0932951912865809,
        "1day.excess_return_with_cost.std": 0.0045266338671047,
        "Rank IC": 0.0259373863042807,
        "IC": 0.0060125371661244,
        "1day.excess_return_without_cost.max_drawdown": -0.0958714273116896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3363253885566175,
        "1day.pa": 0.0,
        "l2.valid": 0.9964040722033288,
        "Rank ICIR": 0.1840490634323747,
        "l2.train": 0.9933380235065068,
        "1day.excess_return_with_cost.information_ratio": 0.6565384652952106,
        "1day.excess_return_with_cost.mean": 0.0001926402643245
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Liquidity-Synchronized Exhaustion & Fragility (LSEF) framework. The primary factor, 'LSEF_Fragility_Reversal_20D', demonstrated superior performance compared to the previous SOTA, particularly in Information Ratio (1.336 vs 0.972) and Annualized Return (0.093 vs 0.052). The IC also showed a marginal improvement. However, the Max Drawdown increased slightly (-0.095 vs -0.072), suggesting that while the 'hollow' price extension signal is more predictive, it may introduce higher tail risk or volatility in specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday exhaustion (Z-scored range) with liquidity fragility (Amihud illiquidity/gap ratio) identifies mean-reversion opportunities. The 'LSEF_Fragility_Reversal_20D' factor, which uses the most comprehensive implementation of the theory, outperformed the simplified 'Hollow_Extension_Index_15D' and the cross-sectional 'CSLE'. This suggests that the interaction between time-series exhaustion and liquidity constraints is a more robust signal than simple ranking or raw illiquidity.",
        "decision": true,
        "reason": "While the current LSEF factor is effective, the increase in Max Drawdown suggests it might misidentify high-volume institutional breakouts as 'hollow' extensions. By adjusting the illiquidity measure by recent volatility (e.g., Amihud / TS_STD) and ensuring the volume isn't part of a sustained trend (volume decay), we can better isolate true exhaustion. Additionally, the current formula uses 5 base features ($high, $low, $close, $open, $volume), which is close to the complexity limit; further refinement should focus on mathematical elegance rather than adding more raw data inputs."
      }
    },
    "94e72ccbbacad582": {
      "factor_id": "94e72ccbbacad582",
      "factor_name": "Cross_Sectional_Liquidity_Exhaustion",
      "factor_expression": "RANK(($high - $low) / (TS_STD($close, 10) + 1e-8)) * RANK(INV(ABS($open / (DELAY($close, 1) + 1e-8) - 1) + 1e-6))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_STD($close, 10) + 1e-8)) * RANK(INV(ABS($open / (DELAY($close, 1) + 1e-8) - 1) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Cross_Sectional_Liquidity_Exhaustion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor cross-sectionally ranks stocks based on their intraday volatility normalized by their overnight gap magnitude and volume. It seeks to find outliers that have moved significantly intraday but are 'fragile' due to low volume and narrow gaps relative to the market universe.",
      "factor_formulation": "CSLE = \\text{RANK}(\\frac{high - low}{TS\\_STD(close, 10)}) \\times \\text{RANK}(\\frac{1}{|open/delay(close, 1) - 1| + 1e-6})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "8c49999739ed",
        "parent_trajectory_ids": [
          "328dbeb0c242",
          "210cf87a55de"
        ],
        "hypothesis": "Hypothesis: The Liquidity-Synchronized Exhaustion & Fragility (LSEF) factor, formulated as the product of the 20-day Z-scored intraday range and the 5-day average Amihud illiquidity divided by the absolute overnight gap, identifies high-probability mean-reversion candidates by isolating 'hollow' price extensions that lack institutional liquidity support.\n                Concise Observation: Parent 1 (ILE) captures price exhaustion but suffers from noise in high-liquidity breakouts, while Parent 2 (LGSF) identifies structural fragility but lacks a trigger; combining them targets the intersection of price stretch and liquidity vacuum.\n                Concise Justification: By multiplying price dispersion (exhaustion) with an illiquidity-to-gap ratio (fragility), the factor amplifies signals where price moves are most disconnected from fundamental volume and sentiment, maximizing the probability of a corrective reversal.\n                Concise Knowledge: If a significant intraday price extension occurs with high Amihud illiquidity and a narrow overnight gap, it indicates a lack of structural conviction; such 'hollow' moves are more likely to mean-revert than high-volume, gap-supported breakouts.\n                concise Specification: The factor is defined as [(High - Low) / Close - MA((High - Low) / Close, 20)] / Std((High - Low) / Close, 20) * (MA(Abs(Return) / (Volume * Close), 5) / (Abs(Open / Close_prev - 1) + 1e-6)), focusing on the top decile of the composite score for short-term reversal prediction.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T10:35:04.829976"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072142662673837,
        "ICIR": 0.0422716403544326,
        "1day.excess_return_without_cost.std": 0.0045254165564265,
        "1day.excess_return_with_cost.annualized_return": 0.0458483829092523,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003919966020444,
        "1day.excess_return_without_cost.annualized_return": 0.0932951912865809,
        "1day.excess_return_with_cost.std": 0.0045266338671047,
        "Rank IC": 0.0259373863042807,
        "IC": 0.0060125371661244,
        "1day.excess_return_without_cost.max_drawdown": -0.0958714273116896,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.3363253885566175,
        "1day.pa": 0.0,
        "l2.valid": 0.9964040722033288,
        "Rank ICIR": 0.1840490634323747,
        "l2.train": 0.9933380235065068,
        "1day.excess_return_with_cost.information_ratio": 0.6565384652952106,
        "1day.excess_return_with_cost.mean": 0.0001926402643245
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Liquidity-Synchronized Exhaustion & Fragility (LSEF) framework. The primary factor, 'LSEF_Fragility_Reversal_20D', demonstrated superior performance compared to the previous SOTA, particularly in Information Ratio (1.336 vs 0.972) and Annualized Return (0.093 vs 0.052). The IC also showed a marginal improvement. However, the Max Drawdown increased slightly (-0.095 vs -0.072), suggesting that while the 'hollow' price extension signal is more predictive, it may introduce higher tail risk or volatility in specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining intraday exhaustion (Z-scored range) with liquidity fragility (Amihud illiquidity/gap ratio) identifies mean-reversion opportunities. The 'LSEF_Fragility_Reversal_20D' factor, which uses the most comprehensive implementation of the theory, outperformed the simplified 'Hollow_Extension_Index_15D' and the cross-sectional 'CSLE'. This suggests that the interaction between time-series exhaustion and liquidity constraints is a more robust signal than simple ranking or raw illiquidity.",
        "decision": true,
        "reason": "While the current LSEF factor is effective, the increase in Max Drawdown suggests it might misidentify high-volume institutional breakouts as 'hollow' extensions. By adjusting the illiquidity measure by recent volatility (e.g., Amihud / TS_STD) and ensuring the volume isn't part of a sustained trend (volume decay), we can better isolate true exhaustion. Additionally, the current formula uses 5 base features ($high, $low, $close, $open, $volume), which is close to the complexity limit; further refinement should focus on mathematical elegance rather than adding more raw data inputs."
      }
    },
    "7e8736acb6fd01b3": {
      "factor_id": "7e8736acb6fd01b3",
      "factor_name": "EVIB_Institutional_Breakout_5D",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) * INV(ABS(TS_ZSCORE($return, 5)) + 1) * ($volume / (TS_MEDIAN($volume, 20) + 1e-8)) * (TS_RANK(TS_STD($return, 15), 252) < 0.25 ? 1 : 0.1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) * INV(ABS(TS_SKEW(TS_PCTCHANGE($close, 1), 5)) + 1) * ($volume / TS_MEDIAN($volume, 20)) * (TS_RANK(TS_STD(TS_PCTCHANGE($close, 1), 15), 252) < 0.25 ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"EVIB_Institutional_Breakout_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional breakouts by combining overnight price gaps with liquidity exhaustion (low volume-weighted price skewness) and volatility compression. It scales the gap by the inverse of 5-day return skewness and relative turnover, filtered by low historical volatility.",
      "factor_formulation": "\\text{Gap} = \\frac{\\text{open}_t}{\\text{close}_{t-1}} - 1, \\quad \\text{EVIB} = \\text{Gap} \\times \\frac{1}{\\text{ABS}(\\text{TS\\_SKEW}(\\text{return}, 5)) + 1} \\times \\frac{\\text{volume}}{\\text{TS\\_MEDIAN}(\\text{volume}, 20)} \\times (\\text{TS\\_RANK}(\\text{TS\\_STD}(\\text{return}, 15), 252) < 0.25)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "ebfe41514a99",
        "parent_trajectory_ids": [
          "de18e34ed544",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Institutional Breakout' (EVIB) factor, defined as the product of a 15-day price volatility compression measure and a 5-day liquidity exhaustion skew, identifies high-alpha entries when an overnight price gap occurs following a period of retail volume depletion.\n                Concise Observation: Parent 1 successfully used volume-weighted skewness to find exhaustion points (RankIC 0.024), while Parent 2 identified that overnight gaps from low-volatility states signal institutional conviction (RankIC 0.023); combining them addresses the false-positive breakouts occurring in high-retail-activity environments.\n                Concise Justification: Institutional investors often accumulate during periods of low retail interest; by requiring both a volatility compression (Parent 2) and a liquidity exhaustion signal (Parent 1), we isolate the transition from retail-driven mean reversion to institutional-driven momentum.\n                Concise Knowledge: If a stock experiences a price gap after a period of low volatility and high volume skewness (liquidity exhaustion), it indicates an institutional 'hand-off' from retail sellers; when turnover is low relative to its 20-day median during this gap, the breakout is more likely to be sustainable due to the absence of retail noise.\n                concise Specification: The factor is calculated as the 1-day overnight gap ($open / $close[t-1] - 1) multiplied by the inverse of the 5-day volume-weighted price skewness, further scaled by the ratio of current turnover to its 20-day median, provided the 15-day standard deviation of returns is in the bottom quartile.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T11:26:32.206272"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1153064310351635,
        "ICIR": 0.0532393699022779,
        "1day.excess_return_without_cost.std": 0.0046290026694689,
        "1day.excess_return_with_cost.annualized_return": 0.025903155381319,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003055980717475,
        "1day.excess_return_without_cost.annualized_return": 0.0727323410759241,
        "1day.excess_return_with_cost.std": 0.0046299850554595,
        "Rank IC": 0.0286981642132419,
        "IC": 0.0080598492546855,
        "1day.excess_return_without_cost.max_drawdown": -0.1055193428945952,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.018478010804184,
        "1day.pa": 0.0,
        "l2.valid": 0.9966245869172796,
        "Rank ICIR": 0.1986200325705366,
        "l2.train": 0.994278442406578,
        "1day.excess_return_with_cost.information_ratio": 0.362647429069398,
        "1day.excess_return_with_cost.mean": 0.0001088367873164
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Institutional Breakout' (EVIB) hypothesis. The current results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.02, and the Annualized Return rose from 5.2% to 7.27%. The Information Coefficient (IC) also saw a healthy jump from 0.0058 to 0.0081. However, the Max Drawdown deepened from -0.072 to -0.105, suggesting that while the signal is stronger, it may introduce higher tail risk or sensitivity to specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight price gaps with volatility compression and liquidity exhaustion (low skewness/volume depletion) captures alpha. The 'EVIB_Institutional_Breakout_5D' implementation, which uses a binary filter for volatility rank and scales gaps by inverse skewness, appears to be the most effective driver. The interaction between price gaps and 'quiet' market states (low volatility/low skew) effectively filters out noise from retail-driven volatility.",
        "decision": true,
        "reason": "The current best factor uses a binary filter (TS_RANK < 0.25), which can create 'cliff effects' and ignore valuable information just outside the threshold. By shifting to a continuous efficiency ratio (e.g., (High-Low)/Volume) and incorporating a decay function on the liquidity exhaustion component, we can capture the 'quality' of the breakout more granularly. This should help mitigate the increased Max Drawdown observed in the current results by providing a smoother signal and better risk-weighting."
      }
    },
    "3f3fea20993f0d3b": {
      "factor_id": "3f3fea20993f0d3b",
      "factor_name": "Liquidity_Exhaustion_Gap_10D",
      "factor_expression": "RANK(($open / DELAY($close, 1)) - 1) * RANK(INV(TS_STD($return, 15) + 1e-8)) * RANK(TS_MEDIAN($volume, 20) / ($volume + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1)) - 1) * RANK(INV(TS_STD($close / DELAY($close, 1) - 1, 15) + 0.000001)) * RANK(TS_MEDIAN($volume, 20) / ($volume + 0.000001))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Simplified version of the EVIB hypothesis focusing on the interaction between overnight gaps and volume-weighted price stability. It identifies entries where price gaps occur during periods of low volatility relative to recent history, suggesting a shift from retail to institutional control.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}(\\frac{\\text{open}}{\\text{close}_{t-1}} - 1) \\times \\text{RANK}(\\frac{1}{\\text{TS\\_STD}(\\text{close}, 15)}) \\times \\text{RANK}(\\frac{\\text{TS\\_MEDIAN}(\\text{volume}, 20)}{\\text{volume}})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "ebfe41514a99",
        "parent_trajectory_ids": [
          "de18e34ed544",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Institutional Breakout' (EVIB) factor, defined as the product of a 15-day price volatility compression measure and a 5-day liquidity exhaustion skew, identifies high-alpha entries when an overnight price gap occurs following a period of retail volume depletion.\n                Concise Observation: Parent 1 successfully used volume-weighted skewness to find exhaustion points (RankIC 0.024), while Parent 2 identified that overnight gaps from low-volatility states signal institutional conviction (RankIC 0.023); combining them addresses the false-positive breakouts occurring in high-retail-activity environments.\n                Concise Justification: Institutional investors often accumulate during periods of low retail interest; by requiring both a volatility compression (Parent 2) and a liquidity exhaustion signal (Parent 1), we isolate the transition from retail-driven mean reversion to institutional-driven momentum.\n                Concise Knowledge: If a stock experiences a price gap after a period of low volatility and high volume skewness (liquidity exhaustion), it indicates an institutional 'hand-off' from retail sellers; when turnover is low relative to its 20-day median during this gap, the breakout is more likely to be sustainable due to the absence of retail noise.\n                concise Specification: The factor is calculated as the 1-day overnight gap ($open / $close[t-1] - 1) multiplied by the inverse of the 5-day volume-weighted price skewness, further scaled by the ratio of current turnover to its 20-day median, provided the 15-day standard deviation of returns is in the bottom quartile.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T11:26:32.206272"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1153064310351635,
        "ICIR": 0.0532393699022779,
        "1day.excess_return_without_cost.std": 0.0046290026694689,
        "1day.excess_return_with_cost.annualized_return": 0.025903155381319,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003055980717475,
        "1day.excess_return_without_cost.annualized_return": 0.0727323410759241,
        "1day.excess_return_with_cost.std": 0.0046299850554595,
        "Rank IC": 0.0286981642132419,
        "IC": 0.0080598492546855,
        "1day.excess_return_without_cost.max_drawdown": -0.1055193428945952,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.018478010804184,
        "1day.pa": 0.0,
        "l2.valid": 0.9966245869172796,
        "Rank ICIR": 0.1986200325705366,
        "l2.train": 0.994278442406578,
        "1day.excess_return_with_cost.information_ratio": 0.362647429069398,
        "1day.excess_return_with_cost.mean": 0.0001088367873164
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Institutional Breakout' (EVIB) hypothesis. The current results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.02, and the Annualized Return rose from 5.2% to 7.27%. The Information Coefficient (IC) also saw a healthy jump from 0.0058 to 0.0081. However, the Max Drawdown deepened from -0.072 to -0.105, suggesting that while the signal is stronger, it may introduce higher tail risk or sensitivity to specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight price gaps with volatility compression and liquidity exhaustion (low skewness/volume depletion) captures alpha. The 'EVIB_Institutional_Breakout_5D' implementation, which uses a binary filter for volatility rank and scales gaps by inverse skewness, appears to be the most effective driver. The interaction between price gaps and 'quiet' market states (low volatility/low skew) effectively filters out noise from retail-driven volatility.",
        "decision": true,
        "reason": "The current best factor uses a binary filter (TS_RANK < 0.25), which can create 'cliff effects' and ignore valuable information just outside the threshold. By shifting to a continuous efficiency ratio (e.g., (High-Low)/Volume) and incorporating a decay function on the liquidity exhaustion component, we can capture the 'quality' of the breakout more granularly. This should help mitigate the increased Max Drawdown observed in the current results by providing a smoother signal and better risk-weighting."
      }
    },
    "93168839dc70f19a": {
      "factor_id": "93168839dc70f19a",
      "factor_name": "Volatility_Compression_Skew_Factor",
      "factor_expression": "(($open / DELAY($close, 1)) - 1) / ( (TS_STD($return, 15) / (TS_MIN(TS_STD($return, 15), 60) + 1e-8)) + ABS(TS_ZSCORE($return, 5)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1)) - 1) / ((TS_STD(($close / DELAY($close, 1)) - 1, 15) / (TS_MIN(TS_STD(($close / DELAY($close, 1)) - 1, 15), 60) + 0.000001)) + ABS(TS_ZSCORE(($close / DELAY($close, 1)) - 1, 5)) + 0.000001)\" # Your output factor expression will be filled in here\n    name = \"Volatility_Compression_Skew_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets the 'institutional hand-off' by looking for price gaps that happen when 15-day volatility is at a local minimum and price skewness is low, indicating a lack of retail-driven directional extremes.",
      "factor_formulation": "\\text{Factor} = ((\\text{open} / \\text{close}_{t-1}) - 1) / (\\text{TS\\_STD}(\\text{return}, 15) / \\text{TS\\_MIN}(\\text{TS\\_STD}(\\text{return}, 15), 60) + \\text{ABS}(TS\\_ZSCORE(\\$return, 5)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "ebfe41514a99",
        "parent_trajectory_ids": [
          "de18e34ed544",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Validated Institutional Breakout' (EVIB) factor, defined as the product of a 15-day price volatility compression measure and a 5-day liquidity exhaustion skew, identifies high-alpha entries when an overnight price gap occurs following a period of retail volume depletion.\n                Concise Observation: Parent 1 successfully used volume-weighted skewness to find exhaustion points (RankIC 0.024), while Parent 2 identified that overnight gaps from low-volatility states signal institutional conviction (RankIC 0.023); combining them addresses the false-positive breakouts occurring in high-retail-activity environments.\n                Concise Justification: Institutional investors often accumulate during periods of low retail interest; by requiring both a volatility compression (Parent 2) and a liquidity exhaustion signal (Parent 1), we isolate the transition from retail-driven mean reversion to institutional-driven momentum.\n                Concise Knowledge: If a stock experiences a price gap after a period of low volatility and high volume skewness (liquidity exhaustion), it indicates an institutional 'hand-off' from retail sellers; when turnover is low relative to its 20-day median during this gap, the breakout is more likely to be sustainable due to the absence of retail noise.\n                concise Specification: The factor is calculated as the 1-day overnight gap ($open / $close[t-1] - 1) multiplied by the inverse of the 5-day volume-weighted price skewness, further scaled by the ratio of current turnover to its 20-day median, provided the 15-day standard deviation of returns is in the bottom quartile.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T11:26:32.206272"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1153064310351635,
        "ICIR": 0.0532393699022779,
        "1day.excess_return_without_cost.std": 0.0046290026694689,
        "1day.excess_return_with_cost.annualized_return": 0.025903155381319,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003055980717475,
        "1day.excess_return_without_cost.annualized_return": 0.0727323410759241,
        "1day.excess_return_with_cost.std": 0.0046299850554595,
        "Rank IC": 0.0286981642132419,
        "IC": 0.0080598492546855,
        "1day.excess_return_without_cost.max_drawdown": -0.1055193428945952,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.018478010804184,
        "1day.pa": 0.0,
        "l2.valid": 0.9966245869172796,
        "Rank ICIR": 0.1986200325705366,
        "l2.train": 0.994278442406578,
        "1day.excess_return_with_cost.information_ratio": 0.362647429069398,
        "1day.excess_return_with_cost.mean": 0.0001088367873164
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Exhaustion-Validated Institutional Breakout' (EVIB) hypothesis. The current results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.02, and the Annualized Return rose from 5.2% to 7.27%. The Information Coefficient (IC) also saw a healthy jump from 0.0058 to 0.0081. However, the Max Drawdown deepened from -0.072 to -0.105, suggesting that while the signal is stronger, it may introduce higher tail risk or sensitivity to specific market regimes.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining overnight price gaps with volatility compression and liquidity exhaustion (low skewness/volume depletion) captures alpha. The 'EVIB_Institutional_Breakout_5D' implementation, which uses a binary filter for volatility rank and scales gaps by inverse skewness, appears to be the most effective driver. The interaction between price gaps and 'quiet' market states (low volatility/low skew) effectively filters out noise from retail-driven volatility.",
        "decision": true,
        "reason": "The current best factor uses a binary filter (TS_RANK < 0.25), which can create 'cliff effects' and ignore valuable information just outside the threshold. By shifting to a continuous efficiency ratio (e.g., (High-Low)/Volume) and incorporating a decay function on the liquidity exhaustion component, we can capture the 'quality' of the breakout more granularly. This should help mitigate the increased Max Drawdown observed in the current results by providing a smoother signal and better risk-weighting."
      }
    },
    "77d8252b11666c8d": {
      "factor_id": "77d8252b11666c8d",
      "factor_name": "ETIB_Factor_15D",
      "factor_expression": "(1 / (TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 10) + 1e-8)) * ($open / DELAY($close, 1) - 1) * (1 / (TS_STD($return, 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(1 / (TS_MEAN(($high - $low) / (ABS($close - $open) + 1e-8), 10) + 1e-8)) * ($open / DELAY($close, 1) - 1) * (1 / (TS_STD(TS_PCTCHANGE($close, 1), 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ETIB_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Exhaustion-Triggered Institutional Breakout factor. It identifies institutional conviction by combining the inverse of intraday exhaustion (efficiency of price movement), the magnitude of the overnight gap, and the inverse of recent volatility compression. High values suggest a breakout from a liquidity-clearing phase.",
      "factor_formulation": "\\text{ETIB} = \\frac{1}{\\text{TS_MEAN}(\\frac{high - low}{\\text{ABS}(close - open) + 1e-8}, 10)} \\times \\left(\\frac{open}{\\text{DELAY}(close, 1)} - 1\\right) \\times \\frac{1}{\\text{TS_STD}(\\text{return}, 15) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "022fef225bae",
        "parent_trajectory_ids": [
          "a9d61694829a",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Triggered Institutional Breakout' (ETIB) factor, calculated as the product of the 10-day mean intraday range-to-volume efficiency and the overnight gap magnitude following a 15-day volatility compression, predicts positive returns by identifying institutional breakouts that resolve prior liquidity churn.\n                Concise Observation: Parent 1 identified that intraday exhaustion (high range, low efficiency) precedes reversals, while Parent 2 found that overnight gaps from compression states signal institutional conviction; combining them targets the specific moment 'churn' turns into 'trend'.\n                Concise Justification: High intraday ranges with low price displacement suggest a 'coiling' effect where supply and demand are fighting; an institutional gap-up provides the necessary directional catalyst to release this energy, leading to high-momentum breakouts with lower false-signal rates.\n                Concise Knowledge: If a stock exhibits high intraday price volatility without significant directional progress (exhaustion), it indicates a liquidity-clearing phase; when followed by an overnight gap breaking out of low-volatility compression, the subsequent trend is more robust due to the resolution of that prior churn.\n                concise Specification: Define 'Exhaustion' as the 10-day average of (High-Low)/(Close-Open absolute); define 'Compression' as the 15-day standard deviation of returns; define 'Gap' as (Open/Prev_Close - 1). The ETIB factor is (1 / Exhaustion) * Gap * (1 / Compression), focusing on the interaction between previous inefficiency and current breakout strength.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T11:28:58.519542"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current experiment attempted to implement the 'Exhaustion-Triggered Institutional Breakout' (ETIB) framework using two variations: a raw multiplicative form (ETIB_Factor_15D) and a cross-sectional rank-based additive form (Ranked_ETIB_Efficiency_15D). However, the results for these factors are missing (NaN) in the provided combined results table, while the SOTA result remains at an Information Ratio of 0.97 and Annualized Return of 5.2%. This suggests that while the factors were 'implemented' in code, they failed to generate valid signals or were not successfully evaluated against the benchmark in this specific run.",
        "hypothesis_evaluation": "The hypothesis that combining intraday efficiency, overnight gaps, and volatility compression can identify institutional breakouts remains unverified due to the lack of performance data (NaN). The mathematical formulation of ETIB_Factor_15D is potentially unstable because it uses a product of three distinct units (inverse exhaustion, gap percentage, and inverse volatility), which can lead to extreme outliers. The Ranked_ETIB_Efficiency_15D is a more robust approach to the hypothesis as it standardizes these disparate scales.",
        "decision": false,
        "reason": "The previous formulations likely suffered from scaling issues or noise in the 'exhaustion' component. By using volume-weighted gaps, we directly target 'institutional conviction' (high volume + price gap). Furthermore, replacing the complex triple-component rank with a more focused 'Gap / Volatility' ratio simplified by a 20-day window (instead of 15) provides better stability. Reducing the complexity of the 'efficiency' term will also address potential overfitting risks inherent in the original ETIB definition."
      }
    },
    "920243b4afb9af06": {
      "factor_id": "920243b4afb9af06",
      "factor_name": "Ranked_ETIB_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 10)) + RANK($open / DELAY($close, 1) - 1) - RANK(TS_STD($return, 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS($close - $open) / ($high - $low + 1e-8), 15)) + RANK($open / DELAY($close, 1) - 1) - RANK(TS_STD($close / DELAY($close, 1) - 1, 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_ETIB_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally robust version of the ETIB factor. It uses RANK to normalize the components: intraday efficiency (inverse of exhaustion), overnight gap magnitude, and volatility compression. This version focuses on the relative strength of the breakout signal across the universe.",
      "factor_formulation": "\\text{Ranked_ETIB} = \\text{RANK}(\\text{TS_MEAN}(\\frac{\\text{ABS}(close - open)}{high - low + 1e-8}, 10)) + \\text{RANK}(\\frac{open}{\\text{DELAY}(close, 1)} - 1) - \\text{RANK}(\\text{TS_STD}(return, 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 8,
        "evolution_phase": "crossover",
        "trajectory_id": "022fef225bae",
        "parent_trajectory_ids": [
          "a9d61694829a",
          "061e5ede53d0"
        ],
        "hypothesis": "Hypothesis: The 'Exhaustion-Triggered Institutional Breakout' (ETIB) factor, calculated as the product of the 10-day mean intraday range-to-volume efficiency and the overnight gap magnitude following a 15-day volatility compression, predicts positive returns by identifying institutional breakouts that resolve prior liquidity churn.\n                Concise Observation: Parent 1 identified that intraday exhaustion (high range, low efficiency) precedes reversals, while Parent 2 found that overnight gaps from compression states signal institutional conviction; combining them targets the specific moment 'churn' turns into 'trend'.\n                Concise Justification: High intraday ranges with low price displacement suggest a 'coiling' effect where supply and demand are fighting; an institutional gap-up provides the necessary directional catalyst to release this energy, leading to high-momentum breakouts with lower false-signal rates.\n                Concise Knowledge: If a stock exhibits high intraday price volatility without significant directional progress (exhaustion), it indicates a liquidity-clearing phase; when followed by an overnight gap breaking out of low-volatility compression, the subsequent trend is more robust due to the resolution of that prior churn.\n                concise Specification: Define 'Exhaustion' as the 10-day average of (High-Low)/(Close-Open absolute); define 'Compression' as the 15-day standard deviation of returns; define 'Gap' as (Open/Prev_Close - 1). The ETIB factor is (1 / Exhaustion) * Gap * (1 / Compression), focusing on the interaction between previous inefficiency and current breakout strength.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T11:28:58.519542"
      },
      "backtest_results": {},
      "feedback": {
        "observations": "The current experiment attempted to implement the 'Exhaustion-Triggered Institutional Breakout' (ETIB) framework using two variations: a raw multiplicative form (ETIB_Factor_15D) and a cross-sectional rank-based additive form (Ranked_ETIB_Efficiency_15D). However, the results for these factors are missing (NaN) in the provided combined results table, while the SOTA result remains at an Information Ratio of 0.97 and Annualized Return of 5.2%. This suggests that while the factors were 'implemented' in code, they failed to generate valid signals or were not successfully evaluated against the benchmark in this specific run.",
        "hypothesis_evaluation": "The hypothesis that combining intraday efficiency, overnight gaps, and volatility compression can identify institutional breakouts remains unverified due to the lack of performance data (NaN). The mathematical formulation of ETIB_Factor_15D is potentially unstable because it uses a product of three distinct units (inverse exhaustion, gap percentage, and inverse volatility), which can lead to extreme outliers. The Ranked_ETIB_Efficiency_15D is a more robust approach to the hypothesis as it standardizes these disparate scales.",
        "decision": false,
        "reason": "The previous formulations likely suffered from scaling issues or noise in the 'exhaustion' component. By using volume-weighted gaps, we directly target 'institutional conviction' (high volume + price gap). Furthermore, replacing the complex triple-component rank with a more focused 'Gap / Volatility' ratio simplified by a 20-day window (instead of 15) provides better stability. Reducing the complexity of the 'efficiency' term will also address potential overfitting risks inherent in the original ETIB definition."
      }
    },
    "0719633a92b12f68": {
      "factor_id": "0719633a92b12f68",
      "factor_name": "AID_Stealth_Accumulation_10D",
      "factor_expression": "(($high + $low + $close) / 3) / (($high + $low) / 2 + 1e-8) * (TS_MEAN($volume, 10) / ($volume + 1e-8)) * (($high - $low) < TS_MEAN($high - $low, 20) ? 1 : 0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($high + $low + $close) / 3) / (($high + $low) / 2 + 1e-8) * (TS_MEAN($volume, 10) / ($volume + 1e-8)) * (($high - $low) < TS_MEAN($high - $low, 20) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"AID_Stealth_Accumulation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Asymmetric Information Decay (AID) factor identifies institutional positioning by measuring the divergence between the typical price (VWAP proxy) and the median price. This divergence is scaled by the inverse of the volume trend and filtered for low-volatility regimes (intraday range below its 20-day average), signaling informed accumulation during quiet periods.",
      "factor_formulation": "AID = \\frac{(High + Low + Close) / 3}{(High + Low) / 2} \\times \\frac{TS\\_MEAN(volume, 10)}{volume} \\times ( (High - Low) < TS\\_MEAN(High - Low, 20) ? 1 : 0 )",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b2a1a5b73f18",
        "parent_trajectory_ids": [
          "7412ba9b2323"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Decay' (AID) factor identifies stealth institutional positioning by measuring the divergence between price-weighted and time-weighted averages during low-volume regimes, where a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation.\n                Concise Observation: The parent strategy (EVB) focused on high-volatility breakouts and gaps, which are often crowded retail signals, whereas market microstructure suggests that institutional 'stealth' orders often create subtle price-volume coupling during quiet periods that precedes major moves.\n                Concise Justification: Informed traders minimize market impact by splitting orders, causing the VWAP to deviate from the simple average price (TWAP proxy) even when the overall range is narrow, creating a 'quiet flow' that is orthogonal to high-volatility breakout signals.\n                Concise Knowledge: If price-weighted averages (VWAP) consistently exceed time-weighted averages (Median) during periods of low volume and low volatility, it indicates informed buyers are executing aggressively within a passive market; when this divergence occurs without price breakouts, it signals a high probability of future upward drift.\n                concise Specification: The AID factor is defined as the ratio of the daily (High+Low+Close)/3 to the (High+Low)/2, scaled by the inverse of the 10-day volume trend, specifically targeting days where the intraday range is below its 20-day moving average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T11:32:17.110619"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072093479093911,
        "ICIR": 0.037928943204933,
        "1day.excess_return_without_cost.std": 0.0042372806570693,
        "1day.excess_return_with_cost.annualized_return": 0.0071946987984656,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002275301706517,
        "1day.excess_return_without_cost.annualized_return": 0.0541521806151281,
        "1day.excess_return_with_cost.std": 0.0042369958631361,
        "Rank IC": 0.0231094315003661,
        "IC": 0.0052456320855065,
        "1day.excess_return_without_cost.max_drawdown": -0.0997414553065788,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.82840028674129,
        "1day.pa": 0.0,
        "l2.valid": 0.9964541965158707,
        "Rank ICIR": 0.1667716639028527,
        "l2.train": 0.9935006785059004,
        "1day.excess_return_with_cost.information_ratio": 0.1100692731748338,
        "1day.excess_return_with_cost.mean": 3.0229826884309665e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Asymmetric Information Decay' (AID) framework shows mixed results. While the annualized return (0.054152) has surpassed the previous SOTA (0.052010), the Information Ratio (IR) and Information Coefficient (IC) have slightly declined, and the Maximum Drawdown has deepened significantly (-0.099 vs -0.072). This suggests that while the current implementation captures higher magnitude returns, it does so with increased volatility and less consistency across the time series. The use of Z-scores and cross-sectional ranking in the current factors (AID_Z and AID_CS) likely contributed to the higher return but introduced more noise compared to simpler formulations.",
        "hypothesis_evaluation": "The hypothesis that a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation is partially supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the 'low-volume regime' filter might be too restrictive or binary (using 0/1 masks), leading to a loss of predictive signal in transition periods. The divergence between price-weighted and time-weighted averages remains a valid signal, but its interaction with volume requires a smoother mathematical representation than simple thresholding.",
        "decision": true,
        "reason": "The current binary filters (e.g., volume < mean) create sharp discontinuities that hurt the Information Ratio. By moving to a continuous interaction (e.g., dividing the price spread by a volume-volatility ratio), we can maintain the core 'Asymmetric Information' logic while improving the signal-to-noise ratio. Furthermore, reducing the reliance on complex Z-scores (which can be unstable in short windows) in favor of simple ratios will improve the factor's robustness and generalization, addressing the slight deterioration in IC."
      }
    },
    "754803e93cb75a39": {
      "factor_id": "754803e93cb75a39",
      "factor_name": "AID_CrossSectional_Informed_Flow",
      "factor_expression": "RANK(($close - ($high + $low) / 2) / ($high - $low + 1e-8)) * (TS_PCTCHANGE($volume, 5) < 0 ? 1 : 0)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high + $low + $close) / 3) - (($high + $low) / 2)) * (TS_PCTCHANGE($volume, 5) < 0 ? 1 : 0) * (($high - $low) < TS_MEAN($high - $low, 20) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"AID_CrossSectional_Informed_Flow\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the 'quiet flow' of informed traders by calculating the cross-sectional rank of the spread between price-weighted and time-weighted averages, specifically when the volume is decreasing relative to its recent past and volatility is low.",
      "factor_formulation": "AID\\_CS = RANK(\\frac{Close - (High + Low) / 2}{High - Low + 1e-8}) \\times (TS\\_PCTCHANGE(volume, 5) < 0 ? 1 : 0)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b2a1a5b73f18",
        "parent_trajectory_ids": [
          "7412ba9b2323"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Decay' (AID) factor identifies stealth institutional positioning by measuring the divergence between price-weighted and time-weighted averages during low-volume regimes, where a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation.\n                Concise Observation: The parent strategy (EVB) focused on high-volatility breakouts and gaps, which are often crowded retail signals, whereas market microstructure suggests that institutional 'stealth' orders often create subtle price-volume coupling during quiet periods that precedes major moves.\n                Concise Justification: Informed traders minimize market impact by splitting orders, causing the VWAP to deviate from the simple average price (TWAP proxy) even when the overall range is narrow, creating a 'quiet flow' that is orthogonal to high-volatility breakout signals.\n                Concise Knowledge: If price-weighted averages (VWAP) consistently exceed time-weighted averages (Median) during periods of low volume and low volatility, it indicates informed buyers are executing aggressively within a passive market; when this divergence occurs without price breakouts, it signals a high probability of future upward drift.\n                concise Specification: The AID factor is defined as the ratio of the daily (High+Low+Close)/3 to the (High+Low)/2, scaled by the inverse of the 10-day volume trend, specifically targeting days where the intraday range is below its 20-day moving average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T11:32:17.110619"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072093479093911,
        "ICIR": 0.037928943204933,
        "1day.excess_return_without_cost.std": 0.0042372806570693,
        "1day.excess_return_with_cost.annualized_return": 0.0071946987984656,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002275301706517,
        "1day.excess_return_without_cost.annualized_return": 0.0541521806151281,
        "1day.excess_return_with_cost.std": 0.0042369958631361,
        "Rank IC": 0.0231094315003661,
        "IC": 0.0052456320855065,
        "1day.excess_return_without_cost.max_drawdown": -0.0997414553065788,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.82840028674129,
        "1day.pa": 0.0,
        "l2.valid": 0.9964541965158707,
        "Rank ICIR": 0.1667716639028527,
        "l2.train": 0.9935006785059004,
        "1day.excess_return_with_cost.information_ratio": 0.1100692731748338,
        "1day.excess_return_with_cost.mean": 3.0229826884309665e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Asymmetric Information Decay' (AID) framework shows mixed results. While the annualized return (0.054152) has surpassed the previous SOTA (0.052010), the Information Ratio (IR) and Information Coefficient (IC) have slightly declined, and the Maximum Drawdown has deepened significantly (-0.099 vs -0.072). This suggests that while the current implementation captures higher magnitude returns, it does so with increased volatility and less consistency across the time series. The use of Z-scores and cross-sectional ranking in the current factors (AID_Z and AID_CS) likely contributed to the higher return but introduced more noise compared to simpler formulations.",
        "hypothesis_evaluation": "The hypothesis that a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation is partially supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the 'low-volume regime' filter might be too restrictive or binary (using 0/1 masks), leading to a loss of predictive signal in transition periods. The divergence between price-weighted and time-weighted averages remains a valid signal, but its interaction with volume requires a smoother mathematical representation than simple thresholding.",
        "decision": true,
        "reason": "The current binary filters (e.g., volume < mean) create sharp discontinuities that hurt the Information Ratio. By moving to a continuous interaction (e.g., dividing the price spread by a volume-volatility ratio), we can maintain the core 'Asymmetric Information' logic while improving the signal-to-noise ratio. Furthermore, reducing the reliance on complex Z-scores (which can be unstable in short windows) in favor of simple ratios will improve the factor's robustness and generalization, addressing the slight deterioration in IC."
      }
    },
    "c1d113524fc337ab": {
      "factor_id": "c1d113524fc337ab",
      "factor_name": "AID_Divergence_ZScore_20D",
      "factor_expression": "TS_ZSCORE((($high + $low + $close) / 3) / (($high + $low) / 2 + 1e-8), 20) / (TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE((($high + $low + $close) / 3) / (($high + $low) / 2 + 1e-8), 20) / (TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"AID_Divergence_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Measures the statistical significance of the divergence between the typical price and the median price using a 20-day Z-score, weighted by the inverse of volume volatility to emphasize periods of steady, low-impact institutional buying.",
      "factor_formulation": "AID\\_Z = TS\\_ZSCORE(\\frac{(High + Low + Close) / 3}{(High + Low) / 2}, 20) / TS\\_STD($volume / TS\\_MEAN($volume, 20), 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b2a1a5b73f18",
        "parent_trajectory_ids": [
          "7412ba9b2323"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Decay' (AID) factor identifies stealth institutional positioning by measuring the divergence between price-weighted and time-weighted averages during low-volume regimes, where a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation.\n                Concise Observation: The parent strategy (EVB) focused on high-volatility breakouts and gaps, which are often crowded retail signals, whereas market microstructure suggests that institutional 'stealth' orders often create subtle price-volume coupling during quiet periods that precedes major moves.\n                Concise Justification: Informed traders minimize market impact by splitting orders, causing the VWAP to deviate from the simple average price (TWAP proxy) even when the overall range is narrow, creating a 'quiet flow' that is orthogonal to high-volatility breakout signals.\n                Concise Knowledge: If price-weighted averages (VWAP) consistently exceed time-weighted averages (Median) during periods of low volume and low volatility, it indicates informed buyers are executing aggressively within a passive market; when this divergence occurs without price breakouts, it signals a high probability of future upward drift.\n                concise Specification: The AID factor is defined as the ratio of the daily (High+Low+Close)/3 to the (High+Low)/2, scaled by the inverse of the 10-day volume trend, specifically targeting days where the intraday range is below its 20-day moving average.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T11:32:17.110619"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1072093479093911,
        "ICIR": 0.037928943204933,
        "1day.excess_return_without_cost.std": 0.0042372806570693,
        "1day.excess_return_with_cost.annualized_return": 0.0071946987984656,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002275301706517,
        "1day.excess_return_without_cost.annualized_return": 0.0541521806151281,
        "1day.excess_return_with_cost.std": 0.0042369958631361,
        "Rank IC": 0.0231094315003661,
        "IC": 0.0052456320855065,
        "1day.excess_return_without_cost.max_drawdown": -0.0997414553065788,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.82840028674129,
        "1day.pa": 0.0,
        "l2.valid": 0.9964541965158707,
        "Rank ICIR": 0.1667716639028527,
        "l2.train": 0.9935006785059004,
        "1day.excess_return_with_cost.information_ratio": 0.1100692731748338,
        "1day.excess_return_with_cost.mean": 3.0229826884309665e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Asymmetric Information Decay' (AID) framework shows mixed results. While the annualized return (0.054152) has surpassed the previous SOTA (0.052010), the Information Ratio (IR) and Information Coefficient (IC) have slightly declined, and the Maximum Drawdown has deepened significantly (-0.099 vs -0.072). This suggests that while the current implementation captures higher magnitude returns, it does so with increased volatility and less consistency across the time series. The use of Z-scores and cross-sectional ranking in the current factors (AID_Z and AID_CS) likely contributed to the higher return but introduced more noise compared to simpler formulations.",
        "hypothesis_evaluation": "The hypothesis that a positive VWAP-to-Median-Price spread on declining volume signals informed accumulation is partially supported by the improvement in annualized returns. However, the drop in IC and IR suggests that the 'low-volume regime' filter might be too restrictive or binary (using 0/1 masks), leading to a loss of predictive signal in transition periods. The divergence between price-weighted and time-weighted averages remains a valid signal, but its interaction with volume requires a smoother mathematical representation than simple thresholding.",
        "decision": true,
        "reason": "The current binary filters (e.g., volume < mean) create sharp discontinuities that hurt the Information Ratio. By moving to a continuous interaction (e.g., dividing the price spread by a volume-volatility ratio), we can maintain the core 'Asymmetric Information' logic while improving the signal-to-noise ratio. Furthermore, reducing the reliance on complex Z-scores (which can be unstable in short windows) in favor of simple ratios will improve the factor's robustness and generalization, addressing the slight deterioration in IC."
      }
    },
    "0016abc35f0b7a77": {
      "factor_id": "0016abc35f0b7a77",
      "factor_name": "MSIA_Resonance_10D",
      "factor_expression": "RANK(TS_CORR($return, $volume, 10)) * (1.0 - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 10)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10)) * (1.0 - RANK(TS_MEAN(($high - $low) / ($close + 0.00001), 10)))\" # Your output factor expression will be filled in here\n    name = \"MSIA_Resonance_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies informed accumulation by combining low intraday price dispersion with high price-volume correlation. It targets stocks where price range is compressed relative to the close price (signaling low impact) while volume strongly supports the direction of price changes (signaling informed trading).",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 10)) * (1 - \\text{RANK}(\\text{TS\\_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{close}}, 10)))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "31b253f3f764",
        "parent_trajectory_ids": [
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Micro-Structural Information Asymmetry' (MSIA) factor identifies trend incubation by detecting periods where low intraday price dispersion (High-Low range) coincides with high volume-weighted price directionality, signaling informed accumulation before a volatility expansion.\n                Concise Observation: While the parent strategy (FES) successfully captured trend exhaustion via high dispersion and linearity, it failed to identify the quiet accumulation phases where volatility is compressed but volume-price resonance is high.\n                Concise Justification: Informed traders often minimize price impact during accumulation, leading to low intraday volatility (dispersion); however, their presence is revealed through a high correlation between price movement and volume (signed volume), distinguishing 'smart' accumulation from 'noisy' sideways trading.\n                Concise Knowledge: If a stock exhibits low price dispersion alongside high 'signed' volume concentration, it indicates institutional absorption of liquidity; when these conditions are met, the probability of a subsequent directional breakout increases as information asymmetry is resolved.\n                concise Specification: The factor is defined as the product of the inverse Rank of 10-day average intraday range (1/Rank(($high-$low)/$close)) and the 10-day correlation between price change and volume, specifically focusing on the bottom quartile of volatility and top quartile of volume-price resonance.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T11:38:36.498783"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0962934879318825,
        "ICIR": 0.0489811307563156,
        "1day.excess_return_without_cost.std": 0.0042583474903097,
        "1day.excess_return_with_cost.annualized_return": 0.0260412021184194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003056281209863,
        "1day.excess_return_without_cost.annualized_return": 0.07273949279475,
        "1day.excess_return_with_cost.std": 0.0042595346928909,
        "Rank IC": 0.0242970025498205,
        "IC": 0.0069688891293137,
        "1day.excess_return_without_cost.max_drawdown": -0.07674656553098,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1072372601378095,
        "1day.pa": 0.0,
        "l2.valid": 0.9965089813588252,
        "Rank ICIR": 0.1784864229840788,
        "l2.train": 0.9938712873526044,
        "1day.excess_return_with_cost.information_ratio": 0.3962875148571084,
        "1day.excess_return_with_cost.mean": 0.0001094168156236
      },
      "feedback": {
        "observations": "The current iteration of the 'Micro-Structural Information Asymmetry' (MSIA) framework has yielded significant performance gains. Specifically, the MSIA_Directional_Efficiency_10D factor (or the combined ensemble) has achieved an annualized return of 7.27% compared to the SOTA's 5.20%, and an Information Ratio (IR) of 1.11 compared to 0.97. The IC has also improved to 0.0069. While the maximum drawdown increased slightly (-0.076 vs -0.072), the risk-adjusted return profile is substantially stronger. The use of a ratio-based approach in MSIA_Directional_Efficiency_10D appears more effective at capturing the 'efficiency' of price movement than the additive Z-score or multiplicative Rank methods used in previous tasks.",
        "hypothesis_evaluation": "The results strongly support the MSIA hypothesis. The core idea—that low intraday dispersion coupled with high price-volume correlation signals informed accumulation—is validated by the improved IC and IR. The 'Efficiency' formulation (Correlation / Range) suggests that the relationship is non-linear and that the compression of the denominator (volatility) exponentially magnifies the signal of the numerator (informed volume directionality).",
        "decision": true,
        "reason": "While the current 10-day efficiency ratio is strong, it may be susceptible to short-term noise. By introducing a 'Stability' component (e.g., the inverse of the standard deviation of volume over the same period), we can filter for stocks where the accumulation is steady. Furthermore, replacing the simple price range with a 'Volatility-Adjusted Range' (Range / ATR) could normalize the factor across different market regimes, improving the Max Drawdown which slightly deteriorated in this run."
      }
    },
    "a0b9064d7871b56c": {
      "factor_id": "a0b9064d7871b56c",
      "factor_name": "MSIA_Accumulation_ZScore_20D",
      "factor_expression": "TS_ZSCORE(TS_CORR($return, $volume, 20), 20) - TS_ZSCORE(($high - $low) / ($close + 1e-8), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20), 20) - TS_ZSCORE(($high - $low) / ($close + 0.00000001), 20)\" # Your output factor expression will be filled in here\n    name = \"MSIA_Accumulation_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A refined version of the MSIA hypothesis using Z-scores to identify extreme divergence between price volatility and volume-price resonance. It captures the 'quiet accumulation' phase by looking for high directional volume intensity during periods of below-average price dispersion over a 20-day window.",
      "factor_formulation": "\\text{TS\\_ZSCORE}(\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 20), 20) - \\text{TS\\_ZSCORE}(\\frac{\\text{high} - \\text{low}}{\\text{close}}, 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "31b253f3f764",
        "parent_trajectory_ids": [
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Micro-Structural Information Asymmetry' (MSIA) factor identifies trend incubation by detecting periods where low intraday price dispersion (High-Low range) coincides with high volume-weighted price directionality, signaling informed accumulation before a volatility expansion.\n                Concise Observation: While the parent strategy (FES) successfully captured trend exhaustion via high dispersion and linearity, it failed to identify the quiet accumulation phases where volatility is compressed but volume-price resonance is high.\n                Concise Justification: Informed traders often minimize price impact during accumulation, leading to low intraday volatility (dispersion); however, their presence is revealed through a high correlation between price movement and volume (signed volume), distinguishing 'smart' accumulation from 'noisy' sideways trading.\n                Concise Knowledge: If a stock exhibits low price dispersion alongside high 'signed' volume concentration, it indicates institutional absorption of liquidity; when these conditions are met, the probability of a subsequent directional breakout increases as information asymmetry is resolved.\n                concise Specification: The factor is defined as the product of the inverse Rank of 10-day average intraday range (1/Rank(($high-$low)/$close)) and the 10-day correlation between price change and volume, specifically focusing on the bottom quartile of volatility and top quartile of volume-price resonance.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T11:38:36.498783"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0962934879318825,
        "ICIR": 0.0489811307563156,
        "1day.excess_return_without_cost.std": 0.0042583474903097,
        "1day.excess_return_with_cost.annualized_return": 0.0260412021184194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003056281209863,
        "1day.excess_return_without_cost.annualized_return": 0.07273949279475,
        "1day.excess_return_with_cost.std": 0.0042595346928909,
        "Rank IC": 0.0242970025498205,
        "IC": 0.0069688891293137,
        "1day.excess_return_without_cost.max_drawdown": -0.07674656553098,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1072372601378095,
        "1day.pa": 0.0,
        "l2.valid": 0.9965089813588252,
        "Rank ICIR": 0.1784864229840788,
        "l2.train": 0.9938712873526044,
        "1day.excess_return_with_cost.information_ratio": 0.3962875148571084,
        "1day.excess_return_with_cost.mean": 0.0001094168156236
      },
      "feedback": {
        "observations": "The current iteration of the 'Micro-Structural Information Asymmetry' (MSIA) framework has yielded significant performance gains. Specifically, the MSIA_Directional_Efficiency_10D factor (or the combined ensemble) has achieved an annualized return of 7.27% compared to the SOTA's 5.20%, and an Information Ratio (IR) of 1.11 compared to 0.97. The IC has also improved to 0.0069. While the maximum drawdown increased slightly (-0.076 vs -0.072), the risk-adjusted return profile is substantially stronger. The use of a ratio-based approach in MSIA_Directional_Efficiency_10D appears more effective at capturing the 'efficiency' of price movement than the additive Z-score or multiplicative Rank methods used in previous tasks.",
        "hypothesis_evaluation": "The results strongly support the MSIA hypothesis. The core idea—that low intraday dispersion coupled with high price-volume correlation signals informed accumulation—is validated by the improved IC and IR. The 'Efficiency' formulation (Correlation / Range) suggests that the relationship is non-linear and that the compression of the denominator (volatility) exponentially magnifies the signal of the numerator (informed volume directionality).",
        "decision": true,
        "reason": "While the current 10-day efficiency ratio is strong, it may be susceptible to short-term noise. By introducing a 'Stability' component (e.g., the inverse of the standard deviation of volume over the same period), we can filter for stocks where the accumulation is steady. Furthermore, replacing the simple price range with a 'Volatility-Adjusted Range' (Range / ATR) could normalize the factor across different market regimes, improving the Max Drawdown which slightly deteriorated in this run."
      }
    },
    "e09f77241280cb3a": {
      "factor_id": "e09f77241280cb3a",
      "factor_name": "MSIA_Directional_Efficiency_10D",
      "factor_expression": "TS_CORR($return, $volume, 10) / (TS_MEAN(($high - $low) / ($close + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), $volume, 10) / (TS_MEAN(($high - $low) / ($close + 0.000001), 10) + 0.000001)\" # Your output factor expression will be filled in here\n    name = \"MSIA_Directional_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures 'Micro-Structural Information Asymmetry' by calculating the ratio of price-volume resonance to the average intraday range. High values indicate that volume is efficiently driving price direction with minimal intraday volatility, a hallmark of institutional absorption.",
      "factor_formulation": "\\frac{\\text{TS\\_CORR}(\\text{return}, \\text{volume}, 10)}{\\text{TS\\_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{close}}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "31b253f3f764",
        "parent_trajectory_ids": [
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Micro-Structural Information Asymmetry' (MSIA) factor identifies trend incubation by detecting periods where low intraday price dispersion (High-Low range) coincides with high volume-weighted price directionality, signaling informed accumulation before a volatility expansion.\n                Concise Observation: While the parent strategy (FES) successfully captured trend exhaustion via high dispersion and linearity, it failed to identify the quiet accumulation phases where volatility is compressed but volume-price resonance is high.\n                Concise Justification: Informed traders often minimize price impact during accumulation, leading to low intraday volatility (dispersion); however, their presence is revealed through a high correlation between price movement and volume (signed volume), distinguishing 'smart' accumulation from 'noisy' sideways trading.\n                Concise Knowledge: If a stock exhibits low price dispersion alongside high 'signed' volume concentration, it indicates institutional absorption of liquidity; when these conditions are met, the probability of a subsequent directional breakout increases as information asymmetry is resolved.\n                concise Specification: The factor is defined as the product of the inverse Rank of 10-day average intraday range (1/Rank(($high-$low)/$close)) and the 10-day correlation between price change and volume, specifically focusing on the bottom quartile of volatility and top quartile of volume-price resonance.\n                ",
        "initial_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "planning_direction": "Examine 'Volatility Quality' by conditioning KLEN on WVMA5: high intraday range with low price-volume resonance may indicate noise, whereas high resonance suggests institutional participation.",
        "created_at": "2026-01-21T11:38:36.498783"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0962934879318825,
        "ICIR": 0.0489811307563156,
        "1day.excess_return_without_cost.std": 0.0042583474903097,
        "1day.excess_return_with_cost.annualized_return": 0.0260412021184194,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003056281209863,
        "1day.excess_return_without_cost.annualized_return": 0.07273949279475,
        "1day.excess_return_with_cost.std": 0.0042595346928909,
        "Rank IC": 0.0242970025498205,
        "IC": 0.0069688891293137,
        "1day.excess_return_without_cost.max_drawdown": -0.07674656553098,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1072372601378095,
        "1day.pa": 0.0,
        "l2.valid": 0.9965089813588252,
        "Rank ICIR": 0.1784864229840788,
        "l2.train": 0.9938712873526044,
        "1day.excess_return_with_cost.information_ratio": 0.3962875148571084,
        "1day.excess_return_with_cost.mean": 0.0001094168156236
      },
      "feedback": {
        "observations": "The current iteration of the 'Micro-Structural Information Asymmetry' (MSIA) framework has yielded significant performance gains. Specifically, the MSIA_Directional_Efficiency_10D factor (or the combined ensemble) has achieved an annualized return of 7.27% compared to the SOTA's 5.20%, and an Information Ratio (IR) of 1.11 compared to 0.97. The IC has also improved to 0.0069. While the maximum drawdown increased slightly (-0.076 vs -0.072), the risk-adjusted return profile is substantially stronger. The use of a ratio-based approach in MSIA_Directional_Efficiency_10D appears more effective at capturing the 'efficiency' of price movement than the additive Z-score or multiplicative Rank methods used in previous tasks.",
        "hypothesis_evaluation": "The results strongly support the MSIA hypothesis. The core idea—that low intraday dispersion coupled with high price-volume correlation signals informed accumulation—is validated by the improved IC and IR. The 'Efficiency' formulation (Correlation / Range) suggests that the relationship is non-linear and that the compression of the denominator (volatility) exponentially magnifies the signal of the numerator (informed volume directionality).",
        "decision": true,
        "reason": "While the current 10-day efficiency ratio is strong, it may be susceptible to short-term noise. By introducing a 'Stability' component (e.g., the inverse of the standard deviation of volume over the same period), we can filter for stocks where the accumulation is steady. Furthermore, replacing the simple price range with a 'Volatility-Adjusted Range' (Range / ATR) could normalize the factor across different market regimes, improving the Max Drawdown which slightly deteriorated in this run."
      }
    },
    "c46e82aee444859b": {
      "factor_id": "c46e82aee444859b",
      "factor_name": "Support_Integrity_V1_5D",
      "factor_expression": "RANK(($close - $low) / ($high - $low + 1e-8)) * RANK(INV(TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - $low) / ($high - $low + 1e-8)) * RANK(INV(TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Support_Integrity_V1_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies price floors by measuring the ratio of the lower shadow to the total intraday range, scaled by the inverse of volume volatility over 5 days. A high value suggests price rejection at lows with stable, passive liquidity absorption.",
      "factor_formulation": "\\text{RANK}\\left( \\frac{\\text{close} - \\text{low}}{\\text{high} - \\text{low} + 1e-8} \\right) \\times \\text{RANK}\\left( \\frac{1}{\\text{TS\\_STD}(\\text{volume}, 5) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "108c8be91b44",
        "parent_trajectory_ids": [
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor identifies price floors by detecting sessions where significant lower shadows (KLOW) occur alongside low volume volatility (VSTD5), signaling that selling pressure is being absorbed by passive liquidity rather than aggressive liquidation.\n                Concise Observation: The parent strategy (LVSB) focuses on aggressive morning breakouts, but ignores the stabilizing effect of end-of-day price defense where low volume dispersion indicates a 'quiet' absorption of supply.\n                Concise Justification: Passive accumulation often manifests as a price floor where the intraday low is significantly below the close, but the lack of volume spikes suggests that the 'smart money' is providing liquidity at a fixed price level without triggering market impact.\n                Concise Knowledge: If a price rejection (long lower shadow) occurs with low volume variance, it suggests a stable limit-order cluster; when volume volatility is high, the same price action likely represents chaotic exhaustion rather than structural support.\n                concise Specification: The factor is defined as the ratio of the lower shadow length (Close - Low) to the total range (High - Low), scaled by the inverse of the 5-day rolling standard deviation of volume, specifically targeting stocks with high price recovery and low volume churn.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T11:41:16.658732"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1188355009643111,
        "ICIR": 0.0327467094241051,
        "1day.excess_return_without_cost.std": 0.0043720287806785,
        "1day.excess_return_with_cost.annualized_return": 0.0182609563014136,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002758497695757,
        "1day.excess_return_without_cost.annualized_return": 0.0656522451590179,
        "1day.excess_return_with_cost.std": 0.0043728825790773,
        "Rank IC": 0.0180760768539602,
        "IC": 0.004264252181711,
        "1day.excess_return_without_cost.max_drawdown": -0.0883925864163692,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9733703025859328,
        "1day.pa": 0.0,
        "l2.valid": 0.9963619484215,
        "Rank ICIR": 0.1412951233012623,
        "l2.train": 0.9932769260318552,
        "1day.excess_return_with_cost.information_ratio": 0.2706868903097159,
        "1day.excess_return_with_cost.mean": 7.67267071487969e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Support Integrity' hypothesis, specifically exploring different ways to combine lower shadow magnitude with volume stability. The 'Stable_Floor_Detection_5D' and 'Support_Integrity_V1_5D' factors were implemented. The results show a significant improvement in Annualized Return (0.0656 vs 0.0520) and a slight improvement in the Information Ratio (0.973 vs 0.972). However, the IC (0.0042) is lower than the SOTA (0.0057), and the Max Drawdown has worsened (-0.088 vs -0.072), suggesting that while the new factors capture higher alpha, they introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The hypothesis that price floors can be identified by lower shadows coupled with low volume volatility is supported by the improvement in annualized returns. Specifically, the 'Stable_Floor_Detection_5D' factor's use of an exponential decay penalty for volume variance appears to be a robust way to model 'passive' absorption. However, the drop in IC suggests the signal might be sparse or noisy, and the increased drawdown indicates that these 'floors' may occasionally fail or represent 'falling knives' in high-volatility regimes.",
        "decision": true,
        "reason": "The current factors focus on single-day price action (lower shadows) and volume stability. By adding a condition that requires the asset to be locally oversold (e.g., price below a 20-day MA), we ensure the 'support' is being tested after a meaningful correction, which increases the probability of a reversal. This should help improve the IC and reduce the Max Drawdown by filtering out noise in neutral or bullish trends."
      }
    },
    "dafb1fa481643d04": {
      "factor_id": "dafb1fa481643d04",
      "factor_name": "Passive_Absorption_Ratio_10D",
      "factor_expression": "ZSCORE(($close - $low) / ((TS_STD($volume, 10) + 1e-8) * ($high - $low + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(($close - $low) / ((TS_STD($volume, 10) + 1e-8) * ($high - $low + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Passive_Absorption_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets stocks where price recovery from daily lows occurs under low volume dispersion. It uses a 10-day window for volume stability to ensure the 'quiet' nature of the support level, cross-sectionally ranked for comparability.",
      "factor_formulation": "\\text{ZSCORE}\\left( \\frac{\\text{close} - \\text{low}}{\\text{TS\\_STD}(\\text{volume}, 10) \\times (\\text{high} - \\text{low} + 1e-8)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "108c8be91b44",
        "parent_trajectory_ids": [
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor identifies price floors by detecting sessions where significant lower shadows (KLOW) occur alongside low volume volatility (VSTD5), signaling that selling pressure is being absorbed by passive liquidity rather than aggressive liquidation.\n                Concise Observation: The parent strategy (LVSB) focuses on aggressive morning breakouts, but ignores the stabilizing effect of end-of-day price defense where low volume dispersion indicates a 'quiet' absorption of supply.\n                Concise Justification: Passive accumulation often manifests as a price floor where the intraday low is significantly below the close, but the lack of volume spikes suggests that the 'smart money' is providing liquidity at a fixed price level without triggering market impact.\n                Concise Knowledge: If a price rejection (long lower shadow) occurs with low volume variance, it suggests a stable limit-order cluster; when volume volatility is high, the same price action likely represents chaotic exhaustion rather than structural support.\n                concise Specification: The factor is defined as the ratio of the lower shadow length (Close - Low) to the total range (High - Low), scaled by the inverse of the 5-day rolling standard deviation of volume, specifically targeting stocks with high price recovery and low volume churn.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T11:41:16.658732"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1188355009643111,
        "ICIR": 0.0327467094241051,
        "1day.excess_return_without_cost.std": 0.0043720287806785,
        "1day.excess_return_with_cost.annualized_return": 0.0182609563014136,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002758497695757,
        "1day.excess_return_without_cost.annualized_return": 0.0656522451590179,
        "1day.excess_return_with_cost.std": 0.0043728825790773,
        "Rank IC": 0.0180760768539602,
        "IC": 0.004264252181711,
        "1day.excess_return_without_cost.max_drawdown": -0.0883925864163692,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9733703025859328,
        "1day.pa": 0.0,
        "l2.valid": 0.9963619484215,
        "Rank ICIR": 0.1412951233012623,
        "l2.train": 0.9932769260318552,
        "1day.excess_return_with_cost.information_ratio": 0.2706868903097159,
        "1day.excess_return_with_cost.mean": 7.67267071487969e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Support Integrity' hypothesis, specifically exploring different ways to combine lower shadow magnitude with volume stability. The 'Stable_Floor_Detection_5D' and 'Support_Integrity_V1_5D' factors were implemented. The results show a significant improvement in Annualized Return (0.0656 vs 0.0520) and a slight improvement in the Information Ratio (0.973 vs 0.972). However, the IC (0.0042) is lower than the SOTA (0.0057), and the Max Drawdown has worsened (-0.088 vs -0.072), suggesting that while the new factors capture higher alpha, they introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The hypothesis that price floors can be identified by lower shadows coupled with low volume volatility is supported by the improvement in annualized returns. Specifically, the 'Stable_Floor_Detection_5D' factor's use of an exponential decay penalty for volume variance appears to be a robust way to model 'passive' absorption. However, the drop in IC suggests the signal might be sparse or noisy, and the increased drawdown indicates that these 'floors' may occasionally fail or represent 'falling knives' in high-volatility regimes.",
        "decision": true,
        "reason": "The current factors focus on single-day price action (lower shadows) and volume stability. By adding a condition that requires the asset to be locally oversold (e.g., price below a 20-day MA), we ensure the 'support' is being tested after a meaningful correction, which increases the probability of a reversal. This should help improve the IC and reduce the Max Drawdown by filtering out noise in neutral or bullish trends."
      }
    },
    "6b64853b19aac8e2": {
      "factor_id": "6b64853b19aac8e2",
      "factor_name": "Stable_Floor_Detection_5D",
      "factor_expression": "(($close - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) * EXP(-1 * TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($close - $low) / (TS_MEAN($high - $low, 5) + 1e-8)) * EXP(-1 * TS_STD($volume / (TS_MEAN($volume, 20) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"Stable_Floor_Detection_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Identifies structural support by combining the lower shadow magnitude with a penalty for high volume variance. It filters for sessions where the price rejection (lower shadow) is significant relative to recent volume churn.",
      "factor_formulation": "\\frac{\\text{close} - \\text{low}}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 5)} \\times \\exp\\left(-\\text{TS\\_STD}\\left(\\frac{\\text{volume}}{\\text{TS\\_MEAN}(\\text{volume}, 20)}, 5\\right)\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "108c8be91b44",
        "parent_trajectory_ids": [
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Support Integrity' factor identifies price floors by detecting sessions where significant lower shadows (KLOW) occur alongside low volume volatility (VSTD5), signaling that selling pressure is being absorbed by passive liquidity rather than aggressive liquidation.\n                Concise Observation: The parent strategy (LVSB) focuses on aggressive morning breakouts, but ignores the stabilizing effect of end-of-day price defense where low volume dispersion indicates a 'quiet' absorption of supply.\n                Concise Justification: Passive accumulation often manifests as a price floor where the intraday low is significantly below the close, but the lack of volume spikes suggests that the 'smart money' is providing liquidity at a fixed price level without triggering market impact.\n                Concise Knowledge: If a price rejection (long lower shadow) occurs with low volume variance, it suggests a stable limit-order cluster; when volume volatility is high, the same price action likely represents chaotic exhaustion rather than structural support.\n                concise Specification: The factor is defined as the ratio of the lower shadow length (Close - Low) to the total range (High - Low), scaled by the inverse of the 5-day rolling standard deviation of volume, specifically targeting stocks with high price recovery and low volume churn.\n                ",
        "initial_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "planning_direction": "Analyze 'Support Integrity' under stress by crossing KLOW with VSTD5: strong lower shadows accompanied by low volume volatility indicate stable accumulation at price floors.",
        "created_at": "2026-01-21T11:41:16.658732"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1188355009643111,
        "ICIR": 0.0327467094241051,
        "1day.excess_return_without_cost.std": 0.0043720287806785,
        "1day.excess_return_with_cost.annualized_return": 0.0182609563014136,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002758497695757,
        "1day.excess_return_without_cost.annualized_return": 0.0656522451590179,
        "1day.excess_return_with_cost.std": 0.0043728825790773,
        "Rank IC": 0.0180760768539602,
        "IC": 0.004264252181711,
        "1day.excess_return_without_cost.max_drawdown": -0.0883925864163692,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.9733703025859328,
        "1day.pa": 0.0,
        "l2.valid": 0.9963619484215,
        "Rank ICIR": 0.1412951233012623,
        "l2.train": 0.9932769260318552,
        "1day.excess_return_with_cost.information_ratio": 0.2706868903097159,
        "1day.excess_return_with_cost.mean": 7.67267071487969e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Support Integrity' hypothesis, specifically exploring different ways to combine lower shadow magnitude with volume stability. The 'Stable_Floor_Detection_5D' and 'Support_Integrity_V1_5D' factors were implemented. The results show a significant improvement in Annualized Return (0.0656 vs 0.0520) and a slight improvement in the Information Ratio (0.973 vs 0.972). However, the IC (0.0042) is lower than the SOTA (0.0057), and the Max Drawdown has worsened (-0.088 vs -0.072), suggesting that while the new factors capture higher alpha, they introduce higher volatility or tail risk.",
        "hypothesis_evaluation": "The hypothesis that price floors can be identified by lower shadows coupled with low volume volatility is supported by the improvement in annualized returns. Specifically, the 'Stable_Floor_Detection_5D' factor's use of an exponential decay penalty for volume variance appears to be a robust way to model 'passive' absorption. However, the drop in IC suggests the signal might be sparse or noisy, and the increased drawdown indicates that these 'floors' may occasionally fail or represent 'falling knives' in high-volatility regimes.",
        "decision": true,
        "reason": "The current factors focus on single-day price action (lower shadows) and volume stability. By adding a condition that requires the asset to be locally oversold (e.g., price below a 20-day MA), we ensure the 'support' is being tested after a meaningful correction, which increases the probability of a reversal. This should help improve the IC and reduce the Max Drawdown by filtering out noise in neutral or bullish trends."
      }
    },
    "54cfcee302450c9c": {
      "factor_id": "54cfcee302450c9c",
      "factor_name": "AIFP_Stealth_Momentum_20D",
      "factor_expression": "TS_CORR($return, DELAY($return, 1), 10) * (MEDIAN(TS_MEAN($volume, 20)) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close / DELAY($close, 1) - 1, DELAY($close / DELAY($close, 1) - 1, 1), 10) * (MEDIAN(TS_MEAN($volume, 20)) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"AIFP_Stealth_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies trend persistence by multiplying the 10-day lag-1 return autocorrelation by the inverse of the relative volume impact. High autocorrelation combined with low relative volume suggests informed traders are building positions 'quietly' to minimize market impact, leading to sustained medium-term trends.",
      "factor_formulation": "\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{return}, 1), 10) \\times \\left( \\frac{\\text{MEDIAN}(\\text{TS\\_MEAN}(\\text{volume}, 20))}{\\text{TS\\_MEAN}(\\text{volume}, 20) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "4edbcce4ab82",
        "parent_trajectory_ids": [
          "7754f9bf40e9"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Flow Persistence' (AIFP) factor predicts medium-term trend continuation by identifying assets where high return autocorrelation is sustained by low relative volume impact, suggesting stealthy informed positioning.\n                Concise Observation: The parent LVSR strategy focused on high-volatility mean reversion; however, market trends often persist when price moves are 'quiet' and exhibit high serial correlation without massive volume spikes.\n                Concise Justification: Informed investors often split orders to reduce slippage, causing price trends to exhibit high autocorrelation (signal) with low relative volume (low noise), creating a 'stealth' momentum effect.\n                Concise Knowledge: If return autocorrelation is high while the asset's volume share relative to its peers is declining, then the price move is likely driven by informed traders minimizing market impact, leading to trend persistence.\n                concise Specification: The factor is defined as the product of the 10-day lag-1 return autocorrelation and the inverse of the ratio between individual volume and the cross-sectional median volume, calculated over a 20-day window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T11:47:42.090807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1255277288344417,
        "ICIR": 0.030921509993652,
        "1day.excess_return_without_cost.std": 0.0040626009563249,
        "1day.excess_return_with_cost.annualized_return": 0.005023744007352,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002180673973566,
        "1day.excess_return_without_cost.annualized_return": 0.0519000405708872,
        "1day.excess_return_with_cost.std": 0.0040643656744735,
        "Rank IC": 0.0198411732141004,
        "IC": 0.0041111320130093,
        "1day.excess_return_without_cost.max_drawdown": -0.0823111775441301,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8280852565197517,
        "1day.pa": 0.0,
        "l2.valid": 0.9965156230262624,
        "Rank ICIR": 0.155082717561439,
        "l2.train": 0.9939156500916012,
        "1day.excess_return_with_cost.information_ratio": 0.0801209790789856,
        "1day.excess_return_with_cost.mean": 2.110816809811766e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Asymmetric Information Flow Persistence' (AIFP) hypothesis. While the core concept of combining return autocorrelation with volume-based 'stealth' metrics is theoretically sound, the current implementations failed to surpass the existing SOTA. The 'AIFP_Rank_Efficiency_15D' utilized cross-sectional ranking to normalize the signals, which is a robust approach, but the overall IC (0.0041) and Information Ratio (0.828) lagged behind the SOTA (IC 0.0058, IR 0.973). The 'AIFP_Volatility_Adjusted_Persistence' attempted to incorporate price volatility as a denominator, but the resulting metrics suggest that the interaction between volume and volatility might be too noisy or improperly scaled in its current linear form.",
        "hypothesis_evaluation": "The hypothesis that 'stealthy' informed positioning leads to trend continuation is partially supported by the positive IC and annualized return, but the current mathematical formulations are likely capturing too much noise. The inverse relationship with volume is a strong proxy for stealth, but using raw volume or simple averages (as seen in AIFP_Stealth_Momentum_20D) without proper normalization across different market regimes or sectors may be limiting the factor's predictive power. The persistence (autocorrelation) component is also sensitive to the window size (10-15 days), which might be too short to capture 'medium-term' trends effectively.",
        "decision": false,
        "reason": "1. **Relative vs. Absolute Stealth**: Instead of cross-sectional RANK of volume, using a Z-score of volume (TS_ZSCORE) identifies when an individual stock is trading 'quietly' relative to its own norm. 2. **Efficiency Ratio**: Replacing simple autocorrelation with a price efficiency ratio (Net Change / Sum of Absolute Changes) can better filter out 'noisy' mean-reverting price action. 3. **Complexity Control**: By focusing on two primary dimensions (Relative Volume and Price Efficiency) rather than multiplying multiple raw averages, we keep the Symbol Length low and improve generalization. 4. **Window Alignment**: Aligning the lookback for both volume and price persistence to a consistent 20-day window to capture a full monthly cycle."
      }
    },
    "9438eb34d536a949": {
      "factor_id": "9438eb34d536a949",
      "factor_name": "AIFP_Rank_Efficiency_15D",
      "factor_expression": "RANK(TS_CORR($return, DELAY($return, 1), 15)) - RANK(TS_MEAN($volume, 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(($close/DELAY($close, 1)-1), DELAY(($close/DELAY($close, 1)-1), 1), 15)) - RANK(TS_MEAN($volume, 15))\" # Your output factor expression will be filled in here\n    name = \"AIFP_Rank_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A refined version of the Asymmetric Information Flow Persistence hypothesis using cross-sectional ranking to normalize the components. It measures the strength of return serial correlation relative to the asset's volume intensity. High rank in autocorrelation and low rank in volume intensity indicates high-quality information flow.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{return}, 1), 15)) - \\text{RANK}(\\text{TS\\_MEAN}(\\text{volume}, 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "4edbcce4ab82",
        "parent_trajectory_ids": [
          "7754f9bf40e9"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Flow Persistence' (AIFP) factor predicts medium-term trend continuation by identifying assets where high return autocorrelation is sustained by low relative volume impact, suggesting stealthy informed positioning.\n                Concise Observation: The parent LVSR strategy focused on high-volatility mean reversion; however, market trends often persist when price moves are 'quiet' and exhibit high serial correlation without massive volume spikes.\n                Concise Justification: Informed investors often split orders to reduce slippage, causing price trends to exhibit high autocorrelation (signal) with low relative volume (low noise), creating a 'stealth' momentum effect.\n                Concise Knowledge: If return autocorrelation is high while the asset's volume share relative to its peers is declining, then the price move is likely driven by informed traders minimizing market impact, leading to trend persistence.\n                concise Specification: The factor is defined as the product of the 10-day lag-1 return autocorrelation and the inverse of the ratio between individual volume and the cross-sectional median volume, calculated over a 20-day window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T11:47:42.090807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1255277288344417,
        "ICIR": 0.030921509993652,
        "1day.excess_return_without_cost.std": 0.0040626009563249,
        "1day.excess_return_with_cost.annualized_return": 0.005023744007352,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002180673973566,
        "1day.excess_return_without_cost.annualized_return": 0.0519000405708872,
        "1day.excess_return_with_cost.std": 0.0040643656744735,
        "Rank IC": 0.0198411732141004,
        "IC": 0.0041111320130093,
        "1day.excess_return_without_cost.max_drawdown": -0.0823111775441301,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8280852565197517,
        "1day.pa": 0.0,
        "l2.valid": 0.9965156230262624,
        "Rank ICIR": 0.155082717561439,
        "l2.train": 0.9939156500916012,
        "1day.excess_return_with_cost.information_ratio": 0.0801209790789856,
        "1day.excess_return_with_cost.mean": 2.110816809811766e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Asymmetric Information Flow Persistence' (AIFP) hypothesis. While the core concept of combining return autocorrelation with volume-based 'stealth' metrics is theoretically sound, the current implementations failed to surpass the existing SOTA. The 'AIFP_Rank_Efficiency_15D' utilized cross-sectional ranking to normalize the signals, which is a robust approach, but the overall IC (0.0041) and Information Ratio (0.828) lagged behind the SOTA (IC 0.0058, IR 0.973). The 'AIFP_Volatility_Adjusted_Persistence' attempted to incorporate price volatility as a denominator, but the resulting metrics suggest that the interaction between volume and volatility might be too noisy or improperly scaled in its current linear form.",
        "hypothesis_evaluation": "The hypothesis that 'stealthy' informed positioning leads to trend continuation is partially supported by the positive IC and annualized return, but the current mathematical formulations are likely capturing too much noise. The inverse relationship with volume is a strong proxy for stealth, but using raw volume or simple averages (as seen in AIFP_Stealth_Momentum_20D) without proper normalization across different market regimes or sectors may be limiting the factor's predictive power. The persistence (autocorrelation) component is also sensitive to the window size (10-15 days), which might be too short to capture 'medium-term' trends effectively.",
        "decision": false,
        "reason": "1. **Relative vs. Absolute Stealth**: Instead of cross-sectional RANK of volume, using a Z-score of volume (TS_ZSCORE) identifies when an individual stock is trading 'quietly' relative to its own norm. 2. **Efficiency Ratio**: Replacing simple autocorrelation with a price efficiency ratio (Net Change / Sum of Absolute Changes) can better filter out 'noisy' mean-reverting price action. 3. **Complexity Control**: By focusing on two primary dimensions (Relative Volume and Price Efficiency) rather than multiplying multiple raw averages, we keep the Symbol Length low and improve generalization. 4. **Window Alignment**: Aligning the lookback for both volume and price persistence to a consistent 20-day window to capture a full monthly cycle."
      }
    },
    "8ba7cfbc0f64d4cb": {
      "factor_id": "8ba7cfbc0f64d4cb",
      "factor_name": "AIFP_Volatility_Adjusted_Persistence",
      "factor_expression": "TS_CORR($return, DELAY($return, 1), 10) / (TS_MEAN($volume, 20) / (TS_STD($close, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR(TS_PCTCHANGE($close, 1), DELAY(TS_PCTCHANGE($close, 1), 1), 10) / (TS_MEAN($volume, 20) / (TS_STD($close, 20) + 0.00000001) + 0.00000001)\" # Your output factor expression will be filled in here\n    name = \"AIFP_Volatility_Adjusted_Persistence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets the 'stealth' aspect of the hypothesis by scaling return autocorrelation by the inverse of the volume-to-volatility ratio. It seeks assets where price trends are consistent (autocorrelated) but not accompanied by the volume spikes typically seen in retail-driven or high-impact trades.",
      "factor_formulation": "\\frac{\\text{TS\\_CORR}(\\text{return}, \\text{DELAY}(\\text{return}, 1), 10)}{\\text{TS\\_MEAN}(\\text{volume}, 20) / \\text{TS\\_STD}(\\text{close}, 20) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "4edbcce4ab82",
        "parent_trajectory_ids": [
          "7754f9bf40e9"
        ],
        "hypothesis": "Hypothesis: The 'Asymmetric Information Flow Persistence' (AIFP) factor predicts medium-term trend continuation by identifying assets where high return autocorrelation is sustained by low relative volume impact, suggesting stealthy informed positioning.\n                Concise Observation: The parent LVSR strategy focused on high-volatility mean reversion; however, market trends often persist when price moves are 'quiet' and exhibit high serial correlation without massive volume spikes.\n                Concise Justification: Informed investors often split orders to reduce slippage, causing price trends to exhibit high autocorrelation (signal) with low relative volume (low noise), creating a 'stealth' momentum effect.\n                Concise Knowledge: If return autocorrelation is high while the asset's volume share relative to its peers is declining, then the price move is likely driven by informed traders minimizing market impact, leading to trend persistence.\n                concise Specification: The factor is defined as the product of the 10-day lag-1 return autocorrelation and the inverse of the ratio between individual volume and the cross-sectional median volume, calculated over a 20-day window.\n                ",
        "initial_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "planning_direction": "Develop a 'Long-term Mean Reversion' signal by weighting ROC60 with CORR20: a high ROC60 (downtrend) coupled with negative price-volume correlation suggests a capitulation phase.",
        "created_at": "2026-01-21T11:47:42.090807"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1255277288344417,
        "ICIR": 0.030921509993652,
        "1day.excess_return_without_cost.std": 0.0040626009563249,
        "1day.excess_return_with_cost.annualized_return": 0.005023744007352,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002180673973566,
        "1day.excess_return_without_cost.annualized_return": 0.0519000405708872,
        "1day.excess_return_with_cost.std": 0.0040643656744735,
        "Rank IC": 0.0198411732141004,
        "IC": 0.0041111320130093,
        "1day.excess_return_without_cost.max_drawdown": -0.0823111775441301,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8280852565197517,
        "1day.pa": 0.0,
        "l2.valid": 0.9965156230262624,
        "Rank ICIR": 0.155082717561439,
        "l2.train": 0.9939156500916012,
        "1day.excess_return_with_cost.information_ratio": 0.0801209790789856,
        "1day.excess_return_with_cost.mean": 2.110816809811766e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Asymmetric Information Flow Persistence' (AIFP) hypothesis. While the core concept of combining return autocorrelation with volume-based 'stealth' metrics is theoretically sound, the current implementations failed to surpass the existing SOTA. The 'AIFP_Rank_Efficiency_15D' utilized cross-sectional ranking to normalize the signals, which is a robust approach, but the overall IC (0.0041) and Information Ratio (0.828) lagged behind the SOTA (IC 0.0058, IR 0.973). The 'AIFP_Volatility_Adjusted_Persistence' attempted to incorporate price volatility as a denominator, but the resulting metrics suggest that the interaction between volume and volatility might be too noisy or improperly scaled in its current linear form.",
        "hypothesis_evaluation": "The hypothesis that 'stealthy' informed positioning leads to trend continuation is partially supported by the positive IC and annualized return, but the current mathematical formulations are likely capturing too much noise. The inverse relationship with volume is a strong proxy for stealth, but using raw volume or simple averages (as seen in AIFP_Stealth_Momentum_20D) without proper normalization across different market regimes or sectors may be limiting the factor's predictive power. The persistence (autocorrelation) component is also sensitive to the window size (10-15 days), which might be too short to capture 'medium-term' trends effectively.",
        "decision": false,
        "reason": "1. **Relative vs. Absolute Stealth**: Instead of cross-sectional RANK of volume, using a Z-score of volume (TS_ZSCORE) identifies when an individual stock is trading 'quietly' relative to its own norm. 2. **Efficiency Ratio**: Replacing simple autocorrelation with a price efficiency ratio (Net Change / Sum of Absolute Changes) can better filter out 'noisy' mean-reverting price action. 3. **Complexity Control**: By focusing on two primary dimensions (Relative Volume and Price Efficiency) rather than multiplying multiple raw averages, we keep the Symbol Length low and improve generalization. 4. **Window Alignment**: Aligning the lookback for both volume and price persistence to a consistent 20-day window to capture a full monthly cycle."
      }
    },
    "3da846a0f74fabcb": {
      "factor_id": "3da846a0f74fabcb",
      "factor_name": "Trend_Fragility_Index_5_10",
      "factor_expression": "TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Index_5_10\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Trend Fragility Index (TFI) measures the ratio of short-term price noise (5-day standard deviation) to medium-term trend linearity (10-day R-squared). A high ratio indicates that the price trend is becoming unstable and is prone to reversal.",
      "factor_formulation": "TFI = \\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "afce8b4ee48e",
        "parent_trajectory_ids": [
          "d59086bbe768"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI), defined as the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared of price against time), predicts trend exhaustion and subsequent structural breaks when high volatility destabilizes a persistent price path.\n                Concise Observation: While previous reversion factors (LVSR) focused on liquidity vacuums, they often failed during strong trends because they lacked a measure of trend 'quality' or 'stability' to differentiate between healthy pullbacks and terminal exhaustion.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but when the 5-day standard deviation (noise) rises relative to this linearity, it signals that the consensus is fracturing, leading to a 'fragile' state prone to sharp reversals.\n                Concise Knowledge: If a price trend exhibits high linearity but is accompanied by rising short-term volatility, the probability of a structural break increases; conversely, low volatility within a stable linear trend suggests sustainable momentum.\n                concise Specification: The factor is calculated as the ratio of the 5-day standard deviation of close prices to the R-squared of a 10-day linear regression of price over time, where a higher ratio indicates higher fragility and an expected reversal of the current 10-day trend.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T11:58:15.926268"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2049552748322303,
        "ICIR": 0.0314751819893284,
        "1day.excess_return_without_cost.std": 0.0045941400265835,
        "1day.excess_return_with_cost.annualized_return": -0.0070381250894762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001708644420367,
        "1day.excess_return_without_cost.annualized_return": 0.0406657372047555,
        "1day.excess_return_with_cost.std": 0.0045953706624785,
        "Rank IC": 0.0165618477836568,
        "IC": 0.0042271614572164,
        "1day.excess_return_without_cost.max_drawdown": -0.1536079338628623,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5737674978252352,
        "1day.pa": 0.0,
        "l2.valid": 0.9965336772426716,
        "Rank ICIR": 0.1252940890518588,
        "l2.train": 0.9936899139057808,
        "1day.excess_return_with_cost.information_ratio": -0.0992768423899848,
        "1day.excess_return_with_cost.mean": -2.957195415746329e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Trend Fragility Index' (TFI) framework, which posits that the ratio of short-term volatility to medium-term trend linearity predicts structural breaks. While the logic is sound, the current implementation (IC: 0.0042, IR: 0.573) underperforms the SOTA result (IC: 0.0058, IR: 0.972). Specifically, the current results show a significantly higher Max Drawdown (-0.153 vs -0.072), suggesting that the current formulation of 'fragility' might be catching noise or late-stage trends rather than timely reversals. The 'Fragile_Momentum_Reversal' factor attempted to add directionality, but the overall performance indicates that the R-squared denominator might be too unstable when correlation approaches zero, leading to extreme factor values that degrade the information ratio.",
        "hypothesis_evaluation": "The hypothesis that TFI predicts trend exhaustion is partially supported by the positive IC, but the weak Information Ratio and high drawdown suggest the 'linearity' component (R-squared) needs better regularization. Using R-squared as a denominator creates convexity issues; when a trend is non-existent (low R-squared), the factor explodes, which may not necessarily imply fragility but rather a sideways market. The hypothesis needs to be refined to distinguish between 'noisy trends' and 'mean-reverting noise'.",
        "decision": false,
        "reason": "1. Ratios with R-squared in the denominator are numerically unstable; a subtraction-based 'gap' or a ranked-difference approach is more robust. 2. Incorporating volume-weighted volatility provides a better proxy for 'effort vs. result' in trend persistence. 3. Reducing the lookback for volatility relative to the trend window (e.g., 3 days vs 10 days) may provide a more sensitive 'trigger' for the structural break predicted by the hypothesis. 4. Complexity control: The current factors are within limits, but simplifying the denominator will improve generalization."
      }
    },
    "ed20b5de96647245": {
      "factor_id": "ed20b5de96647245",
      "factor_name": "Fragile_Momentum_Reversal",
      "factor_expression": "SIGN(DELTA($close, 10)) * (TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(DELTA($close, 10)) * (TS_STD($close, 5) / (POW(TS_CORR($close, SEQUENCE(10), 10), 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Fragile_Momentum_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the directional risk of a fragile trend. It multiplies the Trend Fragility Index by the sign of the 10-day price change to predict the direction of the expected structural break or reversal.",
      "factor_formulation": "FMR = SIGN(DELTA(close, 10)) * \\frac{TS\\_STD(close, 5)}{POW(TS\\_CORR(close, SEQUENCE(10), 10), 2)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "afce8b4ee48e",
        "parent_trajectory_ids": [
          "d59086bbe768"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI), defined as the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared of price against time), predicts trend exhaustion and subsequent structural breaks when high volatility destabilizes a persistent price path.\n                Concise Observation: While previous reversion factors (LVSR) focused on liquidity vacuums, they often failed during strong trends because they lacked a measure of trend 'quality' or 'stability' to differentiate between healthy pullbacks and terminal exhaustion.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but when the 5-day standard deviation (noise) rises relative to this linearity, it signals that the consensus is fracturing, leading to a 'fragile' state prone to sharp reversals.\n                Concise Knowledge: If a price trend exhibits high linearity but is accompanied by rising short-term volatility, the probability of a structural break increases; conversely, low volatility within a stable linear trend suggests sustainable momentum.\n                concise Specification: The factor is calculated as the ratio of the 5-day standard deviation of close prices to the R-squared of a 10-day linear regression of price over time, where a higher ratio indicates higher fragility and an expected reversal of the current 10-day trend.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T11:58:15.926268"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2049552748322303,
        "ICIR": 0.0314751819893284,
        "1day.excess_return_without_cost.std": 0.0045941400265835,
        "1day.excess_return_with_cost.annualized_return": -0.0070381250894762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001708644420367,
        "1day.excess_return_without_cost.annualized_return": 0.0406657372047555,
        "1day.excess_return_with_cost.std": 0.0045953706624785,
        "Rank IC": 0.0165618477836568,
        "IC": 0.0042271614572164,
        "1day.excess_return_without_cost.max_drawdown": -0.1536079338628623,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5737674978252352,
        "1day.pa": 0.0,
        "l2.valid": 0.9965336772426716,
        "Rank ICIR": 0.1252940890518588,
        "l2.train": 0.9936899139057808,
        "1day.excess_return_with_cost.information_ratio": -0.0992768423899848,
        "1day.excess_return_with_cost.mean": -2.957195415746329e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Trend Fragility Index' (TFI) framework, which posits that the ratio of short-term volatility to medium-term trend linearity predicts structural breaks. While the logic is sound, the current implementation (IC: 0.0042, IR: 0.573) underperforms the SOTA result (IC: 0.0058, IR: 0.972). Specifically, the current results show a significantly higher Max Drawdown (-0.153 vs -0.072), suggesting that the current formulation of 'fragility' might be catching noise or late-stage trends rather than timely reversals. The 'Fragile_Momentum_Reversal' factor attempted to add directionality, but the overall performance indicates that the R-squared denominator might be too unstable when correlation approaches zero, leading to extreme factor values that degrade the information ratio.",
        "hypothesis_evaluation": "The hypothesis that TFI predicts trend exhaustion is partially supported by the positive IC, but the weak Information Ratio and high drawdown suggest the 'linearity' component (R-squared) needs better regularization. Using R-squared as a denominator creates convexity issues; when a trend is non-existent (low R-squared), the factor explodes, which may not necessarily imply fragility but rather a sideways market. The hypothesis needs to be refined to distinguish between 'noisy trends' and 'mean-reverting noise'.",
        "decision": false,
        "reason": "1. Ratios with R-squared in the denominator are numerically unstable; a subtraction-based 'gap' or a ranked-difference approach is more robust. 2. Incorporating volume-weighted volatility provides a better proxy for 'effort vs. result' in trend persistence. 3. Reducing the lookback for volatility relative to the trend window (e.g., 3 days vs 10 days) may provide a more sensitive 'trigger' for the structural break predicted by the hypothesis. 4. Complexity control: The current factors are within limits, but simplifying the denominator will improve generalization."
      }
    },
    "47a6a6f88d56d98c": {
      "factor_id": "47a6a6f88d56d98c",
      "factor_name": "Relative_Linearity_Instability",
      "factor_expression": "RANK(TS_STD($close, 10) / (ABS(TS_CORR($close, SEQUENCE(10), 10)) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($close, 10) / (ABS(TS_CORR($close, SEQUENCE(10), 10)) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Linearity_Instability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the fragility index, measuring how unstable a stock's trend is relative to the market. It focuses on the 10-day window to identify stocks where noise is overwhelming the linear trend component.",
      "factor_formulation": "RLI = RANK(\\frac{TS\\_STD(close, 10)}{ABS(TS\\_CORR(close, SEQUENCE(10), 10)) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "afce8b4ee48e",
        "parent_trajectory_ids": [
          "d59086bbe768"
        ],
        "hypothesis": "Hypothesis: The 'Trend Fragility Index' (TFI), defined as the ratio of short-term price dispersion (5-day standard deviation) to medium-term trend linearity (10-day R-squared of price against time), predicts trend exhaustion and subsequent structural breaks when high volatility destabilizes a persistent price path.\n                Concise Observation: While previous reversion factors (LVSR) focused on liquidity vacuums, they often failed during strong trends because they lacked a measure of trend 'quality' or 'stability' to differentiate between healthy pullbacks and terminal exhaustion.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, but when the 5-day standard deviation (noise) rises relative to this linearity, it signals that the consensus is fracturing, leading to a 'fragile' state prone to sharp reversals.\n                Concise Knowledge: If a price trend exhibits high linearity but is accompanied by rising short-term volatility, the probability of a structural break increases; conversely, low volatility within a stable linear trend suggests sustainable momentum.\n                concise Specification: The factor is calculated as the ratio of the 5-day standard deviation of close prices to the R-squared of a 10-day linear regression of price over time, where a higher ratio indicates higher fragility and an expected reversal of the current 10-day trend.\n                ",
        "initial_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "planning_direction": "Measure 'Trend Fragility' using the ratio of STD5 to RSQR10: high price volatility relative to trend stability indicates an imminent structural break in the medium-term direction.",
        "created_at": "2026-01-21T11:58:15.926268"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.2049552748322303,
        "ICIR": 0.0314751819893284,
        "1day.excess_return_without_cost.std": 0.0045941400265835,
        "1day.excess_return_with_cost.annualized_return": -0.0070381250894762,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001708644420367,
        "1day.excess_return_without_cost.annualized_return": 0.0406657372047555,
        "1day.excess_return_with_cost.std": 0.0045953706624785,
        "Rank IC": 0.0165618477836568,
        "IC": 0.0042271614572164,
        "1day.excess_return_without_cost.max_drawdown": -0.1536079338628623,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5737674978252352,
        "1day.pa": 0.0,
        "l2.valid": 0.9965336772426716,
        "Rank ICIR": 0.1252940890518588,
        "l2.train": 0.9936899139057808,
        "1day.excess_return_with_cost.information_ratio": -0.0992768423899848,
        "1day.excess_return_with_cost.mean": -2.957195415746329e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Trend Fragility Index' (TFI) framework, which posits that the ratio of short-term volatility to medium-term trend linearity predicts structural breaks. While the logic is sound, the current implementation (IC: 0.0042, IR: 0.573) underperforms the SOTA result (IC: 0.0058, IR: 0.972). Specifically, the current results show a significantly higher Max Drawdown (-0.153 vs -0.072), suggesting that the current formulation of 'fragility' might be catching noise or late-stage trends rather than timely reversals. The 'Fragile_Momentum_Reversal' factor attempted to add directionality, but the overall performance indicates that the R-squared denominator might be too unstable when correlation approaches zero, leading to extreme factor values that degrade the information ratio.",
        "hypothesis_evaluation": "The hypothesis that TFI predicts trend exhaustion is partially supported by the positive IC, but the weak Information Ratio and high drawdown suggest the 'linearity' component (R-squared) needs better regularization. Using R-squared as a denominator creates convexity issues; when a trend is non-existent (low R-squared), the factor explodes, which may not necessarily imply fragility but rather a sideways market. The hypothesis needs to be refined to distinguish between 'noisy trends' and 'mean-reverting noise'.",
        "decision": false,
        "reason": "1. Ratios with R-squared in the denominator are numerically unstable; a subtraction-based 'gap' or a ranked-difference approach is more robust. 2. Incorporating volume-weighted volatility provides a better proxy for 'effort vs. result' in trend persistence. 3. Reducing the lookback for volatility relative to the trend window (e.g., 3 days vs 10 days) may provide a more sensitive 'trigger' for the structural break predicted by the hypothesis. 4. Complexity control: The current factors are within limits, but simplifying the denominator will improve generalization."
      }
    },
    "9fcc65d73726aaf8": {
      "factor_id": "9fcc65d73726aaf8",
      "factor_name": "Quiet_Accumulation_Density_5D",
      "factor_expression": "SUMIF(($close / $open - 1) * $volume, 5, ($high - $low) < TS_MEAN($high - $low, 20)) / (TS_STD($return, 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SUMIF(($close / $open - 1) * $volume, 5, ($high - $low) < TS_MEAN($high - $low, 20)) / (TS_STD($close / DELAY($close, 1) - 1, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Quiet_Accumulation_Density_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional positioning by calculating the cumulative volume-weighted return during days where the price range is below its 20-day average. It then normalizes this accumulation by the rolling 5-day standard deviation of returns to isolate efficient, low-volatility price displacement.",
      "factor_formulation": "QAD = \\frac{\\sum_{i=1}^{5} [(\\frac{close_i - open_i}{open_i} \\times volume_i) \\text{ if } (high_i - low_i) < \\text{TS_MEAN}(high - low, 20)]}{\\text{TS_STD}(return, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b3ea6c0e98bb",
        "parent_trajectory_ids": [
          "795c64f9cea7"
        ],
        "hypothesis": "Hypothesis: The 'Quiet Accumulation' factor, defined as the 5-day cumulative volume-weighted return during low-volatility periods, identifies institutional positioning that precedes momentum breakouts by capturing directional price displacement hidden within consolidation phases.\n                Concise Observation: The parent strategy (LVSF) focused on 'hollow' trends where price linearity and liquidity decoupled at extremes; however, market data often shows periods of low volatility where volume-weighted returns diverge from raw price action, suggesting a buildup of directional pressure.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to 'quiet' accumulation where price moves slightly but steadily on significant volume during low-volatility windows, creating a lead indicator for future volatility expansion.\n                Concise Knowledge: If price displacement is consistently positive on days with low relative volatility and high volume, then institutional accumulation is likely occurring; when this 'dense' consolidation is detected, it signals a high-probability trend continuation or breakout rather than mean reversion.\n                concise Specification: The factor calculates the 5-day sum of ($close/$open - 1) * $volume, conditioned on the daily range ($high-$low) being below its 20-day average, then normalized by the 5-day standard deviation of returns to isolate efficient information flow.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T12:01:12.697468"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1418757748124768,
        "ICIR": 0.0257290070512764,
        "1day.excess_return_without_cost.std": 0.00520152498999,
        "1day.excess_return_with_cost.annualized_return": 0.0098828729681368,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002421401169006,
        "1day.excess_return_without_cost.annualized_return": 0.0576293478223489,
        "1day.excess_return_with_cost.std": 0.0052031004176868,
        "Rank IC": 0.0191347987048938,
        "IC": 0.0038022747371534,
        "1day.excess_return_without_cost.max_drawdown": -0.1164911368608064,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7181654979302649,
        "1day.pa": 0.0,
        "l2.valid": 0.9965860452976786,
        "Rank ICIR": 0.1308944021399088,
        "l2.train": 0.9940077470271604,
        "1day.excess_return_with_cost.information_ratio": 0.1231211113197645,
        "1day.excess_return_with_cost.mean": 4.152467633670937e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Quiet Accumulation' hypothesis. While the 'Current Result' (likely driven by the Institutional_Stealth_Index_15D or the ensemble) achieved a higher annualized return (0.0576 vs 0.0520) compared to the SOTA, it suffered from a significantly higher max drawdown (-0.116 vs -0.072) and a lower Information Ratio (0.718 vs 0.972). The IC also dropped from 0.0058 to 0.0038, suggesting that while the directional bet on 'stealth' accumulation captured some high-alpha events, the overall signal-to-noise ratio and consistency of the factors have deteriorated compared to previous benchmarks.",
        "hypothesis_evaluation": "The hypothesis that institutional positioning can be captured during low-volatility periods is partially supported by the improvement in annualized returns. However, the drop in Information Ratio and IC suggests that the current definitions—specifically the use of raw volume and price ranges—might be introducing noise. The 'Quiet_Accumulation_Density_5D' and 'Relative_Quiet_Flow_ZScore_10D' use absolute volume in their weighting, which often biases factors toward large-cap stocks or high-liquidity regimes, potentially explaining the increased drawdown.",
        "decision": true,
        "reason": "The current factors use raw volume, which can be dominated by market makers or high-frequency trading. By switching to 'Abnormal Volume' (e.g., volume divided by its 20-day moving average) and focusing on the 'persistence' (count of positive days) rather than just the sum, we can better isolate deliberate institutional accumulation. Furthermore, the Institutional_Stealth_Index_15D used a complex ratio (close change / (range/volume)) which might be over-engineered; simplifying this to a volume-weighted efficiency ratio over a longer lookback should improve the Information Ratio."
      }
    },
    "2d446f6470a08591": {
      "factor_id": "2d446f6470a08591",
      "factor_name": "Relative_Quiet_Flow_ZScore_10D",
      "factor_expression": "ZSCORE(TS_SUM((($high - $low) < TS_MEDIAN($high - $low, 10)) ? (($close / $open - 1) * $volume) : 0, 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_SUM((($high - $low) < TS_MEDIAN($high - $low, 10)) ? (($close / $open - 1) * $volume) : 0, 5))\" # Your output factor expression will be filled in here\n    name = \"Relative_Quiet_Flow_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the quiet accumulation hypothesis focusing on the cross-sectional strength of low-volatility volume flow. It measures the Z-score of volume-weighted returns specifically on days where the intraday range is tighter than the recent median, capturing 'dense' consolidation relative to the market.",
      "factor_formulation": "RQF = \\text{ZSCORE}(\\text{TS_SUM}(((\\text{high} - \\text{low}) < \\text{TS_MEDIAN}(\\text{high} - \\text{low}, 10)) ? ((\\text{close} - \\text{open}) / \\text{open} \\times \\text{volume}) : 0, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b3ea6c0e98bb",
        "parent_trajectory_ids": [
          "795c64f9cea7"
        ],
        "hypothesis": "Hypothesis: The 'Quiet Accumulation' factor, defined as the 5-day cumulative volume-weighted return during low-volatility periods, identifies institutional positioning that precedes momentum breakouts by capturing directional price displacement hidden within consolidation phases.\n                Concise Observation: The parent strategy (LVSF) focused on 'hollow' trends where price linearity and liquidity decoupled at extremes; however, market data often shows periods of low volatility where volume-weighted returns diverge from raw price action, suggesting a buildup of directional pressure.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to 'quiet' accumulation where price moves slightly but steadily on significant volume during low-volatility windows, creating a lead indicator for future volatility expansion.\n                Concise Knowledge: If price displacement is consistently positive on days with low relative volatility and high volume, then institutional accumulation is likely occurring; when this 'dense' consolidation is detected, it signals a high-probability trend continuation or breakout rather than mean reversion.\n                concise Specification: The factor calculates the 5-day sum of ($close/$open - 1) * $volume, conditioned on the daily range ($high-$low) being below its 20-day average, then normalized by the 5-day standard deviation of returns to isolate efficient information flow.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T12:01:12.697468"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1418757748124768,
        "ICIR": 0.0257290070512764,
        "1day.excess_return_without_cost.std": 0.00520152498999,
        "1day.excess_return_with_cost.annualized_return": 0.0098828729681368,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002421401169006,
        "1day.excess_return_without_cost.annualized_return": 0.0576293478223489,
        "1day.excess_return_with_cost.std": 0.0052031004176868,
        "Rank IC": 0.0191347987048938,
        "IC": 0.0038022747371534,
        "1day.excess_return_without_cost.max_drawdown": -0.1164911368608064,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7181654979302649,
        "1day.pa": 0.0,
        "l2.valid": 0.9965860452976786,
        "Rank ICIR": 0.1308944021399088,
        "l2.train": 0.9940077470271604,
        "1day.excess_return_with_cost.information_ratio": 0.1231211113197645,
        "1day.excess_return_with_cost.mean": 4.152467633670937e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Quiet Accumulation' hypothesis. While the 'Current Result' (likely driven by the Institutional_Stealth_Index_15D or the ensemble) achieved a higher annualized return (0.0576 vs 0.0520) compared to the SOTA, it suffered from a significantly higher max drawdown (-0.116 vs -0.072) and a lower Information Ratio (0.718 vs 0.972). The IC also dropped from 0.0058 to 0.0038, suggesting that while the directional bet on 'stealth' accumulation captured some high-alpha events, the overall signal-to-noise ratio and consistency of the factors have deteriorated compared to previous benchmarks.",
        "hypothesis_evaluation": "The hypothesis that institutional positioning can be captured during low-volatility periods is partially supported by the improvement in annualized returns. However, the drop in Information Ratio and IC suggests that the current definitions—specifically the use of raw volume and price ranges—might be introducing noise. The 'Quiet_Accumulation_Density_5D' and 'Relative_Quiet_Flow_ZScore_10D' use absolute volume in their weighting, which often biases factors toward large-cap stocks or high-liquidity regimes, potentially explaining the increased drawdown.",
        "decision": true,
        "reason": "The current factors use raw volume, which can be dominated by market makers or high-frequency trading. By switching to 'Abnormal Volume' (e.g., volume divided by its 20-day moving average) and focusing on the 'persistence' (count of positive days) rather than just the sum, we can better isolate deliberate institutional accumulation. Furthermore, the Institutional_Stealth_Index_15D used a complex ratio (close change / (range/volume)) which might be over-engineered; simplifying this to a volume-weighted efficiency ratio over a longer lookback should improve the Information Ratio."
      }
    },
    "620d7b194db80a3b": {
      "factor_id": "620d7b194db80a3b",
      "factor_name": "Institutional_Stealth_Index_15D",
      "factor_expression": "RANK(TS_MEAN(($close - DELAY($close, 1)) / (($high - $low) / ($volume + 1e-8) + 1e-8), 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - DELAY($close, 1)) / (($high - $low) / ($volume + 1e-8) + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Stealth_Index_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the divergence between price volatility and volume intensity. It ranks the ratio of cumulative returns to cumulative volatility specifically during periods of low price-range-to-volume ratios, highlighting efficient accumulation with minimal price impact.",
      "factor_formulation": "ISI = \\text{RANK}(\\text{TS_MEAN}((\\text{close} - \\text{DELAY}(\\text{close}, 1)) / ((\\text{high} - \\text{low}) / \\text{volume} + 1e-8), 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "b3ea6c0e98bb",
        "parent_trajectory_ids": [
          "795c64f9cea7"
        ],
        "hypothesis": "Hypothesis: The 'Quiet Accumulation' factor, defined as the 5-day cumulative volume-weighted return during low-volatility periods, identifies institutional positioning that precedes momentum breakouts by capturing directional price displacement hidden within consolidation phases.\n                Concise Observation: The parent strategy (LVSF) focused on 'hollow' trends where price linearity and liquidity decoupled at extremes; however, market data often shows periods of low volatility where volume-weighted returns diverge from raw price action, suggesting a buildup of directional pressure.\n                Concise Justification: Institutional investors often use execution algorithms to minimize market impact, leading to 'quiet' accumulation where price moves slightly but steadily on significant volume during low-volatility windows, creating a lead indicator for future volatility expansion.\n                Concise Knowledge: If price displacement is consistently positive on days with low relative volatility and high volume, then institutional accumulation is likely occurring; when this 'dense' consolidation is detected, it signals a high-probability trend continuation or breakout rather than mean reversion.\n                concise Specification: The factor calculates the 5-day sum of ($close/$open - 1) * $volume, conditioned on the daily range ($high-$low) being below its 20-day average, then normalized by the 5-day standard deviation of returns to isolate efficient information flow.\n                ",
        "initial_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "planning_direction": "Construct a 'Liquidity-Adjusted Rebound' factor by filtering RESI5 with VSTD5: deep negative residuals with stable volume (low VSTD5) suggest an orderly sell-off ripe for a bounce.",
        "created_at": "2026-01-21T12:01:12.697468"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1418757748124768,
        "ICIR": 0.0257290070512764,
        "1day.excess_return_without_cost.std": 0.00520152498999,
        "1day.excess_return_with_cost.annualized_return": 0.0098828729681368,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002421401169006,
        "1day.excess_return_without_cost.annualized_return": 0.0576293478223489,
        "1day.excess_return_with_cost.std": 0.0052031004176868,
        "Rank IC": 0.0191347987048938,
        "IC": 0.0038022747371534,
        "1day.excess_return_without_cost.max_drawdown": -0.1164911368608064,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7181654979302649,
        "1day.pa": 0.0,
        "l2.valid": 0.9965860452976786,
        "Rank ICIR": 0.1308944021399088,
        "l2.train": 0.9940077470271604,
        "1day.excess_return_with_cost.information_ratio": 0.1231211113197645,
        "1day.excess_return_with_cost.mean": 4.152467633670937e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Quiet Accumulation' hypothesis. While the 'Current Result' (likely driven by the Institutional_Stealth_Index_15D or the ensemble) achieved a higher annualized return (0.0576 vs 0.0520) compared to the SOTA, it suffered from a significantly higher max drawdown (-0.116 vs -0.072) and a lower Information Ratio (0.718 vs 0.972). The IC also dropped from 0.0058 to 0.0038, suggesting that while the directional bet on 'stealth' accumulation captured some high-alpha events, the overall signal-to-noise ratio and consistency of the factors have deteriorated compared to previous benchmarks.",
        "hypothesis_evaluation": "The hypothesis that institutional positioning can be captured during low-volatility periods is partially supported by the improvement in annualized returns. However, the drop in Information Ratio and IC suggests that the current definitions—specifically the use of raw volume and price ranges—might be introducing noise. The 'Quiet_Accumulation_Density_5D' and 'Relative_Quiet_Flow_ZScore_10D' use absolute volume in their weighting, which often biases factors toward large-cap stocks or high-liquidity regimes, potentially explaining the increased drawdown.",
        "decision": true,
        "reason": "The current factors use raw volume, which can be dominated by market makers or high-frequency trading. By switching to 'Abnormal Volume' (e.g., volume divided by its 20-day moving average) and focusing on the 'persistence' (count of positive days) rather than just the sum, we can better isolate deliberate institutional accumulation. Furthermore, the Institutional_Stealth_Index_15D used a complex ratio (close change / (range/volume)) which might be over-engineered; simplifying this to a volume-weighted efficiency ratio over a longer lookback should improve the Information Ratio."
      }
    },
    "83ed6baf586b4405": {
      "factor_id": "83ed6baf586b4405",
      "factor_name": "ICP_SignalToNoise_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ICP_SignalToNoise_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Inertial Capital Persistence (ICP) factor identifies sustainable trend regimes by scaling the 20-day price momentum by the signal-to-noise ratio of trading volume. High values indicate strong price trends supported by stable, low-variance volume profiles, suggesting institutional accumulation.",
      "factor_formulation": "ICP_{20D} = \\text{TS_PCTCHANGE}(\\text{close}, 20) \\times \\frac{\\text{TS_MEAN}(\\text{volume}, 20)}{\\text{TS_STD}(\\text{volume}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "bfa914caa408",
        "parent_trajectory_ids": [
          "b1dcd5e9d4ae"
        ],
        "hypothesis": "Hypothesis: The Inertial Capital Persistence (ICP) factor identifies sustainable trend regimes by scaling the 20-day price momentum by the inverse of volume volatility, specifically targeting periods where price direction is reinforced by stable, low-entropy transaction density.\n                Concise Observation: Parent strategies focusing on price-volume decoupling (residuals) effectively capture short-term mean-reversion but fail to distinguish between noise-driven spikes and the steady, low-variance volume profiles characteristic of institutional trend-building.\n                Concise Justification: Stable volume growth suggests a consensus among market participants and a steady absorption of liquidity, which reduces the probability of immediate price reversals and supports the continuation of the current trend direction.\n                Concise Knowledge: If price momentum is accompanied by a decreasing coefficient of variation in volume, the trend is more likely to persist; when volume variance is high during a price move, the trend is likely driven by noise or transient liquidity shocks rather than informed institutional accumulation.\n                concise Specification: The factor is defined as the 20-day price return multiplied by the ratio of the 20-day mean volume to the 20-day standard deviation of volume, capturing the 'signal-to-noise' ratio of capital flows.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T12:04:15.776054"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1000213090885694,
        "ICIR": 0.0490687748135292,
        "1day.excess_return_without_cost.std": 0.0050181549718496,
        "1day.excess_return_with_cost.annualized_return": 0.0298963457217139,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003255778311365,
        "1day.excess_return_without_cost.annualized_return": 0.0774875238104972,
        "1day.excess_return_with_cost.std": 0.0050194877707238,
        "Rank IC": 0.0249354043859447,
        "IC": 0.0072988821492799,
        "1day.excess_return_without_cost.max_drawdown": -0.0927217215098744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.000919695476993,
        "1day.pa": 0.0,
        "l2.valid": 0.9968629670012896,
        "Rank ICIR": 0.1691117987058406,
        "l2.train": 0.9939532734287198,
        "1day.excess_return_with_cost.information_ratio": 0.3860737091630212,
        "1day.excess_return_with_cost.mean": 0.0001256148979903
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Inertial Capital Persistence (ICP) hypothesis. The results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.00, and the Annualized Return saw a substantial jump from 5.2% to 7.7%. The Information Coefficient (IC) also improved from 0.0058 to 0.0073. While the Max Drawdown slightly worsened (-0.092 vs -0.072), the overall return-to-risk profile is superior. The use of volume stability (Mean/Std) as a scaling factor for price momentum appears to be a robust signal for identifying high-conviction trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that scaling 20-day momentum by the inverse of volume volatility (signal-to-noise ratio) identifies sustainable trend regimes. The transition from raw momentum to a rank-based and z-score-based combination (as seen in ICP_Rank_Stability and ICP_ZScore_Persistence) likely contributed to the improved IC and Annualized Return by normalizing the signal across the cross-section, reducing the impact of outliers while capturing 'orderly' capital flows.",
        "decision": true,
        "reason": "While the current ICP factor uses volume stability (Mean/Std) as a static multiplier, it doesn't account for the 'direction' of volume changes relative to price. Adding a term that rewards positive price-volume correlation (convergence) while penalizing divergence should further filter out 'exhaustion' moves where volume is stable but no longer supporting price direction. This maintains the core 'low-entropy' concept but adds a dynamic confirmation layer."
      }
    },
    "31839f0b35d6cc76": {
      "factor_id": "31839f0b35d6cc76",
      "factor_name": "ICP_Rank_Stability_20D",
      "factor_expression": "RANK(DELTA($close, 20) / ($close - DELTA($close, 20) + 1e-8)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($close, 20) / ($close - DELTA($close, 20) + 1e-8)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ICP_Rank_Stability_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the Inertial Capital Persistence factor. It captures the relative strength of the price trend adjusted by the inverse coefficient of variation of volume, highlighting assets with the most 'orderly' capital inflows relative to the market.",
      "factor_formulation": "ICP\\_Rank_{20D} = \\text{RANK}(\\frac{\\text{close} - \\text{DELAY}(\\text{close}, 20)}{\\text{DELAY}(\\text{close}, 20)}) \\times \\text{RANK}(\\frac{\\text{TS_MEAN}(\\text{volume}, 20)}{\\text{TS_STD}(\\text{volume}, 20)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "bfa914caa408",
        "parent_trajectory_ids": [
          "b1dcd5e9d4ae"
        ],
        "hypothesis": "Hypothesis: The Inertial Capital Persistence (ICP) factor identifies sustainable trend regimes by scaling the 20-day price momentum by the inverse of volume volatility, specifically targeting periods where price direction is reinforced by stable, low-entropy transaction density.\n                Concise Observation: Parent strategies focusing on price-volume decoupling (residuals) effectively capture short-term mean-reversion but fail to distinguish between noise-driven spikes and the steady, low-variance volume profiles characteristic of institutional trend-building.\n                Concise Justification: Stable volume growth suggests a consensus among market participants and a steady absorption of liquidity, which reduces the probability of immediate price reversals and supports the continuation of the current trend direction.\n                Concise Knowledge: If price momentum is accompanied by a decreasing coefficient of variation in volume, the trend is more likely to persist; when volume variance is high during a price move, the trend is likely driven by noise or transient liquidity shocks rather than informed institutional accumulation.\n                concise Specification: The factor is defined as the 20-day price return multiplied by the ratio of the 20-day mean volume to the 20-day standard deviation of volume, capturing the 'signal-to-noise' ratio of capital flows.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T12:04:15.776054"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1000213090885694,
        "ICIR": 0.0490687748135292,
        "1day.excess_return_without_cost.std": 0.0050181549718496,
        "1day.excess_return_with_cost.annualized_return": 0.0298963457217139,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003255778311365,
        "1day.excess_return_without_cost.annualized_return": 0.0774875238104972,
        "1day.excess_return_with_cost.std": 0.0050194877707238,
        "Rank IC": 0.0249354043859447,
        "IC": 0.0072988821492799,
        "1day.excess_return_without_cost.max_drawdown": -0.0927217215098744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.000919695476993,
        "1day.pa": 0.0,
        "l2.valid": 0.9968629670012896,
        "Rank ICIR": 0.1691117987058406,
        "l2.train": 0.9939532734287198,
        "1day.excess_return_with_cost.information_ratio": 0.3860737091630212,
        "1day.excess_return_with_cost.mean": 0.0001256148979903
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Inertial Capital Persistence (ICP) hypothesis. The results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.00, and the Annualized Return saw a substantial jump from 5.2% to 7.7%. The Information Coefficient (IC) also improved from 0.0058 to 0.0073. While the Max Drawdown slightly worsened (-0.092 vs -0.072), the overall return-to-risk profile is superior. The use of volume stability (Mean/Std) as a scaling factor for price momentum appears to be a robust signal for identifying high-conviction trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that scaling 20-day momentum by the inverse of volume volatility (signal-to-noise ratio) identifies sustainable trend regimes. The transition from raw momentum to a rank-based and z-score-based combination (as seen in ICP_Rank_Stability and ICP_ZScore_Persistence) likely contributed to the improved IC and Annualized Return by normalizing the signal across the cross-section, reducing the impact of outliers while capturing 'orderly' capital flows.",
        "decision": true,
        "reason": "While the current ICP factor uses volume stability (Mean/Std) as a static multiplier, it doesn't account for the 'direction' of volume changes relative to price. Adding a term that rewards positive price-volume correlation (convergence) while penalizing divergence should further filter out 'exhaustion' moves where volume is stable but no longer supporting price direction. This maintains the core 'low-entropy' concept but adds a dynamic confirmation layer."
      }
    },
    "a37a86117b6c227c": {
      "factor_id": "a37a86117b6c227c",
      "factor_name": "ICP_ZScore_Persistence_20D",
      "factor_expression": "ZSCORE(TS_SUM($return, 20)) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 20)) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ICP_ZScore_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the persistence of a trend by multiplying the 20-day price return z-score by the volume stability (mean/std). It identifies regimes where price momentum is statistically significant and volume volatility is low, indicating a high-conviction trend.",
      "factor_formulation": "ICP\\_ZScore_{20D} = \\text{ZSCORE}(\\text{TS_SUM}(\\text{return}, 20)) \\times (\\frac{\\text{TS_MEAN}(\\text{volume}, 20)}{\\text{TS_STD}(\\text{volume}, 20)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "bfa914caa408",
        "parent_trajectory_ids": [
          "b1dcd5e9d4ae"
        ],
        "hypothesis": "Hypothesis: The Inertial Capital Persistence (ICP) factor identifies sustainable trend regimes by scaling the 20-day price momentum by the inverse of volume volatility, specifically targeting periods where price direction is reinforced by stable, low-entropy transaction density.\n                Concise Observation: Parent strategies focusing on price-volume decoupling (residuals) effectively capture short-term mean-reversion but fail to distinguish between noise-driven spikes and the steady, low-variance volume profiles characteristic of institutional trend-building.\n                Concise Justification: Stable volume growth suggests a consensus among market participants and a steady absorption of liquidity, which reduces the probability of immediate price reversals and supports the continuation of the current trend direction.\n                Concise Knowledge: If price momentum is accompanied by a decreasing coefficient of variation in volume, the trend is more likely to persist; when volume variance is high during a price move, the trend is likely driven by noise or transient liquidity shocks rather than informed institutional accumulation.\n                concise Specification: The factor is defined as the 20-day price return multiplied by the ratio of the 20-day mean volume to the 20-day standard deviation of volume, capturing the 'signal-to-noise' ratio of capital flows.\n                ",
        "initial_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "planning_direction": "Evaluate 'Intraday-to-Interday Volatility Shift' by comparing KLEN to STD5: when intraday ranges exceed 5-day realized volatility, it signals a regime shift in market participants' urgency.",
        "created_at": "2026-01-21T12:04:15.776054"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1000213090885694,
        "ICIR": 0.0490687748135292,
        "1day.excess_return_without_cost.std": 0.0050181549718496,
        "1day.excess_return_with_cost.annualized_return": 0.0298963457217139,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003255778311365,
        "1day.excess_return_without_cost.annualized_return": 0.0774875238104972,
        "1day.excess_return_with_cost.std": 0.0050194877707238,
        "Rank IC": 0.0249354043859447,
        "IC": 0.0072988821492799,
        "1day.excess_return_without_cost.max_drawdown": -0.0927217215098744,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.000919695476993,
        "1day.pa": 0.0,
        "l2.valid": 0.9968629670012896,
        "Rank ICIR": 0.1691117987058406,
        "l2.train": 0.9939532734287198,
        "1day.excess_return_with_cost.information_ratio": 0.3860737091630212,
        "1day.excess_return_with_cost.mean": 0.0001256148979903
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the Inertial Capital Persistence (ICP) hypothesis. The results show a significant improvement in predictive power and risk-adjusted returns compared to the previous SOTA. Specifically, the Information Ratio (IR) increased from 0.97 to 1.00, and the Annualized Return saw a substantial jump from 5.2% to 7.7%. The Information Coefficient (IC) also improved from 0.0058 to 0.0073. While the Max Drawdown slightly worsened (-0.092 vs -0.072), the overall return-to-risk profile is superior. The use of volume stability (Mean/Std) as a scaling factor for price momentum appears to be a robust signal for identifying high-conviction trends.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that scaling 20-day momentum by the inverse of volume volatility (signal-to-noise ratio) identifies sustainable trend regimes. The transition from raw momentum to a rank-based and z-score-based combination (as seen in ICP_Rank_Stability and ICP_ZScore_Persistence) likely contributed to the improved IC and Annualized Return by normalizing the signal across the cross-section, reducing the impact of outliers while capturing 'orderly' capital flows.",
        "decision": true,
        "reason": "While the current ICP factor uses volume stability (Mean/Std) as a static multiplier, it doesn't account for the 'direction' of volume changes relative to price. Adding a term that rewards positive price-volume correlation (convergence) while penalizing divergence should further filter out 'exhaustion' moves where volume is stable but no longer supporting price direction. This maintains the core 'low-entropy' concept but adds a dynamic confirmation layer."
      }
    },
    "830f5c2ee06c9f98": {
      "factor_id": "830f5c2ee06c9f98",
      "factor_name": "Institutional_Absorption_Factor_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * INV(TS_MEAN(($high - $low) / ($volume + 1e-8), 5))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_MEAN(($high - $low) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Absorption_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies sustainable price trends by combining linear persistence (R-squared) with low volume-weighted intraday volatility. High R-squared indicates a steady price climb, while low volume-weighted range suggests institutional accumulation without price spikes or liquidity gaps.",
      "factor_formulation": "IAF = \\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) * \\text{INV}(\\text{TS_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{volume} + 1e-8}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "3b723480152e",
        "parent_trajectory_ids": [
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Institutional Absorption Factor (IAF) identifies sustainable price trends by detecting periods where the 10-day R-squared of price returns is high (indicating linear persistence) while the 5-day volume-weighted price volatility is low, suggesting non-disruptive institutional accumulation.\n                Concise Observation: The parent strategy (LSEF) focused on mean-reversion from 'hollow' price spikes; however, market leaders often exhibit 'efficient' climbs where price moves steadily with minimal intraday noise, signaling a different regime of institutional conviction.\n                Concise Justification: High R-squared values filter for steady directional movement, while low volume-weighted volatility (WVMA) ensures that this movement is not driven by speculative spikes or liquidity gaps, but rather by consistent, controlled buying pressure.\n                Concise Knowledge: If a price trend exhibits high linear persistence (R-squared) alongside low volume-weighted volatility, it likely reflects institutional absorption; such 'quiet' trends are more sustainable than high-volatility breakouts which often lead to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Pearson R-squared of daily close prices against a time index and the inverse of the 5-day moving average of the volume-weighted intraday range ($high-$low)/$volume. It targets trend-following entries in low-noise environments.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T12:20:55.615002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191894507604488,
        "ICIR": 0.0423436700109229,
        "1day.excess_return_without_cost.std": 0.004051247398869,
        "1day.excess_return_with_cost.annualized_return": 0.00293898401951,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002105760575969,
        "1day.excess_return_without_cost.annualized_return": 0.050117101708071,
        "1day.excess_return_with_cost.std": 0.0040529893723043,
        "Rank IC": 0.0230786334929141,
        "IC": 0.0058217224994981,
        "1day.excess_return_without_cost.max_drawdown": -0.0953488136540804,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8018787485030696,
        "1day.pa": 0.0,
        "l2.valid": 0.9964740395164088,
        "Rank ICIR": 0.1727121375528159,
        "l2.train": 0.9940822192532732,
        "1day.excess_return_with_cost.information_ratio": 0.0470038337115988,
        "1day.excess_return_with_cost.mean": 1.2348672350882373e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Absorption Factor (IAF) hypothesis, focusing on the synergy between price trend linearity (R-squared/Correlation) and low intraday volatility. The 'Current Result' achieved a higher Information Coefficient (IC) of 0.005822 compared to the SOTA's 0.005798, indicating a slight improvement in the raw predictive power of the signal. However, the risk-adjusted metrics (Information Ratio) and drawdown protection (Max Drawdown) underperformed relative to the SOTA. Among the tested factors, the 'Institutional_Accumulation_Efficiency' and 'Quiet_Trend_Persistence_ZScore' provided more robust normalization than the original IAF_10D by using cross-sectional ranking and smoothed volume denominators.",
        "hypothesis_evaluation": "The hypothesis that linear persistence combined with low volume-weighted volatility identifies sustainable trends is partially supported by the improved IC. The results suggest that the 'linear persistence' component (TS_CORR) is a strong signal, but the 'volatility' denominator needs better scaling. The current implementation of (high-low)/volume can be extremely noisy due to small volume values, which likely led to the higher drawdown and lower IR compared to SOTA.",
        "decision": false,
        "reason": "The current results show that while the predictive correlation (IC) is high, the stability of the return (IR) is lacking. The volume-based denominator in IAF_10D and IAE is prone to outliers. By replacing the volume-weighted range with a pure price-relative range (High-Low)/Close and applying a cross-sectional Rank to both the persistence and the volatility components separately before combining them, we can create a more stable, scale-invariant factor that captures the same 'quiet markup' logic without the instability of volume-driven denominators."
      }
    },
    "d7ae30e09c457386": {
      "factor_id": "d7ae30e09c457386",
      "factor_name": "Quiet_Trend_Persistence_ZScore",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) / (RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 5)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) / (RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 5)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Quiet_Trend_Persistence_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the absorption hypothesis that uses Z-scored persistence and normalized volatility. It captures regimes where the price trend is unusually linear relative to its recent intraday noise levels, favoring 'quiet' institutional markups over volatile retail breakouts.",
      "factor_formulation": "QTP = \\text{RANK}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)) / \\text{RANK}(\\text{TS_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{close}}, 5))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "3b723480152e",
        "parent_trajectory_ids": [
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Institutional Absorption Factor (IAF) identifies sustainable price trends by detecting periods where the 10-day R-squared of price returns is high (indicating linear persistence) while the 5-day volume-weighted price volatility is low, suggesting non-disruptive institutional accumulation.\n                Concise Observation: The parent strategy (LSEF) focused on mean-reversion from 'hollow' price spikes; however, market leaders often exhibit 'efficient' climbs where price moves steadily with minimal intraday noise, signaling a different regime of institutional conviction.\n                Concise Justification: High R-squared values filter for steady directional movement, while low volume-weighted volatility (WVMA) ensures that this movement is not driven by speculative spikes or liquidity gaps, but rather by consistent, controlled buying pressure.\n                Concise Knowledge: If a price trend exhibits high linear persistence (R-squared) alongside low volume-weighted volatility, it likely reflects institutional absorption; such 'quiet' trends are more sustainable than high-volatility breakouts which often lead to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Pearson R-squared of daily close prices against a time index and the inverse of the 5-day moving average of the volume-weighted intraday range ($high-$low)/$volume. It targets trend-following entries in low-noise environments.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T12:20:55.615002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191894507604488,
        "ICIR": 0.0423436700109229,
        "1day.excess_return_without_cost.std": 0.004051247398869,
        "1day.excess_return_with_cost.annualized_return": 0.00293898401951,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002105760575969,
        "1day.excess_return_without_cost.annualized_return": 0.050117101708071,
        "1day.excess_return_with_cost.std": 0.0040529893723043,
        "Rank IC": 0.0230786334929141,
        "IC": 0.0058217224994981,
        "1day.excess_return_without_cost.max_drawdown": -0.0953488136540804,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8018787485030696,
        "1day.pa": 0.0,
        "l2.valid": 0.9964740395164088,
        "Rank ICIR": 0.1727121375528159,
        "l2.train": 0.9940822192532732,
        "1day.excess_return_with_cost.information_ratio": 0.0470038337115988,
        "1day.excess_return_with_cost.mean": 1.2348672350882373e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Absorption Factor (IAF) hypothesis, focusing on the synergy between price trend linearity (R-squared/Correlation) and low intraday volatility. The 'Current Result' achieved a higher Information Coefficient (IC) of 0.005822 compared to the SOTA's 0.005798, indicating a slight improvement in the raw predictive power of the signal. However, the risk-adjusted metrics (Information Ratio) and drawdown protection (Max Drawdown) underperformed relative to the SOTA. Among the tested factors, the 'Institutional_Accumulation_Efficiency' and 'Quiet_Trend_Persistence_ZScore' provided more robust normalization than the original IAF_10D by using cross-sectional ranking and smoothed volume denominators.",
        "hypothesis_evaluation": "The hypothesis that linear persistence combined with low volume-weighted volatility identifies sustainable trends is partially supported by the improved IC. The results suggest that the 'linear persistence' component (TS_CORR) is a strong signal, but the 'volatility' denominator needs better scaling. The current implementation of (high-low)/volume can be extremely noisy due to small volume values, which likely led to the higher drawdown and lower IR compared to SOTA.",
        "decision": false,
        "reason": "The current results show that while the predictive correlation (IC) is high, the stability of the return (IR) is lacking. The volume-based denominator in IAF_10D and IAE is prone to outliers. By replacing the volume-weighted range with a pure price-relative range (High-Low)/Close and applying a cross-sectional Rank to both the persistence and the volatility components separately before combining them, we can create a more stable, scale-invariant factor that captures the same 'quiet markup' logic without the instability of volume-driven denominators."
      }
    },
    "cff56aabe0bd256e": {
      "factor_id": "cff56aabe0bd256e",
      "factor_name": "Institutional_Accumulation_Efficiency",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_MEAN(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) / (TS_MEAN(($high - $low) / (TS_MEAN($volume, 10) + 1e-8), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the 'efficiency' of a price move by dividing the 10-day price persistence (R-squared) by the 10-day average of the volume-weighted spread. Higher values indicate the price is moving linearly with minimal volume-induced volatility, characteristic of institutional absorption.",
      "factor_formulation": "IAE = \\frac{\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2}{\\text{TS_MEAN}(\\frac{\\text{high} - \\text{low}}{\\text{TS_MEAN}(\\text{volume}, 10) + 1e-8}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "3b723480152e",
        "parent_trajectory_ids": [
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Institutional Absorption Factor (IAF) identifies sustainable price trends by detecting periods where the 10-day R-squared of price returns is high (indicating linear persistence) while the 5-day volume-weighted price volatility is low, suggesting non-disruptive institutional accumulation.\n                Concise Observation: The parent strategy (LSEF) focused on mean-reversion from 'hollow' price spikes; however, market leaders often exhibit 'efficient' climbs where price moves steadily with minimal intraday noise, signaling a different regime of institutional conviction.\n                Concise Justification: High R-squared values filter for steady directional movement, while low volume-weighted volatility (WVMA) ensures that this movement is not driven by speculative spikes or liquidity gaps, but rather by consistent, controlled buying pressure.\n                Concise Knowledge: If a price trend exhibits high linear persistence (R-squared) alongside low volume-weighted volatility, it likely reflects institutional absorption; such 'quiet' trends are more sustainable than high-volatility breakouts which often lead to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Pearson R-squared of daily close prices against a time index and the inverse of the 5-day moving average of the volume-weighted intraday range ($high-$low)/$volume. It targets trend-following entries in low-noise environments.\n                ",
        "initial_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "planning_direction": "Detect 'Institutional Absorption' by identifying periods of high RSQR10 and low WVMA5: a steady price climb on low relative volume-weighted volatility indicates efficient, non-disruptive buying.",
        "created_at": "2026-01-21T12:20:55.615002"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1191894507604488,
        "ICIR": 0.0423436700109229,
        "1day.excess_return_without_cost.std": 0.004051247398869,
        "1day.excess_return_with_cost.annualized_return": 0.00293898401951,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002105760575969,
        "1day.excess_return_without_cost.annualized_return": 0.050117101708071,
        "1day.excess_return_with_cost.std": 0.0040529893723043,
        "Rank IC": 0.0230786334929141,
        "IC": 0.0058217224994981,
        "1day.excess_return_without_cost.max_drawdown": -0.0953488136540804,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8018787485030696,
        "1day.pa": 0.0,
        "l2.valid": 0.9964740395164088,
        "Rank ICIR": 0.1727121375528159,
        "l2.train": 0.9940822192532732,
        "1day.excess_return_with_cost.information_ratio": 0.0470038337115988,
        "1day.excess_return_with_cost.mean": 1.2348672350882373e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Absorption Factor (IAF) hypothesis, focusing on the synergy between price trend linearity (R-squared/Correlation) and low intraday volatility. The 'Current Result' achieved a higher Information Coefficient (IC) of 0.005822 compared to the SOTA's 0.005798, indicating a slight improvement in the raw predictive power of the signal. However, the risk-adjusted metrics (Information Ratio) and drawdown protection (Max Drawdown) underperformed relative to the SOTA. Among the tested factors, the 'Institutional_Accumulation_Efficiency' and 'Quiet_Trend_Persistence_ZScore' provided more robust normalization than the original IAF_10D by using cross-sectional ranking and smoothed volume denominators.",
        "hypothesis_evaluation": "The hypothesis that linear persistence combined with low volume-weighted volatility identifies sustainable trends is partially supported by the improved IC. The results suggest that the 'linear persistence' component (TS_CORR) is a strong signal, but the 'volatility' denominator needs better scaling. The current implementation of (high-low)/volume can be extremely noisy due to small volume values, which likely led to the higher drawdown and lower IR compared to SOTA.",
        "decision": false,
        "reason": "The current results show that while the predictive correlation (IC) is high, the stability of the return (IR) is lacking. The volume-based denominator in IAF_10D and IAE is prone to outliers. By replacing the volume-weighted range with a pure price-relative range (High-Low)/Close and applying a cross-sectional Rank to both the persistence and the volatility components separately before combining them, we can create a more stable, scale-invariant factor that captures the same 'quiet markup' logic without the instability of volume-driven denominators."
      }
    },
    "1e932506ffc81d44": {
      "factor_id": "1e932506ffc81d44",
      "factor_name": "ILER_Exhaustion_5D",
      "factor_expression": "TS_MEAN(ABS($return) / ($volume + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8)) * TS_STD($return, 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (($close - $low) / ($high - $low + 1e-8)) * TS_STD(TS_PCTCHANGE($close, 1), 5)\" # Your output factor expression will be filled in here\n    name = \"ILER_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Intraday Liquidity Exhaustion Reversal (ILER) factor identifies stocks where price gains are driven by low liquidity (high Amihud ratio) and followed by an intraday fade (close near low). It targets mean-reversion by multiplying the 5-day average illiquidity by the relative closing position within the daily range, conditioned on high volatility.",
      "factor_formulation": "\\text{TS\\_MEAN}(\\frac{|\\text{return}|}{\\text{volume}}, 5) \\times \\frac{\\text{close} - \\text{low}}{\\text{high} - \\text{low} + 1e-8} \\times \\text{TS\\_STD}(\\text{return}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "9ccc7a99227b",
        "parent_trajectory_ids": [
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion Reversal' (ILER) factor: A high ratio of daily price range to volume (Amihud Illiquidity) combined with a closing price near the day's low after a positive return indicates that aggressive buying has exhausted liquidity, predicting a mean-reverting downward correction.\n                Concise Observation: The parent strategy focused on breakout momentum via overnight gaps; however, many intraday trends fail when the price impact per unit of volume becomes excessive, signaling a lack of liquidity depth to sustain the move.\n                Concise Justification: High illiquidity during a price advance suggests that the move was driven by a lack of sell-side depth rather than strong conviction; a subsequent intraday pullback (low close) confirms the exhaustion of the temporary demand shock.\n                Concise Knowledge: If a price trend is achieved on low relative volume with high price impact (illiquidity), the move is likely fragile; when the close-to-low ratio suggests a late-session fade, a reversal is imminent.\n                concise Specification: The factor is defined as the product of the 5-day Amihud Illiquidity ratio (ABS(return)/volume) and the 'Closing Position' within the daily range ((close - low) / (high - low + 1e-8)), specifically targeting stocks with high 5-day price volatility.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T12:24:51.706378"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0940519231086551,
        "ICIR": 0.0294061358516936,
        "1day.excess_return_without_cost.std": 0.0041051808264252,
        "1day.excess_return_with_cost.annualized_return": 0.0157653139990206,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002636286041853,
        "1day.excess_return_without_cost.annualized_return": 0.0627436077961156,
        "1day.excess_return_with_cost.std": 0.0041048671579882,
        "Rank IC": 0.0215884135924361,
        "IC": 0.0041841351276836,
        "1day.excess_return_without_cost.max_drawdown": -0.0815083546062419,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.99071495074564,
        "1day.pa": 0.0,
        "l2.valid": 0.9964717445446064,
        "Rank ICIR": 0.1533004440639324,
        "l2.train": 0.9935982864668176,
        "1day.excess_return_with_cost.information_ratio": 0.2489516674674197,
        "1day.excess_return_with_cost.mean": 6.624081512193568e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Liquidity Exhaustion Reversal' (ILER) hypothesis, testing three variations: a volatility-weighted illiquidity measure (ILER_Exhaustion_5D), a ranked fragility index (Liquidity_Fragility_Index_10D), and a Z-score based interaction model (Amihud_Volatility_Interaction_5D). The performance metrics show a significant improvement in the Information Ratio (0.99 vs 0.97) and Annualized Return (6.27% vs 5.20%) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. This suggests the factors are capturing specific, high-conviction reversal signals effectively, even if the overall correlation (IC) is lower.",
        "hypothesis_evaluation": "The results strongly support the ILER hypothesis. The core concept—that price moves on low liquidity (high Amihud ratio) followed by an intraday retreat (close near low) predict reversals—is validated by the improved risk-adjusted returns. Specifically, the interaction between illiquidity and the intraday price location relative to the range appears to be a robust signal for mean-reversion.",
        "decision": true,
        "reason": "While the current factors use TS_MEAN or TS_ZSCORE of the Amihud ratio, they might be missing the 'divergence' aspect. By specifically looking for days where volatility (High-Low range) increases but volume does not follow (widening the spread/illiquidity), we can isolate 'exhaustion' more precisely. Furthermore, replacing the linear 'close-to-range' ratio with a non-linear threshold (e.g., failing to hold the top quartile) may filter out noise from minor intraday fluctuations."
      }
    },
    "45efd84269ffab43": {
      "factor_id": "45efd84269ffab43",
      "factor_name": "Liquidity_Fragility_Index_10D",
      "factor_expression": "RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 10)) * RANK(($close - $high) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 10)) * RANK(($close - $high) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Fragility_Index_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the fragility of recent price moves by scaling the 10-day Amihud illiquidity ratio against the session's closing strength. A high illiquidity paired with a failure to maintain highs (low close-to-range ratio) suggests that the price advance lacks depth and is prone to reversal.",
      "factor_formulation": "\\text{RANK}(\\text{TS\\_MEAN}(\\frac{|\\text{return}|}{\\text{volume} + 1e-8}, 10)) \\times \\text{RANK}(\\frac{\\text{close} - \\text{high}}{\\text{high} - \\text{low} + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "9ccc7a99227b",
        "parent_trajectory_ids": [
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion Reversal' (ILER) factor: A high ratio of daily price range to volume (Amihud Illiquidity) combined with a closing price near the day's low after a positive return indicates that aggressive buying has exhausted liquidity, predicting a mean-reverting downward correction.\n                Concise Observation: The parent strategy focused on breakout momentum via overnight gaps; however, many intraday trends fail when the price impact per unit of volume becomes excessive, signaling a lack of liquidity depth to sustain the move.\n                Concise Justification: High illiquidity during a price advance suggests that the move was driven by a lack of sell-side depth rather than strong conviction; a subsequent intraday pullback (low close) confirms the exhaustion of the temporary demand shock.\n                Concise Knowledge: If a price trend is achieved on low relative volume with high price impact (illiquidity), the move is likely fragile; when the close-to-low ratio suggests a late-session fade, a reversal is imminent.\n                concise Specification: The factor is defined as the product of the 5-day Amihud Illiquidity ratio (ABS(return)/volume) and the 'Closing Position' within the daily range ((close - low) / (high - low + 1e-8)), specifically targeting stocks with high 5-day price volatility.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T12:24:51.706378"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0940519231086551,
        "ICIR": 0.0294061358516936,
        "1day.excess_return_without_cost.std": 0.0041051808264252,
        "1day.excess_return_with_cost.annualized_return": 0.0157653139990206,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002636286041853,
        "1day.excess_return_without_cost.annualized_return": 0.0627436077961156,
        "1day.excess_return_with_cost.std": 0.0041048671579882,
        "Rank IC": 0.0215884135924361,
        "IC": 0.0041841351276836,
        "1day.excess_return_without_cost.max_drawdown": -0.0815083546062419,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.99071495074564,
        "1day.pa": 0.0,
        "l2.valid": 0.9964717445446064,
        "Rank ICIR": 0.1533004440639324,
        "l2.train": 0.9935982864668176,
        "1day.excess_return_with_cost.information_ratio": 0.2489516674674197,
        "1day.excess_return_with_cost.mean": 6.624081512193568e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Liquidity Exhaustion Reversal' (ILER) hypothesis, testing three variations: a volatility-weighted illiquidity measure (ILER_Exhaustion_5D), a ranked fragility index (Liquidity_Fragility_Index_10D), and a Z-score based interaction model (Amihud_Volatility_Interaction_5D). The performance metrics show a significant improvement in the Information Ratio (0.99 vs 0.97) and Annualized Return (6.27% vs 5.20%) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. This suggests the factors are capturing specific, high-conviction reversal signals effectively, even if the overall correlation (IC) is lower.",
        "hypothesis_evaluation": "The results strongly support the ILER hypothesis. The core concept—that price moves on low liquidity (high Amihud ratio) followed by an intraday retreat (close near low) predict reversals—is validated by the improved risk-adjusted returns. Specifically, the interaction between illiquidity and the intraday price location relative to the range appears to be a robust signal for mean-reversion.",
        "decision": true,
        "reason": "While the current factors use TS_MEAN or TS_ZSCORE of the Amihud ratio, they might be missing the 'divergence' aspect. By specifically looking for days where volatility (High-Low range) increases but volume does not follow (widening the spread/illiquidity), we can isolate 'exhaustion' more precisely. Furthermore, replacing the linear 'close-to-range' ratio with a non-linear threshold (e.g., failing to hold the top quartile) may filter out noise from minor intraday fluctuations."
      }
    },
    "f6301623c208beb0": {
      "factor_id": "f6301623c208beb0",
      "factor_name": "Amihud_Volatility_Interaction_5D",
      "factor_expression": "TS_ZSCORE(ABS($return) / ($volume + 1e-8), 5) * (($high - $close) / ($high - $low + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(ABS(TS_PCTCHANGE($close, 1)) / ($volume + 1e-8), 5) * (($high - $close) / ($high - $low + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Amihud_Volatility_Interaction_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Focuses on the interaction between price impact and volatility. It identifies overextended moves where the price impact per unit of volume is high relative to its 5-day average, weighted by the intraday price retracement from the high.",
      "factor_formulation": "\\text{TS\\_ZSCORE}(\\frac{|\\text{return}|}{\\text{volume} + 1e-8}, 5) * \\frac{\\text{high} - \\text{close}}{\\text{high} - \\text{low} + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "9ccc7a99227b",
        "parent_trajectory_ids": [
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Intraday Liquidity Exhaustion Reversal' (ILER) factor: A high ratio of daily price range to volume (Amihud Illiquidity) combined with a closing price near the day's low after a positive return indicates that aggressive buying has exhausted liquidity, predicting a mean-reverting downward correction.\n                Concise Observation: The parent strategy focused on breakout momentum via overnight gaps; however, many intraday trends fail when the price impact per unit of volume becomes excessive, signaling a lack of liquidity depth to sustain the move.\n                Concise Justification: High illiquidity during a price advance suggests that the move was driven by a lack of sell-side depth rather than strong conviction; a subsequent intraday pullback (low close) confirms the exhaustion of the temporary demand shock.\n                Concise Knowledge: If a price trend is achieved on low relative volume with high price impact (illiquidity), the move is likely fragile; when the close-to-low ratio suggests a late-session fade, a reversal is imminent.\n                concise Specification: The factor is defined as the product of the 5-day Amihud Illiquidity ratio (ABS(return)/volume) and the 'Closing Position' within the daily range ((close - low) / (high - low + 1e-8)), specifically targeting stocks with high 5-day price volatility.\n                ",
        "initial_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "planning_direction": "Synthesize a 'Capitulation Index' using ROC60 and KLOW: extreme long-term price declines (ROC60 > 1) paired with increasing lower shadows suggest the formation of a durable bottom.",
        "created_at": "2026-01-21T12:24:51.706378"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0940519231086551,
        "ICIR": 0.0294061358516936,
        "1day.excess_return_without_cost.std": 0.0041051808264252,
        "1day.excess_return_with_cost.annualized_return": 0.0157653139990206,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002636286041853,
        "1day.excess_return_without_cost.annualized_return": 0.0627436077961156,
        "1day.excess_return_with_cost.std": 0.0041048671579882,
        "Rank IC": 0.0215884135924361,
        "IC": 0.0041841351276836,
        "1day.excess_return_without_cost.max_drawdown": -0.0815083546062419,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.99071495074564,
        "1day.pa": 0.0,
        "l2.valid": 0.9964717445446064,
        "Rank ICIR": 0.1533004440639324,
        "l2.train": 0.9935982864668176,
        "1day.excess_return_with_cost.information_ratio": 0.2489516674674197,
        "1day.excess_return_with_cost.mean": 6.624081512193568e-05
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Intraday Liquidity Exhaustion Reversal' (ILER) hypothesis, testing three variations: a volatility-weighted illiquidity measure (ILER_Exhaustion_5D), a ranked fragility index (Liquidity_Fragility_Index_10D), and a Z-score based interaction model (Amihud_Volatility_Interaction_5D). The performance metrics show a significant improvement in the Information Ratio (0.99 vs 0.97) and Annualized Return (6.27% vs 5.20%) compared to the SOTA, although the IC slightly decreased and the Max Drawdown increased. This suggests the factors are capturing specific, high-conviction reversal signals effectively, even if the overall correlation (IC) is lower.",
        "hypothesis_evaluation": "The results strongly support the ILER hypothesis. The core concept—that price moves on low liquidity (high Amihud ratio) followed by an intraday retreat (close near low) predict reversals—is validated by the improved risk-adjusted returns. Specifically, the interaction between illiquidity and the intraday price location relative to the range appears to be a robust signal for mean-reversion.",
        "decision": true,
        "reason": "While the current factors use TS_MEAN or TS_ZSCORE of the Amihud ratio, they might be missing the 'divergence' aspect. By specifically looking for days where volatility (High-Low range) increases but volume does not follow (widening the spread/illiquidity), we can isolate 'exhaustion' more precisely. Furthermore, replacing the linear 'close-to-range' ratio with a non-linear threshold (e.g., failing to hold the top quartile) may filter out noise from minor intraday fluctuations."
      }
    },
    "dbb0fe49c55eecc7": {
      "factor_id": "dbb0fe49c55eecc7",
      "factor_name": "VPDS_Divergence_Index_20D",
      "factor_expression": "(1 - TS_CORR($return, $volume, 20)) * (POW(REGBETA($close, SEQUENCE(10), 10), 2) * TS_VAR(SEQUENCE(10), 10) / (TS_VAR($close, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), $volume, 20))\" # Your output factor expression will be filled in here\n    name = \"VPDS_Divergence_Index_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies trend exhaustion by multiplying the 10-day price trend linearity (R-squared) with the inverse of the 20-day price-volume correlation. High values indicate a strong price trend that is losing volume support, suggesting a potential reversal.",
      "factor_formulation": "\\text{RSQR10} = \\frac{\\text{REGBETA}(\\text{close}, \\text{SEQ}(10), 10)^2 \\times \\text{TS\\_VAR}(\\text{SEQ}(10), 10)}{\\text{TS\\_VAR}(\\text{close}, 10)}, \\text{Factor} = (1 - \\text{TS\\_CORR}(\\text{return}, \\text{volume}, 20)) \\times \\text{RSQR10}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "df0b36290d2b",
        "parent_trajectory_ids": [
          "5b355730b825"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Price Divergence Stability' (VPDS) factor, defined as the interaction between the 20-day price-volume correlation and the 10-day price trend R-squared, predicts trend exhaustion or reversal when a high-certainty price trend (high R-squared) is accompanied by declining volume support (low correlation).\n                Concise Observation: The parent strategy focused on volatility compression and breakout gaps, whereas market data often shows that the most 'perfect' looking trends (high R-squared) frequently fail when volume fails to confirm the price movement, suggesting a divergence-based exhaustion.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if the correlation between price changes and volume turns negative or near-zero, it suggests that the price is moving on 'thin air' without institutional participation, leading to a structural fragility.\n                Concise Knowledge: If a price trend exhibits high linear persistence but loses its positive correlation with volume, the trend is likely driven by liquidity depletion rather than conviction; when R-squared is high and CORR(Price, Volume) is low, a reversal is imminent.\n                concise Specification: Calculate the 20-day Pearson correlation between daily returns and volume (CORR20) and the 10-day R-squared of price against a time index (RSQR10); the factor is the product of (1 - CORR20) and RSQR10 to highlight high-certainty trends with low volume support.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T12:36:25.845432"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0835560975837344,
        "ICIR": 0.0316280820347688,
        "1day.excess_return_without_cost.std": 0.0044306461250762,
        "1day.excess_return_with_cost.annualized_return": 0.0335549157373347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003405950890439,
        "1day.excess_return_without_cost.annualized_return": 0.0810616311924554,
        "1day.excess_return_with_cost.std": 0.0044333809093015,
        "Rank IC": 0.0204878043756415,
        "IC": 0.0042095562459937,
        "1day.excess_return_without_cost.max_drawdown": -0.0584526007267863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1859320219408709,
        "1day.pa": 0.0,
        "l2.valid": 0.996383224490512,
        "Rank ICIR": 0.1597292714011644,
        "l2.train": 0.993573119686708,
        "1day.excess_return_with_cost.information_ratio": 0.4906057424207661,
        "1day.excess_return_with_cost.mean": 0.0001409870409131
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Volume-Price Divergence Stability' (VPDS) framework, testing three variations: a regression-based divergence index, a rank-based fragility score, and an exhaustion ratio. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and annualized returns (from 5.2% to 8.1%), while also reducing the Maximum Drawdown. However, the Information Coefficient (IC) saw a slight decrease from 0.0058 to 0.0042, suggesting that while the new factors are better at identifying high-conviction turning points (improving tail performance/portfolio metrics), they may have lower overall predictive correlation across the entire universe.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that capturing the divergence between price trend certainty and volume support predicts reversals. The 'VPDS_Divergence_Index_20D' and 'Trend_Fragility_Score_15D' effectively translate the theoretical 'exhaustion' into tradable signals. The improvement in Information Ratio suggests that the interaction between R-squared (trend linearity) and Price-Volume correlation is a robust risk-management signal.",
        "decision": true,
        "reason": "While the current R-squared approach is effective, it only measures linear fit. Trends often accelerate before reversing (climax). By replacing the linear REGBETA/RSQR with a measure of price acceleration or a shorter-term momentum Z-score, and refining the volume component to look at volume 'shocks' (Z-score of volume) relative to price movement, we can improve the IC. The current complexity is manageable, but we should aim to simplify the RSQR calculation to improve generalization."
      }
    },
    "f669ad580eac7e3b": {
      "factor_id": "f669ad580eac7e3b",
      "factor_name": "Trend_Fragility_Score_15D",
      "factor_expression": "RANK(TS_RANK($close, 15)) * RANK(1 - TS_CORR($return, $volume, 15))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_RANK($close, 15)) * RANK(1 - TS_CORR(TS_PCTCHANGE($close, 1), $volume, 15))\" # Your output factor expression will be filled in here\n    name = \"Trend_Fragility_Score_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified measure of trend fragility that captures the cross-sectional rank of price persistence (TS_RANK of price over 15 days) weighted by the cross-sectional rank of volume-return divergence. It targets stocks where the price is at a local high but volume participation is declining.",
      "factor_formulation": "\\text{Factor} = \\text{RANK}(\\text{TS\\_RANK}(\\text{close}, 15)) \\times \\text{RANK}(1 - \\text{TS\\_CORR}(\\text{return}, \\text{volume}, 15))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "df0b36290d2b",
        "parent_trajectory_ids": [
          "5b355730b825"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Price Divergence Stability' (VPDS) factor, defined as the interaction between the 20-day price-volume correlation and the 10-day price trend R-squared, predicts trend exhaustion or reversal when a high-certainty price trend (high R-squared) is accompanied by declining volume support (low correlation).\n                Concise Observation: The parent strategy focused on volatility compression and breakout gaps, whereas market data often shows that the most 'perfect' looking trends (high R-squared) frequently fail when volume fails to confirm the price movement, suggesting a divergence-based exhaustion.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if the correlation between price changes and volume turns negative or near-zero, it suggests that the price is moving on 'thin air' without institutional participation, leading to a structural fragility.\n                Concise Knowledge: If a price trend exhibits high linear persistence but loses its positive correlation with volume, the trend is likely driven by liquidity depletion rather than conviction; when R-squared is high and CORR(Price, Volume) is low, a reversal is imminent.\n                concise Specification: Calculate the 20-day Pearson correlation between daily returns and volume (CORR20) and the 10-day R-squared of price against a time index (RSQR10); the factor is the product of (1 - CORR20) and RSQR10 to highlight high-certainty trends with low volume support.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T12:36:25.845432"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0835560975837344,
        "ICIR": 0.0316280820347688,
        "1day.excess_return_without_cost.std": 0.0044306461250762,
        "1day.excess_return_with_cost.annualized_return": 0.0335549157373347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003405950890439,
        "1day.excess_return_without_cost.annualized_return": 0.0810616311924554,
        "1day.excess_return_with_cost.std": 0.0044333809093015,
        "Rank IC": 0.0204878043756415,
        "IC": 0.0042095562459937,
        "1day.excess_return_without_cost.max_drawdown": -0.0584526007267863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1859320219408709,
        "1day.pa": 0.0,
        "l2.valid": 0.996383224490512,
        "Rank ICIR": 0.1597292714011644,
        "l2.train": 0.993573119686708,
        "1day.excess_return_with_cost.information_ratio": 0.4906057424207661,
        "1day.excess_return_with_cost.mean": 0.0001409870409131
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Volume-Price Divergence Stability' (VPDS) framework, testing three variations: a regression-based divergence index, a rank-based fragility score, and an exhaustion ratio. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and annualized returns (from 5.2% to 8.1%), while also reducing the Maximum Drawdown. However, the Information Coefficient (IC) saw a slight decrease from 0.0058 to 0.0042, suggesting that while the new factors are better at identifying high-conviction turning points (improving tail performance/portfolio metrics), they may have lower overall predictive correlation across the entire universe.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that capturing the divergence between price trend certainty and volume support predicts reversals. The 'VPDS_Divergence_Index_20D' and 'Trend_Fragility_Score_15D' effectively translate the theoretical 'exhaustion' into tradable signals. The improvement in Information Ratio suggests that the interaction between R-squared (trend linearity) and Price-Volume correlation is a robust risk-management signal.",
        "decision": true,
        "reason": "While the current R-squared approach is effective, it only measures linear fit. Trends often accelerate before reversing (climax). By replacing the linear REGBETA/RSQR with a measure of price acceleration or a shorter-term momentum Z-score, and refining the volume component to look at volume 'shocks' (Z-score of volume) relative to price movement, we can improve the IC. The current complexity is manageable, but we should aim to simplify the RSQR calculation to improve generalization."
      }
    },
    "f6e0cd6df362a9c3": {
      "factor_id": "f6e0cd6df362a9c3",
      "factor_name": "Volume_Exhaustion_Ratio_10D",
      "factor_expression": "(ABS(TS_PCTCHANGE($close, 10)) / (TS_STD($return, 10) + 1e-8)) / (1 + TS_CORR(ABS($return), $volume, 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS(TS_PCTCHANGE($close, 10)) / (TS_STD(TS_PCTCHANGE($close, 1), 10) + 1e-8)) / (1 + TS_CORR(ABS(TS_PCTCHANGE($close, 1)), $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Volume_Exhaustion_Ratio_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the ratio of price trend strength to volume confirmation. It uses the absolute 10-day return normalized by volatility, divided by the 10-day correlation between volume and price change magnitude.",
      "factor_formulation": "\\text{Factor} = \\frac{\\text{ABS}(\\text{TS\\_PCTCHANGE}(\\text{close}, 10)) / \\text{TS\\_STD}(\\text{return}, 10)}{1 + \\text{TS\\_CORR}(\\text{ABS}(\\text{return}), \\text{volume}, 10)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 9,
        "evolution_phase": "mutation",
        "trajectory_id": "df0b36290d2b",
        "parent_trajectory_ids": [
          "5b355730b825"
        ],
        "hypothesis": "Hypothesis: The 'Volume-Price Divergence Stability' (VPDS) factor, defined as the interaction between the 20-day price-volume correlation and the 10-day price trend R-squared, predicts trend exhaustion or reversal when a high-certainty price trend (high R-squared) is accompanied by declining volume support (low correlation).\n                Concise Observation: The parent strategy focused on volatility compression and breakout gaps, whereas market data often shows that the most 'perfect' looking trends (high R-squared) frequently fail when volume fails to confirm the price movement, suggesting a divergence-based exhaustion.\n                Concise Justification: High R-squared indicates a consensus-driven trend, but if the correlation between price changes and volume turns negative or near-zero, it suggests that the price is moving on 'thin air' without institutional participation, leading to a structural fragility.\n                Concise Knowledge: If a price trend exhibits high linear persistence but loses its positive correlation with volume, the trend is likely driven by liquidity depletion rather than conviction; when R-squared is high and CORR(Price, Volume) is low, a reversal is imminent.\n                concise Specification: Calculate the 20-day Pearson correlation between daily returns and volume (CORR20) and the 10-day R-squared of price against a time index (RSQR10); the factor is the product of (1 - CORR20) and RSQR10 to highlight high-certainty trends with low volume support.\n                ",
        "initial_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "planning_direction": "Assess 'Volume-Price Divergence' by interacting CORR20 with RSQR10: a high R-squared trend that loses its correlation with volume often precedes a trend reversal or consolidation.",
        "created_at": "2026-01-21T12:36:25.845432"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0835560975837344,
        "ICIR": 0.0316280820347688,
        "1day.excess_return_without_cost.std": 0.0044306461250762,
        "1day.excess_return_with_cost.annualized_return": 0.0335549157373347,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003405950890439,
        "1day.excess_return_without_cost.annualized_return": 0.0810616311924554,
        "1day.excess_return_with_cost.std": 0.0044333809093015,
        "Rank IC": 0.0204878043756415,
        "IC": 0.0042095562459937,
        "1day.excess_return_without_cost.max_drawdown": -0.0584526007267863,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.1859320219408709,
        "1day.pa": 0.0,
        "l2.valid": 0.996383224490512,
        "Rank ICIR": 0.1597292714011644,
        "l2.train": 0.993573119686708,
        "1day.excess_return_with_cost.information_ratio": 0.4906057424207661,
        "1day.excess_return_with_cost.mean": 0.0001409870409131
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Volume-Price Divergence Stability' (VPDS) framework, testing three variations: a regression-based divergence index, a rank-based fragility score, and an exhaustion ratio. The results show a significant improvement in risk-adjusted returns (Information Ratio increased from 0.97 to 1.18) and annualized returns (from 5.2% to 8.1%), while also reducing the Maximum Drawdown. However, the Information Coefficient (IC) saw a slight decrease from 0.0058 to 0.0042, suggesting that while the new factors are better at identifying high-conviction turning points (improving tail performance/portfolio metrics), they may have lower overall predictive correlation across the entire universe.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that capturing the divergence between price trend certainty and volume support predicts reversals. The 'VPDS_Divergence_Index_20D' and 'Trend_Fragility_Score_15D' effectively translate the theoretical 'exhaustion' into tradable signals. The improvement in Information Ratio suggests that the interaction between R-squared (trend linearity) and Price-Volume correlation is a robust risk-management signal.",
        "decision": true,
        "reason": "While the current R-squared approach is effective, it only measures linear fit. Trends often accelerate before reversing (climax). By replacing the linear REGBETA/RSQR with a measure of price acceleration or a shorter-term momentum Z-score, and refining the volume component to look at volume 'shocks' (Z-score of volume) relative to price movement, we can improve the IC. The current complexity is manageable, but we should aim to simplify the RSQR calculation to improve generalization."
      }
    },
    "f61362cad2ae4bff": {
      "factor_id": "f61362cad2ae4bff",
      "factor_name": "IILV_Momentum_Stability_20D",
      "factor_expression": "(($open / DELAY($close, 1) - 1) / (TS_STD($close, 15) / (TS_MEAN($close, 15) + 1e-8) + 1e-8)) * (DELTA($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1) - 1) / (TS_STD($close, 15) / (TS_MEAN($close, 15) + 1e-8) + 1e-8)) * (DELTA($close, 20) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"IILV_Momentum_Stability_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies high-conviction trends by combining a volatility-normalized overnight gap with volume-stability-weighted momentum. It captures breakouts that occur from low-volatility states and are supported by steady capital flows, reducing the impact of erratic retail speculation.",
      "factor_formulation": "\\text{IILV} = \\left( \\frac{\\text{open} / \\text{delay}(\\text{close}, 1) - 1}{\\text{TS_STD}(\\text{close}, 15) / \\text{TS_MEAN}(\\text{close}, 15) + 1e-8} \\right) \\times \\left( (\\text{close} - \\text{delay}(\\text{close}, 20)) \\times \\frac{\\text{TS_MEAN}(\\text{volume}, 20)}{\\text{TS_STD}(\\text{volume}, 20) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "f5c2f570cbf7",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Liquidity Vacuum' (IILV) factor identifies high-conviction trends by multiplying the 1-day overnight price gap (normalized by 15-day volatility compression) with the 20-day volume-stability-weighted momentum, capturing breakouts that possess both immediate institutional entry and structural capital persistence.\n                Concise Observation: Parent 1 showed that volume-volatility-adjusted momentum (RankIC 0.0249) captures trend sustainability, while Parent 2 showed that volatility-compressed breakouts (RankIC 0.0287) provide strong entry signals; however, individual signals often suffer from false breakouts or decaying momentum.\n                Concise Justification: Combining short-term overnight gaps with medium-term inertial persistence filters out 'noisy' breakouts; scaling the signal by the inverse of volume volatility ensures that only breakouts supported by steady, non-erratic capital flows are prioritized.\n                Concise Knowledge: If a price breakout occurs from a low-volatility state (volatility compression) and is accompanied by high volume stability (low volume variance relative to its mean), the resulting trend is more likely to persist due to institutional accumulation rather than retail speculation.\n                concise Specification: The factor is defined as: [($open / $close.shift(1) - 1) / (std($close, 15) / mean($close, 15))] * [mean($close - $close.shift(20), 1) * (mean($volume, 20) / (std($volume, 20) + 1e-6))]. This integrates a 15-day volatility compression ratio, a 1-day gap, and a 20-day volume-weighted momentum.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:40:01.110042"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1416466447967556,
        "ICIR": 0.0480657888890976,
        "1day.excess_return_without_cost.std": 0.0043733217550421,
        "1day.excess_return_with_cost.annualized_return": 0.0015565608927098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002041011487076,
        "1day.excess_return_without_cost.annualized_return": 0.0485760733924271,
        "1day.excess_return_with_cost.std": 0.0043753569601605,
        "Rank IC": 0.0224019762465862,
        "IC": 0.0061841072725354,
        "1day.excess_return_without_cost.max_drawdown": -0.1106947286823017,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7199834224914314,
        "1day.pa": 0.0,
        "l2.valid": 0.9963663934296204,
        "Rank ICIR": 0.1787582628102196,
        "l2.train": 0.9933531259128724,
        "1day.excess_return_with_cost.information_ratio": 0.0230602571579243,
        "1day.excess_return_with_cost.mean": 6.54017181810842e-06
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Inertia & Liquidity Vacuum' (IILV) hypothesis, testing three variations: a multiplicative raw-value factor, a dual-rank version, and an additive Z-score version. The results show a significant improvement in the Information Coefficient (IC) reaching 0.006184, which is higher than the SOTA result (0.005798). However, the risk-adjusted returns (Information Ratio) and drawdown metrics (Max Drawdown) have deteriorated compared to the SOTA. Specifically, while the IC is higher, the Information Ratio dropped from 0.97 to 0.72, and the Max Drawdown increased from -0.07 to -0.11, suggesting that while the signal's predictive correlation improved, its stability and tail-risk profile worsened.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with volume-stability-weighted momentum identifies high-conviction trends is partially supported by the improved IC. The 'Institutional_Flow_Persistence_Factor' (additive Z-score) likely contributed to the predictive power but introduced higher volatility. The multiplicative interaction in 'IILV_Momentum_Stability_20D' might be creating extreme values that lead to higher drawdowns. The 'Liquidity Vacuum' concept (using Volume CV as a denominator) is effective for signal strength but requires better normalization to prevent outlier-driven turnover.",
        "decision": false,
        "reason": "The current multiplicative and additive models are capturing the signal but also amplifying noise, as evidenced by the higher IC but lower IR and worse drawdown. By applying a 'SQUASH' or 'RANK' transformation to the volatility-normalized gap and then multiplying it by a long-term momentum signal that is strictly filtered for low volume-variance, we can isolate the 'Inertia' without the 'Volatility' penalty. Transitioning from raw price changes to log-returns or using a more robust measure of volume stability ( like the 20-day median volume relative to its standard deviation) should improve the Information Ratio."
      }
    },
    "80525514209d9a23": {
      "factor_id": "80525514209d9a23",
      "factor_name": "Ranked_IILV_Compression_Signal",
      "factor_expression": "RANK(TS_PCTCHANGE($open, 1) / (TS_STD($return, 15) + 1e-8)) * RANK(DELTA($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1) - 1) / (TS_STD(TS_PCTCHANGE($close, 1), 15) + 1e-8)) * RANK(DELTA($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_IILV_Compression_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally robust version of the Institutional Inertia factor. It uses RANK to normalize the overnight gap relative to volatility compression and multiplies it by the volume-stability-adjusted price change over 20 days to isolate institutional accumulation patterns.",
      "factor_formulation": "\\text{Ranked_IILV} = \\text{RANK}\\left(\\frac{\\text{TS_PCTCHANGE}(\\text{open}, 1)}{\\text{TS_STD}(\\text{return}, 15) + 1e-8}\\right) \\times \\text{RANK}\\left(\\frac{\\text{DELTA}(\\text{close}, 20)}{\\text{TS_STD}(\\text{volume}, 20) / \\text{TS_MEAN}(\\text{volume}, 20) + 1e-8}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "f5c2f570cbf7",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Liquidity Vacuum' (IILV) factor identifies high-conviction trends by multiplying the 1-day overnight price gap (normalized by 15-day volatility compression) with the 20-day volume-stability-weighted momentum, capturing breakouts that possess both immediate institutional entry and structural capital persistence.\n                Concise Observation: Parent 1 showed that volume-volatility-adjusted momentum (RankIC 0.0249) captures trend sustainability, while Parent 2 showed that volatility-compressed breakouts (RankIC 0.0287) provide strong entry signals; however, individual signals often suffer from false breakouts or decaying momentum.\n                Concise Justification: Combining short-term overnight gaps with medium-term inertial persistence filters out 'noisy' breakouts; scaling the signal by the inverse of volume volatility ensures that only breakouts supported by steady, non-erratic capital flows are prioritized.\n                Concise Knowledge: If a price breakout occurs from a low-volatility state (volatility compression) and is accompanied by high volume stability (low volume variance relative to its mean), the resulting trend is more likely to persist due to institutional accumulation rather than retail speculation.\n                concise Specification: The factor is defined as: [($open / $close.shift(1) - 1) / (std($close, 15) / mean($close, 15))] * [mean($close - $close.shift(20), 1) * (mean($volume, 20) / (std($volume, 20) + 1e-6))]. This integrates a 15-day volatility compression ratio, a 1-day gap, and a 20-day volume-weighted momentum.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:40:01.110042"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1416466447967556,
        "ICIR": 0.0480657888890976,
        "1day.excess_return_without_cost.std": 0.0043733217550421,
        "1day.excess_return_with_cost.annualized_return": 0.0015565608927098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002041011487076,
        "1day.excess_return_without_cost.annualized_return": 0.0485760733924271,
        "1day.excess_return_with_cost.std": 0.0043753569601605,
        "Rank IC": 0.0224019762465862,
        "IC": 0.0061841072725354,
        "1day.excess_return_without_cost.max_drawdown": -0.1106947286823017,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7199834224914314,
        "1day.pa": 0.0,
        "l2.valid": 0.9963663934296204,
        "Rank ICIR": 0.1787582628102196,
        "l2.train": 0.9933531259128724,
        "1day.excess_return_with_cost.information_ratio": 0.0230602571579243,
        "1day.excess_return_with_cost.mean": 6.54017181810842e-06
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Inertia & Liquidity Vacuum' (IILV) hypothesis, testing three variations: a multiplicative raw-value factor, a dual-rank version, and an additive Z-score version. The results show a significant improvement in the Information Coefficient (IC) reaching 0.006184, which is higher than the SOTA result (0.005798). However, the risk-adjusted returns (Information Ratio) and drawdown metrics (Max Drawdown) have deteriorated compared to the SOTA. Specifically, while the IC is higher, the Information Ratio dropped from 0.97 to 0.72, and the Max Drawdown increased from -0.07 to -0.11, suggesting that while the signal's predictive correlation improved, its stability and tail-risk profile worsened.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with volume-stability-weighted momentum identifies high-conviction trends is partially supported by the improved IC. The 'Institutional_Flow_Persistence_Factor' (additive Z-score) likely contributed to the predictive power but introduced higher volatility. The multiplicative interaction in 'IILV_Momentum_Stability_20D' might be creating extreme values that lead to higher drawdowns. The 'Liquidity Vacuum' concept (using Volume CV as a denominator) is effective for signal strength but requires better normalization to prevent outlier-driven turnover.",
        "decision": false,
        "reason": "The current multiplicative and additive models are capturing the signal but also amplifying noise, as evidenced by the higher IC but lower IR and worse drawdown. By applying a 'SQUASH' or 'RANK' transformation to the volatility-normalized gap and then multiplying it by a long-term momentum signal that is strictly filtered for low volume-variance, we can isolate the 'Inertia' without the 'Volatility' penalty. Transitioning from raw price changes to log-returns or using a more robust measure of volume stability ( like the 20-day median volume relative to its standard deviation) should improve the Information Ratio."
      }
    },
    "f1cd5e9260bbf254": {
      "factor_id": "f1cd5e9260bbf254",
      "factor_name": "Institutional_Flow_Persistence_Factor",
      "factor_expression": "ZSCORE(DELTA($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)) + ZSCORE($open / DELAY($close, 1) - 1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(DELTA($close, 20) / (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8)) + ZSCORE($open / DELAY($close, 1) - 1)\" # Your output factor expression will be filled in here\n    name = \"Institutional_Flow_Persistence_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor focuses on the 'Liquidity Vacuum' aspect by measuring the 20-day price trend scaled by the inverse of volume volatility (Volume CV), further filtered by the 1-day gap magnitude to ensure the trend is initiated by a strong entry signal.",
      "factor_formulation": "\\text{IFP} = \\text{ZSCORE}\\left( \\frac{\\text{DELTA}(\\text{close}, 20)}{\\text{TS_STD}(\\text{volume}, 20) / \\text{TS_MEAN}(\\text{volume}, 20) + 1e-8} \\right) + \\text{ZSCORE}(\\text{open} / \\text{delay}(\\text{close}, 1) - 1)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "f5c2f570cbf7",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Liquidity Vacuum' (IILV) factor identifies high-conviction trends by multiplying the 1-day overnight price gap (normalized by 15-day volatility compression) with the 20-day volume-stability-weighted momentum, capturing breakouts that possess both immediate institutional entry and structural capital persistence.\n                Concise Observation: Parent 1 showed that volume-volatility-adjusted momentum (RankIC 0.0249) captures trend sustainability, while Parent 2 showed that volatility-compressed breakouts (RankIC 0.0287) provide strong entry signals; however, individual signals often suffer from false breakouts or decaying momentum.\n                Concise Justification: Combining short-term overnight gaps with medium-term inertial persistence filters out 'noisy' breakouts; scaling the signal by the inverse of volume volatility ensures that only breakouts supported by steady, non-erratic capital flows are prioritized.\n                Concise Knowledge: If a price breakout occurs from a low-volatility state (volatility compression) and is accompanied by high volume stability (low volume variance relative to its mean), the resulting trend is more likely to persist due to institutional accumulation rather than retail speculation.\n                concise Specification: The factor is defined as: [($open / $close.shift(1) - 1) / (std($close, 15) / mean($close, 15))] * [mean($close - $close.shift(20), 1) * (mean($volume, 20) / (std($volume, 20) + 1e-6))]. This integrates a 15-day volatility compression ratio, a 1-day gap, and a 20-day volume-weighted momentum.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:40:01.110042"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1416466447967556,
        "ICIR": 0.0480657888890976,
        "1day.excess_return_without_cost.std": 0.0043733217550421,
        "1day.excess_return_with_cost.annualized_return": 0.0015565608927098,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002041011487076,
        "1day.excess_return_without_cost.annualized_return": 0.0485760733924271,
        "1day.excess_return_with_cost.std": 0.0043753569601605,
        "Rank IC": 0.0224019762465862,
        "IC": 0.0061841072725354,
        "1day.excess_return_without_cost.max_drawdown": -0.1106947286823017,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7199834224914314,
        "1day.pa": 0.0,
        "l2.valid": 0.9963663934296204,
        "Rank ICIR": 0.1787582628102196,
        "l2.train": 0.9933531259128724,
        "1day.excess_return_with_cost.information_ratio": 0.0230602571579243,
        "1day.excess_return_with_cost.mean": 6.54017181810842e-06
      },
      "feedback": {
        "observations": "The current iteration focused on the 'Institutional Inertia & Liquidity Vacuum' (IILV) hypothesis, testing three variations: a multiplicative raw-value factor, a dual-rank version, and an additive Z-score version. The results show a significant improvement in the Information Coefficient (IC) reaching 0.006184, which is higher than the SOTA result (0.005798). However, the risk-adjusted returns (Information Ratio) and drawdown metrics (Max Drawdown) have deteriorated compared to the SOTA. Specifically, while the IC is higher, the Information Ratio dropped from 0.97 to 0.72, and the Max Drawdown increased from -0.07 to -0.11, suggesting that while the signal's predictive correlation improved, its stability and tail-risk profile worsened.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with volume-stability-weighted momentum identifies high-conviction trends is partially supported by the improved IC. The 'Institutional_Flow_Persistence_Factor' (additive Z-score) likely contributed to the predictive power but introduced higher volatility. The multiplicative interaction in 'IILV_Momentum_Stability_20D' might be creating extreme values that lead to higher drawdowns. The 'Liquidity Vacuum' concept (using Volume CV as a denominator) is effective for signal strength but requires better normalization to prevent outlier-driven turnover.",
        "decision": false,
        "reason": "The current multiplicative and additive models are capturing the signal but also amplifying noise, as evidenced by the higher IC but lower IR and worse drawdown. By applying a 'SQUASH' or 'RANK' transformation to the volatility-normalized gap and then multiplying it by a long-term momentum signal that is strictly filtered for low volume-variance, we can isolate the 'Inertia' without the 'Volatility' penalty. Transitioning from raw price changes to log-returns or using a more robust measure of volume stability ( like the 20-day median volume relative to its standard deviation) should improve the Information Ratio."
      }
    },
    "eade94a8c64a1f82": {
      "factor_id": "eade94a8c64a1f82",
      "factor_name": "ICB_Factor_10D_5D",
      "factor_expression": "(TS_MEAN(($close - $open) / ($high - $low + 1e-8) * $volume, 10) / (TS_STD(($high - $low) / ($close + 1e-8), 10) + 1e-8)) * (($open - DELAY($close, 1)) / (TS_STD(LOG($close / DELAY($close, 1)), 15) + 1e-6))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(($close - $open) / ($high - $low + 1e-8) * $volume, 10) / (TS_STD(($high - $low) / ($close + 1e-8), 10) + 1e-8)) * (($open - DELAY($close, 1)) / (TS_STD(LOG($close / DELAY($close, 1)), 15) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"ICB_Factor_10D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Informed Compression-Breakout (ICB) factor identifies high-conviction trends by combining a 10-day Micro-Structural Information Asymmetry (MSIA) score with a volatility-adjusted overnight gap. It filters for stocks where informed accumulation (high volume-weighted directionality and low intraday dispersion) is followed by a significant overnight breakout relative to historical volatility.",
      "factor_formulation": "ICB = \\left( \\frac{TS\\_MEAN(\\frac{close-open}{high-low+1e-8} \\times volume, 10)}{TS\\_STD(\\frac{high-low}{close+1e-8}, 10) + 1e-8} \\right) \\times \\left( \\frac{open - DELAY(close, 1)}{TS\\_STD(LOG(close/DELAY(close, 1)), 15) + 1e-6} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "93de3acb823a",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Compression-Breakout' (ICB) factor, calculated as the product of a 10-day Micro-Structural Information Asymmetry (MSIA) score and a 5-day Volatility-Adjusted Overnight Gap, identifies high-conviction trends by filtering breakout triggers with evidence of stealthy informed accumulation.\n                Concise Observation: Parent 1 (MSIA) excels at identifying accumulation but lacks timing, while Parent 2 (EVIB) identifies breakouts but is prone to 'fake-outs' without structural support; both utilize price-volume relationships and volatility compression to predict short-term returns.\n                Concise Justification: By multiplying the MSIA score (accumulation filter) with the EVIB gap metric (breakout trigger), the factor ensures that only those price gaps occurring after a period of informed positioning and low dispersion are prioritized, maximizing the signal-to-noise ratio.\n                Concise Knowledge: If a period of low intraday price dispersion is accompanied by high volume-weighted price directionality, it indicates informed accumulation; when this state is followed by an overnight price gap during a period of low historical volatility, the subsequent breakout is more likely to be persistent.\n                concise Specification: The factor is defined as: [Mean( (Close-Open)/(High-Low) * Volume, 10) / Std( (High-Low)/Close, 10 )] * [(Open - Close[t-1]) / (Std(Log(Close/Close[t-1]), 15) + 1e-6)]. It targets assets with high directional efficiency and low intraday range, coupled with significant overnight momentum relative to recent volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:43:42.264921"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1330550182538235,
        "ICIR": 0.0339954268033133,
        "1day.excess_return_without_cost.std": 0.0043163462086389,
        "1day.excess_return_with_cost.annualized_return": -0.0105245100911624,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001545397825286,
        "1day.excess_return_without_cost.annualized_return": 0.0367804682418305,
        "1day.excess_return_with_cost.std": 0.0043163876925111,
        "Rank IC": 0.0214279954692257,
        "IC": 0.0046733287338853,
        "1day.excess_return_without_cost.max_drawdown": -0.0782602794765694,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5523476411746017,
        "1day.pa": 0.0,
        "l2.valid": 0.9966364718538696,
        "Rank ICIR": 0.1586207603304279,
        "l2.train": 0.9940271733512288,
        "1day.excess_return_with_cost.information_ratio": -0.1580494412374032,
        "1day.excess_return_with_cost.mean": -4.422063063513647e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Informed Compression-Breakout' (ICB) framework. While the core hypothesis (ICB_Factor_10D_5D) and its components (IAR and VAGT) were implemented, the combined results show a deterioration compared to the current SOTA. The Information Ratio (0.552 vs 0.972) and IC (0.0046 vs 0.0057) are significantly lower, suggesting that the current mathematical formulation of 'informed accumulation' might be too noisy or that the interaction between the accumulation score and the overnight gap is not additive/multiplicative in the way currently defined.",
        "hypothesis_evaluation": "The results partially refute the current implementation of the ICB hypothesis. While the logic of combining accumulation with breakout triggers is sound, the 'Informed_Accumulation_Rank' (IAR) likely suffers from high noise by using raw volume without normalization against a longer-term baseline. Furthermore, the ICB_Factor_10D_5D has a relatively high complexity in its formulation (multiple nested ratios and standard deviations), which may lead to poor generalization as seen in the lower IR.",
        "decision": false,
        "reason": "1. Complexity Reduction: The current ICB factor uses 5 base features and multiple nested TS_STD functions. Simplifying the 'accumulation' measure to a ratio of recent volume vs. 20-day average volume will reduce noise. 2. Better Normalization: Instead of using TS_STD of (high-low)/close, using a RANK of the intraday range relative to volume surge ensures we capture 'stealth' (low price movement on high volume) more robustly across different market regimes. 3. Interaction: Using a conditional logic or a simpler Z-score for the gap will likely perform better than a direct product of two high-variance signals."
      }
    },
    "f798dbe3f07233a4": {
      "factor_id": "f798dbe3f07233a4",
      "factor_name": "Informed_Accumulation_Rank_10D",
      "factor_expression": "RANK(TS_MEAN(($close - $open) / ($close + 1e-8) * $volume, 10) / (TS_STD(($high - $low) / ($close + 1e-8), 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $open) / ($close + 1e-8) * $volume, 10) / (TS_STD(($high - $low) / ($close + 1e-8), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Informed_Accumulation_Rank_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified component of the ICB hypothesis focusing on the Micro-Structural Information Asymmetry (MSIA). It ranks assets based on the ratio of volume-weighted price movement to intraday price dispersion over 10 days. High values indicate stealthy accumulation by informed players during periods of low volatility.",
      "factor_formulation": "IAR = RANK\\left( \\frac{TS\\_MEAN((close-open)/close \\times volume, 10)}{TS\\_STD((high-low)/close, 10) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "93de3acb823a",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Compression-Breakout' (ICB) factor, calculated as the product of a 10-day Micro-Structural Information Asymmetry (MSIA) score and a 5-day Volatility-Adjusted Overnight Gap, identifies high-conviction trends by filtering breakout triggers with evidence of stealthy informed accumulation.\n                Concise Observation: Parent 1 (MSIA) excels at identifying accumulation but lacks timing, while Parent 2 (EVIB) identifies breakouts but is prone to 'fake-outs' without structural support; both utilize price-volume relationships and volatility compression to predict short-term returns.\n                Concise Justification: By multiplying the MSIA score (accumulation filter) with the EVIB gap metric (breakout trigger), the factor ensures that only those price gaps occurring after a period of informed positioning and low dispersion are prioritized, maximizing the signal-to-noise ratio.\n                Concise Knowledge: If a period of low intraday price dispersion is accompanied by high volume-weighted price directionality, it indicates informed accumulation; when this state is followed by an overnight price gap during a period of low historical volatility, the subsequent breakout is more likely to be persistent.\n                concise Specification: The factor is defined as: [Mean( (Close-Open)/(High-Low) * Volume, 10) / Std( (High-Low)/Close, 10 )] * [(Open - Close[t-1]) / (Std(Log(Close/Close[t-1]), 15) + 1e-6)]. It targets assets with high directional efficiency and low intraday range, coupled with significant overnight momentum relative to recent volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:43:42.264921"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1330550182538235,
        "ICIR": 0.0339954268033133,
        "1day.excess_return_without_cost.std": 0.0043163462086389,
        "1day.excess_return_with_cost.annualized_return": -0.0105245100911624,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001545397825286,
        "1day.excess_return_without_cost.annualized_return": 0.0367804682418305,
        "1day.excess_return_with_cost.std": 0.0043163876925111,
        "Rank IC": 0.0214279954692257,
        "IC": 0.0046733287338853,
        "1day.excess_return_without_cost.max_drawdown": -0.0782602794765694,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5523476411746017,
        "1day.pa": 0.0,
        "l2.valid": 0.9966364718538696,
        "Rank ICIR": 0.1586207603304279,
        "l2.train": 0.9940271733512288,
        "1day.excess_return_with_cost.information_ratio": -0.1580494412374032,
        "1day.excess_return_with_cost.mean": -4.422063063513647e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Informed Compression-Breakout' (ICB) framework. While the core hypothesis (ICB_Factor_10D_5D) and its components (IAR and VAGT) were implemented, the combined results show a deterioration compared to the current SOTA. The Information Ratio (0.552 vs 0.972) and IC (0.0046 vs 0.0057) are significantly lower, suggesting that the current mathematical formulation of 'informed accumulation' might be too noisy or that the interaction between the accumulation score and the overnight gap is not additive/multiplicative in the way currently defined.",
        "hypothesis_evaluation": "The results partially refute the current implementation of the ICB hypothesis. While the logic of combining accumulation with breakout triggers is sound, the 'Informed_Accumulation_Rank' (IAR) likely suffers from high noise by using raw volume without normalization against a longer-term baseline. Furthermore, the ICB_Factor_10D_5D has a relatively high complexity in its formulation (multiple nested ratios and standard deviations), which may lead to poor generalization as seen in the lower IR.",
        "decision": false,
        "reason": "1. Complexity Reduction: The current ICB factor uses 5 base features and multiple nested TS_STD functions. Simplifying the 'accumulation' measure to a ratio of recent volume vs. 20-day average volume will reduce noise. 2. Better Normalization: Instead of using TS_STD of (high-low)/close, using a RANK of the intraday range relative to volume surge ensures we capture 'stealth' (low price movement on high volume) more robustly across different market regimes. 3. Interaction: Using a conditional logic or a simpler Z-score for the gap will likely perform better than a direct product of two high-variance signals."
      }
    },
    "3a4c935911d97289": {
      "factor_id": "3a4c935911d97289",
      "factor_name": "Volatility_Adjusted_Gap_Trigger",
      "factor_expression": "ZSCORE(($open - DELAY($close, 1)) / (DELAY($close, 1) * TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($open - DELAY($close, 1)) / DELAY($close, 1)) / (TS_STD(LOG($close / DELAY($close, 1)), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Gap_Trigger\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Captures the 'Breakout Trigger' part of the ICB hypothesis. It measures the overnight price gap normalized by the 20-day standard deviation of daily returns. This identifies price jumps that are statistically significant relative to the asset's recent volatility profile.",
      "factor_formulation": "VAGT = ZSCORE\\left( \\frac{open - DELAY(close, 1)}{DELAY(close, 1) \\times TS\\_STD(return, 20) + 1e-8} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "93de3acb823a",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Compression-Breakout' (ICB) factor, calculated as the product of a 10-day Micro-Structural Information Asymmetry (MSIA) score and a 5-day Volatility-Adjusted Overnight Gap, identifies high-conviction trends by filtering breakout triggers with evidence of stealthy informed accumulation.\n                Concise Observation: Parent 1 (MSIA) excels at identifying accumulation but lacks timing, while Parent 2 (EVIB) identifies breakouts but is prone to 'fake-outs' without structural support; both utilize price-volume relationships and volatility compression to predict short-term returns.\n                Concise Justification: By multiplying the MSIA score (accumulation filter) with the EVIB gap metric (breakout trigger), the factor ensures that only those price gaps occurring after a period of informed positioning and low dispersion are prioritized, maximizing the signal-to-noise ratio.\n                Concise Knowledge: If a period of low intraday price dispersion is accompanied by high volume-weighted price directionality, it indicates informed accumulation; when this state is followed by an overnight price gap during a period of low historical volatility, the subsequent breakout is more likely to be persistent.\n                concise Specification: The factor is defined as: [Mean( (Close-Open)/(High-Low) * Volume, 10) / Std( (High-Low)/Close, 10 )] * [(Open - Close[t-1]) / (Std(Log(Close/Close[t-1]), 15) + 1e-6)]. It targets assets with high directional efficiency and low intraday range, coupled with significant overnight momentum relative to recent volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:43:42.264921"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1330550182538235,
        "ICIR": 0.0339954268033133,
        "1day.excess_return_without_cost.std": 0.0043163462086389,
        "1day.excess_return_with_cost.annualized_return": -0.0105245100911624,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001545397825286,
        "1day.excess_return_without_cost.annualized_return": 0.0367804682418305,
        "1day.excess_return_with_cost.std": 0.0043163876925111,
        "Rank IC": 0.0214279954692257,
        "IC": 0.0046733287338853,
        "1day.excess_return_without_cost.max_drawdown": -0.0782602794765694,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.5523476411746017,
        "1day.pa": 0.0,
        "l2.valid": 0.9966364718538696,
        "Rank ICIR": 0.1586207603304279,
        "l2.train": 0.9940271733512288,
        "1day.excess_return_with_cost.information_ratio": -0.1580494412374032,
        "1day.excess_return_with_cost.mean": -4.422063063513647e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Informed Compression-Breakout' (ICB) framework. While the core hypothesis (ICB_Factor_10D_5D) and its components (IAR and VAGT) were implemented, the combined results show a deterioration compared to the current SOTA. The Information Ratio (0.552 vs 0.972) and IC (0.0046 vs 0.0057) are significantly lower, suggesting that the current mathematical formulation of 'informed accumulation' might be too noisy or that the interaction between the accumulation score and the overnight gap is not additive/multiplicative in the way currently defined.",
        "hypothesis_evaluation": "The results partially refute the current implementation of the ICB hypothesis. While the logic of combining accumulation with breakout triggers is sound, the 'Informed_Accumulation_Rank' (IAR) likely suffers from high noise by using raw volume without normalization against a longer-term baseline. Furthermore, the ICB_Factor_10D_5D has a relatively high complexity in its formulation (multiple nested ratios and standard deviations), which may lead to poor generalization as seen in the lower IR.",
        "decision": false,
        "reason": "1. Complexity Reduction: The current ICB factor uses 5 base features and multiple nested TS_STD functions. Simplifying the 'accumulation' measure to a ratio of recent volume vs. 20-day average volume will reduce noise. 2. Better Normalization: Instead of using TS_STD of (high-low)/close, using a RANK of the intraday range relative to volume surge ensures we capture 'stealth' (low price movement on high volume) more robustly across different market regimes. 3. Interaction: Using a conditional logic or a simpler Z-score for the gap will likely perform better than a direct product of two high-variance signals."
      }
    },
    "ff8b30d83cdf54ef": {
      "factor_id": "ff8b30d83cdf54ef",
      "factor_name": "IISV_Stability_Gap_20D",
      "factor_expression": "(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ABS($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * (TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IISV_Stability_Gap_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Institutional Inertia & Structural Validation (IISV) factor identifies high-conviction alpha by multiplying the overnight price gap, normalized by the intraday range, with the 20-day volume stability (the ratio of mean volume to its standard deviation). High values suggest institutional accumulation during stable liquidity regimes.",
      "factor_formulation": "IISV = \\frac{|open_t - close_{t-1}|}{(high_t - low_t) + 1e-8} \\times \\frac{TS\\_MEAN(volume, 20)}{TS\\_STD(volume, 20) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "da527933097b",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Structural Validation' (IISV) factor identifies high-conviction alpha by multiplying the overnight price gap, normalized by intraday range, with the 20-day volume stability (the inverse of the standard deviation of volume over 20 days).\n                Concise Observation: Parent 1 (ICP) shows that volume stability improves momentum reliability (RankIC 0.0249), while Parent 2 (LVSB) shows that overnight gaps normalized by intraday efficiency capture institutional intent (RankIC 0.0274).\n                Concise Justification: Combining the structural breakout signal with a liquidity stability filter reduces 'fake-outs' by ensuring that the price jump occurs within a regime of consistent capital flow rather than erratic retail trading.\n                Concise Knowledge: If an overnight price gap is validated by low intraday price dispersion and high historical volume stability, then the resulting price move is more likely to represent institutional accumulation rather than transient noise.\n                concise Specification: The factor is calculated as (Gap / (High - Low + epsilon)) * (Mean_Volume_20d / Std_Volume_20d), where Gap is the absolute difference between today's open and yesterday's close, using a 20-day lookback for volume stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:46:38.099876"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1006002189896827,
        "ICIR": 0.0637047946798284,
        "1day.excess_return_without_cost.std": 0.0042740057395895,
        "1day.excess_return_with_cost.annualized_return": 0.031410952509216,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003325193769718,
        "1day.excess_return_without_cost.annualized_return": 0.0791396117192999,
        "1day.excess_return_with_cost.std": 0.0042762629799031,
        "Rank IC": 0.0256647055986261,
        "IC": 0.0085803294117226,
        "1day.excess_return_without_cost.max_drawdown": -0.086991218729221,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.200246188762697,
        "1day.pa": 0.0,
        "l2.valid": 0.9967061978011852,
        "Rank ICIR": 0.1950490737264125,
        "l2.train": 0.9934598426634448,
        "1day.excess_return_with_cost.information_ratio": 0.4761329336498174,
        "1day.excess_return_with_cost.mean": 0.0001319787920555
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Inertia & Structural Validation' (IISV) hypothesis. The results show a significant improvement over the previous SOTA, particularly in predictive power and risk-adjusted returns. The Information Ratio (IR) increased from 0.97 to 1.20, and the IC improved from 0.0058 to 0.0086. While the Max Drawdown slightly worsened, the substantial gain in Annualized Return (7.9% vs 5.2%) indicates that the combination of overnight price gaps and volume stability is a potent alpha source. The Z-score and Ranking approaches appear to have successfully mitigated scale issues across different instruments.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional conviction can be identified by combining overnight price action with volume consistency. The 'Structural Validation' component (volume stability) effectively filters out noise from the 'Institutional Inertia' (overnight gaps). The transition from raw values to cross-sectional Z-scores and Ranks has proven beneficial for the model's ability to generalize across the market universe.",
        "decision": true,
        "reason": "Current iterations use the immediate intraday range to normalize the gap, but they don't account for the broader volatility regime of the stock. A stock with high historical intraday volatility might naturally produce larger gaps that lack institutional 'inertia'. By introducing a short-term volatility lookback (e.g., 5-day range) and maintaining the volume stability (20-day), we can better distinguish between structural shifts and high-beta noise. This maintains the core IISV framework while refining the 'Structural Validation' part with a volatility-regime filter."
      }
    },
    "8e0e48edc2d20afa": {
      "factor_id": "8e0e48edc2d20afa",
      "factor_name": "IISV_Ranked_Validation_20D",
      "factor_expression": "RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open - DELAY($close, 1)) / ($high - $low + 1e-8)) * RANK(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IISV_Ranked_Validation_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally ranked version of the IISV hypothesis. It captures the relative strength of the overnight gap normalized by intraday volatility, scaled by the 20-day volume coefficient of variation. This ensures the factor is robust to different price and volume scales across the market.",
      "factor_formulation": "IISV_{Ranked} = RANK(\\frac{open_t - close_{t-1}}{high_t - low_t + 1e-8}) \\times RANK(\\frac{TS\\_MEAN(volume, 20)}{TS\\_STD(volume, 20) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "da527933097b",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Structural Validation' (IISV) factor identifies high-conviction alpha by multiplying the overnight price gap, normalized by intraday range, with the 20-day volume stability (the inverse of the standard deviation of volume over 20 days).\n                Concise Observation: Parent 1 (ICP) shows that volume stability improves momentum reliability (RankIC 0.0249), while Parent 2 (LVSB) shows that overnight gaps normalized by intraday efficiency capture institutional intent (RankIC 0.0274).\n                Concise Justification: Combining the structural breakout signal with a liquidity stability filter reduces 'fake-outs' by ensuring that the price jump occurs within a regime of consistent capital flow rather than erratic retail trading.\n                Concise Knowledge: If an overnight price gap is validated by low intraday price dispersion and high historical volume stability, then the resulting price move is more likely to represent institutional accumulation rather than transient noise.\n                concise Specification: The factor is calculated as (Gap / (High - Low + epsilon)) * (Mean_Volume_20d / Std_Volume_20d), where Gap is the absolute difference between today's open and yesterday's close, using a 20-day lookback for volume stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:46:38.099876"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1006002189896827,
        "ICIR": 0.0637047946798284,
        "1day.excess_return_without_cost.std": 0.0042740057395895,
        "1day.excess_return_with_cost.annualized_return": 0.031410952509216,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003325193769718,
        "1day.excess_return_without_cost.annualized_return": 0.0791396117192999,
        "1day.excess_return_with_cost.std": 0.0042762629799031,
        "Rank IC": 0.0256647055986261,
        "IC": 0.0085803294117226,
        "1day.excess_return_without_cost.max_drawdown": -0.086991218729221,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.200246188762697,
        "1day.pa": 0.0,
        "l2.valid": 0.9967061978011852,
        "Rank ICIR": 0.1950490737264125,
        "l2.train": 0.9934598426634448,
        "1day.excess_return_with_cost.information_ratio": 0.4761329336498174,
        "1day.excess_return_with_cost.mean": 0.0001319787920555
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Inertia & Structural Validation' (IISV) hypothesis. The results show a significant improvement over the previous SOTA, particularly in predictive power and risk-adjusted returns. The Information Ratio (IR) increased from 0.97 to 1.20, and the IC improved from 0.0058 to 0.0086. While the Max Drawdown slightly worsened, the substantial gain in Annualized Return (7.9% vs 5.2%) indicates that the combination of overnight price gaps and volume stability is a potent alpha source. The Z-score and Ranking approaches appear to have successfully mitigated scale issues across different instruments.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional conviction can be identified by combining overnight price action with volume consistency. The 'Structural Validation' component (volume stability) effectively filters out noise from the 'Institutional Inertia' (overnight gaps). The transition from raw values to cross-sectional Z-scores and Ranks has proven beneficial for the model's ability to generalize across the market universe.",
        "decision": true,
        "reason": "Current iterations use the immediate intraday range to normalize the gap, but they don't account for the broader volatility regime of the stock. A stock with high historical intraday volatility might naturally produce larger gaps that lack institutional 'inertia'. By introducing a short-term volatility lookback (e.g., 5-day range) and maintaining the volume stability (20-day), we can better distinguish between structural shifts and high-beta noise. This maintains the core IISV framework while refining the 'Structural Validation' part with a volatility-regime filter."
      }
    },
    "761d3b9b8cc68fb7": {
      "factor_id": "761d3b9b8cc68fb7",
      "factor_name": "IISV_ZScore_Momentum_20D",
      "factor_expression": "(($open - DELAY($close, 1)) / DELAY($close, 1)) * ZSCORE(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / DELAY($close, 1)) * ZSCORE(TS_MEAN($volume, 20) / (TS_STD($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"IISV_ZScore_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This variation uses the Z-score of the volume stability to isolate stocks with significantly more consistent trading activity than their peers, combined with the normalized overnight gap to filter for structural price jumps.",
      "factor_formulation": "IISV_{ZScore} = \\frac{open_t - close_{t-1}}{close_{t-1}} \\times ZSCORE(\\frac{TS\\_MEAN(volume, 20)}{TS\\_STD(volume, 20) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "da527933097b",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Inertia & Structural Validation' (IISV) factor identifies high-conviction alpha by multiplying the overnight price gap, normalized by intraday range, with the 20-day volume stability (the inverse of the standard deviation of volume over 20 days).\n                Concise Observation: Parent 1 (ICP) shows that volume stability improves momentum reliability (RankIC 0.0249), while Parent 2 (LVSB) shows that overnight gaps normalized by intraday efficiency capture institutional intent (RankIC 0.0274).\n                Concise Justification: Combining the structural breakout signal with a liquidity stability filter reduces 'fake-outs' by ensuring that the price jump occurs within a regime of consistent capital flow rather than erratic retail trading.\n                Concise Knowledge: If an overnight price gap is validated by low intraday price dispersion and high historical volume stability, then the resulting price move is more likely to represent institutional accumulation rather than transient noise.\n                concise Specification: The factor is calculated as (Gap / (High - Low + epsilon)) * (Mean_Volume_20d / Std_Volume_20d), where Gap is the absolute difference between today's open and yesterday's close, using a 20-day lookback for volume stability.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:46:38.099876"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1006002189896827,
        "ICIR": 0.0637047946798284,
        "1day.excess_return_without_cost.std": 0.0042740057395895,
        "1day.excess_return_with_cost.annualized_return": 0.031410952509216,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003325193769718,
        "1day.excess_return_without_cost.annualized_return": 0.0791396117192999,
        "1day.excess_return_with_cost.std": 0.0042762629799031,
        "Rank IC": 0.0256647055986261,
        "IC": 0.0085803294117226,
        "1day.excess_return_without_cost.max_drawdown": -0.086991218729221,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.200246188762697,
        "1day.pa": 0.0,
        "l2.valid": 0.9967061978011852,
        "Rank ICIR": 0.1950490737264125,
        "l2.train": 0.9934598426634448,
        "1day.excess_return_with_cost.information_ratio": 0.4761329336498174,
        "1day.excess_return_with_cost.mean": 0.0001319787920555
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Inertia & Structural Validation' (IISV) hypothesis. The results show a significant improvement over the previous SOTA, particularly in predictive power and risk-adjusted returns. The Information Ratio (IR) increased from 0.97 to 1.20, and the IC improved from 0.0058 to 0.0086. While the Max Drawdown slightly worsened, the substantial gain in Annualized Return (7.9% vs 5.2%) indicates that the combination of overnight price gaps and volume stability is a potent alpha source. The Z-score and Ranking approaches appear to have successfully mitigated scale issues across different instruments.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that institutional conviction can be identified by combining overnight price action with volume consistency. The 'Structural Validation' component (volume stability) effectively filters out noise from the 'Institutional Inertia' (overnight gaps). The transition from raw values to cross-sectional Z-scores and Ranks has proven beneficial for the model's ability to generalize across the market universe.",
        "decision": true,
        "reason": "Current iterations use the immediate intraday range to normalize the gap, but they don't account for the broader volatility regime of the stock. A stock with high historical intraday volatility might naturally produce larger gaps that lack institutional 'inertia'. By introducing a short-term volatility lookback (e.g., 5-day range) and maintaining the volume stability (20-day), we can better distinguish between structural shifts and high-beta noise. This maintains the core IISV framework while refining the 'Structural Validation' part with a volatility-regime filter."
      }
    },
    "ed001b0f1ff58ebf": {
      "factor_id": "ed001b0f1ff58ebf",
      "factor_name": "ILC_Informed_Liquidity_Capture_10D",
      "factor_expression": "ZSCORE((TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) - TS_MEAN($close, 10)) * (TS_STD($volume, 5) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) - TS_MEAN($close, 10)) * (TS_STD($volume, 5) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ILC_Informed_Liquidity_Capture_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Informed Liquidity Capture (ILC) factor identifies institutional entries by combining an Asymmetric Information Decay (AID) score with a Volatility-Liquidity Compression (VLC) trigger. AID measures the divergence between volume-weighted and time-weighted prices over 10 days, while VLC captures price range contraction relative to volume stability over 5 days.",
      "factor_formulation": "ILC = ZSCORE(\\frac{TS\\_MEAN(close \\cdot volume, 10)}{TS\\_MEAN(volume, 10)} - TS\\_MEAN(close, 10)) \\cdot \\frac{TS\\_STD(volume, 5)}{TS\\_MAX(high, 15) - TS\\_MIN(low, 15)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "5fa4813ff432",
        "parent_trajectory_ids": [
          "51d281e76291",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Liquidity Capture' (ILC) factor identifies high-conviction institutional entries by multiplying a 10-day Asymmetric Information Decay (AID) score—measuring the divergence between price-weighted and time-weighted averages—with a 5-day Volatility-Liquidity Compression (VLC) trigger.\n                Concise Observation: Parent 1 (AID) captures early positioning but lacks timing precision (RankIC 0.023), while Parent 2 (EVIB) identifies explosive breakouts but suffers from false signals (RankIC 0.028); both rely on low-volume regimes to signal institutional dominance.\n                Concise Justification: The fusion uses AID as a quality filter to ensure the breakout identified by VLC is backed by prior informed positioning, reducing 'fake-outs' caused by random retail noise or temporary liquidity gaps.\n                Concise Knowledge: If stealth institutional accumulation (AID) is validated by a regime of extreme liquidity exhaustion and volatility compression, then the subsequent price breakout is more likely to be persistent; when retail participation is low, institutional flows exert a disproportionate impact on price discovery.\n                concise Specification: Calculate AID as (mean($close * $volume) / mean($volume)) - mean($close) over 10 days; calculate VLC as the inverse of (15-day price range / 5-day volume std); the final factor is the product of Z-scored AID and VLC.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:49:36.045609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1464951525904688,
        "ICIR": 0.0462264064691406,
        "1day.excess_return_without_cost.std": 0.0048558753352584,
        "1day.excess_return_with_cost.annualized_return": -0.0124405956915143,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001478378988452,
        "1day.excess_return_without_cost.annualized_return": 0.0351854199251635,
        "1day.excess_return_with_cost.std": 0.0048573660157832,
        "Rank IC": 0.0239522573739457,
        "IC": 0.006782042392544,
        "1day.excess_return_without_cost.max_drawdown": -0.1252697331476359,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4696850441079855,
        "1day.pa": 0.0,
        "l2.valid": 0.9964999011476624,
        "Rank ICIR": 0.1662924338659375,
        "l2.train": 0.9940839710932244,
        "1day.excess_return_with_cost.information_ratio": -0.1660167346715036,
        "1day.excess_return_with_cost.mean": -5.227141046854785e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Informed Liquidity Capture' (ILC) framework by evaluating the combined factor and its two components (AID and VLC) individually. The current result achieved a higher Information Coefficient (IC) of 0.006782 compared to the SOTA's 0.005798, indicating a stronger point-in-time predictive correlation. However, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) significantly underperformed the SOTA, suggesting that while the signal has predictive power, its volatility or turnover characteristics lead to poorer risk-adjusted returns in a backtest environment.",
        "hypothesis_evaluation": "The hypothesis that combining AID and VLC identifies high-conviction entries is partially supported by the improved IC, which suggests the interaction between volume-weighted price divergence and liquidity compression contains alpha. However, the high Max Drawdown (-0.125) and lower IR (0.469) suggest the current formulation of the VLC trigger—specifically using the 15-day price range in the denominator—might be too sensitive to outliers or market-wide volatility, leading to unstable signals.",
        "decision": false,
        "reason": "The current VLC component uses 'TS_MAX(high, 15) - TS_MIN(low, 15)', which can expand drastically during flash crashes or idiosyncratic spikes, diluting the factor value. Using a standardized volatility measure like Average True Range (ATR) or a simple standard deviation of returns would provide a more consistent scaling. Furthermore, the product of a Z-score and a raw ratio can create extreme outliers; mapping the components to a uniform distribution (RANK) before multiplication will likely improve the Information Ratio and reduce Drawdown."
      }
    },
    "083c2b7e640797ea": {
      "factor_id": "083c2b7e640797ea",
      "factor_name": "VLC_Compression_Trigger_5D",
      "factor_expression": "RANK(TS_STD($volume, 5) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($volume, 5) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VLC_Compression_Trigger_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A standalone Volatility-Liquidity Compression (VLC) factor that identifies regimes of extreme liquidity exhaustion. It calculates the ratio of volume volatility over the 15-day price range. High values indicate that volume is fluctuating while price remains range-bound, often preceding institutional breakouts.",
      "factor_formulation": "VLC = RANK(\\frac{TS\\_STD(volume, 5)}{TS\\_MAX(high, 15) - TS\\_MIN(low, 15)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "5fa4813ff432",
        "parent_trajectory_ids": [
          "51d281e76291",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Liquidity Capture' (ILC) factor identifies high-conviction institutional entries by multiplying a 10-day Asymmetric Information Decay (AID) score—measuring the divergence between price-weighted and time-weighted averages—with a 5-day Volatility-Liquidity Compression (VLC) trigger.\n                Concise Observation: Parent 1 (AID) captures early positioning but lacks timing precision (RankIC 0.023), while Parent 2 (EVIB) identifies explosive breakouts but suffers from false signals (RankIC 0.028); both rely on low-volume regimes to signal institutional dominance.\n                Concise Justification: The fusion uses AID as a quality filter to ensure the breakout identified by VLC is backed by prior informed positioning, reducing 'fake-outs' caused by random retail noise or temporary liquidity gaps.\n                Concise Knowledge: If stealth institutional accumulation (AID) is validated by a regime of extreme liquidity exhaustion and volatility compression, then the subsequent price breakout is more likely to be persistent; when retail participation is low, institutional flows exert a disproportionate impact on price discovery.\n                concise Specification: Calculate AID as (mean($close * $volume) / mean($volume)) - mean($close) over 10 days; calculate VLC as the inverse of (15-day price range / 5-day volume std); the final factor is the product of Z-scored AID and VLC.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:49:36.045609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1464951525904688,
        "ICIR": 0.0462264064691406,
        "1day.excess_return_without_cost.std": 0.0048558753352584,
        "1day.excess_return_with_cost.annualized_return": -0.0124405956915143,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001478378988452,
        "1day.excess_return_without_cost.annualized_return": 0.0351854199251635,
        "1day.excess_return_with_cost.std": 0.0048573660157832,
        "Rank IC": 0.0239522573739457,
        "IC": 0.006782042392544,
        "1day.excess_return_without_cost.max_drawdown": -0.1252697331476359,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4696850441079855,
        "1day.pa": 0.0,
        "l2.valid": 0.9964999011476624,
        "Rank ICIR": 0.1662924338659375,
        "l2.train": 0.9940839710932244,
        "1day.excess_return_with_cost.information_ratio": -0.1660167346715036,
        "1day.excess_return_with_cost.mean": -5.227141046854785e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Informed Liquidity Capture' (ILC) framework by evaluating the combined factor and its two components (AID and VLC) individually. The current result achieved a higher Information Coefficient (IC) of 0.006782 compared to the SOTA's 0.005798, indicating a stronger point-in-time predictive correlation. However, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) significantly underperformed the SOTA, suggesting that while the signal has predictive power, its volatility or turnover characteristics lead to poorer risk-adjusted returns in a backtest environment.",
        "hypothesis_evaluation": "The hypothesis that combining AID and VLC identifies high-conviction entries is partially supported by the improved IC, which suggests the interaction between volume-weighted price divergence and liquidity compression contains alpha. However, the high Max Drawdown (-0.125) and lower IR (0.469) suggest the current formulation of the VLC trigger—specifically using the 15-day price range in the denominator—might be too sensitive to outliers or market-wide volatility, leading to unstable signals.",
        "decision": false,
        "reason": "The current VLC component uses 'TS_MAX(high, 15) - TS_MIN(low, 15)', which can expand drastically during flash crashes or idiosyncratic spikes, diluting the factor value. Using a standardized volatility measure like Average True Range (ATR) or a simple standard deviation of returns would provide a more consistent scaling. Furthermore, the product of a Z-score and a raw ratio can create extreme outliers; mapping the components to a uniform distribution (RANK) before multiplication will likely improve the Information Ratio and reduce Drawdown."
      }
    },
    "b516d5d364127ec9": {
      "factor_id": "b516d5d364127ec9",
      "factor_name": "AID_Institutional_Accumulation_10D",
      "factor_expression": "ZSCORE((TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) - TS_MEAN($close, 10))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MEAN($close * $volume, 10) / (TS_MEAN($volume, 10) + 1e-8)) - TS_MEAN($close, 10))\" # Your output factor expression will be filled in here\n    name = \"AID_Institutional_Accumulation_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Asymmetric Information Decay (AID) factor measures the alpha generated by volume-weighted price deviations. A positive divergence suggests that high-volume trades are occurring at prices above the simple average, signaling stealth institutional accumulation.",
      "factor_formulation": "AID = ZSCORE(\\frac{TS\\_MEAN(close \\cdot volume, 10)}{TS\\_MEAN(volume, 10)} - TS\\_MEAN(close, 10))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "5fa4813ff432",
        "parent_trajectory_ids": [
          "51d281e76291",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Informed Liquidity Capture' (ILC) factor identifies high-conviction institutional entries by multiplying a 10-day Asymmetric Information Decay (AID) score—measuring the divergence between price-weighted and time-weighted averages—with a 5-day Volatility-Liquidity Compression (VLC) trigger.\n                Concise Observation: Parent 1 (AID) captures early positioning but lacks timing precision (RankIC 0.023), while Parent 2 (EVIB) identifies explosive breakouts but suffers from false signals (RankIC 0.028); both rely on low-volume regimes to signal institutional dominance.\n                Concise Justification: The fusion uses AID as a quality filter to ensure the breakout identified by VLC is backed by prior informed positioning, reducing 'fake-outs' caused by random retail noise or temporary liquidity gaps.\n                Concise Knowledge: If stealth institutional accumulation (AID) is validated by a regime of extreme liquidity exhaustion and volatility compression, then the subsequent price breakout is more likely to be persistent; when retail participation is low, institutional flows exert a disproportionate impact on price discovery.\n                concise Specification: Calculate AID as (mean($close * $volume) / mean($volume)) - mean($close) over 10 days; calculate VLC as the inverse of (15-day price range / 5-day volume std); the final factor is the product of Z-scored AID and VLC.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T12:49:36.045609"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1464951525904688,
        "ICIR": 0.0462264064691406,
        "1day.excess_return_without_cost.std": 0.0048558753352584,
        "1day.excess_return_with_cost.annualized_return": -0.0124405956915143,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001478378988452,
        "1day.excess_return_without_cost.annualized_return": 0.0351854199251635,
        "1day.excess_return_with_cost.std": 0.0048573660157832,
        "Rank IC": 0.0239522573739457,
        "IC": 0.006782042392544,
        "1day.excess_return_without_cost.max_drawdown": -0.1252697331476359,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.4696850441079855,
        "1day.pa": 0.0,
        "l2.valid": 0.9964999011476624,
        "Rank ICIR": 0.1662924338659375,
        "l2.train": 0.9940839710932244,
        "1day.excess_return_with_cost.information_ratio": -0.1660167346715036,
        "1day.excess_return_with_cost.mean": -5.227141046854785e-05
      },
      "feedback": {
        "observations": "The experiment tested the 'Informed Liquidity Capture' (ILC) framework by evaluating the combined factor and its two components (AID and VLC) individually. The current result achieved a higher Information Coefficient (IC) of 0.006782 compared to the SOTA's 0.005798, indicating a stronger point-in-time predictive correlation. However, the portfolio-based metrics (Annualized Return, Information Ratio, and Max Drawdown) significantly underperformed the SOTA, suggesting that while the signal has predictive power, its volatility or turnover characteristics lead to poorer risk-adjusted returns in a backtest environment.",
        "hypothesis_evaluation": "The hypothesis that combining AID and VLC identifies high-conviction entries is partially supported by the improved IC, which suggests the interaction between volume-weighted price divergence and liquidity compression contains alpha. However, the high Max Drawdown (-0.125) and lower IR (0.469) suggest the current formulation of the VLC trigger—specifically using the 15-day price range in the denominator—might be too sensitive to outliers or market-wide volatility, leading to unstable signals.",
        "decision": false,
        "reason": "The current VLC component uses 'TS_MAX(high, 15) - TS_MIN(low, 15)', which can expand drastically during flash crashes or idiosyncratic spikes, diluting the factor value. Using a standardized volatility measure like Average True Range (ATR) or a simple standard deviation of returns would provide a more consistent scaling. Furthermore, the product of a Z-score and a raw ratio can create extreme outliers; mapping the components to a uniform distribution (RANK) before multiplication will likely improve the Information Ratio and reduce Drawdown."
      }
    },
    "5ba7d0c1ce0746a0": {
      "factor_id": "5ba7d0c1ce0746a0",
      "factor_name": "ISB_Linearity_Gap_10D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($open - DELAY($close, 1)) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * ($open - DELAY($close, 1)) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ISB_Linearity_Gap_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Institutional Stealth Breakout (ISB) factor identifies price continuations by multiplying the linearity of the recent trend (R-squared of close prices) with the volatility-normalized overnight gap. High linearity suggests institutional accumulation, while the gap captures the liquidity shift.",
      "factor_formulation": "\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS_MAX}(\\text{high}, 15) - \\text{TS_MIN}(\\text{low}, 15)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "c22c4c2570d5",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Stealth Breakout' (ISB) factor, calculated as the product of the 10-day price return R-squared and the ratio of the overnight gap to the 15-day price range, identifies sustainable price continuations by filtering overnight liquidity events through a lens of prior trend linearity.\n                Concise Observation: Parent 1 (IAF) captures stable institutional trends (RankIC 0.023) while Parent 2 (EVIB) captures explosive breakout events (RankIC 0.028); combining the slow-moving trend persistence with fast-moving overnight price gaps can filter out high-noise volatility spikes.\n                Concise Justification: High R-squared values indicate a 'quiet trend' of professional absorption, and an overnight gap (close-to-open) represents a sudden shift in liquidity; multiplying these ensures that only breakouts emerging from a disciplined, linear trend are flagged as high-conviction signals.\n                Concise Knowledge: If a price breakout occurs following a period of high statistical linearity (R-squared), it is more likely to represent institutional accumulation than a random speculative spike; when such breakouts are normalized by recent volatility compression, the signal quality improves.\n                concise Specification: The factor is defined as (10-day R-squared of daily close prices) * ((Open_t - Close_{t-1}) / (Max(High, 15) - Min(Low, 15))), where the R-squared is calculated against a linear time index and the denominator serves as a volatility-normalization constant.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:04:50.419086"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0909875213438115,
        "ICIR": 0.0461961229115339,
        "1day.excess_return_without_cost.std": 0.0038009238399316,
        "1day.excess_return_with_cost.annualized_return": 0.0257242435898082,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003044643583881,
        "1day.excess_return_without_cost.annualized_return": 0.0724625172963808,
        "1day.excess_return_with_cost.std": 0.00380161473814,
        "Rank IC": 0.0214296406808696,
        "IC": 0.0059630592524499,
        "1day.excess_return_without_cost.max_drawdown": -0.0775491315485204,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.235764659002519,
        "1day.pa": 0.0,
        "l2.valid": 0.9966106898626148,
        "Rank ICIR": 0.1704505814668444,
        "l2.train": 0.9937751907437564,
        "1day.excess_return_with_cost.information_ratio": 0.4386175777673567,
        "1day.excess_return_with_cost.mean": 0.0001080850571
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Stealth Breakout' (ISB) framework. The results show a significant improvement over the previous SOTA, particularly in terms of Information Ratio (1.236 vs 0.973) and Annualized Return (7.25% vs 5.20%). The IC also saw a marginal increase. While the Max Drawdown slightly worsened (-0.077 vs -0.072), the risk-adjusted returns (IR) suggest the current iteration is much more robust. The 'ISB_Zscore_Breakout_20D' and 'ISB_Ranked_Persistence_15D' likely contributed to this stability by normalizing the overnight gap, which is often a noisy signal.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining trend linearity (R-squared) with overnight gap dynamics identifies sustainable continuations. The use of R-squared (POW of TS_CORR) effectively filters for 'stealth' accumulation where price movement is persistent rather than erratic. The transition from raw price ranges to Z-scores and cross-sectional ranks significantly improved the signal-to-noise ratio, confirming that the 'breakout' component needs to be relative to the specific instrument's volatility environment.",
        "decision": true,
        "reason": "Currently, the factor uses price-based linearity. However, true 'stealth' accumulation often occurs with consistent, non-volatile volume. If the volume during the 10-day linearity period is also stable (low coefficient of variation), it increases the probability that the subsequent gap is a genuine institutional shift rather than retail noise. Additionally, replacing the raw gap with a Volume-Weighted Average Price (VWAP) relative gap could improve the entry signal precision."
      }
    },
    "26e53e25e09a4b98": {
      "factor_id": "26e53e25e09a4b98",
      "factor_name": "ISB_Ranked_Persistence_15D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(($open - DELAY($close, 1)) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) * RANK(($open - DELAY($close, 1)) / (TS_MAX($high, 15) - TS_MIN($low, 15) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ISB_Ranked_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A robust version of the ISB factor that uses cross-sectional ranking of trend linearity and the overnight gap relative to the 15-day price range. This version ensures the signal is comparable across different stocks and reduces the impact of outliers.",
      "factor_formulation": "\\text{RANK}(\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2)) \\times \\text{RANK}(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS_MAX}(\\text{high}, 15) - \\text{TS_MIN}(\\text{low}, 15)})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "c22c4c2570d5",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Stealth Breakout' (ISB) factor, calculated as the product of the 10-day price return R-squared and the ratio of the overnight gap to the 15-day price range, identifies sustainable price continuations by filtering overnight liquidity events through a lens of prior trend linearity.\n                Concise Observation: Parent 1 (IAF) captures stable institutional trends (RankIC 0.023) while Parent 2 (EVIB) captures explosive breakout events (RankIC 0.028); combining the slow-moving trend persistence with fast-moving overnight price gaps can filter out high-noise volatility spikes.\n                Concise Justification: High R-squared values indicate a 'quiet trend' of professional absorption, and an overnight gap (close-to-open) represents a sudden shift in liquidity; multiplying these ensures that only breakouts emerging from a disciplined, linear trend are flagged as high-conviction signals.\n                Concise Knowledge: If a price breakout occurs following a period of high statistical linearity (R-squared), it is more likely to represent institutional accumulation than a random speculative spike; when such breakouts are normalized by recent volatility compression, the signal quality improves.\n                concise Specification: The factor is defined as (10-day R-squared of daily close prices) * ((Open_t - Close_{t-1}) / (Max(High, 15) - Min(Low, 15))), where the R-squared is calculated against a linear time index and the denominator serves as a volatility-normalization constant.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:04:50.419086"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0909875213438115,
        "ICIR": 0.0461961229115339,
        "1day.excess_return_without_cost.std": 0.0038009238399316,
        "1day.excess_return_with_cost.annualized_return": 0.0257242435898082,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003044643583881,
        "1day.excess_return_without_cost.annualized_return": 0.0724625172963808,
        "1day.excess_return_with_cost.std": 0.00380161473814,
        "Rank IC": 0.0214296406808696,
        "IC": 0.0059630592524499,
        "1day.excess_return_without_cost.max_drawdown": -0.0775491315485204,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.235764659002519,
        "1day.pa": 0.0,
        "l2.valid": 0.9966106898626148,
        "Rank ICIR": 0.1704505814668444,
        "l2.train": 0.9937751907437564,
        "1day.excess_return_with_cost.information_ratio": 0.4386175777673567,
        "1day.excess_return_with_cost.mean": 0.0001080850571
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Stealth Breakout' (ISB) framework. The results show a significant improvement over the previous SOTA, particularly in terms of Information Ratio (1.236 vs 0.973) and Annualized Return (7.25% vs 5.20%). The IC also saw a marginal increase. While the Max Drawdown slightly worsened (-0.077 vs -0.072), the risk-adjusted returns (IR) suggest the current iteration is much more robust. The 'ISB_Zscore_Breakout_20D' and 'ISB_Ranked_Persistence_15D' likely contributed to this stability by normalizing the overnight gap, which is often a noisy signal.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining trend linearity (R-squared) with overnight gap dynamics identifies sustainable continuations. The use of R-squared (POW of TS_CORR) effectively filters for 'stealth' accumulation where price movement is persistent rather than erratic. The transition from raw price ranges to Z-scores and cross-sectional ranks significantly improved the signal-to-noise ratio, confirming that the 'breakout' component needs to be relative to the specific instrument's volatility environment.",
        "decision": true,
        "reason": "Currently, the factor uses price-based linearity. However, true 'stealth' accumulation often occurs with consistent, non-volatile volume. If the volume during the 10-day linearity period is also stable (low coefficient of variation), it increases the probability that the subsequent gap is a genuine institutional shift rather than retail noise. Additionally, replacing the raw gap with a Volume-Weighted Average Price (VWAP) relative gap could improve the entry signal precision."
      }
    },
    "5521b9058ce1fb22": {
      "factor_id": "5521b9058ce1fb22",
      "factor_name": "ISB_Zscore_Breakout_20D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE($open - DELAY($close, 1), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE($open - DELAY($close, 1), 20)\" # Your output factor expression will be filled in here\n    name = \"ISB_Zscore_Breakout_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor combines the 10-day price linearity with a Z-scored overnight gap to identify breakouts that are statistically significant relative to the recent 20-day volatility environment.",
      "factor_formulation": "\\text{POW}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10), 2) \\times \\text{TS_ZSCORE}(\\text{open} - \\text{DELAY}(\\text{close}, 1), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "c22c4c2570d5",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "15343411702f"
        ],
        "hypothesis": "Hypothesis: The 'Institutional Stealth Breakout' (ISB) factor, calculated as the product of the 10-day price return R-squared and the ratio of the overnight gap to the 15-day price range, identifies sustainable price continuations by filtering overnight liquidity events through a lens of prior trend linearity.\n                Concise Observation: Parent 1 (IAF) captures stable institutional trends (RankIC 0.023) while Parent 2 (EVIB) captures explosive breakout events (RankIC 0.028); combining the slow-moving trend persistence with fast-moving overnight price gaps can filter out high-noise volatility spikes.\n                Concise Justification: High R-squared values indicate a 'quiet trend' of professional absorption, and an overnight gap (close-to-open) represents a sudden shift in liquidity; multiplying these ensures that only breakouts emerging from a disciplined, linear trend are flagged as high-conviction signals.\n                Concise Knowledge: If a price breakout occurs following a period of high statistical linearity (R-squared), it is more likely to represent institutional accumulation than a random speculative spike; when such breakouts are normalized by recent volatility compression, the signal quality improves.\n                concise Specification: The factor is defined as (10-day R-squared of daily close prices) * ((Open_t - Close_{t-1}) / (Max(High, 15) - Min(Low, 15))), where the R-squared is calculated against a linear time index and the denominator serves as a volatility-normalization constant.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:04:50.419086"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.0909875213438115,
        "ICIR": 0.0461961229115339,
        "1day.excess_return_without_cost.std": 0.0038009238399316,
        "1day.excess_return_with_cost.annualized_return": 0.0257242435898082,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0003044643583881,
        "1day.excess_return_without_cost.annualized_return": 0.0724625172963808,
        "1day.excess_return_with_cost.std": 0.00380161473814,
        "Rank IC": 0.0214296406808696,
        "IC": 0.0059630592524499,
        "1day.excess_return_without_cost.max_drawdown": -0.0775491315485204,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 1.235764659002519,
        "1day.pa": 0.0,
        "l2.valid": 0.9966106898626148,
        "Rank ICIR": 0.1704505814668444,
        "l2.train": 0.9937751907437564,
        "1day.excess_return_with_cost.information_ratio": 0.4386175777673567,
        "1day.excess_return_with_cost.mean": 0.0001080850571
      },
      "feedback": {
        "observations": "The experiment successfully tested three variations of the 'Institutional Stealth Breakout' (ISB) framework. The results show a significant improvement over the previous SOTA, particularly in terms of Information Ratio (1.236 vs 0.973) and Annualized Return (7.25% vs 5.20%). The IC also saw a marginal increase. While the Max Drawdown slightly worsened (-0.077 vs -0.072), the risk-adjusted returns (IR) suggest the current iteration is much more robust. The 'ISB_Zscore_Breakout_20D' and 'ISB_Ranked_Persistence_15D' likely contributed to this stability by normalizing the overnight gap, which is often a noisy signal.",
        "hypothesis_evaluation": "The results strongly support the hypothesis that combining trend linearity (R-squared) with overnight gap dynamics identifies sustainable continuations. The use of R-squared (POW of TS_CORR) effectively filters for 'stealth' accumulation where price movement is persistent rather than erratic. The transition from raw price ranges to Z-scores and cross-sectional ranks significantly improved the signal-to-noise ratio, confirming that the 'breakout' component needs to be relative to the specific instrument's volatility environment.",
        "decision": true,
        "reason": "Currently, the factor uses price-based linearity. However, true 'stealth' accumulation often occurs with consistent, non-volatile volume. If the volume during the 10-day linearity period is also stable (low coefficient of variation), it increases the probability that the subsequent gap is a genuine institutional shift rather than retail noise. Additionally, replacing the raw gap with a Volume-Weighted Average Price (VWAP) relative gap could improve the entry signal precision."
      }
    },
    "c2bc880157b825f2": {
      "factor_id": "c2bc880157b825f2",
      "factor_name": "Informed_Breakout_Resonance_5D",
      "factor_expression": "TS_CORR($close, $volume, 5) * (($open / (DELAY($close, 1) + 1e-8) - 1) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, $volume, 5) * (($open / DELAY($close, 1) - 1) / TS_MEAN($high - $low, 5)))\" # Your output factor expression will be filled in here\n    name = \"Informed_Breakout_Resonance_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies institutional trend initiation by combining pre-breakout accumulation (return-volume correlation) with breakout conviction (volatility-adjusted overnight gap). It targets stocks where prior volume-price synergy is validated by a significant price gap relative to recent intraday volatility.",
      "factor_formulation": "IBR_{5D} = \\text{TS\\_CORR}(\\text{close}, \\text{volume}, 5) \\times \\frac{(\\text{open} / \\text{DELAY}(\\text{close}, 1) - 1)}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "e3f9689b3f0b",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Informed Breakout Resonance' (IBR) factor identifies institutional trend initiation by multiplying the 5-day return-volume correlation (MSIA component) with the ratio of the overnight gap to the 5-day average intraday range (LVSB component), capturing breakouts preceded by informed accumulation.\n                Concise Observation: Parent 1 (MSIA) captures pre-breakout accumulation through volume-return synergy, while Parent 2 (LVSB) identifies breakout conviction via gap-to-dispersion ratios; both show positive RankIC but suffer from noise when used in isolation.\n                Concise Justification: Combining lead-lag indicators of accumulation and execution filters out speculative gaps that lack structural support, ensuring that the captured momentum is rooted in prior information asymmetry and validated by liquidity-efficient price action.\n                Concise Knowledge: If a significant overnight price gap occurs following a period of high volume-weighted price directionality, it likely represents institutional execution; when this gap is large relative to recent intraday volatility, the signal quality for a sustainable trend is enhanced.\n                concise Specification: The factor is defined as (Correlation of $close and $volume over 5 days) * (($open / $close[t-1] - 1) / Mean($high - $low, 5)), targeting stocks where the incubation phase (correlation) resonates with the breakout trigger (volatility-adjusted gap).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:12:25.934893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1010204969084028,
        "ICIR": 0.0394664694473316,
        "1day.excess_return_without_cost.std": 0.0041006287833142,
        "1day.excess_return_with_cost.annualized_return": -0.0055615139225531,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001751926683843,
        "1day.excess_return_without_cost.annualized_return": 0.0416958550754759,
        "1day.excess_return_with_cost.std": 0.0041022351106141,
        "Rank IC": 0.0225058594061146,
        "IC": 0.0054558898487561,
        "1day.excess_return_without_cost.max_drawdown": -0.0902128926008573,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6591040044051556,
        "1day.pa": 0.0,
        "l2.valid": 0.9965083323208964,
        "Rank ICIR": 0.1693125969117782,
        "l2.train": 0.9938567513835428,
        "1day.excess_return_with_cost.information_ratio": -0.0878787767151277,
        "1day.excess_return_with_cost.mean": -2.336770555694614e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Informed Breakout Resonance' (IBR) hypothesis. The current results, while positive, failed to outperform the existing SOTA across all key metrics including IC (0.0054 vs 0.0057) and Information Ratio (0.659 vs 0.972). Among the implementations, the 'Accumulated_Gap_Momentum_S_5D' and 'Z_Informed_Gap_Efficiency_10D' attempted to stabilize the signal using ranking and Z-scores, but the increased complexity in normalization did not translate to higher risk-adjusted returns. The original IBR_5D formulation suffered from scale mismatch between the correlation component and the volatility-adjusted gap, which likely introduced noise.",
        "hypothesis_evaluation": "The hypothesis that institutional breakouts are preceded by return-volume synergy is supported by the positive IC and annualized return, but the 'Resonance' (multiplication) of these two components appears highly sensitive to the normalization method. The 5-day window for accumulation (MSIA) might be too short to capture true institutional positioning, potentially picking up high-frequency noise instead of informed flow. Furthermore, using 'high - low' as a denominator in IBR_5D may create extreme outliers when intraday ranges compress, destabilizing the factor.",
        "decision": false,
        "reason": "1. Extending the accumulation window from 5 to 20 days filters out short-term retail noise and better aligns with institutional execution horizons. 2. Replacing 'high-low' with 'TS_STD(returns)' provides a more robust normalization for the gap, as price ranges are non-stationary and prone to spikes. 3. Using a Rank-based combination (addition instead of multiplication) can reduce the impact of outliers and prevent the signal from being zeroed out when one component is neutral."
      }
    },
    "9a986d11fbe7aba3": {
      "factor_id": "9a986d11fbe7aba3",
      "factor_name": "Z_Informed_Gap_Efficiency_10D",
      "factor_expression": "RANK(TS_CORR($close, $volume, 10)) * RANK(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(RANK(TS_CORR($close, $volume, 10)) * RANK(($open - DELAY($close, 1)) / (TS_STD($close, 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Z_Informed_Gap_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A cross-sectionally standardized version of the Informed Breakout Resonance hypothesis, using a 10-day window for accumulation and volatility normalization. It measures the efficiency of price gaps following periods of high volume-weighted price directionality.",
      "factor_formulation": "IGE_{10D} = \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{volume}, 10)) \\times \\text{RANK}\\left(\\frac{\\text{open} - \\text{DELAY}(\\text{close}, 1)}{\\text{TS\\_STD}(\\text{close}, 10)}\\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "e3f9689b3f0b",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Informed Breakout Resonance' (IBR) factor identifies institutional trend initiation by multiplying the 5-day return-volume correlation (MSIA component) with the ratio of the overnight gap to the 5-day average intraday range (LVSB component), capturing breakouts preceded by informed accumulation.\n                Concise Observation: Parent 1 (MSIA) captures pre-breakout accumulation through volume-return synergy, while Parent 2 (LVSB) identifies breakout conviction via gap-to-dispersion ratios; both show positive RankIC but suffer from noise when used in isolation.\n                Concise Justification: Combining lead-lag indicators of accumulation and execution filters out speculative gaps that lack structural support, ensuring that the captured momentum is rooted in prior information asymmetry and validated by liquidity-efficient price action.\n                Concise Knowledge: If a significant overnight price gap occurs following a period of high volume-weighted price directionality, it likely represents institutional execution; when this gap is large relative to recent intraday volatility, the signal quality for a sustainable trend is enhanced.\n                concise Specification: The factor is defined as (Correlation of $close and $volume over 5 days) * (($open / $close[t-1] - 1) / Mean($high - $low, 5)), targeting stocks where the incubation phase (correlation) resonates with the breakout trigger (volatility-adjusted gap).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:12:25.934893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1010204969084028,
        "ICIR": 0.0394664694473316,
        "1day.excess_return_without_cost.std": 0.0041006287833142,
        "1day.excess_return_with_cost.annualized_return": -0.0055615139225531,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001751926683843,
        "1day.excess_return_without_cost.annualized_return": 0.0416958550754759,
        "1day.excess_return_with_cost.std": 0.0041022351106141,
        "Rank IC": 0.0225058594061146,
        "IC": 0.0054558898487561,
        "1day.excess_return_without_cost.max_drawdown": -0.0902128926008573,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6591040044051556,
        "1day.pa": 0.0,
        "l2.valid": 0.9965083323208964,
        "Rank ICIR": 0.1693125969117782,
        "l2.train": 0.9938567513835428,
        "1day.excess_return_with_cost.information_ratio": -0.0878787767151277,
        "1day.excess_return_with_cost.mean": -2.336770555694614e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Informed Breakout Resonance' (IBR) hypothesis. The current results, while positive, failed to outperform the existing SOTA across all key metrics including IC (0.0054 vs 0.0057) and Information Ratio (0.659 vs 0.972). Among the implementations, the 'Accumulated_Gap_Momentum_S_5D' and 'Z_Informed_Gap_Efficiency_10D' attempted to stabilize the signal using ranking and Z-scores, but the increased complexity in normalization did not translate to higher risk-adjusted returns. The original IBR_5D formulation suffered from scale mismatch between the correlation component and the volatility-adjusted gap, which likely introduced noise.",
        "hypothesis_evaluation": "The hypothesis that institutional breakouts are preceded by return-volume synergy is supported by the positive IC and annualized return, but the 'Resonance' (multiplication) of these two components appears highly sensitive to the normalization method. The 5-day window for accumulation (MSIA) might be too short to capture true institutional positioning, potentially picking up high-frequency noise instead of informed flow. Furthermore, using 'high - low' as a denominator in IBR_5D may create extreme outliers when intraday ranges compress, destabilizing the factor.",
        "decision": false,
        "reason": "1. Extending the accumulation window from 5 to 20 days filters out short-term retail noise and better aligns with institutional execution horizons. 2. Replacing 'high-low' with 'TS_STD(returns)' provides a more robust normalization for the gap, as price ranges are non-stationary and prone to spikes. 3. Using a Rank-based combination (addition instead of multiplication) can reduce the impact of outliers and prevent the signal from being zeroed out when one component is neutral."
      }
    },
    "ad68a3156bf94181": {
      "factor_id": "ad68a3156bf94181",
      "factor_name": "Accumulated_Gap_Momentum_S_5D",
      "factor_expression": "TS_RANK(TS_CORR($close, $volume, 5), 10) * TS_ZSCORE($open / (DELAY($close, 1) + 1e-8), 10)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_RANK(TS_CORR($close, $volume, 5), 10) * TS_ZSCORE($open / (DELAY($close, 1) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Accumulated_Gap_Momentum_S_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the resonance between accumulation and breakout by multiplying the time-series rank of return-volume correlation with the standardized overnight gap. It focuses on the relative strength of the accumulation signal compared to its own history.",
      "factor_formulation": "AGM = \\text{TS\\_RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{volume}, 5), 10) \\times \\text{TS\\_ZSCORE}(\\text{open} / \\text{DELAY}(\\text{close}, 1), 10)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "e3f9689b3f0b",
        "parent_trajectory_ids": [
          "eb432bc3d7d9",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The 'Informed Breakout Resonance' (IBR) factor identifies institutional trend initiation by multiplying the 5-day return-volume correlation (MSIA component) with the ratio of the overnight gap to the 5-day average intraday range (LVSB component), capturing breakouts preceded by informed accumulation.\n                Concise Observation: Parent 1 (MSIA) captures pre-breakout accumulation through volume-return synergy, while Parent 2 (LVSB) identifies breakout conviction via gap-to-dispersion ratios; both show positive RankIC but suffer from noise when used in isolation.\n                Concise Justification: Combining lead-lag indicators of accumulation and execution filters out speculative gaps that lack structural support, ensuring that the captured momentum is rooted in prior information asymmetry and validated by liquidity-efficient price action.\n                Concise Knowledge: If a significant overnight price gap occurs following a period of high volume-weighted price directionality, it likely represents institutional execution; when this gap is large relative to recent intraday volatility, the signal quality for a sustainable trend is enhanced.\n                concise Specification: The factor is defined as (Correlation of $close and $volume over 5 days) * (($open / $close[t-1] - 1) / Mean($high - $low, 5)), targeting stocks where the incubation phase (correlation) resonates with the breakout trigger (volatility-adjusted gap).\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:12:25.934893"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1010204969084028,
        "ICIR": 0.0394664694473316,
        "1day.excess_return_without_cost.std": 0.0041006287833142,
        "1day.excess_return_with_cost.annualized_return": -0.0055615139225531,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0001751926683843,
        "1day.excess_return_without_cost.annualized_return": 0.0416958550754759,
        "1day.excess_return_with_cost.std": 0.0041022351106141,
        "Rank IC": 0.0225058594061146,
        "IC": 0.0054558898487561,
        "1day.excess_return_without_cost.max_drawdown": -0.0902128926008573,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.6591040044051556,
        "1day.pa": 0.0,
        "l2.valid": 0.9965083323208964,
        "Rank ICIR": 0.1693125969117782,
        "l2.train": 0.9938567513835428,
        "1day.excess_return_with_cost.information_ratio": -0.0878787767151277,
        "1day.excess_return_with_cost.mean": -2.336770555694614e-05
      },
      "feedback": {
        "observations": "The experiment evaluated three variations of the 'Informed Breakout Resonance' (IBR) hypothesis. The current results, while positive, failed to outperform the existing SOTA across all key metrics including IC (0.0054 vs 0.0057) and Information Ratio (0.659 vs 0.972). Among the implementations, the 'Accumulated_Gap_Momentum_S_5D' and 'Z_Informed_Gap_Efficiency_10D' attempted to stabilize the signal using ranking and Z-scores, but the increased complexity in normalization did not translate to higher risk-adjusted returns. The original IBR_5D formulation suffered from scale mismatch between the correlation component and the volatility-adjusted gap, which likely introduced noise.",
        "hypothesis_evaluation": "The hypothesis that institutional breakouts are preceded by return-volume synergy is supported by the positive IC and annualized return, but the 'Resonance' (multiplication) of these two components appears highly sensitive to the normalization method. The 5-day window for accumulation (MSIA) might be too short to capture true institutional positioning, potentially picking up high-frequency noise instead of informed flow. Furthermore, using 'high - low' as a denominator in IBR_5D may create extreme outliers when intraday ranges compress, destabilizing the factor.",
        "decision": false,
        "reason": "1. Extending the accumulation window from 5 to 20 days filters out short-term retail noise and better aligns with institutional execution horizons. 2. Replacing 'high-low' with 'TS_STD(returns)' provides a more robust normalization for the gap, as price ranges are non-stationary and prone to spikes. 3. Using a Rank-based combination (addition instead of multiplication) can reduce the impact of outliers and prevent the signal from being zeroed out when one component is neutral."
      }
    },
    "e127356ebc9b0da5": {
      "factor_id": "e127356ebc9b0da5",
      "factor_name": "ARP_Stability_Momentum_20D",
      "factor_expression": "(TS_SUM($return, 20) / (TS_STD($volume, 20) + 1e-8)) * (POW(TS_CORR($close, SEQUENCE(20), 20), 2) / ((TS_MEAN($high - $low, 20) / (TS_MEAN($close, 20) + 1e-8)) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_SUM(TS_PCTCHANGE($close, 1), 20) / (TS_STD($volume, 20) + 1e-8)) * (POW(TS_CORR($close, SEQUENCE(20), 20), 2) / (TS_MEAN($high - $low, 20) / (TS_MEAN($close, 20) + 1e-8) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"ARP_Stability_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Adaptive Regime Persistence (ARP) factor: It identifies high-quality trends by combining 20-day momentum (normalized by volume volatility) with a structural health filter. The filter rewards price linearity (R-squared of price vs. time) and penalizes high intraday dispersion (High-Low range).",
      "factor_formulation": "ARP = \\left( \\frac{\\sum_{i=1}^{20} \\text{return}_i}{\\text{TS_STD}(\\text{volume}, 20)} \\right) \\times \\left( \\frac{\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(20), 20)^2}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 20) / \\text{TS_MEAN}(\\text{close}, 20)} \\right)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "326a44359ecb",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Adaptive Regime Persistence' (ARP) factor identifies high-quality trends by multiplying the 20-day momentum (scaled by the inverse of 20-day volume standard deviation) by a 'Structural Health' filter that penalizes high intraday price dispersion (High-Low range) relative to price linearity (R-squared).\n                Concise Observation: Parent 1 (ICP) successfully captures trend persistence via volume stability (RankIC 0.0249), while Parent 2 (FES) identifies reversal points through price linearity and dispersion (RankIC 0.0260), suggesting that momentum quality is conditional on intraday price behavior.\n                Concise Justification: By fusing Parent 1's volume-weighted momentum with Parent 2's exhaustion logic, the factor distinguishes between 'quiet accumulation' (stable volume, narrow intraday ranges) and 'noisy distribution' (volatile volume, wide intraday ranges), enhancing the signal-to-noise ratio of trend following.\n                Concise Knowledge: If momentum is accompanied by low volume volatility, the trend is more sustainable; however, if high trend linearity (R-squared) coincides with expanding intraday price dispersion, the asset is likely entering a fractal exhaustion phase regardless of its momentum.\n                concise Specification: Define ARP as (20-day Return / 20-day StdDev of Volume) * (1 / (20-day High-Low Range / 20-day R-squared of Close prices)), where R-squared is calculated over a 20-day lookback window.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:28:30.766967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1447182964967509,
        "ICIR": 0.046053784675255,
        "1day.excess_return_without_cost.std": 0.0050125035457234,
        "1day.excess_return_with_cost.annualized_return": 0.0119503732617394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000251075075355,
        "1day.excess_return_without_cost.annualized_return": 0.0597558679344904,
        "1day.excess_return_with_cost.std": 0.0050139212530742,
        "Rank IC": 0.0221755251648344,
        "IC": 0.0066530330598884,
        "1day.excess_return_without_cost.max_drawdown": -0.1314612386632318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7727471062294823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965626427365224,
        "Rank ICIR": 0.1549158454935542,
        "l2.train": 0.9932464419146758,
        "1day.excess_return_with_cost.information_ratio": 0.1544953750789007,
        "1day.excess_return_with_cost.mean": 5.021165236024973e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Adaptive Regime Persistence' (ARP) framework. The 'ARP_Stability_Momentum_20D' and 'STQ' factors successfully captured the interaction between price linearity (R-squared) and intraday noise. The current results show a significant improvement in IC (0.0066 vs 0.0057) and Annualized Return (0.0597 vs 0.0520) compared to the SOTA, although the Information Ratio and Max Drawdown have deteriorated, suggesting higher volatility in the new factor's performance.",
        "hypothesis_evaluation": "The results support the hypothesis that combining price linearity (R-squared) with a penalty for intraday dispersion (High-Low range) identifies higher-quality trends. Specifically, the inclusion of the 'Structural Health' filter (Linearity / Noise) effectively filters out 'noisy' momentum. However, the high Max Drawdown suggests that the current scaling method (using raw volume standard deviation) might be introducing instability or that the 20-day window is sensitive to regime shifts.",
        "decision": true,
        "reason": "The current ARP factor uses a 20-day average for both linearity and intraday dispersion. Intraday noise (High-Low) is often a leading indicator of trend exhaustion and reacts faster than 20-day linearity. By shortening the noise window to 5 days, we can exit deteriorating trends sooner. Additionally, the current volume scaling (TS_STD) is not unit-less; using a Z-score or Rank-based volume stability will prevent the factor from being dominated by high-volume stocks, likely improving the Information Ratio and reducing Drawdown."
      }
    },
    "d4247873a500eacf": {
      "factor_id": "d4247873a500eacf",
      "factor_name": "Structural_Trend_Quality_20D",
      "factor_expression": "TS_PCTCHANGE($close, 20) * POW(TS_CORR($close, SEQUENCE(20), 20), 2) / (TS_MEAN($high - $low, 20) / (TS_MEAN($close, 20) + 1e-8) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 20) * POW(TS_CORR($close, SEQUENCE(20), 20), 2) / (TS_MEAN($high - $low, 20) / (TS_MEAN($close, 20) + 1e-8) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Structural_Trend_Quality_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the ARP hypothesis focusing on the ratio of trend linearity to intraday noise, scaled by momentum. It uses the R-squared of closing prices against time to measure trend strength and the average daily range to measure noise, ensuring the trend is 'quiet' and 'linear'.",
      "factor_formulation": "STQ = \\text{TS_PCTCHANGE}(\\text{close}, 20) \\times \\frac{\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(20), 20)^2}{\\text{TS_MEAN}(\\text{high} - \\text{low}, 20) / \\text{TS_MEAN}(\\text{close}, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "326a44359ecb",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Adaptive Regime Persistence' (ARP) factor identifies high-quality trends by multiplying the 20-day momentum (scaled by the inverse of 20-day volume standard deviation) by a 'Structural Health' filter that penalizes high intraday price dispersion (High-Low range) relative to price linearity (R-squared).\n                Concise Observation: Parent 1 (ICP) successfully captures trend persistence via volume stability (RankIC 0.0249), while Parent 2 (FES) identifies reversal points through price linearity and dispersion (RankIC 0.0260), suggesting that momentum quality is conditional on intraday price behavior.\n                Concise Justification: By fusing Parent 1's volume-weighted momentum with Parent 2's exhaustion logic, the factor distinguishes between 'quiet accumulation' (stable volume, narrow intraday ranges) and 'noisy distribution' (volatile volume, wide intraday ranges), enhancing the signal-to-noise ratio of trend following.\n                Concise Knowledge: If momentum is accompanied by low volume volatility, the trend is more sustainable; however, if high trend linearity (R-squared) coincides with expanding intraday price dispersion, the asset is likely entering a fractal exhaustion phase regardless of its momentum.\n                concise Specification: Define ARP as (20-day Return / 20-day StdDev of Volume) * (1 / (20-day High-Low Range / 20-day R-squared of Close prices)), where R-squared is calculated over a 20-day lookback window.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:28:30.766967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1447182964967509,
        "ICIR": 0.046053784675255,
        "1day.excess_return_without_cost.std": 0.0050125035457234,
        "1day.excess_return_with_cost.annualized_return": 0.0119503732617394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000251075075355,
        "1day.excess_return_without_cost.annualized_return": 0.0597558679344904,
        "1day.excess_return_with_cost.std": 0.0050139212530742,
        "Rank IC": 0.0221755251648344,
        "IC": 0.0066530330598884,
        "1day.excess_return_without_cost.max_drawdown": -0.1314612386632318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7727471062294823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965626427365224,
        "Rank ICIR": 0.1549158454935542,
        "l2.train": 0.9932464419146758,
        "1day.excess_return_with_cost.information_ratio": 0.1544953750789007,
        "1day.excess_return_with_cost.mean": 5.021165236024973e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Adaptive Regime Persistence' (ARP) framework. The 'ARP_Stability_Momentum_20D' and 'STQ' factors successfully captured the interaction between price linearity (R-squared) and intraday noise. The current results show a significant improvement in IC (0.0066 vs 0.0057) and Annualized Return (0.0597 vs 0.0520) compared to the SOTA, although the Information Ratio and Max Drawdown have deteriorated, suggesting higher volatility in the new factor's performance.",
        "hypothesis_evaluation": "The results support the hypothesis that combining price linearity (R-squared) with a penalty for intraday dispersion (High-Low range) identifies higher-quality trends. Specifically, the inclusion of the 'Structural Health' filter (Linearity / Noise) effectively filters out 'noisy' momentum. However, the high Max Drawdown suggests that the current scaling method (using raw volume standard deviation) might be introducing instability or that the 20-day window is sensitive to regime shifts.",
        "decision": true,
        "reason": "The current ARP factor uses a 20-day average for both linearity and intraday dispersion. Intraday noise (High-Low) is often a leading indicator of trend exhaustion and reacts faster than 20-day linearity. By shortening the noise window to 5 days, we can exit deteriorating trends sooner. Additionally, the current volume scaling (TS_STD) is not unit-less; using a Z-score or Rank-based volume stability will prevent the factor from being dominated by high-volume stocks, likely improving the Information Ratio and reducing Drawdown."
      }
    },
    "a6d43eef351aeb6c": {
      "factor_id": "a6d43eef351aeb6c",
      "factor_name": "Volume_Adjusted_Linearity_20D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (RANK(TS_STD($volume, 20)) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) / (RANK(TS_STD($volume, 20)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Adjusted_Linearity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor captures the ARP logic by weighting price linearity (R-squared) with the inverse of volume volatility. It identifies regimes where price moves are consistent and volume is stable, suggesting institutional accumulation rather than speculative volatility.",
      "factor_formulation": "VAL = \\text{RANK}(\\text{TS_CORR}(\\text{close}, \\text{SEQUENCE}(20), 20)^2) / \\text{RANK}(\\text{TS_STD}(\\text{volume}, 20))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "326a44359ecb",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "387975e43d62"
        ],
        "hypothesis": "Hypothesis: The 'Adaptive Regime Persistence' (ARP) factor identifies high-quality trends by multiplying the 20-day momentum (scaled by the inverse of 20-day volume standard deviation) by a 'Structural Health' filter that penalizes high intraday price dispersion (High-Low range) relative to price linearity (R-squared).\n                Concise Observation: Parent 1 (ICP) successfully captures trend persistence via volume stability (RankIC 0.0249), while Parent 2 (FES) identifies reversal points through price linearity and dispersion (RankIC 0.0260), suggesting that momentum quality is conditional on intraday price behavior.\n                Concise Justification: By fusing Parent 1's volume-weighted momentum with Parent 2's exhaustion logic, the factor distinguishes between 'quiet accumulation' (stable volume, narrow intraday ranges) and 'noisy distribution' (volatile volume, wide intraday ranges), enhancing the signal-to-noise ratio of trend following.\n                Concise Knowledge: If momentum is accompanied by low volume volatility, the trend is more sustainable; however, if high trend linearity (R-squared) coincides with expanding intraday price dispersion, the asset is likely entering a fractal exhaustion phase regardless of its momentum.\n                concise Specification: Define ARP as (20-day Return / 20-day StdDev of Volume) * (1 / (20-day High-Low Range / 20-day R-squared of Close prices)), where R-squared is calculated over a 20-day lookback window.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:28:30.766967"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1447182964967509,
        "ICIR": 0.046053784675255,
        "1day.excess_return_without_cost.std": 0.0050125035457234,
        "1day.excess_return_with_cost.annualized_return": 0.0119503732617394,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.000251075075355,
        "1day.excess_return_without_cost.annualized_return": 0.0597558679344904,
        "1day.excess_return_with_cost.std": 0.0050139212530742,
        "Rank IC": 0.0221755251648344,
        "IC": 0.0066530330598884,
        "1day.excess_return_without_cost.max_drawdown": -0.1314612386632318,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.7727471062294823,
        "1day.pa": 0.0,
        "l2.valid": 0.9965626427365224,
        "Rank ICIR": 0.1549158454935542,
        "l2.train": 0.9932464419146758,
        "1day.excess_return_with_cost.information_ratio": 0.1544953750789007,
        "1day.excess_return_with_cost.mean": 5.021165236024973e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the 'Adaptive Regime Persistence' (ARP) framework. The 'ARP_Stability_Momentum_20D' and 'STQ' factors successfully captured the interaction between price linearity (R-squared) and intraday noise. The current results show a significant improvement in IC (0.0066 vs 0.0057) and Annualized Return (0.0597 vs 0.0520) compared to the SOTA, although the Information Ratio and Max Drawdown have deteriorated, suggesting higher volatility in the new factor's performance.",
        "hypothesis_evaluation": "The results support the hypothesis that combining price linearity (R-squared) with a penalty for intraday dispersion (High-Low range) identifies higher-quality trends. Specifically, the inclusion of the 'Structural Health' filter (Linearity / Noise) effectively filters out 'noisy' momentum. However, the high Max Drawdown suggests that the current scaling method (using raw volume standard deviation) might be introducing instability or that the 20-day window is sensitive to regime shifts.",
        "decision": true,
        "reason": "The current ARP factor uses a 20-day average for both linearity and intraday dispersion. Intraday noise (High-Low) is often a leading indicator of trend exhaustion and reacts faster than 20-day linearity. By shortening the noise window to 5 days, we can exit deteriorating trends sooner. Additionally, the current volume scaling (TS_STD) is not unit-less; using a Z-score or Rank-based volume stability will prevent the factor from being dominated by high-volume stocks, likely improving the Information Ratio and reducing Drawdown."
      }
    },
    "20d54d7b48e883fc": {
      "factor_id": "20d54d7b48e883fc",
      "factor_name": "SLVP_Trend_Quality_20D",
      "factor_expression": "(TS_MEAN($return, 20) / (TS_STD($volume, 20) + 1e-8)) / ((TS_ZSCORE($high - $low, 20) + 3) * (TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(($close / DELAY($close, 1) - 1), 20) / (TS_STD($volume, 20) + 1e-8)) / ((TS_ZSCORE(($high - $low), 20) + 3) * (TS_MEAN(ABS(($close / DELAY($close, 1) - 1)) / ($volume + 1e-8), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"SLVP_Trend_Quality_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "Structural Liquidity-Validated Persistence (SLVP) identifies high-quality price trends by scaling volatility-adjusted momentum by a liquidity-driven exhaustion index. It rewards stable price growth and penalizes moves driven by liquidity gaps or extreme volatility.",
      "factor_formulation": "\\frac{TS\\_MEAN(return, 20) / (TS\\_STD(volume, 20) + 1e-8)}{TS\\_ZSCORE(high - low, 20) * (TS\\_MEAN(ABS(return) / (volume + 1e-8), 5) + 1e-8)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d1120623eeb4",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity-Validated Persistence (SLVP) factor identifies high-quality price trends by calculating the ratio of the 20-day volatility-adjusted momentum (ICP) to the 5-day liquidity-driven exhaustion risk (LSEF), effectively filtering out fragile price extensions.\n                Concise Observation: Parent 1 (ICP) captures trend stability but fails at blow-off tops, while Parent 2 (LSEF) identifies exhaustion but may prematurely signal reversals in strong trends; combining them addresses the 'hollow trend' problem.\n                Concise Justification: By dividing a stability-weighted momentum signal by a liquidity-based fragility index, we create a 'Trend-Quality Score' that rewards persistent accumulation and penalizes price moves driven by liquidity gaps.\n                Concise Knowledge: If price momentum is supported by low volume volatility (institutional stability) and low illiquidity-to-range ratios (liquidity depth), the trend is more likely to persist; conversely, high momentum coupled with high illiquidity and extreme ranges signals speculative exhaustion.\n                concise Specification: Define SLVP as (Momentum_20d / StdDev_Volume_20d) / ((High-Low)_Zscore_20d * (Amihud_Illiquidity_5d + epsilon)), where Amihud is abs(return)/volume; high values indicate liquid-backed persistence, low values indicate fragile or exhausting moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:33:58.070557"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1303720928184681,
        "ICIR": 0.0380192815918315,
        "1day.excess_return_without_cost.std": 0.0046823213224096,
        "1day.excess_return_with_cost.annualized_return": 0.011364598649236,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002452135700422,
        "1day.excess_return_without_cost.annualized_return": 0.0583608296700495,
        "1day.excess_return_with_cost.std": 0.0046830729416243,
        "Rank IC": 0.0216528874157297,
        "IC": 0.0054538600892595,
        "1day.excess_return_without_cost.max_drawdown": -0.1107188278706524,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8079263360390512,
        "1day.pa": 0.0,
        "l2.valid": 0.9965786579495284,
        "Rank ICIR": 0.1567837122833507,
        "l2.train": 0.9942921509664324,
        "1day.excess_return_with_cost.information_ratio": 0.1573021657560529,
        "1day.excess_return_with_cost.mean": 4.775041449258864e-05
      },
      "feedback": {
        "observations": "The current experiment tested two variations of the 'Structural Liquidity-Validated Persistence' (SLVP) hypothesis. The 'SLVP_Trend_Quality_20D' factor achieved a higher annualized return (0.05836 vs. 0.05201) compared to the previous SOTA, although it showed a higher maximum drawdown and a slightly lower Information Ratio and IC. The implementation of 'Liquidity_Adjusted_Momentum_Stability' provided a simplified baseline, but the more complex SLVP formulation drove the gain in raw return. However, the current SOTA still maintains better risk-adjusted performance (IR) and lower drawdown, suggesting the current implementation of SLVP might be capturing higher beta or more volatile alpha segments.",
        "hypothesis_evaluation": "The hypothesis that scaling volatility-adjusted momentum by a liquidity-driven exhaustion index identifies high-quality trends is partially supported. The improvement in annualized return suggests that the interaction between price persistence and liquidity constraints (Amihud illiquidity and range-based Z-scores) captures meaningful market dynamics. However, the deterioration in Information Ratio and Max Drawdown indicates that the current mathematical representation (specifically the product of Z-score and Amihud illiquidity in the denominator) may be creating extreme values or 'noise' that reduces factor stability.",
        "decision": true,
        "reason": "The current formulation uses a product of two high-variance terms in the denominator ($TS_ZSCORE(high-low)$ and $TS_MEAN(Amihud)$). This can lead to unstable factor values when either liquidity or volatility spikes momentarily. By using a log-transform or an additive approach for the 'exhaustion' component, we can create a smoother filter. Additionally, reducing the number of base features (currently using high, low, close, volume, and return) will help manage the complexity and improve the Information Ratio by focusing on the most robust interactions."
      }
    },
    "c7093d578e94ee6b": {
      "factor_id": "c7093d578e94ee6b",
      "factor_name": "Liquidity_Adjusted_Momentum_Stability",
      "factor_expression": "RANK(TS_MEAN($return, 20) / (TS_STD($return, 20) + 1e-8)) / RANK(TS_MEAN(ABS($return) / ($volume + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN(($close / DELAY($close, 1) - 1), 20) / (TS_STD(($close / DELAY($close, 1) - 1), 20) + 1e-8)) / (TS_MEAN(ABS(($close / DELAY($close, 1) - 1)) / ($volume + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Momentum_Stability\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the SLVP hypothesis focusing on the ratio of return persistence to the Amihud illiquidity measure. High values indicate that returns are achieved with high liquidity (low price impact), suggesting institutional accumulation rather than retail exhaustion.",
      "factor_formulation": "\\frac{TS\\_MEAN(return, 20) / TS\\_STD(return, 20)}{TS\\_MEAN(ABS(return) / (volume + 1e-8), 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d1120623eeb4",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity-Validated Persistence (SLVP) factor identifies high-quality price trends by calculating the ratio of the 20-day volatility-adjusted momentum (ICP) to the 5-day liquidity-driven exhaustion risk (LSEF), effectively filtering out fragile price extensions.\n                Concise Observation: Parent 1 (ICP) captures trend stability but fails at blow-off tops, while Parent 2 (LSEF) identifies exhaustion but may prematurely signal reversals in strong trends; combining them addresses the 'hollow trend' problem.\n                Concise Justification: By dividing a stability-weighted momentum signal by a liquidity-based fragility index, we create a 'Trend-Quality Score' that rewards persistent accumulation and penalizes price moves driven by liquidity gaps.\n                Concise Knowledge: If price momentum is supported by low volume volatility (institutional stability) and low illiquidity-to-range ratios (liquidity depth), the trend is more likely to persist; conversely, high momentum coupled with high illiquidity and extreme ranges signals speculative exhaustion.\n                concise Specification: Define SLVP as (Momentum_20d / StdDev_Volume_20d) / ((High-Low)_Zscore_20d * (Amihud_Illiquidity_5d + epsilon)), where Amihud is abs(return)/volume; high values indicate liquid-backed persistence, low values indicate fragile or exhausting moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:33:58.070557"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1303720928184681,
        "ICIR": 0.0380192815918315,
        "1day.excess_return_without_cost.std": 0.0046823213224096,
        "1day.excess_return_with_cost.annualized_return": 0.011364598649236,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002452135700422,
        "1day.excess_return_without_cost.annualized_return": 0.0583608296700495,
        "1day.excess_return_with_cost.std": 0.0046830729416243,
        "Rank IC": 0.0216528874157297,
        "IC": 0.0054538600892595,
        "1day.excess_return_without_cost.max_drawdown": -0.1107188278706524,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8079263360390512,
        "1day.pa": 0.0,
        "l2.valid": 0.9965786579495284,
        "Rank ICIR": 0.1567837122833507,
        "l2.train": 0.9942921509664324,
        "1day.excess_return_with_cost.information_ratio": 0.1573021657560529,
        "1day.excess_return_with_cost.mean": 4.775041449258864e-05
      },
      "feedback": {
        "observations": "The current experiment tested two variations of the 'Structural Liquidity-Validated Persistence' (SLVP) hypothesis. The 'SLVP_Trend_Quality_20D' factor achieved a higher annualized return (0.05836 vs. 0.05201) compared to the previous SOTA, although it showed a higher maximum drawdown and a slightly lower Information Ratio and IC. The implementation of 'Liquidity_Adjusted_Momentum_Stability' provided a simplified baseline, but the more complex SLVP formulation drove the gain in raw return. However, the current SOTA still maintains better risk-adjusted performance (IR) and lower drawdown, suggesting the current implementation of SLVP might be capturing higher beta or more volatile alpha segments.",
        "hypothesis_evaluation": "The hypothesis that scaling volatility-adjusted momentum by a liquidity-driven exhaustion index identifies high-quality trends is partially supported. The improvement in annualized return suggests that the interaction between price persistence and liquidity constraints (Amihud illiquidity and range-based Z-scores) captures meaningful market dynamics. However, the deterioration in Information Ratio and Max Drawdown indicates that the current mathematical representation (specifically the product of Z-score and Amihud illiquidity in the denominator) may be creating extreme values or 'noise' that reduces factor stability.",
        "decision": true,
        "reason": "The current formulation uses a product of two high-variance terms in the denominator ($TS_ZSCORE(high-low)$ and $TS_MEAN(Amihud)$). This can lead to unstable factor values when either liquidity or volatility spikes momentarily. By using a log-transform or an additive approach for the 'exhaustion' component, we can create a smoother filter. Additionally, reducing the number of base features (currently using high, low, close, volume, and return) will help manage the complexity and improve the Information Ratio by focusing on the most robust interactions."
      }
    },
    "d433a5c79a48fbb9": {
      "factor_id": "d433a5c79a48fbb9",
      "factor_name": "Exhaustion_Risk_Filtered_Momentum",
      "factor_expression": "TS_PCTCHANGE($close, 20) / ((TS_ZSCORE($high - $low, 20) + 3) * (TS_STD($volume, 20) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "",
      "factor_description": "This factor identifies 'hollow trends' by penalizing 20-day price momentum when the 5-day price range (volatility) expands significantly relative to its recent history, normalized by volume stability.",
      "factor_formulation": "\\frac{TS\\_PCTCHANGE(close, 20)}{TS\\_ZSCORE(high - low, 20) * TS\\_STD(volume, 20)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d1120623eeb4",
        "parent_trajectory_ids": [
          "7695cdd33a33",
          "00a50f728443"
        ],
        "hypothesis": "Hypothesis: The Structural Liquidity-Validated Persistence (SLVP) factor identifies high-quality price trends by calculating the ratio of the 20-day volatility-adjusted momentum (ICP) to the 5-day liquidity-driven exhaustion risk (LSEF), effectively filtering out fragile price extensions.\n                Concise Observation: Parent 1 (ICP) captures trend stability but fails at blow-off tops, while Parent 2 (LSEF) identifies exhaustion but may prematurely signal reversals in strong trends; combining them addresses the 'hollow trend' problem.\n                Concise Justification: By dividing a stability-weighted momentum signal by a liquidity-based fragility index, we create a 'Trend-Quality Score' that rewards persistent accumulation and penalizes price moves driven by liquidity gaps.\n                Concise Knowledge: If price momentum is supported by low volume volatility (institutional stability) and low illiquidity-to-range ratios (liquidity depth), the trend is more likely to persist; conversely, high momentum coupled with high illiquidity and extreme ranges signals speculative exhaustion.\n                concise Specification: Define SLVP as (Momentum_20d / StdDev_Volume_20d) / ((High-Low)_Zscore_20d * (Amihud_Illiquidity_5d + epsilon)), where Amihud is abs(return)/volume; high values indicate liquid-backed persistence, low values indicate fragile or exhausting moves.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:33:58.070557"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1303720928184681,
        "ICIR": 0.0380192815918315,
        "1day.excess_return_without_cost.std": 0.0046823213224096,
        "1day.excess_return_with_cost.annualized_return": 0.011364598649236,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002452135700422,
        "1day.excess_return_without_cost.annualized_return": 0.0583608296700495,
        "1day.excess_return_with_cost.std": 0.0046830729416243,
        "Rank IC": 0.0216528874157297,
        "IC": 0.0054538600892595,
        "1day.excess_return_without_cost.max_drawdown": -0.1107188278706524,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8079263360390512,
        "1day.pa": 0.0,
        "l2.valid": 0.9965786579495284,
        "Rank ICIR": 0.1567837122833507,
        "l2.train": 0.9942921509664324,
        "1day.excess_return_with_cost.information_ratio": 0.1573021657560529,
        "1day.excess_return_with_cost.mean": 4.775041449258864e-05
      },
      "feedback": {
        "observations": "The current experiment tested two variations of the 'Structural Liquidity-Validated Persistence' (SLVP) hypothesis. The 'SLVP_Trend_Quality_20D' factor achieved a higher annualized return (0.05836 vs. 0.05201) compared to the previous SOTA, although it showed a higher maximum drawdown and a slightly lower Information Ratio and IC. The implementation of 'Liquidity_Adjusted_Momentum_Stability' provided a simplified baseline, but the more complex SLVP formulation drove the gain in raw return. However, the current SOTA still maintains better risk-adjusted performance (IR) and lower drawdown, suggesting the current implementation of SLVP might be capturing higher beta or more volatile alpha segments.",
        "hypothesis_evaluation": "The hypothesis that scaling volatility-adjusted momentum by a liquidity-driven exhaustion index identifies high-quality trends is partially supported. The improvement in annualized return suggests that the interaction between price persistence and liquidity constraints (Amihud illiquidity and range-based Z-scores) captures meaningful market dynamics. However, the deterioration in Information Ratio and Max Drawdown indicates that the current mathematical representation (specifically the product of Z-score and Amihud illiquidity in the denominator) may be creating extreme values or 'noise' that reduces factor stability.",
        "decision": true,
        "reason": "The current formulation uses a product of two high-variance terms in the denominator ($TS_ZSCORE(high-low)$ and $TS_MEAN(Amihud)$). This can lead to unstable factor values when either liquidity or volatility spikes momentarily. By using a log-transform or an additive approach for the 'exhaustion' component, we can create a smoother filter. Additionally, reducing the number of base features (currently using high, low, close, volume, and return) will help manage the complexity and improve the Information Ratio by focusing on the most robust interactions."
      }
    },
    "a4dc54dfc38597a5": {
      "factor_id": "a4dc54dfc38597a5",
      "factor_name": "ISP_Stealth_Breakout_Factor",
      "factor_expression": "RANK(TS_MEAN((($high + $low + $close) / 3 - ($open + $close) / 2), 10)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN((($high + $low + $close) / 3 - ($open + $close) / 2), 10)) * RANK(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ISP_Stealth_Breakout_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies Informed Structural Pre-emption by combining a 10-day stealth accumulation score with a 1-day breakout efficiency score. The stealth component uses the divergence between the average price (approximated by (H+L+C)/3) and the time-weighted average (open/close proxy) during low-volume periods. The breakout component normalizes the overnight gap by the recent intraday range.",
      "factor_formulation": "\\text{ISP} = \\text{RANK}(\\text{TS_MEAN}((($high + $low + $close)/3 - ($open + $close)/2), 10)) * \\text{RANK}(($open - \\text{DELAY}($close, 1)) / (\\text{TS_MEAN}($high - $low, 5) + 1e-8))",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d7204bd90464",
        "parent_trajectory_ids": [
          "51d281e76291",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Informed Structural Pre-emption (ISP) factor identifies stocks by multiplying a 10-day stealth accumulation score (low-volume divergence between price-weighted and time-weighted averages) by a 1-day breakout efficiency score (overnight gap normalized by intraday volatility).\n                Concise Observation: Parent 1 (AID) captures early signals but lacks timing, while Parent 2 (LVSB) captures momentum but suffers from false breakouts; combining them targets the transition from quiet positioning to active price discovery.\n                Concise Justification: The interaction between information decay (setup) and gap efficiency (trigger) creates a non-linear filter that requires both prior hidden demand and current market validation, reducing noise from retail-driven volatility.\n                Concise Knowledge: If stealth accumulation by informed actors precedes a price breakout, the subsequent price move is more sustainable; when low-volume price-time divergence is followed by a high-efficiency overnight gap, the probability of a high-conviction institutional trend increases.\n                concise Specification: Define AID as the 10-day mean of (VWAP - TWAP) during low-volume periods; define LVSB as (Open - Prev_Close) divided by the 5-day average intraday range; the final ISP factor is the product of these two metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:37:56.729630"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1181062109795754,
        "ICIR": 0.049588885020752,
        "1day.excess_return_without_cost.std": 0.0041557530030952,
        "1day.excess_return_with_cost.annualized_return": 0.0118769886272772,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002475769761354,
        "1day.excess_return_without_cost.annualized_return": 0.0589233203202325,
        "1day.excess_return_with_cost.std": 0.0041553580966072,
        "Rank IC": 0.0271742342497613,
        "IC": 0.006922327091659,
        "1day.excess_return_without_cost.max_drawdown": -0.0948400043707983,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.919070878543165,
        "1day.pa": 0.0,
        "l2.valid": 0.9963171462588418,
        "Rank ICIR": 0.1980746999492646,
        "l2.train": 0.9933581287159392,
        "1day.excess_return_with_cost.information_ratio": 0.1852718363568608,
        "1day.excess_return_with_cost.mean": 4.9903313559988514e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Informed Structural Pre-emption (ISP) hypothesis. The current result, primarily driven by the 'ISP_Stealth_Breakout_Factor' and its counterparts, shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0069 and an increase in Annualized Return from 0.052 to 0.0589. However, this comes at the cost of a higher Max Drawdown (-0.0948 vs -0.0726) and a slightly lower Information Ratio (0.919 vs 0.972). The IC improvement suggests that the interaction between stealth accumulation and breakout efficiency captures meaningful predictive signal.",
        "hypothesis_evaluation": "The results support the hypothesis that combining a multi-day stealth accumulation metric with a 1-day breakout efficiency score provides a superior predictive signal compared to single-dimension factors. The 'ISP_Stealth_Breakout_Factor' successfully identifies a lead-lag relationship between quiet positioning and price discovery. However, the increased drawdown suggests that the 'breakout' component might be sensitive to market volatility, requiring better normalization or a more robust definition of 'stealth'.",
        "decision": true,
        "reason": "The current 'stealth' component uses a simple price difference which may be scale-dependent. By using the 'volume-weighted price spread' (as seen in SGZ) but refining it to focus on 'negative volume-return correlation' (quiet accumulation often happens on low volume or price-volume divergence), we can better isolate informed buying. Furthermore, the 1-day gap should be compared against the cross-section rather than just its own history to ensure the 'breakout' is idiosyncratic rather than a market-wide gap-up, which should improve the Information Ratio and reduce Drawdown."
      }
    },
    "ad9ccae192bc35c8": {
      "factor_id": "ad9ccae192bc35c8",
      "factor_name": "Informed_Accumulation_Efficiency",
      "factor_expression": "RANK($open / DELAY($close, 1) - 1) / (RANK(TS_CORR($return, $volume, 10)) + 1.1)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($open / DELAY($close, 1)) - 1) / (RANK(TS_CORR($close / DELAY($close, 1) - 1, $volume, 10)) + 1.1)\" # Your output factor expression will be filled in here\n    name = \"Informed_Accumulation_Efficiency\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A simplified version of the ISP hypothesis focusing on the interaction between price-volume divergence and gap momentum. It captures stocks where the current overnight gap is high relative to its 10-day price-volume correlation, identifying high-conviction institutional moves following quiet accumulation.",
      "factor_formulation": "\\text{IAE} = \\frac{\\text{RANK}($open / \\text{DELAY}($close, 1) - 1)}{\\text{RANK}(\\text{TS_CORR}($return, $volume, 10)) + 1.1}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d7204bd90464",
        "parent_trajectory_ids": [
          "51d281e76291",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Informed Structural Pre-emption (ISP) factor identifies stocks by multiplying a 10-day stealth accumulation score (low-volume divergence between price-weighted and time-weighted averages) by a 1-day breakout efficiency score (overnight gap normalized by intraday volatility).\n                Concise Observation: Parent 1 (AID) captures early signals but lacks timing, while Parent 2 (LVSB) captures momentum but suffers from false breakouts; combining them targets the transition from quiet positioning to active price discovery.\n                Concise Justification: The interaction between information decay (setup) and gap efficiency (trigger) creates a non-linear filter that requires both prior hidden demand and current market validation, reducing noise from retail-driven volatility.\n                Concise Knowledge: If stealth accumulation by informed actors precedes a price breakout, the subsequent price move is more sustainable; when low-volume price-time divergence is followed by a high-efficiency overnight gap, the probability of a high-conviction institutional trend increases.\n                concise Specification: Define AID as the 10-day mean of (VWAP - TWAP) during low-volume periods; define LVSB as (Open - Prev_Close) divided by the 5-day average intraday range; the final ISP factor is the product of these two metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:37:56.729630"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1181062109795754,
        "ICIR": 0.049588885020752,
        "1day.excess_return_without_cost.std": 0.0041557530030952,
        "1day.excess_return_with_cost.annualized_return": 0.0118769886272772,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002475769761354,
        "1day.excess_return_without_cost.annualized_return": 0.0589233203202325,
        "1day.excess_return_with_cost.std": 0.0041553580966072,
        "Rank IC": 0.0271742342497613,
        "IC": 0.006922327091659,
        "1day.excess_return_without_cost.max_drawdown": -0.0948400043707983,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.919070878543165,
        "1day.pa": 0.0,
        "l2.valid": 0.9963171462588418,
        "Rank ICIR": 0.1980746999492646,
        "l2.train": 0.9933581287159392,
        "1day.excess_return_with_cost.information_ratio": 0.1852718363568608,
        "1day.excess_return_with_cost.mean": 4.9903313559988514e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Informed Structural Pre-emption (ISP) hypothesis. The current result, primarily driven by the 'ISP_Stealth_Breakout_Factor' and its counterparts, shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0069 and an increase in Annualized Return from 0.052 to 0.0589. However, this comes at the cost of a higher Max Drawdown (-0.0948 vs -0.0726) and a slightly lower Information Ratio (0.919 vs 0.972). The IC improvement suggests that the interaction between stealth accumulation and breakout efficiency captures meaningful predictive signal.",
        "hypothesis_evaluation": "The results support the hypothesis that combining a multi-day stealth accumulation metric with a 1-day breakout efficiency score provides a superior predictive signal compared to single-dimension factors. The 'ISP_Stealth_Breakout_Factor' successfully identifies a lead-lag relationship between quiet positioning and price discovery. However, the increased drawdown suggests that the 'breakout' component might be sensitive to market volatility, requiring better normalization or a more robust definition of 'stealth'.",
        "decision": true,
        "reason": "The current 'stealth' component uses a simple price difference which may be scale-dependent. By using the 'volume-weighted price spread' (as seen in SGZ) but refining it to focus on 'negative volume-return correlation' (quiet accumulation often happens on low volume or price-volume divergence), we can better isolate informed buying. Furthermore, the 1-day gap should be compared against the cross-section rather than just its own history to ensure the 'breakout' is idiosyncratic rather than a market-wide gap-up, which should improve the Information Ratio and reduce Drawdown."
      }
    },
    "b340b157a57ca9fb": {
      "factor_id": "b340b157a57ca9fb",
      "factor_name": "Stealth_Gap_ZScore_Factor",
      "factor_expression": "RANK(TS_MEAN(($close - $open) / ($volume + 1e-8), 10)) * TS_ZSCORE($open - DELAY($close, 1), 20)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($close - $open) / ($volume + 1e-8), 10)) * TS_ZSCORE($open - DELAY($close, 1), 20)\" # Your output factor expression will be filled in here\n    name = \"Stealth_Gap_ZScore_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor targets the 'transition from quiet positioning to active price discovery' by multiplying the 10-day inverse volume-weighted price spread (stealth) by the Z-score of the overnight gap. It uses cross-sectional ranking to ensure the factor is robust against market-wide volatility shifts.",
      "factor_formulation": "\\text{SGZ} = \\text{RANK}(\\text{TS_MEAN}(($close - $open) * (1 / $volume), 10)) * \\text{TS_ZSCORE}($open - \\text{DELAY}($close, 1), 20)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "d7204bd90464",
        "parent_trajectory_ids": [
          "51d281e76291",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Informed Structural Pre-emption (ISP) factor identifies stocks by multiplying a 10-day stealth accumulation score (low-volume divergence between price-weighted and time-weighted averages) by a 1-day breakout efficiency score (overnight gap normalized by intraday volatility).\n                Concise Observation: Parent 1 (AID) captures early signals but lacks timing, while Parent 2 (LVSB) captures momentum but suffers from false breakouts; combining them targets the transition from quiet positioning to active price discovery.\n                Concise Justification: The interaction between information decay (setup) and gap efficiency (trigger) creates a non-linear filter that requires both prior hidden demand and current market validation, reducing noise from retail-driven volatility.\n                Concise Knowledge: If stealth accumulation by informed actors precedes a price breakout, the subsequent price move is more sustainable; when low-volume price-time divergence is followed by a high-efficiency overnight gap, the probability of a high-conviction institutional trend increases.\n                concise Specification: Define AID as the 10-day mean of (VWAP - TWAP) during low-volume periods; define LVSB as (Open - Prev_Close) divided by the 5-day average intraday range; the final ISP factor is the product of these two metrics.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:37:56.729630"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1181062109795754,
        "ICIR": 0.049588885020752,
        "1day.excess_return_without_cost.std": 0.0041557530030952,
        "1day.excess_return_with_cost.annualized_return": 0.0118769886272772,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002475769761354,
        "1day.excess_return_without_cost.annualized_return": 0.0589233203202325,
        "1day.excess_return_with_cost.std": 0.0041553580966072,
        "Rank IC": 0.0271742342497613,
        "IC": 0.006922327091659,
        "1day.excess_return_without_cost.max_drawdown": -0.0948400043707983,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.919070878543165,
        "1day.pa": 0.0,
        "l2.valid": 0.9963171462588418,
        "Rank ICIR": 0.1980746999492646,
        "l2.train": 0.9933581287159392,
        "1day.excess_return_with_cost.information_ratio": 0.1852718363568608,
        "1day.excess_return_with_cost.mean": 4.9903313559988514e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Informed Structural Pre-emption (ISP) hypothesis. The current result, primarily driven by the 'ISP_Stealth_Breakout_Factor' and its counterparts, shows a significant improvement in Information Coefficient (IC) from 0.0058 to 0.0069 and an increase in Annualized Return from 0.052 to 0.0589. However, this comes at the cost of a higher Max Drawdown (-0.0948 vs -0.0726) and a slightly lower Information Ratio (0.919 vs 0.972). The IC improvement suggests that the interaction between stealth accumulation and breakout efficiency captures meaningful predictive signal.",
        "hypothesis_evaluation": "The results support the hypothesis that combining a multi-day stealth accumulation metric with a 1-day breakout efficiency score provides a superior predictive signal compared to single-dimension factors. The 'ISP_Stealth_Breakout_Factor' successfully identifies a lead-lag relationship between quiet positioning and price discovery. However, the increased drawdown suggests that the 'breakout' component might be sensitive to market volatility, requiring better normalization or a more robust definition of 'stealth'.",
        "decision": true,
        "reason": "The current 'stealth' component uses a simple price difference which may be scale-dependent. By using the 'volume-weighted price spread' (as seen in SGZ) but refining it to focus on 'negative volume-return correlation' (quiet accumulation often happens on low volume or price-volume divergence), we can better isolate informed buying. Furthermore, the 1-day gap should be compared against the cross-section rather than just its own history to ensure the 'breakout' is idiosyncratic rather than a market-wide gap-up, which should improve the Information Ratio and reduce Drawdown."
      }
    },
    "fc88e87480f42f89": {
      "factor_id": "fc88e87480f42f89",
      "factor_name": "ISB_Factor_10D",
      "factor_expression": "(($open / DELAY($close, 1) - 1) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 5) + 1e-8)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open / DELAY($close, 1) - 1) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ISB_Factor_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "The Institutional Stealth Breakout (ISB) factor identifies high-quality price trends by multiplying the overnight gap with the 10-day linear regression R-squared of close prices, normalized by intraday volatility. High R-squared indicates a stable, persistent trend, while the gap serves as a tactical entry trigger.",
      "factor_formulation": "ISB = \\frac{(\\text{open} / \\text{delay}(\\text{close}, 1) - 1) \\times \\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2}{\\text{TS\\_MEAN}((\\text{high} - \\text{low}) / \\text{close}, 5)}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "ab440405fa20",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Institutional Stealth Breakout (ISB) factor identifies high-quality price trends by multiplying the magnitude of a liquidity-validated overnight gap with the 10-day linear regression R-squared of daily close prices, while penalizing high intraday volatility.\n                Concise Observation: Parent 2 (RankIC=0.027) successfully captures momentum via gaps but suffers from volatility decay, while Parent 1 (RankIC=0.023) identifies stable trends but lacks a clear entry trigger.\n                Concise Justification: Combining the overnight gap (tactical trigger) with R-squared (persistence filter) ensures that the momentum is both significant at inception and orderly in execution, reducing the risk of 'pump-and-dump' reversals.\n                Concise Knowledge: If an overnight price gap is supported by high relative volume and followed by a high R-squared linear trend with low intraday dispersion, it indicates institutional accumulation rather than retail speculation.\n                concise Specification: Calculate the overnight gap ($open / $close[1] - 1) multiplied by the 10-day rolling R-squared of $close, then divide by the 5-day average of ($high - $low) / $close to normalize for volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:53:09.652573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1126646268963909,
        "ICIR": 0.0420610830854019,
        "1day.excess_return_without_cost.std": 0.004051589566095,
        "1day.excess_return_with_cost.annualized_return": 0.0124731560122608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002493869676311,
        "1day.excess_return_without_cost.annualized_return": 0.0593540982962082,
        "1day.excess_return_with_cost.std": 0.004051176761841,
        "Rank IC": 0.0224972946475899,
        "IC": 0.005657134676375,
        "1day.excess_return_without_cost.max_drawdown": -0.1027964714387138,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.949591435560056,
        "1day.pa": 0.0,
        "l2.valid": 0.9964255113415672,
        "Rank ICIR": 0.1721698278239003,
        "l2.train": 0.9943750166471697,
        "1day.excess_return_with_cost.information_ratio": 0.1995752505235117,
        "1day.excess_return_with_cost.mean": 5.240821853891099e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Stealth Breakout (ISB) hypothesis. The current iteration achieved a higher annualized return (0.059 vs 0.052) compared to the SOTA, although it showed a slight decline in Information Ratio (0.949 vs 0.972) and a deeper maximum drawdown (-0.102 vs -0.072). The IC remains very close to the SOTA (0.0056 vs 0.0057). The results suggest that while the 'Stealth' entry (overnight gap) combined with trend persistence (R-squared) is a valid alpha source, the current implementations may be introducing higher tail risk or volatility, as evidenced by the drawdown increase.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with price persistence (R-squared) identifies high-quality trends is supported by the improvement in annualized returns. However, the 'penalizing high intraday volatility' component (used in ISB_Factor_10D) or the 'volume validation' (ISB_Liquidity_Validated_10D) seems to increase the aggressiveness of the factor at the cost of stability. The 'Stealth' aspect—entering on gaps within low-volatility regimes—shows promise but needs better risk-adjustment to improve the Information Ratio and Drawdown.",
        "decision": true,
        "reason": "The current results show improved returns but higher risk. By using a 'Gap-to-Range' ratio, we normalize the entry trigger against the asset's recent volatility, preventing outsized bets on naturally volatile stocks. Extending the volatility normalization window from 5 to 20 days will provide a more stable denominator, likely reducing the Max Drawdown. Furthermore, integrating volume directly into the persistence measure (rather than as a separate multiplier) ensures that the trend is truly institutional, addressing the 'Stealth' and 'Institutional' components of the hypothesis more cohesively without increasing complexity (SL/ER)."
      }
    },
    "b083151f08771eb0": {
      "factor_id": "b083151f08771eb0",
      "factor_name": "ISB_Liquidity_Validated_10D",
      "factor_expression": "RANK($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK($open / DELAY($close, 1) - 1) * ($volume / (TS_MEAN($volume, 10) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"ISB_Liquidity_Validated_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the ISB factor that incorporates volume validation. It weights the overnight gap by the relative volume to ensure the breakout is supported by institutional activity, then filters by trend persistence (R-squared) and penalizes high-dispersion intraday moves.",
      "factor_formulation": "ISB_{vol} = \\text{RANK}\\left(\\frac{\\text{open}}{\\text{delay}(\\text{close}, 1)} - 1\\right) \\times \\frac{\\text{volume}}{\\text{TS\\_MEAN}(\\text{volume}, 10)} \\times \\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "ab440405fa20",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Institutional Stealth Breakout (ISB) factor identifies high-quality price trends by multiplying the magnitude of a liquidity-validated overnight gap with the 10-day linear regression R-squared of daily close prices, while penalizing high intraday volatility.\n                Concise Observation: Parent 2 (RankIC=0.027) successfully captures momentum via gaps but suffers from volatility decay, while Parent 1 (RankIC=0.023) identifies stable trends but lacks a clear entry trigger.\n                Concise Justification: Combining the overnight gap (tactical trigger) with R-squared (persistence filter) ensures that the momentum is both significant at inception and orderly in execution, reducing the risk of 'pump-and-dump' reversals.\n                Concise Knowledge: If an overnight price gap is supported by high relative volume and followed by a high R-squared linear trend with low intraday dispersion, it indicates institutional accumulation rather than retail speculation.\n                concise Specification: Calculate the overnight gap ($open / $close[1] - 1) multiplied by the 10-day rolling R-squared of $close, then divide by the 5-day average of ($high - $low) / $close to normalize for volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:53:09.652573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1126646268963909,
        "ICIR": 0.0420610830854019,
        "1day.excess_return_without_cost.std": 0.004051589566095,
        "1day.excess_return_with_cost.annualized_return": 0.0124731560122608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002493869676311,
        "1day.excess_return_without_cost.annualized_return": 0.0593540982962082,
        "1day.excess_return_with_cost.std": 0.004051176761841,
        "Rank IC": 0.0224972946475899,
        "IC": 0.005657134676375,
        "1day.excess_return_without_cost.max_drawdown": -0.1027964714387138,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.949591435560056,
        "1day.pa": 0.0,
        "l2.valid": 0.9964255113415672,
        "Rank ICIR": 0.1721698278239003,
        "l2.train": 0.9943750166471697,
        "1day.excess_return_with_cost.information_ratio": 0.1995752505235117,
        "1day.excess_return_with_cost.mean": 5.240821853891099e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Stealth Breakout (ISB) hypothesis. The current iteration achieved a higher annualized return (0.059 vs 0.052) compared to the SOTA, although it showed a slight decline in Information Ratio (0.949 vs 0.972) and a deeper maximum drawdown (-0.102 vs -0.072). The IC remains very close to the SOTA (0.0056 vs 0.0057). The results suggest that while the 'Stealth' entry (overnight gap) combined with trend persistence (R-squared) is a valid alpha source, the current implementations may be introducing higher tail risk or volatility, as evidenced by the drawdown increase.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with price persistence (R-squared) identifies high-quality trends is supported by the improvement in annualized returns. However, the 'penalizing high intraday volatility' component (used in ISB_Factor_10D) or the 'volume validation' (ISB_Liquidity_Validated_10D) seems to increase the aggressiveness of the factor at the cost of stability. The 'Stealth' aspect—entering on gaps within low-volatility regimes—shows promise but needs better risk-adjustment to improve the Information Ratio and Drawdown.",
        "decision": true,
        "reason": "The current results show improved returns but higher risk. By using a 'Gap-to-Range' ratio, we normalize the entry trigger against the asset's recent volatility, preventing outsized bets on naturally volatile stocks. Extending the volatility normalization window from 5 to 20 days will provide a more stable denominator, likely reducing the Max Drawdown. Furthermore, integrating volume directly into the persistence measure (rather than as a separate multiplier) ensures that the trend is truly institutional, addressing the 'Stealth' and 'Institutional' components of the hypothesis more cohesively without increasing complexity (SL/ER)."
      }
    },
    "a1ed978b60929311": {
      "factor_id": "a1ed978b60929311",
      "factor_name": "ISB_Volatility_Adjusted_Trigger",
      "factor_expression": "(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(($open - DELAY($close, 1)) / (TS_MEAN($high - $low, 5) + 1e-8)) * POW(TS_CORR($close, SEQUENCE(10), 10), 2)\" # Your output factor expression will be filled in here\n    name = \"ISB_Volatility_Adjusted_Trigger\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor focuses on the 'Stealth' aspect by identifying gaps that occur within a low-volatility regime. It uses the ratio of the overnight gap to the 5-day average true range (approximated) and scales it by the 10-day price persistence (R-squared).",
      "factor_formulation": "ISB_{adj} = \\frac{\\text{open} - \\text{delay}(\\text{close}, 1)}{\\text{TS\\_MEAN}(\\text{high} - \\text{low}, 5) + 1e-8} \\times \\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)^2",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 10,
        "evolution_phase": "crossover",
        "trajectory_id": "ab440405fa20",
        "parent_trajectory_ids": [
          "e50ec3582ef8",
          "8d9bd5be78a0"
        ],
        "hypothesis": "Hypothesis: The Institutional Stealth Breakout (ISB) factor identifies high-quality price trends by multiplying the magnitude of a liquidity-validated overnight gap with the 10-day linear regression R-squared of daily close prices, while penalizing high intraday volatility.\n                Concise Observation: Parent 2 (RankIC=0.027) successfully captures momentum via gaps but suffers from volatility decay, while Parent 1 (RankIC=0.023) identifies stable trends but lacks a clear entry trigger.\n                Concise Justification: Combining the overnight gap (tactical trigger) with R-squared (persistence filter) ensures that the momentum is both significant at inception and orderly in execution, reducing the risk of 'pump-and-dump' reversals.\n                Concise Knowledge: If an overnight price gap is supported by high relative volume and followed by a high R-squared linear trend with low intraday dispersion, it indicates institutional accumulation rather than retail speculation.\n                concise Specification: Calculate the overnight gap ($open / $close[1] - 1) multiplied by the 10-day rolling R-squared of $close, then divide by the 5-day average of ($high - $low) / $close to normalize for volatility.\n                ",
        "initial_direction": null,
        "planning_direction": null,
        "created_at": "2026-01-21T13:53:09.652573"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1126646268963909,
        "ICIR": 0.0420610830854019,
        "1day.excess_return_without_cost.std": 0.004051589566095,
        "1day.excess_return_with_cost.annualized_return": 0.0124731560122608,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002493869676311,
        "1day.excess_return_without_cost.annualized_return": 0.0593540982962082,
        "1day.excess_return_with_cost.std": 0.004051176761841,
        "Rank IC": 0.0224972946475899,
        "IC": 0.005657134676375,
        "1day.excess_return_without_cost.max_drawdown": -0.1027964714387138,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.949591435560056,
        "1day.pa": 0.0,
        "l2.valid": 0.9964255113415672,
        "Rank ICIR": 0.1721698278239003,
        "l2.train": 0.9943750166471697,
        "1day.excess_return_with_cost.information_ratio": 0.1995752505235117,
        "1day.excess_return_with_cost.mean": 5.240821853891099e-05
      },
      "feedback": {
        "observations": "The experiment tested three variations of the Institutional Stealth Breakout (ISB) hypothesis. The current iteration achieved a higher annualized return (0.059 vs 0.052) compared to the SOTA, although it showed a slight decline in Information Ratio (0.949 vs 0.972) and a deeper maximum drawdown (-0.102 vs -0.072). The IC remains very close to the SOTA (0.0056 vs 0.0057). The results suggest that while the 'Stealth' entry (overnight gap) combined with trend persistence (R-squared) is a valid alpha source, the current implementations may be introducing higher tail risk or volatility, as evidenced by the drawdown increase.",
        "hypothesis_evaluation": "The hypothesis that combining overnight gaps with price persistence (R-squared) identifies high-quality trends is supported by the improvement in annualized returns. However, the 'penalizing high intraday volatility' component (used in ISB_Factor_10D) or the 'volume validation' (ISB_Liquidity_Validated_10D) seems to increase the aggressiveness of the factor at the cost of stability. The 'Stealth' aspect—entering on gaps within low-volatility regimes—shows promise but needs better risk-adjustment to improve the Information Ratio and Drawdown.",
        "decision": true,
        "reason": "The current results show improved returns but higher risk. By using a 'Gap-to-Range' ratio, we normalize the entry trigger against the asset's recent volatility, preventing outsized bets on naturally volatile stocks. Extending the volatility normalization window from 5 to 20 days will provide a more stable denominator, likely reducing the Max Drawdown. Furthermore, integrating volume directly into the persistence measure (rather than as a separate multiplier) ensures that the trend is truly institutional, addressing the 'Stealth' and 'Institutional' components of the hypothesis more cohesively without increasing complexity (SL/ER)."
      }
    },
    "bddbe645cb422037": {
      "factor_id": "bddbe645cb422037",
      "factor_name": "Trend_Exhaustion_Index_10D_5D",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE($close, 5)",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(10), 10), 2) * TS_ZSCORE($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Trend_Exhaustion_Index_10D_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor identifies potential price reversals by multiplying the linearity of a 10-day trend (R-squared) with the short-term price deviation (standardized residual). High values indicate a 'perfect' trend that has over-extended, signaling a speculative climax prone to mean reversion.",
      "factor_formulation": "TEI = (\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10))^2 \\times \\text{TS\\_ZSCORE}(\\text{close}, 5)",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 11,
        "evolution_phase": "mutation",
        "trajectory_id": "9b496977c9e9",
        "parent_trajectory_ids": [
          "b5130bd370bd"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion Index' (TEI) identifies imminent price reversals by calculating the product of the 10-day price-time linear regression R-squared and the 5-day standardized residual of the close price, where extreme values signal a decoupling of price from its structural trend.\n                Concise Observation: The parent strategy focused on trend persistence via volume stability, but failed to account for 'over-extended' states where high-conviction buying leads to technical blow-offs rather than continued growth.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, while high positive residuals represent a 'stretch' beyond the trend line; the interaction of these two identifies speculative climaxes that typically precede a mean-reverting correction.\n                Concise Knowledge: If a price trend exhibits exceptionally high linearity (R-squared) alongside significant positive price deviations (residuals), the probability of mean reversion increases as liquidity demand outstrips sustainable supply; When trends become too 'perfect', they are prone to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Rolling R-Squared of Close vs. Time and the 5-day Standardized Residual (Close minus 5-day Mean Close, divided by 5-day StdDev), targeting a 1-5 day reversal horizon.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T14:08:56.358473"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1633949137073185,
        "ICIR": 0.0681186538195247,
        "1day.excess_return_without_cost.std": 0.0047406425140845,
        "1day.excess_return_with_cost.annualized_return": 0.0132250543006071,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002551803001294,
        "1day.excess_return_without_cost.annualized_return": 0.0607329114308175,
        "1day.excess_return_with_cost.std": 0.004741946905026,
        "Rank IC": 0.0227117109529899,
        "IC": 0.0098400970097212,
        "1day.excess_return_without_cost.max_drawdown": -0.1147480720655139,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8304211763417851,
        "1day.pa": 0.0,
        "l2.valid": 0.9964968733857864,
        "Rank ICIR": 0.1649235812966548,
        "l2.train": 0.9932242337412928,
        "1day.excess_return_with_cost.information_ratio": 0.1807807977087844,
        "1day.excess_return_with_cost.mean": 5.556745504456805e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Trend Exhaustion Index' (TEI) framework has yielded a significant improvement in predictive power, as evidenced by the IC (0.0098 vs 0.0058) and Annualized Return (0.0607 vs 0.0520). However, the Information Ratio (IR) has decreased, and the Max Drawdown has worsened significantly (-0.1147 vs -0.0725), suggesting that while the signal is stronger on average, it has become more volatile or prone to tail risks. The Structural_Decoupling_Score (SDS) and Linear_Stretch_Reversal_Factor (LSR) successfully captured different dimensions of the decoupling effect, but the increased drawdown suggests that the 'exhaustion' signal might be catching high-volatility regimes that are difficult to time perfectly.",
        "hypothesis_evaluation": "The results support the hypothesis that combining trend linearity (R-squared/Correlation) with price deviation (Residuals/Z-Score) identifies meaningful alpha. The increase in IC confirms that the 'decoupling' of price from its structural trend is a valid predictor of future returns. However, the divergence between higher IC/Return and lower IR/higher Drawdown indicates that the current 10-day/5-day window combination might be too sensitive, leading to 'false positives' where a trend appears exhausted but continues to extend (the 'melt-up' problem).",
        "decision": true,
        "reason": "The current drawdown issue suggests the factor triggers too early in high-volatility environments. By introducing a volatility ratio (e.g., TS_STD(close, 20) / TS_STD(close, 5)), we can dampen the signal when short-term volatility spikes relative to the trend, ensuring the 'exhaustion' is measured against a stable structural backdrop. Additionally, simplifying the interaction from a product of ranks to a direct ratio of trend-strength to deviation may reduce complexity while maintaining the core logic."
      }
    },
    "d350e652dc4898b9": {
      "factor_id": "d350e652dc4898b9",
      "factor_name": "Linear_Stretch_Reversal_Factor",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(($close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * RANK(($close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Linear_Stretch_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "A variation of the exhaustion index focusing on the interaction between the 10-day trend strength and the 5-day price deviation from its mean. It uses cross-sectional ranking to normalize the exhaustion signal across the universe.",
      "factor_formulation": "LSR = \\text{RANK}(\\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10)) \\times \\text{RANK}(\\frac{\\text{close} - \\text{TS\\_MEAN}(\\text{close}, 5)}{\\text{TS\\_STD}(\\text{close}, 5) + 1e-8})",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 11,
        "evolution_phase": "mutation",
        "trajectory_id": "9b496977c9e9",
        "parent_trajectory_ids": [
          "b5130bd370bd"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion Index' (TEI) identifies imminent price reversals by calculating the product of the 10-day price-time linear regression R-squared and the 5-day standardized residual of the close price, where extreme values signal a decoupling of price from its structural trend.\n                Concise Observation: The parent strategy focused on trend persistence via volume stability, but failed to account for 'over-extended' states where high-conviction buying leads to technical blow-offs rather than continued growth.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, while high positive residuals represent a 'stretch' beyond the trend line; the interaction of these two identifies speculative climaxes that typically precede a mean-reverting correction.\n                Concise Knowledge: If a price trend exhibits exceptionally high linearity (R-squared) alongside significant positive price deviations (residuals), the probability of mean reversion increases as liquidity demand outstrips sustainable supply; When trends become too 'perfect', they are prone to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Rolling R-Squared of Close vs. Time and the 5-day Standardized Residual (Close minus 5-day Mean Close, divided by 5-day StdDev), targeting a 1-5 day reversal horizon.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T14:08:56.358473"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1633949137073185,
        "ICIR": 0.0681186538195247,
        "1day.excess_return_without_cost.std": 0.0047406425140845,
        "1day.excess_return_with_cost.annualized_return": 0.0132250543006071,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002551803001294,
        "1day.excess_return_without_cost.annualized_return": 0.0607329114308175,
        "1day.excess_return_with_cost.std": 0.004741946905026,
        "Rank IC": 0.0227117109529899,
        "IC": 0.0098400970097212,
        "1day.excess_return_without_cost.max_drawdown": -0.1147480720655139,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8304211763417851,
        "1day.pa": 0.0,
        "l2.valid": 0.9964968733857864,
        "Rank ICIR": 0.1649235812966548,
        "l2.train": 0.9932242337412928,
        "1day.excess_return_with_cost.information_ratio": 0.1807807977087844,
        "1day.excess_return_with_cost.mean": 5.556745504456805e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Trend Exhaustion Index' (TEI) framework has yielded a significant improvement in predictive power, as evidenced by the IC (0.0098 vs 0.0058) and Annualized Return (0.0607 vs 0.0520). However, the Information Ratio (IR) has decreased, and the Max Drawdown has worsened significantly (-0.1147 vs -0.0725), suggesting that while the signal is stronger on average, it has become more volatile or prone to tail risks. The Structural_Decoupling_Score (SDS) and Linear_Stretch_Reversal_Factor (LSR) successfully captured different dimensions of the decoupling effect, but the increased drawdown suggests that the 'exhaustion' signal might be catching high-volatility regimes that are difficult to time perfectly.",
        "hypothesis_evaluation": "The results support the hypothesis that combining trend linearity (R-squared/Correlation) with price deviation (Residuals/Z-Score) identifies meaningful alpha. The increase in IC confirms that the 'decoupling' of price from its structural trend is a valid predictor of future returns. However, the divergence between higher IC/Return and lower IR/higher Drawdown indicates that the current 10-day/5-day window combination might be too sensitive, leading to 'false positives' where a trend appears exhausted but continues to extend (the 'melt-up' problem).",
        "decision": true,
        "reason": "The current drawdown issue suggests the factor triggers too early in high-volatility environments. By introducing a volatility ratio (e.g., TS_STD(close, 20) / TS_STD(close, 5)), we can dampen the signal when short-term volatility spikes relative to the trend, ensuring the 'exhaustion' is measured against a stable structural backdrop. Additionally, simplifying the interaction from a product of ranks to a direct ratio of trend-strength to deviation may reduce complexity while maintaining the core logic."
      }
    },
    "958bb1068fe220d6": {
      "factor_id": "958bb1068fe220d6",
      "factor_name": "Structural_Decoupling_Score",
      "factor_expression": "TS_CORR($close, SEQUENCE(10), 10) * (REGRESI($close, SEQUENCE(5), 5) / (TS_STD($close, 5) + 1e-8))",
      "factor_implementation_code": "File: factor.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_CORR($close, SEQUENCE(10), 10) * (REGRESI($close, SEQUENCE(5), 5) / (TS_STD($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Structural_Decoupling_Score\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)\n",
      "factor_description": "This factor measures the decoupling of price from its structural trend by calculating the product of the 10-day price-time correlation and the 5-day residual from a linear regression. It identifies stocks that are deviating significantly from a highly linear path.",
      "factor_formulation": "SDS = \\text{TS\\_CORR}(\\text{close}, \\text{SEQUENCE}(10), 10) \\times \\frac{\\text{REGRESI}(\\text{close}, \\text{SEQUENCE}(5), 5)}{\\text{TS\\_STD}(\\text{close}, 5) + 1e-8}",
      "cache_location": null,
      "metadata": {
        "experiment_id": "2026-01-20_12-56-39-160392",
        "round_number": 11,
        "evolution_phase": "mutation",
        "trajectory_id": "9b496977c9e9",
        "parent_trajectory_ids": [
          "b5130bd370bd"
        ],
        "hypothesis": "Hypothesis: The 'Trend Exhaustion Index' (TEI) identifies imminent price reversals by calculating the product of the 10-day price-time linear regression R-squared and the 5-day standardized residual of the close price, where extreme values signal a decoupling of price from its structural trend.\n                Concise Observation: The parent strategy focused on trend persistence via volume stability, but failed to account for 'over-extended' states where high-conviction buying leads to technical blow-offs rather than continued growth.\n                Concise Justification: High R-squared values indicate a consensus-driven trend, while high positive residuals represent a 'stretch' beyond the trend line; the interaction of these two identifies speculative climaxes that typically precede a mean-reverting correction.\n                Concise Knowledge: If a price trend exhibits exceptionally high linearity (R-squared) alongside significant positive price deviations (residuals), the probability of mean reversion increases as liquidity demand outstrips sustainable supply; When trends become too 'perfect', they are prone to exhaustion.\n                concise Specification: The factor is defined as the product of the 10-day Rolling R-Squared of Close vs. Time and the 5-day Standardized Residual (Close minus 5-day Mean Close, divided by 5-day StdDev), targeting a 1-5 day reversal horizon.\n                ",
        "initial_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "planning_direction": "Identify 'Trend Exhaustion' by interacting RSQR10 with RESI5: high R-squared combined with high positive residuals suggests an overextended trend prone to mean reversion.",
        "created_at": "2026-01-21T14:08:56.358473"
      },
      "backtest_results": {
        "1day.excess_return_with_cost.max_drawdown": -0.1633949137073185,
        "ICIR": 0.0681186538195247,
        "1day.excess_return_without_cost.std": 0.0047406425140845,
        "1day.excess_return_with_cost.annualized_return": 0.0132250543006071,
        "1day.ffr": 1.0,
        "1day.excess_return_without_cost.mean": 0.0002551803001294,
        "1day.excess_return_without_cost.annualized_return": 0.0607329114308175,
        "1day.excess_return_with_cost.std": 0.004741946905026,
        "Rank IC": 0.0227117109529899,
        "IC": 0.0098400970097212,
        "1day.excess_return_without_cost.max_drawdown": -0.1147480720655139,
        "1day.pos": 0.0,
        "1day.excess_return_without_cost.information_ratio": 0.8304211763417851,
        "1day.pa": 0.0,
        "l2.valid": 0.9964968733857864,
        "Rank ICIR": 0.1649235812966548,
        "l2.train": 0.9932242337412928,
        "1day.excess_return_with_cost.information_ratio": 0.1807807977087844,
        "1day.excess_return_with_cost.mean": 5.556745504456805e-05
      },
      "feedback": {
        "observations": "The current iteration of the 'Trend Exhaustion Index' (TEI) framework has yielded a significant improvement in predictive power, as evidenced by the IC (0.0098 vs 0.0058) and Annualized Return (0.0607 vs 0.0520). However, the Information Ratio (IR) has decreased, and the Max Drawdown has worsened significantly (-0.1147 vs -0.0725), suggesting that while the signal is stronger on average, it has become more volatile or prone to tail risks. The Structural_Decoupling_Score (SDS) and Linear_Stretch_Reversal_Factor (LSR) successfully captured different dimensions of the decoupling effect, but the increased drawdown suggests that the 'exhaustion' signal might be catching high-volatility regimes that are difficult to time perfectly.",
        "hypothesis_evaluation": "The results support the hypothesis that combining trend linearity (R-squared/Correlation) with price deviation (Residuals/Z-Score) identifies meaningful alpha. The increase in IC confirms that the 'decoupling' of price from its structural trend is a valid predictor of future returns. However, the divergence between higher IC/Return and lower IR/higher Drawdown indicates that the current 10-day/5-day window combination might be too sensitive, leading to 'false positives' where a trend appears exhausted but continues to extend (the 'melt-up' problem).",
        "decision": true,
        "reason": "The current drawdown issue suggests the factor triggers too early in high-volatility environments. By introducing a volatility ratio (e.g., TS_STD(close, 20) / TS_STD(close, 5)), we can dampen the signal when short-term volatility spikes relative to the trend, ensuring the 'exhaustion' is measured against a stable structural backdrop. Additionally, simplifying the interaction from a product of ranks to a direct ratio of trend-strength to deviation may reduce complexity while maintaining the core logic."
      }
    }
  }
}